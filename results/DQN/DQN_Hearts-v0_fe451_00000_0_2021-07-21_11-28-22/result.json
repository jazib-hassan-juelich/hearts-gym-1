{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 1080, "agent_timesteps_total": 999, "timers": {"learn_time_ms": 90.535, "learn_throughput": 353.456, "update_time_ms": 4.434}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 0.0018687548581510782, "min_q": -0.008061058819293976, "max_q": 0.012277090921998024, "mean_td_error": -0.05904197692871094, "model": {}}}, "num_steps_sampled": 1080, "num_agent_steps_sampled": 999, "num_steps_trained": 32, "num_agent_steps_trained": 32, "last_target_update_ts": 1080, "num_target_updates": 1}, "done": false, "episodes_total": 0, "training_iteration": 1, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-35", "timestamp": 1626859715, "time_this_iter_s": 0.574526309967041, "time_total_s": 0.574526309967041, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 0.574526309967041, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 41.9, "ram_util_percent": 13.9}, "trial_id": "fe451_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.049382716049383, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7623456790123457}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-14.0, 10.0, 10.0, 9.0, 9.0, 0.0, -6.0, 13.0, 10.0, -10.0, 13.0, 2.0, 14.0, 13.0, -18.0, 6.0, 9.0, 3.0, -6.0, 9.0, -16.0, 13.0, 6.0, 12.0, 13.0, 3.0, 8.0, -9.0, 4.0, 9.0, -6.0, 8.0, 0.0, -5.0, 13.0, 7.0, 10.0, 5.0, -6.0, 6.0, 14.0, -8.0, 1.0, 9.0, 1.0, 9.0, 8.0, -3.0, -4.0, 8.0, 5.0, 6.0, 8.0, 4.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, -10.0, 12.0, 5.0, 8.0, 4.0, 9.0, -9.0, 11.0, 7.0, 6.0, 13.0, -11.0, 5.0, 13.0, -10.0, 7.0, 8.0, 3.0, -5.0, 9.0, -10.0, 8.0, 6.0, 11.0, 11.0, 6.0, -5.0, 3.0, 4.0, 13.0, 5.0, -7.0, 5.0, -9.0, 13.0, 6.0, 10.0, 10.0, -13.0, 8.0, 14.0, 5.0, -9.0, 5.0, -10.0, 11.0, 13.0, 1.0, 8.0, 8.0, 9.0, -10.0, 13.0, 0.0, -10.0, 12.0, -14.0, 10.0, 13.0, 6.0, 6.0, 5.0, -5.0, 9.0, -9.0, 4.0, 7.0, 13.0, 4.0, -4.0, 11.0, 4.0, 12.0, 5.0, 5.0, -7.0, -4.0, 1.0, 7.0, 11.0, -2.0, -1.0, 12.0, 6.0, -6.0, 7.0, 8.0, 6.0, 10.0, 13.0, 4.0, -12.0, 5.0, -9.0, 13.0, 6.0, 11.0, -6.0, 9.0, 1.0, 13.0, -11.0, 1.0, 12.0, 5.0, -8.0, 8.0, 10.0, 10.0, 13.0, -13.0, 5.0, -8.0, 6.0, 8.0, 9.0, 0.0, -2.0, 10.0, 7.0, 13.0, 8.0, -14.0, 8.0, 0.0, 8.0, 3.0, 5.0, 1.0, -11.0, 13.0, 12.0, 0.0, 3.0, 1.0, 11.0, 8.0, 12.0, 10.0, -15.0, 1.0, 7.0, 12.0, -5.0, 9.0, 8.0, -5.0, 3.0, 9.0, 9.0, 2.0, -5.0, -17.0, 12.0, 9.0, 11.0, -7.0, 11.0, -1.0, 12.0, -6.0, 7.0, 5.0, 9.0, 0.0, -5.0, 8.0, 12.0, 11.0, -1.0, -7.0, 12.0, 10.0, 7.0, 9.0, -11.0, 4.0, -6.0, 9.0, 8.0, 11.0, 9.0, -14.0, 9.0, 13.0, 8.0, 3.0, -9.0, 1.0, -6.0, 13.0, 7.0, 10.0, 9.0, -5.0, 1.0, 13.0, -19.0, 12.0, 9.0, -18.0, 10.0, 11.0, 12.0, -11.0, 9.0, 4.0, 13.0, 13.0, 2.0, -12.0, 12.0, 0.0, -6.0, 13.0, 8.0, 13.0, 13.0, -18.0, 7.0, 9.0, 13.0, 8.0, -15.0, 5.0, -6.0, 11.0, 5.0, 10.0, 10.0, 7.0, -12.0, 4.0, 6.0, -2.0, 7.0, 3.0, 7.0, 13.0, -8.0, 12.0, 7.0, 4.0, -8.0, 7.0, 14.0, 10.0, -16.0, 0.0, 9.0, 13.0, -7.0, 9.0, 8.0, -12.0, 10.0, 8.0, 4.0, 4.0, -1.0, 4.0, -12.0, 13.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49183421884154566, "mean_inference_ms": 2.3257063810156766, "mean_action_processing_ms": 0.1482898294445781, "mean_env_wait_ms": 0.2874493297281171, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 4320, "agent_timesteps_total": 4239, "timers": {"learn_time_ms": 1.892, "learn_throughput": 16916.993, "update_time_ms": 4.589}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 2.07486891746521, "min_q": 0.6588262915611267, "max_q": 2.4486308097839355, "mean_td_error": -0.084482342004776, "model": {}}}, "num_steps_sampled": 4320, "num_agent_steps_sampled": 4239, "num_steps_trained": 992, "num_agent_steps_trained": 992, "last_target_update_ts": 4320, "num_target_updates": 7}, "done": false, "episodes_total": 81, "training_iteration": 2, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-36", "timestamp": 1626859716, "time_this_iter_s": 1.149031400680542, "time_total_s": 1.723557710647583, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985059d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1.723557710647583, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 48.35, "ram_util_percent": 13.9}, "trial_id": "fe451_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.01, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 11.0, -17.0, 11.0, 0.0, 5.0, -2.0, 12.0, -2.0, 1.0, 12.0, 4.0, 14.0, 0.0, 12.0, -11.0, 10.0, 12.0, 12.0, -19.0, 12.0, 3.0, -4.0, 4.0, 12.0, 3.0, 6.0, -6.0, 6.0, 11.0, -12.0, 10.0, 11.0, 13.0, 6.0, -15.0, 12.0, 2.0, 9.0, -8.0, -2.0, 12.0, 0.0, 5.0, 10.0, 11.0, -10.0, 4.0, 8.0, 7.0, 6.0, -6.0, 14.0, 2.0, -7.0, 6.0, -1.0, 13.0, 6.0, -3.0, 4.0, 3.0, -5.0, 13.0, 10.0, 8.0, 9.0, -12.0, 9.0, -12.0, 12.0, 6.0, -2.0, 7.0, 0.0, 10.0, 9.0, 7.0, -6.0, 5.0, -1.0, 9.0, 0.0, 7.0, 5.0, 12.0, -11.0, 9.0, -2.0, 11.0, 8.0, -2.0, 9.0, 3.0, -6.0, 9.0, -1.0, 7.0, 8.0, 1.0, 7.0, 5.0, -10.0, 13.0, -5.0, 8.0, -1.0, 13.0, -4.0, 9.0, -3.0, 13.0, 9.0, 12.0, 10.0, -16.0, 0.0, 11.0, -6.0, 10.0, -7.0, 13.0, 2.0, 7.0, 2.0, -5.0, 5.0, 13.0, -6.0, 8.0, 12.0, 1.0, 12.0, 5.0, 0.0, -2.0, 10.0, -5.0, 6.0, 4.0, 7.0, 5.0, -10.0, 13.0, -9.0, 6.0, 7.0, 11.0, 5.0, -4.0, 4.0, 10.0, -5.0, 12.0, 7.0, 1.0, 3.0, -4.0, 4.0, 12.0, 12.0, 12.0, -8.0, -1.0, 12.0, 5.0, -13.0, 11.0, 11.0, -5.0, 10.0, -1.0, -16.0, 6.0, 12.0, 13.0, 8.0, 12.0, 7.0, -12.0, 2.0, 8.0, -6.0, 11.0, 12.0, -3.0, 4.0, 2.0, 8.0, 5.0, -11.0, 13.0, 11.0, 12.0, 10.0, -18.0, 12.0, 6.0, -6.0, 3.0, 9.0, -5.0, 12.0, -1.0, 14.0, 7.0, -5.0, -1.0, -3.0, 11.0, 1.0, 6.0, 7.0, 5.0, -2.0, 5.0, -2.0, -1.0, 12.0, 6.0, -6.0, 7.0, 8.0, 6.0, 10.0, 13.0, 4.0, -12.0, 5.0, -9.0, 13.0, 6.0, 11.0, -6.0, 9.0, 1.0, 13.0, -11.0, 1.0, 12.0, 5.0, -8.0, 8.0, 10.0, 10.0, 13.0, -13.0, 5.0, -8.0, 6.0, 8.0, 9.0, 0.0, -2.0, 10.0, 7.0, 13.0, 8.0, -14.0, 8.0, 0.0, 8.0, 3.0, 5.0, 1.0, -11.0, 13.0, 12.0, 0.0, 3.0, 1.0, 11.0, 8.0, 12.0, 10.0, -15.0, 1.0, 7.0, 12.0, -5.0, 9.0, 8.0, -5.0, 3.0, 9.0, 9.0, 2.0, -5.0, -17.0, 12.0, 9.0, 11.0, -7.0, 11.0, -1.0, 12.0, -6.0, 7.0, 5.0, 9.0, 0.0, -5.0, 8.0, 12.0, 11.0, -1.0, -7.0, 12.0, 10.0, 7.0, 9.0, -11.0, 4.0, -6.0, 9.0, 8.0, 11.0, 9.0, -14.0, 9.0, 13.0, 8.0, 3.0, -9.0, 1.0, -6.0, 13.0, 7.0, 10.0, 9.0, -5.0, 1.0, 13.0, -19.0, 12.0, 9.0, -18.0, 10.0, 11.0, 12.0, -11.0, 9.0, 4.0, 13.0, 13.0, 2.0, -12.0, 12.0, 0.0, -6.0, 13.0, 8.0, 13.0, 13.0, -18.0, 7.0, 9.0, 13.0, 8.0, -15.0, 5.0, -6.0, 11.0, 5.0, 10.0, 10.0, 7.0, -12.0, 4.0, 6.0, -2.0, 7.0, 3.0, 7.0, 13.0, -8.0, 12.0, 7.0, 4.0, -8.0, 7.0, 14.0, 10.0, -16.0, 0.0, 9.0, 13.0, -7.0, 9.0, 8.0, -12.0, 10.0, 8.0, 4.0, 4.0, -1.0, 4.0, -12.0, 13.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4765876288998019, "mean_inference_ms": 2.228262608285445, "mean_action_processing_ms": 0.14015097808981236, "mean_env_wait_ms": 0.2824931354353645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 7560, "agent_timesteps_total": 7479, "timers": {"learn_time_ms": 1.827, "learn_throughput": 17519.381, "update_time_ms": 4.472}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.802488327026367, "min_q": 1.8189221620559692, "max_q": 5.251001834869385, "mean_td_error": -0.5823278427124023, "model": {}}}, "num_steps_sampled": 7560, "num_agent_steps_sampled": 7479, "num_steps_trained": 1952, "num_agent_steps_trained": 1952, "last_target_update_ts": 7560, "num_target_updates": 13}, "done": false, "episodes_total": 135, "training_iteration": 3, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-37", "timestamp": 1626859717, "time_this_iter_s": 1.0876128673553467, "time_total_s": 2.8111705780029297, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2.8111705780029297, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 52.35, "ram_util_percent": 13.95}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 14.0, -9.0, 10.0, 6.0, -8.0, 7.0, 10.0, 6.0, 13.0, -8.0, 4.0, -14.0, 9.0, 7.0, 13.0, 12.0, 6.0, -8.0, 5.0, 4.0, -9.0, 12.0, 8.0, 12.0, 13.0, -9.0, -1.0, 4.0, -2.0, 7.0, 6.0, 6.0, 13.0, -3.0, -1.0, 4.0, -3.0, 4.0, 10.0, 7.0, -6.0, 6.0, 8.0, 4.0, 6.0, -2.0, 7.0, 10.0, 14.0, -8.0, -1.0, 6.0, -3.0, 3.0, 9.0, 10.0, 3.0, -1.0, 3.0, 6.0, -7.0, 7.0, 9.0, 2.0, 8.0, 8.0, -3.0, 6.0, -7.0, 12.0, 4.0, 6.0, 13.0, 4.0, -8.0, -18.0, 10.0, 12.0, 11.0, 12.0, 11.0, -7.0, -1.0, 3.0, 11.0, 12.0, -11.0, 7.0, 12.0, -11.0, 7.0, -14.0, 12.0, 11.0, 6.0, 6.0, 13.0, 8.0, -12.0, 11.0, -6.0, 3.0, 7.0, 6.0, 11.0, 11.0, -13.0, -14.0, 10.0, 7.0, 12.0, 5.0, 11.0, -4.0, 3.0, -13.0, 11.0, 7.0, 10.0, 3.0, 14.0, 5.0, -7.0, 9.0, -9.0, 7.0, 8.0, 8.0, 8.0, -7.0, 6.0, 4.0, -7.0, 7.0, 11.0, 7.0, 10.0, -4.0, 2.0, -12.0, 13.0, 7.0, 7.0, 10.0, 12.0, 9.0, -16.0, 6.0, -5.0, 8.0, 6.0, 10.0, 11.0, -12.0, 6.0, -13.0, 8.0, 12.0, 8.0, 0.0, 12.0, 7.0, -4.0, 7.0, -5.0, 4.0, 9.0, 12.0, -12.0, 12.0, 3.0, 4.0, -2.0, 8.0, 5.0, 6.0, 13.0, 7.0, -11.0, 2.0, -7.0, 12.0, 8.0, 12.0, 11.0, -8.0, 0.0, 9.0, 10.0, -9.0, 5.0, 6.0, 11.0, -3.0, 1.0, -16.0, 11.0, 12.0, 8.0, 12.0, 13.0, 5.0, -15.0, 4.0, -3.0, 7.0, 7.0, 12.0, 11.0, -10.0, 2.0, 4.0, -4.0, 7.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 2.0, 9.0, -8.0, -2.0, 12.0, 0.0, 5.0, 10.0, 11.0, -10.0, 4.0, 8.0, 7.0, 6.0, -6.0, 14.0, 2.0, -7.0, 6.0, -1.0, 13.0, 6.0, -3.0, 4.0, 3.0, -5.0, 13.0, 10.0, 8.0, 9.0, -12.0, 9.0, -12.0, 12.0, 6.0, -2.0, 7.0, 0.0, 10.0, 9.0, 7.0, -6.0, 5.0, -1.0, 9.0, 0.0, 7.0, 5.0, 12.0, -11.0, 9.0, -2.0, 11.0, 8.0, -2.0, 9.0, 3.0, -6.0, 9.0, -1.0, 7.0, 8.0, 1.0, 7.0, 5.0, -10.0, 13.0, -5.0, 8.0, -1.0, 13.0, -4.0, 9.0, -3.0, 13.0, 9.0, 12.0, 10.0, -16.0, 0.0, 11.0, -6.0, 10.0, -7.0, 13.0, 2.0, 7.0, 2.0, -5.0, 5.0, 13.0, -6.0, 8.0, 12.0, 1.0, 12.0, 5.0, 0.0, -2.0, 10.0, -5.0, 6.0, 4.0, 7.0, 5.0, -10.0, 13.0, -9.0, 6.0, 7.0, 11.0, 5.0, -4.0, 4.0, 10.0, -5.0, 12.0, 7.0, 1.0, 3.0, -4.0, 4.0, 12.0, 12.0, 12.0, -8.0, -1.0, 12.0, 5.0, -13.0, 11.0, 11.0, -5.0, 10.0, -1.0, -16.0, 6.0, 12.0, 13.0, 8.0, 12.0, 7.0, -12.0, 2.0, 8.0, -6.0, 11.0, 12.0, -3.0, 4.0, 2.0, 8.0, 5.0, -11.0, 13.0, 11.0, 12.0, 10.0, -18.0, 12.0, 6.0, -6.0, 3.0, 9.0, -5.0, 12.0, -1.0, 14.0, 7.0, -5.0, -1.0, -3.0, 11.0, 1.0, 6.0, 7.0, 5.0, -2.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4814734780408939, "mean_inference_ms": 2.1419360399184852, "mean_action_processing_ms": 0.1331879781778086, "mean_env_wait_ms": 0.2843527843353366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 10800, "agent_timesteps_total": 10719, "timers": {"learn_time_ms": 2.099, "learn_throughput": 15244.912, "update_time_ms": 5.07}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 7.174667835235596, "min_q": 3.215106964111328, "max_q": 7.932251453399658, "mean_td_error": 0.21982930600643158, "model": {}}}, "num_steps_sampled": 10800, "num_agent_steps_sampled": 10719, "num_steps_trained": 2912, "num_agent_steps_trained": 2912, "last_target_update_ts": 10800, "num_target_updates": 19}, "done": false, "episodes_total": 189, "training_iteration": 4, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-39", "timestamp": 1626859719, "time_this_iter_s": 1.1484711170196533, "time_total_s": 3.959641695022583, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985419d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 3.959641695022583, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 50.7, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, -8.0, 10.0, 10.0, 3.0, 11.0, 12.0, 10.0, -18.0, 10.0, 11.0, 4.0, -10.0, 13.0, 12.0, -12.0, 2.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 13.0, 11.0, 6.0, -15.0, 12.0, 11.0, -11.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 12.0, 12.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 7.0, -3.0, 9.0, 2.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 9.0, 12.0, 5.0, -11.0, 10.0, 11.0, 4.0, -10.0, 12.0, 11.0, -11.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 9.0, 12.0, 5.0, -11.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 13.0, -6.0, 5.0, 3.0, 13.0, 12.0, -12.0, 2.0, 12.0, -4.0, 5.0, 2.0, 10.0, 11.0, 4.0, -10.0, 7.0, -4.0, 9.0, 3.0, 10.0, 13.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 12.0, 12.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 11.0, 11.0, 5.0, -12.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 9.0, 11.0, 1.0, -6.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 9.0, 12.0, 10.0, -16.0, 10.0, 11.0, 4.0, -10.0, 7.0, -4.0, 9.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 5.0, 11.0, 4.0, -5.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, -12.0, 13.0, 7.0, 7.0, 10.0, 12.0, 9.0, -16.0, 6.0, -5.0, 8.0, 6.0, 10.0, 11.0, -12.0, 6.0, -13.0, 8.0, 12.0, 8.0, 0.0, 12.0, 7.0, -4.0, 7.0, -5.0, 4.0, 9.0, 12.0, -12.0, 12.0, 3.0, 4.0, -2.0, 8.0, 5.0, 6.0, 13.0, 7.0, -11.0, 2.0, -7.0, 12.0, 8.0, 12.0, 11.0, -8.0, 0.0, 9.0, 10.0, -9.0, 5.0, 6.0, 11.0, -3.0, 1.0, -16.0, 11.0, 12.0, 8.0, 12.0, 13.0, 5.0, -15.0, 4.0, -3.0, 7.0, 7.0, 12.0, 11.0, -10.0, 2.0, 4.0, -4.0, 7.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.47942820233307837, "mean_inference_ms": 2.0779303391711346, "mean_action_processing_ms": 0.1279487281132058, "mean_env_wait_ms": 0.2811290033693684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 14040, "agent_timesteps_total": 13959, "timers": {"learn_time_ms": 1.902, "learn_throughput": 16823.059, "update_time_ms": 4.011}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 9.496915817260742, "min_q": 8.104626655578613, "max_q": 10.048816680908203, "mean_td_error": 1.8656500577926636, "model": {}}}, "num_steps_sampled": 14040, "num_agent_steps_sampled": 13959, "num_steps_trained": 3872, "num_agent_steps_trained": 3872, "last_target_update_ts": 14040, "num_target_updates": 25}, "done": false, "episodes_total": 270, "training_iteration": 5, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-40", "timestamp": 1626859720, "time_this_iter_s": 1.1752119064331055, "time_total_s": 5.1348536014556885, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 5.1348536014556885, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 51.55, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 6.0, -9.0, 10.0, 8.0, -6.0, 1.0, 10.0, 10.0, 6.0, -10.0, 11.0, 8.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -7.0, 1.0, 11.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 6.0, -10.0, 11.0, 8.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 6.0, -3.0, 3.0, 9.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, 11.0, -20.0, 11.0, 13.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 12.0, 11.0, 3.0, -11.0, 11.0, -19.0, 10.0, 13.0, 7.0, 7.0, 12.0, -11.0, -3.0, -2.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, -7.0, 10.0, 3.0, 9.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 6.0, -10.0, 11.0, 8.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 6.0, 13.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, 9.0, 1.0, 10.0, -5.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 9.0, 12.0, 5.0, -11.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 13.0, -6.0, 5.0, 3.0, 13.0, 12.0, -12.0, 2.0, 12.0, -4.0, 5.0, 2.0, 10.0, 11.0, 4.0, -10.0, 7.0, -4.0, 9.0, 3.0, 10.0, 13.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 12.0, 12.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 11.0, 11.0, 5.0, -12.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 9.0, 11.0, 1.0, -6.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 9.0, 12.0, 10.0, -16.0, 10.0, 11.0, 4.0, -10.0, 7.0, -4.0, 9.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 5.0, 11.0, 4.0, -5.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0, 13.0, 11.0, -12.0, 3.0, 11.0, 12.0, 5.0, -13.0, 10.0, 11.0, 4.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.47745929285255884, "mean_inference_ms": 2.0537826588439545, "mean_action_processing_ms": 0.12624590751288164, "mean_env_wait_ms": 0.27860038500607376, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 17280, "agent_timesteps_total": 17199, "timers": {"learn_time_ms": 1.899, "learn_throughput": 16851.785, "update_time_ms": 4.348}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 10.493539810180664, "min_q": 6.440011024475098, "max_q": 11.172215461730957, "mean_td_error": 1.3554420471191406, "model": {}}}, "num_steps_sampled": 17280, "num_agent_steps_sampled": 17199, "num_steps_trained": 4832, "num_agent_steps_trained": 4832, "last_target_update_ts": 17280, "num_target_updates": 31}, "done": false, "episodes_total": 324, "training_iteration": 6, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-41", "timestamp": 1626859721, "time_this_iter_s": 1.0912833213806152, "time_total_s": 6.226136922836304, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 6.226136922836304, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 48.5, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 7.0, 4.0, 11.0, -7.0, 4.0, 10.0, 7.0, -6.0, 5.0, -9.0, 11.0, 8.0, 3.0, 14.0, -7.0, 5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 7.0, 4.0, 11.0, -7.0, 3.0, 10.0, 7.0, -5.0, 9.0, 2.0, 11.0, -7.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 7.0, -9.0, 11.0, 6.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 6.0, 9.0, 11.0, -11.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, -8.0, 8.0, 10.0, 5.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, -2.0, 10.0, -2.0, 9.0, 5.0, -9.0, 11.0, 8.0, -2.0, 14.0, 8.0, -5.0, 10.0, 9.0, 10.0, -14.0, 3.0, 10.0, 7.0, -5.0, 3.0, 8.0, 11.0, -7.0, 3.0, 10.0, 7.0, -5.0, 6.0, 6.0, 12.0, -9.0, 3.0, 10.0, 7.0, -5.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 6.0, -9.0, 10.0, 8.0, -6.0, 1.0, 10.0, 10.0, 6.0, -10.0, 11.0, 8.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -7.0, 1.0, 11.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 6.0, -10.0, 11.0, 8.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 6.0, -3.0, 3.0, 9.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, 11.0, -20.0, 11.0, 13.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 12.0, 11.0, 3.0, -11.0, 11.0, -19.0, 10.0, 13.0, 7.0, 7.0, 12.0, -11.0, -3.0, -2.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, -7.0, 10.0, 3.0, 9.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 6.0, -10.0, 11.0, 8.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 6.0, 13.0, -11.0, -6.0, 1.0, 10.0, 10.0, 7.0, 7.0, 12.0, -11.0, 9.0, 1.0, 10.0, -5.0, 7.0, 7.0, 12.0, -11.0, -6.0, 1.0, 10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4812897160018155, "mean_inference_ms": 2.055002528702579, "mean_action_processing_ms": 0.12600492341005481, "mean_env_wait_ms": 0.2811971804574364, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 20520, "agent_timesteps_total": 20439, "timers": {"learn_time_ms": 1.892, "learn_throughput": 16915.713, "update_time_ms": 5.271}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 12.37751579284668, "min_q": 11.263598442077637, "max_q": 12.84737777709961, "mean_td_error": 0.9732487201690674, "model": {}}}, "num_steps_sampled": 20520, "num_agent_steps_sampled": 20439, "num_steps_trained": 5792, "num_agent_steps_trained": 5792, "last_target_update_ts": 20520, "num_target_updates": 37}, "done": false, "episodes_total": 378, "training_iteration": 7, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-42", "timestamp": 1626859722, "time_this_iter_s": 1.136369228363037, "time_total_s": 7.362506151199341, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 7.362506151199341, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 49.6, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -14.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-7.0, 12.0, 2.0, 8.0, 1.0, 7.0, 9.0, -2.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, 9.0, 13.0, -2.0, -5.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 9.0, 1.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -10.0, 12.0, 2.0, 11.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, 7.0, 7.0, 6.0, -5.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, -8.0, 12.0, 10.0, 9.0, 10.0, 0.0, -4.0, -11.0, 14.0, -1.0, 13.0, -12.0, 12.0, 2.0, 13.0, 9.0, 10.0, 0.0, -4.0, 13.0, 6.0, -14.0, 10.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -6.0, 12.0, 1.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -6.0, 12.0, -1.0, 10.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 7.0, 12.0, -5.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, -8.0, 8.0, 10.0, 5.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, 3.0, 10.0, 7.0, -5.0, 5.0, -9.0, 11.0, 8.0, -2.0, 10.0, -2.0, 9.0, 5.0, -9.0, 11.0, 8.0, -2.0, 14.0, 8.0, -5.0, 10.0, 9.0, 10.0, -14.0, 3.0, 10.0, 7.0, -5.0, 3.0, 8.0, 11.0, -7.0, 3.0, 10.0, 7.0, -5.0, 6.0, 6.0, 12.0, -9.0, 3.0, 10.0, 7.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4780114053324445, "mean_inference_ms": 2.0465778417423888, "mean_action_processing_ms": 0.12467050376125588, "mean_env_wait_ms": 0.28100652605485565, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 23760, "agent_timesteps_total": 23679, "timers": {"learn_time_ms": 2.011, "learn_throughput": 15911.435, "update_time_ms": 4.404}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 13.41256332397461, "min_q": 11.42762279510498, "max_q": 14.457015991210938, "mean_td_error": 0.6290714740753174, "model": {}}}, "num_steps_sampled": 23760, "num_agent_steps_sampled": 23679, "num_steps_trained": 6752, "num_agent_steps_trained": 6752, "last_target_update_ts": 23760, "num_target_updates": 43}, "done": false, "episodes_total": 459, "training_iteration": 8, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-43", "timestamp": 1626859723, "time_this_iter_s": 1.110170841217041, "time_total_s": 8.472676992416382, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 8.472676992416382, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 52.3, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -14.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 7.0, 5.0, 4.0, -10.0, 13.0, 10.0, 2.0, 12.0, 7.0, 8.0, -12.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, 13.0, -13.0, 11.0, 4.0, 6.0, 13.0, -6.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, 13.0, -9.0, 7.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, 0.0, 5.0, 6.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, 0.0, 4.0, 11.0, 0.0, 6.0, 14.0, -7.0, 2.0, -1.0, 6.0, 6.0, 4.0, 12.0, -7.0, 11.0, -1.0, -8.0, 9.0, 9.0, 5.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 6.0, 3.0, 6.0, -1.0, 10.0, 0.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 5.0, -7.0, 11.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -12.0, 7.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, 7.0, 7.0, 6.0, -5.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, -8.0, 12.0, 10.0, 9.0, 10.0, 0.0, -4.0, -11.0, 14.0, -1.0, 13.0, -12.0, 12.0, 2.0, 13.0, 9.0, 10.0, 0.0, -4.0, 13.0, 6.0, -14.0, 10.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -6.0, 12.0, 1.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -6.0, 12.0, -1.0, 10.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 7.0, 12.0, -5.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0, -7.0, 12.0, 2.0, 8.0, 1.0, 6.0, 9.0, -1.0, 9.0, 10.0, 0.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.47624384764250216, "mean_inference_ms": 2.036362931879114, "mean_action_processing_ms": 0.12399708411710933, "mean_env_wait_ms": 0.27969225956988364, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 27000, "agent_timesteps_total": 26919, "timers": {"learn_time_ms": 1.852, "learn_throughput": 17279.621, "update_time_ms": 4.723}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 14.089498519897461, "min_q": 10.462028503417969, "max_q": 15.357046127319336, "mean_td_error": 1.089735746383667, "model": {}}}, "num_steps_sampled": 27000, "num_agent_steps_sampled": 26919, "num_steps_trained": 7712, "num_agent_steps_trained": 7712, "last_target_update_ts": 27000, "num_target_updates": 49}, "done": false, "episodes_total": 513, "training_iteration": 9, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-44", "timestamp": 1626859724, "time_this_iter_s": 1.084895372390747, "time_total_s": 9.557572364807129, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 9.557572364807129, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 52.099999999999994, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, 4.0, -1.0, 12.0, 0.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -11.0, 11.0, 12.0, 3.0, 13.0, -16.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -12.0, 12.0, 3.0, -10.0, 11.0, 12.0, 2.0, 12.0, -13.0, 10.0, 6.0, 4.0, -1.0, 12.0, 0.0, 12.0, -15.0, 9.0, 9.0, -14.0, 12.0, 12.0, 5.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -10.0, 4.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -14.0, 10.0, 12.0, 7.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -13.0, 7.0, 9.0, 3.0, -1.0, 12.0, 1.0, 12.0, -15.0, 9.0, 9.0, 3.0, 12.0, 12.0, -12.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, 4.0, 12.0, 12.0, -13.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, 3.0, 13.0, 12.0, -13.0, 12.0, -15.0, 9.0, 9.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, 13.0, -9.0, 7.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, 0.0, 5.0, 6.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, 0.0, 4.0, 11.0, 0.0, 6.0, 14.0, -7.0, 2.0, -1.0, 6.0, 6.0, 4.0, 12.0, -7.0, 11.0, -1.0, -8.0, 9.0, 9.0, 5.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 6.0, 3.0, 6.0, -1.0, 10.0, 0.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 5.0, -7.0, 11.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -12.0, 7.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0, -1.0, 7.0, 5.0, 4.0, 6.0, 14.0, -7.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4810745046102646, "mean_inference_ms": 2.0403776221422656, "mean_action_processing_ms": 0.12429512602402017, "mean_env_wait_ms": 0.28240214261294677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 30240, "agent_timesteps_total": 30159, "timers": {"learn_time_ms": 1.824, "learn_throughput": 17546.177, "update_time_ms": 4.838}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 15.231819152832031, "min_q": 12.017353057861328, "max_q": 16.622648239135742, "mean_td_error": 1.3143956661224365, "model": {}}}, "num_steps_sampled": 30240, "num_agent_steps_sampled": 30159, "num_steps_trained": 8672, "num_agent_steps_trained": 8672, "last_target_update_ts": 30240, "num_target_updates": 55}, "done": false, "episodes_total": 567, "training_iteration": 10, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-46", "timestamp": 1626859726, "time_this_iter_s": 1.2707796096801758, "time_total_s": 10.828351974487305, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da0d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 10.828351974487305, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 47.0, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 8.0, 14.0, -10.0, 3.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, -9.0, -1.0, 8.0, 10.0, -4.0, 1.0, -10.0, 6.0, 13.0, 6.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, -7.0, 5.0, 13.0, 4.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 5.0, -14.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 5.0, 4.0, 10.0, -4.0, 11.0, 14.0, 12.0, -22.0, 11.0, 10.0, -7.0, 1.0, 11.0, -16.0, 13.0, 7.0, 11.0, 14.0, 12.0, -22.0, -5.0, 10.0, 9.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, -2.0, -8.0, 6.0, 10.0, 9.0, -10.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 3.0, 1.0, 13.0, -2.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 5.0, 4.0, 10.0, -4.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 12.0, 14.0, 12.0, 316.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 3.0, -11.0, 13.0, 10.0, 11.0, 14.0, -8.0, -2.0, 7.0, 11.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 12.0, 14.0, 12.0, 316.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 13.0, 14.0, 10.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 7.0, -11.0, 13.0, 6.0, 13.0, 6.0, 11.0, -15.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 7.0, 10.0, -3.0, 1.0, 3.0, -13.0, 13.0, 12.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -13.0, 7.0, 9.0, 3.0, -1.0, 12.0, 1.0, 12.0, -15.0, 9.0, 9.0, 3.0, 12.0, 12.0, -12.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, 4.0, 12.0, 12.0, -13.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, -10.0, 11.0, 12.0, 2.0, 12.0, -15.0, 9.0, 9.0, 3.0, 13.0, 12.0, -13.0, 12.0, -15.0, 9.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48032348554355636, "mean_inference_ms": 2.0297325021821924, "mean_action_processing_ms": 0.12308246293436015, "mean_env_wait_ms": 0.2817891955105661, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 33480, "agent_timesteps_total": 33399, "timers": {"learn_time_ms": 1.839, "learn_throughput": 17400.818, "update_time_ms": 4.298}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 16.109333038330078, "min_q": 13.009016036987305, "max_q": 17.498519897460938, "mean_td_error": 2.2078187465667725, "model": {}}}, "num_steps_sampled": 33480, "num_agent_steps_sampled": 33399, "num_steps_trained": 9632, "num_agent_steps_trained": 9632, "last_target_update_ts": 33480, "num_target_updates": 61}, "done": false, "episodes_total": 648, "training_iteration": 11, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-47", "timestamp": 1626859727, "time_this_iter_s": 1.1047868728637695, "time_total_s": 11.933138847351074, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 11.933138847351074, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 51.5, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -16.0, 13.0, 7.0, 5.0, -12.0, 9.0, 13.0, 11.0, -16.0, 13.0, 7.0, 14.0, 0.0, -8.0, 9.0, 11.0, -14.0, 13.0, 5.0, 7.0, -13.0, 9.0, 12.0, 10.0, -15.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 10.0, -17.0, 12.0, 10.0, 14.0, 1.0, 8.0, -8.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 8.0, -12.0, 11.0, 8.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 13.0, 1.0, 9.0, -8.0, 9.0, -7.0, 10.0, 3.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 14.0, 0.0, 11.0, -10.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 10.0, -5.0, 7.0, 3.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 8.0, -13.0, 10.0, 10.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -2.0, -1.0, 7.0, 14.0, 1.0, 8.0, -8.0, 11.0, -16.0, 13.0, 7.0, -2.0, -2.0, 9.0, 10.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 13.0, 1.0, 9.0, -8.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 3.0, 1.0, 13.0, -2.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 5.0, 4.0, 10.0, -4.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 12.0, 14.0, 12.0, 316.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 3.0, -11.0, 13.0, 10.0, 11.0, 14.0, -8.0, -2.0, 7.0, 11.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 12.0, 14.0, 12.0, 316.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 13.0, 14.0, 10.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 7.0, -11.0, 13.0, 6.0, 13.0, 6.0, 11.0, -15.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 7.0, 10.0, -3.0, 1.0, 3.0, -13.0, 13.0, 12.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0, 8.0, 10.0, -4.0, 1.0, 6.0, -15.0, 13.0, 11.0, 11.0, 14.0, 12.0, -22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.47759961164118164, "mean_inference_ms": 2.0177867275965657, "mean_action_processing_ms": 0.12223234433551726, "mean_env_wait_ms": 0.27978242039997736, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 36720, "agent_timesteps_total": 36639, "timers": {"learn_time_ms": 1.756, "learn_throughput": 18222.24, "update_time_ms": 3.91}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 15.98570442199707, "min_q": 12.432424545288086, "max_q": 18.630075454711914, "mean_td_error": 1.3051735162734985, "model": {}}}, "num_steps_sampled": 36720, "num_agent_steps_sampled": 36639, "num_steps_trained": 10592, "num_agent_steps_trained": 10592, "last_target_update_ts": 36720, "num_target_updates": 67}, "done": false, "episodes_total": 702, "training_iteration": 12, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-48", "timestamp": 1626859728, "time_this_iter_s": 1.0693912506103516, "time_total_s": 13.002530097961426, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99bb6fb730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 13.002530097961426, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 50.9, "ram_util_percent": 14.0}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 4.0, 8.0, 6.0, -3.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 6.0, -1.0, -1.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 2.0, 3.0, 10.0, -4.0, 13.0, 12.0, -6.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -16.0, 8.0, 11.0, 12.0, 11.0, 13.0, -4.0, -5.0, -1.0, 1.0, 10.0, 5.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -7.0, 12.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, -2.0, 7.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, -13.0, 13.0, 3.0, 12.0, 0.0, 2.0, 3.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, -5.0, 10.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 2.0, 3.0, 10.0, -4.0, 13.0, 12.0, -6.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, -5.0, 10.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -16.0, 8.0, 11.0, 12.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -16.0, 8.0, 11.0, 12.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 3.0, 8.0, 5.0, -1.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 2.0, 3.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 8.0, -13.0, 10.0, 10.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -2.0, -1.0, 7.0, 14.0, 1.0, 8.0, -8.0, 11.0, -16.0, 13.0, 7.0, -2.0, -2.0, 9.0, 10.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 7.0, -13.0, 9.0, 12.0, 11.0, -16.0, 13.0, 7.0, 13.0, 1.0, 9.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4788029541994628, "mean_inference_ms": 2.014429700072677, "mean_action_processing_ms": 0.12212470631203978, "mean_env_wait_ms": 0.28091399787379073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 39960, "agent_timesteps_total": 39933, "timers": {"learn_time_ms": 1.932, "learn_throughput": 16562.524, "update_time_ms": 4.616}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 16.909420013427734, "min_q": 13.910341262817383, "max_q": 19.836292266845703, "mean_td_error": 1.2858045101165771, "model": {}}}, "num_steps_sampled": 39960, "num_agent_steps_sampled": 39933, "num_steps_trained": 11552, "num_agent_steps_trained": 11552, "last_target_update_ts": 39960, "num_target_updates": 73}, "done": false, "episodes_total": 783, "training_iteration": 13, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-49", "timestamp": 1626859729, "time_this_iter_s": 1.1320860385894775, "time_total_s": 14.134616136550903, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985057b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 14.134616136550903, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 14.0, 2.0, -14.0, 13.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 1.0, 10.0, -9.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -6.0, -1.0, 10.0, 12.0, 13.0, 7.0, 4.0, -9.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 9.0, -9.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 14.0, 2.0, 3.0, -4.0, -18.0, 11.0, 10.0, 12.0, 13.0, -1.0, -4.0, 7.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, -5.0, 10.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 2.0, 3.0, 10.0, -4.0, 13.0, 12.0, -6.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, -5.0, 10.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -16.0, 8.0, 11.0, 12.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -16.0, 8.0, 11.0, 12.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 3.0, 8.0, 5.0, -1.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 2.0, 3.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0, 11.0, 13.0, -4.0, -5.0, 0.0, 1.0, 4.0, 10.0, -3.0, 8.0, 11.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4773965914345878, "mean_inference_ms": 2.009526680499346, "mean_action_processing_ms": 0.12182567492589552, "mean_env_wait_ms": 0.27984673576735686, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 43200, "agent_timesteps_total": 43119, "timers": {"learn_time_ms": 1.854, "learn_throughput": 17257.181, "update_time_ms": 4.682}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 18.81936264038086, "min_q": 14.655940055847168, "max_q": 20.610883712768555, "mean_td_error": 0.41356194019317627, "model": {}}}, "num_steps_sampled": 43200, "num_agent_steps_sampled": 43119, "num_steps_trained": 12512, "num_agent_steps_trained": 12512, "last_target_update_ts": 43200, "num_target_updates": 79}, "done": false, "episodes_total": 837, "training_iteration": 14, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-50", "timestamp": 1626859730, "time_this_iter_s": 1.1123933792114258, "time_total_s": 15.247009515762329, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 15.247009515762329, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 51.45, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 14.0, 3.0, 8.0, 6.0, 3.0, -6.0, 12.0, 8.0, 14.0, -11.0, 4.0, 13.0, -1.0, -6.0, 9.0, 1.0, 14.0, -11.0, 11.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, 1.0, 14.0, -11.0, 11.0, 11.0, -1.0, -5.0, 10.0, -11.0, 14.0, 3.0, 9.0, 9.0, -1.0, -5.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 13.0, 9.0, 3.0, 8.0, 0.0, -5.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -3.0, 14.0, 3.0, 1.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -3.0, 14.0, -3.0, 7.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 13.0, -3.0, -5.0, 10.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 13.0, 3.0, 9.0, 10.0, -1.0, -6.0, 12.0, -11.0, 14.0, 3.0, 9.0, 10.0, -2.0, -3.0, 10.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 13.0, 9.0, 3.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 14.0, -4.0, -5.0, 10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -6.0, -1.0, 10.0, 12.0, 13.0, 7.0, 4.0, -9.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 9.0, -9.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 14.0, 2.0, 3.0, -4.0, -18.0, 11.0, 10.0, 12.0, 13.0, -1.0, -4.0, 7.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0, -18.0, 11.0, 10.0, 12.0, 13.0, 2.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4829309772463071, "mean_inference_ms": 2.022116096125205, "mean_action_processing_ms": 0.1227780246437336, "mean_env_wait_ms": 0.28281602357237495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 46440, "agent_timesteps_total": 46359, "timers": {"learn_time_ms": 1.895, "learn_throughput": 16888.256, "update_time_ms": 4.045}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 18.440258026123047, "min_q": 14.475669860839844, "max_q": 21.399715423583984, "mean_td_error": 2.0624871253967285, "model": {}}}, "num_steps_sampled": 46440, "num_agent_steps_sampled": 46359, "num_steps_trained": 13472, "num_agent_steps_trained": 13472, "last_target_update_ts": 46440, "num_target_updates": 85}, "done": false, "episodes_total": 891, "training_iteration": 15, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-52", "timestamp": 1626859732, "time_this_iter_s": 1.1376080513000488, "time_total_s": 16.384617567062378, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 16.384617567062378, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 51.75, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 8.0, -20.0, 7.0, 2.0, 7.0, -1.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 12.0, 11.0, -20.0, 12.0, 14.0, 9.0, -20.0, 4.0, 7.0, -4.0, 8.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 13.0, 7.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, -2.0, 11.0, 7.0, -1.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 9.0, 14.0, 1.0, -9.0, 5.0, 7.0, 7.0, -4.0, 11.0, 5.0, 10.0, -11.0, 13.0, 14.0, 4.0, -16.0, 6.0, 6.0, 12.0, -9.0, 12.0, 13.0, 12.0, 317.0, -9.0, 12.0, 4.0, 8.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 4.0, 7.0, -4.0, 8.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 10.0, -1.0, -6.0, 12.0, -3.0, 14.0, -3.0, 7.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 13.0, -3.0, -5.0, 10.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 13.0, 3.0, 9.0, 10.0, -1.0, -6.0, 12.0, -11.0, 14.0, 3.0, 9.0, 10.0, -2.0, -3.0, 10.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 10.0, -1.0, -6.0, 12.0, -10.0, 13.0, 9.0, 3.0, 10.0, -1.0, -6.0, 12.0, -10.0, 14.0, 3.0, 8.0, 14.0, -4.0, -5.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4807722169782005, "mean_inference_ms": 2.0126891829220224, "mean_action_processing_ms": 0.12188189617908612, "mean_env_wait_ms": 0.2817466078214253, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 49680, "agent_timesteps_total": 49626, "timers": {"learn_time_ms": 1.832, "learn_throughput": 17471.034, "update_time_ms": 4.246}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 19.071483612060547, "min_q": 14.063986778259277, "max_q": 21.103260040283203, "mean_td_error": 0.5294293165206909, "model": {}}}, "num_steps_sampled": 49680, "num_agent_steps_sampled": 49626, "num_steps_trained": 14432, "num_agent_steps_trained": 14432, "last_target_update_ts": 49680, "num_target_updates": 91}, "done": false, "episodes_total": 972, "training_iteration": 16, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-53", "timestamp": 1626859733, "time_this_iter_s": 1.2364351749420166, "time_total_s": 17.621052742004395, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 17.621052742004395, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 46.05, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, 13.0, -9.0, 4.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 13.0, 8.0, 0.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 13.0, 8.0, 0.0, -2.0, 10.0, 4.0, 3.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, 319.0, 13.0, 10.0, 12.0, 11.0, -2.0, 3.0, 3.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 13.0, 8.0, 0.0, -2.0, 5.0, 5.0, 7.0, 8.0, -1.0, 8.0, 0.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -1.0, 6.0, 8.0, 2.0, 0.0, 4.0, 4.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -14.0, 13.0, 8.0, 8.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, 11.0, 5.0, -8.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, 8.0, -1.0, 8.0, 0.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -4.0, 9.0, 7.0, 3.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, 12.0, 14.0, 9.0, -20.0, 4.0, 7.0, -4.0, 8.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 13.0, 7.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, -2.0, 11.0, 7.0, -1.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 9.0, 14.0, 1.0, -9.0, 5.0, 7.0, 7.0, -4.0, 11.0, 5.0, 10.0, -11.0, 13.0, 14.0, 4.0, -16.0, 6.0, 6.0, 12.0, -9.0, 12.0, 13.0, 12.0, 317.0, -9.0, 12.0, 4.0, 8.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 4.0, 7.0, -4.0, 8.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0, 5.0, 7.0, 7.0, -4.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 4.0, -16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.47820574070010763, "mean_inference_ms": 2.0058556359163116, "mean_action_processing_ms": 0.12140037268523565, "mean_env_wait_ms": 0.27993292040921786, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 52920, "agent_timesteps_total": 52839, "timers": {"learn_time_ms": 1.888, "learn_throughput": 16949.251, "update_time_ms": 4.82}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 20.28531265258789, "min_q": 13.644176483154297, "max_q": 21.755075454711914, "mean_td_error": -0.2082269787788391, "model": {}}}, "num_steps_sampled": 52920, "num_agent_steps_sampled": 52839, "num_steps_trained": 15392, "num_agent_steps_trained": 15392, "last_target_update_ts": 52920, "num_target_updates": 97}, "done": false, "episodes_total": 1026, "training_iteration": 17, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-54", "timestamp": 1626859734, "time_this_iter_s": 1.0826797485351562, "time_total_s": 18.70373249053955, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 18.70373249053955, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 49.9, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -6.0, 8.0, 12.0, 1.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 4.0, -9.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, -9.0, 4.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, 11.0, 8.0, -17.0, 13.0, 14.0, 2.0, -7.0, 6.0, -3.0, 4.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 7.0, 2.0, 13.0, 12.0, 4.0, -7.0, 6.0, 13.0, 6.0, -17.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, 4.0, -5.0, 12.0, 4.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 7.0, 2.0, 13.0, 14.0, 2.0, -7.0, 6.0, 14.0, 5.0, -17.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -11.0, 8.0, 7.0, 11.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -1.0, 2.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 13.0, 8.0, 0.0, -2.0, 10.0, 4.0, 3.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, 319.0, 13.0, 10.0, 12.0, 11.0, -2.0, 3.0, 3.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 13.0, 8.0, 0.0, -2.0, 5.0, 5.0, 7.0, 8.0, -1.0, 8.0, 0.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -1.0, 6.0, 8.0, 2.0, 0.0, 4.0, 4.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -14.0, 13.0, 8.0, 8.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, 11.0, 5.0, -8.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, 8.0, -1.0, 8.0, 0.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -4.0, 9.0, 7.0, 3.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0, -2.0, 5.0, 5.0, 7.0, -6.0, 6.0, 8.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4826219490773984, "mean_inference_ms": 2.015287449545413, "mean_action_processing_ms": 0.1220979053979145, "mean_env_wait_ms": 0.2824590035408867, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 56160, "agent_timesteps_total": 56079, "timers": {"learn_time_ms": 1.8, "learn_throughput": 17781.657, "update_time_ms": 4.126}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 19.292034149169922, "min_q": 12.674402236938477, "max_q": 22.245283126831055, "mean_td_error": 2.8140602111816406, "model": {}}}, "num_steps_sampled": 56160, "num_agent_steps_sampled": 56079, "num_steps_trained": 16352, "num_agent_steps_trained": 16352, "last_target_update_ts": 56160, "num_target_updates": 103}, "done": false, "episodes_total": 1080, "training_iteration": 18, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-55", "timestamp": 1626859735, "time_this_iter_s": 1.0760796070098877, "time_total_s": 19.77981209754944, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 19.77981209754944, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 51.75, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 14.0, 4.0, -15.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 9.0, 14.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 8.0, -10.0, 7.0, 10.0, 9.0, -17.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, -10.0, 6.0, 6.0, 13.0, 9.0, -17.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, -4.0, 13.0, 2.0, 4.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -7.0, 6.0, 11.0, -4.0, -4.0, 11.0, 12.0, 1.0, 14.0, 9.0, -9.0, 5.0, -11.0, 8.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, 9.0, -17.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 12.0, 14.0, 3.0, -14.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 12.0, 14.0, 3.0, -14.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, 9.0, -10.0, 4.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, 3.0, 3.0, 13.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 6.0, -14.0, 10.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 12.0, 13.0, 3.0, -13.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, -10.0, 6.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -3.0, 10.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, 10.0, -14.0, 11.0, 8.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 12.0, 13.0, 3.0, -13.0, 8.0, -11.0, 5.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -8.0, 5.0, 13.0, -4.0, -4.0, 11.0, 12.0, 14.0, 2.0, -7.0, 6.0, -7.0, 7.0, 2.0, 13.0, 14.0, 2.0, -7.0, 6.0, 14.0, 5.0, -17.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -11.0, 8.0, 7.0, 11.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -1.0, 2.0, 1.0, 13.0, 14.0, 2.0, -7.0, 6.0, -7.0, 8.0, 1.0, 13.0, 14.0, 2.0, -8.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.47968577022778974, "mean_inference_ms": 2.005873212402421, "mean_action_processing_ms": 0.12127818956727192, "mean_env_wait_ms": 0.2811815561472529, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 59400, "agent_timesteps_total": 59319, "timers": {"learn_time_ms": 1.94, "learn_throughput": 16497.988, "update_time_ms": 4.877}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 20.78582763671875, "min_q": 11.134196281433105, "max_q": 22.626693725585938, "mean_td_error": 1.3569061756134033, "model": {}}}, "num_steps_sampled": 59400, "num_agent_steps_sampled": 59319, "num_steps_trained": 17312, "num_agent_steps_trained": 17312, "last_target_update_ts": 59400, "num_target_updates": 109}, "done": false, "episodes_total": 1161, "training_iteration": 19, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-56", "timestamp": 1626859736, "time_this_iter_s": 1.1012048721313477, "time_total_s": 20.881016969680786, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 20.881016969680786, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 49.6, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 92.97, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -14.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 23.2425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, -1.0, 9.0, 12.0, -5.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, -3.0, 12.0, 7.0, -1.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 12.0, 12.0, 12.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 13.0, 7.0, -4.0, -1.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, -6.0, 12.0, 7.0, 2.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 3.0, 2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 8.0, 1.0, 10.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, -6.0, 12.0, 10.0, -1.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 8.0, 3.0, 8.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 12.0, 12.0, 12.0, 318.0, 8.0, 3.0, 8.0, -4.0, 13.0, 12.0, 11.0, 318.0, 10.0, 3.0, 10.0, -8.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, -4.0, -4.0, 11.0, 12.0, 12.0, 14.0, 3.0, -14.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, 9.0, -10.0, 4.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, 3.0, 3.0, 13.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 6.0, -14.0, 10.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 12.0, 13.0, 3.0, -13.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, -10.0, 6.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -3.0, 10.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, 10.0, -14.0, 11.0, 8.0, 10.0, 13.0, 3.0, -11.0, 5.0, -9.0, 6.0, 13.0, -4.0, -4.0, 11.0, 12.0, 12.0, 13.0, 3.0, -13.0, 8.0, -11.0, 5.0, 13.0, -4.0, -4.0, 11.0, 12.0, 10.0, 13.0, 3.0, -11.0, 5.0, -8.0, 5.0, 13.0, -4.0, -4.0, 11.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4774130323378104, "mean_inference_ms": 2.000637758690724, "mean_action_processing_ms": 0.12091153430815638, "mean_env_wait_ms": 0.27997439184979706, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 62640, "agent_timesteps_total": 62559, "timers": {"learn_time_ms": 1.88, "learn_throughput": 17022.769, "update_time_ms": 4.132}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 20.546672821044922, "min_q": 9.291295051574707, "max_q": 23.19634246826172, "mean_td_error": 2.1397948265075684, "model": {}}}, "num_steps_sampled": 62640, "num_agent_steps_sampled": 62559, "num_steps_trained": 18272, "num_agent_steps_trained": 18272, "last_target_update_ts": 62640, "num_target_updates": 115}, "done": false, "episodes_total": 1215, "training_iteration": 20, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-57", "timestamp": 1626859737, "time_this_iter_s": 1.1177949905395508, "time_total_s": 21.998811960220337, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 21.998811960220337, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 52.0, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 86.19, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 21.5475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 11.0, 12.0, -1.0, -7.0, 9.0, 1.0, 9.0, -4.0, 8.0, 14.0, -7.0, 0.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 12.0, 13.0, 4.0, -14.0, 9.0, 1.0, 9.0, -4.0, 14.0, 13.0, -14.0, 2.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 11.0, 14.0, -7.0, -3.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 13.0, 14.0, -14.0, 2.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 13.0, 14.0, 3.0, -15.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 8.0, 0.0, -1.0, 8.0, 10.0, 14.0, -8.0, -1.0, 9.0, 11.0, -1.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 4.0, 6.0, -4.0, 10.0, 14.0, -8.0, -1.0, 10.0, 7.0, 11.0, -13.0, 12.0, 14.0, -9.0, -2.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 12.0, 12.0, 12.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 13.0, 7.0, -4.0, -1.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, -6.0, 12.0, 7.0, 2.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 3.0, 2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 8.0, 1.0, 10.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, -6.0, 12.0, 10.0, -1.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 8.0, 3.0, 8.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 12.0, 12.0, 12.0, 318.0, 8.0, 3.0, 8.0, -4.0, 13.0, 12.0, 11.0, 318.0, 10.0, 3.0, 10.0, -8.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0, 13.0, 12.0, 11.0, 318.0, 14.0, 7.0, -2.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4830003517037116, "mean_inference_ms": 2.0125787199583822, "mean_action_processing_ms": 0.12177781338080437, "mean_env_wait_ms": 0.2825559078708476, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 65880, "agent_timesteps_total": 65799, "timers": {"learn_time_ms": 1.833, "learn_throughput": 17455.811, "update_time_ms": 4.348}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 20.811447143554688, "min_q": 7.858065128326416, "max_q": 23.486616134643555, "mean_td_error": -0.052101075649261475, "model": {}}}, "num_steps_sampled": 65880, "num_agent_steps_sampled": 65799, "num_steps_trained": 19232, "num_agent_steps_trained": 19232, "last_target_update_ts": 65880, "num_target_updates": 121}, "done": false, "episodes_total": 1269, "training_iteration": 21, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-28-59", "timestamp": 1626859739, "time_this_iter_s": 1.1346795558929443, "time_total_s": 23.13349151611328, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 23.13349151611328, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 51.1, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 157.17, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -24.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 39.2925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 15.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 15.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 15.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 10.0, 13.0, -22.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 9.0, 13.0, -18.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 7.0, -16.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, -6.0, 13.0, -6.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 11.0, 8.0, -18.0, 12.0, 13.0, 316.0, 12.0, 12.0, -1.0, -5.0, 9.0, 14.0, 12.0, 13.0, -24.0, 10.0, 13.0, -15.0, 7.0, 13.0, 4.0, -13.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 10.0, 13.0, -22.0, 12.0, 7.0, -16.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 11.0, 7.0, 0.0, -3.0, 12.0, 4.0, -12.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 9.0, 13.0, -18.0, 11.0, 14.0, 12.0, 13.0, -24.0, 10.0, 14.0, -20.0, 11.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 13.0, 8.0, -12.0, 6.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 12.0, 4.0, -11.0, 10.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 12.0, 14.0, 11.0, 317.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0, 8.0, 0.0, -1.0, 8.0, 10.0, 14.0, -8.0, -1.0, 9.0, 11.0, -1.0, -4.0, 10.0, 14.0, -8.0, -1.0, 9.0, 4.0, 6.0, -4.0, 10.0, 14.0, -8.0, -1.0, 10.0, 7.0, 11.0, -13.0, 12.0, 14.0, -9.0, -2.0, 9.0, 1.0, 9.0, -4.0, 10.0, 14.0, -8.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4810528784885615, "mean_inference_ms": 2.008456240389401, "mean_action_processing_ms": 0.12120077503446051, "mean_env_wait_ms": 0.28167435421460413, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 69120, "agent_timesteps_total": 69039, "timers": {"learn_time_ms": 1.896, "learn_throughput": 16879.973, "update_time_ms": 4.678}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 19.584596633911133, "min_q": 6.235047817230225, "max_q": 23.890779495239258, "mean_td_error": 1.219054102897644, "model": {}}}, "num_steps_sampled": 69120, "num_agent_steps_sampled": 69039, "num_steps_trained": 20192, "num_agent_steps_trained": 20192, "last_target_update_ts": 69120, "num_target_updates": 127}, "done": false, "episodes_total": 1350, "training_iteration": 22, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-00", "timestamp": 1626859740, "time_this_iter_s": 1.3254644870758057, "time_total_s": 24.458956003189087, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 24.458956003189087, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 47.0, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 160.46, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -24.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 40.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 15.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 15.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 9.0, -19.0, 13.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 0.0, 11.0, -8.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 10.0, -13.0, 10.0, 8.0, 12.0, 8.0, -18.0, 13.0, 12.0, 0.0, 12.0, -9.0, 12.0, -12.0, 7.0, 8.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 6.0, 11.0, -14.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 1.0, 10.0, -8.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 11.0, 10.0, -19.0, 13.0, 8.0, 2.0, 12.0, -7.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 13.0, 3.0, -14.0, 13.0, 13.0, 9.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 13.0, 4.0, -13.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 10.0, 13.0, -22.0, 12.0, 7.0, -16.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 11.0, 7.0, 0.0, -3.0, 12.0, 4.0, -12.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 9.0, 13.0, -18.0, 11.0, 14.0, 12.0, 13.0, -24.0, 10.0, 14.0, -20.0, 11.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 13.0, 8.0, -12.0, 6.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 13.0, 13.0, 317.0, 11.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 12.0, 4.0, -11.0, 10.0, 14.0, 12.0, 13.0, -24.0, 12.0, 13.0, 316.0, 12.0, 12.0, 14.0, 11.0, 317.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.47874550395891563, "mean_inference_ms": 2.0027387552145353, "mean_action_processing_ms": 0.1206923917728909, "mean_env_wait_ms": 0.2802638571381638, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 72360, "agent_timesteps_total": 72279, "timers": {"learn_time_ms": 1.802, "learn_throughput": 17758.836, "update_time_ms": 4.335}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 17.852169036865234, "min_q": 4.215791702270508, "max_q": 25.014829635620117, "mean_td_error": 1.0463889837265015, "model": {}}}, "num_steps_sampled": 72360, "num_agent_steps_sampled": 72279, "num_steps_trained": 21152, "num_agent_steps_trained": 21152, "last_target_update_ts": 72360, "num_target_updates": 133}, "done": false, "episodes_total": 1404, "training_iteration": 23, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-01", "timestamp": 1626859741, "time_this_iter_s": 1.0983352661132812, "time_total_s": 25.557291269302368, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 25.557291269302368, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 51.7, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 69.08, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 17.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, 3.0, -4.0, 8.0, 8.0, 5.0, 9.0, 10.0, -9.0, -1.0, 11.0, 13.0, -8.0, 8.0, 2.0, 10.0, -5.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, 6.0, -4.0, 7.0, 6.0, 5.0, 9.0, 10.0, -9.0, -2.0, 12.0, 13.0, -8.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 8.0, 9.0, 4.0, -6.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 8.0, 10.0, -8.0, -1.0, 12.0, 13.0, -9.0, 6.0, 8.0, 10.0, -9.0, 3.0, 10.0, 8.0, -6.0, 5.0, 9.0, 10.0, -9.0, -1.0, 13.0, 13.0, -10.0, 8.0, 7.0, 10.0, -10.0, -1.0, 12.0, 13.0, -9.0, 6.0, 9.0, 9.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -2.0, 12.0, 13.0, -8.0, 11.0, 3.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 6.0, 9.0, 9.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, 0.0, 12.0, 13.0, -10.0, 8.0, 14.0, 9.0, -16.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, 0.0, 12.0, 12.0, -9.0, 7.0, 9.0, 10.0, -11.0, 1.0, 13.0, 8.0, -7.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 9.0, -19.0, 13.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 0.0, 11.0, -8.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 10.0, -13.0, 10.0, 8.0, 12.0, 8.0, -18.0, 13.0, 12.0, 0.0, 12.0, -9.0, 12.0, -12.0, 7.0, 8.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 6.0, 11.0, -14.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 1.0, 10.0, -8.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 11.0, 10.0, -19.0, 13.0, 8.0, 2.0, 12.0, -7.0, 12.0, 10.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0, 13.0, 3.0, -14.0, 13.0, 13.0, 9.0, -19.0, 12.0, 12.0, 317.0, 11.0, 13.0, 12.0, 10.0, -19.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4836081054980357, "mean_inference_ms": 2.0141000196204186, "mean_action_processing_ms": 0.1214994440354468, "mean_env_wait_ms": 0.2824033200747044, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 75600, "agent_timesteps_total": 75519, "timers": {"learn_time_ms": 1.791, "learn_throughput": 17864.018, "update_time_ms": 4.026}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 19.891414642333984, "min_q": 1.4508665800094604, "max_q": 24.649742126464844, "mean_td_error": -10.721046447753906, "model": {}}}, "num_steps_sampled": 75600, "num_agent_steps_sampled": 75519, "num_steps_trained": 22112, "num_agent_steps_trained": 22112, "last_target_update_ts": 75600, "num_target_updates": 139}, "done": false, "episodes_total": 1458, "training_iteration": 24, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-02", "timestamp": 1626859742, "time_this_iter_s": 1.0828864574432373, "time_total_s": 26.640177726745605, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99bb6fb730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 26.640177726745605, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 51.45, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 6.0, 0.0, 10.0, 4.0, -9.0, 9.0, 11.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 13.0, -7.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, 0.0, 13.0, -8.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 11.0, -5.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 8.0, -5.0, 13.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 10.0, -13.0, 5.0, 13.0, 319.0, 14.0, 8.0, 13.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -14.0, 4.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -16.0, 6.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -16.0, 6.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 9.0, 4.0, 3.0, 12.0, -14.0, 4.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, 13.0, 6.0, -2.0, -2.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 7.0, -3.0, 12.0, 12.0, -15.0, 5.0, 13.0, -15.0, 13.0, 6.0, 11.0, -1.0, 11.0, -4.0, 9.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 7.0, -10.0, 9.0, 9.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -2.0, 12.0, 13.0, -8.0, 11.0, 3.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 6.0, 9.0, 9.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, 0.0, 12.0, 13.0, -10.0, 8.0, 14.0, 9.0, -16.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, 0.0, 12.0, 12.0, -9.0, 7.0, 9.0, 10.0, -11.0, 1.0, 13.0, 8.0, -7.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0, 5.0, 9.0, 10.0, -9.0, -1.0, 12.0, 13.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4798273844753646, "mean_inference_ms": 2.002822972683975, "mean_action_processing_ms": 0.12059165306374356, "mean_env_wait_ms": 0.28072584727470784, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 78840, "agent_timesteps_total": 78759, "timers": {"learn_time_ms": 1.846, "learn_throughput": 17334.073, "update_time_ms": 4.036}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 21.42986297607422, "min_q": 1.08963143825531, "max_q": 25.268796920776367, "mean_td_error": 1.6673781871795654, "model": {}}}, "num_steps_sampled": 78840, "num_agent_steps_sampled": 78759, "num_steps_trained": 23072, "num_agent_steps_trained": 23072, "last_target_update_ts": 78840, "num_target_updates": 145}, "done": false, "episodes_total": 1539, "training_iteration": 25, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-03", "timestamp": 1626859743, "time_this_iter_s": 1.077996015548706, "time_total_s": 27.71817374229431, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 27.71817374229431, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 51.8, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -5.0, -2.0, 9.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 8.0, -6.0, 12.0, 1.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, 0.0, -2.0, 8.0, 9.0, 13.0, -6.0, 12.0, -4.0, -2.0, -2.0, 8.0, 11.0, 13.0, -6.0, 12.0, -4.0, -3.0, -3.0, 9.0, 12.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, 8.0, 12.0, -18.0, -4.0, -2.0, 8.0, 13.0, 14.0, -6.0, 11.0, -4.0, -17.0, 11.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -3.0, -3.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -4.0, 10.0, -4.0, -2.0, -3.0, 8.0, 12.0, 14.0, -6.0, 11.0, -4.0, 1.0, -3.0, 4.0, 13.0, 12.0, 11.0, 13.0, 316.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -17.0, 11.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -16.0, 6.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -16.0, 6.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 9.0, 4.0, 3.0, 12.0, -14.0, 4.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, 13.0, 6.0, -2.0, -2.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 7.0, -3.0, 12.0, 12.0, -15.0, 5.0, 13.0, -15.0, 13.0, 6.0, 11.0, -1.0, 11.0, -4.0, 9.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 7.0, -10.0, 9.0, 9.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0, -1.0, 6.0, 0.0, 10.0, 12.0, -15.0, 5.0, 13.0, -14.0, 9.0, 10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4778389228829614, "mean_inference_ms": 1.9970154935142963, "mean_action_processing_ms": 0.12012038320904857, "mean_env_wait_ms": 0.2793250819684674, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 82080, "agent_timesteps_total": 81999, "timers": {"learn_time_ms": 1.928, "learn_throughput": 16597.753, "update_time_ms": 4.745}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 21.712318420410156, "min_q": 1.2807388305664062, "max_q": 25.68033790588379, "mean_td_error": 3.41397762298584, "model": {}}}, "num_steps_sampled": 82080, "num_agent_steps_sampled": 81999, "num_steps_trained": 24032, "num_agent_steps_trained": 24032, "last_target_update_ts": 82080, "num_target_updates": 151}, "done": false, "episodes_total": 1593, "training_iteration": 26, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-05", "timestamp": 1626859745, "time_this_iter_s": 1.1025428771972656, "time_total_s": 28.820716619491577, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985410d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 28.820716619491577, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 180.35, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 45.0875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 352.0, 353.0, 15.0, 353.0, 352.0, 353.0, 352.0, 15.0, 352.0, 352.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 15.0, 352.0, 353.0, 15.0, 353.0, 352.0, 15.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 13.0, -2.0, -8.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, -19.0, 13.0, 12.0, 9.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 12.0, -2.0, 12.0, -7.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 11.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 12.0, 11.0, -19.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, -19.0, 13.0, 11.0, 10.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 0.0, 12.0, -8.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 8.0, -6.0, 12.0, 1.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, 0.0, -2.0, 8.0, 9.0, 13.0, -6.0, 12.0, -4.0, -2.0, -2.0, 8.0, 11.0, 13.0, -6.0, 12.0, -4.0, -3.0, -3.0, 9.0, 12.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, 8.0, 12.0, -18.0, -4.0, -2.0, 8.0, 13.0, 14.0, -6.0, 11.0, -4.0, -17.0, 11.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -3.0, -3.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -4.0, 10.0, -4.0, -2.0, -3.0, 8.0, 12.0, 14.0, -6.0, 11.0, -4.0, 1.0, -3.0, 4.0, 13.0, 12.0, 11.0, 13.0, 316.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -17.0, 11.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0, -4.0, -2.0, 8.0, 13.0, 13.0, -6.0, 12.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4835038605053858, "mean_inference_ms": 2.010400988253045, "mean_action_processing_ms": 0.12106440941931884, "mean_env_wait_ms": 0.28200316584633833, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 85320, "agent_timesteps_total": 85239, "timers": {"learn_time_ms": 1.872, "learn_throughput": 17098.453, "update_time_ms": 4.332}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 18.181631088256836, "min_q": 1.2827225923538208, "max_q": 25.780963897705078, "mean_td_error": -9.117908477783203, "model": {}}}, "num_steps_sampled": 85320, "num_agent_steps_sampled": 85239, "num_steps_trained": 24992, "num_agent_steps_trained": 24992, "last_target_update_ts": 85320, "num_target_updates": 157}, "done": false, "episodes_total": 1647, "training_iteration": 27, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-06", "timestamp": 1626859746, "time_this_iter_s": 1.1453397274017334, "time_total_s": 29.96605634689331, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 29.96605634689331, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 51.45, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 156.63, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 39.1575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0, 353.0, 352.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, -2.0, 13.0, 13.0, -9.0, -1.0, 13.0, -9.0, 12.0, 8.0, -3.0, 8.0, 2.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -3.0, 9.0, 6.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 8.0, -6.0, 4.0, 9.0, 315.0, 13.0, 13.0, 11.0, -4.0, 13.0, -7.0, 13.0, 3.0, -6.0, 9.0, 9.0, -19.0, 13.0, 11.0, 10.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 8.0, 4.0, 9.0, -6.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 8.0, -9.0, 9.0, 7.0, -17.0, 13.0, 13.0, 6.0, -3.0, 13.0, -6.0, 11.0, 13.0, -9.0, 9.0, 2.0, 314.0, 14.0, 12.0, 12.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -2.0, 10.0, 4.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 8.0, -3.0, 6.0, 4.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -9.0, 9.0, 12.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 13.0, -7.0, 9.0, 0.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, -19.0, 10.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 13.0, -7.0, 8.0, 1.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0, 11.0, 14.0, 12.0, 316.0, 315.0, 12.0, 12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4803806067845403, "mean_inference_ms": 2.0018656078536403, "mean_action_processing_ms": 0.1203248051821027, "mean_env_wait_ms": 0.2806533756458444, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 88560, "agent_timesteps_total": 88479, "timers": {"learn_time_ms": 1.846, "learn_throughput": 17332.059, "update_time_ms": 4.339}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 19.447782516479492, "min_q": 1.1490498781204224, "max_q": 26.325210571289062, "mean_td_error": -0.5698308944702148, "model": {}}}, "num_steps_sampled": 88560, "num_agent_steps_sampled": 88479, "num_steps_trained": 25952, "num_agent_steps_trained": 25952, "last_target_update_ts": 88560, "num_target_updates": 163}, "done": false, "episodes_total": 1728, "training_iteration": 28, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-07", "timestamp": 1626859747, "time_this_iter_s": 1.0679004192352295, "time_total_s": 31.03395676612854, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 31.03395676612854, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 52.25, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 85.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 21.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 13.0, 9.0, -5.0, -2.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 6.0, 9.0, -10.0, 10.0, 13.0, 13.0, -4.0, -7.0, 5.0, 9.0, -9.0, 10.0, 4.0, 8.0, -8.0, 11.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 13.0, 9.0, -5.0, -2.0, 7.0, 9.0, -12.0, 11.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, -1.0, 13.0, -9.0, 12.0, 8.0, -3.0, 8.0, 2.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -3.0, 9.0, 6.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 8.0, -6.0, 4.0, 9.0, 315.0, 13.0, 13.0, 11.0, -4.0, 13.0, -7.0, 13.0, 3.0, -6.0, 9.0, 9.0, -19.0, 13.0, 11.0, 10.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 8.0, 4.0, 9.0, -6.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 8.0, -9.0, 9.0, 7.0, -17.0, 13.0, 13.0, 6.0, -3.0, 13.0, -6.0, 11.0, 13.0, -9.0, 9.0, 2.0, 314.0, 14.0, 12.0, 12.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -2.0, 10.0, 4.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 8.0, -3.0, 6.0, 4.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -9.0, 9.0, 12.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 13.0, -7.0, 9.0, 0.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 3.0, -6.0, 9.0, 9.0, -19.0, 10.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 13.0, -7.0, 8.0, 1.0, 315.0, 13.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.483121638903239, "mean_inference_ms": 2.0089634316026057, "mean_action_processing_ms": 0.1209540605847277, "mean_env_wait_ms": 0.28179188131044164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 90720, "agent_timesteps_total": 90639, "timers": {"learn_time_ms": 1.977, "learn_throughput": 16183.68, "update_time_ms": 6.015}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 19.640838623046875, "min_q": 1.1914693117141724, "max_q": 26.352035522460938, "mean_td_error": 3.266397476196289, "model": {}}}, "num_steps_sampled": 90720, "num_agent_steps_sampled": 90639, "num_steps_trained": 26592, "num_agent_steps_trained": 26592, "last_target_update_ts": 90720, "num_target_updates": 167}, "done": false, "episodes_total": 1755, "training_iteration": 29, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-08", "timestamp": 1626859748, "time_this_iter_s": 0.9661695957183838, "time_total_s": 32.000126361846924, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 32.000126361846924, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 40.7, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -4.0, 0.0, 8.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -11.0, 5.0, 12.0, 9.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, -5.0, 13.0, 11.0, -4.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, -17.0, 13.0, 12.0, 7.0, 11.0, -10.0, 1.0, 13.0, -2.0, 5.0, 0.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -9.0, 5.0, 7.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -9.0, 0.0, 13.0, -9.0, 11.0, 3.0, 10.0, 0.0, 13.0, 11.0, -9.0, 10.0, -9.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 12.0, -10.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 11.0, 3.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -11.0, 2.0, 13.0, -10.0, 5.0, 8.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -10.0, 5.0, 8.0, 12.0, -15.0, 12.0, 8.0, 10.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -10.0, 5.0, 8.0, 12.0, 0.0, 12.0, 2.0, 1.0, 11.0, -10.0, 1.0, 13.0, -9.0, 5.0, 7.0, 12.0, -8.0, 13.0, 11.0, -1.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -11.0, 2.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 10.0, -9.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -11.0, 5.0, 11.0, 10.0, 0.0, 13.0, 11.0, -9.0, 11.0, -11.0, 12.0, 3.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 6.0, 9.0, -10.0, 10.0, 13.0, 13.0, -4.0, -7.0, 5.0, 9.0, -9.0, 10.0, 4.0, 8.0, -8.0, 11.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 13.0, 9.0, -5.0, -2.0, 7.0, 9.0, -12.0, 11.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0, 5.0, 9.0, -9.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4853080260018548, "mean_inference_ms": 2.0128320634179118, "mean_action_processing_ms": 0.12121645284873693, "mean_env_wait_ms": 0.2829966063347323, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 93960, "agent_timesteps_total": 93879, "timers": {"learn_time_ms": 1.849, "learn_throughput": 17309.929, "update_time_ms": 4.335}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 18.554841995239258, "min_q": 1.1674493551254272, "max_q": 25.381406784057617, "mean_td_error": -8.876179695129395, "model": {}}}, "num_steps_sampled": 93960, "num_agent_steps_sampled": 93879, "num_steps_trained": 27552, "num_agent_steps_trained": 27552, "last_target_update_ts": 93960, "num_target_updates": 173}, "done": false, "episodes_total": 1836, "training_iteration": 30, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-09", "timestamp": 1626859749, "time_this_iter_s": 1.182060718536377, "time_total_s": 33.1821870803833, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 33.1821870803833, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 49.95, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 13.0, 11.0, 14.0, 10.0, 6.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, 0.0, 13.0, 9.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, 2.0, -2.0, 13.0, 2.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, 0.0, 9.0, -2.0, 8.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, -2.0, 5.0, -2.0, -7.0, -1.0, 13.0, 10.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, 1.0, -5.0, 12.0, 7.0, 14.0, 10.0, 6.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -1.0, 12.0, 11.0, 14.0, 11.0, 10.0, -20.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 10.0, 6.0, -15.0, -7.0, -2.0, 12.0, 12.0, 0.0, 7.0, 9.0, -1.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 10.0, 6.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -1.0, -4.0, 8.0, 12.0, 14.0, 11.0, 5.0, -15.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 11.0, 3.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -11.0, 2.0, 13.0, -10.0, 5.0, 8.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -10.0, 5.0, 8.0, 12.0, -15.0, 12.0, 8.0, 10.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -10.0, 5.0, 8.0, 12.0, 0.0, 12.0, 2.0, 1.0, 11.0, -10.0, 1.0, 13.0, -9.0, 5.0, 7.0, 12.0, -8.0, 13.0, 11.0, -1.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -11.0, 2.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 10.0, -9.0, 1.0, 13.0, -13.0, 5.0, 11.0, 12.0, 0.0, 13.0, 11.0, -9.0, 11.0, -10.0, 1.0, 13.0, -11.0, 5.0, 11.0, 10.0, 0.0, 13.0, 11.0, -9.0, 11.0, -11.0, 12.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4797736019543577, "mean_inference_ms": 1.9987418195314886, "mean_action_processing_ms": 0.12011254499800682, "mean_env_wait_ms": 0.28017352084774105, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 97200, "agent_timesteps_total": 97119, "timers": {"learn_time_ms": 2.032, "learn_throughput": 15745.862, "update_time_ms": 5.544}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 18.468358993530273, "min_q": 1.109316349029541, "max_q": 24.952062606811523, "mean_td_error": -1.5329170227050781, "model": {}}}, "num_steps_sampled": 97200, "num_agent_steps_sampled": 97119, "num_steps_trained": 28512, "num_agent_steps_trained": 28512, "last_target_update_ts": 97200, "num_target_updates": 179}, "done": false, "episodes_total": 1890, "training_iteration": 31, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-10", "timestamp": 1626859750, "time_this_iter_s": 1.1061484813690186, "time_total_s": 34.28833556175232, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 34.28833556175232, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 50.4, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 11.0, 12.0, 7.0, -15.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, -2.0, 10.0, -3.0, 10.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 6.0, 13.0, 6.0, -10.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -1.0, -1.0, 6.0, 9.0, 13.0, 6.0, -13.0, 11.0, -1.0, -3.0, 8.0, 9.0, 13.0, 6.0, -13.0, 6.0, -6.0, 6.0, 9.0, 6.0, 13.0, 6.0, -10.0, 11.0, -6.0, 1.0, 9.0, 6.0, 13.0, 6.0, -10.0, -2.0, 7.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -7.0, 2.0, 9.0, 12.0, 12.0, 7.0, -16.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -1.0, -3.0, 8.0, 9.0, 13.0, 6.0, -13.0, -7.0, 0.0, 13.0, 9.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, 2.0, -2.0, 13.0, 2.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, 0.0, 9.0, -2.0, 8.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, -2.0, 5.0, -2.0, -7.0, -1.0, 13.0, 10.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, 1.0, -5.0, 12.0, 7.0, 14.0, 10.0, 6.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -1.0, 12.0, 11.0, 14.0, 11.0, 10.0, -20.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 10.0, 6.0, -15.0, -7.0, -2.0, 12.0, 12.0, 0.0, 7.0, 9.0, -1.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 10.0, 6.0, -15.0, -7.0, -2.0, 12.0, 12.0, 14.0, 11.0, 5.0, -15.0, -1.0, -4.0, 8.0, 12.0, 14.0, 11.0, 5.0, -15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48461315035001745, "mean_inference_ms": 2.01087541948809, "mean_action_processing_ms": 0.12100568960684363, "mean_env_wait_ms": 0.2825592874162958, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 100440, "agent_timesteps_total": 100359, "timers": {"learn_time_ms": 1.829, "learn_throughput": 17494.718, "update_time_ms": 4.175}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 16.329620361328125, "min_q": 1.3591114282608032, "max_q": 24.37674903869629, "mean_td_error": 2.2352657318115234, "model": {}}}, "num_steps_sampled": 100440, "num_agent_steps_sampled": 100359, "num_steps_trained": 29472, "num_agent_steps_trained": 29472, "last_target_update_ts": 100440, "num_target_updates": 185}, "done": false, "episodes_total": 1944, "training_iteration": 32, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-11", "timestamp": 1626859751, "time_this_iter_s": 1.0837452411651611, "time_total_s": 35.37208080291748, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985ad378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 35.37208080291748, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 51.45, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.27, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.8175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 6.0, 5.0, -8.0, 13.0, 14.0, -10.0, -2.0, 11.0, -11.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, -5.0, 0.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -3.0, 13.0, -7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -11.0, 7.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -15.0, 11.0, 7.0, 13.0, -10.0, 6.0, 7.0, 13.0, 1.0, -9.0, 10.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 9.0, 4.0, -10.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 5.0, 3.0, -5.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -3.0, 9.0, -3.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 10.0, 4.0, -11.0, 12.0, 7.0, -15.0, 11.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 3.0, -6.0, 12.0, -5.0, 4.0, 4.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 2.0, -5.0, 8.0, 8.0, -13.0, 12.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -3.0, 13.0, -7.0, 13.0, 7.0, 4.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 0.0, -3.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 4.0, 8.0, -9.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 10.0, -10.0, 8.0, 7.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -7.0, 2.0, 9.0, 12.0, 12.0, 7.0, -16.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -6.0, 1.0, 9.0, 9.0, 13.0, 6.0, -13.0, 11.0, -1.0, -3.0, 8.0, 9.0, 13.0, 6.0, -13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48200755223102587, "mean_inference_ms": 2.002850672639418, "mean_action_processing_ms": 0.12031950495662606, "mean_env_wait_ms": 0.2814527255868285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 103680, "agent_timesteps_total": 103599, "timers": {"learn_time_ms": 1.862, "learn_throughput": 17186.689, "update_time_ms": 4.037}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 19.927696228027344, "min_q": 1.4629102945327759, "max_q": 25.07499885559082, "mean_td_error": -9.216484069824219, "model": {}}}, "num_steps_sampled": 103680, "num_agent_steps_sampled": 103599, "num_steps_trained": 30432, "num_agent_steps_trained": 30432, "last_target_update_ts": 103680, "num_target_updates": 191}, "done": false, "episodes_total": 2025, "training_iteration": 33, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-13", "timestamp": 1626859753, "time_this_iter_s": 1.1072313785552979, "time_total_s": 36.47931218147278, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 36.47931218147278, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 52.05, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.16, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 7.0, 3.0, -4.0, 2.0, 6.0, 11.0, -1.0, -1.0, 8.0, 9.0, -8.0, 5.0, 7.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -5.0, 3.0, 10.0, 8.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 1.0, 6.0, 12.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 7.0, -1.0, 4.0, 5.0, -4.0, 2.0, 6.0, 11.0, 9.0, -4.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 8.0, -1.0, 1.0, 7.0, -9.0, 4.0, 7.0, 13.0, 6.0, -1.0, 8.0, 2.0, -4.0, 6.0, 2.0, 11.0, 14.0, -1.0, 5.0, -3.0, -4.0, 2.0, 6.0, 11.0, 9.0, -1.0, 8.0, -1.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -15.0, 12.0, 7.0, 11.0, 10.0, -4.0, 1.0, 8.0, -4.0, 2.0, 6.0, 11.0, 11.0, -1.0, 2.0, 3.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -10.0, 4.0, 10.0, 11.0, 9.0, -4.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 12.0, -12.0, 8.0, 7.0, 13.0, 5.0, 3.0, -5.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -3.0, 9.0, -3.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 10.0, 4.0, -11.0, 12.0, 7.0, -15.0, 11.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 3.0, -6.0, 12.0, -5.0, 4.0, 4.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 2.0, -5.0, 8.0, 8.0, -13.0, 12.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -3.0, 13.0, -7.0, 13.0, 7.0, 4.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 0.0, -3.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 4.0, 8.0, -9.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 12.0, -12.0, 8.0, 7.0, 13.0, 6.0, 5.0, -8.0, 13.0, 8.0, -13.0, 7.0, 10.0, -10.0, 8.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4797294655944962, "mean_inference_ms": 1.998692820843125, "mean_action_processing_ms": 0.11994594025870234, "mean_env_wait_ms": 0.280262420572461, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 106920, "agent_timesteps_total": 106839, "timers": {"learn_time_ms": 1.849, "learn_throughput": 17308.366, "update_time_ms": 4.211}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 16.708648681640625, "min_q": 1.2695605754852295, "max_q": 25.261402130126953, "mean_td_error": -20.558757781982422, "model": {}}}, "num_steps_sampled": 106920, "num_agent_steps_sampled": 106839, "num_steps_trained": 31392, "num_agent_steps_trained": 31392, "last_target_update_ts": 106920, "num_target_updates": 197}, "done": false, "episodes_total": 2079, "training_iteration": 34, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-14", "timestamp": 1626859754, "time_this_iter_s": 1.1393938064575195, "time_total_s": 37.6187059879303, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 37.6187059879303, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 8.0, -2.0, 14.0, 11.0, -17.0, 7.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 9.0, 13.0, -20.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -4.0, 8.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -6.0, 9.0, -2.0, 7.0, 11.0, -16.0, 13.0, 0.0, 6.0, 12.0, -3.0, 9.0, -1.0, 12.0, -5.0, 4.0, 9.0, -10.0, 12.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 6.0, 13.0, -4.0, 14.0, -5.0, 9.0, -3.0, 12.0, 11.0, 317.0, 12.0, 0.0, 5.0, 13.0, -3.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 11.0, 2.0, 2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 14.0, -8.0, 12.0, -3.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 4.0, 9.0, -10.0, 12.0, 0.0, -4.0, 12.0, 7.0, 14.0, -6.0, 10.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 1.0, 13.0, 1.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 11.0, -2.0, 11.0, -5.0, 7.0, 11.0, -2.0, -1.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, 6.0, 5.0, -10.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 9.0, 13.0, -16.0, 9.0, 0.0, -1.0, 13.0, 3.0, 14.0, -7.0, 10.0, -2.0, 7.0, 11.0, -16.0, 13.0, -4.0, 6.0, 2.0, 11.0, 14.0, -1.0, 5.0, -3.0, -4.0, 2.0, 6.0, 11.0, 9.0, -1.0, 8.0, -1.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -15.0, 12.0, 7.0, 11.0, 10.0, -4.0, 1.0, 8.0, -4.0, 2.0, 6.0, 11.0, 11.0, -1.0, 2.0, 3.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0, 6.0, -1.0, 8.0, 2.0, -10.0, 4.0, 10.0, 11.0, 9.0, -4.0, 8.0, 2.0, -4.0, 2.0, 6.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4830650481352455, "mean_inference_ms": 2.005753350365966, "mean_action_processing_ms": 0.1204907133350535, "mean_env_wait_ms": 0.2819020336382911, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 110160, "agent_timesteps_total": 110160, "timers": {"learn_time_ms": 1.935, "learn_throughput": 16536.405, "update_time_ms": 4.137}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 14.678546905517578, "min_q": 1.1289962530136108, "max_q": 24.337251663208008, "mean_td_error": -9.51966381072998, "model": {}}}, "num_steps_sampled": 110160, "num_agent_steps_sampled": 110160, "num_steps_trained": 32352, "num_agent_steps_trained": 32352, "last_target_update_ts": 110160, "num_target_updates": 203}, "done": false, "episodes_total": 2160, "training_iteration": 35, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-15", "timestamp": 1626859755, "time_this_iter_s": 1.1763825416564941, "time_total_s": 38.79508852958679, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 38.79508852958679, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 50.7, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -10.0, -1.0, 8.0, 9.0, 0.0, -2.0, 13.0, 13.0, -7.0, -4.0, 8.0, 9.0, -1.0, -1.0, 14.0, 11.0, -8.0, -2.0, 8.0, 9.0, -1.0, -1.0, 13.0, 12.0, -8.0, -2.0, 7.0, 7.0, 4.0, -3.0, 13.0, 12.0, -13.0, 3.0, 10.0, 2.0, 6.0, -3.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -5.0, -6.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -10.0, -1.0, 8.0, 8.0, 0.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 6.0, 10.0, 1.0, -2.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -10.0, -1.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 8.0, 0.0, -1.0, 13.0, 13.0, -7.0, -4.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 6.0, 9.0, 1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 14.0, 11.0, -9.0, -1.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -9.0, -2.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -9.0, -2.0, 12.0, 11.0, 317.0, 12.0, 0.0, 5.0, 13.0, -3.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 11.0, 2.0, 2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 14.0, -8.0, 12.0, -3.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 4.0, 9.0, -10.0, 12.0, 0.0, -4.0, 12.0, 7.0, 14.0, -6.0, 10.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 1.0, 13.0, 1.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 11.0, -2.0, 11.0, -5.0, 7.0, 11.0, -2.0, -1.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, 6.0, 5.0, -10.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 7.0, 11.0, -16.0, 13.0, 0.0, 4.0, 13.0, -2.0, 14.0, -5.0, 9.0, -3.0, 9.0, 13.0, -16.0, 9.0, 0.0, -1.0, 13.0, 3.0, 14.0, -7.0, 10.0, -2.0, 7.0, 11.0, -16.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48076772259485295, "mean_inference_ms": 2.0001881711248757, "mean_action_processing_ms": 0.12005630277219889, "mean_env_wait_ms": 0.28065962034304126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 113400, "agent_timesteps_total": 113319, "timers": {"learn_time_ms": 1.765, "learn_throughput": 18127.977, "update_time_ms": 4.004}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 17.416309356689453, "min_q": 1.1010719537734985, "max_q": 23.241247177124023, "mean_td_error": 1.9800400733947754, "model": {}}}, "num_steps_sampled": 113400, "num_agent_steps_sampled": 113319, "num_steps_trained": 33312, "num_agent_steps_trained": 33312, "last_target_update_ts": 113400, "num_target_updates": 209}, "done": false, "episodes_total": 2214, "training_iteration": 36, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-16", "timestamp": 1626859756, "time_this_iter_s": 1.2909696102142334, "time_total_s": 40.086058139801025, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 40.086058139801025, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 46.15, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 2.0, 13.0, -12.0, -7.0, -3.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -13.0, 3.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 13.0, 13.0, -7.0, -4.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -11.0, 1.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -16.0, 6.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 4.0, 13.0, -14.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 9.0, 14.0, -1.0, -7.0, -6.0, -5.0, 13.0, 13.0, 11.0, 2.0, 13.0, -11.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 3.0, 13.0, -13.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -7.0, -3.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 9.0, 13.0, 13.0, -20.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 7.0, 7.0, 4.0, -3.0, 13.0, 12.0, -13.0, 3.0, 10.0, 2.0, 6.0, -3.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -5.0, -6.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -10.0, -1.0, 8.0, 8.0, 0.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 6.0, 10.0, 1.0, -2.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -10.0, -1.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 8.0, 0.0, -1.0, 13.0, 13.0, -7.0, -4.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 6.0, 9.0, 1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -8.0, -3.0, 8.0, 9.0, -1.0, -1.0, 14.0, 11.0, -9.0, -1.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -9.0, -2.0, 8.0, 9.0, -1.0, -1.0, 13.0, 13.0, -9.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48593115361326766, "mean_inference_ms": 2.0122844160623443, "mean_action_processing_ms": 0.12103011778829971, "mean_env_wait_ms": 0.2832393150930133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 116640, "agent_timesteps_total": 116559, "timers": {"learn_time_ms": 2.025, "learn_throughput": 15800.173, "update_time_ms": 5.177}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 12.840730667114258, "min_q": 0.9568508863449097, "max_q": 21.143489837646484, "mean_td_error": -8.467023849487305, "model": {}}}, "num_steps_sampled": 116640, "num_agent_steps_sampled": 116559, "num_steps_trained": 34272, "num_agent_steps_trained": 34272, "last_target_update_ts": 116640, "num_target_updates": 215}, "done": false, "episodes_total": 2268, "training_iteration": 37, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-17", "timestamp": 1626859757, "time_this_iter_s": 1.130760669708252, "time_total_s": 41.21681880950928, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985051e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 41.21681880950928, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 51.85, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, 10.0, 14.0, 11.0, -20.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, -8.0, -4.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 14.0, 13.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, -8.0, -4.0, 1.0, 7.0, 9.0, -2.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, 12.0, 14.0, 12.0, 316.0, 9.0, 13.0, 12.0, -19.0, 13.0, 14.0, 4.0, -16.0, 7.0, 14.0, 12.0, -18.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 8.0, 14.0, 11.0, -18.0, 13.0, 14.0, 4.0, -16.0, -2.0, 14.0, 10.0, -7.0, 9.0, 14.0, 11.0, -19.0, 13.0, 14.0, 4.0, -16.0, 0.0, 13.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 0.0, -4.0, 6.0, -1.0, 14.0, 9.0, -7.0, 8.0, 14.0, 11.0, -18.0, 13.0, 0.0, -5.0, 7.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, 12.0, -3.0, 8.0, -2.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, -5.0, -7.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, -5.0, -7.0, -1.0, 14.0, 9.0, -7.0, 9.0, 13.0, 12.0, -19.0, 13.0, 14.0, -5.0, -7.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 11.0, -19.0, -6.0, -5.0, 13.0, 13.0, 11.0, 2.0, 13.0, -11.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 3.0, 13.0, -13.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -7.0, -3.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 9.0, 13.0, 13.0, -20.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0, 12.0, 2.0, 13.0, -12.0, -6.0, -4.0, 12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48345303255976035, "mean_inference_ms": 2.004589884138445, "mean_action_processing_ms": 0.12038916298360747, "mean_env_wait_ms": 0.2821224376967831, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 119880, "agent_timesteps_total": 119826, "timers": {"learn_time_ms": 1.926, "learn_throughput": 16615.629, "update_time_ms": 4.257}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 12.708309173583984, "min_q": 1.536196231842041, "max_q": 20.283430099487305, "mean_td_error": -20.88258171081543, "model": {}}}, "num_steps_sampled": 119880, "num_agent_steps_sampled": 119826, "num_steps_trained": 35232, "num_agent_steps_trained": 35232, "last_target_update_ts": 119880, "num_target_updates": 221}, "done": false, "episodes_total": 2349, "training_iteration": 38, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-19", "timestamp": 1626859759, "time_this_iter_s": 1.1724095344543457, "time_total_s": 42.38922834396362, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 42.38922834396362, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 47.5, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 10.0, 13.0, -7.0, -12.0, 13.0, 8.0, 6.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, 9.0, 11.0, 2.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -14.0, 10.0, 13.0, 6.0, -15.0, 14.0, 6.0, 10.0, 3.0, 10.0, 9.0, -7.0, -15.0, 14.0, 5.0, 11.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, 14.0, 11.0, 12.0, 315.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 13.0, 11.0, 6.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 5.0, 11.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -12.0, 13.0, 9.0, 5.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 8.0, 14.0, 11.0, -18.0, 13.0, 14.0, 4.0, -16.0, -2.0, 14.0, 10.0, -7.0, 9.0, 14.0, 11.0, -19.0, 13.0, 14.0, 4.0, -16.0, 0.0, 13.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 0.0, -4.0, 6.0, -1.0, 14.0, 9.0, -7.0, 8.0, 14.0, 11.0, -18.0, 13.0, 0.0, -5.0, 7.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, 12.0, -3.0, 8.0, -2.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, -5.0, -7.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, -5.0, -7.0, -1.0, 14.0, 9.0, -7.0, 9.0, 13.0, 12.0, -19.0, 13.0, 14.0, -5.0, -7.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 12.0, -20.0, 13.0, 14.0, 4.0, -16.0, -1.0, 14.0, 9.0, -7.0, 9.0, 14.0, 11.0, -19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4809456317576382, "mean_inference_ms": 1.9994939525344737, "mean_action_processing_ms": 0.11998846150160604, "mean_env_wait_ms": 0.2808740213549594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 123120, "agent_timesteps_total": 123039, "timers": {"learn_time_ms": 1.926, "learn_throughput": 16611.927, "update_time_ms": 4.194}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 11.834230422973633, "min_q": 1.2023109197616577, "max_q": 17.655622482299805, "mean_td_error": -9.929763793945312, "model": {}}}, "num_steps_sampled": 123120, "num_agent_steps_sampled": 123039, "num_steps_trained": 36192, "num_agent_steps_trained": 36192, "last_target_update_ts": 123120, "num_target_updates": 227}, "done": false, "episodes_total": 2403, "training_iteration": 39, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-20", "timestamp": 1626859760, "time_this_iter_s": 1.127544641494751, "time_total_s": 43.516772985458374, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 43.516772985458374, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 50.65, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 11.0, -3.0, -2.0, 9.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 10.0, 1.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 10.0, -3.0, -2.0, 10.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 0.0, -3.0, 9.0, 9.0, 14.0, -10.0, -2.0, 13.0, 6.0, -3.0, 10.0, 2.0, 14.0, -3.0, -5.0, 9.0, 1.0, -3.0, 12.0, 5.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 8.0, -2.0, 7.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 5.0, -1.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 1.0, -2.0, 11.0, 5.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -9.0, -3.0, 13.0, 6.0, -2.0, 9.0, 2.0, -14.0, 10.0, 13.0, 6.0, -15.0, 14.0, 6.0, 10.0, 3.0, 10.0, 9.0, -7.0, -15.0, 14.0, 5.0, 11.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, 14.0, 11.0, 12.0, 315.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 13.0, 11.0, 6.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 5.0, 11.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -12.0, 13.0, 9.0, 5.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0, -1.0, 10.0, 13.0, -7.0, -15.0, 14.0, 6.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48659983844250526, "mean_inference_ms": 2.0129764269862487, "mean_action_processing_ms": 0.12102564364582939, "mean_env_wait_ms": 0.28349646166991216, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 126360, "agent_timesteps_total": 126279, "timers": {"learn_time_ms": 1.921, "learn_throughput": 16656.457, "update_time_ms": 4.67}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 9.699393272399902, "min_q": 0.9115762710571289, "max_q": 16.23766326904297, "mean_td_error": -0.7627710103988647, "model": {}}}, "num_steps_sampled": 126360, "num_agent_steps_sampled": 126279, "num_steps_trained": 37152, "num_agent_steps_trained": 37152, "last_target_update_ts": 126360, "num_target_updates": 233}, "done": false, "episodes_total": 2457, "training_iteration": 40, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-21", "timestamp": 1626859761, "time_this_iter_s": 1.149552345275879, "time_total_s": 44.66632533073425, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 44.66632533073425, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 51.05, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 106.25, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 26.5625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 315.0, 12.0, 14.0, 13.0, -13.0, 1.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -18.0, 14.0, 7.0, 12.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 12.0, 12.0, -5.0, -4.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 13.0, -8.0, -3.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -7.0, 9.0, 10.0, 3.0, 14.0, 13.0, 315.0, 10.0, 12.0, 13.0, -6.0, -4.0, 7.0, 8.0, -3.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 13.0, -7.0, -4.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -7.0, 7.0, 12.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 12.0, 8.0, -2.0, -3.0, -12.0, 8.0, 12.0, 7.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, 8.0, -18.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 13.0, -7.0, -4.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 7.0, -1.0, -4.0, 4.0, -4.0, 12.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -6.0, -4.0, -6.0, 6.0, 12.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -7.0, 9.0, 10.0, 3.0, 14.0, 12.0, 317.0, 10.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -21.0, 14.0, 9.0, 13.0, 14.0, 12.0, 316.0, 11.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 8.0, -2.0, 7.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 5.0, -1.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -10.0, -2.0, 13.0, 1.0, -2.0, 11.0, 5.0, 14.0, -10.0, -2.0, 13.0, 6.0, -2.0, 9.0, 2.0, 14.0, -9.0, -3.0, 13.0, 6.0, -2.0, 9.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48424458796094483, "mean_inference_ms": 2.006448700143218, "mean_action_processing_ms": 0.12045613898097982, "mean_env_wait_ms": 0.2824900842722017, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 129600, "agent_timesteps_total": 129519, "timers": {"learn_time_ms": 1.939, "learn_throughput": 16499.204, "update_time_ms": 5.484}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 8.008825302124023, "min_q": 0.9866165518760681, "max_q": 13.700748443603516, "mean_td_error": 0.28131309151649475, "model": {}}}, "num_steps_sampled": 129600, "num_agent_steps_sampled": 129519, "num_steps_trained": 38112, "num_agent_steps_trained": 38112, "last_target_update_ts": 129600, "num_target_updates": 239}, "done": false, "episodes_total": 2538, "training_iteration": 41, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-22", "timestamp": 1626859762, "time_this_iter_s": 1.159256935119629, "time_total_s": 45.82558226585388, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 45.82558226585388, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 51.4, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 69.08, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 17.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, -1.0, 6.0, 12.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 7.0, 12.0, -3.0, -3.0, 3.0, 8.0, 7.0, 5.0, -6.0, 10.0, 6.0, -3.0, 6.0, 4.0, 8.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 5.0, 6.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, -1.0, 7.0, 12.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 10.0, 1.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, 9.0, -9.0, 12.0, 3.0, -3.0, 2.0, 8.0, 8.0, -1.0, 12.0, 12.0, -8.0, 12.0, 1.0, 8.0, -6.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, 5.0, -6.0, 10.0, 6.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 10.0, -6.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, -1.0, 12.0, 7.0, -1.0, 12.0, 12.0, -8.0, 11.0, 2.0, 8.0, -6.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, -1.0, 12.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 12.0, 8.0, -2.0, -3.0, -12.0, 8.0, 12.0, 7.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, 8.0, -18.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 13.0, -7.0, -4.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 7.0, -1.0, -4.0, 4.0, -4.0, 12.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -6.0, -4.0, -6.0, 6.0, 12.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -7.0, 9.0, 10.0, 3.0, 14.0, 12.0, 317.0, 10.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -6.0, 8.0, 10.0, 3.0, 14.0, 12.0, 316.0, 11.0, 13.0, 12.0, -5.0, -5.0, -21.0, 14.0, 9.0, 13.0, 14.0, 12.0, 316.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48196325935154327, "mean_inference_ms": 2.0016457513601975, "mean_action_processing_ms": 0.12012492116549334, "mean_env_wait_ms": 0.281231239064906, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 132840, "agent_timesteps_total": 132759, "timers": {"learn_time_ms": 2.107, "learn_throughput": 15188.843, "update_time_ms": 5.163}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 6.776035308837891, "min_q": 0.8918258547782898, "max_q": 12.237401008605957, "mean_td_error": 0.719383955001831, "model": {}}}, "num_steps_sampled": 132840, "num_agent_steps_sampled": 132759, "num_steps_trained": 39072, "num_agent_steps_trained": 39072, "last_target_update_ts": 132840, "num_target_updates": 245}, "done": false, "episodes_total": 2592, "training_iteration": 42, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-24", "timestamp": 1626859764, "time_this_iter_s": 1.3038241863250732, "time_total_s": 47.129406452178955, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 47.129406452178955, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 50.3, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.24, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -12.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 7.0, -5.0, 6.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 3.0, 12.0, -2.0, 3.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 11.0, 12.0, -7.0, 0.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 12.0, -2.0, -2.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 4.0, 10.0, -12.0, 13.0, 11.0, -3.0, -1.0, 8.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 1.0, 10.0, -9.0, 13.0, 12.0, -2.0, -2.0, 7.0, 1.0, 9.0, -5.0, 11.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 13.0, -1.0, -2.0, 5.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 6.0, -5.0, 8.0, 11.0, -2.0, -1.0, 7.0, 7.0, 7.0, -5.0, 7.0, 12.0, -2.0, -1.0, 6.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 5.0, 6.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, -1.0, 7.0, 12.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 10.0, 1.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, 9.0, -9.0, 12.0, 3.0, -3.0, 2.0, 8.0, 8.0, -1.0, 12.0, 12.0, -8.0, 12.0, 1.0, 8.0, -6.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, 5.0, -6.0, 10.0, 6.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 10.0, -6.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, -1.0, 12.0, 7.0, -1.0, 12.0, 12.0, -8.0, 11.0, 2.0, 8.0, -6.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, -1.0, 12.0, 7.0, -1.0, 12.0, 12.0, -8.0, -3.0, 3.0, 8.0, 7.0, -1.0, 12.0, 12.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4876119575380099, "mean_inference_ms": 2.0151646286881997, "mean_action_processing_ms": 0.12112177814266985, "mean_env_wait_ms": 0.2837938843241681, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 136080, "agent_timesteps_total": 135999, "timers": {"learn_time_ms": 1.969, "learn_throughput": 16252.071, "update_time_ms": 4.468}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.949538230895996, "min_q": 1.0371406078338623, "max_q": 11.769513130187988, "mean_td_error": 0.5869805216789246, "model": {}}}, "num_steps_sampled": 136080, "num_agent_steps_sampled": 135999, "num_steps_trained": 40032, "num_agent_steps_trained": 40032, "last_target_update_ts": 136080, "num_target_updates": 251}, "done": false, "episodes_total": 2646, "training_iteration": 43, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-25", "timestamp": 1626859765, "time_this_iter_s": 1.1291170120239258, "time_total_s": 48.25852346420288, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 48.25852346420288, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 46.05, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.09, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 12.0, 12.0, 2.0, -11.0, 8.0, -3.0, 12.0, -2.0, -4.0, 10.0, 12.0, -3.0, 4.0, 14.0, 10.0, -13.0, 13.0, -3.0, 7.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 7.0, 7.0, 3.0, 14.0, 10.0, -12.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 7.0, -2.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 9.0, 14.0, 7.0, -15.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 2.0, 14.0, 10.0, -11.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 12.0, 14.0, -1.0, -10.0, 8.0, -3.0, 12.0, -2.0, -1.0, 10.0, 13.0, -7.0, 12.0, 14.0, 0.0, -11.0, 8.0, -3.0, 10.0, 0.0, -4.0, 5.0, 12.0, 2.0, 3.0, 14.0, 10.0, -12.0, 6.0, -1.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 1.0, 13.0, 12.0, 11.0, 3.0, -11.0, 6.0, -1.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 7.0, -2.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 13.0, -1.0, 6.0, -3.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 3.0, 14.0, 9.0, -11.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -3.0, 11.0, 8.0, -1.0, 4.0, 14.0, 10.0, -13.0, 7.0, -6.0, 12.0, 2.0, -4.0, 5.0, 12.0, 2.0, 2.0, 14.0, 10.0, -11.0, 8.0, -3.0, 12.0, -2.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 13.0, -1.0, -2.0, 5.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 6.0, -5.0, 8.0, 11.0, -2.0, -1.0, 7.0, 7.0, 7.0, -5.0, 7.0, 12.0, -2.0, -1.0, 6.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0, 7.0, 7.0, -5.0, 7.0, 12.0, -6.0, -2.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4848870705740627, "mean_inference_ms": 2.007785473593317, "mean_action_processing_ms": 0.12049882934787876, "mean_env_wait_ms": 0.28265793773296727, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 139320, "agent_timesteps_total": 139239, "timers": {"learn_time_ms": 1.89, "learn_throughput": 16930.009, "update_time_ms": 4.21}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.347262382507324, "min_q": 0.9087762236595154, "max_q": 8.65401554107666, "mean_td_error": 0.4302405118942261, "model": {}}}, "num_steps_sampled": 139320, "num_agent_steps_sampled": 139239, "num_steps_trained": 40992, "num_agent_steps_trained": 40992, "last_target_update_ts": 139320, "num_target_updates": 257}, "done": false, "episodes_total": 2727, "training_iteration": 44, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-26", "timestamp": 1626859766, "time_this_iter_s": 1.1060845851898193, "time_total_s": 49.3646080493927, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985ad378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 49.3646080493927, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 52.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 13.0, 10.0, -4.0, 8.0, -13.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 12.0, -3.0, 13.0, -7.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -19.0, 13.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 13.0, 8.0, 5.0, -11.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 11.0, -14.0, 6.0, 12.0, 13.0, 13.0, 3.0, -14.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 9.0, 8.0, -4.0, 2.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 12.0, -12.0, 13.0, 2.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 11.0, -14.0, 6.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 12.0, 14.0, -1.0, -10.0, 8.0, -3.0, 12.0, -2.0, -1.0, 10.0, 13.0, -7.0, 12.0, 14.0, 0.0, -11.0, 8.0, -3.0, 10.0, 0.0, -4.0, 5.0, 12.0, 2.0, 3.0, 14.0, 10.0, -12.0, 6.0, -1.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 1.0, 13.0, 12.0, 11.0, 3.0, -11.0, 6.0, -1.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 7.0, -2.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 13.0, -1.0, 6.0, -3.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 3.0, 14.0, 9.0, -11.0, 8.0, -3.0, 12.0, -2.0, -4.0, 5.0, 12.0, 2.0, 4.0, 14.0, 10.0, -13.0, 8.0, -3.0, 12.0, -2.0, -3.0, 11.0, 8.0, -1.0, 4.0, 14.0, 10.0, -13.0, 7.0, -6.0, 12.0, 2.0, -4.0, 5.0, 12.0, 2.0, 2.0, 14.0, 10.0, -11.0, 8.0, -3.0, 12.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4826919380730073, "mean_inference_ms": 2.0029167034053357, "mean_action_processing_ms": 0.12016899074086504, "mean_env_wait_ms": 0.2815305239000077, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 142560, "agent_timesteps_total": 142479, "timers": {"learn_time_ms": 1.871, "learn_throughput": 17103.247, "update_time_ms": 4.492}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.667270660400391, "min_q": 1.0565519332885742, "max_q": 10.15202808380127, "mean_td_error": 0.8462570905685425, "model": {}}}, "num_steps_sampled": 142560, "num_agent_steps_sampled": 142479, "num_steps_trained": 41952, "num_agent_steps_trained": 41952, "last_target_update_ts": 142560, "num_target_updates": 263}, "done": false, "episodes_total": 2781, "training_iteration": 45, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-27", "timestamp": 1626859767, "time_this_iter_s": 1.1428077220916748, "time_total_s": 50.507415771484375, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 50.507415771484375, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 50.6, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.74, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 5.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 13.0, 2.0, -12.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 11.0, -18.0, 10.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 12.0, -20.0, 11.0, 12.0, 13.0, 2.0, -12.0, 12.0, 11.0, -19.0, 11.0, 12.0, 14.0, 2.0, -13.0, 12.0, 9.0, -19.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 12.0, 1.0, -8.0, 10.0, 12.0, 315.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 12.0, 315.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, -5.0, -5.0, 13.0, 12.0, 14.0, 7.0, -18.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, -8.0, -2.0, 13.0, 12.0, 14.0, 8.0, -10.0, 3.0, 8.0, -18.0, 13.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -19.0, 13.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 13.0, 8.0, 5.0, -11.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 11.0, -14.0, 6.0, 12.0, 13.0, 13.0, 3.0, -14.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 9.0, 8.0, -4.0, 2.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 12.0, -12.0, 13.0, 2.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0, 10.0, 13.0, -9.0, 1.0, 11.0, -14.0, 6.0, 12.0, 10.0, 13.0, -9.0, 1.0, 9.0, -14.0, 8.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4881982566773142, "mean_inference_ms": 2.015883324239885, "mean_action_processing_ms": 0.12116123155633572, "mean_env_wait_ms": 0.28404169567280285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 145800, "agent_timesteps_total": 145719, "timers": {"learn_time_ms": 1.851, "learn_throughput": 17290.083, "update_time_ms": 4.127}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.471006870269775, "min_q": 0.877288818359375, "max_q": 10.121569633483887, "mean_td_error": 0.5368795990943909, "model": {}}}, "num_steps_sampled": 145800, "num_agent_steps_sampled": 145719, "num_steps_trained": 42912, "num_agent_steps_trained": 42912, "last_target_update_ts": 145800, "num_target_updates": 269}, "done": false, "episodes_total": 2835, "training_iteration": 46, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-28", "timestamp": 1626859768, "time_this_iter_s": 1.1129887104034424, "time_total_s": 51.62040448188782, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 51.62040448188782, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 50.6, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 8.0, 14.0, -11.0, 4.0, 13.0, 6.0, 5.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -5.0, 12.0, 10.0, -2.0, 12.0, 12.0, -15.0, 6.0, 14.0, -1.0, 11.0, -9.0, -4.0, 12.0, 12.0, -5.0, -2.0, 12.0, 7.0, -2.0, 14.0, 0.0, 10.0, -9.0, -5.0, 11.0, 11.0, -2.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 11.0, 13.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 6.0, 11.0, -15.0, 13.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 12.0, -4.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, -3.0, 4.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, -1.0, 11.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -14.0, 5.0, 14.0, 0.0, 11.0, -10.0, 0.0, 7.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 10.0, 13.0, -4.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 10.0, 10.0, -1.0, 13.0, 11.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 6.0, 11.0, -15.0, 13.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 0.0, 9.0, -7.0, 13.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -7.0, 11.0, 13.0, -2.0, 10.0, 11.0, -13.0, 7.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 13.0, 11.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 12.0, 315.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, -5.0, -5.0, 13.0, 12.0, 14.0, 7.0, -18.0, 12.0, 8.0, -18.0, 13.0, 12.0, 14.0, 2.0, -13.0, 12.0, -8.0, -2.0, 13.0, 12.0, 14.0, 8.0, -10.0, 3.0, 8.0, -18.0, 13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4851356828650196, "mean_inference_ms": 2.0072017093124255, "mean_action_processing_ms": 0.12049098496010108, "mean_env_wait_ms": 0.28268117284642974, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 149040, "agent_timesteps_total": 148959, "timers": {"learn_time_ms": 1.88, "learn_throughput": 17021.69, "update_time_ms": 4.781}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.0301361083984375, "min_q": 1.0408931970596313, "max_q": 8.562990188598633, "mean_td_error": 1.40874445438385, "model": {}}}, "num_steps_sampled": 149040, "num_agent_steps_sampled": 148959, "num_steps_trained": 43872, "num_agent_steps_trained": 43872, "last_target_update_ts": 149040, "num_target_updates": 275}, "done": false, "episodes_total": 2916, "training_iteration": 47, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-29", "timestamp": 1626859769, "time_this_iter_s": 1.0955657958984375, "time_total_s": 52.715970277786255, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 52.715970277786255, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 51.75, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 79.03, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 19.7575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 2.0, -1.0, 13.0, 11.0, 14.0, -21.0, 11.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, -19.0, 9.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 9.0, 14.0, -18.0, 10.0, 1.0, 2.0, -1.0, 13.0, 12.0, 12.0, 315.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 3.0, -10.0, 11.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 5.0, -12.0, 11.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, -11.0, 12.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 3.0, 11.0, -1.0, 2.0, 11.0, 14.0, 314.0, 13.0, 1.0, -11.0, 12.0, 13.0, 10.0, 14.0, 316.0, 12.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, -7.0, -3.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 5.0, 9.0, -10.0, 11.0, 7.0, -3.0, -2.0, 13.0, 11.0, 14.0, 314.0, 13.0, 5.0, 3.0, -1.0, 8.0, 10.0, 12.0, -18.0, 11.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -14.0, 5.0, 14.0, 0.0, 11.0, -10.0, 0.0, 7.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 10.0, 13.0, -4.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 10.0, 10.0, -1.0, 13.0, 11.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 6.0, 11.0, -15.0, 13.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 0.0, 9.0, -7.0, 13.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -7.0, 11.0, 13.0, -2.0, 10.0, 11.0, -13.0, 7.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 13.0, 11.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0, 12.0, 12.0, -15.0, 6.0, 14.0, 0.0, 10.0, -9.0, -4.0, 11.0, 13.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48270862135060183, "mean_inference_ms": 2.0015550602918957, "mean_action_processing_ms": 0.12013146253497105, "mean_env_wait_ms": 0.2814549678515093, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 152280, "agent_timesteps_total": 152199, "timers": {"learn_time_ms": 1.871, "learn_throughput": 17105.426, "update_time_ms": 4.438}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.433177947998047, "min_q": 1.1500393152236938, "max_q": 9.848557472229004, "mean_td_error": 0.18001432716846466, "model": {}}}, "num_steps_sampled": 152280, "num_agent_steps_sampled": 152199, "num_steps_trained": 44832, "num_agent_steps_trained": 44832, "last_target_update_ts": 152280, "num_target_updates": 281}, "done": false, "episodes_total": 2970, "training_iteration": 48, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-31", "timestamp": 1626859771, "time_this_iter_s": 1.1098721027374268, "time_total_s": 53.82584238052368, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 53.82584238052368, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 49.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 75.66, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 18.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 13.0, 8.0, -4.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 10.0, 14.0, 315.0, 13.0, 0.0, 7.0, 10.0, -2.0, 8.0, 14.0, -19.0, 12.0, 1.0, 7.0, 9.0, -2.0, 12.0, 14.0, 314.0, 12.0, 2.0, 7.0, 8.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 5.0, -3.0, 12.0, 7.0, 4.0, -9.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, -1.0, 7.0, -2.0, 11.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 9.0, 14.0, -21.0, 13.0, 1.0, 7.0, 9.0, -2.0, 11.0, 13.0, -20.0, 11.0, 1.0, 7.0, 9.0, -2.0, 11.0, 4.0, -13.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 0.0, 11.0, 6.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 6.0, 7.0, 9.0, -7.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, -19.0, 9.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 9.0, 14.0, -18.0, 10.0, 1.0, 2.0, -1.0, 13.0, 12.0, 12.0, 315.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 3.0, -10.0, 11.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 5.0, -12.0, 11.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, -11.0, 12.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 3.0, 11.0, -1.0, 2.0, 11.0, 14.0, 314.0, 13.0, 1.0, -11.0, 12.0, 13.0, 10.0, 14.0, 316.0, 12.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, -7.0, -3.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 11.0, 14.0, 314.0, 13.0, 1.0, 2.0, -1.0, 13.0, 5.0, 9.0, -10.0, 11.0, 7.0, -3.0, -2.0, 13.0, 11.0, 14.0, 314.0, 13.0, 5.0, 3.0, -1.0, 8.0, 10.0, 12.0, -18.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4882284701316304, "mean_inference_ms": 2.015588508497713, "mean_action_processing_ms": 0.12112252716384067, "mean_env_wait_ms": 0.28402654732843663, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 155520, "agent_timesteps_total": 155439, "timers": {"learn_time_ms": 1.942, "learn_throughput": 16478.745, "update_time_ms": 4.778}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.036888122558594, "min_q": 1.008465051651001, "max_q": 9.8187894821167, "mean_td_error": 0.10307706892490387, "model": {}}}, "num_steps_sampled": 155520, "num_agent_steps_sampled": 155439, "num_steps_trained": 45792, "num_agent_steps_trained": 45792, "last_target_update_ts": 155520, "num_target_updates": 287}, "done": false, "episodes_total": 3024, "training_iteration": 49, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-32", "timestamp": 1626859772, "time_this_iter_s": 1.3206782341003418, "time_total_s": 55.14652061462402, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 55.14652061462402, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 51.35, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 89.36, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 22.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 6.0, 12.0, 13.0, -16.0, 7.0, -5.0, 8.0, 5.0, 1.0, -4.0, 7.0, 11.0, 8.0, 12.0, 13.0, -18.0, 6.0, -5.0, 2.0, 12.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 9.0, 3.0, 12.0, -9.0, 12.0, 12.0, 13.0, 316.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 14.0, -11.0, 1.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 9.0, 3.0, 10.0, -7.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 4.0, -5.0, 6.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 8.0, -6.0, 3.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 9.0, 11.0, 13.0, -18.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 7.0, 13.0, -16.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 6.0, -5.0, 4.0, 10.0, 1.0, -4.0, 8.0, 10.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 8.0, 10.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 9.0, 12.0, 13.0, -19.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 0.0, 11.0, 6.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0, 6.0, 7.0, 9.0, -7.0, 8.0, 14.0, -20.0, 13.0, 1.0, 7.0, 9.0, -2.0, 8.0, 14.0, -20.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48574203643250646, "mean_inference_ms": 2.008446528715033, "mean_action_processing_ms": 0.1205543343423861, "mean_env_wait_ms": 0.28290432031697516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 158760, "agent_timesteps_total": 158679, "timers": {"learn_time_ms": 1.839, "learn_throughput": 17398.788, "update_time_ms": 4.062}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.239710807800293, "min_q": 0.9697493314743042, "max_q": 8.517735481262207, "mean_td_error": 0.03693574294447899, "model": {}}}, "num_steps_sampled": 158760, "num_agent_steps_sampled": 158679, "num_steps_trained": 46752, "num_agent_steps_trained": 46752, "last_target_update_ts": 158760, "num_target_updates": 293}, "done": false, "episodes_total": 3105, "training_iteration": 50, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-33", "timestamp": 1626859773, "time_this_iter_s": 1.1365032196044922, "time_total_s": 56.283023834228516, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 56.283023834228516, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 46.85, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 129.7, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 32.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [314.0, 14.0, 12.0, 12.0, -6.0, 9.0, -1.0, 13.0, 314.0, 14.0, 12.0, 12.0, 12.0, 12.0, 8.0, -17.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, -20.0, 13.0, 10.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, -21.0, 13.0, 10.0, 13.0, 11.0, 12.0, 12.0, -20.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, -4.0, 11.0, 10.0, -2.0, 6.0, 12.0, 13.0, -16.0, 315.0, 14.0, 11.0, 12.0, 6.0, 12.0, 13.0, -16.0, -21.0, 13.0, 10.0, 13.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 9.0, -12.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, -18.0, 14.0, 12.0, 7.0, 6.0, 12.0, 13.0, -16.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 4.0, -5.0, 6.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 8.0, -6.0, 3.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 9.0, 11.0, 13.0, -18.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 7.0, 13.0, -16.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 6.0, -5.0, 4.0, 10.0, 1.0, -4.0, 8.0, 10.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 8.0, 10.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 9.0, 12.0, 13.0, -19.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0, 1.0, -4.0, 7.0, 11.0, 11.0, 12.0, 13.0, 317.0, 3.0, -6.0, 8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48309027026672496, "mean_inference_ms": 2.0025299522207884, "mean_action_processing_ms": 0.12015572169278381, "mean_env_wait_ms": 0.2815544670194549, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 162000, "agent_timesteps_total": 161919, "timers": {"learn_time_ms": 1.868, "learn_throughput": 17133.157, "update_time_ms": 4.333}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.783356189727783, "min_q": 1.1084033250808716, "max_q": 8.959538459777832, "mean_td_error": -9.847352981567383, "model": {}}}, "num_steps_sampled": 162000, "num_agent_steps_sampled": 161919, "num_steps_trained": 47712, "num_agent_steps_trained": 47712, "last_target_update_ts": 162000, "num_target_updates": 299}, "done": false, "episodes_total": 3159, "training_iteration": 51, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-34", "timestamp": 1626859774, "time_this_iter_s": 1.1335437297821045, "time_total_s": 57.41656756401062, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 57.41656756401062, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 52.5, "ram_util_percent": 14.149999999999999}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 41.96, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 10.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 9.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -1.0, 8.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, 1.0, 12.0, -10.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, 13.0, -3.0, 9.0, -4.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -13.0, 14.0, 1.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -4.0, 12.0, -5.0, 12.0, -13.0, 14.0, 1.0, 13.0, 9.0, -17.0, 13.0, 10.0, 1.0, 12.0, -6.0, 8.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -13.0, 14.0, 1.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, 8.0, 13.0, -7.0, 1.0, -13.0, 14.0, 1.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 7.0, -15.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 6.0, -14.0, 13.0, 10.0, 2.0, 7.0, 8.0, -2.0, -15.0, 14.0, 3.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -15.0, 14.0, 3.0, 13.0, 8.0, -15.0, 11.0, 11.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, 1.0, 12.0, -11.0, 13.0, -7.0, 8.0, 1.0, 13.0, 9.0, -17.0, 13.0, 10.0, -4.0, 12.0, -5.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -2.0, 13.0, -8.0, 12.0, -9.0, 4.0, 7.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -15.0, 14.0, 3.0, 13.0, 9.0, -17.0, 13.0, 10.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 9.0, -12.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, 314.0, 14.0, 12.0, 12.0, 6.0, 12.0, 13.0, -16.0, -18.0, 14.0, 12.0, 7.0, 6.0, 12.0, 13.0, -16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4858366289865728, "mean_inference_ms": 2.0079311778031426, "mean_action_processing_ms": 0.12054858614421765, "mean_env_wait_ms": 0.2828593874806564, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 165240, "agent_timesteps_total": 165240, "timers": {"learn_time_ms": 1.892, "learn_throughput": 16913.155, "update_time_ms": 4.112}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.860497951507568, "min_q": 1.0690363645553589, "max_q": 8.375128746032715, "mean_td_error": -0.01579931378364563, "model": {}}}, "num_steps_sampled": 165240, "num_agent_steps_sampled": 165240, "num_steps_trained": 48672, "num_agent_steps_trained": 48672, "last_target_update_ts": 165240, "num_target_updates": 305}, "done": false, "episodes_total": 3240, "training_iteration": 52, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-36", "timestamp": 1626859776, "time_this_iter_s": 1.166191577911377, "time_total_s": 58.582759141922, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 58.582759141922, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 50.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, -3.0, -2.0, 10.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 8.0, -15.0, 12.0, 14.0, 12.0, -6.0, -5.0, -1.0, 7.0, 13.0, -4.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -14.0, 10.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, -8.0, 10.0, -1.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 3.0, -8.0, 10.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 3.0, -3.0, 10.0, 5.0, 10.0, 9.0, -15.0, 11.0, 5.0, -7.0, 12.0, 5.0, 1.0, 14.0, -12.0, 12.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -14.0, 10.0, 14.0, 12.0, -6.0, -5.0, 10.0, 1.0, -6.0, 10.0, 7.0, -6.0, 12.0, 2.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 11.0, 7.0, -15.0, 12.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, -10.0, 10.0, 1.0, 1.0, 14.0, -12.0, 12.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 7.0, -15.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 6.0, -14.0, 13.0, 10.0, 2.0, 7.0, 8.0, -2.0, -15.0, 14.0, 3.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -15.0, 14.0, 3.0, 13.0, 8.0, -15.0, 11.0, 11.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, 1.0, 12.0, -11.0, 13.0, -7.0, 8.0, 1.0, 13.0, 9.0, -17.0, 13.0, 10.0, -4.0, 12.0, -5.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -2.0, 13.0, -8.0, 12.0, -9.0, 4.0, 7.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -14.0, 14.0, 2.0, 13.0, 9.0, -17.0, 13.0, 10.0, -5.0, 12.0, -4.0, 12.0, -15.0, 14.0, 3.0, 13.0, 9.0, -17.0, 13.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4833516486115017, "mean_inference_ms": 2.002314062597196, "mean_action_processing_ms": 0.12016897818550858, "mean_env_wait_ms": 0.28161365174859104, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 168480, "agent_timesteps_total": 168399, "timers": {"learn_time_ms": 1.842, "learn_throughput": 17369.966, "update_time_ms": 4.32}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.530991554260254, "min_q": 0.9489076733589172, "max_q": 9.07829475402832, "mean_td_error": -10.499374389648438, "model": {}}}, "num_steps_sampled": 168480, "num_agent_steps_sampled": 168399, "num_steps_trained": 49632, "num_agent_steps_trained": 49632, "last_target_update_ts": 168480, "num_target_updates": 311}, "done": false, "episodes_total": 3294, "training_iteration": 53, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-37", "timestamp": 1626859777, "time_this_iter_s": 1.1051669120788574, "time_total_s": 59.687926054000854, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 59.687926054000854, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 49.3, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -7.0, -1.0, 11.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 13.0, 8.0, 7.0, -13.0, 12.0, 13.0, 319.0, 10.0, 12.0, 4.0, 1.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -1.0, -6.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 9.0, -4.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -7.0, -3.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, -3.0, 3.0, 3.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 11.0, 13.0, -11.0, 2.0, 12.0, 10.0, 3.0, -10.0, 13.0, 12.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -19.0, 12.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 13.0, 12.0, -12.0, 2.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, -1.0, 7.0, 13.0, -4.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -14.0, 10.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, -8.0, 10.0, -1.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 3.0, -8.0, 10.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 3.0, -3.0, 10.0, 5.0, 10.0, 9.0, -15.0, 11.0, 5.0, -7.0, 12.0, 5.0, 1.0, 14.0, -12.0, 12.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -14.0, 10.0, 14.0, 12.0, -6.0, -5.0, 10.0, 1.0, -6.0, 10.0, 7.0, -6.0, 12.0, 2.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 11.0, 7.0, -15.0, 12.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, -10.0, 10.0, 1.0, 1.0, 14.0, -12.0, 12.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0, 10.0, 9.0, -15.0, 11.0, 14.0, 12.0, -6.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4884752254861943, "mean_inference_ms": 2.0148933815215893, "mean_action_processing_ms": 0.12108436854556275, "mean_env_wait_ms": 0.2839961749891577, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 171720, "agent_timesteps_total": 171639, "timers": {"learn_time_ms": 1.824, "learn_throughput": 17542.279, "update_time_ms": 4.7}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.542926788330078, "min_q": 1.2517558336257935, "max_q": 9.244532585144043, "mean_td_error": 0.3254322111606598, "model": {}}}, "num_steps_sampled": 171720, "num_agent_steps_sampled": 171639, "num_steps_trained": 50592, "num_agent_steps_trained": 50592, "last_target_update_ts": 171720, "num_target_updates": 317}, "done": false, "episodes_total": 3348, "training_iteration": 54, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-38", "timestamp": 1626859778, "time_this_iter_s": 1.1064858436584473, "time_total_s": 60.7944118976593, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985058c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 60.7944118976593, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 51.85, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.13, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 6.2825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 14.0, -14.0, 10.0, 5.0, 5.0, 12.0, 12.0, -14.0, 14.0, 11.0, 315.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 7.0, 11.0, 12.0, -15.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 13.0, -15.0, 12.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, 11.0, 315.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, 3.0, 12.0, -14.0, -1.0, -2.0, 7.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, 316.0, 9.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 11.0, 13.0, -11.0, 2.0, 12.0, 10.0, 3.0, -10.0, 13.0, 12.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -19.0, 12.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 13.0, 12.0, -12.0, 2.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -10.0, 0.0, 12.0, 10.0, -5.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48590752791165776, "mean_inference_ms": 2.0075775781611394, "mean_action_processing_ms": 0.12045113976974793, "mean_env_wait_ms": 0.28284897063142145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 174960, "agent_timesteps_total": 174906, "timers": {"learn_time_ms": 1.882, "learn_throughput": 17000.992, "update_time_ms": 4.613}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.8517374992370605, "min_q": 1.1358259916305542, "max_q": 8.594030380249023, "mean_td_error": -10.602693557739258, "model": {}}}, "num_steps_sampled": 174960, "num_agent_steps_sampled": 174906, "num_steps_trained": 51552, "num_agent_steps_trained": 51552, "last_target_update_ts": 174960, "num_target_updates": 323}, "done": false, "episodes_total": 3429, "training_iteration": 55, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-39", "timestamp": 1626859779, "time_this_iter_s": 1.176396131515503, "time_total_s": 61.970808029174805, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 61.970808029174805, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 50.7, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.13, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 6.2825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -8.0, 2.0, 10.0, 11.0, -11.0, 7.0, 6.0, 13.0, -13.0, 7.0, 10.0, 11.0, -8.0, 2.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -8.0, 11.0, 1.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -12.0, 11.0, 10.0, 6.0, -11.0, 5.0, 10.0, 11.0, -10.0, 4.0, 10.0, 11.0, -10.0, 10.0, 4.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -12.0, 6.0, 10.0, 11.0, -11.0, 4.0, 10.0, 12.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 14.0, -14.0, 10.0, 5.0, 5.0, 12.0, 12.0, -14.0, 14.0, 11.0, 315.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 7.0, 11.0, 12.0, -15.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 13.0, -15.0, 12.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, 11.0, 315.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, 3.0, 12.0, -14.0, -1.0, -2.0, 7.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, 316.0, 9.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4887332519603486, "mean_inference_ms": 2.0157158988169273, "mean_action_processing_ms": 0.12118155439903446, "mean_env_wait_ms": 0.284075894502592, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 177120, "agent_timesteps_total": 177039, "timers": {"learn_time_ms": 2.017, "learn_throughput": 15862.355, "update_time_ms": 5.458}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.478876113891602, "min_q": 1.2355539798736572, "max_q": 9.171664237976074, "mean_td_error": -10.227771759033203, "model": {}}}, "num_steps_sampled": 177120, "num_agent_steps_sampled": 177039, "num_steps_trained": 52192, "num_agent_steps_trained": 52192, "last_target_update_ts": 177120, "num_target_updates": 327}, "done": false, "episodes_total": 3456, "training_iteration": 56, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-40", "timestamp": 1626859780, "time_this_iter_s": 0.9476075172424316, "time_total_s": 62.918415546417236, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985417b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 62.918415546417236, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 38.7, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.75, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -14.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.4375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 8.0, -5.0, 13.0, -5.0, 2.0, 5.0, 13.0, -7.0, 8.0, 3.0, 11.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 5.0, 2.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -7.0, 8.0, 3.0, 11.0, -5.0, 3.0, 4.0, 13.0, -12.0, 14.0, 11.0, 2.0, -5.0, 2.0, 5.0, 13.0, -3.0, 8.0, 7.0, 3.0, -5.0, 3.0, 5.0, 12.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -7.0, 9.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -7.0, 7.0, 5.0, 10.0, -5.0, 2.0, 5.0, 13.0, 0.0, 8.0, -5.0, 12.0, -4.0, 4.0, 3.0, 12.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -1.0, 4.0, 1.0, 11.0, -6.0, 7.0, 3.0, 11.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -11.0, 8.0, 7.0, 11.0, -5.0, 2.0, 5.0, 13.0, 14.0, 11.0, 315.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, 3.0, 12.0, -14.0, -1.0, -2.0, 7.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, 316.0, 9.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, 3.0, -2.0, 3.0, 11.0, 5.0, 12.0, 12.0, -14.0, 14.0, -2.0, -10.0, 13.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -8.0, 2.0, 10.0, 11.0, -11.0, 7.0, 6.0, 13.0, -13.0, 7.0, 10.0, 11.0, -8.0, 2.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -8.0, 11.0, 1.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -12.0, 11.0, 10.0, 6.0, -11.0, 5.0, 10.0, 11.0, -10.0, 4.0, 10.0, 11.0, -10.0, 10.0, 4.0, 11.0, -11.0, 5.0, 10.0, 11.0, -11.0, 5.0, 10.0, 11.0, -12.0, 6.0, 10.0, 11.0, -11.0, 4.0, 10.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.484830523645522, "mean_inference_ms": 2.0052131708790792, "mean_action_processing_ms": 0.12040592082333465, "mean_env_wait_ms": 0.2825711138845998, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 180360, "agent_timesteps_total": 180279, "timers": {"learn_time_ms": 1.958, "learn_throughput": 16339.919, "update_time_ms": 4.551}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.516201019287109, "min_q": 1.2620002031326294, "max_q": 6.955509185791016, "mean_td_error": 0.13529999554157257, "model": {}}}, "num_steps_sampled": 180360, "num_agent_steps_sampled": 180279, "num_steps_trained": 53152, "num_agent_steps_trained": 53152, "last_target_update_ts": 180360, "num_target_updates": 333}, "done": false, "episodes_total": 3510, "training_iteration": 57, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-41", "timestamp": 1626859781, "time_this_iter_s": 1.1861248016357422, "time_total_s": 64.10454034805298, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 64.10454034805298, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 13.0, 6.0, -10.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -16.0, 13.0, 7.0, 11.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 9.0, 12.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, 11.0, -2.0, -7.0, 7.0, 11.0, 2.0, -5.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 5.0, 13.0, 1.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 6.0, 13.0, 0.0, -4.0, -3.0, 0.0, 5.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 5.0, 13.0, 2.0, -5.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 10.0, 8.0, 11.0, -14.0, -11.0, 10.0, 5.0, 11.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 9.0, 6.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 6.0, 10.0, 3.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -2.0, 11.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 5.0, 13.0, 2.0, -5.0, -18.0, 12.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 9.0, 7.0, 2.0, -3.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -16.0, 14.0, 8.0, 9.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 6.0, 10.0, 3.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, -5.0, 2.0, 5.0, 13.0, -7.0, 7.0, 5.0, 10.0, -5.0, 2.0, 5.0, 13.0, 0.0, 8.0, -5.0, 12.0, -4.0, 4.0, 3.0, 12.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -1.0, 4.0, 1.0, 11.0, -6.0, 7.0, 3.0, 11.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -6.0, 8.0, 3.0, 10.0, -5.0, 2.0, 5.0, 13.0, -11.0, 8.0, 7.0, 11.0, -5.0, 2.0, 5.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48652753667033055, "mean_inference_ms": 2.0089261560533105, "mean_action_processing_ms": 0.12051406489680452, "mean_env_wait_ms": 0.2832345549476902, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 183600, "agent_timesteps_total": 183519, "timers": {"learn_time_ms": 1.936, "learn_throughput": 16525.207, "update_time_ms": 5.073}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.5814208984375, "min_q": 0.7620648145675659, "max_q": 8.748405456542969, "mean_td_error": 0.25748270750045776, "model": {}}}, "num_steps_sampled": 183600, "num_agent_steps_sampled": 183519, "num_steps_trained": 54112, "num_agent_steps_trained": 54112, "last_target_update_ts": 183600, "num_target_updates": 339}, "done": false, "episodes_total": 3591, "training_iteration": 58, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-43", "timestamp": 1626859783, "time_this_iter_s": 1.1294047832489014, "time_total_s": 65.23394513130188, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 65.23394513130188, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 48.8, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -10.0, 10.0, 6.0, 9.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -16.0, 6.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -10.0, 0.0, 13.0, 12.0, -6.0, -1.0, 10.0, 12.0, -12.0, 5.0, 12.0, 10.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -5.0, 13.0, -4.0, 11.0, -15.0, 5.0, 12.0, 13.0, -6.0, 13.0, -3.0, 11.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, 6.0, 1.0, -4.0, 12.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -5.0, -1.0, 10.0, 11.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -9.0, 0.0, 11.0, 13.0, -1.0, 13.0, -7.0, 10.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, 6.0, -12.0, 12.0, 9.0, -2.0, 13.0, -4.0, 8.0, -12.0, 2.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -2.0, -6.0, 11.0, 12.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 9.0, 6.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 6.0, 10.0, 3.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -2.0, 11.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 5.0, 13.0, 2.0, -5.0, -18.0, 12.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 9.0, 7.0, 2.0, -3.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -16.0, 14.0, 8.0, 9.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 4.0, 13.0, 2.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0, 6.0, 10.0, 3.0, -4.0, -20.0, 14.0, 8.0, 13.0, 13.0, -3.0, 12.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48422152580406924, "mean_inference_ms": 2.0026517155390686, "mean_action_processing_ms": 0.12011966774996213, "mean_env_wait_ms": 0.28197459026147514, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 186840, "agent_timesteps_total": 186759, "timers": {"learn_time_ms": 1.903, "learn_throughput": 16818.0, "update_time_ms": 4.121}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.457738876342773, "min_q": 1.373775601387024, "max_q": 9.134736061096191, "mean_td_error": 0.14132367074489594, "model": {}}}, "num_steps_sampled": 186840, "num_agent_steps_sampled": 186759, "num_steps_trained": 55072, "num_agent_steps_trained": 55072, "last_target_update_ts": 186840, "num_target_updates": 345}, "done": false, "episodes_total": 3645, "training_iteration": 59, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-44", "timestamp": 1626859784, "time_this_iter_s": 1.1175568103790283, "time_total_s": 66.35150194168091, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 66.35150194168091, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 51.3, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 112.98, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 28.245}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 352.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 352.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 352.0, 15.0, 15.0, 15.0, 353.0, 15.0, 352.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 354.0, 353.0, 15.0, 15.0, 353.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 7.0, -17.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 5.0, 9.0, 6.0, -5.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 315.0, 14.0, 11.0, 12.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -9.0, 14.0, 11.0, -1.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -7.0, 14.0, 11.0, -3.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, 3.0, -10.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 315.0, 14.0, 11.0, 12.0, 13.0, 12.0, 316.0, 12.0, 14.0, 6.0, -8.0, 3.0, -17.0, 14.0, 12.0, 6.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 0.0, 12.0, -9.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 5.0, 13.0, 3.0, -6.0, 13.0, 11.0, -17.0, 8.0, 14.0, 9.0, -7.0, -1.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 14.0, 13.0, -9.0, -3.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, 3.0, -10.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 316.0, 14.0, 11.0, 11.0, 0.0, 10.0, -7.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 6.0, -7.0, 7.0, 316.0, 14.0, 11.0, 11.0, 13.0, 12.0, 316.0, 12.0, 9.0, 7.0, 4.0, -5.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -19.0, 14.0, 11.0, 9.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 317.0, 14.0, 11.0, 12.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 316.0, 14.0, 11.0, 11.0, -5.0, -1.0, 10.0, 11.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -9.0, 0.0, 11.0, 13.0, -1.0, 13.0, -7.0, 10.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, 6.0, -12.0, 12.0, 9.0, -2.0, 13.0, -4.0, 8.0, -12.0, 2.0, 12.0, 13.0, -6.0, -1.0, 10.0, 12.0, -15.0, 5.0, 12.0, 13.0, -2.0, -6.0, 11.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4866146964524113, "mean_inference_ms": 2.0076840370514564, "mean_action_processing_ms": 0.12044006628829884, "mean_env_wait_ms": 0.2832015570738251, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 190080, "agent_timesteps_total": 190026, "timers": {"learn_time_ms": 1.824, "learn_throughput": 17543.884, "update_time_ms": 4.169}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.626859188079834, "min_q": 1.0176429748535156, "max_q": 9.341054916381836, "mean_td_error": -20.003887176513672, "model": {}}}, "num_steps_sampled": 190080, "num_agent_steps_sampled": 190026, "num_steps_trained": 56032, "num_agent_steps_trained": 56032, "last_target_update_ts": 190080, "num_target_updates": 351}, "done": false, "episodes_total": 3726, "training_iteration": 60, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-45", "timestamp": 1626859785, "time_this_iter_s": 1.1547739505767822, "time_total_s": 67.50627589225769, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 67.50627589225769, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 50.849999999999994, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 72.44, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 18.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 352.0, 15.0, 15.0, 15.0, 353.0, 15.0, 352.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 354.0, 353.0, 15.0, 15.0, 353.0, 15.0, 352.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 5.0, 8.0, 4.0, 4.0, -5.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, 11.0, 6.0, 8.0, -10.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, 12.0, -12.0, 13.0, 2.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 10.0, -5.0, 8.0, 2.0, -2.0, 5.0, 8.0, 4.0, 3.0, -3.0, 7.0, 8.0, -1.0, 2.0, 6.0, 8.0, 5.0, -6.0, 8.0, 8.0, 11.0, 6.0, 8.0, -10.0, 4.0, -5.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, 10.0, 7.0, 8.0, -10.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -7.0, 7.0, 7.0, 8.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, -6.0, -3.0, 11.0, 13.0, 10.0, -13.0, 13.0, 5.0, 5.0, -5.0, 8.0, 7.0, -2.0, 7.0, 8.0, 2.0, 5.0, -6.0, 8.0, 8.0, 11.0, 6.0, 8.0, -10.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 6.0, -7.0, 8.0, 8.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 5.0, 13.0, 3.0, -6.0, 13.0, 11.0, -17.0, 8.0, 14.0, 9.0, -7.0, -1.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 14.0, 13.0, -9.0, -3.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, 3.0, -10.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 316.0, 14.0, 11.0, 11.0, 0.0, 10.0, -7.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 6.0, -7.0, 7.0, 316.0, 14.0, 11.0, 11.0, 13.0, 12.0, 316.0, 12.0, 9.0, 7.0, 4.0, -5.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -19.0, 14.0, 11.0, 9.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 317.0, 14.0, 11.0, 12.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, -8.0, 14.0, 11.0, -2.0, 13.0, 12.0, 316.0, 12.0, 9.0, 13.0, -9.0, 2.0, 316.0, 14.0, 11.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4840644484473481, "mean_inference_ms": 2.0023456489891096, "mean_action_processing_ms": 0.12006367695785586, "mean_env_wait_ms": 0.2819685066064417, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 193320, "agent_timesteps_total": 193239, "timers": {"learn_time_ms": 1.923, "learn_throughput": 16643.651, "update_time_ms": 5.721}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.706989288330078, "min_q": 1.1610275506973267, "max_q": 9.244586944580078, "mean_td_error": 0.8047630786895752, "model": {}}}, "num_steps_sampled": 193320, "num_agent_steps_sampled": 193239, "num_steps_trained": 56992, "num_agent_steps_trained": 56992, "last_target_update_ts": 193320, "num_target_updates": 357}, "done": false, "episodes_total": 3780, "training_iteration": 61, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-46", "timestamp": 1626859786, "time_this_iter_s": 1.1518640518188477, "time_total_s": 68.65813994407654, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 68.65813994407654, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 51.05, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 9.0, 7.0, -15.0, 5.0, 9.0, 9.0, -8.0, 14.0, -5.0, 2.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 14.0, 11.0, 13.0, 315.0, 14.0, -15.0, 12.0, 4.0, 13.0, 10.0, 9.0, -17.0, 14.0, -4.0, -1.0, 6.0, 13.0, 6.0, 13.0, -17.0, 14.0, -6.0, 1.0, 6.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -14.0, 12.0, 3.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, 1.0, 10.0, -10.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 14.0, 13.0, 313.0, 14.0, -15.0, 12.0, 4.0, 4.0, 10.0, 12.0, -11.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 14.0, 7.0, 13.0, -19.0, 14.0, -15.0, 12.0, 4.0, 14.0, 13.0, 7.0, -19.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 8.0, 11.0, -17.0, 14.0, -1.0, 12.0, -10.0, 13.0, 6.0, 13.0, -17.0, 14.0, -5.0, 2.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, -10.0, 10.0, 12.0, 3.0, 14.0, -14.0, 12.0, 3.0, 9.0, 5.0, 13.0, -12.0, 14.0, -15.0, 12.0, 4.0, 9.0, 12.0, 13.0, -19.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -5.0, 2.0, 4.0, 13.0, 6.0, 13.0, -17.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, 11.0, 6.0, 8.0, -10.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, 12.0, -12.0, 13.0, 2.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 10.0, -5.0, 8.0, 2.0, -2.0, 5.0, 8.0, 4.0, 3.0, -3.0, 7.0, 8.0, -1.0, 2.0, 6.0, 8.0, 5.0, -6.0, 8.0, 8.0, 11.0, 6.0, 8.0, -10.0, 4.0, -5.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, 10.0, 7.0, 8.0, -10.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 5.0, -6.0, 8.0, 8.0, -7.0, 7.0, 7.0, 8.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, -6.0, -3.0, 11.0, 13.0, 10.0, -13.0, 13.0, 5.0, 5.0, -5.0, 8.0, 7.0, -2.0, 7.0, 8.0, 2.0, 5.0, -6.0, 8.0, 8.0, 11.0, 6.0, 8.0, -10.0, 5.0, -6.0, 8.0, 8.0, -2.0, 5.0, 8.0, 4.0, 6.0, -7.0, 8.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48963102648594775, "mean_inference_ms": 2.016351782937925, "mean_action_processing_ms": 0.12112978956334068, "mean_env_wait_ms": 0.2845973464003705, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 196560, "agent_timesteps_total": 196479, "timers": {"learn_time_ms": 1.86, "learn_throughput": 17208.725, "update_time_ms": 4.684}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.263128757476807, "min_q": 1.3794258832931519, "max_q": 8.359292030334473, "mean_td_error": 0.034843847155570984, "model": {}}}, "num_steps_sampled": 196560, "num_agent_steps_sampled": 196479, "num_steps_trained": 57952, "num_agent_steps_trained": 57952, "last_target_update_ts": 196560, "num_target_updates": 363}, "done": false, "episodes_total": 3834, "training_iteration": 62, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-47", "timestamp": 1626859787, "time_this_iter_s": 1.1399099826812744, "time_total_s": 69.79804992675781, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 69.79804992675781, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 5.0, 10.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 10.0, 10.0, -13.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 12.0, 318.0, 13.0, 11.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, -2.0, 6.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 7.0, 12.0, -12.0, 8.0, 13.0, -8.0, 13.0, -3.0, -6.0, 12.0, 1.0, 8.0, 13.0, -8.0, 13.0, -3.0, 5.0, 12.0, -8.0, 6.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 10.0, 10.0, -13.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 7.0, 10.0, -8.0, 6.0, 13.0, -8.0, 13.0, -3.0, -1.0, 12.0, -9.0, 13.0, 13.0, -8.0, 13.0, -3.0, 14.0, -15.0, 12.0, 4.0, 13.0, 10.0, 9.0, -17.0, 14.0, -4.0, -1.0, 6.0, 13.0, 6.0, 13.0, -17.0, 14.0, -6.0, 1.0, 6.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -14.0, 12.0, 3.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, 1.0, 10.0, -10.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 14.0, 13.0, 313.0, 14.0, -15.0, 12.0, 4.0, 4.0, 10.0, 12.0, -11.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 14.0, 7.0, 13.0, -19.0, 14.0, -15.0, 12.0, 4.0, 14.0, 13.0, 7.0, -19.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 8.0, 11.0, -17.0, 14.0, -1.0, 12.0, -10.0, 13.0, 6.0, 13.0, -17.0, 14.0, -5.0, 2.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -15.0, 12.0, 4.0, -10.0, 10.0, 12.0, 3.0, 14.0, -14.0, 12.0, 3.0, 9.0, 5.0, 13.0, -12.0, 14.0, -15.0, 12.0, 4.0, 9.0, 12.0, 13.0, -19.0, 14.0, -15.0, 12.0, 4.0, 13.0, 6.0, 13.0, -17.0, 14.0, -5.0, 2.0, 4.0, 13.0, 6.0, 13.0, -17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49007977571428013, "mean_inference_ms": 2.01770419793756, "mean_action_processing_ms": 0.12123177414381008, "mean_env_wait_ms": 0.28482739742133273, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 198720, "agent_timesteps_total": 198639, "timers": {"learn_time_ms": 2.102, "learn_throughput": 15224.679, "update_time_ms": 5.926}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.743525505065918, "min_q": 1.2049442529678345, "max_q": 9.280925750732422, "mean_td_error": 0.37934085726737976, "model": {}}}, "num_steps_sampled": 198720, "num_agent_steps_sampled": 198639, "num_steps_trained": 58592, "num_agent_steps_trained": 58592, "last_target_update_ts": 198720, "num_target_updates": 367}, "done": false, "episodes_total": 3888, "training_iteration": 63, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-48", "timestamp": 1626859788, "time_this_iter_s": 1.0222692489624023, "time_total_s": 70.82031917572021, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985052f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 70.82031917572021, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 45.1, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 8.0, 12.0, -16.0, 11.0, 12.0, -3.0, 12.0, -6.0, -3.0, 12.0, 11.0, -5.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 7.0, 11.0, 6.0, -9.0, 11.0, -11.0, 5.0, 10.0, 13.0, -4.0, 12.0, -6.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 13.0, -4.0, 12.0, -6.0, 11.0, -11.0, 5.0, 10.0, 9.0, -15.0, 12.0, 9.0, 315.0, 14.0, 11.0, 13.0, 12.0, -4.0, 12.0, -5.0, 3.0, -11.0, 11.0, 12.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 7.0, 5.0, 5.0, -2.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, -15.0, 13.0, 7.0, 10.0, 12.0, -4.0, 12.0, -5.0, 4.0, -11.0, 11.0, 11.0, 12.0, -3.0, 12.0, -6.0, -9.0, 13.0, 13.0, -2.0, 12.0, -4.0, 12.0, -5.0, 0.0, -7.0, 11.0, 11.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 10.0, -4.0, 13.0, -4.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, -9.0, 13.0, 13.0, -2.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, 5.0, 7.0, -9.0, 11.0, -11.0, 5.0, 10.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 12.0, 318.0, 13.0, 11.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, -2.0, 6.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 7.0, 12.0, -12.0, 8.0, 13.0, -8.0, 13.0, -3.0, -6.0, 12.0, 1.0, 8.0, 13.0, -8.0, 13.0, -3.0, 5.0, 12.0, -8.0, 6.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 10.0, 10.0, -13.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 3.0, 12.0, -8.0, 8.0, 13.0, -8.0, 13.0, -3.0, 7.0, 10.0, -8.0, 6.0, 13.0, -8.0, 13.0, -3.0, -1.0, 12.0, -9.0, 13.0, 13.0, -8.0, 13.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49041674848863354, "mean_inference_ms": 2.0190553453215734, "mean_action_processing_ms": 0.12129985211623814, "mean_env_wait_ms": 0.2850065544327643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 201960, "agent_timesteps_total": 201879, "timers": {"learn_time_ms": 1.866, "learn_throughput": 17144.538, "update_time_ms": 4.721}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.9618635177612305, "min_q": 1.4014536142349243, "max_q": 8.878092765808105, "mean_td_error": -20.3016300201416, "model": {}}}, "num_steps_sampled": 201960, "num_agent_steps_sampled": 201879, "num_steps_trained": 59552, "num_agent_steps_trained": 59552, "last_target_update_ts": 201960, "num_target_updates": 373}, "done": false, "episodes_total": 3942, "training_iteration": 64, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-50", "timestamp": 1626859790, "time_this_iter_s": 1.149726152420044, "time_total_s": 71.97004532814026, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985ad378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 71.97004532814026, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 51.9, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 13.0, -19.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -18.0, 9.0, -18.0, 11.0, 9.0, 13.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 7.0, -9.0, 9.0, 8.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 12.0, -3.0, 3.0, 3.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -1.0, 11.0, -3.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -1.0, 11.0, -3.0, 11.0, 13.0, -20.0, 11.0, -13.0, 12.0, 9.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 1.0, -1.0, 11.0, 4.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -1.0, 11.0, -3.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -10.0, 1.0, -13.0, 13.0, 8.0, 7.0, 7.0, -7.0, 9.0, 6.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 7.0, -5.0, 11.0, 2.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -14.0, 12.0, 10.0, 7.0, 7.0, -5.0, 11.0, 2.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 7.0, -7.0, 9.0, 6.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 11.0, 9.0, 8.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -1.0, 11.0, -3.0, -9.0, 13.0, 13.0, -2.0, 12.0, -4.0, 12.0, -5.0, 0.0, -7.0, 11.0, 11.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 10.0, -4.0, 13.0, -4.0, 11.0, -11.0, 5.0, 10.0, 12.0, -4.0, 12.0, -5.0, -9.0, 13.0, 13.0, -2.0, 12.0, -4.0, 12.0, -5.0, 11.0, -11.0, 5.0, 10.0, 12.0, 5.0, 7.0, -9.0, 11.0, -11.0, 5.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.487259357756418, "mean_inference_ms": 2.011233512878752, "mean_action_processing_ms": 0.12059461934478052, "mean_env_wait_ms": 0.2837599820373306, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 205200, "agent_timesteps_total": 205173, "timers": {"learn_time_ms": 1.746, "learn_throughput": 18328.744, "update_time_ms": 4.128}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.224470138549805, "min_q": 1.3318710327148438, "max_q": 9.1881685256958, "mean_td_error": -9.930813789367676, "model": {}}}, "num_steps_sampled": 205200, "num_agent_steps_sampled": 205173, "num_steps_trained": 60512, "num_agent_steps_trained": 60512, "last_target_update_ts": 205200, "num_target_updates": 379}, "done": false, "episodes_total": 4023, "training_iteration": 65, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-51", "timestamp": 1626859791, "time_this_iter_s": 1.139998197555542, "time_total_s": 73.1100435256958, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 73.1100435256958, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 51.099999999999994, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -2.0, 0.0, 12.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, -4.0, 11.0, 9.0, -17.0, 12.0, 12.0, 8.0, -8.0, 0.0, 11.0, 12.0, -17.0, 12.0, 12.0, 8.0, -1.0, -2.0, 11.0, 7.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -18.0, 12.0, 12.0, 9.0, -1.0, 0.0, 11.0, 5.0, -15.0, 12.0, 6.0, 12.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -15.0, 11.0, 8.0, 11.0, -1.0, 0.0, 11.0, 5.0, -15.0, 12.0, 6.0, 12.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, 3.0, 0.0, 11.0, 1.0, 1.0, 11.0, 12.0, -9.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -2.0, -2.0, 11.0, 8.0, -15.0, 12.0, 12.0, 6.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -15.0, 14.0, 12.0, 4.0, -17.0, 12.0, 12.0, 8.0, -15.0, 14.0, 12.0, 4.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -10.0, 11.0, 1.0, 13.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -5.0, 0.0, 11.0, 9.0, -16.0, 12.0, 11.0, 8.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, 0.0, -4.0, 12.0, 7.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -10.0, 1.0, -13.0, 13.0, 8.0, 7.0, 7.0, -7.0, 9.0, 6.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 7.0, -5.0, 11.0, 2.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -14.0, 12.0, 10.0, 7.0, 7.0, -5.0, 11.0, 2.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 7.0, -7.0, 9.0, 6.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 11.0, 9.0, 8.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 11.0, 13.0, -20.0, 11.0, -13.0, 13.0, 8.0, 7.0, 8.0, -1.0, 11.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48479312567236404, "mean_inference_ms": 2.005857883014073, "mean_action_processing_ms": 0.12021832806948318, "mean_env_wait_ms": 0.2825432834452746, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 208440, "agent_timesteps_total": 208359, "timers": {"learn_time_ms": 2.013, "learn_throughput": 15893.724, "update_time_ms": 4.611}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.067531585693359, "min_q": 1.1625970602035522, "max_q": 8.981393814086914, "mean_td_error": 0.7417545914649963, "model": {}}}, "num_steps_sampled": 208440, "num_agent_steps_sampled": 208359, "num_steps_trained": 61472, "num_agent_steps_trained": 61472, "last_target_update_ts": 208440, "num_target_updates": 385}, "done": false, "episodes_total": 4077, "training_iteration": 66, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-52", "timestamp": 1626859792, "time_this_iter_s": 1.1221954822540283, "time_total_s": 74.23223900794983, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 74.23223900794983, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 50.75, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 99.49, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 24.8725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, -2.0, 11.0, 3.0, 14.0, -10.0, -1.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 8.0, -1.0, 11.0, -3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -3.0, 11.0, 4.0, 14.0, -10.0, -2.0, 13.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, -13.0, 11.0, 11.0, 6.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 8.0, -2.0, 6.0, 3.0, 14.0, 314.0, 13.0, 12.0, 8.0, -2.0, 6.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, -13.0, 12.0, 10.0, 6.0, 14.0, 314.0, 11.0, 13.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 12.0, 13.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 9.0, -10.0, 11.0, 5.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 12.0, 13.0, -17.0, 12.0, 12.0, 8.0, -1.0, -4.0, 11.0, 9.0, -17.0, 12.0, 12.0, 8.0, -8.0, 0.0, 11.0, 12.0, -17.0, 12.0, 12.0, 8.0, -1.0, -2.0, 11.0, 7.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -18.0, 12.0, 12.0, 9.0, -1.0, 0.0, 11.0, 5.0, -15.0, 12.0, 6.0, 12.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -15.0, 11.0, 8.0, 11.0, -1.0, 0.0, 11.0, 5.0, -15.0, 12.0, 6.0, 12.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, 3.0, 0.0, 11.0, 1.0, 1.0, 11.0, 12.0, -9.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -2.0, -2.0, 11.0, 8.0, -15.0, 12.0, 12.0, 6.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -15.0, 14.0, 12.0, 4.0, -17.0, 12.0, 12.0, 8.0, -15.0, 14.0, 12.0, 4.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -10.0, 11.0, 1.0, 13.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -5.0, 0.0, 11.0, 9.0, -16.0, 12.0, 11.0, 8.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0, 0.0, -4.0, 12.0, 7.0, -1.0, 0.0, 11.0, 5.0, -17.0, 12.0, 12.0, 8.0, -1.0, 0.0, 11.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4902486127542511, "mean_inference_ms": 2.0197937278798865, "mean_action_processing_ms": 0.12124774263875106, "mean_env_wait_ms": 0.2851073914782727, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 211680, "agent_timesteps_total": 211599, "timers": {"learn_time_ms": 1.999, "learn_throughput": 16008.03, "update_time_ms": 6.798}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.67898416519165, "min_q": 1.1047089099884033, "max_q": 9.643091201782227, "mean_td_error": 0.8813989162445068, "model": {}}}, "num_steps_sampled": 211680, "num_agent_steps_sampled": 211599, "num_steps_trained": 62432, "num_agent_steps_trained": 62432, "last_target_update_ts": 211680, "num_target_updates": 391}, "done": false, "episodes_total": 4131, "training_iteration": 67, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-53", "timestamp": 1626859793, "time_this_iter_s": 1.1596322059631348, "time_total_s": 75.39187121391296, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 75.39187121391296, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 50.3, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 48.79, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 12.1975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 12.0, -11.0, 3.0, 13.0, -11.0, 10.0, 3.0, -6.0, -4.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, 9.0, -19.0, 12.0, 13.0, 9.0, 13.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -5.0, -5.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -5.0, -5.0, 12.0, 13.0, 10.0, 12.0, -11.0, 4.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 12.0, -4.0, 4.0, 3.0, 12.0, -14.0, 9.0, 8.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, 11.0, 7.0, 5.0, -8.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, 10.0, -20.0, 12.0, 13.0, 13.0, 10.0, -13.0, 5.0, 10.0, 5.0, -3.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, 3.0, -4.0, 3.0, -5.0, -5.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, 12.0, -4.0, 8.0, -1.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 13.0, 10.0, -13.0, 5.0, 10.0, -8.0, 10.0, 3.0, -4.0, 12.0, 8.0, -1.0, 11.0, 12.0, -15.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 14.0, -10.0, 8.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 12.0, -10.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 10.0, -12.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, 9.0, -19.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -5.0, -5.0, 12.0, 13.0, 11.0, 12.0, -15.0, 7.0, 14.0, -10.0, 8.0, 3.0, -4.0, -6.0, 12.0, 13.0, 9.0, 11.0, -12.0, 7.0, 13.0, -11.0, 10.0, 3.0, 10.0, -20.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, -13.0, 12.0, 10.0, 6.0, 14.0, 314.0, 11.0, 13.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 12.0, 13.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 13.0, 12.0, 9.0, -10.0, 11.0, 5.0, 14.0, 314.0, 13.0, 12.0, 3.0, -2.0, 11.0, 3.0, 14.0, 314.0, 12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48744899272318576, "mean_inference_ms": 2.0123185494587896, "mean_action_processing_ms": 0.12057121419601241, "mean_env_wait_ms": 0.2839506558755344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 214920, "agent_timesteps_total": 214866, "timers": {"learn_time_ms": 1.909, "learn_throughput": 16766.737, "update_time_ms": 4.561}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.054642677307129, "min_q": 1.260863184928894, "max_q": 9.196030616760254, "mean_td_error": 0.5976463556289673, "model": {}}}, "num_steps_sampled": 214920, "num_agent_steps_sampled": 214866, "num_steps_trained": 63392, "num_agent_steps_trained": 63392, "last_target_update_ts": 214920, "num_target_updates": 397}, "done": false, "episodes_total": 4212, "training_iteration": 68, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-54", "timestamp": 1626859794, "time_this_iter_s": 1.1580045223236084, "time_total_s": 76.54987573623657, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 76.54987573623657, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 48.9, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, -10.0, 8.0, 13.0, 5.0, 13.0, -1.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, -6.0, 14.0, 11.0, -4.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 10.0, -11.0, 3.0, 13.0, 4.0, -10.0, 8.0, 13.0, -12.0, 14.0, 2.0, 11.0, 4.0, -10.0, 8.0, 13.0, -11.0, 13.0, 2.0, 11.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 9.0, -6.0, -1.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 5.0, -6.0, 8.0, 8.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 3.0, -10.0, 13.0, 9.0, 1.0, 9.0, 7.0, -2.0, 4.0, -10.0, 9.0, 12.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 6.0, -9.0, 9.0, 9.0, 1.0, 14.0, 2.0, -2.0, 4.0, -9.0, 7.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 2.0, 14.0, 1.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, 3.0, -4.0, 3.0, -5.0, -5.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, 12.0, -4.0, 8.0, -1.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 13.0, 10.0, -13.0, 5.0, 10.0, -8.0, 10.0, 3.0, -4.0, 12.0, 8.0, -1.0, 11.0, 12.0, -15.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 14.0, -10.0, 8.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 12.0, -10.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 10.0, -12.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, 9.0, -19.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -5.0, -5.0, 12.0, 13.0, 11.0, 12.0, -15.0, 7.0, 14.0, -10.0, 8.0, 3.0, -4.0, -6.0, 12.0, 13.0, 9.0, 11.0, -12.0, 7.0, 13.0, -11.0, 10.0, 3.0, 10.0, -20.0, 12.0, 13.0, 10.0, 12.0, -14.0, 7.0, 13.0, -11.0, 10.0, 3.0, -4.0, -6.0, 12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4848843225230435, "mean_inference_ms": 2.0066214798547537, "mean_action_processing_ms": 0.12019198108812851, "mean_env_wait_ms": 0.2826528224643931, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 218160, "agent_timesteps_total": 218079, "timers": {"learn_time_ms": 1.775, "learn_throughput": 18029.355, "update_time_ms": 4.623}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.288712501525879, "min_q": 1.491064429283142, "max_q": 9.080390930175781, "mean_td_error": 0.9729098677635193, "model": {}}}, "num_steps_sampled": 218160, "num_agent_steps_sampled": 218079, "num_steps_trained": 64352, "num_agent_steps_trained": 64352, "last_target_update_ts": 218160, "num_target_updates": 403}, "done": false, "episodes_total": 4266, "training_iteration": 69, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-56", "timestamp": 1626859796, "time_this_iter_s": 1.1229395866394043, "time_total_s": 77.67281532287598, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 77.67281532287598, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 12.0, 9.0, -14.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -11.0, 5.0, 13.0, 11.0, 8.0, -17.0, 13.0, 9.0, -10.0, 3.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 12.0, 12.0, 1.0, -10.0, 12.0, 9.0, -10.0, 4.0, -13.0, 13.0, 8.0, 7.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 6.0, -7.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 8.0, -14.0, 9.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 9.0, 9.0, 12.0, -15.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 1.0, -10.0, 12.0, 9.0, -10.0, 4.0, 3.0, 13.0, 9.0, -10.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 9.0, 2.0, -9.0, 13.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 13.0, -11.0, 0.0, 12.0, 9.0, -10.0, 4.0, 10.0, 11.0, 8.0, -14.0, 13.0, 9.0, -17.0, 10.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, -1.0, 7.0, -4.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 11.0, 13.0, 9.0, -18.0, 4.0, -10.0, 8.0, 13.0, -6.0, 14.0, 11.0, -4.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 10.0, -11.0, 3.0, 13.0, 4.0, -10.0, 8.0, 13.0, -12.0, 14.0, 2.0, 11.0, 4.0, -10.0, 8.0, 13.0, -11.0, 13.0, 2.0, 11.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 9.0, -6.0, -1.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 5.0, -6.0, 8.0, 8.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 3.0, -10.0, 13.0, 9.0, 1.0, 9.0, 7.0, -2.0, 4.0, -10.0, 9.0, 12.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 6.0, -9.0, 9.0, 9.0, 1.0, 14.0, 2.0, -2.0, 4.0, -9.0, 7.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0, 4.0, -10.0, 8.0, 13.0, 2.0, 14.0, 1.0, -2.0, 4.0, -10.0, 8.0, 13.0, 1.0, 14.0, 2.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4902214907461342, "mean_inference_ms": 2.0198675230729726, "mean_action_processing_ms": 0.12120646968629498, "mean_env_wait_ms": 0.28513799106513504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 221400, "agent_timesteps_total": 221319, "timers": {"learn_time_ms": 1.982, "learn_throughput": 16146.105, "update_time_ms": 4.285}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.2378458976745605, "min_q": 1.3043817281723022, "max_q": 9.672508239746094, "mean_td_error": -0.0816083550453186, "model": {}}}, "num_steps_sampled": 221400, "num_agent_steps_sampled": 221319, "num_steps_trained": 65312, "num_agent_steps_trained": 65312, "last_target_update_ts": 221400, "num_target_updates": 409}, "done": false, "episodes_total": 4320, "training_iteration": 70, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-57", "timestamp": 1626859797, "time_this_iter_s": 1.3052542209625244, "time_total_s": 78.9780695438385, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 78.9780695438385, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 45.3, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 10.0, 7.0, -1.0, -1.0, -5.0, 7.0, 12.0, 1.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, 11.0, -2.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -4.0, 12.0, 12.0, -5.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 7.0, 7.0, 2.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 5.0, 4.0, 7.0, -1.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 5.0, 4.0, 7.0, -1.0, 11.0, 6.0, 12.0, -14.0, 4.0, 11.0, 10.0, -10.0, 1.0, 7.0, 8.0, -1.0, -4.0, 12.0, 12.0, -5.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 5.0, 10.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, -9.0, 12.0, 10.0, 2.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, -15.0, 13.0, 10.0, 7.0, 1.0, 7.0, 8.0, -1.0, -5.0, 7.0, 0.0, 13.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -4.0, 7.0, 12.0, 0.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 9.0, 2.0, -9.0, 13.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, 13.0, -11.0, 0.0, 12.0, 9.0, -10.0, 4.0, 10.0, 11.0, 8.0, -14.0, 13.0, 9.0, -17.0, 10.0, 13.0, 11.0, 8.0, -17.0, 12.0, 9.0, -10.0, 4.0, 13.0, -1.0, 7.0, -4.0, 12.0, 9.0, -10.0, 4.0, 13.0, 11.0, 8.0, -17.0, 11.0, 13.0, 9.0, -18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48750558807199185, "mean_inference_ms": 2.0123619943476423, "mean_action_processing_ms": 0.12053976261216473, "mean_env_wait_ms": 0.28398390317406297, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 224640, "agent_timesteps_total": 224559, "timers": {"learn_time_ms": 1.924, "learn_throughput": 16633.338, "update_time_ms": 4.671}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.830277442932129, "min_q": 1.4699350595474243, "max_q": 9.119003295898438, "mean_td_error": 1.351962924003601, "model": {}}}, "num_steps_sampled": 224640, "num_agent_steps_sampled": 224559, "num_steps_trained": 66272, "num_agent_steps_trained": 66272, "last_target_update_ts": 224640, "num_target_updates": 415}, "done": false, "episodes_total": 4401, "training_iteration": 71, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-58", "timestamp": 1626859798, "time_this_iter_s": 1.1689434051513672, "time_total_s": 80.14701294898987, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 80.14701294898987, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 12.0, -19.0, 11.0, 11.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -18.0, 10.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 8.0, 0.0, -3.0, 10.0, -20.0, 12.0, 10.0, 13.0, 1.0, -7.0, 9.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -15.0, 8.0, 9.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 7.0, -14.0, 11.0, 11.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -16.0, 8.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -12.0, 7.0, 12.0, 8.0, 0.0, -6.0, 9.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -16.0, 12.0, 6.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -1.0, 12.0, -9.0, 13.0, 11.0, -19.0, 11.0, 12.0, 317.0, 12.0, 12.0, 13.0, 11.0, -19.0, 11.0, 12.0, -14.0, 4.0, 12.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 5.0, 4.0, 7.0, -1.0, 11.0, 6.0, 12.0, -14.0, 4.0, 11.0, 10.0, -10.0, 1.0, 7.0, 8.0, -1.0, -4.0, 12.0, 12.0, -5.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 5.0, 10.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, -9.0, 12.0, 10.0, 2.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, -15.0, 13.0, 10.0, 7.0, 1.0, 7.0, 8.0, -1.0, -5.0, 7.0, 0.0, 13.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -4.0, 7.0, 12.0, 0.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0, 4.0, 12.0, 10.0, -11.0, 1.0, 7.0, 8.0, -1.0, -3.0, 12.0, 12.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48504581493787163, "mean_inference_ms": 2.007134990789106, "mean_action_processing_ms": 0.12018389720086517, "mean_env_wait_ms": 0.2827291611523445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 227880, "agent_timesteps_total": 227799, "timers": {"learn_time_ms": 1.844, "learn_throughput": 17358.06, "update_time_ms": 4.744}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.61989164352417, "min_q": 1.208890676498413, "max_q": 8.85802936553955, "mean_td_error": -20.951217651367188, "model": {}}}, "num_steps_sampled": 227880, "num_agent_steps_sampled": 227799, "num_steps_trained": 67232, "num_agent_steps_trained": 67232, "last_target_update_ts": 227880, "num_target_updates": 421}, "done": false, "episodes_total": 4455, "training_iteration": 72, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-29-59", "timestamp": 1626859799, "time_this_iter_s": 1.1358373165130615, "time_total_s": 81.28285026550293, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 81.28285026550293, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 11.0, -20.0, 12.0, 12.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -8.0, -1.0, 11.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -7.0, -1.0, 10.0, 13.0, -3.0, -4.0, 11.0, 11.0, -13.0, 4.0, 11.0, 13.0, 13.0, -9.0, 12.0, -1.0, -8.0, -1.0, 11.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 8.0, -4.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 12.0, -8.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -9.0, 13.0, -2.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 12.0, -8.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, 8.0, 0.0, -3.0, 10.0, -20.0, 12.0, 10.0, 13.0, 1.0, -7.0, 9.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -15.0, 8.0, 9.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 7.0, -14.0, 11.0, 11.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -16.0, 8.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -12.0, 7.0, 12.0, 8.0, 0.0, -6.0, 9.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -16.0, 12.0, 6.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 12.0, -1.0, 12.0, -9.0, 13.0, 11.0, -19.0, 11.0, 12.0, 317.0, 12.0, 12.0, 13.0, 11.0, -19.0, 11.0, 12.0, -14.0, 4.0, 12.0, 13.0, 11.0, -19.0, 11.0, 12.0, -20.0, 12.0, 10.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49050776459783535, "mean_inference_ms": 2.020716375392731, "mean_action_processing_ms": 0.1211907141120871, "mean_env_wait_ms": 0.2852676478693849, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 231120, "agent_timesteps_total": 231039, "timers": {"learn_time_ms": 1.781, "learn_throughput": 17971.417, "update_time_ms": 4.131}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.952763557434082, "min_q": 1.3184001445770264, "max_q": 9.069696426391602, "mean_td_error": 2.7871384620666504, "model": {}}}, "num_steps_sampled": 231120, "num_agent_steps_sampled": 231039, "num_steps_trained": 68192, "num_agent_steps_trained": 68192, "last_target_update_ts": 231120, "num_target_updates": 427}, "done": false, "episodes_total": 4509, "training_iteration": 73, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-00", "timestamp": 1626859800, "time_this_iter_s": 1.0894415378570557, "time_total_s": 82.37229180335999, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 82.37229180335999, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 51.650000000000006, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 7.0, 12.0, 9.0, 1.0, -6.0, 13.0, 7.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -5.0, 3.0, 7.0, 10.0, 9.0, 11.0, -11.0, 6.0, -15.0, 5.0, 12.0, 13.0, 12.0, -9.0, 12.0, 0.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, -3.0, 3.0, 6.0, -1.0, 5.0, 12.0, -1.0, -9.0, 1.0, 13.0, 10.0, 9.0, 11.0, -10.0, 5.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, -1.0, 8.0, 1.0, 7.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -9.0, 4.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -7.0, -3.0, 12.0, 13.0, -3.0, 7.0, 13.0, -2.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, 8.0, 13.0, -2.0, 9.0, 11.0, -11.0, 6.0, -8.0, -2.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, -3.0, 11.0, 1.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 12.0, 13.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, -1.0, -4.0, 8.0, 12.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -10.0, 5.0, -13.0, 3.0, 12.0, 13.0, 9.0, -6.0, 1.0, 11.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -10.0, 5.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, -1.0, -4.0, 11.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 13.0, 11.0, -21.0, 12.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -12.0, 8.0, 7.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -12.0, 8.0, 7.0, 12.0, 10.0, 13.0, -12.0, 4.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -9.0, 13.0, -2.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 12.0, -8.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, -1.0, 13.0, 13.0, -9.0, 12.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4877656053545363, "mean_inference_ms": 2.0129075306577446, "mean_action_processing_ms": 0.12056673869199659, "mean_env_wait_ms": 0.28408156550171404, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 234360, "agent_timesteps_total": 234279, "timers": {"learn_time_ms": 1.901, "learn_throughput": 16834.875, "update_time_ms": 4.185}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.213903427124023, "min_q": 1.09061598777771, "max_q": 9.225234031677246, "mean_td_error": 0.7891275882720947, "model": {}}}, "num_steps_sampled": 234360, "num_agent_steps_sampled": 234279, "num_steps_trained": 69152, "num_agent_steps_trained": 69152, "last_target_update_ts": 234360, "num_target_updates": 433}, "done": false, "episodes_total": 4590, "training_iteration": 74, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-02", "timestamp": 1626859802, "time_this_iter_s": 1.1573364734649658, "time_total_s": 83.52962827682495, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985416a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 83.52962827682495, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 11.0, 11.0, -19.0, 12.0, -15.0, 14.0, 11.0, 5.0, 10.0, 10.0, -18.0, 13.0, -3.0, 14.0, -4.0, 8.0, 10.0, 10.0, -18.0, 13.0, -11.0, 11.0, 3.0, 12.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 12.0, 10.0, -19.0, 12.0, -8.0, 7.0, 3.0, 13.0, 5.0, 10.0, -13.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 6.0, 10.0, -14.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -17.0, 14.0, 6.0, 12.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 13.0, 10.0, 319.0, 12.0, -16.0, 14.0, 6.0, 11.0, 13.0, 8.0, -19.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -4.0, 14.0, -4.0, 9.0, 11.0, 11.0, -20.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -8.0, 7.0, 3.0, 13.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 11.0, 9.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 9.0, 11.0, -11.0, 6.0, -8.0, -2.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, -3.0, 11.0, 1.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 12.0, 13.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, -1.0, -4.0, 8.0, 12.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -10.0, 5.0, -13.0, 3.0, 12.0, 13.0, 9.0, -6.0, 1.0, 11.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -10.0, 5.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, -1.0, -4.0, 11.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 13.0, 11.0, -21.0, 12.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -12.0, 8.0, 7.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -12.0, 8.0, 7.0, 12.0, 10.0, 13.0, -12.0, 4.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0, -13.0, 3.0, 12.0, 13.0, -4.0, -6.0, 13.0, 12.0, 9.0, 11.0, -11.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48531789527535724, "mean_inference_ms": 2.007350677891252, "mean_action_processing_ms": 0.12020422368063277, "mean_env_wait_ms": 0.2828375593072391, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 237600, "agent_timesteps_total": 237519, "timers": {"learn_time_ms": 1.925, "learn_throughput": 16622.831, "update_time_ms": 4.225}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.981093406677246, "min_q": 1.1202294826507568, "max_q": 9.018027305603027, "mean_td_error": -10.283393859863281, "model": {}}}, "num_steps_sampled": 237600, "num_agent_steps_sampled": 237519, "num_steps_trained": 70112, "num_agent_steps_trained": 70112, "last_target_update_ts": 237600, "num_target_updates": 439}, "done": false, "episodes_total": 4644, "training_iteration": 75, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-03", "timestamp": 1626859803, "time_this_iter_s": 1.1568565368652344, "time_total_s": 84.68648481369019, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985419d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 84.68648481369019, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 49.1, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -4.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, 8.0, -4.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, 8.0, -4.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -5.0, -5.0, 12.0, 13.0, -2.0, 12.0, 9.0, -4.0, -4.0, 8.0, -2.0, 13.0, 8.0, 13.0, -5.0, -1.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, 0.0, 14.0, -5.0, 6.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -17.0, 7.0, 12.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -5.0, 14.0, -4.0, 10.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, 14.0, 11.0, 10.0, -20.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -5.0, 9.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -5.0, 14.0, -3.0, 9.0, 12.0, -8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -7.0, -3.0, 12.0, 13.0, -3.0, 14.0, -5.0, 9.0, 10.0, 10.0, -18.0, 13.0, -11.0, 11.0, 3.0, 12.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 12.0, 10.0, -19.0, 12.0, -8.0, 7.0, 3.0, 13.0, 5.0, 10.0, -13.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 6.0, 10.0, -14.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -17.0, 14.0, 6.0, 12.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 13.0, 10.0, 319.0, 12.0, -16.0, 14.0, 6.0, 11.0, 13.0, 8.0, -19.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -4.0, 14.0, -4.0, 9.0, 11.0, 11.0, -20.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, -8.0, 7.0, 3.0, 13.0, 10.0, 10.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0, 11.0, 9.0, -18.0, 13.0, -16.0, 14.0, 6.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4909282149187602, "mean_inference_ms": 2.0211640291612394, "mean_action_processing_ms": 0.12126763626752675, "mean_env_wait_ms": 0.2854801851582527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 240840, "agent_timesteps_total": 240759, "timers": {"learn_time_ms": 1.953, "learn_throughput": 16387.401, "update_time_ms": 4.472}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.808284759521484, "min_q": 1.2218220233917236, "max_q": 9.327046394348145, "mean_td_error": -9.935632705688477, "model": {}}}, "num_steps_sampled": 240840, "num_agent_steps_sampled": 240759, "num_steps_trained": 71072, "num_agent_steps_trained": 71072, "last_target_update_ts": 240840, "num_target_updates": 445}, "done": false, "episodes_total": 4698, "training_iteration": 76, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-04", "timestamp": 1626859804, "time_this_iter_s": 1.180846929550171, "time_total_s": 85.86733174324036, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 85.86733174324036, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 50.9, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -3.0, -9.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -13.0, 13.0, 7.0, 8.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -5.0, 13.0, 8.0, -1.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -6.0, 13.0, 8.0, 0.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -2.0, 13.0, 8.0, -4.0, 13.0, 14.0, -2.0, -10.0, -2.0, 13.0, 8.0, -4.0, 11.0, 14.0, -11.0, 1.0, -3.0, 13.0, 8.0, -3.0, 12.0, 14.0, -2.0, -9.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -3.0, -9.0, -3.0, 13.0, 8.0, -3.0, 14.0, 8.0, -5.0, -2.0, -2.0, 13.0, 8.0, -4.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 6.0, -1.0, 13.0, 14.0, -2.0, -10.0, -5.0, 13.0, 10.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -5.0, 13.0, 8.0, -1.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 9.0, -2.0, -5.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, 8.0, -4.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -5.0, -5.0, 12.0, 13.0, -2.0, 12.0, 9.0, -4.0, -4.0, 8.0, -2.0, 13.0, 8.0, 13.0, -5.0, -1.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, 0.0, 14.0, -5.0, 6.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -17.0, 7.0, 12.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -5.0, 14.0, -4.0, 10.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, 14.0, 11.0, 10.0, -20.0, -4.0, 8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -5.0, 9.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -4.0, 8.0, -2.0, 13.0, -5.0, 14.0, -3.0, 9.0, 12.0, -8.0, -2.0, 13.0, -3.0, 14.0, -5.0, 9.0, -7.0, -3.0, 12.0, 13.0, -3.0, 14.0, -5.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49114262602759423, "mean_inference_ms": 2.021656379508414, "mean_action_processing_ms": 0.12131620391132163, "mean_env_wait_ms": 0.28561516186677416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 243000, "agent_timesteps_total": 242919, "timers": {"learn_time_ms": 2.013, "learn_throughput": 15898.995, "update_time_ms": 5.1}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.43241024017334, "min_q": 1.0235719680786133, "max_q": 8.607537269592285, "mean_td_error": 0.9253520965576172, "model": {}}}, "num_steps_sampled": 243000, "num_agent_steps_sampled": 242919, "num_steps_trained": 71712, "num_agent_steps_trained": 71712, "last_target_update_ts": 243000, "num_target_updates": 449}, "done": false, "episodes_total": 4752, "training_iteration": 77, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-05", "timestamp": 1626859805, "time_this_iter_s": 0.9657747745513916, "time_total_s": 86.83310651779175, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791ea60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 86.83310651779175, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 39.7, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -12.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, -1.0, 13.0, 6.0, -3.0, -2.0, 14.0, 8.0, -5.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 14.0, 2.0, -5.0, -2.0, 14.0, 8.0, -5.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 3.0, 12.0, 3.0, -3.0, -3.0, 5.0, 6.0, 7.0, 4.0, 12.0, 2.0, -3.0, -3.0, 12.0, 6.0, 0.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 1.0, 8.0, 9.0, -3.0, -3.0, 10.0, 6.0, 2.0, 2.0, 13.0, 3.0, -3.0, -3.0, 10.0, 6.0, 2.0, -12.0, 14.0, 1.0, 12.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 2.0, 14.0, 4.0, -5.0, -2.0, 9.0, 3.0, 5.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 2.0, 6.0, 4.0, 12.0, 2.0, -3.0, -4.0, 6.0, 11.0, 2.0, 4.0, 12.0, 0.0, -1.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, -1.0, 13.0, 6.0, -3.0, -3.0, 10.0, 6.0, 2.0, 7.0, 12.0, -1.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 14.0, 6.0, -2.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -5.0, 13.0, 8.0, -1.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -6.0, 13.0, 8.0, 0.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -2.0, 13.0, 8.0, -4.0, 13.0, 14.0, -2.0, -10.0, -2.0, 13.0, 8.0, -4.0, 11.0, 14.0, -11.0, 1.0, -3.0, 13.0, 8.0, -3.0, 12.0, 14.0, -2.0, -9.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -3.0, -9.0, -3.0, 13.0, 8.0, -3.0, 14.0, 8.0, -5.0, -2.0, -2.0, 13.0, 8.0, -4.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 6.0, -1.0, 13.0, 14.0, -2.0, -10.0, -5.0, 13.0, 10.0, -3.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0, -5.0, 13.0, 8.0, -1.0, 13.0, 14.0, -2.0, -10.0, -3.0, 13.0, 8.0, -3.0, 13.0, 9.0, -2.0, -5.0, -3.0, 13.0, 8.0, -3.0, 13.0, 14.0, -2.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49124343926032926, "mean_inference_ms": 2.0219126841745076, "mean_action_processing_ms": 0.12134264752426795, "mean_env_wait_ms": 0.28565963524644195, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 246240, "agent_timesteps_total": 246159, "timers": {"learn_time_ms": 1.811, "learn_throughput": 17665.341, "update_time_ms": 4.128}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.398133277893066, "min_q": 1.1592457294464111, "max_q": 9.482171058654785, "mean_td_error": 0.9440926313400269, "model": {}}}, "num_steps_sampled": 246240, "num_agent_steps_sampled": 246159, "num_steps_trained": 72672, "num_agent_steps_trained": 72672, "last_target_update_ts": 246240, "num_target_updates": 455}, "done": false, "episodes_total": 4806, "training_iteration": 78, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-06", "timestamp": 1626859806, "time_this_iter_s": 1.166100263595581, "time_total_s": 87.99920678138733, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985059d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 87.99920678138733, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 50.45, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 6.0, -1.0, -2.0, 12.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 9.0, 6.0, 12.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 3.0, 9.0, -10.0, 13.0, -1.0, -6.0, 11.0, 11.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 3.0, 8.0, -5.0, 9.0, -6.0, -2.0, 11.0, 12.0, -7.0, 3.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 7.0, 3.0, -8.0, 13.0, -3.0, -5.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, -1.0, 5.0, -2.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 7.0, 3.0, -8.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 6.0, 5.0, -9.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 1.0, 5.0, -4.0, 13.0, -6.0, -2.0, 10.0, 13.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, 11.0, -19.0, 12.0, 11.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -3.0, -5.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, -15.0, 5.0, 12.0, 13.0, -19.0, 11.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 1.0, 5.0, -4.0, 13.0, -6.0, -3.0, 11.0, 13.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, -2.0, 9.0, 3.0, 5.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 2.0, 6.0, 4.0, 12.0, 2.0, -3.0, -4.0, 6.0, 11.0, 2.0, 4.0, 12.0, 0.0, -1.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 10.0, 6.0, 2.0, -1.0, 13.0, 6.0, -3.0, -3.0, 10.0, 6.0, 2.0, 7.0, 12.0, -1.0, -3.0, -3.0, 10.0, 6.0, 2.0, 4.0, 12.0, 2.0, -3.0, -3.0, 14.0, 6.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4881021802020712, "mean_inference_ms": 2.013466524338517, "mean_action_processing_ms": 0.12067094773706383, "mean_env_wait_ms": 0.2842996357456144, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 249480, "agent_timesteps_total": 249399, "timers": {"learn_time_ms": 1.781, "learn_throughput": 17962.518, "update_time_ms": 4.134}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.412679672241211, "min_q": 0.9979905486106873, "max_q": 8.600348472595215, "mean_td_error": -10.33420181274414, "model": {}}}, "num_steps_sampled": 249480, "num_agent_steps_sampled": 249399, "num_steps_trained": 73632, "num_agent_steps_trained": 73632, "last_target_update_ts": 249480, "num_target_updates": 461}, "done": false, "episodes_total": 4887, "training_iteration": 79, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-08", "timestamp": 1626859808, "time_this_iter_s": 1.120788335800171, "time_total_s": 89.1199951171875, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 89.1199951171875, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 13.0, 10.0, -3.0, -5.0, 11.0, -5.0, -1.0, 10.0, -14.0, 10.0, 12.0, 7.0, -13.0, 11.0, 8.0, 9.0, -9.0, 14.0, -2.0, 12.0, -5.0, 8.0, 12.0, 0.0, 6.0, 10.0, 9.0, -10.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 13.0, -5.0, 7.0, 0.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, -7.0, 11.0, -1.0, 12.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, -8.0, 8.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 10.0, 9.0, -11.0, 7.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, -14.0, 9.0, 12.0, 8.0, 4.0, 13.0, -13.0, 11.0, 11.0, -5.0, -1.0, 10.0, -5.0, 13.0, -5.0, 12.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, -14.0, 10.0, 12.0, 7.0, -17.0, 11.0, 8.0, 13.0, 8.0, 8.0, -13.0, 12.0, 11.0, 14.0, -2.0, -8.0, 5.0, 10.0, 5.0, -5.0, -5.0, 11.0, 0.0, 9.0, 5.0, 10.0, 5.0, -5.0, -4.0, 14.0, -7.0, 12.0, 10.0, 10.0, -11.0, 6.0, 11.0, -5.0, -1.0, 10.0, -2.0, 10.0, -5.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 3.0, 8.0, -5.0, 9.0, -6.0, -2.0, 11.0, 12.0, -7.0, 3.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 7.0, 3.0, -8.0, 13.0, -3.0, -5.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, -1.0, 5.0, -2.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 7.0, 3.0, -8.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 6.0, 5.0, -9.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 1.0, 5.0, -4.0, 13.0, -6.0, -2.0, 10.0, 13.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, 11.0, -19.0, 12.0, 11.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -3.0, -5.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, -15.0, 5.0, 12.0, 13.0, -19.0, 11.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0, 1.0, 5.0, -4.0, 13.0, -6.0, -3.0, 11.0, 13.0, -12.0, 8.0, 6.0, 13.0, 4.0, 8.0, -10.0, 13.0, -6.0, -2.0, 11.0, 12.0, -12.0, 8.0, 6.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48574352533392146, "mean_inference_ms": 2.0081400085742978, "mean_action_processing_ms": 0.12030453388885999, "mean_env_wait_ms": 0.28308065764272916, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 252720, "agent_timesteps_total": 252639, "timers": {"learn_time_ms": 1.888, "learn_throughput": 16951.177, "update_time_ms": 5.145}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.778264999389648, "min_q": 1.1012845039367676, "max_q": 9.479361534118652, "mean_td_error": 0.3162064552307129, "model": {}}}, "num_steps_sampled": 252720, "num_agent_steps_sampled": 252639, "num_steps_trained": 74592, "num_agent_steps_trained": 74592, "last_target_update_ts": 252720, "num_target_updates": 467}, "done": false, "episodes_total": 4941, "training_iteration": 80, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-09", "timestamp": 1626859809, "time_this_iter_s": 1.1626217365264893, "time_total_s": 90.28261685371399, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dac80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 90.28261685371399, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 2.0, -14.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 8.0, -8.0, 11.0, 4.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, -1.0, -5.0, 11.0, 10.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 9.0, 14.0, 4.0, -12.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, -4.0, 0.0, 11.0, 8.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 13.0, -5.0, 12.0, -5.0, 13.0, 14.0, 9.0, -21.0, 13.0, -5.0, 11.0, -4.0, 13.0, 14.0, 9.0, -21.0, 13.0, -3.0, -4.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 9.0, 14.0, 4.0, -12.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -3.0, 11.0, 7.0, 13.0, 14.0, 9.0, -21.0, 13.0, -4.0, -4.0, 10.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, -13.0, 11.0, 8.0, 9.0, -9.0, 14.0, -2.0, 12.0, -5.0, 8.0, 12.0, 0.0, 6.0, 10.0, 9.0, -10.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 13.0, -5.0, 7.0, 0.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, -7.0, 11.0, -1.0, 12.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, -8.0, 8.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 10.0, 9.0, -11.0, 7.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, -14.0, 9.0, 12.0, 8.0, 4.0, 13.0, -13.0, 11.0, 11.0, -5.0, -1.0, 10.0, -5.0, 13.0, -5.0, 12.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, 5.0, 10.0, 5.0, -5.0, 11.0, -5.0, -1.0, 10.0, -14.0, 10.0, 12.0, 7.0, -17.0, 11.0, 8.0, 13.0, 8.0, 8.0, -13.0, 12.0, 11.0, 14.0, -2.0, -8.0, 5.0, 10.0, 5.0, -5.0, -5.0, 11.0, 0.0, 9.0, 5.0, 10.0, 5.0, -5.0, -4.0, 14.0, -7.0, 12.0, 10.0, 10.0, -11.0, 6.0, 11.0, -5.0, -1.0, 10.0, -2.0, 10.0, -5.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49125098788288585, "mean_inference_ms": 2.021801880724718, "mean_action_processing_ms": 0.12135611897210395, "mean_env_wait_ms": 0.2856514303413567, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 255960, "agent_timesteps_total": 255879, "timers": {"learn_time_ms": 1.903, "learn_throughput": 16812.733, "update_time_ms": 4.15}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.915929317474365, "min_q": 1.9924464225769043, "max_q": 8.989001274108887, "mean_td_error": 1.4816157817840576, "model": {}}}, "num_steps_sampled": 255960, "num_agent_steps_sampled": 255879, "num_steps_trained": 75552, "num_agent_steps_trained": 75552, "last_target_update_ts": 255960, "num_target_updates": 473}, "done": false, "episodes_total": 4995, "training_iteration": 81, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-10", "timestamp": 1626859810, "time_this_iter_s": 1.1152381896972656, "time_total_s": 91.39785504341125, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 91.39785504341125, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 49.1, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.88, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 7.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, 318.0, 13.0, 10.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -12.0, 13.0, 3.0, 11.0, 14.0, -1.0, 4.0, -2.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 6.0, -6.0, 2.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 14.0, -18.0, 10.0, 9.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, -8.0, 1.0, 9.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, -14.0, 6.0, 10.0, 13.0, 318.0, 13.0, 10.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, -3.0, -1.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 9.0, -15.0, 9.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 10.0, -3.0, -5.0, 13.0, 12.0, 13.0, -1.0, -9.0, 14.0, -1.0, 4.0, -2.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 14.0, 320.0, 8.0, 12.0, 2.0, -3.0, 3.0, 13.0, 13.0, 13.0, 1.0, -12.0, 11.0, -12.0, 4.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 14.0, 318.0, 9.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 12.0, -16.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, 318.0, 13.0, 10.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, 13.0, 14.0, 9.0, -21.0, 0.0, -3.0, 11.0, 7.0, 13.0, 14.0, 9.0, -21.0, 13.0, -4.0, -4.0, 10.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0, 0.0, -5.0, 11.0, 9.0, 13.0, 14.0, 9.0, -21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4880965398205258, "mean_inference_ms": 2.0129855086248325, "mean_action_processing_ms": 0.12066125435117492, "mean_env_wait_ms": 0.2842870152137673, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 259200, "agent_timesteps_total": 259119, "timers": {"learn_time_ms": 1.886, "learn_throughput": 16970.253, "update_time_ms": 4.844}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.346011161804199, "min_q": 0.9270010590553284, "max_q": 9.076796531677246, "mean_td_error": 0.7296854257583618, "model": {}}}, "num_steps_sampled": 259200, "num_agent_steps_sampled": 259119, "num_steps_trained": 76512, "num_agent_steps_trained": 76512, "last_target_update_ts": 259200, "num_target_updates": 479}, "done": false, "episodes_total": 5076, "training_iteration": 82, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-11", "timestamp": 1626859811, "time_this_iter_s": 1.1302075386047363, "time_total_s": 92.52806258201599, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985052f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 92.52806258201599, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 50.55, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.89, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 7.9725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 9.0, 12.0, -17.0, 11.0, 11.0, 13.0, 10.0, -19.0, 13.0, -6.0, 10.0, -2.0, 11.0, 13.0, 8.0, -17.0, 14.0, -6.0, 10.0, -3.0, 13.0, 13.0, -11.0, 0.0, 14.0, 5.0, -1.0, -3.0, 13.0, 13.0, 1.0, -12.0, -1.0, 12.0, 11.0, -7.0, 6.0, 14.0, 10.0, -15.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 8.0, 13.0, -5.0, -1.0, 3.0, 12.0, 11.0, -11.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 5.0, 14.0, -4.0, 0.0, 14.0, -6.0, 10.0, -3.0, -3.0, 13.0, 6.0, -1.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, -11.0, 12.0, 11.0, 3.0, 14.0, -6.0, 10.0, -3.0, -11.0, 12.0, 11.0, 3.0, 0.0, 12.0, 10.0, -7.0, 11.0, 13.0, 10.0, -19.0, 14.0, -1.0, 10.0, -8.0, 4.0, 14.0, -4.0, 1.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 13.0, 14.0, 12.0, 314.0, 9.0, 12.0, 11.0, -17.0, 11.0, 13.0, 10.0, -19.0, 14.0, -1.0, 5.0, -3.0, 11.0, 12.0, 8.0, -16.0, 13.0, -6.0, 11.0, -3.0, -10.0, 14.0, -1.0, 12.0, 14.0, -6.0, 10.0, -3.0, 0.0, 12.0, -6.0, 9.0, -14.0, 6.0, 10.0, 13.0, 318.0, 13.0, 10.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, -3.0, -1.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 9.0, -15.0, 9.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 10.0, -3.0, -5.0, 13.0, 12.0, 13.0, -1.0, -9.0, 14.0, -1.0, 4.0, -2.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 14.0, 320.0, 8.0, 12.0, 2.0, -3.0, 3.0, 13.0, 13.0, 13.0, 1.0, -12.0, 11.0, -12.0, 4.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 14.0, 318.0, 9.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 12.0, -16.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, 318.0, 13.0, 10.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0, -18.0, 13.0, 9.0, 11.0, 11.0, -15.0, 7.0, 12.0, 2.0, -3.0, 3.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4857644401075784, "mean_inference_ms": 2.0079315260455197, "mean_action_processing_ms": 0.1202915378723605, "mean_env_wait_ms": 0.28311927998771774, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 262440, "agent_timesteps_total": 262359, "timers": {"learn_time_ms": 1.902, "learn_throughput": 16827.699, "update_time_ms": 4.611}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.4418840408325195, "min_q": 0.8690193891525269, "max_q": 8.643231391906738, "mean_td_error": 0.4239814877510071, "model": {}}}, "num_steps_sampled": 262440, "num_agent_steps_sampled": 262359, "num_steps_trained": 77472, "num_agent_steps_trained": 77472, "last_target_update_ts": 262440, "num_target_updates": 485}, "done": false, "episodes_total": 5130, "training_iteration": 83, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-12", "timestamp": 1626859812, "time_this_iter_s": 1.2068994045257568, "time_total_s": 93.73496198654175, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791ea60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 93.73496198654175, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 50.45, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.38, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 4.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, 12.0, -14.0, 4.0, 13.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 13.0, 14.0, -9.0, -3.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, 13.0, 9.0, -16.0, 9.0, 14.0, 14.0, -3.0, -10.0, -14.0, 9.0, 7.0, 13.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 9.0, 0.0, 7.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 10.0, -4.0, 11.0, -2.0, -1.0, -4.0, 7.0, 13.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, 12.0, -9.0, -1.0, 13.0, 14.0, 14.0, -3.0, -10.0, -1.0, 0.0, 3.0, 13.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, 12.0, -14.0, 4.0, 13.0, 14.0, 14.0, -3.0, -10.0, 0.0, -1.0, 3.0, 13.0, 14.0, 14.0, -3.0, -10.0, 12.0, -10.0, 4.0, 9.0, 14.0, 14.0, -3.0, -10.0, 14.0, -6.0, 10.0, -3.0, 13.0, 13.0, -11.0, 0.0, 14.0, 5.0, -1.0, -3.0, 13.0, 13.0, 1.0, -12.0, -1.0, 12.0, 11.0, -7.0, 6.0, 14.0, 10.0, -15.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 8.0, 13.0, -5.0, -1.0, 3.0, 12.0, 11.0, -11.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 5.0, 14.0, -4.0, 0.0, 14.0, -6.0, 10.0, -3.0, -3.0, 13.0, 6.0, -1.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, -11.0, 12.0, 11.0, 3.0, 14.0, -6.0, 10.0, -3.0, -11.0, 12.0, 11.0, 3.0, 0.0, 12.0, 10.0, -7.0, 11.0, 13.0, 10.0, -19.0, 14.0, -1.0, 10.0, -8.0, 4.0, 14.0, -4.0, 1.0, 14.0, -6.0, 10.0, -3.0, 11.0, 13.0, 10.0, -19.0, 14.0, -6.0, 10.0, -3.0, 13.0, 14.0, 12.0, 314.0, 9.0, 12.0, 11.0, -17.0, 11.0, 13.0, 10.0, -19.0, 14.0, -1.0, 5.0, -3.0, 11.0, 12.0, 8.0, -16.0, 13.0, -6.0, 11.0, -3.0, -10.0, 14.0, -1.0, 12.0, 14.0, -6.0, 10.0, -3.0, 0.0, 12.0, -6.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4913786581470637, "mean_inference_ms": 2.0220507596448174, "mean_action_processing_ms": 0.12139042043329602, "mean_env_wait_ms": 0.2858089529354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 265680, "agent_timesteps_total": 265599, "timers": {"learn_time_ms": 1.849, "learn_throughput": 17307.251, "update_time_ms": 4.349}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.127782344818115, "min_q": 1.6229339838027954, "max_q": 8.985212326049805, "mean_td_error": 0.5091816186904907, "model": {}}}, "num_steps_sampled": 265680, "num_agent_steps_sampled": 265599, "num_steps_trained": 78432, "num_agent_steps_trained": 78432, "last_target_update_ts": 265680, "num_target_updates": 491}, "done": false, "episodes_total": 5184, "training_iteration": 84, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-14", "timestamp": 1626859814, "time_this_iter_s": 1.276149034500122, "time_total_s": 95.01111102104187, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 95.01111102104187, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 46.05, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 96.35, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 24.0875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -2.0, 0.0, 10.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, 7.0, 13.0, -11.0, 6.0, 13.0, 315.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 8.0, -19.0, 13.0, 13.0, -3.0, -5.0, 11.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 3.0, -5.0, 5.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 2.0, -4.0, 5.0, 12.0, -12.0, 14.0, 5.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 7.0, -18.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 7.0, 7.0, 12.0, 316.0, 13.0, 13.0, 7.0, -4.0, 1.0, 11.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 6.0, -5.0, 13.0, 1.0, 14.0, 13.0, -20.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, 14.0, 13.0, -20.0, 8.0, 14.0, 314.0, 12.0, 13.0, 7.0, -5.0, 1.0, 12.0, 0.0, 14.0, -7.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 317.0, 13.0, 12.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -4.0, 1.0, 11.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 6.0, -10.0, 7.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 2.0, -4.0, 6.0, 11.0, -13.0, 14.0, 6.0, 8.0, 2.0, -13.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 14.0, 14.0, -3.0, -10.0, 12.0, -9.0, -1.0, 13.0, 14.0, 14.0, -3.0, -10.0, -1.0, 0.0, 3.0, 13.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, -1.0, 1.0, 6.0, 9.0, 14.0, 14.0, -3.0, -10.0, 12.0, -14.0, 4.0, 13.0, 14.0, 14.0, -3.0, -10.0, 0.0, -1.0, 3.0, 13.0, 14.0, 14.0, -3.0, -10.0, 12.0, -10.0, 4.0, 9.0, 14.0, 14.0, -3.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4885954831936798, "mean_inference_ms": 2.0141021089049036, "mean_action_processing_ms": 0.12070389469873756, "mean_env_wait_ms": 0.2845831465569502, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 268920, "agent_timesteps_total": 268839, "timers": {"learn_time_ms": 1.854, "learn_throughput": 17261.842, "update_time_ms": 4.086}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.422856330871582, "min_q": 0.8781271576881409, "max_q": 9.235875129699707, "mean_td_error": 0.22226420044898987, "model": {}}}, "num_steps_sampled": 268920, "num_agent_steps_sampled": 268839, "num_steps_trained": 79392, "num_agent_steps_trained": 79392, "last_target_update_ts": 268920, "num_target_updates": 497}, "done": false, "episodes_total": 5265, "training_iteration": 85, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-15", "timestamp": 1626859815, "time_this_iter_s": 1.1346900463104248, "time_total_s": 96.1458010673523, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 96.1458010673523, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 50.3, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 143.81, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 35.9525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [318.0, 12.0, 13.0, 11.0, 13.0, 11.0, 2.0, -11.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 13.0, -4.0, 10.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 14.0, 8.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 14.0, 8.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, -2.0, 11.0, -3.0, 9.0, -18.0, 9.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 14.0, 6.0, -2.0, -3.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 13.0, 10.0, 13.0, 14.0, 7.0, -3.0, -3.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, -2.0, 11.0, -3.0, 9.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 14.0, 11.0, -7.0, -3.0, 318.0, 12.0, 13.0, 11.0, 14.0, -3.0, -7.0, 11.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 0.0, 11.0, -5.0, 9.0, -6.0, 10.0, 13.0, -2.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 14.0, -6.0, -2.0, 9.0, -6.0, 10.0, 13.0, -2.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 6.0, -5.0, 13.0, 1.0, 14.0, 13.0, -20.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, 14.0, 13.0, -20.0, 8.0, 14.0, 314.0, 12.0, 13.0, 7.0, -5.0, 1.0, 12.0, 0.0, 14.0, -7.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 317.0, 13.0, 12.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -4.0, 1.0, 11.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 6.0, -10.0, 7.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0, 12.0, 316.0, 13.0, 13.0, 2.0, -4.0, 6.0, 11.0, -13.0, 14.0, 6.0, 8.0, 2.0, -13.0, 13.0, 13.0, 7.0, -5.0, 1.0, 12.0, -13.0, 14.0, 6.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4861548520535996, "mean_inference_ms": 2.009041734809343, "mean_action_processing_ms": 0.12034291432675631, "mean_env_wait_ms": 0.28339675599070263, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 272160, "agent_timesteps_total": 272079, "timers": {"learn_time_ms": 1.961, "learn_throughput": 16321.241, "update_time_ms": 4.822}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.188567638397217, "min_q": 0.7930037975311279, "max_q": 8.70423412322998, "mean_td_error": -9.81313705444336, "model": {}}}, "num_steps_sampled": 272160, "num_agent_steps_sampled": 272079, "num_steps_trained": 80352, "num_agent_steps_trained": 80352, "last_target_update_ts": 272160, "num_target_updates": 503}, "done": false, "episodes_total": 5319, "training_iteration": 86, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-16", "timestamp": 1626859816, "time_this_iter_s": 1.187652826309204, "time_total_s": 97.3334538936615, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 97.3334538936615, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 120.31, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 30.0775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 353.0, 15.0, 15.0, 355.0, 15.0, 15.0, 354.0, 15.0, 15.0, 355.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 13.0, 4.0, -9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -5.0, 13.0, 1.0, 6.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 6.0, 8.0, -12.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 14.0, -23.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, 2.0, 13.0, -5.0, 5.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -5.0, 14.0, 1.0, 5.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 12.0, -6.0, 10.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 14.0, -8.0, 10.0, 11.0, 12.0, 319.0, 13.0, -14.0, 13.0, 8.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -15.0, 14.0, 9.0, 7.0, 8.0, 14.0, 1.0, -8.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -1.0, 13.0, -5.0, 8.0, -1.0, 13.0, -6.0, 9.0, 13.0, 14.0, 313.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 12.0, 14.0, 315.0, 13.0, 0.0, 12.0, -5.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 320.0, 13.0, -13.0, 13.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 13.0, 0.0, -11.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, 0.0, 12.0, -5.0, 8.0, -6.0, 13.0, 1.0, 7.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, 14.0, -3.0, -7.0, 11.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 0.0, 11.0, -5.0, 9.0, -6.0, 10.0, 13.0, -2.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 14.0, -6.0, -2.0, 9.0, -6.0, 10.0, 13.0, -2.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0, 318.0, 12.0, 13.0, 11.0, 11.0, 11.0, -3.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4888386066508049, "mean_inference_ms": 2.0150369266865225, "mean_action_processing_ms": 0.12075074443327428, "mean_env_wait_ms": 0.2847566303338258, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 275400, "agent_timesteps_total": 275400, "timers": {"learn_time_ms": 1.9, "learn_throughput": 16837.832, "update_time_ms": 4.177}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.409642219543457, "min_q": 1.079221248626709, "max_q": 8.91273021697998, "mean_td_error": 1.4813141822814941, "model": {}}}, "num_steps_sampled": 275400, "num_agent_steps_sampled": 275400, "num_steps_trained": 81312, "num_agent_steps_trained": 81312, "last_target_update_ts": 275400, "num_target_updates": 509}, "done": false, "episodes_total": 5400, "training_iteration": 87, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-17", "timestamp": 1626859817, "time_this_iter_s": 1.1478166580200195, "time_total_s": 98.48127055168152, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 98.48127055168152, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 50.6, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 62.58, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 15.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 353.0, 15.0, 15.0, 355.0, 15.0, 15.0, 354.0, 15.0, 15.0, 355.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, 3.0, 13.0, -14.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, -5.0, 9.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -4.0, 14.0, -3.0, 8.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 2.0, 13.0, -11.0, 11.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 7.0, 13.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, -5.0, 9.0, 13.0, 11.0, 9.0, -11.0, 6.0, -14.0, 14.0, 7.0, 8.0, -5.0, 14.0, 1.0, 5.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 12.0, -6.0, 10.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 14.0, -8.0, 10.0, 11.0, 12.0, 319.0, 13.0, -14.0, 13.0, 8.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -15.0, 14.0, 9.0, 7.0, 8.0, 14.0, 1.0, -8.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -1.0, 13.0, -5.0, 8.0, -1.0, 13.0, -6.0, 9.0, 13.0, 14.0, 313.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 12.0, 14.0, 315.0, 13.0, 0.0, 12.0, -5.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 320.0, 13.0, -13.0, 13.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 13.0, 0.0, -11.0, 13.0, -14.0, 14.0, 7.0, 8.0, -1.0, 13.0, -6.0, 9.0, 11.0, 12.0, 319.0, 13.0, 0.0, 12.0, -5.0, 8.0, -6.0, 13.0, 1.0, 7.0, 11.0, 12.0, 319.0, 13.0, -14.0, 14.0, 7.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48644347795531007, "mean_inference_ms": 2.0101926739106446, "mean_action_processing_ms": 0.1204113811670506, "mean_env_wait_ms": 0.2836082812009078, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 278640, "agent_timesteps_total": 278559, "timers": {"learn_time_ms": 2.033, "learn_throughput": 15740.507, "update_time_ms": 4.234}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.047596454620361, "min_q": 0.6774030327796936, "max_q": 8.871733665466309, "mean_td_error": 0.664186418056488, "model": {}}}, "num_steps_sampled": 278640, "num_agent_steps_sampled": 278559, "num_steps_trained": 82272, "num_agent_steps_trained": 82272, "last_target_update_ts": 278640, "num_target_updates": 515}, "done": false, "episodes_total": 5454, "training_iteration": 88, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-19", "timestamp": 1626859819, "time_this_iter_s": 1.2064261436462402, "time_total_s": 99.68769669532776, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 99.68769669532776, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 49.6, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -9.0, 13.0, 3.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, 0.0, 13.0, -12.0, 10.0, 13.0, 0.0, -8.0, 5.0, 4.0, 13.0, -7.0, 10.0, 13.0, 8.0, -16.0, 14.0, -9.0, 8.0, 2.0, 10.0, 11.0, 8.0, -14.0, 14.0, -13.0, 13.0, 1.0, 7.0, 2.0, -6.0, 12.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 10.0, -9.0, 8.0, 6.0, 11.0, 3.0, 2.0, -1.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 13.0, 13.0, 7.0, -18.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 13.0, 5.0, 2.0, -5.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, 4.0, 8.0, -11.0, 10.0, 12.0, 7.0, -14.0, 11.0, 2.0, -6.0, 8.0, 10.0, 12.0, 7.0, -14.0, 12.0, 2.0, 8.0, -7.0, 11.0, 13.0, -12.0, 3.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 8.0, -9.0, 8.0, 8.0, 10.0, 12.0, 7.0, -14.0, 9.0, 12.0, 8.0, -14.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 3.0, 13.0, -14.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, -5.0, 9.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -4.0, 14.0, -3.0, 8.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 2.0, 13.0, -11.0, 11.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 7.0, 13.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, 9.0, -5.0, 13.0, 11.0, 9.0, -11.0, 6.0, -2.0, -5.0, 9.0, 13.0, 11.0, 9.0, -11.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49221230036971725, "mean_inference_ms": 2.0249990122022807, "mean_action_processing_ms": 0.12152533374629215, "mean_env_wait_ms": 0.2863790997854257, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 281880, "agent_timesteps_total": 281799, "timers": {"learn_time_ms": 1.969, "learn_throughput": 16251.874, "update_time_ms": 4.87}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.754427909851074, "min_q": 1.0111159086227417, "max_q": 8.740262031555176, "mean_td_error": 0.21020829677581787, "model": {}}}, "num_steps_sampled": 281880, "num_agent_steps_sampled": 281799, "num_steps_trained": 83232, "num_agent_steps_trained": 83232, "last_target_update_ts": 281880, "num_target_updates": 521}, "done": false, "episodes_total": 5508, "training_iteration": 89, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-20", "timestamp": 1626859820, "time_this_iter_s": 1.1956367492675781, "time_total_s": 100.88333344459534, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985050d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 100.88333344459534, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 50.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -5.0, 5.0, 2.0, 13.0, 13.0, 4.0, 7.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 12.0, 12.0, 10.0, -19.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -14.0, 10.0, 8.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -3.0, 1.0, 7.0, 10.0, 10.0, -2.0, -2.0, 9.0, 11.0, 10.0, 8.0, -14.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 10.0, 13.0, 10.0, -18.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 9.0, 11.0, -10.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, -7.0, -2.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, 11.0, -3.0, -6.0, 13.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, 6.0, 7.0, 3.0, -1.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 10.0, -5.0, -1.0, -9.0, 9.0, 4.0, 11.0, 5.0, 8.0, -9.0, 11.0, 9.0, 10.0, 10.0, -14.0, -10.0, 7.0, 5.0, 13.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 8.0, 7.0, 10.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 13.0, 4.0, 7.0, -9.0, 11.0, 13.0, 8.0, -17.0, -9.0, 9.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, 4.0, 9.0, 3.0, -1.0, 5.0, 8.0, 11.0, -9.0, 10.0, 12.0, 7.0, -14.0, 11.0, 2.0, -6.0, 8.0, 10.0, 12.0, 7.0, -14.0, 12.0, 2.0, 8.0, -7.0, 11.0, 13.0, -12.0, 3.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 8.0, -9.0, 8.0, 8.0, 10.0, 12.0, 7.0, -14.0, 9.0, 12.0, 8.0, -14.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0, 14.0, -9.0, 8.0, 2.0, 10.0, 12.0, 7.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4891328958622621, "mean_inference_ms": 2.016531668780707, "mean_action_processing_ms": 0.12082939373111605, "mean_env_wait_ms": 0.2849989403787036, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 285120, "agent_timesteps_total": 285066, "timers": {"learn_time_ms": 1.909, "learn_throughput": 16765.271, "update_time_ms": 4.369}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.603516101837158, "min_q": 1.0582367181777954, "max_q": 8.960000038146973, "mean_td_error": 0.03304669260978699, "model": {}}}, "num_steps_sampled": 285120, "num_agent_steps_sampled": 285066, "num_steps_trained": 84192, "num_agent_steps_trained": 84192, "last_target_update_ts": 285120, "num_target_updates": 527}, "done": false, "episodes_total": 5589, "training_iteration": 90, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-21", "timestamp": 1626859821, "time_this_iter_s": 1.2887823581695557, "time_total_s": 102.17211580276489, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 102.17211580276489, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 50.650000000000006, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-16.0, 14.0, 5.0, 12.0, 14.0, 13.0, -3.0, -9.0, -16.0, 14.0, 5.0, 12.0, 13.0, 11.0, -2.0, -7.0, -16.0, 14.0, 5.0, 12.0, 12.0, 13.0, -9.0, -1.0, -14.0, 14.0, 5.0, 10.0, 14.0, 11.0, 11.0, -21.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -11.0, 14.0, 2.0, 10.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -13.0, 13.0, 3.0, 12.0, 14.0, 11.0, -3.0, -7.0, -3.0, 0.0, 6.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -2.0, -8.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -11.0, 9.0, 10.0, 7.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 11.0, 13.0, -2.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -14.0, 14.0, 5.0, 10.0, 14.0, 11.0, -3.0, -7.0, -6.0, 14.0, 11.0, -4.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, 7.0, 13.0, -16.0, 11.0, 14.0, 11.0, -3.0, -7.0, 10.0, 0.0, -5.0, 10.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -11.0, 14.0, 5.0, 7.0, 14.0, 11.0, -16.0, 6.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, 5.0, 8.0, 11.0, -9.0, 10.0, 13.0, 10.0, -18.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 9.0, 11.0, -10.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, -7.0, -2.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, 11.0, -3.0, -6.0, 13.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, 6.0, 7.0, 3.0, -1.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 10.0, -5.0, -1.0, -9.0, 9.0, 4.0, 11.0, 5.0, 8.0, -9.0, 11.0, 9.0, 10.0, 10.0, -14.0, -10.0, 7.0, 5.0, 13.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 8.0, 7.0, 10.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 13.0, 4.0, 7.0, -9.0, 11.0, 13.0, 8.0, -17.0, -9.0, 9.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, -10.0, 10.0, 4.0, 11.0, 5.0, 8.0, 11.0, -9.0, 11.0, 13.0, 8.0, -17.0, 4.0, 9.0, 3.0, -1.0, 5.0, 8.0, 11.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4864840712125691, "mean_inference_ms": 2.01069628001906, "mean_action_processing_ms": 0.12040412213820657, "mean_env_wait_ms": 0.28363412669809973, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 288360, "agent_timesteps_total": 288279, "timers": {"learn_time_ms": 1.84, "learn_throughput": 17392.926, "update_time_ms": 4.356}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.326456546783447, "min_q": 0.9413114190101624, "max_q": 8.680285453796387, "mean_td_error": -10.135664939880371, "model": {}}}, "num_steps_sampled": 288360, "num_agent_steps_sampled": 288279, "num_steps_trained": 85152, "num_agent_steps_trained": 85152, "last_target_update_ts": 288360, "num_target_updates": 533}, "done": false, "episodes_total": 5643, "training_iteration": 91, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-22", "timestamp": 1626859822, "time_this_iter_s": 1.1112897396087646, "time_total_s": 103.28340554237366, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daa60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 103.28340554237366, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 45.85, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 14.0, 3.0, 7.0, -9.0, 4.0, 6.0, 9.0, -4.0, 14.0, 10.0, -8.0, -1.0, 13.0, 13.0, -3.0, -8.0, 14.0, 2.0, 12.0, -13.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 13.0, 9.0, -8.0, 1.0, 8.0, 5.0, 8.0, -6.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 9.0, 8.0, 7.0, -9.0, 8.0, 5.0, -3.0, 5.0, 9.0, 7.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 9.0, 7.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 4.0, 4.0, 11.0, -4.0, 14.0, 3.0, 7.0, -9.0, 8.0, 13.0, 11.0, -17.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 14.0, -10.0, 7.0, 4.0, 8.0, 5.0, -3.0, 5.0, 14.0, 7.0, -2.0, -4.0, 4.0, 9.0, 8.0, -6.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 10.0, 5.0, -7.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 13.0, 9.0, -6.0, -1.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 14.0, 3.0, 7.0, -9.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -11.0, 14.0, 2.0, 10.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -13.0, 13.0, 3.0, 12.0, 14.0, 11.0, -3.0, -7.0, -3.0, 0.0, 6.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -2.0, -8.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -11.0, 9.0, 10.0, 7.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 11.0, 13.0, -2.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -14.0, 14.0, 5.0, 10.0, 14.0, 11.0, -3.0, -7.0, -6.0, 14.0, 11.0, -4.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, 7.0, 13.0, -16.0, 11.0, 14.0, 11.0, -3.0, -7.0, 10.0, 0.0, -5.0, 10.0, 14.0, 11.0, -3.0, -7.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0, -11.0, 14.0, 5.0, 7.0, 14.0, 11.0, -16.0, 6.0, -16.0, 14.0, 5.0, 12.0, 14.0, 11.0, -3.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49199297195048325, "mean_inference_ms": 2.024475584034273, "mean_action_processing_ms": 0.12144720874621343, "mean_env_wait_ms": 0.2861920845246691, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 291600, "agent_timesteps_total": 291519, "timers": {"learn_time_ms": 1.878, "learn_throughput": 17043.305, "update_time_ms": 4.312}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.933075428009033, "min_q": 0.9520788788795471, "max_q": 9.049455642700195, "mean_td_error": -10.095138549804688, "model": {}}}, "num_steps_sampled": 291600, "num_agent_steps_sampled": 291519, "num_steps_trained": 86112, "num_agent_steps_trained": 86112, "last_target_update_ts": 291600, "num_target_updates": 539}, "done": false, "episodes_total": 5697, "training_iteration": 92, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-23", "timestamp": 1626859823, "time_this_iter_s": 1.1409292221069336, "time_total_s": 104.42433476448059, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 104.42433476448059, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 48.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 35.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 8.8475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 2.0, 7.0, -8.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, 14.0, 313.0, 12.0, 7.0, 7.0, 11.0, -10.0, -11.0, 3.0, 13.0, 10.0, 14.0, -12.0, 7.0, 6.0, 5.0, 11.0, 11.0, -12.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 12.0, 12.0, 11.0, 319.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, 321.0, 12.0, 13.0, 10.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, 3.0, -15.0, 13.0, 7.0, 7.0, 11.0, -10.0, -12.0, 8.0, 13.0, 6.0, 14.0, -12.0, 7.0, 6.0, 12.0, 12.0, 11.0, 319.0, -14.0, 8.0, 13.0, 8.0, 14.0, 8.0, -10.0, 3.0, 7.0, 7.0, 11.0, -10.0, 13.0, 6.0, 13.0, -17.0, 14.0, -13.0, 7.0, 7.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -8.0, 3.0, 13.0, 7.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, 10.0, 5.0, 13.0, -13.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 8.0, 6.0, 11.0, -10.0, -10.0, 5.0, 13.0, 7.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, 13.0, 8.0, 13.0, -19.0, 14.0, -12.0, 7.0, 6.0, 8.0, 7.0, 11.0, -11.0, -14.0, 8.0, 13.0, 8.0, 14.0, 1.0, 2.0, -2.0, 7.0, 7.0, 11.0, -10.0, 321.0, 12.0, 12.0, 11.0, 14.0, 4.0, 7.0, -10.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 8.0, 7.0, 11.0, -11.0, 321.0, 12.0, 13.0, 10.0, 14.0, -13.0, 7.0, 7.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, 9.0, -6.0, -2.0, 9.0, 10.0, 8.0, -12.0, -14.0, 8.0, 13.0, 8.0, 8.0, 5.0, -3.0, 5.0, 14.0, 7.0, -2.0, -4.0, 4.0, 9.0, 8.0, -6.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 7.0, 10.0, 5.0, -7.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 13.0, 9.0, -6.0, -1.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0, 14.0, 3.0, 7.0, -9.0, 8.0, 5.0, -3.0, 5.0, 7.0, 9.0, 7.0, -8.0, 8.0, 5.0, -3.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4892140751664311, "mean_inference_ms": 2.017063947230046, "mean_action_processing_ms": 0.12081333295253675, "mean_env_wait_ms": 0.2849760331808775, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 294840, "agent_timesteps_total": 294759, "timers": {"learn_time_ms": 1.913, "learn_throughput": 16725.784, "update_time_ms": 4.715}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.5956201553344727, "min_q": 0.8552937507629395, "max_q": 9.150134086608887, "mean_td_error": 1.067851185798645, "model": {}}}, "num_steps_sampled": 294840, "num_agent_steps_sampled": 294759, "num_steps_trained": 87072, "num_agent_steps_trained": 87072, "last_target_update_ts": 294840, "num_target_updates": 545}, "done": false, "episodes_total": 5778, "training_iteration": 93, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-25", "timestamp": 1626859825, "time_this_iter_s": 1.195202112197876, "time_total_s": 105.61953687667847, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 105.61953687667847, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.82, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 13.0, 13.0, 2.0, 14.0, 9.0, 12.0, -20.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 11.0, 4.0, -13.0, 9.0, -2.0, -5.0, 13.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 5.0, -1.0, 13.0, -2.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, -7.0, 13.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 11.0, 11.0, -20.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -2.0, 13.0, -6.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 14.0, 3.0, 12.0, -14.0, -13.0, 11.0, 13.0, 4.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -2.0, 13.0, -6.0, 13.0, 5.0, 5.0, -8.0, 3.0, -1.0, 13.0, 0.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, -14.0, 8.0, 13.0, 8.0, 14.0, 8.0, -10.0, 3.0, 7.0, 7.0, 11.0, -10.0, 13.0, 6.0, 13.0, -17.0, 14.0, -13.0, 7.0, 7.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -8.0, 3.0, 13.0, 7.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, 10.0, 5.0, 13.0, -13.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 8.0, 6.0, 11.0, -10.0, -10.0, 5.0, 13.0, 7.0, 14.0, -12.0, 7.0, 6.0, 7.0, 7.0, 11.0, -10.0, 13.0, 8.0, 13.0, -19.0, 14.0, -12.0, 7.0, 6.0, 8.0, 7.0, 11.0, -11.0, -14.0, 8.0, 13.0, 8.0, 14.0, 1.0, 2.0, -2.0, 7.0, 7.0, 11.0, -10.0, 321.0, 12.0, 12.0, 11.0, 14.0, 4.0, 7.0, -10.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, -12.0, 7.0, 6.0, 8.0, 7.0, 11.0, -11.0, 321.0, 12.0, 13.0, 10.0, 14.0, -13.0, 7.0, 7.0, 7.0, 7.0, 11.0, -10.0, -14.0, 8.0, 13.0, 8.0, 14.0, 9.0, -6.0, -2.0, 9.0, 10.0, 8.0, -12.0, -14.0, 8.0, 13.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4867789000828442, "mean_inference_ms": 2.0116444089476326, "mean_action_processing_ms": 0.12043190130872397, "mean_env_wait_ms": 0.28374936998419314, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 298080, "agent_timesteps_total": 297999, "timers": {"learn_time_ms": 1.848, "learn_throughput": 17311.492, "update_time_ms": 4.051}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.321023941040039, "min_q": 0.7043721079826355, "max_q": 8.146739959716797, "mean_td_error": -0.08100403845310211, "model": {}}}, "num_steps_sampled": 298080, "num_agent_steps_sampled": 297999, "num_steps_trained": 88032, "num_agent_steps_trained": 88032, "last_target_update_ts": 298080, "num_target_updates": 551}, "done": false, "episodes_total": 5832, "training_iteration": 94, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-26", "timestamp": 1626859826, "time_this_iter_s": 1.1576454639434814, "time_total_s": 106.77718234062195, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 106.77718234062195, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 49.75, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, -3.0, 14.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, -3.0, 14.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 0.0, 11.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 12.0, -9.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -20.0, 7.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 5.0, -1.0, 13.0, -2.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, -7.0, 13.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 11.0, 11.0, -20.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -2.0, 13.0, -6.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 14.0, 3.0, 12.0, -14.0, -13.0, 11.0, 13.0, 4.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0, 10.0, -2.0, 13.0, -6.0, 13.0, 5.0, 5.0, -8.0, 3.0, -1.0, 13.0, 0.0, 13.0, 10.0, 11.0, -19.0, 10.0, -1.0, 13.0, -7.0, 13.0, 10.0, 11.0, -19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49239043635197605, "mean_inference_ms": 2.025304712646528, "mean_action_processing_ms": 0.12148605178998605, "mean_env_wait_ms": 0.28635278182058527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 301320, "agent_timesteps_total": 301239, "timers": {"learn_time_ms": 1.819, "learn_throughput": 17590.329, "update_time_ms": 4.044}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.221081733703613, "min_q": 0.8270966410636902, "max_q": 9.079983711242676, "mean_td_error": -10.26720905303955, "model": {}}}, "num_steps_sampled": 301320, "num_agent_steps_sampled": 301239, "num_steps_trained": 88992, "num_agent_steps_trained": 88992, "last_target_update_ts": 301320, "num_target_updates": 557}, "done": false, "episodes_total": 5886, "training_iteration": 95, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-27", "timestamp": 1626859827, "time_this_iter_s": 1.1296443939208984, "time_total_s": 107.90682673454285, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 107.90682673454285, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 52.25, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 2.0, -8.0, 8.0, 12.0, 12.0, -4.0, -5.0, -12.0, 7.0, 10.0, 10.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, -8.0, 5.0, 9.0, 9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 11.0, 2.0, 10.0, -8.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 8.0, 4.0, -7.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 8.0, 4.0, -7.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 11.0, 8.0, -14.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, -5.0, 6.0, 9.0, 5.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 11.0, -14.0, 5.0, 12.0, 13.0, -1.0, -9.0, -2.0, -6.0, 12.0, 11.0, 13.0, 6.0, -12.0, 8.0, 12.0, 13.0, -1.0, -9.0, -11.0, 5.0, 9.0, 12.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 0.0, 12.0, -1.0, 4.0, 13.0, 9.0, -14.0, 7.0, 10.0, 13.0, -1.0, -7.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, -3.0, 0.0, 5.0, -2.0, 13.0, 12.0, -8.0, 13.0, 12.0, -1.0, -9.0, 8.0, 9.0, -12.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -15.0, 8.0, 12.0, 13.0, 12.0, 315.0, 13.0, 12.0, -1.0, -9.0, 8.0, 8.0, -11.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -14.0, 4.0, 13.0, 9.0, -12.0, 5.0, 12.0, 10.0, -6.0, -1.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -20.0, 7.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0, 4.0, 7.0, -4.0, 8.0, 14.0, 14.0, -19.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48931796871597444, "mean_inference_ms": 2.0170812879015307, "mean_action_processing_ms": 0.12080017861636193, "mean_env_wait_ms": 0.2849560425617453, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 304560, "agent_timesteps_total": 304479, "timers": {"learn_time_ms": 1.855, "learn_throughput": 17255.185, "update_time_ms": 4.572}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.072906494140625, "min_q": 0.9947325587272644, "max_q": 8.929309844970703, "mean_td_error": 1.2226142883300781, "model": {}}}, "num_steps_sampled": 304560, "num_agent_steps_sampled": 304479, "num_steps_trained": 89952, "num_agent_steps_trained": 89952, "last_target_update_ts": 304560, "num_target_updates": 563}, "done": false, "episodes_total": 5967, "training_iteration": 96, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-28", "timestamp": 1626859828, "time_this_iter_s": 1.1325442790985107, "time_total_s": 109.03937101364136, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 109.03937101364136, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 49.4, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 96.34, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 24.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 15.0, 354.0, 15.0, 354.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-18.0, 14.0, 8.0, 11.0, 319.0, 14.0, 10.0, 11.0, -19.0, 14.0, 10.0, 10.0, 319.0, 14.0, 9.0, 12.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 11.0, 10.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, -17.0, 14.0, 11.0, 7.0, 319.0, 14.0, 10.0, 11.0, -14.0, 9.0, 8.0, 12.0, 319.0, 14.0, 11.0, 10.0, 319.0, 14.0, 10.0, 11.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 11.0, 2.0, 10.0, -8.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 8.0, 4.0, -7.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 8.0, 4.0, -7.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 11.0, 8.0, -14.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, -5.0, 6.0, 9.0, 5.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 11.0, -14.0, 5.0, 12.0, 13.0, -1.0, -9.0, -2.0, -6.0, 12.0, 11.0, 13.0, 6.0, -12.0, 8.0, 12.0, 13.0, -1.0, -9.0, -11.0, 5.0, 9.0, 12.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 0.0, 12.0, -1.0, 4.0, 13.0, 9.0, -14.0, 7.0, 10.0, 13.0, -1.0, -7.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, -3.0, 0.0, 5.0, -2.0, 13.0, 12.0, -8.0, 13.0, 12.0, -1.0, -9.0, 8.0, 9.0, -12.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -15.0, 8.0, 12.0, 13.0, 12.0, 315.0, 13.0, 12.0, -1.0, -9.0, 8.0, 8.0, -11.0, 10.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -14.0, 4.0, 13.0, 9.0, -12.0, 5.0, 12.0, 10.0, -6.0, -1.0, 13.0, 12.0, -1.0, -9.0, 13.0, 9.0, -12.0, 5.0, 12.0, 13.0, -1.0, -9.0, 13.0, 12.0, -1.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4921215103972338, "mean_inference_ms": 2.0251206676395244, "mean_action_processing_ms": 0.12148684966859166, "mean_env_wait_ms": 0.28616867035201343, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 306720, "agent_timesteps_total": 306639, "timers": {"learn_time_ms": 1.973, "learn_throughput": 16218.293, "update_time_ms": 5.889}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.867234230041504, "min_q": 0.8076613545417786, "max_q": 9.011120796203613, "mean_td_error": 0.46449193358421326, "model": {}}}, "num_steps_sampled": 306720, "num_agent_steps_sampled": 306639, "num_steps_trained": 90592, "num_agent_steps_trained": 90592, "last_target_update_ts": 306720, "num_target_updates": 567}, "done": false, "episodes_total": 5994, "training_iteration": 97, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-29", "timestamp": 1626859829, "time_this_iter_s": 0.965827226638794, "time_total_s": 110.00519824028015, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e6a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 110.00519824028015, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 46.25, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 79.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 19.8475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 15.0, 354.0, 15.0, 354.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 316.0, 13.0, 13.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -6.0, 13.0, 13.0, -5.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -13.0, 11.0, 13.0, 4.0, -17.0, 8.0, 11.0, 13.0, 7.0, 0.0, 9.0, -1.0, -5.0, 13.0, 13.0, -6.0, -15.0, 13.0, 5.0, 12.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 7.0, 0.0, 9.0, -1.0, -5.0, 13.0, 13.0, -6.0, -19.0, 10.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 5.0, 0.0, 8.0, 2.0, -8.0, 13.0, 13.0, -3.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, 4.0, -14.0, 12.0, 13.0, 12.0, -20.0, 11.0, 12.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -19.0, 10.0, 11.0, 13.0, 4.0, 0.0, 9.0, 2.0, -5.0, 13.0, 13.0, -6.0, -19.0, 10.0, 11.0, 13.0, 11.0, -21.0, 12.0, 13.0, -6.0, 13.0, 13.0, -5.0, -17.0, 8.0, 11.0, 13.0, 11.0, -22.0, 13.0, 13.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 7.0, 0.0, 9.0, -1.0, -4.0, 13.0, 13.0, -7.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -14.0, 11.0, 6.0, 12.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 13.0, -10.0, 13.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -4.0, 13.0, 13.0, -7.0, -20.0, 9.0, 13.0, 13.0, 6.0, 0.0, 10.0, -1.0, -6.0, 12.0, 13.0, -4.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, 316.0, 12.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -21.0, 11.0, 12.0, 13.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -5.0, -4.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 11.0, 10.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, 319.0, 14.0, 10.0, 11.0, -17.0, 14.0, 11.0, 7.0, 319.0, 14.0, 10.0, 11.0, -14.0, 9.0, 8.0, 12.0, 319.0, 14.0, 11.0, 10.0, 319.0, 14.0, 10.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4927873047459547, "mean_inference_ms": 2.0254057042201707, "mean_action_processing_ms": 0.12154245132428915, "mean_env_wait_ms": 0.2866099966406856, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 309960, "agent_timesteps_total": 309879, "timers": {"learn_time_ms": 1.897, "learn_throughput": 16865.337, "update_time_ms": 4.78}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.7100625038146973, "min_q": 0.955452024936676, "max_q": 8.911467552185059, "mean_td_error": -10.16958236694336, "model": {}}}, "num_steps_sampled": 309960, "num_agent_steps_sampled": 309879, "num_steps_trained": 91552, "num_agent_steps_trained": 91552, "last_target_update_ts": 309960, "num_target_updates": 573}, "done": false, "episodes_total": 6075, "training_iteration": 98, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-30", "timestamp": 1626859830, "time_this_iter_s": 1.1188545227050781, "time_total_s": 111.12405276298523, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 111.12405276298523, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 49.3, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 92.7, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 23.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 353.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 14.0, 14.0, 314.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, 11.0, 316.0, 13.0, 13.0, 13.0, 14.0, 316.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -3.0, -6.0, 12.0, 12.0, 12.0, 14.0, -3.0, -8.0, -3.0, -6.0, 12.0, 12.0, 12.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 13.0, 10.0, -21.0, -2.0, -8.0, 12.0, 13.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -7.0, -2.0, 12.0, 12.0, 12.0, 14.0, -4.0, -7.0, -3.0, -6.0, 12.0, 12.0, 13.0, 13.0, -8.0, -3.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -1.0, -7.0, 12.0, 11.0, 13.0, 14.0, 315.0, 11.0, -7.0, -2.0, 12.0, 12.0, 13.0, 13.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -4.0, -6.0, 12.0, 13.0, 13.0, 14.0, 315.0, 11.0, -11.0, 2.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 13.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 12.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -5.0, 11.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 11.0, 9.0, -10.0, 5.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -19.0, 10.0, 11.0, 13.0, 4.0, 0.0, 9.0, 2.0, -5.0, 13.0, 13.0, -6.0, -19.0, 10.0, 11.0, 13.0, 11.0, -21.0, 12.0, 13.0, -6.0, 13.0, 13.0, -5.0, -17.0, 8.0, 11.0, 13.0, 11.0, -22.0, 13.0, 13.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 7.0, 0.0, 9.0, -1.0, -4.0, 13.0, 13.0, -7.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -14.0, 11.0, 6.0, 12.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 13.0, -10.0, 13.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -4.0, 13.0, 13.0, -7.0, -20.0, 9.0, 13.0, 13.0, 6.0, 0.0, 10.0, -1.0, -6.0, 12.0, 13.0, -4.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, 316.0, 12.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -21.0, 11.0, 12.0, 13.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -5.0, -4.0, 11.0, 13.0, 6.0, 0.0, 10.0, -1.0, -5.0, 13.0, 13.0, -6.0, -17.0, 8.0, 11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48664174971467405, "mean_inference_ms": 2.0105826909106743, "mean_action_processing_ms": 0.12037760717251432, "mean_env_wait_ms": 0.2837429499903628, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 313200, "agent_timesteps_total": 313119, "timers": {"learn_time_ms": 1.93, "learn_throughput": 16576.229, "update_time_ms": 4.216}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.590182304382324, "min_q": 0.7907019257545471, "max_q": 9.119600296020508, "mean_td_error": 0.25072601437568665, "model": {}}}, "num_steps_sampled": 313200, "num_agent_steps_sampled": 313119, "num_steps_trained": 92512, "num_agent_steps_trained": 92512, "last_target_update_ts": 313200, "num_target_updates": 579}, "done": false, "episodes_total": 6129, "training_iteration": 99, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-32", "timestamp": 1626859832, "time_this_iter_s": 1.1052815914154053, "time_total_s": 112.22933435440063, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 112.22933435440063, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 50.25, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 147.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 36.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 6.0, 6.0, -5.0, 319.0, 11.0, 13.0, 11.0, 9.0, 9.0, 3.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 9.0, -7.0, 4.0, 12.0, -3.0, -4.0, 10.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 8.0, 8.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 6.0, 5.0, -5.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, -14.0, 11.0, 8.0, 10.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, -6.0, 7.0, 4.0, 10.0, 9.0, 10.0, 0.0, -4.0, 13.0, 7.0, 8.0, -13.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, -6.0, 10.0, 0.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 12.0, -1.0, -5.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 320.0, 12.0, 13.0, 9.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 3.0, 13.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -3.0, -6.0, 12.0, 12.0, 12.0, 14.0, -3.0, -8.0, -3.0, -6.0, 12.0, 12.0, 12.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 13.0, 10.0, -21.0, -2.0, -8.0, 12.0, 13.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -7.0, -2.0, 12.0, 12.0, 12.0, 14.0, -4.0, -7.0, -3.0, -6.0, 12.0, 12.0, 13.0, 13.0, -8.0, -3.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -1.0, -7.0, 12.0, 11.0, 13.0, 14.0, 315.0, 11.0, -7.0, -2.0, 12.0, 12.0, 13.0, 13.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -4.0, -6.0, 12.0, 13.0, 13.0, 14.0, 315.0, 11.0, -11.0, 2.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 13.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 12.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -5.0, 11.0, 12.0, 13.0, 14.0, 315.0, 11.0, -3.0, -6.0, 12.0, 12.0, 11.0, 9.0, -10.0, 5.0, -3.0, -6.0, 12.0, 12.0, 13.0, 14.0, 315.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49210782748877385, "mean_inference_ms": 2.0242789291869485, "mean_action_processing_ms": 0.12140601741292813, "mean_env_wait_ms": 0.2863082884457229, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 316440, "agent_timesteps_total": 316359, "timers": {"learn_time_ms": 1.863, "learn_throughput": 17181.189, "update_time_ms": 4.383}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.082332611083984, "min_q": 0.7535994648933411, "max_q": 9.040923118591309, "mean_td_error": 0.002576693892478943, "model": {}}}, "num_steps_sampled": 316440, "num_agent_steps_sampled": 316359, "num_steps_trained": 93472, "num_agent_steps_trained": 93472, "last_target_update_ts": 316440, "num_target_updates": 585}, "done": false, "episodes_total": 6183, "training_iteration": 100, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-33", "timestamp": 1626859833, "time_this_iter_s": 1.1885707378387451, "time_total_s": 113.41790509223938, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 113.41790509223938, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 50.8, "ram_util_percent": 14.149999999999999}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 136.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -14.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 34.1925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 353.0, 15.0, 353.0, 353.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -4.0, 12.0, -2.0, 3.0, 10.0, 4.0, -2.0, -14.0, 13.0, 9.0, 7.0, -1.0, 11.0, -1.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, 13.0, 315.0, 13.0, 12.0, -5.0, 1.0, 7.0, 12.0, 315.0, 14.0, 12.0, 12.0, 12.0, 316.0, 13.0, 12.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 13.0, 13.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, 12.0, 0.0, 10.0, -7.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, -10.0, 10.0, 4.0, 11.0, -14.0, 13.0, 9.0, 7.0, -13.0, 11.0, 11.0, 6.0, 10.0, -1.0, -6.0, 12.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -14.0, 11.0, 12.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 13.0, 13.0, 12.0, -13.0, 11.0, 11.0, 6.0, -10.0, 10.0, 4.0, 11.0, 315.0, 13.0, 13.0, 12.0, -13.0, 11.0, 11.0, 6.0, -8.0, 6.0, 8.0, 9.0, 315.0, 14.0, 12.0, 12.0, -9.0, 9.0, 9.0, 6.0, -13.0, 9.0, 7.0, 12.0, 315.0, 14.0, 12.0, 12.0, -12.0, 13.0, 8.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -8.0, 6.0, 11.0, 6.0, 8.0, 12.0, 8.0, -13.0, 317.0, 14.0, 12.0, 11.0, -14.0, 13.0, 11.0, 5.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -1.0, 13.0, 3.0, 0.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -12.0, 13.0, 10.0, 4.0, 3.0, 10.0, 4.0, -2.0, 315.0, 13.0, 13.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -12.0, 11.0, 10.0, 6.0, 3.0, 10.0, 4.0, -2.0, 316.0, 14.0, 12.0, 10.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, -6.0, 10.0, 0.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 12.0, -1.0, -5.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 9.0, 7.0, 5.0, -6.0, 320.0, 12.0, 13.0, 9.0, 9.0, 7.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0, 3.0, 13.0, 5.0, -6.0, 319.0, 11.0, 13.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48902790078695624, "mean_inference_ms": 2.0160272486513757, "mean_action_processing_ms": 0.12071560735347933, "mean_env_wait_ms": 0.28495314253781406, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 319680, "agent_timesteps_total": 319599, "timers": {"learn_time_ms": 1.982, "learn_throughput": 16144.94, "update_time_ms": 4.474}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.266986846923828, "min_q": 0.8682770729064941, "max_q": 9.235261917114258, "mean_td_error": -10.198186874389648, "model": {}}}, "num_steps_sampled": 319680, "num_agent_steps_sampled": 319599, "num_steps_trained": 94432, "num_agent_steps_trained": 94432, "last_target_update_ts": 319680, "num_target_updates": 591}, "done": false, "episodes_total": 6264, "training_iteration": 101, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-34", "timestamp": 1626859834, "time_this_iter_s": 1.167351484298706, "time_total_s": 114.58525657653809, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 114.58525657653809, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 50.599999999999994, "ram_util_percent": 14.149999999999999}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 217.81, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 54.4525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.0, 15.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 15.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 354.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 12.0, 315.0, 13.0, 10.0, 10.0, 12.0, -17.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 10.0, 12.0, -20.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 12.0, 316.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 8.0, -18.0, 7.0, 10.0, -15.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 6.0, 11.0, -15.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 11.0, 317.0, 13.0, 12.0, 13.0, 13.0, 315.0, 6.0, 11.0, -15.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 10.0, -20.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, -1.0, 11.0, 1.0, 4.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 0.0, -10.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 10.0, -20.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -14.0, 11.0, 12.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 13.0, 13.0, 12.0, -13.0, 11.0, 11.0, 6.0, -10.0, 10.0, 4.0, 11.0, 315.0, 13.0, 13.0, 12.0, -13.0, 11.0, 11.0, 6.0, -8.0, 6.0, 8.0, 9.0, 315.0, 14.0, 12.0, 12.0, -9.0, 9.0, 9.0, 6.0, -13.0, 9.0, 7.0, 12.0, 315.0, 14.0, 12.0, 12.0, -12.0, 13.0, 8.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -8.0, 6.0, 11.0, 6.0, 8.0, 12.0, 8.0, -13.0, 317.0, 14.0, 12.0, 11.0, -14.0, 13.0, 11.0, 5.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -1.0, 13.0, 3.0, 0.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -12.0, 13.0, 10.0, 4.0, 3.0, 10.0, 4.0, -2.0, 315.0, 13.0, 13.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0, -12.0, 11.0, 10.0, 6.0, 3.0, 10.0, 4.0, -2.0, 316.0, 14.0, 12.0, 10.0, -13.0, 11.0, 11.0, 6.0, 3.0, 10.0, 4.0, -2.0, 315.0, 14.0, 12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48658455296004655, "mean_inference_ms": 2.010908112235424, "mean_action_processing_ms": 0.12037343385756444, "mean_env_wait_ms": 0.2837696321846952, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 322920, "agent_timesteps_total": 322839, "timers": {"learn_time_ms": 2.056, "learn_throughput": 15566.168, "update_time_ms": 5.53}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.744065761566162, "min_q": 0.8332951068878174, "max_q": 8.998991966247559, "mean_td_error": -9.93519401550293, "model": {}}}, "num_steps_sampled": 322920, "num_agent_steps_sampled": 322839, "num_steps_trained": 95392, "num_agent_steps_trained": 95392, "last_target_update_ts": 322920, "num_target_updates": 597}, "done": false, "episodes_total": 6318, "training_iteration": 102, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-35", "timestamp": 1626859835, "time_this_iter_s": 1.1874845027923584, "time_total_s": 115.77274107933044, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 115.77274107933044, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 143.45, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 35.8625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 354.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -8.0, 8.0, 2.0, 12.0, -10.0, 0.0, 13.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -4.0, 12.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -3.0, -2.0, 7.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -12.0, 8.0, 6.0, 13.0, 7.0, -16.0, 11.0, -2.0, 2.0, 3.0, 12.0, 14.0, -2.0, -2.0, 5.0, 14.0, -8.0, 7.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -12.0, 8.0, 6.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, 8.0, -1.0, -5.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 14.0, -15.0, 7.0, 9.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -7.0, 11.0, -2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -2.0, -2.0, 6.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 12.0, -10.0, 7.0, 6.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 12.0, -8.0, 6.0, 5.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 8.0, -18.0, 7.0, 10.0, -15.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 6.0, 11.0, -15.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 11.0, 317.0, 13.0, 12.0, 13.0, 13.0, 315.0, 6.0, 11.0, -15.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 10.0, -20.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, -1.0, 11.0, 1.0, 4.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 0.0, -10.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 10.0, -20.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0, 13.0, 12.0, 315.0, 13.0, 12.0, 13.0, 13.0, 315.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49219595810256744, "mean_inference_ms": 2.025107688206257, "mean_action_processing_ms": 0.12143217586994058, "mean_env_wait_ms": 0.28645543694658415, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 326160, "agent_timesteps_total": 326079, "timers": {"learn_time_ms": 1.864, "learn_throughput": 17164.929, "update_time_ms": 4.889}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.836938381195068, "min_q": 0.884649395942688, "max_q": 9.427603721618652, "mean_td_error": -31.16230583190918, "model": {}}}, "num_steps_sampled": 326160, "num_agent_steps_sampled": 326079, "num_steps_trained": 96352, "num_agent_steps_trained": 96352, "last_target_update_ts": 326160, "num_target_updates": 603}, "done": false, "episodes_total": 6372, "training_iteration": 103, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-37", "timestamp": 1626859837, "time_this_iter_s": 1.1474676132202148, "time_total_s": 116.92020869255066, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 116.92020869255066, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 50.849999999999994, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 316.0, 14.0, 13.0, 9.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 13.0, -5.0, -6.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, -1.0, 11.0, -4.0, 9.0, 11.0, 12.0, -2.0, -6.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -12.0, 3.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 5.0, 9.0, -8.0, 9.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 10.0, 13.0, 13.0, -21.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, -1.0, 12.0, 13.0, -9.0, 4.0, 2.0, -2.0, 11.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 10.0, -16.0, 8.0, 10.0, 12.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 5.0, 13.0, -12.0, 4.0, 2.0, -2.0, 11.0, 13.0, 11.0, -17.0, 8.0, 10.0, 12.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 5.0, -12.0, 9.0, 1.0, 11.0, 13.0, -10.0, -1.0, 10.0, -5.0, 11.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 12.0, 9.0, 12.0, -18.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, -1.0, 9.0, -4.0, 11.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 6.0, -15.0, 11.0, 9.0, 13.0, 13.0, -20.0, 4.0, 2.0, -2.0, 11.0, 13.0, 14.0, -17.0, 5.0, 1.0, 11.0, 13.0, -10.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -2.0, -2.0, 6.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 12.0, -10.0, 7.0, 6.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0, 12.0, -8.0, 6.0, 5.0, 13.0, -6.0, -3.0, 11.0, 13.0, -8.0, 8.0, 2.0, 13.0, -6.0, -3.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48931078588744115, "mean_inference_ms": 2.016945339186116, "mean_action_processing_ms": 0.12076205826610803, "mean_env_wait_ms": 0.2851819139916998, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 329400, "agent_timesteps_total": 329319, "timers": {"learn_time_ms": 1.903, "learn_throughput": 16811.469, "update_time_ms": 4.829}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.596373081207275, "min_q": 0.9291756749153137, "max_q": 9.063106536865234, "mean_td_error": -10.085823059082031, "model": {}}}, "num_steps_sampled": 329400, "num_agent_steps_sampled": 329319, "num_steps_trained": 97312, "num_agent_steps_trained": 97312, "last_target_update_ts": 329400, "num_target_updates": 609}, "done": false, "episodes_total": 6453, "training_iteration": 104, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-38", "timestamp": 1626859838, "time_this_iter_s": 1.3102014064788818, "time_total_s": 118.23041009902954, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 118.23041009902954, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 44.65, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -1.0, -9.0, 13.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 1.0, -12.0, 13.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 10.0, -15.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 14.0, 10.0, -21.0, 12.0, 13.0, 1.0, -12.0, 13.0, 14.0, 10.0, -21.0, 12.0, 13.0, 11.0, -16.0, 7.0, -2.0, 13.0, -7.0, 11.0, 14.0, -17.0, 5.0, 13.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 9.0, 10.0, -16.0, 12.0, 13.0, 5.0, 8.0, -11.0, 10.0, -12.0, 6.0, 11.0, 13.0, 11.0, -16.0, 7.0, 319.0, 13.0, 10.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 2.0, -7.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 6.0, -16.0, 12.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 317.0, 14.0, 10.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 9.0, 10.0, -16.0, 12.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 10.0, -16.0, 8.0, 10.0, 12.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 5.0, 13.0, -12.0, 4.0, 2.0, -2.0, 11.0, 13.0, 11.0, -17.0, 8.0, 10.0, 12.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 5.0, -12.0, 9.0, 1.0, 11.0, 13.0, -10.0, -1.0, 10.0, -5.0, 11.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 12.0, 9.0, 12.0, -18.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, -1.0, 9.0, -4.0, 11.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 6.0, -15.0, 11.0, 9.0, 13.0, 13.0, -20.0, 4.0, 2.0, -2.0, 11.0, 13.0, 14.0, -17.0, 5.0, 1.0, 11.0, 13.0, -10.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0, 9.0, 13.0, 13.0, -20.0, 4.0, 9.0, -4.0, 6.0, 13.0, 11.0, -17.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48671433560320176, "mean_inference_ms": 2.011361419313253, "mean_action_processing_ms": 0.12037757490058047, "mean_env_wait_ms": 0.2839271638242177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 332640, "agent_timesteps_total": 332559, "timers": {"learn_time_ms": 1.943, "learn_throughput": 16469.039, "update_time_ms": 5.152}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.319221019744873, "min_q": 0.9001530408859253, "max_q": 9.073419570922852, "mean_td_error": 0.21018944680690765, "model": {}}}, "num_steps_sampled": 332640, "num_agent_steps_sampled": 332559, "num_steps_trained": 98272, "num_agent_steps_trained": 98272, "last_target_update_ts": 332640, "num_target_updates": 615}, "done": false, "episodes_total": 6507, "training_iteration": 105, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-39", "timestamp": 1626859839, "time_this_iter_s": 1.1307291984558105, "time_total_s": 119.36113929748535, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 119.36113929748535, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 50.75, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 109.65, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 27.4125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 354.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 14.0, 10.0, 315.0, 13.0, 4.0, 5.0, -7.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 13.0, 14.0, 10.0, 317.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 7.0, 11.0, -16.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 1.0, -13.0, 14.0, 14.0, 10.0, 315.0, 13.0, 4.0, 8.0, -10.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 8.0, -20.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 13.0, 14.0, 10.0, 315.0, 13.0, 7.0, 11.0, -16.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 14.0, 14.0, -13.0, 0.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 9.0, 8.0, -15.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, -1.0, -5.0, 12.0, 9.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 10.0, -15.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 14.0, 10.0, -21.0, 12.0, 13.0, 1.0, -12.0, 13.0, 14.0, 10.0, -21.0, 12.0, 13.0, 11.0, -16.0, 7.0, -2.0, 13.0, -7.0, 11.0, 14.0, -17.0, 5.0, 13.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 9.0, 10.0, -16.0, 12.0, 13.0, 5.0, 8.0, -11.0, 10.0, -12.0, 6.0, 11.0, 13.0, 11.0, -16.0, 7.0, 319.0, 13.0, 10.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 2.0, -7.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 6.0, -16.0, 12.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 317.0, 14.0, 10.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 11.0, -16.0, 7.0, 9.0, 10.0, -16.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4922430412032718, "mean_inference_ms": 2.0252695103319085, "mean_action_processing_ms": 0.12142816092630791, "mean_env_wait_ms": 0.28652192794651227, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 335880, "agent_timesteps_total": 335799, "timers": {"learn_time_ms": 1.894, "learn_throughput": 16893.996, "update_time_ms": 5.007}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.272002696990967, "min_q": 0.9134619235992432, "max_q": 8.866008758544922, "mean_td_error": 0.05983702838420868, "model": {}}}, "num_steps_sampled": 335880, "num_agent_steps_sampled": 335799, "num_steps_trained": 99232, "num_agent_steps_trained": 99232, "last_target_update_ts": 335880, "num_target_updates": 621}, "done": false, "episodes_total": 6561, "training_iteration": 106, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-40", "timestamp": 1626859840, "time_this_iter_s": 1.1574673652648926, "time_total_s": 120.51860666275024, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985051e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 120.51860666275024, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 45.45, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 11.3625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -22.0, 11.0, 13.0, 3.0, 4.0, 10.0, -2.0, -11.0, 11.0, 3.0, 12.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, -1.0, 13.0, 8.0, -5.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, -13.0, 13.0, 3.0, 12.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, -12.0, 13.0, 2.0, 12.0, 6.0, -7.0, 12.0, 4.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 8.0, 6.0, 5.0, -4.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, -5.0, -3.0, 10.0, 13.0, -5.0, 12.0, 10.0, -2.0, -10.0, 8.0, 11.0, 6.0, 13.0, -22.0, 11.0, 13.0, 4.0, 1.0, 12.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 9.0, -9.0, 10.0, 5.0, 3.0, -12.0, 12.0, 12.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 8.0, -6.0, 9.0, -9.0, 10.0, 5.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, -12.0, 13.0, 2.0, 12.0, 13.0, -22.0, 11.0, 13.0, 13.0, 12.0, 12.0, 319.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, 2.0, 2.0, 12.0, -1.0, -11.0, 11.0, 3.0, 12.0, 13.0, -22.0, 11.0, 13.0, 4.0, -12.0, 11.0, 12.0, 0.0, 13.0, 6.0, -4.0, 1.0, -4.0, 12.0, 6.0, -5.0, 12.0, 10.0, -2.0, -13.0, 11.0, 6.0, 11.0, 8.0, -9.0, 8.0, 8.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 2.0, -2.0, 3.0, 12.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, -4.0, 13.0, 6.0, 0.0, 4.0, -3.0, 10.0, 4.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 14.0, 14.0, -13.0, 0.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 9.0, 8.0, -15.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0, -1.0, -5.0, 12.0, 9.0, 13.0, 14.0, 0.0, -12.0, 14.0, 14.0, 10.0, 315.0, 13.0, 14.0, 0.0, -12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4892725312100964, "mean_inference_ms": 2.0172258802829894, "mean_action_processing_ms": 0.12077336784226275, "mean_env_wait_ms": 0.2851900268038397, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 339120, "agent_timesteps_total": 339039, "timers": {"learn_time_ms": 1.92, "learn_throughput": 16669.489, "update_time_ms": 4.201}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.353185176849365, "min_q": 1.0408103466033936, "max_q": 8.60977840423584, "mean_td_error": 0.10479418188333511, "model": {}}}, "num_steps_sampled": 339120, "num_agent_steps_sampled": 339039, "num_steps_trained": 100192, "num_agent_steps_trained": 100192, "last_target_update_ts": 339120, "num_target_updates": 627}, "done": false, "episodes_total": 6642, "training_iteration": 107, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-41", "timestamp": 1626859841, "time_this_iter_s": 1.1279122829437256, "time_total_s": 121.64651894569397, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 121.64651894569397, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 50.599999999999994, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.41, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.6025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 11.0, -11.0, 1.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, 7.0, 6.0, 13.0, -11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -1.0, 8.0, 11.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -14.0, 6.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -4.0, 9.0, 13.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 14.0, 12.0, -5.0, -6.0, -16.0, 8.0, 12.0, 11.0, 14.0, 11.0, -10.0, 0.0, 13.0, -3.0, 9.0, -4.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, 13.0, -15.0, 11.0, 6.0, 10.0, 11.0, -11.0, 5.0, -5.0, 10.0, 13.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -1.0, 8.0, 11.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -17.0, 9.0, 12.0, 11.0, -4.0, 11.0, 1.0, 7.0, -4.0, -4.0, 13.0, 10.0, 14.0, -3.0, -5.0, 9.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 14.0, 12.0, 9.0, -20.0, 8.0, 0.0, 10.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -6.0, 10.0, 13.0, -2.0, 10.0, 11.0, -11.0, 5.0, -4.0, -5.0, 13.0, 11.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 8.0, -6.0, 9.0, -9.0, 10.0, 5.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, -12.0, 13.0, 2.0, 12.0, 13.0, -22.0, 11.0, 13.0, 13.0, 12.0, 12.0, 319.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, 2.0, 2.0, 12.0, -1.0, -11.0, 11.0, 3.0, 12.0, 13.0, -22.0, 11.0, 13.0, 4.0, -12.0, 11.0, 12.0, 0.0, 13.0, 6.0, -4.0, 1.0, -4.0, 12.0, 6.0, -5.0, 12.0, 10.0, -2.0, -13.0, 11.0, 6.0, 11.0, 8.0, -9.0, 8.0, 8.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, 2.0, -2.0, 3.0, 12.0, 13.0, -22.0, 11.0, 13.0, -5.0, 12.0, 10.0, -2.0, -4.0, 13.0, 6.0, 0.0, 4.0, -3.0, 10.0, 4.0, -5.0, 12.0, 10.0, -2.0, 0.0, 13.0, 6.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4866516731403675, "mean_inference_ms": 2.01156573410428, "mean_action_processing_ms": 0.12038384983351827, "mean_env_wait_ms": 0.2839265874727228, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 342360, "agent_timesteps_total": 342279, "timers": {"learn_time_ms": 1.821, "learn_throughput": 17576.278, "update_time_ms": 4.502}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.106635093688965, "min_q": 1.0751824378967285, "max_q": 8.844830513000488, "mean_td_error": -8.896873474121094, "model": {}}}, "num_steps_sampled": 342360, "num_agent_steps_sampled": 342279, "num_steps_trained": 101152, "num_agent_steps_trained": 101152, "last_target_update_ts": 342360, "num_target_updates": 633}, "done": false, "episodes_total": 6696, "training_iteration": 108, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-43", "timestamp": 1626859843, "time_this_iter_s": 1.127366065979004, "time_total_s": 122.77388501167297, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 122.77388501167297, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 5.0, -7.0, 5.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 5.0, -2.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 11.0, 7.0, -10.0, 7.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 13.0, 6.0, 3.0, -7.0, 12.0, 10.0, -7.0, 0.0, 9.0, 7.0, -9.0, 8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 6.0, -2.0, -1.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 5.0, -2.0, 0.0, 8.0, 8.0, 7.0, -8.0, 11.0, 2.0, -5.0, 7.0, 9.0, 7.0, -9.0, 8.0, 12.0, 10.0, -7.0, 0.0, 14.0, 7.0, -12.0, 6.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -14.0, 6.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -4.0, 9.0, 13.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 14.0, 12.0, -5.0, -6.0, -16.0, 8.0, 12.0, 11.0, 14.0, 11.0, -10.0, 0.0, 13.0, -3.0, 9.0, -4.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, 13.0, -15.0, 11.0, 6.0, 10.0, 11.0, -11.0, 5.0, -5.0, 10.0, 13.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -1.0, 8.0, 11.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -17.0, 9.0, 12.0, 11.0, -4.0, 11.0, 1.0, 7.0, -4.0, -4.0, 13.0, 10.0, 14.0, -3.0, -5.0, 9.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 14.0, 12.0, 9.0, -20.0, 8.0, 0.0, 10.0, -3.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -16.0, 8.0, 12.0, 11.0, 10.0, 11.0, -11.0, 5.0, -6.0, 10.0, 13.0, -2.0, 10.0, 11.0, -11.0, 5.0, -4.0, -5.0, 13.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4921432576134079, "mean_inference_ms": 2.025048563834226, "mean_action_processing_ms": 0.12142060910699609, "mean_env_wait_ms": 0.28649940456596124, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 345600, "agent_timesteps_total": 345519, "timers": {"learn_time_ms": 1.948, "learn_throughput": 16427.716, "update_time_ms": 5.177}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.124845504760742, "min_q": 0.8737590312957764, "max_q": 8.781359672546387, "mean_td_error": -20.100976943969727, "model": {}}}, "num_steps_sampled": 345600, "num_agent_steps_sampled": 345519, "num_steps_trained": 102112, "num_agent_steps_trained": 102112, "last_target_update_ts": 345600, "num_target_updates": 639}, "done": false, "episodes_total": 6750, "training_iteration": 109, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-44", "timestamp": 1626859844, "time_this_iter_s": 1.1601355075836182, "time_total_s": 123.93402051925659, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 123.93402051925659, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 49.4, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 12.0, 1.0, -9.0, 11.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, -2.0, 13.0, 7.0, -3.0, -11.0, 14.0, 7.0, 5.0, 14.0, 10.0, -9.0, 0.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, 1.0, 14.0, 8.0, -8.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -13.0, 14.0, 8.0, 6.0, 14.0, 5.0, -9.0, 5.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 8.0, 12.0, 11.0, -16.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -11.0, 14.0, 8.0, 4.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -11.0, 14.0, 8.0, 4.0, 14.0, 3.0, -8.0, 6.0, 2.0, 13.0, 8.0, -8.0, -11.0, 14.0, 6.0, 6.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 4.0, 12.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 4.0, 13.0, 7.0, -9.0, -11.0, 14.0, 6.0, 6.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 13.0, 6.0, -14.0, 10.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 8.0, 8.0, -4.0, 3.0, 3.0, 13.0, 7.0, -8.0, -11.0, 13.0, 5.0, 8.0, 8.0, 9.0, -7.0, 5.0, 3.0, 13.0, 7.0, -8.0, 5.0, 14.0, 4.0, -8.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 1.0, -12.0, 12.0, 3.0, 13.0, 7.0, -8.0, 318.0, 14.0, 11.0, 9.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 6.0, -2.0, -1.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 5.0, -2.0, 0.0, 8.0, 8.0, 7.0, -8.0, 11.0, 2.0, -5.0, 7.0, 9.0, 7.0, -9.0, 8.0, 12.0, 10.0, -7.0, 0.0, 14.0, 7.0, -12.0, 6.0, 12.0, 10.0, -7.0, 0.0, 8.0, 8.0, 7.0, -8.0, 12.0, 10.0, -7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48920522909278574, "mean_inference_ms": 2.0169468958858374, "mean_action_processing_ms": 0.12077009796938398, "mean_env_wait_ms": 0.2851580687397042, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 348840, "agent_timesteps_total": 348759, "timers": {"learn_time_ms": 1.839, "learn_throughput": 17401.72, "update_time_ms": 3.991}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.9427642822265625, "min_q": 1.3499176502227783, "max_q": 9.678153991699219, "mean_td_error": 0.7431608438491821, "model": {}}}, "num_steps_sampled": 348840, "num_agent_steps_sampled": 348759, "num_steps_trained": 103072, "num_agent_steps_trained": 103072, "last_target_update_ts": 348840, "num_target_updates": 645}, "done": false, "episodes_total": 6831, "training_iteration": 110, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-45", "timestamp": 1626859845, "time_this_iter_s": 1.1188604831695557, "time_total_s": 125.05288100242615, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 125.05288100242615, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 50.65, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 12.0, -21.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, 11.0, -4.0, 11.0, -3.0, 5.0, -5.0, 2.0, 13.0, 1.0, 12.0, -10.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 13.0, -1.0, -10.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 11.0, 12.0, -21.0, 13.0, -12.0, 11.0, 4.0, 12.0, 6.0, -5.0, 1.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 12.0, -8.0, -2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -14.0, 12.0, 5.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, -5.0, 13.0, -4.0, 11.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -14.0, 11.0, 5.0, 13.0, 13.0, 11.0, -21.0, 12.0, -12.0, 11.0, 3.0, 13.0, 12.0, -8.0, -2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 14.0, 3.0, -8.0, 6.0, 2.0, 13.0, 8.0, -8.0, -11.0, 14.0, 6.0, 6.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 4.0, 12.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 4.0, 13.0, 7.0, -9.0, -11.0, 14.0, 6.0, 6.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 13.0, 6.0, -14.0, 10.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 8.0, 8.0, -4.0, 3.0, 3.0, 13.0, 7.0, -8.0, -11.0, 13.0, 5.0, 8.0, 8.0, 9.0, -7.0, 5.0, 3.0, 13.0, 7.0, -8.0, 5.0, 14.0, 4.0, -8.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 1.0, -12.0, 12.0, 3.0, 13.0, 7.0, -8.0, 318.0, 14.0, 11.0, 9.0, 14.0, 3.0, -8.0, 6.0, 3.0, 13.0, 7.0, -8.0, -12.0, 14.0, 8.0, 5.0, 14.0, 3.0, -8.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4867119539633857, "mean_inference_ms": 2.011571462970195, "mean_action_processing_ms": 0.12036918352204723, "mean_env_wait_ms": 0.2839477652187005, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 352080, "agent_timesteps_total": 351999, "timers": {"learn_time_ms": 1.867, "learn_throughput": 17135.345, "update_time_ms": 4.033}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.191920280456543, "min_q": 1.3598930835723877, "max_q": 7.873202323913574, "mean_td_error": 1.2873246669769287, "model": {}}}, "num_steps_sampled": 352080, "num_agent_steps_sampled": 351999, "num_steps_trained": 104032, "num_agent_steps_trained": 104032, "last_target_update_ts": 352080, "num_target_updates": 651}, "done": false, "episodes_total": 6885, "training_iteration": 111, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-46", "timestamp": 1626859846, "time_this_iter_s": 1.3164336681365967, "time_total_s": 126.36931467056274, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 126.36931467056274, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 44.95, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 99.68, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 24.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 353.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 354.0, 15.0, 15.0, 352.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 353.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 352.0, 15.0, 15.0, 354.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 11.0, 316.0, 14.0, 14.0, 313.0, 12.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 318.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 318.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 13.0, 13.0, 11.0, 315.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 12.0, -1.0, 13.0, -9.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, 313.0, 12.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 14.0, 11.0, 314.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -8.0, 10.0, 14.0, 13.0, 10.0, 315.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -9.0, 11.0, 14.0, 11.0, 12.0, 315.0, 14.0, 14.0, -23.0, 10.0, -2.0, 1.0, 7.0, 9.0, 14.0, 13.0, 10.0, 318.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, -3.0, 8.0, 10.0, 0.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 11.0, 10.0, -20.0, 9.0, 14.0, -18.0, 10.0, 14.0, -5.0, -5.0, 11.0, 14.0, 12.0, 11.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 7.0, 9.0, -15.0, 14.0, 14.0, -23.0, 10.0, -1.0, 0.0, 5.0, 11.0, 14.0, 11.0, 10.0, -20.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 11.0, 11.0, 316.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 12.0, 11.0, 318.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -14.0, 11.0, 5.0, 13.0, 13.0, 11.0, -21.0, 12.0, -12.0, 11.0, 3.0, 13.0, 12.0, -8.0, -2.0, 13.0, -12.0, 11.0, 4.0, 12.0, 5.0, -5.0, 2.0, 13.0, -12.0, 11.0, 4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48941376885532106, "mean_inference_ms": 2.0173840915706402, "mean_action_processing_ms": 0.1207732590684479, "mean_env_wait_ms": 0.2853068560570145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 355320, "agent_timesteps_total": 355266, "timers": {"learn_time_ms": 1.877, "learn_throughput": 17052.182, "update_time_ms": 5.12}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.90354061126709, "min_q": 1.033678412437439, "max_q": 9.063623428344727, "mean_td_error": -20.751447677612305, "model": {}}}, "num_steps_sampled": 355320, "num_agent_steps_sampled": 355266, "num_steps_trained": 104992, "num_agent_steps_trained": 104992, "last_target_update_ts": 355320, "num_target_updates": 657}, "done": false, "episodes_total": 6966, "training_iteration": 112, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-48", "timestamp": 1626859848, "time_this_iter_s": 1.1582167148590088, "time_total_s": 127.52753138542175, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 127.52753138542175, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 51.349999999999994, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 59.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 14.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 352.0, 15.0, 15.0, 354.0, 15.0, 15.0, 355.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -1.0, 8.0, 0.0, -3.0, 13.0, 12.0, -7.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, 316.0, 13.0, 12.0, 11.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, -1.0, -1.0, 8.0, 9.0, -3.0, 12.0, 12.0, -6.0, 11.0, -3.0, 11.0, -4.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 0.0, -1.0, 8.0, 8.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -20.0, 12.0, 12.0, 11.0, 7.0, -1.0, 1.0, 8.0, -3.0, 12.0, 12.0, -6.0, 7.0, -1.0, 1.0, 8.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 0.0, -1.0, 8.0, 8.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 14.0, 11.0, 314.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -8.0, 10.0, 14.0, 13.0, 10.0, 315.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -9.0, 11.0, 14.0, 11.0, 12.0, 315.0, 14.0, 14.0, -23.0, 10.0, -2.0, 1.0, 7.0, 9.0, 14.0, 13.0, 10.0, 318.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, -3.0, 8.0, 10.0, 0.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 11.0, 10.0, -20.0, 9.0, 14.0, -18.0, 10.0, 14.0, -5.0, -5.0, 11.0, 14.0, 12.0, 11.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 7.0, 9.0, -15.0, 14.0, 14.0, -23.0, 10.0, -1.0, 0.0, 5.0, 11.0, 14.0, 11.0, 10.0, -20.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 11.0, 11.0, 316.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 13.0, 10.0, 317.0, 14.0, 14.0, -23.0, 10.0, 14.0, -1.0, -10.0, 12.0, 14.0, 12.0, 11.0, 318.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4869105482103796, "mean_inference_ms": 2.012358709664339, "mean_action_processing_ms": 0.12040278665000231, "mean_env_wait_ms": 0.2841236632115765, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 358560, "agent_timesteps_total": 358479, "timers": {"learn_time_ms": 1.892, "learn_throughput": 16912.942, "update_time_ms": 5.217}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 6.140050888061523, "min_q": 1.2764126062393188, "max_q": 9.727254867553711, "mean_td_error": -10.428409576416016, "model": {}}}, "num_steps_sampled": 358560, "num_agent_steps_sampled": 358479, "num_steps_trained": 105952, "num_agent_steps_trained": 105952, "last_target_update_ts": 358560, "num_target_updates": 663}, "done": false, "episodes_total": 7020, "training_iteration": 113, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-49", "timestamp": 1626859849, "time_this_iter_s": 1.1697266101837158, "time_total_s": 128.69725799560547, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 128.69725799560547, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 49.3, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 116.15, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 29.0375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.0, 15.0, 352.0, 15.0, 353.0, 15.0, 352.0, 353.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 352.0, 352.0, 15.0, 352.0, 355.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 352.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 14.0, 14.0, 10.0, 315.0, 12.0, 11.0, -20.0, 12.0, 13.0, 14.0, 10.0, 315.0, 317.0, 13.0, 12.0, 11.0, 14.0, 13.0, 10.0, 315.0, 10.0, 13.0, -20.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 14.0, 13.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 9.0, 316.0, 317.0, 13.0, 11.0, 11.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, 12.0, 13.0, 318.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 13.0, 11.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, 5.0, 12.0, -14.0, 12.0, 13.0, 14.0, 10.0, 315.0, 316.0, 12.0, 12.0, 12.0, 12.0, 14.0, -5.0, -6.0, -19.0, 13.0, 9.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 14.0, 13.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 12.0, 14.0, -6.0, -5.0, -7.0, 13.0, -3.0, 12.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, 316.0, 13.0, 12.0, 11.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, -1.0, -1.0, 8.0, 9.0, -3.0, 12.0, 12.0, -6.0, 11.0, -3.0, 11.0, -4.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 0.0, -1.0, 8.0, 8.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -20.0, 12.0, 12.0, 11.0, 7.0, -1.0, 1.0, 8.0, -3.0, 12.0, 12.0, -6.0, 7.0, -1.0, 1.0, 8.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0, 0.0, -1.0, 8.0, 8.0, -3.0, 12.0, 12.0, -6.0, 8.0, -1.0, 8.0, 0.0, -3.0, 12.0, 12.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4925413186013264, "mean_inference_ms": 2.0261376975990255, "mean_action_processing_ms": 0.12144990937758822, "mean_env_wait_ms": 0.2867569044374802, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 361800, "agent_timesteps_total": 361719, "timers": {"learn_time_ms": 1.909, "learn_throughput": 16763.596, "update_time_ms": 4.911}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.853160858154297, "min_q": 1.0436294078826904, "max_q": 9.408526420593262, "mean_td_error": -10.074569702148438, "model": {}}}, "num_steps_sampled": 361800, "num_agent_steps_sampled": 361719, "num_steps_trained": 106912, "num_agent_steps_trained": 106912, "last_target_update_ts": 361800, "num_target_updates": 669}, "done": false, "episodes_total": 7074, "training_iteration": 114, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-50", "timestamp": 1626859850, "time_this_iter_s": 1.1541190147399902, "time_total_s": 129.85137701034546, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 129.85137701034546, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 51.400000000000006, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 119.47, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 29.8675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 352.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -3.0, 14.0, 10.0, -6.0, 9.0, 14.0, 11.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -17.0, 5.0, -6.0, 14.0, 5.0, 2.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, 11.0, 14.0, -7.0, -3.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, 2.0, 5.0, 5.0, 14.0, 10.0, -14.0, 9.0, 13.0, -18.0, 11.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 11.0, 9.0, -10.0, 5.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -2.0, 9.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, 11.0, 14.0, -7.0, -3.0, 10.0, 14.0, 10.0, 318.0, 10.0, 9.0, -15.0, 11.0, -6.0, 14.0, 5.0, 2.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 10.0, 9.0, -15.0, 11.0, -2.0, 14.0, -7.0, 10.0, -2.0, 12.0, 12.0, -7.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, -4.0, -5.0, 10.0, 7.0, -14.0, 12.0, -7.0, 14.0, -3.0, 11.0, 10.0, 14.0, 10.0, 318.0, 10.0, 9.0, -14.0, 10.0, -6.0, 14.0, 10.0, -3.0, 8.0, 14.0, 11.0, 319.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -1.0, 14.0, 10.0, -8.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -3.0, 14.0, 10.0, -6.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -18.0, 6.0, -2.0, 14.0, -7.0, 10.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 4.0, 14.0, 10.0, -13.0, 10.0, 9.0, -14.0, 10.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 6.0, 5.0, -7.0, 11.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 14.0, -18.0, 5.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, 5.0, 12.0, -14.0, 12.0, 13.0, 14.0, 10.0, 315.0, 316.0, 12.0, 12.0, 12.0, 12.0, 14.0, -5.0, -6.0, -19.0, 13.0, 9.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 13.0, 14.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 14.0, 13.0, 10.0, 315.0, -7.0, 13.0, -3.0, 12.0, 12.0, 14.0, -6.0, -5.0, -7.0, 13.0, -3.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4895334583677494, "mean_inference_ms": 2.018057141791059, "mean_action_processing_ms": 0.12077195297292231, "mean_env_wait_ms": 0.2854388664595861, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 365040, "agent_timesteps_total": 364986, "timers": {"learn_time_ms": 1.999, "learn_throughput": 16009.176, "update_time_ms": 4.413}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.565181732177734, "min_q": 0.685492992401123, "max_q": 9.251924514770508, "mean_td_error": -9.95801067352295, "model": {}}}, "num_steps_sampled": 365040, "num_agent_steps_sampled": 364986, "num_steps_trained": 107872, "num_agent_steps_trained": 107872, "last_target_update_ts": 365040, "num_target_updates": 675}, "done": false, "episodes_total": 7155, "training_iteration": 115, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-51", "timestamp": 1626859851, "time_this_iter_s": 1.1325979232788086, "time_total_s": 130.98397493362427, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 130.98397493362427, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 50.25, "ram_util_percent": 14.1}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 58.83, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 14.7075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 9.0, 2.0, -9.0, 6.0, 12.0, 13.0, -16.0, 13.0, 14.0, -8.0, -4.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 10.0, 13.0, -14.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 8.0, -20.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 11.0, 10.0, 13.0, -19.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 1.0, 6.0, 12.0, -4.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 5.0, 9.0, -12.0, 9.0, 5.0, 13.0, -12.0, 13.0, 14.0, 7.0, -19.0, 8.0, 13.0, -5.0, -1.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 12.0, 318.0, 12.0, 12.0, 6.0, 11.0, 13.0, -15.0, 10.0, 9.0, -15.0, 11.0, -6.0, 14.0, 5.0, 2.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 10.0, 9.0, -15.0, 11.0, -2.0, 14.0, -7.0, 10.0, -2.0, 12.0, 12.0, -7.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, -4.0, -5.0, 10.0, 7.0, -14.0, 12.0, -7.0, 14.0, -3.0, 11.0, 10.0, 14.0, 10.0, 318.0, 10.0, 9.0, -14.0, 10.0, -6.0, 14.0, 10.0, -3.0, 8.0, 14.0, 11.0, 319.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -1.0, 14.0, 10.0, -8.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -3.0, 14.0, 10.0, -6.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -18.0, 6.0, -2.0, 14.0, -7.0, 10.0, 10.0, 14.0, 10.0, 318.0, 14.0, 13.0, -19.0, 7.0, -6.0, 14.0, -4.0, 11.0, 4.0, 14.0, 10.0, -13.0, 10.0, 9.0, -14.0, 10.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 6.0, 5.0, -7.0, 11.0, -6.0, 14.0, -4.0, 11.0, 10.0, 14.0, 10.0, 318.0, 14.0, 14.0, -18.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4869159322628233, "mean_inference_ms": 2.01218499745161, "mean_action_processing_ms": 0.12036514434714432, "mean_env_wait_ms": 0.2841646037955506, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 368280, "agent_timesteps_total": 368199, "timers": {"learn_time_ms": 1.868, "learn_throughput": 17128.784, "update_time_ms": 4.518}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.181674957275391, "min_q": 0.601369321346283, "max_q": 9.265228271484375, "mean_td_error": 0.5706453323364258, "model": {}}}, "num_steps_sampled": 368280, "num_agent_steps_sampled": 368199, "num_steps_trained": 108832, "num_agent_steps_trained": 108832, "last_target_update_ts": 368280, "num_target_updates": 681}, "done": false, "episodes_total": 7209, "training_iteration": 116, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-52", "timestamp": 1626859852, "time_this_iter_s": 1.1033704280853271, "time_total_s": 132.0873453617096, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 132.0873453617096, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 51.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.89, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 7.9725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 13.0, 12.0, -22.0, 4.0, 11.0, 6.0, -6.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 14.0, 13.0, 11.0, 315.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 12.0, 12.0, -21.0, 14.0, -11.0, 2.0, 10.0, 11.0, 13.0, 1.0, -10.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, 4.0, 11.0, 6.0, -6.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 14.0, 11.0, 12.0, 315.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, -2.0, 13.0, 12.0, -8.0, 0.0, 5.0, -3.0, 13.0, 14.0, 11.0, 12.0, 315.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 13.0, 13.0, 12.0, 315.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -2.0, 4.0, 0.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 14.0, 13.0, 5.0, -17.0, -1.0, 6.0, -3.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, 0.0, 5.0, -3.0, 13.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 8.0, -20.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 11.0, 10.0, 13.0, -19.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 1.0, 6.0, 12.0, -4.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 13.0, 5.0, 9.0, -12.0, 9.0, 5.0, 13.0, -12.0, 13.0, 14.0, 7.0, -19.0, 8.0, 13.0, -5.0, -1.0, 13.0, 14.0, 7.0, -19.0, 6.0, 11.0, 13.0, -15.0, 12.0, 318.0, 12.0, 12.0, 6.0, 11.0, 13.0, -15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49232271025130125, "mean_inference_ms": 2.0254860062241717, "mean_action_processing_ms": 0.1213817123536365, "mean_env_wait_ms": 0.2866835155132969, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 371520, "agent_timesteps_total": 371439, "timers": {"learn_time_ms": 2.04, "learn_throughput": 15688.989, "update_time_ms": 5.221}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.693597793579102, "min_q": 0.9629284143447876, "max_q": 9.504664421081543, "mean_td_error": 0.174515038728714, "model": {}}}, "num_steps_sampled": 371520, "num_agent_steps_sampled": 371439, "num_steps_trained": 109792, "num_agent_steps_trained": 109792, "last_target_update_ts": 371520, "num_target_updates": 687}, "done": false, "episodes_total": 7263, "training_iteration": 117, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-54", "timestamp": 1626859854, "time_this_iter_s": 1.1261916160583496, "time_total_s": 133.21353697776794, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daf28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 133.21353697776794, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 51.05, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 28.52, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 7.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, -1.0, 8.0, -6.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, -18.0, 14.0, 6.0, 13.0, 14.0, 8.0, 5.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 8.0, 6.0, -13.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, -1.0, 6.0, -3.0, 13.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 0.0, 10.0, -3.0, 8.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 12.0, 12.0, -6.0, -3.0, 14.0, 1.0, 6.0, -6.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 10.0, 14.0, 318.0, 13.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, -5.0, 12.0, -4.0, 12.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, -1.0, 6.0, -4.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 13.0, -13.0, 7.0, 14.0, 4.0, 8.0, -11.0, 3.0, 14.0, -3.0, 1.0, 14.0, 1.0, 12.0, -12.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 12.0, 12.0, -21.0, 14.0, -11.0, 2.0, 10.0, 11.0, 13.0, 1.0, -10.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, 4.0, 11.0, 6.0, -6.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 14.0, 11.0, 12.0, 315.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, -2.0, 13.0, 12.0, -8.0, 0.0, 5.0, -3.0, 13.0, 14.0, 11.0, 12.0, 315.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 13.0, 13.0, 12.0, 315.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -2.0, 4.0, 0.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 14.0, 13.0, 5.0, -17.0, -1.0, 6.0, -3.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, -10.0, 5.0, 7.0, 13.0, 12.0, 13.0, 12.0, -22.0, 0.0, 5.0, -3.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49226083362808176, "mean_inference_ms": 2.025524799367334, "mean_action_processing_ms": 0.12136773854767517, "mean_env_wait_ms": 0.28665617756146544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 373680, "agent_timesteps_total": 373599, "timers": {"learn_time_ms": 1.942, "learn_throughput": 16478.542, "update_time_ms": 4.396}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.551998615264893, "min_q": 0.7920287251472473, "max_q": 9.449593544006348, "mean_td_error": 0.20736858248710632, "model": {}}}, "num_steps_sampled": 373680, "num_agent_steps_sampled": 373599, "num_steps_trained": 110432, "num_agent_steps_trained": 110432, "last_target_update_ts": 373680, "num_target_updates": 691}, "done": false, "episodes_total": 7317, "training_iteration": 118, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-55", "timestamp": 1626859855, "time_this_iter_s": 0.9579827785491943, "time_total_s": 134.17151975631714, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 134.17151975631714, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 37.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.4, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -5.0, -6.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, 12.0, -15.0, 7.0, 11.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 12.0, -18.0, 8.0, 13.0, -1.0, -9.0, 12.0, 13.0, 14.0, -18.0, 6.0, 13.0, -1.0, -9.0, 12.0, 13.0, 9.0, -17.0, 10.0, 13.0, 1.0, -2.0, 3.0, 13.0, 13.0, -16.0, 5.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, 3.0, -9.0, 8.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -8.0, 11.0, 13.0, 13.0, -18.0, 7.0, 13.0, 2.0, -10.0, 12.0, 11.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, 12.0, -3.0, -7.0, 13.0, 13.0, -8.0, -3.0, 13.0, -1.0, -9.0, 12.0, 13.0, 12.0, -17.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -17.0, 6.0, 13.0, -1.0, -9.0, 12.0, 13.0, 14.0, -17.0, 5.0, 13.0, 3.0, -9.0, 8.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, -18.0, 14.0, 6.0, 13.0, 14.0, 8.0, 5.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 8.0, 6.0, -13.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, -1.0, 6.0, -3.0, 13.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 0.0, 10.0, -3.0, 8.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 12.0, 12.0, -6.0, -3.0, 14.0, 1.0, 6.0, -6.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 10.0, 14.0, 318.0, 13.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, -5.0, 12.0, -4.0, 12.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, -1.0, 6.0, -4.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 10.0, -3.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 13.0, -13.0, 7.0, 14.0, 4.0, 8.0, -11.0, 3.0, 14.0, -3.0, 1.0, 14.0, 1.0, 12.0, -12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4922918885010975, "mean_inference_ms": 2.025830195601758, "mean_action_processing_ms": 0.12137642281637014, "mean_env_wait_ms": 0.2867098946257314, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 376920, "agent_timesteps_total": 376839, "timers": {"learn_time_ms": 1.918, "learn_throughput": 16686.276, "update_time_ms": 4.539}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.804135799407959, "min_q": 0.7831757664680481, "max_q": 9.288180351257324, "mean_td_error": -21.103477478027344, "model": {}}}, "num_steps_sampled": 376920, "num_agent_steps_sampled": 376839, "num_steps_trained": 111392, "num_agent_steps_trained": 111392, "last_target_update_ts": 376920, "num_target_updates": 697}, "done": false, "episodes_total": 7371, "training_iteration": 119, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-56", "timestamp": 1626859856, "time_this_iter_s": 1.1482648849487305, "time_total_s": 135.31978464126587, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 135.31978464126587, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 51.45, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.38, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 10.0, -1.0, -3.0, 9.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 1.0, 9.0, -2.0, 7.0, 13.0, 8.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 12.0, 1.0, 13.0, -11.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 2.0, -8.0, 8.0, 5.0, 14.0, -16.0, 12.0, 0.0, 12.0, -3.0, 6.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 7.0, 12.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 10.0, -4.0, 0.0, 9.0, 14.0, 7.0, -11.0, 5.0, 13.0, -2.0, 12.0, -8.0, 5.0, 14.0, -16.0, 12.0, 9.0, 8.0, -7.0, 5.0, 13.0, 9.0, 3.0, -10.0, 5.0, 14.0, -16.0, 12.0, -11.0, 9.0, 6.0, 11.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 4.0, 7.0, -9.0, 5.0, 14.0, -16.0, 12.0, 14.0, 5.0, -10.0, 6.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, -13.0, 12.0, 11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, -1.0, 12.0, -9.0, 315.0, 14.0, 12.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, -6.0, 8.0, 7.0, 6.0, 13.0, 1.0, 13.0, -12.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 0.0, 13.0, -11.0, 5.0, 14.0, -16.0, 12.0, 2.0, -10.0, 12.0, 11.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, 12.0, -3.0, -7.0, 13.0, 13.0, -8.0, -3.0, 13.0, -1.0, -9.0, 12.0, 13.0, 12.0, -17.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -17.0, 6.0, 13.0, -1.0, -9.0, 12.0, 13.0, 14.0, -17.0, 5.0, 13.0, 3.0, -9.0, 8.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0, 13.0, -18.0, 7.0, 13.0, -1.0, -9.0, 12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48941737724411943, "mean_inference_ms": 2.018032181174037, "mean_action_processing_ms": 0.1207348195496143, "mean_env_wait_ms": 0.2854043294866506, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 380160, "agent_timesteps_total": 380106, "timers": {"learn_time_ms": 1.981, "learn_throughput": 16155.628, "update_time_ms": 4.809}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.651636123657227, "min_q": 0.903885006904602, "max_q": 9.39665699005127, "mean_td_error": -9.409131050109863, "model": {}}}, "num_steps_sampled": 380160, "num_agent_steps_sampled": 380106, "num_steps_trained": 112352, "num_agent_steps_trained": 112352, "last_target_update_ts": 380160, "num_target_updates": 703}, "done": false, "episodes_total": 7452, "training_iteration": 120, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-57", "timestamp": 1626859857, "time_this_iter_s": 1.1403887271881104, "time_total_s": 136.46017336845398, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 136.46017336845398, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 51.099999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.38, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 1.0, 8.0, -2.0, 6.0, 5.0, 13.0, -9.0, 13.0, -1.0, -5.0, 8.0, 6.0, 5.0, 13.0, -9.0, 8.0, -1.0, 10.0, -2.0, 5.0, 4.0, 13.0, -7.0, 8.0, -13.0, 9.0, 11.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, -4.0, 5.0, 11.0, 3.0, 8.0, 0.0, 9.0, -2.0, 6.0, 4.0, 13.0, -8.0, 13.0, -1.0, 9.0, -6.0, 10.0, 8.0, 12.0, -15.0, 4.0, 11.0, 11.0, -11.0, 1.0, 3.0, 13.0, -2.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 11.0, 9.0, 12.0, -17.0, 13.0, -7.0, 13.0, -4.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 7.0, 12.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 10.0, -4.0, 0.0, 9.0, 14.0, 7.0, -11.0, 5.0, 13.0, -2.0, 12.0, -8.0, 5.0, 14.0, -16.0, 12.0, 9.0, 8.0, -7.0, 5.0, 13.0, 9.0, 3.0, -10.0, 5.0, 14.0, -16.0, 12.0, -11.0, 9.0, 6.0, 11.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 4.0, 7.0, -9.0, 5.0, 14.0, -16.0, 12.0, 14.0, 5.0, -10.0, 6.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, -13.0, 12.0, 11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, -1.0, 12.0, -9.0, 315.0, 14.0, 12.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 3.0, 7.0, -8.0, 5.0, 14.0, -16.0, 12.0, -6.0, 8.0, 7.0, 6.0, 13.0, 1.0, 13.0, -12.0, 5.0, 14.0, -16.0, 12.0, 14.0, 7.0, -11.0, 5.0, 13.0, 0.0, 13.0, -11.0, 5.0, 14.0, -16.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48684651032015774, "mean_inference_ms": 2.012664298687682, "mean_action_processing_ms": 0.12036085309298089, "mean_env_wait_ms": 0.28416079187268045, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 383400, "agent_timesteps_total": 383319, "timers": {"learn_time_ms": 1.925, "learn_throughput": 16620.979, "update_time_ms": 4.743}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.580049514770508, "min_q": 0.9061152935028076, "max_q": 9.235831260681152, "mean_td_error": 0.6788171529769897, "model": {}}}, "num_steps_sampled": 383400, "num_agent_steps_sampled": 383319, "num_steps_trained": 113312, "num_agent_steps_trained": 113312, "last_target_update_ts": 383400, "num_target_updates": 709}, "done": false, "episodes_total": 7506, "training_iteration": 121, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-58", "timestamp": 1626859858, "time_this_iter_s": 1.1518456935882568, "time_total_s": 137.61201906204224, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daa60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 137.61201906204224, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 51.349999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 89.36, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 22.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, -7.0, 12.0, -1.0, 11.0, -2.0, 13.0, -8.0, 12.0, -14.0, 10.0, 13.0, 6.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, 2.0, 9.0, -5.0, 9.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -14.0, 5.0, 13.0, 11.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -13.0, 5.0, 13.0, 10.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 319.0, 11.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, -14.0, 10.0, 12.0, 7.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -12.0, 5.0, 11.0, 11.0, -16.0, 12.0, 12.0, 7.0, -2.0, 13.0, -8.0, 12.0, -15.0, 13.0, 10.0, 7.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 1.0, 8.0, -2.0, 6.0, 5.0, 13.0, -9.0, 13.0, -1.0, -5.0, 8.0, 6.0, 5.0, 13.0, -9.0, 8.0, -1.0, 10.0, -2.0, 5.0, 4.0, 13.0, -7.0, 8.0, -13.0, 9.0, 11.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, -4.0, 5.0, 11.0, 3.0, 8.0, 0.0, 9.0, -2.0, 6.0, 4.0, 13.0, -8.0, 13.0, -1.0, 9.0, -6.0, 10.0, 8.0, 12.0, -15.0, 4.0, 11.0, 11.0, -11.0, 1.0, 3.0, 13.0, -2.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 6.0, 5.0, 13.0, -9.0, 8.0, 0.0, 9.0, -2.0, 11.0, 9.0, 12.0, -17.0, 13.0, -7.0, 13.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4924893889697178, "mean_inference_ms": 2.026475345572714, "mean_action_processing_ms": 0.12143164173677913, "mean_env_wait_ms": 0.2868161234535264, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 386640, "agent_timesteps_total": 386559, "timers": {"learn_time_ms": 1.961, "learn_throughput": 16316.876, "update_time_ms": 5.058}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.6602389812469482, "min_q": 0.7922000288963318, "max_q": 7.662402629852295, "mean_td_error": -10.316882133483887, "model": {}}}, "num_steps_sampled": 386640, "num_agent_steps_sampled": 386559, "num_steps_trained": 114272, "num_agent_steps_trained": 114272, "last_target_update_ts": 386640, "num_target_updates": 715}, "done": false, "episodes_total": 7560, "training_iteration": 122, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-30-59", "timestamp": 1626859859, "time_this_iter_s": 1.1777732372283936, "time_total_s": 138.78979229927063, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da1e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 138.78979229927063, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 49.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 122.94, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 30.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -8.0, 13.0, 12.0, -2.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -3.0, 13.0, 5.0, 0.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -5.0, 13.0, 5.0, 2.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, 12.0, 13.0, 5.0, -15.0, 10.0, 319.0, 12.0, 11.0, 10.0, -9.0, 6.0, 8.0, -6.0, 13.0, 5.0, 3.0, 0.0, 5.0, -3.0, 13.0, 8.0, 7.0, 13.0, -13.0, -1.0, 13.0, 7.0, -4.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, 5.0, 13.0, 7.0, -10.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -1.0, 12.0, 2.0, 2.0, 11.0, 319.0, 11.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -8.0, 13.0, 2.0, -1.0, 12.0, 2.0, 2.0, 10.0, 319.0, 12.0, 11.0, 11.0, -3.0, 1.0, 6.0, -1.0, 13.0, 7.0, -4.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -8.0, 13.0, 6.0, 4.0, 11.0, 319.0, 11.0, 11.0, 8.0, -6.0, 13.0, 0.0, -3.0, 13.0, 5.0, 0.0, 11.0, 319.0, 12.0, 11.0, 11.0, -8.0, 11.0, 1.0, 12.0, 12.0, 2.0, -11.0, 11.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, -1.0, -3.0, 13.0, 6.0, -6.0, 13.0, 5.0, 3.0, 11.0, 319.0, 12.0, 11.0, 2.0, -6.0, 13.0, 6.0, 6.0, 13.0, 9.0, -13.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 11.0, -8.0, 11.0, 1.0, 12.0, 11.0, 2.0, -10.0, 9.0, -17.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 319.0, 11.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, -14.0, 10.0, 12.0, 7.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -12.0, 5.0, 11.0, 11.0, -16.0, 12.0, 12.0, 7.0, -2.0, 13.0, -8.0, 12.0, -15.0, 13.0, 10.0, 7.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0, -2.0, 13.0, -8.0, 12.0, 318.0, 12.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4897276338446537, "mean_inference_ms": 2.0183882980043655, "mean_action_processing_ms": 0.12081005866517447, "mean_env_wait_ms": 0.28550427190185745, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 389880, "agent_timesteps_total": 389799, "timers": {"learn_time_ms": 1.808, "learn_throughput": 17698.885, "update_time_ms": 4.281}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.286048889160156, "min_q": 0.799976646900177, "max_q": 9.131614685058594, "mean_td_error": -20.392200469970703, "model": {}}}, "num_steps_sampled": 389880, "num_agent_steps_sampled": 389799, "num_steps_trained": 115232, "num_agent_steps_trained": 115232, "last_target_update_ts": 389880, "num_target_updates": 721}, "done": false, "episodes_total": 7641, "training_iteration": 123, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-01", "timestamp": 1626859861, "time_this_iter_s": 1.164100170135498, "time_total_s": 139.95389246940613, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 139.95389246940613, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 49.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 136.35, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 34.0875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [315.0, 13.0, 12.0, 12.0, 12.0, 14.0, 2.0, -13.0, 315.0, 13.0, 12.0, 12.0, 10.0, 8.0, 0.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 12.0, 0.0, -11.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 9.0, 14.0, 3.0, -11.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 6.0, 7.0, 4.0, -2.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 14.0, 7.0, -20.0, -21.0, 14.0, 12.0, 10.0, 14.0, 13.0, -9.0, -3.0, -17.0, 13.0, 7.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, -19.0, 13.0, 11.0, 10.0, 14.0, 13.0, -9.0, -3.0, -19.0, 14.0, 12.0, 8.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, 4.0, -16.0, 316.0, 13.0, 10.0, 13.0, 12.0, 13.0, -9.0, -1.0, 315.0, 12.0, 12.0, 13.0, 14.0, 14.0, 7.0, -20.0, -21.0, 14.0, 12.0, 10.0, 9.0, 14.0, 3.0, -11.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -8.0, 13.0, 2.0, -1.0, 12.0, 2.0, 2.0, 10.0, 319.0, 12.0, 11.0, 11.0, -3.0, 1.0, 6.0, -1.0, 13.0, 7.0, -4.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -8.0, 13.0, 6.0, 4.0, 11.0, 319.0, 11.0, 11.0, 8.0, -6.0, 13.0, 0.0, -3.0, 13.0, 5.0, 0.0, 11.0, 319.0, 12.0, 11.0, 11.0, -8.0, 11.0, 1.0, 12.0, 12.0, 2.0, -11.0, 11.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, -1.0, -3.0, 13.0, 6.0, -6.0, 13.0, 5.0, 3.0, 11.0, 319.0, 12.0, 11.0, 2.0, -6.0, 13.0, 6.0, 6.0, 13.0, 9.0, -13.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 11.0, -8.0, 11.0, 1.0, 12.0, 11.0, 2.0, -10.0, 9.0, -17.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0, 10.0, 319.0, 12.0, 11.0, 8.0, -6.0, 13.0, 0.0, -6.0, 13.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48718092621635833, "mean_inference_ms": 2.0130649205038815, "mean_action_processing_ms": 0.12041587826139477, "mean_env_wait_ms": 0.2842360380115892, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 393120, "agent_timesteps_total": 393039, "timers": {"learn_time_ms": 1.828, "learn_throughput": 17504.986, "update_time_ms": 4.271}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.947693824768066, "min_q": 1.2158446311950684, "max_q": 9.639236450195312, "mean_td_error": 0.9248483777046204, "model": {}}}, "num_steps_sampled": 393120, "num_agent_steps_sampled": 393039, "num_steps_trained": 116192, "num_agent_steps_trained": 116192, "last_target_update_ts": 393120, "num_target_updates": 727}, "done": false, "episodes_total": 7695, "training_iteration": 124, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-02", "timestamp": 1626859862, "time_this_iter_s": 1.1461877822875977, "time_total_s": 141.10008025169373, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 141.10008025169373, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 50.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 75.66, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 18.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -5.0, 12.0, -5.0, 13.0, -15.0, 6.0, 12.0, 12.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -17.0, 9.0, 12.0, 11.0, -4.0, 12.0, 0.0, 7.0, -5.0, 13.0, 11.0, -4.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -3.0, 12.0, 6.0, 0.0, -20.0, 10.0, 12.0, 13.0, -3.0, 10.0, -1.0, 9.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -19.0, 9.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -17.0, 7.0, 12.0, 13.0, -4.0, 9.0, -2.0, 12.0, -17.0, 8.0, 12.0, 12.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -6.0, 7.0, 12.0, 2.0, -6.0, 8.0, 1.0, 12.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -3.0, 12.0, 0.0, 6.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 7.0, 0.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 7.0, 0.0, -16.0, 6.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -19.0, 9.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 7.0, 5.0, 7.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 9.0, 14.0, 3.0, -11.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 6.0, 7.0, 4.0, -2.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 14.0, 7.0, -20.0, -21.0, 14.0, 12.0, 10.0, 14.0, 13.0, -9.0, -3.0, -17.0, 13.0, 7.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, -19.0, 13.0, 11.0, 10.0, 14.0, 13.0, -9.0, -3.0, -19.0, 14.0, 12.0, 8.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, -9.0, -3.0, 315.0, 13.0, 12.0, 12.0, 14.0, 13.0, 4.0, -16.0, 316.0, 13.0, 10.0, 13.0, 12.0, 13.0, -9.0, -1.0, 315.0, 12.0, 12.0, 13.0, 14.0, 14.0, 7.0, -20.0, -21.0, 14.0, 12.0, 10.0, 9.0, 14.0, 3.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49285208067743086, "mean_inference_ms": 2.0267217382086953, "mean_action_processing_ms": 0.12147314011887993, "mean_env_wait_ms": 0.2868375863950673, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 395280, "agent_timesteps_total": 395226, "timers": {"learn_time_ms": 1.942, "learn_throughput": 16475.508, "update_time_ms": 5.141}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.248693466186523, "min_q": 0.9556035399436951, "max_q": 9.302931785583496, "mean_td_error": 0.5881036520004272, "model": {}}}, "num_steps_sampled": 395280, "num_agent_steps_sampled": 395226, "num_steps_trained": 116832, "num_agent_steps_trained": 116832, "last_target_update_ts": 395280, "num_target_updates": 731}, "done": false, "episodes_total": 7749, "training_iteration": 125, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-03", "timestamp": 1626859863, "time_this_iter_s": 0.9775114059448242, "time_total_s": 142.07759165763855, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 142.07759165763855, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 37.4, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.13, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 6.2825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -13.0, 11.0, 8.0, 9.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -2.0, -5.0, 9.0, 13.0, 14.0, 316.0, 11.0, 12.0, -16.0, 11.0, 8.0, 12.0, 14.0, -16.0, 12.0, 5.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -14.0, 9.0, 6.0, -17.0, 11.0, 8.0, 13.0, 14.0, -22.0, 12.0, 11.0, -14.0, 13.0, 5.0, 11.0, 14.0, -22.0, 13.0, 10.0, -11.0, 1.0, 12.0, 13.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 13.0, 315.0, 13.0, 12.0, -7.0, 2.0, 8.0, 12.0, 14.0, 314.0, 12.0, 12.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 9.0, 11.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -21.0, 13.0, 9.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -18.0, 11.0, 9.0, 13.0, 14.0, -22.0, 12.0, 11.0, -7.0, -1.0, 10.0, 13.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -11.0, 1.0, 12.0, 13.0, 14.0, -22.0, 12.0, 11.0, -9.0, 0.0, 11.0, 13.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -17.0, 9.0, 12.0, 11.0, -4.0, 12.0, 0.0, 7.0, -5.0, 13.0, 11.0, -4.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -3.0, 12.0, 6.0, 0.0, -20.0, 10.0, 12.0, 13.0, -3.0, 10.0, -1.0, 9.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -19.0, 9.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -17.0, 7.0, 12.0, 13.0, -4.0, 9.0, -2.0, 12.0, -17.0, 8.0, 12.0, 12.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -6.0, 7.0, 12.0, 2.0, -6.0, 8.0, 1.0, 12.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -3.0, 12.0, 0.0, 6.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 7.0, 0.0, -20.0, 10.0, 12.0, 13.0, -4.0, 12.0, 7.0, 0.0, -16.0, 6.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -19.0, 9.0, 12.0, 13.0, -4.0, 12.0, 0.0, 7.0, -20.0, 10.0, 12.0, 13.0, -4.0, 7.0, 5.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49291051760349225, "mean_inference_ms": 2.0269123953316277, "mean_action_processing_ms": 0.12148552972725285, "mean_env_wait_ms": 0.2868670102454905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 398520, "agent_timesteps_total": 398439, "timers": {"learn_time_ms": 1.932, "learn_throughput": 16562.32, "update_time_ms": 4.001}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.4433369636535645, "min_q": 0.9383386373519897, "max_q": 8.310344696044922, "mean_td_error": -10.134420394897461, "model": {}}}, "num_steps_sampled": 398520, "num_agent_steps_sampled": 398439, "num_steps_trained": 117792, "num_agent_steps_trained": 117792, "last_target_update_ts": 398520, "num_target_updates": 737}, "done": false, "episodes_total": 7803, "training_iteration": 126, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-04", "timestamp": 1626859864, "time_this_iter_s": 1.162095546722412, "time_total_s": 143.23968720436096, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985059d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 143.23968720436096, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 28.5, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 7.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 13.0, -7.0, -4.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, 13.0, 11.0, 11.0, 317.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, 8.0, 8.0, 12.0, -13.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, 12.0, 10.0, 12.0, -19.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -1.0, 13.0, 8.0, -5.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, 7.0, 12.0, -2.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -2.0, -1.0, 7.0, 11.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, 14.0, -22.0, 12.0, 11.0, -2.0, -5.0, 9.0, 13.0, 14.0, 316.0, 11.0, 12.0, -16.0, 11.0, 8.0, 12.0, 14.0, -16.0, 12.0, 5.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -14.0, 9.0, 6.0, -17.0, 11.0, 8.0, 13.0, 14.0, -22.0, 12.0, 11.0, -14.0, 13.0, 5.0, 11.0, 14.0, -22.0, 13.0, 10.0, -11.0, 1.0, 12.0, 13.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 13.0, 315.0, 13.0, 12.0, -7.0, 2.0, 8.0, 12.0, 14.0, 314.0, 12.0, 12.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 9.0, 11.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -21.0, 13.0, 9.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -18.0, 11.0, 9.0, 13.0, 14.0, -22.0, 12.0, 11.0, -7.0, -1.0, 10.0, 13.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0, 14.0, -22.0, 12.0, 11.0, -11.0, 1.0, 12.0, 13.0, 14.0, -22.0, 12.0, 11.0, -9.0, 0.0, 11.0, 13.0, 14.0, -22.0, 12.0, 11.0, -16.0, 11.0, 8.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4929013700340382, "mean_inference_ms": 2.0269834605117514, "mean_action_processing_ms": 0.12149992682081522, "mean_env_wait_ms": 0.28688892092301915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 401760, "agent_timesteps_total": 401679, "timers": {"learn_time_ms": 1.899, "learn_throughput": 16853.69, "update_time_ms": 4.38}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.155119895935059, "min_q": 1.022503137588501, "max_q": 8.65391731262207, "mean_td_error": -9.897662162780762, "model": {}}}, "num_steps_sampled": 401760, "num_agent_steps_sampled": 401679, "num_steps_trained": 118752, "num_agent_steps_trained": 118752, "last_target_update_ts": 401760, "num_target_updates": 743}, "done": false, "episodes_total": 7857, "training_iteration": 127, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-05", "timestamp": 1626859865, "time_this_iter_s": 1.1485178470611572, "time_total_s": 144.38820505142212, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 144.38820505142212, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 51.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 102.66, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 25.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 355.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 314.0, 13.0, 12.0, 12.0, 9.0, 5.0, -11.0, -10.0, 12.0, 9.0, 4.0, 13.0, 313.0, 13.0, 13.0, 10.0, 4.0, 13.0, -12.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 12.0, 314.0, 13.0, 13.0, 9.0, 7.0, 13.0, -14.0, -15.0, 12.0, 5.0, 13.0, 12.0, 314.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 11.0, -22.0, 13.0, 13.0, 12.0, 1.0, -1.0, 3.0, -15.0, 12.0, 5.0, 13.0, 14.0, -20.0, 11.0, 10.0, 12.0, 1.0, 13.0, -11.0, -18.0, 10.0, 10.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 13.0, 2.0, 13.0, -13.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 9.0, 4.0, 13.0, -11.0, 321.0, 11.0, 10.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -14.0, 12.0, 9.0, 8.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 12.0, -10.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 12.0, 314.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 13.0, 9.0, 6.0, -13.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -18.0, 12.0, 8.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 2.0, 13.0, -12.0, -15.0, 12.0, 5.0, 13.0, 13.0, 315.0, 13.0, 12.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 314.0, 13.0, 12.0, -11.0, 9.0, 11.0, 6.0, 12.0, 10.0, 12.0, -19.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -1.0, 13.0, 8.0, -5.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, 7.0, 12.0, -2.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -2.0, -1.0, 7.0, 11.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0, -7.0, 12.0, 12.0, -2.0, -11.0, 9.0, 11.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49003871664429355, "mean_inference_ms": 2.0193931901968263, "mean_action_processing_ms": 0.12087289908644819, "mean_env_wait_ms": 0.28563658621774873, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 405000, "agent_timesteps_total": 404919, "timers": {"learn_time_ms": 1.947, "learn_throughput": 16435.361, "update_time_ms": 4.597}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.303110122680664, "min_q": 0.82010817527771, "max_q": 9.027373313903809, "mean_td_error": -20.974262237548828, "model": {}}}, "num_steps_sampled": 405000, "num_agent_steps_sampled": 404919, "num_steps_trained": 119712, "num_agent_steps_trained": 119712, "last_target_update_ts": 405000, "num_target_updates": 749}, "done": false, "episodes_total": 7938, "training_iteration": 128, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-06", "timestamp": 1626859866, "time_this_iter_s": 1.2080588340759277, "time_total_s": 145.59626388549805, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985412f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 145.59626388549805, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 48.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 75.71, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 18.9275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 5.0, -11.0, 10.0, 11.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 9.0, -11.0, 10.0, 7.0, -8.0, -1.0, 13.0, 11.0, 4.0, -11.0, 10.0, 12.0, 317.0, 12.0, 13.0, 12.0, 4.0, -11.0, 10.0, 12.0, -20.0, 11.0, 13.0, 11.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, -1.0, -8.0, 13.0, 11.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -7.0, -2.0, 13.0, 11.0, 4.0, -11.0, 10.0, 12.0, -7.0, -2.0, 13.0, 11.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, 12.0, 316.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 8.0, -8.0, 3.0, 12.0, -8.0, -3.0, 13.0, 13.0, 12.0, -12.0, 11.0, 4.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 9.0, -16.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 9.0, -18.0, 12.0, 12.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -14.0, 12.0, 9.0, 8.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 12.0, -10.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 12.0, 314.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 13.0, 9.0, 6.0, -13.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -18.0, 12.0, 8.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 2.0, 13.0, -12.0, -15.0, 12.0, 5.0, 13.0, 13.0, 315.0, 13.0, 12.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 313.0, 13.0, 13.0, 12.0, 1.0, 13.0, -11.0, -15.0, 12.0, 5.0, 13.0, 13.0, 314.0, 13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4873910601003172, "mean_inference_ms": 2.0140025331424893, "mean_action_processing_ms": 0.12048029611046934, "mean_env_wait_ms": 0.28437632765686816, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 408240, "agent_timesteps_total": 408159, "timers": {"learn_time_ms": 1.84, "learn_throughput": 17395.405, "update_time_ms": 4.264}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.708655834197998, "min_q": 1.004549264907837, "max_q": 8.580777168273926, "mean_td_error": 0.6001355648040771, "model": {}}}, "num_steps_sampled": 408240, "num_agent_steps_sampled": 408159, "num_steps_trained": 120672, "num_agent_steps_trained": 120672, "last_target_update_ts": 408240, "num_target_updates": 755}, "done": false, "episodes_total": 7992, "training_iteration": 129, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-08", "timestamp": 1626859868, "time_this_iter_s": 1.1357131004333496, "time_total_s": 146.7319769859314, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985417b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 146.7319769859314, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 50.15, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -10.0, 11.0, 9.0, 5.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, 5.0, -12.0, 9.0, 13.0, 11.0, -8.0, 0.0, 12.0, -1.0, 6.0, 10.0, 0.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -18.0, 8.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -18.0, 8.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 2.0, 11.0, 7.0, 11.0, 14.0, -18.0, 8.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 2.0, 11.0, 7.0, 11.0, 14.0, -6.0, -4.0, -5.0, 3.0, 10.0, 7.0, 11.0, -6.0, -2.0, 12.0, -5.0, -3.0, 11.0, 12.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -5.0, -5.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, -2.0, 10.0, 12.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, 14.0, -3.0, 9.0, -5.0, 11.0, 14.0, -19.0, 9.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 9.0, -11.0, 10.0, 7.0, -8.0, -1.0, 13.0, 11.0, 4.0, -11.0, 10.0, 12.0, 317.0, 12.0, 13.0, 12.0, 4.0, -11.0, 10.0, 12.0, -20.0, 11.0, 13.0, 11.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, -1.0, -8.0, 13.0, 11.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -7.0, -2.0, 13.0, 11.0, 4.0, -11.0, 10.0, 12.0, -7.0, -2.0, 13.0, 11.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, 12.0, 316.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 8.0, -8.0, 3.0, 12.0, -8.0, -3.0, 13.0, 13.0, 12.0, -12.0, 11.0, 4.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 9.0, -16.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 4.0, -11.0, 10.0, 12.0, -8.0, -3.0, 13.0, 13.0, 9.0, -18.0, 12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4929259824927763, "mean_inference_ms": 2.027296137219566, "mean_action_processing_ms": 0.12151506536097098, "mean_env_wait_ms": 0.28697409479330493, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 411480, "agent_timesteps_total": 411399, "timers": {"learn_time_ms": 1.996, "learn_throughput": 16031.549, "update_time_ms": 4.11}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.8910984992980957, "min_q": 0.8395946621894836, "max_q": 8.947588920593262, "mean_td_error": 0.26220566034317017, "model": {}}}, "num_steps_sampled": 411480, "num_agent_steps_sampled": 411399, "num_steps_trained": 121632, "num_agent_steps_trained": 121632, "last_target_update_ts": 411480, "num_target_updates": 761}, "done": false, "episodes_total": 8046, "training_iteration": 130, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-09", "timestamp": 1626859869, "time_this_iter_s": 1.1416637897491455, "time_total_s": 147.87364077568054, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 147.87364077568054, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 51.85, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 14.0, -18.0, 5.0, -9.0, 13.0, -1.0, 12.0, 11.0, 13.0, 13.0, -22.0, 12.0, 8.0, 8.0, -13.0, -2.0, 8.0, -1.0, 10.0, 11.0, 12.0, 8.0, -16.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, 0.0, 8.0, -1.0, 8.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -7.0, -1.0, 13.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, 316.0, 13.0, 13.0, 12.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -9.0, 13.0, -1.0, 12.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 12.0, 13.0, 12.0, -22.0, 14.0, 8.0, 11.0, -18.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 9.0, 10.0, 6.0, -10.0, -7.0, -1.0, 13.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 11.0, 8.0, 7.0, -11.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 12.0, 13.0, 13.0, -23.0, 8.0, 4.0, 8.0, -5.0, -7.0, -1.0, 13.0, 10.0, 11.0, 13.0, 13.0, -22.0, 9.0, 4.0, 8.0, -6.0, -2.0, 8.0, -1.0, 10.0, 13.0, 9.0, 8.0, -15.0, 11.0, 7.0, 8.0, -11.0, 2.0, 8.0, -1.0, 6.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 12.0, 8.0, -16.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -3.0, 8.0, -1.0, 11.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 8.0, -17.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 12.0, 8.0, 12.0, -17.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 11.0, -6.0, -2.0, 12.0, -5.0, -3.0, 11.0, 12.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -5.0, -5.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, -5.0, -2.0, 10.0, 12.0, 11.0, 14.0, -19.0, 9.0, -5.0, 3.0, 10.0, 7.0, 11.0, 14.0, -19.0, 9.0, 14.0, -3.0, 9.0, -5.0, 11.0, 14.0, -19.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49007199493617803, "mean_inference_ms": 2.0195459938268474, "mean_action_processing_ms": 0.12089420146312314, "mean_env_wait_ms": 0.28569576799098895, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 414720, "agent_timesteps_total": 414639, "timers": {"learn_time_ms": 1.905, "learn_throughput": 16794.851, "update_time_ms": 4.505}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.8945932388305664, "min_q": 1.0320008993148804, "max_q": 9.099264144897461, "mean_td_error": -20.829357147216797, "model": {}}}, "num_steps_sampled": 414720, "num_agent_steps_sampled": 414639, "num_steps_trained": 122592, "num_agent_steps_trained": 122592, "last_target_update_ts": 414720, "num_target_updates": 767}, "done": false, "episodes_total": 8127, "training_iteration": 131, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-10", "timestamp": 1626859870, "time_this_iter_s": 1.1433191299438477, "time_total_s": 149.0169599056244, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 149.0169599056244, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 51.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.94, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 7.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 315.0, 12.0, 12.0, 14.0, -18.0, 7.0, 12.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -3.0, 9.0, -5.0, 14.0, -1.0, 12.0, -10.0, 14.0, -22.0, 12.0, 11.0, 14.0, -1.0, 12.0, -10.0, 14.0, -10.0, 12.0, -1.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, 316.0, 12.0, 12.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -10.0, 12.0, -1.0, 14.0, 317.0, 12.0, 11.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, 316.0, 12.0, 12.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, 0.0, 8.0, -1.0, 8.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -7.0, -1.0, 13.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, 316.0, 13.0, 13.0, 12.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -9.0, 13.0, -1.0, 12.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 12.0, 13.0, 12.0, -22.0, 14.0, 8.0, 11.0, -18.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 9.0, 10.0, 6.0, -10.0, -7.0, -1.0, 13.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 11.0, 8.0, 7.0, -11.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 12.0, 13.0, 13.0, -23.0, 8.0, 4.0, 8.0, -5.0, -7.0, -1.0, 13.0, 10.0, 11.0, 13.0, 13.0, -22.0, 9.0, 4.0, 8.0, -6.0, -2.0, 8.0, -1.0, 10.0, 13.0, 9.0, 8.0, -15.0, 11.0, 7.0, 8.0, -11.0, 2.0, 8.0, -1.0, 6.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 12.0, 8.0, -16.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -3.0, 8.0, -1.0, 11.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 8.0, -17.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 12.0, 8.0, 12.0, -17.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0, 8.0, 4.0, 8.0, -5.0, -2.0, 8.0, -1.0, 10.0, 11.0, 13.0, 13.0, -22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4928981813669539, "mean_inference_ms": 2.0277010839777416, "mean_action_processing_ms": 0.12160825098521016, "mean_env_wait_ms": 0.28694802028164773, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 416880, "agent_timesteps_total": 416799, "timers": {"learn_time_ms": 1.916, "learn_throughput": 16698.109, "update_time_ms": 4.763}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.514873504638672, "min_q": 0.618448793888092, "max_q": 8.931619644165039, "mean_td_error": 0.4326302707195282, "model": {}}}, "num_steps_sampled": 416880, "num_agent_steps_sampled": 416799, "num_steps_trained": 123232, "num_agent_steps_trained": 123232, "last_target_update_ts": 416880, "num_target_updates": 771}, "done": false, "episodes_total": 8154, "training_iteration": 132, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-11", "timestamp": 1626859871, "time_this_iter_s": 0.9796237945556641, "time_total_s": 149.99658370018005, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 149.99658370018005, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 37.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.17, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 6.2925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 7.0, -2.0, 11.0, -12.0, 1.0, 13.0, 13.0, 12.0, 13.0, -9.0, -1.0, 10.0, 12.0, -1.0, -6.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 13.0, 13.0, -9.0, -2.0, 13.0, 7.0, -3.0, -2.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 10.0, 13.0, -9.0, 1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -7.0, 12.0, -2.0, 12.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -6.0, 11.0, -3.0, 13.0, -17.0, 12.0, 13.0, 7.0, 11.0, 13.0, -9.0, 0.0, -1.0, 7.0, -2.0, 11.0, -17.0, 13.0, 12.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 13.0, 13.0, -9.0, -2.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, -6.0, 13.0, 4.0, 4.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 7.0, 14.0, -3.0, -3.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 9.0, 1.0, -3.0, 8.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 8.0, 7.0, -2.0, 2.0, -17.0, 12.0, 13.0, 7.0, 6.0, 9.0, 2.0, -2.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -18.0, 11.0, 13.0, 9.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 13.0, 2.0, 11.0, -11.0, -7.0, 13.0, 2.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 0.0, 10.0, -2.0, 7.0, -18.0, 13.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 12.0, 8.0, -7.0, 2.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 14.0, -22.0, 12.0, 11.0, 14.0, -1.0, 12.0, -10.0, 14.0, -10.0, 12.0, -1.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, 316.0, 12.0, 12.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -10.0, 12.0, -1.0, 14.0, 317.0, 12.0, 11.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0, 14.0, 316.0, 12.0, 12.0, 14.0, -1.0, 12.0, -10.0, 14.0, -1.0, 12.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49371517688879957, "mean_inference_ms": 2.0292031471954872, "mean_action_processing_ms": 0.12172019399648178, "mean_env_wait_ms": 0.28749623521236933, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 420120, "agent_timesteps_total": 420039, "timers": {"learn_time_ms": 1.847, "learn_throughput": 17324.676, "update_time_ms": 4.609}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.661196708679199, "min_q": 0.8599026799201965, "max_q": 9.199318885803223, "mean_td_error": -10.558640480041504, "model": {}}}, "num_steps_sampled": 420120, "num_agent_steps_sampled": 420039, "num_steps_trained": 124192, "num_agent_steps_trained": 124192, "last_target_update_ts": 420120, "num_target_updates": 777}, "done": false, "episodes_total": 8235, "training_iteration": 133, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-12", "timestamp": 1626859872, "time_this_iter_s": 1.161567211151123, "time_total_s": 151.15815091133118, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985057b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 151.15815091133118, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 51.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 2.0, -15.0, 7.0, 14.0, 4.0, -10.0, 14.0, 7.0, 10.0, -16.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 13.0, 9.0, 10.0, -17.0, 7.0, 14.0, 4.0, -10.0, 14.0, 9.0, 6.0, -14.0, 4.0, 11.0, 10.0, -10.0, 14.0, 7.0, 10.0, -16.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 2.0, -15.0, 1.0, 14.0, 10.0, -10.0, 14.0, 14.0, 0.0, -13.0, 316.0, 13.0, 11.0, 12.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, -1.0, -12.0, 1.0, 14.0, 10.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 12.0, 0.0, -4.0, 14.0, 14.0, 1.0, -14.0, 318.0, 14.0, 11.0, 11.0, 14.0, 14.0, 1.0, -14.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 2.0, -15.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 8.0, 8.0, 5.0, -6.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, -6.0, 13.0, 4.0, 4.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 7.0, 14.0, -3.0, -3.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 9.0, 1.0, -3.0, 8.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 8.0, 7.0, -2.0, 2.0, -17.0, 12.0, 13.0, 7.0, 6.0, 9.0, 2.0, -2.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -18.0, 11.0, 13.0, 9.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 13.0, 2.0, 11.0, -11.0, -7.0, 13.0, 2.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 0.0, 10.0, -2.0, 7.0, -18.0, 13.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0, 12.0, 8.0, -7.0, 2.0, -17.0, 12.0, 13.0, 7.0, 12.0, 13.0, -9.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4876070294330311, "mean_inference_ms": 2.0151479447126412, "mean_action_processing_ms": 0.12057538071815925, "mean_env_wait_ms": 0.2845734150712984, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 423360, "agent_timesteps_total": 423279, "timers": {"learn_time_ms": 1.878, "learn_throughput": 17038.545, "update_time_ms": 4.431}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.131342887878418, "min_q": 1.0904561281204224, "max_q": 9.373136520385742, "mean_td_error": 0.721734881401062, "model": {}}}, "num_steps_sampled": 423360, "num_agent_steps_sampled": 423279, "num_steps_trained": 125152, "num_agent_steps_trained": 125152, "last_target_update_ts": 423360, "num_target_updates": 783}, "done": false, "episodes_total": 8289, "training_iteration": 134, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-13", "timestamp": 1626859873, "time_this_iter_s": 1.1366918087005615, "time_total_s": 152.29484272003174, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 152.29484272003174, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 50.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 13.0, -9.0, -3.0, 3.0, 10.0, 12.0, -10.0, 14.0, 13.0, -7.0, -5.0, 8.0, 14.0, 12.0, -19.0, 14.0, 13.0, -9.0, -3.0, 0.0, 14.0, 7.0, -6.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -3.0, -9.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -8.0, -4.0, 11.0, -5.0, 7.0, 2.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 8.0, -19.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, -2.0, 12.0, 8.0, -3.0, 10.0, 14.0, 7.0, -16.0, 14.0, 14.0, -4.0, -9.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 8.0, 14.0, 12.0, -19.0, 14.0, -3.0, 7.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 8.0, -1.0, -6.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -5.0, -7.0, 12.0, 14.0, 2.0, -13.0, 5.0, 14.0, -1.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 7.0, -18.0, 7.0, 14.0, 4.0, -10.0, 14.0, 9.0, 6.0, -14.0, 4.0, 11.0, 10.0, -10.0, 14.0, 7.0, 10.0, -16.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 2.0, -15.0, 1.0, 14.0, 10.0, -10.0, 14.0, 14.0, 0.0, -13.0, 316.0, 13.0, 11.0, 12.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, -1.0, -12.0, 1.0, 14.0, 10.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 12.0, 0.0, -4.0, 14.0, 14.0, 1.0, -14.0, 318.0, 14.0, 11.0, 11.0, 14.0, 14.0, 1.0, -14.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 2.0, -15.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0, 8.0, 8.0, 5.0, -6.0, 14.0, 14.0, 0.0, -13.0, 7.0, 14.0, 4.0, -10.0, 14.0, 14.0, 0.0, -13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49315066984577044, "mean_inference_ms": 2.028732208189028, "mean_action_processing_ms": 0.12162688418438208, "mean_env_wait_ms": 0.2872025890876689, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 426600, "agent_timesteps_total": 426519, "timers": {"learn_time_ms": 1.86, "learn_throughput": 17202.77, "update_time_ms": 4.68}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.938717842102051, "min_q": 0.9390138387680054, "max_q": 9.239616394042969, "mean_td_error": 0.31523239612579346, "model": {}}}, "num_steps_sampled": 426600, "num_agent_steps_sampled": 426519, "num_steps_trained": 126112, "num_agent_steps_trained": 126112, "last_target_update_ts": 426600, "num_target_updates": 789}, "done": false, "episodes_total": 8343, "training_iteration": 135, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-15", "timestamp": 1626859875, "time_this_iter_s": 1.1437511444091797, "time_total_s": 153.43859386444092, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 153.43859386444092, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 51.05, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-20.0, 11.0, 13.0, 11.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 12.0, 12.0, -18.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 11.0, 9.0, -14.0, 9.0, 6.0, 3.0, 8.0, -2.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 8.0, 13.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -2.0, 9.0, 12.0, -4.0, 9.0, 10.0, 13.0, -17.0, 9.0, 12.0, -15.0, 9.0, 10.0, -4.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, -6.0, 8.0, 12.0, 1.0, -3.0, 8.0, 13.0, -3.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 10.0, 12.0, 11.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 12.0, 3.0, -9.0, 9.0, -5.0, 9.0, 13.0, -2.0, 10.0, 12.0, 12.0, -19.0, 9.0, 12.0, -15.0, 9.0, -5.0, 9.0, 13.0, -2.0, -1.0, 12.0, 12.0, -8.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 8.0, 13.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 12.0, 12.0, -18.0, 9.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 8.0, 13.0, 12.0, -18.0, 13.0, 6.0, -13.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 8.0, 12.0, -14.0, 9.0, -3.0, 9.0, 13.0, -4.0, 10.0, 12.0, 12.0, -19.0, 8.0, 12.0, -14.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, 8.0, 14.0, 12.0, -19.0, 14.0, -3.0, 7.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 8.0, -1.0, -6.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -5.0, -7.0, 12.0, 14.0, 2.0, -13.0, 5.0, 14.0, -1.0, -3.0, 12.0, 14.0, 2.0, -13.0, 14.0, 13.0, -9.0, -3.0, 12.0, 14.0, 7.0, -18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49033071840915615, "mean_inference_ms": 2.020803208184232, "mean_action_processing_ms": 0.12098234428393419, "mean_env_wait_ms": 0.28587682069647047, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 429840, "agent_timesteps_total": 429759, "timers": {"learn_time_ms": 1.877, "learn_throughput": 17047.634, "update_time_ms": 4.175}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.616547584533691, "min_q": 0.6907692551612854, "max_q": 9.326918601989746, "mean_td_error": 0.35759758949279785, "model": {}}}, "num_steps_sampled": 429840, "num_agent_steps_sampled": 429759, "num_steps_trained": 127072, "num_agent_steps_trained": 127072, "last_target_update_ts": 429840, "num_target_updates": 795}, "done": false, "episodes_total": 8424, "training_iteration": 136, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-16", "timestamp": 1626859876, "time_this_iter_s": 1.157820224761963, "time_total_s": 154.59641408920288, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 154.59641408920288, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -5.0, -1.0, 13.0, -1.0, 14.0, -9.0, 11.0, 8.0, 0.0, -6.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 11.0, 3.0, -9.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 8.0, -8.0, 6.0, 9.0, 8.0, -5.0, -1.0, 13.0, 11.0, 4.0, -10.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, -2.0, 14.0, -8.0, 11.0, 8.0, -5.0, -1.0, 13.0, 2.0, -6.0, 9.0, 10.0, 8.0, -5.0, -1.0, 13.0, -1.0, 14.0, -9.0, 11.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, -2.0, 14.0, 12.0, -9.0, 8.0, -5.0, -1.0, 13.0, -1.0, 14.0, -3.0, 5.0, 8.0, -5.0, -1.0, 13.0, -2.0, 14.0, -9.0, 12.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 13.0, -4.0, 5.0, 8.0, 0.0, -6.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 2.0, -6.0, 9.0, 10.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 10.0, 12.0, 11.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 12.0, 3.0, -9.0, 9.0, -5.0, 9.0, 13.0, -2.0, 10.0, 12.0, 12.0, -19.0, 9.0, 12.0, -15.0, 9.0, -5.0, 9.0, 13.0, -2.0, -1.0, 12.0, 12.0, -8.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 8.0, 13.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 12.0, 12.0, -18.0, 9.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 8.0, 13.0, 12.0, -18.0, 13.0, 6.0, -13.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 8.0, 12.0, -14.0, 9.0, -3.0, 9.0, 13.0, -4.0, 10.0, 12.0, 12.0, -19.0, 8.0, 12.0, -14.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0, -3.0, 9.0, 13.0, -4.0, 9.0, 12.0, 12.0, -18.0, 9.0, 12.0, -15.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48781469724679105, "mean_inference_ms": 2.015674935900067, "mean_action_processing_ms": 0.12062324174020742, "mean_env_wait_ms": 0.28465729898424896, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 433080, "agent_timesteps_total": 432999, "timers": {"learn_time_ms": 2.069, "learn_throughput": 15462.694, "update_time_ms": 5.413}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.682887077331543, "min_q": 0.8705461621284485, "max_q": 9.278366088867188, "mean_td_error": -20.4951229095459, "model": {}}}, "num_steps_sampled": 433080, "num_agent_steps_sampled": 432999, "num_steps_trained": 128032, "num_agent_steps_trained": 128032, "last_target_update_ts": 433080, "num_target_updates": 801}, "done": false, "episodes_total": 8478, "training_iteration": 137, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-17", "timestamp": 1626859877, "time_this_iter_s": 1.200423002243042, "time_total_s": 155.79683709144592, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daa60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 155.79683709144592, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 50.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.81, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.4525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -3.0, 8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, 4.0, 14.0, -6.0, 3.0, 13.0, 3.0, 2.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, -10.0, 12.0, 7.0, 6.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, -4.0, -2.0, 11.0, 10.0, -1.0, 13.0, -9.0, 12.0, 13.0, 13.0, -8.0, -3.0, -10.0, 14.0, 8.0, 3.0, 8.0, 5.0, -9.0, 11.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, -5.0, 12.0, 12.0, -4.0, 13.0, 13.0, -8.0, -3.0, -16.0, 12.0, 7.0, 12.0, 13.0, 3.0, -12.0, 11.0, 9.0, 12.0, -1.0, -5.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 7.0, -16.0, 11.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, 1.0, 13.0, -7.0, 8.0, 13.0, 13.0, -8.0, -3.0, -1.0, 9.0, -5.0, 12.0, 13.0, 13.0, -8.0, -3.0, 4.0, 11.0, -7.0, 7.0, 11.0, 9.0, -17.0, 12.0, -1.0, 11.0, -7.0, 12.0, 14.0, 14.0, 318.0, 10.0, 1.0, 11.0, -9.0, 12.0, 13.0, 13.0, -8.0, -3.0, 7.0, 14.0, -4.0, -2.0, 13.0, 8.0, -3.0, -3.0, 7.0, 14.0, -5.0, -1.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, 8.0, 11.0, -3.0, -1.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 8.0, 6.0, 4.0, -3.0, -2.0, 11.0, -6.0, 12.0, 13.0, 14.0, 317.0, 11.0, -1.0, 11.0, -7.0, 12.0, 8.0, -5.0, -1.0, 13.0, 11.0, 3.0, -9.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 8.0, -8.0, 6.0, 9.0, 8.0, -5.0, -1.0, 13.0, 11.0, 4.0, -10.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, -2.0, 14.0, -8.0, 11.0, 8.0, -5.0, -1.0, 13.0, 2.0, -6.0, 9.0, 10.0, 8.0, -5.0, -1.0, 13.0, -1.0, 14.0, -9.0, 11.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, -2.0, 14.0, 12.0, -9.0, 8.0, -5.0, -1.0, 13.0, -1.0, 14.0, -3.0, 5.0, 8.0, -5.0, -1.0, 13.0, -2.0, 14.0, -9.0, 12.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 13.0, -4.0, 5.0, 8.0, 0.0, -6.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 1.0, 9.0, -5.0, 10.0, 8.0, -5.0, -1.0, 13.0, 2.0, -6.0, 9.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4933123743361638, "mean_inference_ms": 2.0292205744566743, "mean_action_processing_ms": 0.12167392601715508, "mean_env_wait_ms": 0.28732044015925334, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 436320, "agent_timesteps_total": 436239, "timers": {"learn_time_ms": 1.944, "learn_throughput": 16464.393, "update_time_ms": 4.3}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.239656925201416, "min_q": 0.7753371596336365, "max_q": 9.218622207641602, "mean_td_error": 0.5600243806838989, "model": {}}}, "num_steps_sampled": 436320, "num_agent_steps_sampled": 436239, "num_steps_trained": 128992, "num_agent_steps_trained": 128992, "last_target_update_ts": 436320, "num_target_updates": 807}, "done": false, "episodes_total": 8532, "training_iteration": 138, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-18", "timestamp": 1626859878, "time_this_iter_s": 1.146695852279663, "time_total_s": 156.9435329437256, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 156.9435329437256, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 173.96, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 43.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 354.0, 15.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 5.0, -2.0, 6.0, 6.0, 13.0, 10.0, 13.0, 317.0, -2.0, 0.0, 9.0, 8.0, 12.0, 8.0, 13.0, -18.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 318.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 318.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, -1.0, 0.0, 8.0, 8.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 316.0, 13.0, 13.0, 11.0, 13.0, 10.0, 13.0, 318.0, 5.0, -2.0, 6.0, 6.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, -6.0, -2.0, 13.0, 10.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, -18.0, 13.0, 8.0, 12.0, 13.0, 10.0, 13.0, 318.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 9.0, 11.0, -18.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 318.0, -13.0, 13.0, 5.0, 10.0, 13.0, 10.0, 13.0, 317.0, 13.0, 13.0, -8.0, -3.0, -10.0, 12.0, 7.0, 6.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, -4.0, -2.0, 11.0, 10.0, -1.0, 13.0, -9.0, 12.0, 13.0, 13.0, -8.0, -3.0, -10.0, 14.0, 8.0, 3.0, 8.0, 5.0, -9.0, 11.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, -5.0, 12.0, 12.0, -4.0, 13.0, 13.0, -8.0, -3.0, -16.0, 12.0, 7.0, 12.0, 13.0, 3.0, -12.0, 11.0, 9.0, 12.0, -1.0, -5.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 7.0, -16.0, 11.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, 1.0, 13.0, -7.0, 8.0, 13.0, 13.0, -8.0, -3.0, -1.0, 9.0, -5.0, 12.0, 13.0, 13.0, -8.0, -3.0, 4.0, 11.0, -7.0, 7.0, 11.0, 9.0, -17.0, 12.0, -1.0, 11.0, -7.0, 12.0, 14.0, 14.0, 318.0, 10.0, 1.0, 11.0, -9.0, 12.0, 13.0, 13.0, -8.0, -3.0, 7.0, 14.0, -4.0, -2.0, 13.0, 8.0, -3.0, -3.0, 7.0, 14.0, -5.0, -1.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 13.0, 13.0, -8.0, -3.0, 8.0, 11.0, -3.0, -1.0, 13.0, 13.0, -8.0, -3.0, -1.0, 11.0, -7.0, 12.0, 8.0, 6.0, 4.0, -3.0, -2.0, 11.0, -6.0, 12.0, 13.0, 14.0, 317.0, 11.0, -1.0, 11.0, -7.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49337643715807106, "mean_inference_ms": 2.0292527548730237, "mean_action_processing_ms": 0.12168370097833088, "mean_env_wait_ms": 0.28735035548668947, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 438480, "agent_timesteps_total": 438399, "timers": {"learn_time_ms": 1.847, "learn_throughput": 17324.676, "update_time_ms": 4.989}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.099550247192383, "min_q": 0.81385338306427, "max_q": 9.253993034362793, "mean_td_error": 1.1247279644012451, "model": {}}}, "num_steps_sampled": 438480, "num_agent_steps_sampled": 438399, "num_steps_trained": 129632, "num_agent_steps_trained": 129632, "last_target_update_ts": 438480, "num_target_updates": 811}, "done": false, "episodes_total": 8586, "training_iteration": 139, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-19", "timestamp": 1626859879, "time_this_iter_s": 0.9645402431488037, "time_total_s": 157.9080731868744, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 157.9080731868744, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 45.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 153.64, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 38.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 353.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 354.0, 15.0, 353.0, 353.0, 353.0, 15.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 15.0, 353.0, 354.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-20.0, 13.0, 9.0, 13.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -5.0, 8.0, 0.0, 12.0, 13.0, -7.0, 11.0, -2.0, 6.0, 12.0, -15.0, 12.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -20.0, 13.0, 9.0, 13.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 1.0, 5.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -9.0, 11.0, 1.0, 12.0, 13.0, -7.0, 11.0, -2.0, -5.0, 2.0, 5.0, 13.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, 7.0, 13.0, -12.0, 7.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, 8.0, 8.0, -13.0, 12.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, 318.0, 11.0, 12.0, 11.0, 8.0, -16.0, 12.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 318.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 318.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, -1.0, 0.0, 8.0, 8.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 316.0, 13.0, 13.0, 11.0, 13.0, 10.0, 13.0, 318.0, 5.0, -2.0, 6.0, 6.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, -6.0, -2.0, 13.0, 10.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, -18.0, 13.0, 8.0, 12.0, 13.0, 10.0, 13.0, 318.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 317.0, 315.0, 13.0, 13.0, 12.0, 13.0, 9.0, 11.0, -18.0, 315.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 318.0, -13.0, 13.0, 5.0, 10.0, 13.0, 10.0, 13.0, 317.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49344164326126516, "mean_inference_ms": 2.0293496426201556, "mean_action_processing_ms": 0.1216910029708518, "mean_env_wait_ms": 0.2874006780450463, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 441720, "agent_timesteps_total": 441639, "timers": {"learn_time_ms": 1.858, "learn_throughput": 17226.173, "update_time_ms": 4.151}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.896514892578125, "min_q": 0.8295344114303589, "max_q": 9.248396873474121, "mean_td_error": 1.3733643293380737, "model": {}}}, "num_steps_sampled": 441720, "num_agent_steps_sampled": 441639, "num_steps_trained": 130592, "num_agent_steps_trained": 130592, "last_target_update_ts": 441720, "num_target_updates": 817}, "done": false, "episodes_total": 8640, "training_iteration": 140, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-21", "timestamp": 1626859881, "time_this_iter_s": 1.1712546348571777, "time_total_s": 159.07932782173157, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 159.07932782173157, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 48.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 11.0, 9.0, -9.0, 8.0, -4.0, 3.0, 8.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 14.0, -6.0, 7.0, 0.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 14.0, -6.0, 7.0, 0.0, 10.0, -3.0, 3.0, 5.0, 5.0, 13.0, -3.0, 0.0, 3.0, 11.0, 9.0, -8.0, 12.0, -2.0, 1.0, 4.0, 9.0, 13.0, -2.0, -5.0, 8.0, -3.0, 12.0, -2.0, 14.0, -8.0, 0.0, 9.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, -16.0, 13.0, 11.0, 7.0, 4.0, 11.0, 9.0, -9.0, 8.0, -3.0, 2.0, 8.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, -10.0, 4.0, 11.0, 10.0, 14.0, -5.0, 4.0, 2.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 3.0, 11.0, 9.0, -8.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -4.0, 3.0, 6.0, 5.0, 13.0, -3.0, 0.0, 14.0, 11.0, 1.0, -11.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 8.0, -3.0, 2.0, 8.0, 5.0, 13.0, -3.0, 0.0, 3.0, 11.0, 9.0, -8.0, 10.0, -3.0, 2.0, 6.0, 0.0, 13.0, -3.0, 5.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, -14.0, 13.0, 11.0, 5.0, 4.0, 2.0, 12.0, -3.0, 12.0, 6.0, -13.0, 10.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 8.0, -3.0, 3.0, 7.0, 5.0, 13.0, -3.0, 0.0, 3.0, 6.0, 12.0, -6.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 3.0, 5.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 12.0, -3.0, 3.0, 3.0, -1.0, 13.0, 7.0, -4.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, 7.0, 13.0, -12.0, 7.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, 8.0, 8.0, -13.0, 12.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, 318.0, 11.0, 12.0, 11.0, 8.0, -16.0, 12.0, 13.0, -7.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4905087499982089, "mean_inference_ms": 2.0210429594902903, "mean_action_processing_ms": 0.12103635105248771, "mean_env_wait_ms": 0.28602969342919027, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 444960, "agent_timesteps_total": 444879, "timers": {"learn_time_ms": 1.873, "learn_throughput": 17082.784, "update_time_ms": 4.187}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.9126954078674316, "min_q": 0.7131683230400085, "max_q": 9.380450248718262, "mean_td_error": 1.40604829788208, "model": {}}}, "num_steps_sampled": 444960, "num_agent_steps_sampled": 444879, "num_steps_trained": 131552, "num_agent_steps_trained": 131552, "last_target_update_ts": 444960, "num_target_updates": 823}, "done": false, "episodes_total": 8721, "training_iteration": 141, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-22", "timestamp": 1626859882, "time_this_iter_s": 1.121964931488037, "time_total_s": 160.2012927532196, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 160.2012927532196, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 50.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, 13.0, 11.0, -18.0, 13.0, 13.0, -9.0, -2.0, 10.0, 4.0, 6.0, -5.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 10.0, 4.0, 6.0, -5.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 12.0, 318.0, 12.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, -1.0, 13.0, -9.0, 12.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, 12.0, 315.0, 13.0, 5.0, 6.0, -9.0, 13.0, 13.0, -9.0, -2.0, 13.0, -12.0, 2.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, -1.0, 9.0, -5.0, 12.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, -1.0, 12.0, 11.0, -7.0, 5.0, 13.0, -3.0, 0.0, 3.0, 11.0, 9.0, -8.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -4.0, 3.0, 6.0, 5.0, 13.0, -3.0, 0.0, 14.0, 11.0, 1.0, -11.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 8.0, -3.0, 2.0, 8.0, 5.0, 13.0, -3.0, 0.0, 3.0, 11.0, 9.0, -8.0, 10.0, -3.0, 2.0, 6.0, 0.0, 13.0, -3.0, 5.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, -14.0, 13.0, 11.0, 5.0, 4.0, 2.0, 12.0, -3.0, 12.0, 6.0, -13.0, 10.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 8.0, -3.0, 3.0, 7.0, 5.0, 13.0, -3.0, 0.0, 3.0, 6.0, 12.0, -6.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 3.0, 5.0, 5.0, 13.0, -3.0, 0.0, 4.0, 11.0, 9.0, -9.0, 12.0, -3.0, 3.0, 3.0, -1.0, 13.0, 7.0, -4.0, 4.0, 11.0, 9.0, -9.0, 10.0, -3.0, 2.0, 6.0, 5.0, 13.0, -3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4878103770199994, "mean_inference_ms": 2.015568830592686, "mean_action_processing_ms": 0.1206412090177826, "mean_env_wait_ms": 0.2847653943045397, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 448200, "agent_timesteps_total": 448119, "timers": {"learn_time_ms": 1.93, "learn_throughput": 16581.554, "update_time_ms": 5.07}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.899661064147949, "min_q": 0.6855393052101135, "max_q": 8.509378433227539, "mean_td_error": 0.04229417443275452, "model": {}}}, "num_steps_sampled": 448200, "num_agent_steps_sampled": 448119, "num_steps_trained": 132512, "num_agent_steps_trained": 132512, "last_target_update_ts": 448200, "num_target_updates": 829}, "done": false, "episodes_total": 8775, "training_iteration": 142, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-23", "timestamp": 1626859883, "time_this_iter_s": 1.1302878856658936, "time_total_s": 161.3315806388855, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 161.3315806388855, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 52.05, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 1.0, -3.0, 6.0, 14.0, -3.0, -2.0, 6.0, 13.0, -1.0, -6.0, 9.0, 14.0, -3.0, -2.0, 6.0, -3.0, 12.0, -3.0, 9.0, 14.0, -3.0, -2.0, 6.0, 14.0, 3.0, 4.0, -6.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, 10.0, 10.0, -19.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 12.0, 7.0, -3.0, -1.0, 14.0, -3.0, -2.0, 6.0, 14.0, 3.0, 4.0, -6.0, 13.0, -3.0, 5.0, 0.0, 2.0, 12.0, -11.0, 12.0, 11.0, -3.0, 9.0, -2.0, 2.0, 12.0, -11.0, 12.0, 13.0, -3.0, 10.0, -5.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, 3.0, 1.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 13.0, 3.0, -9.0, 8.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 7.0, 8.0, -8.0, 8.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 13.0, -1.0, -3.0, 6.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 13.0, -4.0, 2.0, 4.0, 6.0, 5.0, -8.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 6.0, 7.0, -3.0, 5.0, 14.0, -3.0, -2.0, 6.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 10.0, 4.0, 6.0, -5.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 12.0, 318.0, 12.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, -1.0, 13.0, -9.0, 12.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, 12.0, 315.0, 13.0, 5.0, 6.0, -9.0, 13.0, 13.0, -9.0, -2.0, 13.0, -12.0, 2.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, -1.0, 9.0, -5.0, 12.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, 13.0, 13.0, -9.0, -2.0, 9.0, -12.0, 6.0, 12.0, -1.0, 12.0, 11.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4932827959942425, "mean_inference_ms": 2.029157905768548, "mean_action_processing_ms": 0.12167127318783559, "mean_env_wait_ms": 0.2874080238793069, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 451440, "agent_timesteps_total": 451359, "timers": {"learn_time_ms": 2.016, "learn_throughput": 15871.546, "update_time_ms": 5.125}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.195449352264404, "min_q": 0.8545914888381958, "max_q": 9.194190979003906, "mean_td_error": 0.6212010979652405, "model": {}}}, "num_steps_sampled": 451440, "num_agent_steps_sampled": 451359, "num_steps_trained": 133472, "num_agent_steps_trained": 133472, "last_target_update_ts": 451440, "num_target_updates": 835}, "done": false, "episodes_total": 8829, "training_iteration": 143, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-24", "timestamp": 1626859884, "time_this_iter_s": 1.1759021282196045, "time_total_s": 162.5074827671051, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985058c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 162.5074827671051, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 49.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.4, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 3.0, -4.0, 7.0, 14.0, 12.0, -10.0, -1.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 8.0, 9.0, -9.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 8.0, 7.0, -6.0, 9.0, 10.0, -11.0, 7.0, 1.0, 13.0, -11.0, 12.0, 11.0, -20.0, 12.0, 12.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 8.0, 12.0, -12.0, 7.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, -1.0, 11.0, -2.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 9.0, -3.0, -5.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 5.0, -3.0, -1.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, -2.0, 11.0, -6.0, 12.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -16.0, 12.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 12.0, 319.0, 12.0, 12.0, 9.0, 10.0, -11.0, 7.0, 13.0, 9.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 8.0, 2.0, -7.0, 12.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, -3.0, -2.0, 6.0, 7.0, 8.0, -8.0, 8.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 13.0, -1.0, -3.0, 6.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 13.0, -4.0, 2.0, 4.0, 6.0, 5.0, -8.0, 12.0, 14.0, -3.0, -2.0, 6.0, 2.0, 12.0, -11.0, 12.0, 14.0, -3.0, -2.0, 6.0, 6.0, 7.0, -3.0, 5.0, 14.0, -3.0, -2.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4903328964063982, "mean_inference_ms": 2.0214309126622596, "mean_action_processing_ms": 0.12102455406618307, "mean_env_wait_ms": 0.2860712558449017, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 454680, "agent_timesteps_total": 454599, "timers": {"learn_time_ms": 2.018, "learn_throughput": 15857.857, "update_time_ms": 4.717}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.898948669433594, "min_q": 0.8163012266159058, "max_q": 9.14303970336914, "mean_td_error": -9.711663246154785, "model": {}}}, "num_steps_sampled": 454680, "num_agent_steps_sampled": 454599, "num_steps_trained": 134432, "num_agent_steps_trained": 134432, "last_target_update_ts": 454680, "num_target_updates": 841}, "done": false, "episodes_total": 8910, "training_iteration": 144, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-25", "timestamp": 1626859885, "time_this_iter_s": 1.1658496856689453, "time_total_s": 163.67333245277405, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 163.67333245277405, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 48.3, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 93.35, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 23.3375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [356.0, 15.0, 15.0, 15.0, 356.0, 353.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 354.0, 356.0, 353.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 357.0, 15.0, 15.0, 15.0, 356.0, 15.0, 356.0, 15.0, 15.0, 15.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, -19.0, 8.0, 13.0, 13.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 13.0, 315.0, 13.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 7.0, 8.0, 11.0, -11.0, 12.0, 2.0, -2.0, 3.0, -1.0, 12.0, 7.0, -3.0, 12.0, 3.0, -3.0, 3.0, 12.0, 7.0, -3.0, -1.0, 12.0, 3.0, -3.0, 3.0, 12.0, 7.0, 7.0, -11.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 10.0, -3.0, 12.0, -4.0, 13.0, 10.0, 318.0, 13.0, 12.0, 13.0, 11.0, 320.0, 13.0, 11.0, 316.0, 13.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 321.0, 12.0, 3.0, -3.0, 3.0, 7.0, 13.0, -2.0, -3.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 6.0, 3.0, -2.0, 8.0, 9.0, -17.0, 12.0, 11.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 9.0, 10.0, -11.0, 7.0, 8.0, 12.0, -12.0, 7.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, -1.0, 11.0, -2.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 9.0, -3.0, -5.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 5.0, -3.0, -1.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, -2.0, 11.0, -6.0, 12.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -16.0, 12.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 12.0, 319.0, 12.0, 12.0, 9.0, 10.0, -11.0, 7.0, 13.0, 9.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 8.0, 2.0, -7.0, 12.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0, 14.0, 8.0, -3.0, -4.0, 6.0, 0.0, 12.0, -3.0, 9.0, 10.0, -11.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4877061784392604, "mean_inference_ms": 2.0161324732404013, "mean_action_processing_ms": 0.1206411600789043, "mean_env_wait_ms": 0.2848193051633416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 457920, "agent_timesteps_total": 457839, "timers": {"learn_time_ms": 1.895, "learn_throughput": 16885.919, "update_time_ms": 3.913}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.578664779663086, "min_q": 0.9068416357040405, "max_q": 8.89707088470459, "mean_td_error": 0.29239776730537415, "model": {}}}, "num_steps_sampled": 457920, "num_agent_steps_sampled": 457839, "num_steps_trained": 135392, "num_agent_steps_trained": 135392, "last_target_update_ts": 457920, "num_target_updates": 847}, "done": false, "episodes_total": 8964, "training_iteration": 145, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-26", "timestamp": 1626859886, "time_this_iter_s": 1.1387245655059814, "time_total_s": 164.81205701828003, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 164.81205701828003, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 51.150000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 76.34, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 19.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 354.0, 356.0, 353.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0, 357.0, 15.0, 15.0, 15.0, 356.0, 15.0, 356.0, 15.0, 15.0, 15.0, 356.0, 15.0, 356.0, 15.0, 356.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 9.0, 1.0, 6.0, -1.0, 9.0, -2.0, 12.0, -4.0, 7.0, 2.0, -6.0, 12.0, 12.0, -8.0, 11.0, 0.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 9.0, 2.0, 5.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, -6.0, 12.0, 12.0, 7.0, 10.0, -14.0, -5.0, 5.0, 5.0, 10.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 6.0, 3.0, 7.0, -1.0, 12.0, -5.0, 11.0, -3.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 4.0, 11.0, -12.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 9.0, 6.0, 2.0, -2.0, 12.0, 7.0, 10.0, -14.0, 8.0, 10.0, -13.0, 10.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 4.0, 11.0, -12.0, 9.0, 4.0, 4.0, -2.0, 12.0, 7.0, 10.0, -14.0, 7.0, 11.0, -1.0, -2.0, 12.0, 7.0, 10.0, -14.0, 9.0, 2.0, 5.0, -1.0, 12.0, 7.0, 10.0, -14.0, 9.0, 2.0, 5.0, -1.0, 12.0, -8.0, 10.0, 1.0, 9.0, 4.0, 7.0, -5.0, 12.0, 7.0, 10.0, -14.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 7.0, 8.0, 11.0, -11.0, 12.0, 2.0, -2.0, 3.0, -1.0, 12.0, 7.0, -3.0, 12.0, 3.0, -3.0, 3.0, 12.0, 7.0, -3.0, -1.0, 12.0, 3.0, -3.0, 3.0, 12.0, 7.0, 7.0, -11.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 10.0, -3.0, 12.0, -4.0, 13.0, 10.0, 318.0, 13.0, 12.0, 13.0, 11.0, 320.0, 13.0, 11.0, 316.0, 13.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 321.0, 12.0, 3.0, -3.0, 3.0, 7.0, 13.0, -2.0, -3.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 6.0, 3.0, -2.0, 8.0, 9.0, -17.0, 12.0, 11.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0, 12.0, 13.0, 11.0, 320.0, 12.0, 3.0, -3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4931710857808125, "mean_inference_ms": 2.029701376238478, "mean_action_processing_ms": 0.12168776189112045, "mean_env_wait_ms": 0.2874692404533744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 460080, "agent_timesteps_total": 459999, "timers": {"learn_time_ms": 1.829, "learn_throughput": 17496.543, "update_time_ms": 4.264}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.842436790466309, "min_q": 0.8470020294189453, "max_q": 9.073160171508789, "mean_td_error": 1.3461811542510986, "model": {}}}, "num_steps_sampled": 460080, "num_agent_steps_sampled": 459999, "num_steps_trained": 136032, "num_agent_steps_trained": 136032, "last_target_update_ts": 460080, "num_target_updates": 851}, "done": false, "episodes_total": 9018, "training_iteration": 146, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-28", "timestamp": 1626859888, "time_this_iter_s": 0.9607334136962891, "time_total_s": 165.77279043197632, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985052f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 165.77279043197632, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 38.3, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 12.0, 13.0, -9.0, -7.0, 14.0, 12.0, -4.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -7.0, 14.0, 12.0, -4.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -2.0, 12.0, 13.0, -8.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -8.0, 14.0, 13.0, -4.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -16.0, 12.0, 13.0, 6.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, 11.0, -2.0, 13.0, -7.0, -5.0, 13.0, 13.0, -6.0, -1.0, 12.0, 13.0, -9.0, -4.0, 13.0, 13.0, -7.0, -1.0, 12.0, 13.0, -9.0, -7.0, 14.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -7.0, 14.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -4.0, 13.0, 13.0, -7.0, 12.0, -2.0, 13.0, -8.0, -8.0, 13.0, 13.0, -3.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, 9.0, 2.0, 5.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, -6.0, 12.0, 12.0, 7.0, 10.0, -14.0, -5.0, 5.0, 5.0, 10.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 6.0, 3.0, 7.0, -1.0, 12.0, -5.0, 11.0, -3.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 4.0, 11.0, -12.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 9.0, 6.0, 2.0, -2.0, 12.0, 7.0, 10.0, -14.0, 8.0, 10.0, -13.0, 10.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 7.0, 10.0, -14.0, 7.0, 2.0, 7.0, -1.0, 12.0, 4.0, 11.0, -12.0, 9.0, 4.0, 4.0, -2.0, 12.0, 7.0, 10.0, -14.0, 7.0, 11.0, -1.0, -2.0, 12.0, 7.0, 10.0, -14.0, 9.0, 2.0, 5.0, -1.0, 12.0, 7.0, 10.0, -14.0, 9.0, 2.0, 5.0, -1.0, 12.0, -8.0, 10.0, 1.0, 9.0, 4.0, 7.0, -5.0, 12.0, 7.0, 10.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49311813018652095, "mean_inference_ms": 2.029786458569747, "mean_action_processing_ms": 0.12168279767789615, "mean_env_wait_ms": 0.2874506560500635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 463320, "agent_timesteps_total": 463239, "timers": {"learn_time_ms": 2.047, "learn_throughput": 15633.435, "update_time_ms": 4.873}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.815741539001465, "min_q": 0.9684094190597534, "max_q": 9.145035743713379, "mean_td_error": 0.06744384765625, "model": {}}}, "num_steps_sampled": 463320, "num_agent_steps_sampled": 463239, "num_steps_trained": 136992, "num_agent_steps_trained": 136992, "last_target_update_ts": 463320, "num_target_updates": 857}, "done": false, "episodes_total": 9072, "training_iteration": 147, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-29", "timestamp": 1626859889, "time_this_iter_s": 1.1830978393554688, "time_total_s": 166.9558882713318, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 166.9558882713318, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, 0.0, 4.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 2.0, 12.0, -11.0, 12.0, -4.0, 8.0, -1.0, 12.0, 3.0, 12.0, -8.0, 8.0, -4.0, 9.0, -2.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, -15.0, 12.0, 11.0, 7.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 10.0, -3.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, -2.0, 13.0, -2.0, 6.0, -3.0, 11.0, -3.0, 10.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -1.0, 5.0, -1.0, 12.0, -2.0, 12.0, -7.0, 12.0, -2.0, 10.0, -4.0, 11.0, 3.0, 13.0, -8.0, 7.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -3.0, 8.0, -1.0, 11.0, 5.0, 12.0, -10.0, 8.0, -4.0, 8.0, -1.0, 12.0, 0.0, 13.0, -10.0, 12.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 10.0, -3.0, 12.0, 4.0, 12.0, -11.0, 10.0, -3.0, 11.0, -3.0, 10.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -1.0, 5.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 5.0, 12.0, -8.0, 6.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -2.0, 12.0, 13.0, -8.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -8.0, 14.0, 13.0, -4.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -16.0, 12.0, 13.0, 6.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, 11.0, -2.0, 13.0, -7.0, -5.0, 13.0, 13.0, -6.0, -1.0, 12.0, 13.0, -9.0, -4.0, 13.0, 13.0, -7.0, -1.0, 12.0, 13.0, -9.0, -7.0, 14.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -7.0, 14.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -4.0, 13.0, 13.0, -7.0, 12.0, -2.0, 13.0, -8.0, -8.0, 13.0, 13.0, -3.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0, -1.0, 12.0, 13.0, -9.0, -5.0, 12.0, 13.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4931358421229925, "mean_inference_ms": 2.0299290239355776, "mean_action_processing_ms": 0.12169171968776854, "mean_env_wait_ms": 0.2874489112131718, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 466560, "agent_timesteps_total": 466479, "timers": {"learn_time_ms": 1.943, "learn_throughput": 16468.029, "update_time_ms": 4.835}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.37394905090332, "min_q": 0.8862762451171875, "max_q": 9.26288890838623, "mean_td_error": 1.1578342914581299, "model": {}}}, "num_steps_sampled": 466560, "num_agent_steps_sampled": 466479, "num_steps_trained": 137952, "num_agent_steps_trained": 137952, "last_target_update_ts": 466560, "num_target_updates": 863}, "done": false, "episodes_total": 9126, "training_iteration": 148, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-30", "timestamp": 1626859890, "time_this_iter_s": 1.1651453971862793, "time_total_s": 168.12103366851807, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 168.12103366851807, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 51.65, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -7.0, 1.0, 11.0, -19.0, 9.0, 12.0, 13.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, -1.0, 12.0, 12.0, -8.0, 13.0, -5.0, -6.0, 13.0, 5.0, -9.0, 6.0, 13.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, -8.0, 8.0, 5.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, -3.0, 4.0, 4.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, -7.0, -3.0, 12.0, 13.0, 13.0, -6.0, 1.0, 7.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, -4.0, 10.0, -3.0, 12.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, -7.0, -3.0, 12.0, 13.0, 13.0, -5.0, -6.0, 13.0, -5.0, 3.0, 7.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, -3.0, 12.0, -4.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -7.0, -3.0, 12.0, 10.0, -7.0, 1.0, 11.0, -2.0, 10.0, 12.0, -5.0, 13.0, -4.0, -6.0, 12.0, 10.0, 12.0, -17.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 3.0, 11.0, 12.0, -11.0, 13.0, -15.0, 6.0, 11.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, 7.0, 6.0, -8.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, 7.0, 1.0, -3.0, 1.0, 11.0, 12.0, -9.0, 13.0, -6.0, -3.0, 11.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 11.0, 6.0, 5.0, -7.0, 1.0, 11.0, 12.0, -9.0, 13.0, -4.0, -6.0, 12.0, -6.0, 5.0, 6.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 10.0, 12.0, -8.0, 14.0, -6.0, -6.0, 13.0, 10.0, -13.0, 6.0, 12.0, 1.0, 11.0, 12.0, -9.0, 12.0, -6.0, 2.0, 7.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 10.0, -3.0, 12.0, 4.0, 12.0, -11.0, 10.0, -3.0, 11.0, -3.0, 10.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -1.0, 5.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 5.0, 12.0, -8.0, 6.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0, -4.0, 8.0, -1.0, 12.0, 4.0, 12.0, -11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4902816120483207, "mean_inference_ms": 2.021508384077529, "mean_action_processing_ms": 0.12103160762297556, "mean_env_wait_ms": 0.2860297723297654, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 469800, "agent_timesteps_total": 469719, "timers": {"learn_time_ms": 1.819, "learn_throughput": 17594.48, "update_time_ms": 4.266}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.356860160827637, "min_q": 0.9132658243179321, "max_q": 9.049842834472656, "mean_td_error": 0.06579656898975372, "model": {}}}, "num_steps_sampled": 469800, "num_agent_steps_sampled": 469719, "num_steps_trained": 138912, "num_agent_steps_trained": 138912, "last_target_update_ts": 469800, "num_target_updates": 869}, "done": false, "episodes_total": 9207, "training_iteration": 149, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-31", "timestamp": 1626859891, "time_this_iter_s": 1.154099702835083, "time_total_s": 169.27513337135315, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985412f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 169.27513337135315, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 49.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 3.0, 13.0, 4.0, 8.0, 14.0, -9.0, 2.0, -4.0, 3.0, 13.0, 3.0, -10.0, 14.0, 2.0, 9.0, -5.0, 4.0, 13.0, 3.0, -4.0, 14.0, 3.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -6.0, 5.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -6.0, 5.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, -6.0, 14.0, 2.0, 5.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -4.0, 7.0, 13.0, -1.0, -13.0, 14.0, 6.0, 8.0, -5.0, 4.0, 13.0, 3.0, 7.0, 14.0, -8.0, 2.0, -5.0, 4.0, 13.0, 3.0, -12.0, 12.0, 2.0, 13.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -4.0, 3.0, 13.0, 3.0, 8.0, 14.0, -14.0, 7.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 1.0, 13.0, 6.0, 8.0, 14.0, -9.0, 2.0, -3.0, 3.0, 2.0, 13.0, 8.0, 14.0, -9.0, 2.0, -4.0, 7.0, 13.0, -1.0, 8.0, 14.0, -14.0, 7.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -8.0, 6.0, 13.0, 4.0, 8.0, 14.0, -8.0, 1.0, -3.0, 8.0, -2.0, 12.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, -5.0, 14.0, 3.0, 3.0, 13.0, -5.0, -6.0, 13.0, -3.0, 12.0, -4.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -7.0, -3.0, 12.0, 10.0, -7.0, 1.0, 11.0, -2.0, 10.0, 12.0, -5.0, 13.0, -4.0, -6.0, 12.0, 10.0, 12.0, -17.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 3.0, 11.0, 12.0, -11.0, 13.0, -15.0, 6.0, 11.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, 7.0, 6.0, -8.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, 7.0, 1.0, -3.0, 1.0, 11.0, 12.0, -9.0, 13.0, -6.0, -3.0, 11.0, 10.0, -7.0, 1.0, 11.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 11.0, 6.0, 5.0, -7.0, 1.0, 11.0, 12.0, -9.0, 13.0, -4.0, -6.0, 12.0, -6.0, 5.0, 6.0, 10.0, 1.0, 11.0, 12.0, -9.0, 13.0, -5.0, -6.0, 13.0, 10.0, -7.0, 1.0, 11.0, 1.0, 10.0, 12.0, -8.0, 14.0, -6.0, -6.0, 13.0, 10.0, -13.0, 6.0, 12.0, 1.0, 11.0, 12.0, -9.0, 12.0, -6.0, 2.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4875727788538578, "mean_inference_ms": 2.015653396184481, "mean_action_processing_ms": 0.12059719046334581, "mean_env_wait_ms": 0.2846826562874828, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 473040, "agent_timesteps_total": 472959, "timers": {"learn_time_ms": 1.896, "learn_throughput": 16873.606, "update_time_ms": 4.876}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.5158233642578125, "min_q": 0.7457617521286011, "max_q": 9.26396369934082, "mean_td_error": -9.65267562866211, "model": {}}}, "num_steps_sampled": 473040, "num_agent_steps_sampled": 472959, "num_steps_trained": 139872, "num_agent_steps_trained": 139872, "last_target_update_ts": 473040, "num_target_updates": 875}, "done": false, "episodes_total": 9261, "training_iteration": 150, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-32", "timestamp": 1626859892, "time_this_iter_s": 1.1219556331634521, "time_total_s": 170.3970890045166, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985419d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 170.3970890045166, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 51.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 13.0, 10.0, 13.0, 316.0, -4.0, -2.0, 11.0, 10.0, 12.0, -8.0, 5.0, 6.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, 0.0, -3.0, 5.0, 13.0, 11.0, -7.0, 6.0, 5.0, 8.0, -2.0, -1.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 9.0, -8.0, 9.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -1.0, -2.0, 8.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 10.0, -8.0, 10.0, 3.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 10.0, -6.0, 6.0, 5.0, -16.0, 11.0, 11.0, 9.0, 13.0, 6.0, 13.0, -17.0, -4.0, -2.0, 11.0, 10.0, 9.0, -8.0, 9.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, 8.0, 13.0, -17.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, 8.0, -2.0, 1.0, 8.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, 8.0, -4.0, 1.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, -6.0, 5.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -6.0, 5.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, -6.0, 14.0, 2.0, 5.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -4.0, 7.0, 13.0, -1.0, -13.0, 14.0, 6.0, 8.0, -5.0, 4.0, 13.0, 3.0, 7.0, 14.0, -8.0, 2.0, -5.0, 4.0, 13.0, 3.0, -12.0, 12.0, 2.0, 13.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -4.0, 3.0, 13.0, 3.0, 8.0, 14.0, -14.0, 7.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -5.0, 1.0, 13.0, 6.0, 8.0, 14.0, -9.0, 2.0, -3.0, 3.0, 2.0, 13.0, 8.0, 14.0, -9.0, 2.0, -4.0, 7.0, 13.0, -1.0, 8.0, 14.0, -14.0, 7.0, -5.0, 4.0, 13.0, 3.0, 8.0, 14.0, -9.0, 2.0, -8.0, 6.0, 13.0, 4.0, 8.0, 14.0, -8.0, 1.0, -3.0, 8.0, -2.0, 12.0, 8.0, 14.0, -9.0, 2.0, -5.0, 4.0, 13.0, 3.0, -5.0, 14.0, 3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49284872129462104, "mean_inference_ms": 2.02864893478587, "mean_action_processing_ms": 0.12159618855906823, "mean_env_wait_ms": 0.287206971397548, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 476280, "agent_timesteps_total": 476199, "timers": {"learn_time_ms": 1.884, "learn_throughput": 16984.211, "update_time_ms": 4.901}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.905219554901123, "min_q": 1.0142617225646973, "max_q": 9.16176700592041, "mean_td_error": 1.139176607131958, "model": {}}}, "num_steps_sampled": 476280, "num_agent_steps_sampled": 476199, "num_steps_trained": 140832, "num_agent_steps_trained": 140832, "last_target_update_ts": 476280, "num_target_updates": 881}, "done": false, "episodes_total": 9315, "training_iteration": 151, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-34", "timestamp": 1626859894, "time_this_iter_s": 1.1783006191253662, "time_total_s": 171.57538962364197, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dabf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 171.57538962364197, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 50.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 11.0, -5.0, 13.0, -4.0, -3.0, 10.0, 12.0, 8.0, 14.0, 11.0, -18.0, 3.0, 14.0, -11.0, 9.0, -5.0, -3.0, 11.0, 12.0, 7.0, 14.0, 11.0, -17.0, -4.0, 11.0, -5.0, 13.0, 10.0, -8.0, 11.0, 2.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 6.0, 14.0, 11.0, -16.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, 3.0, 13.0, -10.0, 9.0, -5.0, -3.0, 11.0, 12.0, 7.0, 14.0, 12.0, -18.0, -4.0, 11.0, -5.0, 13.0, 10.0, -17.0, 10.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 9.0, 13.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -1.0, 14.0, -11.0, 13.0, -5.0, -3.0, 11.0, 12.0, 12.0, 14.0, 7.0, -18.0, -4.0, 11.0, -5.0, 13.0, -18.0, 10.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -2.0, -1.0, 5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 9.0, 13.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -2.0, -1.0, 5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, -3.0, -4.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, 8.0, -2.0, 1.0, 8.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0, 11.0, -7.0, 6.0, 5.0, 8.0, -4.0, 1.0, 10.0, 11.0, -7.0, 6.0, 5.0, -4.0, -2.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48971610219331324, "mean_inference_ms": 2.019735831466414, "mean_action_processing_ms": 0.12090594494231283, "mean_env_wait_ms": 0.2857264922736761, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 479520, "agent_timesteps_total": 479439, "timers": {"learn_time_ms": 1.872, "learn_throughput": 17094.316, "update_time_ms": 4.926}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.5578107833862305, "min_q": 0.9332391023635864, "max_q": 9.367384910583496, "mean_td_error": 0.5287267565727234, "model": {}}}, "num_steps_sampled": 479520, "num_agent_steps_sampled": 479439, "num_steps_trained": 141792, "num_agent_steps_trained": 141792, "last_target_update_ts": 479520, "num_target_updates": 887}, "done": false, "episodes_total": 9396, "training_iteration": 152, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-35", "timestamp": 1626859895, "time_this_iter_s": 1.1237404346466064, "time_total_s": 172.69913005828857, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 172.69913005828857, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 52.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, -2.0, 10.0, 13.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -5.0, -4.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -1.0, -2.0, 5.0, 13.0, -7.0, -2.0, 12.0, 12.0, -2.0, -2.0, 11.0, 8.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -3.0, -7.0, 12.0, 13.0, 2.0, -2.0, 3.0, 12.0, -6.0, -2.0, 12.0, 11.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 11.0, 13.0, -7.0, -2.0, 12.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 6.0, 14.0, 11.0, -16.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, 3.0, 13.0, -10.0, 9.0, -5.0, -3.0, 11.0, 12.0, 7.0, 14.0, 12.0, -18.0, -4.0, 11.0, -5.0, 13.0, 10.0, -17.0, 10.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 9.0, 13.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -1.0, 14.0, -11.0, 13.0, -5.0, -3.0, 11.0, 12.0, 12.0, 14.0, 7.0, -18.0, -4.0, 11.0, -5.0, 13.0, -18.0, 10.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -2.0, -1.0, 5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 9.0, 13.0, 11.0, -18.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0, -2.0, -1.0, 5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, -3.0, -4.0, -4.0, 11.0, -5.0, 13.0, -5.0, -3.0, 11.0, 12.0, 8.0, 14.0, 11.0, -18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49241584996649485, "mean_inference_ms": 2.027708495074583, "mean_action_processing_ms": 0.1215927986783396, "mean_env_wait_ms": 0.28694411328628455, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 481680, "agent_timesteps_total": 481599, "timers": {"learn_time_ms": 1.975, "learn_throughput": 16205.76, "update_time_ms": 4.338}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.505007266998291, "min_q": 1.0498836040496826, "max_q": 9.424751281738281, "mean_td_error": -9.931623458862305, "model": {}}}, "num_steps_sampled": 481680, "num_agent_steps_sampled": 481599, "num_steps_trained": 142432, "num_agent_steps_trained": 142432, "last_target_update_ts": 481680, "num_target_updates": 891}, "done": false, "episodes_total": 9423, "training_iteration": 153, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-36", "timestamp": 1626859896, "time_this_iter_s": 1.0044786930084229, "time_total_s": 173.703608751297, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 173.703608751297, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 36.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 2.0, 3.0, 10.0, 13.0, 12.0, 316.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 4.0, -15.0, 13.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 8.0, 12.0, -18.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 3.0, 5.0, 10.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 0.0, 3.0, 2.0, 10.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 5.0, 0.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 10.0, 11.0, -19.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 2.0, -9.0, 13.0, 13.0, 7.0, -3.0, -2.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 11.0, -6.0, -3.0, 10.0, 9.0, -17.0, 13.0, 13.0, 9.0, -3.0, -4.0, 14.0, -11.0, 0.0, 12.0, 9.0, 0.0, -7.0, 13.0, 13.0, 5.0, -4.0, 1.0, 13.0, -8.0, -1.0, 11.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 7.0, -16.0, 11.0, -5.0, 11.0, -4.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 9.0, -4.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -2.0, -5.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 14.0, -1.0, -11.0, 13.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 0.0, 3.0, 2.0, 10.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 3.0, -5.0, 5.0, 12.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 14.0, 3.0, -15.0, 13.0, 1.0, 5.0, -4.0, 13.0, 13.0, 9.0, -3.0, -4.0, -7.0, -2.0, 12.0, 12.0, -5.0, -4.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -1.0, -2.0, 5.0, 13.0, -7.0, -2.0, 12.0, 12.0, -2.0, -2.0, 11.0, 8.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -3.0, -7.0, 12.0, 13.0, 2.0, -2.0, 3.0, 12.0, -6.0, -2.0, 12.0, 11.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 12.0, 12.0, -7.0, -2.0, 11.0, 13.0, -7.0, -2.0, 12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49323405914168, "mean_inference_ms": 2.028943368973982, "mean_action_processing_ms": 0.12167838035733934, "mean_env_wait_ms": 0.28747750247969517, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 484920, "agent_timesteps_total": 484839, "timers": {"learn_time_ms": 1.985, "learn_throughput": 16122.831, "update_time_ms": 5.621}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.781887531280518, "min_q": 0.9503735303878784, "max_q": 8.798309326171875, "mean_td_error": -9.815337181091309, "model": {}}}, "num_steps_sampled": 484920, "num_agent_steps_sampled": 484839, "num_steps_trained": 143392, "num_agent_steps_trained": 143392, "last_target_update_ts": 484920, "num_target_updates": 897}, "done": false, "episodes_total": 9504, "training_iteration": 154, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-37", "timestamp": 1626859897, "time_this_iter_s": 1.155414342880249, "time_total_s": 174.85902309417725, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 174.85902309417725, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 51.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 11.0, 11.0, -3.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -3.0, 11.0, -3.0, 10.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 14.0, -4.0, 2.0, 3.0, 316.0, 14.0, 11.0, 12.0, 9.0, -4.0, 5.0, 5.0, -5.0, 12.0, -4.0, 12.0, 9.0, -4.0, 5.0, 5.0, -4.0, 13.0, 10.0, -4.0, 9.0, -4.0, 5.0, 5.0, -5.0, 13.0, -2.0, 9.0, 14.0, -4.0, -4.0, 9.0, -6.0, 12.0, -3.0, 12.0, 11.0, 13.0, -18.0, 9.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -1.0, 12.0, -8.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -5.0, 13.0, -2.0, 9.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 14.0, -4.0, -4.0, 9.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 13.0, -4.0, 12.0, 9.0, -4.0, 5.0, 5.0, -5.0, 12.0, 11.0, -3.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, 316.0, 14.0, 11.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 10.0, 13.0, -20.0, 12.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -9.0, 14.0, -2.0, 12.0, 9.0, -4.0, 5.0, 5.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 10.0, 11.0, -19.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 2.0, -9.0, 13.0, 13.0, 7.0, -3.0, -2.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 11.0, -6.0, -3.0, 10.0, 9.0, -17.0, 13.0, 13.0, 9.0, -3.0, -4.0, 14.0, -11.0, 0.0, 12.0, 9.0, 0.0, -7.0, 13.0, 13.0, 5.0, -4.0, 1.0, 13.0, -8.0, -1.0, 11.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 7.0, -16.0, 11.0, -5.0, 11.0, -4.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 13.0, 9.0, -4.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -2.0, -5.0, 13.0, 6.0, -1.0, -3.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 14.0, -1.0, -11.0, 13.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 0.0, 3.0, 2.0, 10.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 3.0, -5.0, 5.0, 12.0, 9.0, 0.0, -7.0, 13.0, 13.0, 9.0, -3.0, -4.0, 14.0, 3.0, -15.0, 13.0, 1.0, 5.0, -4.0, 13.0, 13.0, 9.0, -3.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48714216975212854, "mean_inference_ms": 2.014613891295972, "mean_action_processing_ms": 0.12051501557052506, "mean_env_wait_ms": 0.2845160481725201, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 488160, "agent_timesteps_total": 488079, "timers": {"learn_time_ms": 1.777, "learn_throughput": 18004.202, "update_time_ms": 4.267}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.638652324676514, "min_q": 1.2697341442108154, "max_q": 8.768425941467285, "mean_td_error": 0.9643962383270264, "model": {}}}, "num_steps_sampled": 488160, "num_agent_steps_sampled": 488079, "num_steps_trained": 144352, "num_agent_steps_trained": 144352, "last_target_update_ts": 488160, "num_target_updates": 903}, "done": false, "episodes_total": 9558, "training_iteration": 155, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-38", "timestamp": 1626859898, "time_this_iter_s": 1.1408469676971436, "time_total_s": 175.9998700618744, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 175.9998700618744, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 49.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -2.0, 12.0, -7.0, 12.0, 7.0, -1.0, 10.0, -1.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -6.0, 9.0, 8.0, 4.0, 12.0, 13.0, 0.0, -10.0, -3.0, 11.0, 9.0, -2.0, 3.0, 12.0, 7.0, -7.0, -2.0, 12.0, -7.0, 12.0, 5.0, 10.0, 7.0, -7.0, -2.0, 8.0, 2.0, 7.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 11.0, 12.0, 3.0, -11.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 12.0, 12.0, 5.0, -14.0, -6.0, 9.0, 8.0, 4.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -2.0, 10.0, 7.0, 0.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 9.0, 14.0, 3.0, -11.0, -3.0, 11.0, 9.0, -2.0, 5.0, -3.0, 7.0, 6.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, 10.0, -2.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, 316.0, 14.0, 11.0, 12.0, 9.0, -4.0, 5.0, 5.0, -5.0, 12.0, -4.0, 12.0, 9.0, -4.0, 5.0, 5.0, -4.0, 13.0, 10.0, -4.0, 9.0, -4.0, 5.0, 5.0, -5.0, 13.0, -2.0, 9.0, 14.0, -4.0, -4.0, 9.0, -6.0, 12.0, -3.0, 12.0, 11.0, 13.0, -18.0, 9.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -1.0, 12.0, -8.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -5.0, 13.0, -2.0, 9.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 14.0, -4.0, -4.0, 9.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 13.0, -4.0, 12.0, 9.0, -4.0, 5.0, 5.0, -5.0, 12.0, 11.0, -3.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, 316.0, 14.0, 11.0, 12.0, 9.0, -4.0, 5.0, 5.0, -6.0, 12.0, -3.0, 12.0, 10.0, 13.0, -20.0, 12.0, -6.0, 12.0, -3.0, 12.0, 9.0, -4.0, 5.0, 5.0, -9.0, 14.0, -2.0, 12.0, 9.0, -4.0, 5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49253534219164036, "mean_inference_ms": 2.028003931041761, "mean_action_processing_ms": 0.12155773321552715, "mean_env_wait_ms": 0.28710191379726013, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 491400, "agent_timesteps_total": 491319, "timers": {"learn_time_ms": 1.794, "learn_throughput": 17839.088, "update_time_ms": 4.195}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.399191856384277, "min_q": 1.4420907497406006, "max_q": 9.259256362915039, "mean_td_error": 0.4006789028644562, "model": {}}}, "num_steps_sampled": 491400, "num_agent_steps_sampled": 491319, "num_steps_trained": 145312, "num_agent_steps_trained": 145312, "last_target_update_ts": 491400, "num_target_updates": 909}, "done": false, "episodes_total": 9612, "training_iteration": 156, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-39", "timestamp": 1626859899, "time_this_iter_s": 1.1233422756195068, "time_total_s": 177.1232123374939, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 177.1232123374939, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 51.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 2.0, 12.0, -17.0, 10.0, 13.0, 9.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 2.0, 12.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -3.0, 11.0, 3.0, 4.0, -1.0, 10.0, 13.0, -7.0, 9.0, 14.0, -3.0, -5.0, -7.0, 12.0, 3.0, 7.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -2.0, 11.0, 0.0, 6.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 4.0, 10.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, -3.0, 13.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -9.0, 8.0, 6.0, 10.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -9.0, 11.0, 1.0, 12.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -3.0, 10.0, 3.0, 5.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, -3.0, 13.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 13.0, -5.0, -3.0, -12.0, 11.0, 8.0, 8.0, 0.0, 10.0, 13.0, -8.0, 9.0, 14.0, -4.0, -4.0, -10.0, 11.0, 3.0, 11.0, 9.0, 13.0, 13.0, -20.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, -1.0, 10.0, 13.0, -7.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 9.0, 14.0, 3.0, -11.0, -3.0, 11.0, 9.0, -2.0, 5.0, -3.0, 7.0, 6.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, 10.0, -2.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0, -3.0, 11.0, 9.0, -2.0, 5.0, 10.0, 7.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4896146203745706, "mean_inference_ms": 2.019617121014294, "mean_action_processing_ms": 0.12089641380276558, "mean_env_wait_ms": 0.2857153889414842, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 494640, "agent_timesteps_total": 494559, "timers": {"learn_time_ms": 1.812, "learn_throughput": 17656.51, "update_time_ms": 4.155}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.539656639099121, "min_q": 1.1994712352752686, "max_q": 9.389174461364746, "mean_td_error": 0.9217310547828674, "model": {}}}, "num_steps_sampled": 494640, "num_agent_steps_sampled": 494559, "num_steps_trained": 146272, "num_agent_steps_trained": 146272, "last_target_update_ts": 494640, "num_target_updates": 915}, "done": false, "episodes_total": 9693, "training_iteration": 157, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-41", "timestamp": 1626859901, "time_this_iter_s": 1.1445667743682861, "time_total_s": 178.26777911186218, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 178.26777911186218, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 50.35, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 8.0, 11.0, -4.0, 6.0, 1.0, 10.0, -2.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 6.0, 1.0, 13.0, -5.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 10.0, -3.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, 0.0, 9.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, -5.0, 5.0, 9.0, 6.0, 7.0, -1.0, 10.0, -1.0, 13.0, -10.0, 6.0, 6.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, -7.0, 0.0, 11.0, 11.0, -5.0, 8.0, 6.0, 6.0, 13.0, -5.0, 13.0, -6.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 13.0, -11.0, 10.0, 3.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, 0.0, 11.0, -3.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 8.0, -1.0, 11.0, -3.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -14.0, 11.0, 11.0, 0.0, 8.0, 11.0, -4.0, 7.0, 0.0, 11.0, -3.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 9.0, -3.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 4.0, 10.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, -3.0, 13.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -9.0, 8.0, 6.0, 10.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -9.0, 11.0, 1.0, 12.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -3.0, 10.0, 3.0, 5.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, -3.0, 13.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 13.0, -5.0, -3.0, -12.0, 11.0, 8.0, 8.0, 0.0, 10.0, 13.0, -8.0, 9.0, 14.0, -4.0, -4.0, -10.0, 11.0, 3.0, 11.0, 9.0, 13.0, 13.0, -20.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 6.0, 13.0, 10.0, -14.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, 0.0, 10.0, 13.0, -8.0, 10.0, 14.0, -5.0, -4.0, -10.0, 11.0, 3.0, 11.0, -1.0, 10.0, 13.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4870381890743682, "mean_inference_ms": 2.0142805992514914, "mean_action_processing_ms": 0.12049241831545571, "mean_env_wait_ms": 0.2844773513040422, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 497880, "agent_timesteps_total": 497799, "timers": {"learn_time_ms": 1.974, "learn_throughput": 16211.437, "update_time_ms": 4.609}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.015254020690918, "min_q": 0.5491745471954346, "max_q": 9.561960220336914, "mean_td_error": 0.28205758333206177, "model": {}}}, "num_steps_sampled": 497880, "num_agent_steps_sampled": 497799, "num_steps_trained": 147232, "num_agent_steps_trained": 147232, "last_target_update_ts": 497880, "num_target_updates": 921}, "done": false, "episodes_total": 9747, "training_iteration": 158, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-42", "timestamp": 1626859902, "time_this_iter_s": 1.1591033935546875, "time_total_s": 179.42688250541687, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 179.42688250541687, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 51.150000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-23.0, 12.0, 13.0, 13.0, 3.0, 10.0, 12.0, -10.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, 314.0, 13.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, 314.0, 13.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -9.0, 13.0, 1.0, 10.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, 13.0, 13.0, -19.0, 8.0, -23.0, 12.0, 13.0, 13.0, -13.0, 13.0, 9.0, 6.0, -23.0, 12.0, 13.0, 13.0, -4.0, 6.0, 1.0, 12.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -9.0, 0.0, 13.0, 11.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -1.0, 13.0, -3.0, 6.0, -18.0, 12.0, 8.0, 13.0, -11.0, 12.0, 6.0, 8.0, 0.0, 8.0, 10.0, -3.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, 0.0, 9.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, -5.0, 5.0, 9.0, 6.0, 7.0, -1.0, 10.0, -1.0, 13.0, -10.0, 6.0, 6.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, -7.0, 0.0, 11.0, 11.0, -5.0, 8.0, 6.0, 6.0, 13.0, -5.0, 13.0, -6.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 13.0, -11.0, 10.0, 3.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, 0.0, 11.0, -3.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 8.0, -1.0, 11.0, -3.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -14.0, 11.0, 11.0, 0.0, 8.0, 11.0, -4.0, 7.0, 0.0, 11.0, -3.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 9.0, -3.0, 10.0, -1.0, 0.0, 8.0, 11.0, -4.0, 7.0, -1.0, 10.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4925699037343918, "mean_inference_ms": 2.0279612342408133, "mean_action_processing_ms": 0.12154085965767415, "mean_env_wait_ms": 0.28712691756319464, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 501120, "agent_timesteps_total": 501039, "timers": {"learn_time_ms": 1.891, "learn_throughput": 16924.245, "update_time_ms": 4.604}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.240914344787598, "min_q": 0.545397937297821, "max_q": 7.9761962890625, "mean_td_error": 1.4214668273925781, "model": {}}}, "num_steps_sampled": 501120, "num_agent_steps_sampled": 501039, "num_steps_trained": 148192, "num_agent_steps_trained": 148192, "last_target_update_ts": 501120, "num_target_updates": 927}, "done": false, "episodes_total": 9801, "training_iteration": 159, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-43", "timestamp": 1626859903, "time_this_iter_s": 1.175915002822876, "time_total_s": 180.60279750823975, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 180.60279750823975, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 48.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.14, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 6.285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -5.0, 0.0, 12.0, 13.0, -16.0, 8.0, 10.0, 6.0, -3.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 12.0, 0.0, -9.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 8.0, -15.0, 9.0, 13.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -3.0, -7.0, 12.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 6.0, -6.0, 11.0, 4.0, 13.0, -6.0, 10.0, -2.0, 8.0, -5.0, 0.0, 12.0, 4.0, -10.0, 11.0, 10.0, 8.0, -5.0, 0.0, 12.0, 8.0, -15.0, 10.0, 12.0, 6.0, -3.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 8.0, -16.0, 10.0, 13.0, 11.0, -8.0, 5.0, 7.0, 13.0, 317.0, 10.0, 13.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -3.0, 0.0, 10.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -16.0, 11.0, 7.0, 8.0, -5.0, 0.0, 12.0, 13.0, -19.0, 10.0, 11.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 14.0, -10.0, 8.0, 3.0, 13.0, -14.0, 6.0, 10.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, 314.0, 13.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, 314.0, 13.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -9.0, 13.0, 1.0, 10.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, 13.0, 13.0, -19.0, 8.0, -23.0, 12.0, 13.0, 13.0, -13.0, 13.0, 9.0, 6.0, -23.0, 12.0, 13.0, 13.0, -4.0, 6.0, 1.0, 12.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -11.0, 12.0, 6.0, 8.0, -9.0, 0.0, 13.0, 11.0, -11.0, 12.0, 6.0, 8.0, -23.0, 12.0, 13.0, 13.0, -1.0, 13.0, -3.0, 6.0, -18.0, 12.0, 8.0, 13.0, -11.0, 12.0, 6.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4926599689268508, "mean_inference_ms": 2.0283109514899276, "mean_action_processing_ms": 0.12155932064446442, "mean_env_wait_ms": 0.2871896370693376, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 503280, "agent_timesteps_total": 503199, "timers": {"learn_time_ms": 2.03, "learn_throughput": 15764.726, "update_time_ms": 4.59}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.203236103057861, "min_q": 0.6107080578804016, "max_q": 9.290154457092285, "mean_td_error": -10.245858192443848, "model": {}}}, "num_steps_sampled": 503280, "num_agent_steps_sampled": 503199, "num_steps_trained": 148832, "num_agent_steps_trained": 148832, "last_target_update_ts": 503280, "num_target_updates": 931}, "done": false, "episodes_total": 9855, "training_iteration": 160, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-44", "timestamp": 1626859904, "time_this_iter_s": 0.9753613471984863, "time_total_s": 181.57815885543823, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 181.57815885543823, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 45.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.38, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, 11.0, 13.0, -8.0, -1.0, 8.0, 9.0, -15.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 11.0, -20.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, 9.0, 12.0, -6.0, 0.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, 13.0, 11.0, -8.0, -1.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -7.0, 6.0, 9.0, 7.0, 7.0, 11.0, -16.0, 13.0, 9.0, 10.0, -5.0, 1.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, 0.0, 12.0, 8.0, -5.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 12.0, 9.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, 7.0, 12.0, -9.0, 5.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 11.0, -20.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -3.0, -7.0, 12.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 6.0, -6.0, 11.0, 4.0, 13.0, -6.0, 10.0, -2.0, 8.0, -5.0, 0.0, 12.0, 4.0, -10.0, 11.0, 10.0, 8.0, -5.0, 0.0, 12.0, 8.0, -15.0, 10.0, 12.0, 6.0, -3.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 8.0, -16.0, 10.0, 13.0, 11.0, -8.0, 5.0, 7.0, 13.0, 317.0, 10.0, 13.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 8.0, -3.0, 0.0, 10.0, 13.0, -14.0, 6.0, 10.0, 8.0, -5.0, 0.0, 12.0, 13.0, -16.0, 11.0, 7.0, 8.0, -5.0, 0.0, 12.0, 13.0, -19.0, 10.0, 11.0, 8.0, -5.0, 0.0, 12.0, 13.0, -14.0, 6.0, 10.0, 14.0, -10.0, 8.0, 3.0, 13.0, -14.0, 6.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49271394219771636, "mean_inference_ms": 2.0284826013110986, "mean_action_processing_ms": 0.12157615217325869, "mean_env_wait_ms": 0.28724073609610223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 506520, "agent_timesteps_total": 506439, "timers": {"learn_time_ms": 1.977, "learn_throughput": 16184.07, "update_time_ms": 4.673}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.147701263427734, "min_q": 0.47304511070251465, "max_q": 9.418988227844238, "mean_td_error": 0.1797667294740677, "model": {}}}, "num_steps_sampled": 506520, "num_agent_steps_sampled": 506439, "num_steps_trained": 149792, "num_agent_steps_trained": 149792, "last_target_update_ts": 506520, "num_target_updates": 937}, "done": false, "episodes_total": 9909, "training_iteration": 161, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-45", "timestamp": 1626859905, "time_this_iter_s": 1.168067455291748, "time_total_s": 182.74622631072998, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 182.74622631072998, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 50.05, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 89.14, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 22.285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 5.0, 3.0, 9.0, -2.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 10.0, 10.0, -16.0, 11.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -10.0, 13.0, 12.0, 0.0, 5.0, -1.0, 5.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 1.0, -8.0, 11.0, 11.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 12.0, 315.0, 11.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 12.0, -8.0, 5.0, 6.0, 14.0, 11.0, 315.0, 12.0, 9.0, -8.0, 12.0, 2.0, 9.0, 7.0, 11.0, -12.0, 14.0, 11.0, 315.0, 12.0, 9.0, -9.0, 12.0, 3.0, 8.0, -1.0, 2.0, 6.0, 14.0, 14.0, -21.0, 8.0, -4.0, 5.0, 12.0, 2.0, 9.0, 9.0, 9.0, -12.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 1.0, 11.0, 7.0, -4.0, -4.0, 5.0, 12.0, 2.0, 3.0, -3.0, 12.0, 3.0, 14.0, 11.0, 315.0, 12.0, 9.0, -8.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 13.0, -6.0, 4.0, 4.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 12.0, -8.0, 5.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 0.0, -3.0, 10.0, 8.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 12.0, -1.0, -2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 12.0, -1.0, -2.0, 6.0, 0.0, 13.0, -5.0, 7.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 11.0, -20.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0, -2.0, 1.0, 9.0, 7.0, 11.0, 10.0, -19.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4898523124674168, "mean_inference_ms": 2.0203239288968335, "mean_action_processing_ms": 0.12093236855599994, "mean_env_wait_ms": 0.28591697302955266, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 509760, "agent_timesteps_total": 509679, "timers": {"learn_time_ms": 1.9, "learn_throughput": 16842.481, "update_time_ms": 4.895}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.230681419372559, "min_q": 0.774695873260498, "max_q": 9.41593074798584, "mean_td_error": 0.7327636480331421, "model": {}}}, "num_steps_sampled": 509760, "num_agent_steps_sampled": 509679, "num_steps_trained": 150752, "num_agent_steps_trained": 150752, "last_target_update_ts": 509760, "num_target_updates": 943}, "done": false, "episodes_total": 9990, "training_iteration": 162, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-46", "timestamp": 1626859906, "time_this_iter_s": 1.1647334098815918, "time_total_s": 183.91095972061157, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 183.91095972061157, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 55.44, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 13.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -6.0, 9.0, -7.0, 13.0, 11.0, -2.0, 12.0, 0.0, -8.0, 11.0, 6.0, 12.0, 13.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 13.0, -1.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 12.0, 13.0, -16.0, 12.0, 0.0, -8.0, 11.0, 7.0, 13.0, 11.0, -16.0, 12.0, 0.0, -6.0, 9.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, -7.0, 14.0, 12.0, -4.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 3.0, 13.0, 12.0, -13.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -3.0, 6.0, -7.0, 13.0, 12.0, -3.0, 12.0, 0.0, -8.0, 11.0, -7.0, 13.0, 11.0, -2.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 13.0, -1.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 0.0, 13.0, 10.0, -8.0, 12.0, -2.0, -8.0, 13.0, 6.0, 13.0, 12.0, -16.0, 12.0, -5.0, -3.0, 11.0, 6.0, 13.0, 12.0, -16.0, 14.0, 0.0, -9.0, 10.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 12.0, -8.0, 5.0, 6.0, 14.0, 11.0, 315.0, 12.0, 9.0, -8.0, 12.0, 2.0, 9.0, 7.0, 11.0, -12.0, 14.0, 11.0, 315.0, 12.0, 9.0, -9.0, 12.0, 3.0, 8.0, -1.0, 2.0, 6.0, 14.0, 14.0, -21.0, 8.0, -4.0, 5.0, 12.0, 2.0, 9.0, 9.0, 9.0, -12.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 1.0, 11.0, 7.0, -4.0, -4.0, 5.0, 12.0, 2.0, 3.0, -3.0, 12.0, 3.0, 14.0, 11.0, 315.0, 12.0, 9.0, -8.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 13.0, -6.0, 4.0, 4.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 12.0, -8.0, 5.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 0.0, -3.0, 10.0, 8.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 12.0, -1.0, -2.0, 6.0, 14.0, 11.0, 315.0, 12.0, -4.0, 5.0, 12.0, 2.0, 12.0, -1.0, -2.0, 6.0, 0.0, 13.0, -5.0, 7.0, -4.0, 5.0, 12.0, 2.0, 8.0, -1.0, 2.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48731590958528576, "mean_inference_ms": 2.0150533764072187, "mean_action_processing_ms": 0.12054016331480298, "mean_env_wait_ms": 0.2847118094396282, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 513000, "agent_timesteps_total": 512919, "timers": {"learn_time_ms": 1.946, "learn_throughput": 16443.616, "update_time_ms": 4.982}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.556698799133301, "min_q": 0.5318084955215454, "max_q": 9.478270530700684, "mean_td_error": 0.21882203221321106, "model": {}}}, "num_steps_sampled": 513000, "num_agent_steps_sampled": 512919, "num_steps_trained": 151712, "num_agent_steps_trained": 151712, "last_target_update_ts": 513000, "num_target_updates": 949}, "done": false, "episodes_total": 10044, "training_iteration": 163, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-48", "timestamp": 1626859908, "time_this_iter_s": 1.1712820529937744, "time_total_s": 185.08224177360535, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 185.08224177360535, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 51.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 9.0, 7.0, -14.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 7.0, 6.0, -9.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 3.0, 7.0, -5.0, 10.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 9.0, 10.0, -17.0, 13.0, 14.0, -6.0, -4.0, 11.0, 9.0, 9.0, -16.0, 13.0, 10.0, -2.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 13.0, 314.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, -12.0, 7.0, 11.0, 10.0, 13.0, 10.0, -21.0, 13.0, 10.0, -2.0, -4.0, 11.0, 13.0, 11.0, -22.0, 13.0, 13.0, -6.0, -5.0, 13.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 13.0, 314.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -1.0, -9.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 0.0, 12.0, -10.0, 13.0, 14.0, -6.0, -4.0, 11.0, 1.0, 2.0, 13.0, -1.0, 14.0, -6.0, -4.0, 11.0, 13.0, 6.0, -17.0, 13.0, 14.0, -1.0, -9.0, 11.0, 13.0, 6.0, -17.0, 13.0, 14.0, -6.0, -4.0, 11.0, 9.0, 7.0, -14.0, 13.0, 14.0, -3.0, -4.0, 8.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 13.0, -1.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 12.0, 13.0, -16.0, 12.0, 0.0, -8.0, 11.0, 7.0, 13.0, 11.0, -16.0, 12.0, 0.0, -6.0, 9.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, -7.0, 14.0, 12.0, -4.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 3.0, 13.0, 12.0, -13.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -3.0, 6.0, -7.0, 13.0, 12.0, -3.0, 12.0, 0.0, -8.0, 11.0, -7.0, 13.0, 11.0, -2.0, 12.0, 0.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 13.0, -1.0, -8.0, 11.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0, 0.0, 13.0, 10.0, -8.0, 12.0, -2.0, -8.0, 13.0, 6.0, 13.0, 12.0, -16.0, 12.0, -5.0, -3.0, 11.0, 6.0, 13.0, 12.0, -16.0, 14.0, 0.0, -9.0, 10.0, 6.0, 13.0, 12.0, -16.0, 12.0, 0.0, -8.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49283047343992953, "mean_inference_ms": 2.0288111705872747, "mean_action_processing_ms": 0.12158629498911115, "mean_env_wait_ms": 0.2873301981538352, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 516240, "agent_timesteps_total": 516159, "timers": {"learn_time_ms": 1.897, "learn_throughput": 16867.881, "update_time_ms": 4.462}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.541244029998779, "min_q": 0.6868658661842346, "max_q": 9.004155158996582, "mean_td_error": 0.5290312767028809, "model": {}}}, "num_steps_sampled": 516240, "num_agent_steps_sampled": 516159, "num_steps_trained": 152672, "num_agent_steps_trained": 152672, "last_target_update_ts": 516240, "num_target_updates": 955}, "done": false, "episodes_total": 10098, "training_iteration": 164, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-49", "timestamp": 1626859909, "time_this_iter_s": 1.1809837818145752, "time_total_s": 186.26322555541992, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 186.26322555541992, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 50.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -7.0, 12.0, 5.0, 5.0, 8.0, 4.0, -4.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, 0.0, 8.0, -2.0, 9.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -10.0, 11.0, 4.0, 10.0, 13.0, 1.0, -6.0, 7.0, 7.0, -3.0, 13.0, -2.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -8.0, 10.0, 12.0, 1.0, 10.0, 3.0, -6.0, 8.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, 0.0, 11.0, -5.0, 9.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -6.0, 8.0, 3.0, 10.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -3.0, 13.0, -6.0, -1.0, 1.0, 4.0, 11.0, 7.0, 13.0, -4.0, -1.0, 11.0, -9.0, 13.0, 0.0, -6.0, 8.0, 4.0, 9.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -9.0, 8.0, 10.0, 6.0, 13.0, 8.0, -6.0, 0.0, 11.0, -4.0, 8.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -8.0, 10.0, 3.0, 10.0, 13.0, 1.0, 8.0, -7.0, 11.0, -9.0, 13.0, 0.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -1.0, -9.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 10.0, -21.0, 13.0, 14.0, -6.0, -4.0, 11.0, 0.0, 12.0, -10.0, 13.0, 14.0, -6.0, -4.0, 11.0, 1.0, 2.0, 13.0, -1.0, 14.0, -6.0, -4.0, 11.0, 13.0, 6.0, -17.0, 13.0, 14.0, -1.0, -9.0, 11.0, 13.0, 6.0, -17.0, 13.0, 14.0, -6.0, -4.0, 11.0, 9.0, 7.0, -14.0, 13.0, 14.0, -3.0, -4.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48990838117351715, "mean_inference_ms": 2.0207655786835867, "mean_action_processing_ms": 0.12094366744632414, "mean_env_wait_ms": 0.28596014415590276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 519480, "agent_timesteps_total": 519399, "timers": {"learn_time_ms": 1.916, "learn_throughput": 16702.888, "update_time_ms": 4.71}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.415406227111816, "min_q": 1.362401008605957, "max_q": 8.419493675231934, "mean_td_error": 0.1258240044116974, "model": {}}}, "num_steps_sampled": 519480, "num_agent_steps_sampled": 519399, "num_steps_trained": 153632, "num_agent_steps_trained": 153632, "last_target_update_ts": 519480, "num_target_updates": 961}, "done": false, "episodes_total": 10179, "training_iteration": 165, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-50", "timestamp": 1626859910, "time_this_iter_s": 1.1243553161621094, "time_total_s": 187.38758087158203, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985059d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 187.38758087158203, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 48.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 102.85, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 25.7125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 12.0, 11.0, -17.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 13.0, 14.0, 314.0, 11.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 13.0, -8.0, -3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -7.0, 1.0, 13.0, 14.0, 12.0, 315.0, 12.0, 7.0, -9.0, 4.0, 13.0, 14.0, 12.0, 315.0, 12.0, 12.0, -10.0, 0.0, 13.0, 14.0, 13.0, 314.0, 11.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 13.0, 13.0, 12.0, 315.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 7.0, -8.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 12.0, -11.0, 1.0, 13.0, 14.0, 12.0, 315.0, 12.0, 7.0, -8.0, 3.0, 13.0, 14.0, 13.0, 314.0, 11.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, -4.0, -5.0, 11.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 14.0, -9.0, -3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, 0.0, 11.0, -5.0, 9.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -6.0, 8.0, 3.0, 10.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -3.0, 13.0, -6.0, -1.0, 1.0, 4.0, 11.0, 7.0, 13.0, -4.0, -1.0, 11.0, -9.0, 13.0, 0.0, -6.0, 8.0, 4.0, 9.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -9.0, 8.0, 10.0, 6.0, 13.0, 8.0, -6.0, 0.0, 11.0, -4.0, 8.0, 0.0, -5.0, 11.0, 3.0, 6.0, 13.0, 1.0, -6.0, 7.0, 11.0, -9.0, 13.0, 0.0, -8.0, 10.0, 3.0, 10.0, 13.0, 1.0, 8.0, -7.0, 11.0, -9.0, 13.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48738451928805104, "mean_inference_ms": 2.015407404774782, "mean_action_processing_ms": 0.12055480309699865, "mean_env_wait_ms": 0.2847703787391015, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 522720, "agent_timesteps_total": 522639, "timers": {"learn_time_ms": 1.869, "learn_throughput": 17118.298, "update_time_ms": 4.584}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.7174882888793945, "min_q": 0.7585722208023071, "max_q": 9.064250946044922, "mean_td_error": 0.9985048770904541, "model": {}}}, "num_steps_sampled": 522720, "num_agent_steps_sampled": 522639, "num_steps_trained": 154592, "num_agent_steps_trained": 154592, "last_target_update_ts": 522720, "num_target_updates": 967}, "done": false, "episodes_total": 10233, "training_iteration": 166, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-51", "timestamp": 1626859911, "time_this_iter_s": 1.1496496200561523, "time_total_s": 188.53723049163818, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985050d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 188.53723049163818, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 51.599999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 92.72, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 23.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 352.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -1.0, -5.0, 10.0, 6.0, 13.0, 6.0, -10.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 6.0, 5.0, -9.0, 13.0, 11.0, 13.0, 6.0, -15.0, 12.0, -16.0, 12.0, 7.0, 11.0, 13.0, 6.0, -15.0, 12.0, 1.0, -6.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 6.0, 13.0, 6.0, -10.0, 5.0, -11.0, 11.0, 10.0, 11.0, 13.0, 6.0, -15.0, 12.0, 1.0, -5.0, 7.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, -1.0, -4.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 12.0, 12.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 6.0, 13.0, 6.0, -10.0, 10.0, -17.0, 10.0, 12.0, 2.0, 8.0, 7.0, -2.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 13.0, -6.0, -4.0, 12.0, 11.0, 13.0, 6.0, -15.0, 11.0, 4.0, -12.0, 12.0, 11.0, 13.0, 6.0, -15.0, 9.0, 0.0, -1.0, 7.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 10.0, 13.0, 6.0, -14.0, 12.0, 0.0, -5.0, 8.0, 6.0, 13.0, 6.0, -10.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 11.0, 0.0, -4.0, 8.0, 11.0, 13.0, 6.0, -15.0, 9.0, 0.0, -1.0, 7.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 14.0, 12.0, 315.0, 12.0, 13.0, -8.0, -3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -7.0, 1.0, 13.0, 14.0, 12.0, 315.0, 12.0, 7.0, -9.0, 4.0, 13.0, 14.0, 12.0, 315.0, 12.0, 12.0, -10.0, 0.0, 13.0, 14.0, 13.0, 314.0, 11.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 13.0, 13.0, 12.0, 315.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 7.0, -8.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 12.0, -11.0, 1.0, 13.0, 14.0, 12.0, 315.0, 12.0, 7.0, -8.0, 3.0, 13.0, 14.0, 13.0, 314.0, 11.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, -4.0, -5.0, 11.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 14.0, -9.0, -3.0, 13.0, 14.0, 12.0, 315.0, 12.0, 8.0, -9.0, 3.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49290017182241797, "mean_inference_ms": 2.029069833182524, "mean_action_processing_ms": 0.12160987742608344, "mean_env_wait_ms": 0.2874186814752634, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 524880, "agent_timesteps_total": 524799, "timers": {"learn_time_ms": 2.015, "learn_throughput": 15877.93, "update_time_ms": 5.117}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.959421157836914, "min_q": 0.8850295543670654, "max_q": 9.643890380859375, "mean_td_error": 0.9488149285316467, "model": {}}}, "num_steps_sampled": 524880, "num_agent_steps_sampled": 524799, "num_steps_trained": 155232, "num_agent_steps_trained": 155232, "last_target_update_ts": 524880, "num_target_updates": 971}, "done": false, "episodes_total": 10287, "training_iteration": 167, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-52", "timestamp": 1626859912, "time_this_iter_s": 0.9714252948760986, "time_total_s": 189.50865578651428, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 189.50865578651428, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 45.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 7.0, 0.0, 10.0, 2.0, -8.0, 13.0, 8.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 12.0, 6.0, -1.0, 1.0, -12.0, 13.0, 13.0, -2.0, 7.0, 0.0, 10.0, 2.0, -3.0, 8.0, 8.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, 12.0, 12.0, -8.0, -1.0, 0.0, -8.0, 13.0, 10.0, -4.0, 7.0, 3.0, 9.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 1.0, -8.0, 13.0, 9.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 8.0, 3.0, 6.0, 0.0, -8.0, 13.0, 10.0, -1.0, 9.0, 9.0, -2.0, 1.0, -8.0, 9.0, 13.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 9.0, -2.0, 10.0, 3.0, 5.0, 13.0, -6.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -1.0, 2.0, 4.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 1.0, -8.0, 9.0, 13.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, 12.0, 1.0, -6.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 6.0, 13.0, 6.0, -10.0, 5.0, -11.0, 11.0, 10.0, 11.0, 13.0, 6.0, -15.0, 12.0, 1.0, -5.0, 7.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, -1.0, -4.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 12.0, 12.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 6.0, 13.0, 6.0, -10.0, 10.0, -17.0, 10.0, 12.0, 2.0, 8.0, 7.0, -2.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 13.0, -6.0, -4.0, 12.0, 11.0, 13.0, 6.0, -15.0, 11.0, 4.0, -12.0, 12.0, 11.0, 13.0, 6.0, -15.0, 9.0, 0.0, -1.0, 7.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 10.0, 13.0, 6.0, -14.0, 12.0, 0.0, -5.0, 8.0, 6.0, 13.0, 6.0, -10.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0, 11.0, 0.0, -4.0, 8.0, 11.0, 13.0, 6.0, -15.0, 9.0, 0.0, -1.0, 7.0, 11.0, 13.0, 6.0, -15.0, 12.0, 0.0, -5.0, 8.0, 11.0, 13.0, 6.0, -15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49285991648021205, "mean_inference_ms": 2.0289367370259357, "mean_action_processing_ms": 0.12160850603360988, "mean_env_wait_ms": 0.28740355661924993, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 528120, "agent_timesteps_total": 528039, "timers": {"learn_time_ms": 1.827, "learn_throughput": 17514.351, "update_time_ms": 4.517}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.157137870788574, "min_q": 0.5160010457038879, "max_q": 9.119833946228027, "mean_td_error": -9.618271827697754, "model": {}}}, "num_steps_sampled": 528120, "num_agent_steps_sampled": 528039, "num_steps_trained": 156192, "num_agent_steps_trained": 156192, "last_target_update_ts": 528120, "num_target_updates": 977}, "done": false, "episodes_total": 10341, "training_iteration": 168, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-53", "timestamp": 1626859913, "time_this_iter_s": 1.1077537536621094, "time_total_s": 190.6164095401764, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 190.6164095401764, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 49.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 0.0, -6.0, 13.0, 8.0, 13.0, 6.0, -17.0, 13.0, -1.0, 7.0, -1.0, 10.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, -1.0, 6.0, -3.0, 13.0, 4.0, -8.0, 13.0, 6.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 14.0, 2.0, -14.0, 13.0, 6.0, -7.0, 13.0, 3.0, 14.0, -13.0, 6.0, 8.0, 6.0, -7.0, 13.0, 3.0, 12.0, 6.0, -16.0, 13.0, 6.0, -7.0, 13.0, 3.0, 14.0, -13.0, 6.0, 8.0, 6.0, -7.0, 13.0, 3.0, 6.0, 13.0, -17.0, 13.0, -1.0, 7.0, -1.0, 10.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, -1.0, 6.0, -3.0, 13.0, 6.0, -10.0, 13.0, 6.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 1.0, -7.0, 13.0, 8.0, 13.0, 3.0, -14.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 0.0, -6.0, 13.0, 8.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 11.0, 6.0, -15.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 11.0, 9.0, -18.0, 13.0, -1.0, -6.0, 13.0, 9.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 12.0, 4.0, 12.0, 6.0, -16.0, 13.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, 12.0, 12.0, -8.0, -1.0, 0.0, -8.0, 13.0, 10.0, -4.0, 7.0, 3.0, 9.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 1.0, -8.0, 13.0, 9.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 8.0, 3.0, 6.0, 0.0, -8.0, 13.0, 10.0, -1.0, 9.0, 9.0, -2.0, 1.0, -8.0, 9.0, 13.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 9.0, -2.0, 10.0, 3.0, 5.0, 13.0, -6.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -1.0, 2.0, 4.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 1.0, -8.0, 9.0, 13.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0, -2.0, 7.0, 0.0, 10.0, 0.0, -8.0, 13.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4927910252773604, "mean_inference_ms": 2.0287229423833026, "mean_action_processing_ms": 0.12159877592106196, "mean_env_wait_ms": 0.2873760287632134, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 531360, "agent_timesteps_total": 531279, "timers": {"learn_time_ms": 1.924, "learn_throughput": 16631.07, "update_time_ms": 5.136}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.579296588897705, "min_q": 0.8642997741699219, "max_q": 9.696613311767578, "mean_td_error": 0.22040653228759766, "model": {}}}, "num_steps_sampled": 531360, "num_agent_steps_sampled": 531279, "num_steps_trained": 157152, "num_agent_steps_trained": 157152, "last_target_update_ts": 531360, "num_target_updates": 983}, "done": false, "episodes_total": 10395, "training_iteration": 169, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-55", "timestamp": 1626859915, "time_this_iter_s": 1.1632356643676758, "time_total_s": 191.77964520454407, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 191.77964520454407, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 50.599999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 10.0, -3.0, -5.0, 9.0, 14.0, -16.0, 8.0, 10.0, -17.0, 9.0, 13.0, 12.0, 9.0, -1.0, -5.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 3.0, -2.0, 2.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 13.0, -2.0, -1.0, 5.0, 9.0, 14.0, -16.0, 8.0, 13.0, -14.0, 3.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, 319.0, 13.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 10.0, 13.0, -16.0, 8.0, 14.0, -15.0, 13.0, 3.0, 13.0, -4.0, -1.0, 7.0, 9.0, 14.0, -16.0, 8.0, 7.0, -9.0, 4.0, 13.0, 13.0, 3.0, -2.0, 1.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 13.0, 8.0, -3.0, -3.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 9.0, -7.0, 0.0, 13.0, 10.0, 9.0, -1.0, -3.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 12.0, 14.0, 315.0, 11.0, 14.0, -16.0, 4.0, 13.0, 13.0, 10.0, -2.0, -6.0, 8.0, 14.0, -20.0, 13.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 13.0, -14.0, 3.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 13.0, 10.0, -3.0, -5.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, -14.0, 14.0, 2.0, 13.0, 9.0, -10.0, 3.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 13.0, 8.0, -2.0, -4.0, -14.0, 14.0, 2.0, 13.0, 14.0, -14.0, 2.0, 13.0, 10.0, 5.0, -3.0, 3.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 13.0, 6.0, -17.0, 13.0, 1.0, -7.0, 13.0, 8.0, 13.0, 3.0, -14.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 0.0, -6.0, 13.0, 8.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 11.0, 6.0, -15.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 13.0, 3.0, 11.0, 9.0, -18.0, 13.0, -1.0, -6.0, 13.0, 9.0, 13.0, 6.0, -17.0, 13.0, 6.0, -7.0, 12.0, 4.0, 12.0, 6.0, -16.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4898744042296181, "mean_inference_ms": 2.0204233508751686, "mean_action_processing_ms": 0.12094063851042332, "mean_env_wait_ms": 0.2859998818991692, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 534600, "agent_timesteps_total": 534519, "timers": {"learn_time_ms": 1.942, "learn_throughput": 16478.745, "update_time_ms": 4.42}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.191957473754883, "min_q": 0.7867977023124695, "max_q": 9.036978721618652, "mean_td_error": 1.1132161617279053, "model": {}}}, "num_steps_sampled": 534600, "num_agent_steps_sampled": 534519, "num_steps_trained": 158112, "num_agent_steps_trained": 158112, "last_target_update_ts": 534600, "num_target_updates": 989}, "done": false, "episodes_total": 10476, "training_iteration": 170, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-56", "timestamp": 1626859916, "time_this_iter_s": 1.156099557876587, "time_total_s": 192.93574476242065, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 192.93574476242065, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 50.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, -9.0, 13.0, 11.0, 3.0, 11.0, 9.0, -8.0, 0.0, -11.0, 13.0, 13.0, 7.0, 7.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 3.0, 11.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -8.0, 12.0, 0.0, 11.0, 8.0, 6.0, 9.0, -8.0, 10.0, -20.0, 13.0, 12.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 10.0, 11.0, 1.0, -7.0, -2.0, -7.0, 13.0, 11.0, 3.0, 11.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 6.0, 4.0, 11.0, -6.0, -2.0, -7.0, 13.0, 11.0, 7.0, 7.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 9.0, 11.0, 8.0, -13.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, 0.0, -9.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 5.0, 13.0, -8.0, 5.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -13.0, 4.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -4.0, -5.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -1.0, -8.0, 13.0, 11.0, 8.0, 11.0, 3.0, -7.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 9.0, -7.0, 0.0, 13.0, 10.0, 9.0, -1.0, -3.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 12.0, 14.0, 315.0, 11.0, 14.0, -16.0, 4.0, 13.0, 13.0, 10.0, -2.0, -6.0, 8.0, 14.0, -20.0, 13.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 13.0, -14.0, 3.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 13.0, 10.0, -3.0, -5.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, -14.0, 14.0, 2.0, 13.0, 9.0, -10.0, 3.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 13.0, 8.0, -2.0, -4.0, -14.0, 14.0, 2.0, 13.0, 14.0, -14.0, 2.0, 13.0, 10.0, 5.0, -3.0, 3.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0, 12.0, 8.0, -1.0, -4.0, 9.0, 14.0, -16.0, 8.0, 14.0, -14.0, 2.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4873250775269794, "mean_inference_ms": 2.015220893466226, "mean_action_processing_ms": 0.12055237581811876, "mean_env_wait_ms": 0.28481715100359856, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 537840, "agent_timesteps_total": 537759, "timers": {"learn_time_ms": 1.84, "learn_throughput": 17393.376, "update_time_ms": 4.191}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.507656097412109, "min_q": 0.5313699245452881, "max_q": 8.751707077026367, "mean_td_error": 0.2044600546360016, "model": {}}}, "num_steps_sampled": 537840, "num_agent_steps_sampled": 537759, "num_steps_trained": 159072, "num_agent_steps_trained": 159072, "last_target_update_ts": 537840, "num_target_updates": 995}, "done": false, "episodes_total": 10530, "training_iteration": 171, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-57", "timestamp": 1626859917, "time_this_iter_s": 1.1948935985565186, "time_total_s": 194.13063836097717, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 194.13063836097717, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 48.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -1.0, 10.0, -7.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, 0.0, 14.0, -3.0, 4.0, 8.0, -1.0, 10.0, -2.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -4.0, 14.0, -3.0, 8.0, 13.0, -1.0, 12.0, -9.0, -9.0, 14.0, -3.0, 13.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -1.0, 14.0, -3.0, 5.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 13.0, -3.0, 8.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 10.0, -7.0, 3.0, 14.0, -4.0, 2.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 8.0, -1.0, 10.0, -2.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, 13.0, 12.0, 315.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, 8.0, 12.0, -18.0, -3.0, 14.0, -3.0, 7.0, 13.0, 13.0, 12.0, 316.0, -3.0, 14.0, -3.0, 7.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -8.0, 12.0, 0.0, 11.0, 8.0, 6.0, 9.0, -8.0, 10.0, -20.0, 13.0, 12.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 10.0, 11.0, 1.0, -7.0, -2.0, -7.0, 13.0, 11.0, 3.0, 11.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 6.0, 4.0, 11.0, -6.0, -2.0, -7.0, 13.0, 11.0, 7.0, 7.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 9.0, 11.0, 8.0, -13.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, 0.0, -9.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 5.0, 13.0, -8.0, 5.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -2.0, -7.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -13.0, 4.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -4.0, -5.0, 13.0, 11.0, 8.0, 6.0, 9.0, -8.0, -1.0, -8.0, 13.0, 11.0, 8.0, 11.0, 3.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4927738330387851, "mean_inference_ms": 2.0290984218225656, "mean_action_processing_ms": 0.12159792975902056, "mean_env_wait_ms": 0.2874666547204639, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 541080, "agent_timesteps_total": 540999, "timers": {"learn_time_ms": 2.009, "learn_throughput": 15924.461, "update_time_ms": 5.118}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.713468551635742, "min_q": 0.9195135831832886, "max_q": 9.168704986572266, "mean_td_error": 0.9573737382888794, "model": {}}}, "num_steps_sampled": 541080, "num_agent_steps_sampled": 540999, "num_steps_trained": 160032, "num_agent_steps_trained": 160032, "last_target_update_ts": 541080, "num_target_updates": 1001}, "done": false, "episodes_total": 10584, "training_iteration": 172, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-31-58", "timestamp": 1626859918, "time_this_iter_s": 1.1650726795196533, "time_total_s": 195.29571104049683, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dac80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 195.29571104049683, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 50.75, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.9, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 7.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 14.0, 314.0, 12.0, 13.0, 13.0, 6.0, 13.0, -17.0, 6.0, -1.0, -2.0, 12.0, 4.0, -13.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 14.0, -2.0, -10.0, 13.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 2.0, -11.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 4.0, -13.0, 12.0, 12.0, 7.0, 10.0, 13.0, -15.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, 8.0, -16.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 14.0, -3.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 6.0, 13.0, -15.0, 12.0, -2.0, 11.0, -6.0, 13.0, 315.0, 13.0, 12.0, 14.0, 8.0, 13.0, -20.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 3.0, -12.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 1.0, -11.0, 13.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 14.0, -1.0, -1.0, 3.0, 5.0, -14.0, 12.0, 12.0, 7.0, 10.0, 13.0, -15.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 9.0, -4.0, 0.0, 10.0, 5.0, -14.0, 12.0, 12.0, 11.0, 6.0, 13.0, -15.0, 12.0, -1.0, -7.0, 11.0, 12.0, 317.0, 11.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, 13.0, 12.0, 315.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, -1.0, 12.0, -9.0, -3.0, 14.0, -3.0, 7.0, 13.0, 8.0, 12.0, -18.0, -3.0, 14.0, -3.0, 7.0, 13.0, 13.0, 12.0, 316.0, -3.0, 14.0, -3.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4899056244887667, "mean_inference_ms": 2.0208105045807168, "mean_action_processing_ms": 0.12093877569025846, "mean_env_wait_ms": 0.2860840840350209, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 544320, "agent_timesteps_total": 544239, "timers": {"learn_time_ms": 1.791, "learn_throughput": 17864.018, "update_time_ms": 4.3}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.852501392364502, "min_q": 0.8682340383529663, "max_q": 9.600533485412598, "mean_td_error": -9.004584312438965, "model": {}}}, "num_steps_sampled": 544320, "num_agent_steps_sampled": 544239, "num_steps_trained": 160992, "num_agent_steps_trained": 160992, "last_target_update_ts": 544320, "num_target_updates": 1007}, "done": false, "episodes_total": 10665, "training_iteration": 173, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-00", "timestamp": 1626859920, "time_this_iter_s": 1.135673999786377, "time_total_s": 196.4313850402832, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 196.4313850402832, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 49.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.75, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 5.4375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 1.0, -10.0, 11.0, 14.0, 7.0, -9.0, 3.0, 13.0, 7.0, -15.0, 10.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 6.0, -15.0, 11.0, 7.0, 11.0, -11.0, 8.0, 13.0, 6.0, -15.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -15.0, 6.0, 13.0, 2.0, -12.0, 12.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 6.0, -16.0, 12.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 14.0, 12.0, -10.0, -1.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -12.0, 3.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -12.0, 3.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 12.0, 7.0, -15.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, -1.0, 8.0, 6.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 12.0, 12.0, -13.0, 4.0, 13.0, 5.0, -14.0, 11.0, -1.0, 8.0, 6.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 14.0, -3.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 6.0, 13.0, -15.0, 12.0, -2.0, 11.0, -6.0, 13.0, 315.0, 13.0, 12.0, 14.0, 8.0, 13.0, -20.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 3.0, -12.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 1.0, -11.0, 13.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 14.0, -1.0, -1.0, 3.0, 5.0, -14.0, 12.0, 12.0, 7.0, 10.0, 13.0, -15.0, 12.0, -1.0, -7.0, 11.0, 5.0, -14.0, 12.0, 12.0, 11.0, 7.0, 13.0, -16.0, 9.0, -4.0, 0.0, 10.0, 5.0, -14.0, 12.0, 12.0, 11.0, 6.0, 13.0, -15.0, 12.0, -1.0, -7.0, 11.0, 12.0, 317.0, 11.0, 12.0, 11.0, 7.0, 13.0, -16.0, 12.0, -1.0, -7.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48730732540927574, "mean_inference_ms": 2.0151989976421487, "mean_action_processing_ms": 0.12054204753335222, "mean_env_wait_ms": 0.2848089141478263, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 547560, "agent_timesteps_total": 547479, "timers": {"learn_time_ms": 1.997, "learn_throughput": 16025.041, "update_time_ms": 4.493}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.489065647125244, "min_q": 0.8332260251045227, "max_q": 10.31300163269043, "mean_td_error": 0.22298631072044373, "model": {}}}, "num_steps_sampled": 547560, "num_agent_steps_sampled": 547479, "num_steps_trained": 161952, "num_agent_steps_trained": 161952, "last_target_update_ts": 547560, "num_target_updates": 1013}, "done": false, "episodes_total": 10719, "training_iteration": 174, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-01", "timestamp": 1626859921, "time_this_iter_s": 1.3121452331542969, "time_total_s": 197.7435302734375, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e6a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 197.7435302734375, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 47.15, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -2.0, 4.0, 5.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, 13.0, -5.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 12.0, -3.0, -6.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 0.0, 5.0, -2.0, 12.0, 11.0, -2.0, 4.0, 2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, -1.0, -1.0, 4.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 11.0, -5.0, 4.0, 5.0, -1.0, 6.0, 2.0, 8.0, 11.0, 4.0, -12.0, 12.0, 13.0, 11.0, 8.0, -17.0, -1.0, 9.0, 2.0, 5.0, 11.0, 3.0, -11.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 3.0, -11.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 3.0, 4.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -8.0, 9.0, 7.0, 7.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, 13.0, -5.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -3.0, -2.0, 12.0, 8.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -6.0, 5.0, 8.0, 8.0, 3.0, 7.0, -7.0, 12.0, 13.0, -2.0, 7.0, -3.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -7.0, 5.0, 4.0, -1.0, 9.0, 2.0, 5.0, 2.0, 12.0, -11.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 1.0, 12.0, -10.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, -3.0, 10.0, -4.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, 11.0, -12.0, 3.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -12.0, 3.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 12.0, 7.0, -15.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, -1.0, 8.0, 6.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 12.0, 12.0, -13.0, 4.0, 13.0, 5.0, -14.0, 11.0, -1.0, 8.0, 6.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -11.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48984879340823295, "mean_inference_ms": 2.020502428270807, "mean_action_processing_ms": 0.12092519823134193, "mean_env_wait_ms": 0.2860079422334569, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 550800, "agent_timesteps_total": 550800, "timers": {"learn_time_ms": 2.021, "learn_throughput": 15835.032, "update_time_ms": 4.276}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.984425067901611, "min_q": 0.7653763890266418, "max_q": 9.249946594238281, "mean_td_error": 1.2872165441513062, "model": {}}}, "num_steps_sampled": 550800, "num_agent_steps_sampled": 550800, "num_steps_trained": 162912, "num_agent_steps_trained": 162912, "last_target_update_ts": 550800, "num_target_updates": 1019}, "done": false, "episodes_total": 10800, "training_iteration": 175, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-02", "timestamp": 1626859922, "time_this_iter_s": 1.1742513179779053, "time_total_s": 198.9177815914154, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 198.9177815914154, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 50.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 9.0, -3.0, 1.0, 13.0, -4.0, -6.0, 12.0, 9.0, 8.0, -4.0, 2.0, 13.0, 3.0, -1.0, 0.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 8.0, 8.0, -4.0, 3.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 9.0, -4.0, 1.0, 13.0, 9.0, -6.0, -1.0, 9.0, -5.0, 12.0, -1.0, 12.0, 4.0, -1.0, 0.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 2.0, 10.0, 4.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 6.0, -3.0, 10.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 4.0, -1.0, -1.0, 0.0, 5.0, 9.0, 1.0, 13.0, 6.0, -3.0, -1.0, 8.0, 8.0, -7.0, 6.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 2.0, 11.0, 3.0, -1.0, 6.0, -3.0, 10.0, 2.0, 13.0, 5.0, -2.0, -1.0, 8.0, -3.0, 10.0, 0.0, 3.0, 8.0, 5.0, -1.0, 8.0, -3.0, 10.0, 0.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 12.0, 6.0, -2.0, -1.0, 8.0, 8.0, -3.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 10.0, -7.0, -1.0, 8.0, -5.0, 11.0, 1.0, 8.0, 11.0, -3.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 11.0, 4.0, -12.0, 12.0, 13.0, 11.0, 8.0, -17.0, -1.0, 9.0, 2.0, 5.0, 11.0, 3.0, -11.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 3.0, -11.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 3.0, 4.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -8.0, 9.0, 7.0, 7.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, 13.0, -5.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -3.0, -2.0, 12.0, 8.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -2.0, 6.0, -2.0, -6.0, 5.0, 8.0, 8.0, 3.0, 7.0, -7.0, 12.0, 13.0, -2.0, 7.0, -3.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0, 13.0, -7.0, 5.0, 4.0, -1.0, 9.0, 2.0, 5.0, 2.0, 12.0, -11.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 1.0, 12.0, -10.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, -3.0, 10.0, -4.0, 12.0, 13.0, -2.0, 6.0, -2.0, -1.0, 9.0, 2.0, 5.0, 11.0, 4.0, -12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4872706204145224, "mean_inference_ms": 2.0151971814608705, "mean_action_processing_ms": 0.12052858501066935, "mean_env_wait_ms": 0.28477608943518173, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 554040, "agent_timesteps_total": 553959, "timers": {"learn_time_ms": 2.059, "learn_throughput": 15539.855, "update_time_ms": 5.511}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.683890342712402, "min_q": 0.8118666410446167, "max_q": 9.172708511352539, "mean_td_error": 1.2658534049987793, "model": {}}}, "num_steps_sampled": 554040, "num_agent_steps_sampled": 553959, "num_steps_trained": 163872, "num_agent_steps_trained": 163872, "last_target_update_ts": 554040, "num_target_updates": 1025}, "done": false, "episodes_total": 10854, "training_iteration": 176, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-03", "timestamp": 1626859923, "time_this_iter_s": 1.1581616401672363, "time_total_s": 200.07594323158264, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985050d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 200.07594323158264, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, -7.0, 12.0, -3.0, 13.0, -3.0, 13.0, 8.0, -3.0, 10.0, 9.0, -17.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 7.0, -18.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 1.0, -11.0, 12.0, -4.0, 13.0, 13.0, -7.0, 13.0, 2.0, -12.0, 12.0, -4.0, 13.0, 13.0, -7.0, 6.0, 12.0, 12.0, -15.0, -3.0, 13.0, 8.0, -3.0, 13.0, 9.0, -4.0, -3.0, -4.0, 13.0, 13.0, -7.0, 12.0, 9.0, -3.0, -3.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 10.0, -4.0, -4.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 12.0, 13.0, -6.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 12.0, 13.0, -6.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, -8.0, 12.0, -2.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 9.0, -4.0, 1.0, 13.0, 9.0, -6.0, -1.0, 9.0, -5.0, 12.0, -1.0, 12.0, 4.0, -1.0, 0.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 2.0, 10.0, 4.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 6.0, -3.0, 10.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 4.0, -1.0, -1.0, 0.0, 5.0, 9.0, 1.0, 13.0, 6.0, -3.0, -1.0, 8.0, 8.0, -7.0, 6.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 2.0, 11.0, 3.0, -1.0, 6.0, -3.0, 10.0, 2.0, 13.0, 5.0, -2.0, -1.0, 8.0, -3.0, 10.0, 0.0, 3.0, 8.0, 5.0, -1.0, 8.0, -3.0, 10.0, 0.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 12.0, 6.0, -2.0, -1.0, 8.0, 8.0, -3.0, 2.0, 13.0, 9.0, -6.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 10.0, -7.0, -1.0, 8.0, -5.0, 11.0, 1.0, 8.0, 11.0, -3.0, -1.0, 9.0, 8.0, -4.0, 2.0, 13.0, 9.0, -6.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49262137444512516, "mean_inference_ms": 2.028867818578089, "mean_action_processing_ms": 0.12157672015410202, "mean_env_wait_ms": 0.28737958570257693, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 557280, "agent_timesteps_total": 557199, "timers": {"learn_time_ms": 1.965, "learn_throughput": 16281.248, "update_time_ms": 4.999}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.030291557312012, "min_q": 0.7115747332572937, "max_q": 9.485246658325195, "mean_td_error": 0.8822808265686035, "model": {}}}, "num_steps_sampled": 557280, "num_agent_steps_sampled": 557199, "num_steps_trained": 164832, "num_agent_steps_trained": 164832, "last_target_update_ts": 557280, "num_target_updates": 1031}, "done": false, "episodes_total": 10908, "training_iteration": 177, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-05", "timestamp": 1626859925, "time_this_iter_s": 1.170983076095581, "time_total_s": 201.24692630767822, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da1e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 201.24692630767822, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 10.0, 9.0, 6.0, -10.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 13.0, 2.0, 12.0, -12.0, 4.0, 6.0, -1.0, 6.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 3.0, 9.0, 10.0, -7.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 8.0, 14.0, 11.0, -18.0, 5.0, -10.0, 12.0, 8.0, 3.0, 10.0, -2.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 7.0, 14.0, 5.0, -11.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 10.0, -16.0, 12.0, 9.0, 1.0, 11.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 10.0, -15.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 10.0, 14.0, 10.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 10.0, -12.0, 12.0, 5.0, 3.0, 9.0, -1.0, 4.0, 11.0, 14.0, 11.0, 316.0, 5.0, -10.0, 12.0, 8.0, -6.0, 9.0, 13.0, -1.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 12.0, 4.0, -1.0, 0.0, 9.0, 14.0, 11.0, -19.0, 14.0, -8.0, 11.0, -2.0, 13.0, 4.0, -1.0, -1.0, 7.0, 14.0, 5.0, -11.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 10.0, 14.0, 10.0, -19.0, 5.0, -9.0, 11.0, 8.0, 3.0, 9.0, -1.0, 4.0, 13.0, 0.0, -11.0, 13.0, -4.0, 12.0, 13.0, -6.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 12.0, 13.0, -6.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, -8.0, 12.0, -2.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0, -4.0, 13.0, 13.0, -7.0, 13.0, 0.0, -11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4896920519520191, "mean_inference_ms": 2.020886698684799, "mean_action_processing_ms": 0.12093630201704786, "mean_env_wait_ms": 0.28599162640056724, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 560520, "agent_timesteps_total": 560466, "timers": {"learn_time_ms": 1.957, "learn_throughput": 16350.668, "update_time_ms": 4.618}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.526841640472412, "min_q": 0.9482163190841675, "max_q": 10.288116455078125, "mean_td_error": 0.593049943447113, "model": {}}}, "num_steps_sampled": 560520, "num_agent_steps_sampled": 560466, "num_steps_trained": 165792, "num_agent_steps_trained": 165792, "last_target_update_ts": 560520, "num_target_updates": 1037}, "done": false, "episodes_total": 10989, "training_iteration": 178, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-06", "timestamp": 1626859926, "time_this_iter_s": 1.17600679397583, "time_total_s": 202.42293310165405, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 202.42293310165405, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 2.0, 5.0, 10.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, 13.0, -4.0, -1.0, 7.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 1.0, 9.0, 7.0, -2.0, -1.0, 2.0, 11.0, 3.0, 10.0, 9.0, -2.0, -2.0, -1.0, 12.0, 9.0, -5.0, 7.0, 12.0, -2.0, -2.0, -1.0, 12.0, 9.0, -5.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 14.0, -4.0, -2.0, -1.0, 13.0, 11.0, -8.0, 7.0, 14.0, -4.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, 13.0, -1.0, 12.0, -9.0, 7.0, 12.0, -2.0, -2.0, -1.0, 13.0, 11.0, -8.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 5.0, 2.0, 10.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -2.0, 14.0, 9.0, -6.0, 7.0, 12.0, -2.0, -2.0, -1.0, 13.0, 9.0, -6.0, 2.0, 8.0, 7.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, 13.0, 0.0, -9.0, 11.0, 10.0, 9.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 0.0, 12.0, -6.0, 9.0, -1.0, 13.0, 8.0, -5.0, 1.0, 7.0, 8.0, -1.0, -1.0, 9.0, 7.0, 0.0, 1.0, 9.0, 7.0, -2.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 10.0, -16.0, 12.0, 9.0, 1.0, 11.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 10.0, -15.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 10.0, 14.0, 10.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 10.0, -12.0, 12.0, 5.0, 3.0, 9.0, -1.0, 4.0, 11.0, 14.0, 11.0, 316.0, 5.0, -10.0, 12.0, 8.0, -6.0, 9.0, 13.0, -1.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 12.0, 4.0, -1.0, 0.0, 9.0, 14.0, 11.0, -19.0, 14.0, -8.0, 11.0, -2.0, 13.0, 4.0, -1.0, -1.0, 7.0, 14.0, 5.0, -11.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 9.0, 14.0, 11.0, -19.0, 5.0, -10.0, 12.0, 8.0, 3.0, 9.0, -1.0, 4.0, 10.0, 14.0, 10.0, -19.0, 5.0, -9.0, 11.0, 8.0, 3.0, 9.0, -1.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48708954623410383, "mean_inference_ms": 2.0154105112458836, "mean_action_processing_ms": 0.12054508982064516, "mean_env_wait_ms": 0.28474619040704036, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 563760, "agent_timesteps_total": 563679, "timers": {"learn_time_ms": 1.972, "learn_throughput": 16229.275, "update_time_ms": 4.827}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 6.272775650024414, "min_q": 0.9445935487747192, "max_q": 10.263154983520508, "mean_td_error": 0.2956213057041168, "model": {}}}, "num_steps_sampled": 563760, "num_agent_steps_sampled": 563679, "num_steps_trained": 166752, "num_agent_steps_trained": 166752, "last_target_update_ts": 563760, "num_target_updates": 1043}, "done": false, "episodes_total": 11043, "training_iteration": 179, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-07", "timestamp": 1626859927, "time_this_iter_s": 1.1509387493133545, "time_total_s": 203.5738718509674, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985419d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 203.5738718509674, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 51.150000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 4.0, 13.0, 7.0, -9.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 4.0, -2.0, 8.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 14.0, -3.0, 12.0, -8.0, 1.0, -2.0, 11.0, 5.0, 5.0, -8.0, 13.0, 5.0, 3.0, -4.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 2.0, 9.0, 10.0, -6.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, -1.0, 12.0, -9.0, 13.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 3.0, -7.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 6.0, -9.0, 11.0, 7.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 13.0, -19.0, 13.0, 8.0, 5.0, -6.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 5.0, 13.0, 11.0, -14.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 3.0, -9.0, 12.0, 9.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 5.0, -14.0, 11.0, 13.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 6.0, 7.0, -3.0, 5.0, 4.0, -8.0, 13.0, 6.0, -5.0, -1.0, 8.0, 13.0, 4.0, -8.0, 13.0, 6.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, 13.0, -4.0, -1.0, 7.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 1.0, 9.0, 7.0, -2.0, -1.0, 2.0, 11.0, 3.0, 10.0, 9.0, -2.0, -2.0, -1.0, 12.0, 9.0, -5.0, 7.0, 12.0, -2.0, -2.0, -1.0, 12.0, 9.0, -5.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 14.0, -4.0, -2.0, -1.0, 13.0, 11.0, -8.0, 7.0, 14.0, -4.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, 13.0, -1.0, 12.0, -9.0, 7.0, 12.0, -2.0, -2.0, -1.0, 13.0, 11.0, -8.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 5.0, 2.0, 10.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -2.0, 14.0, 9.0, -6.0, 7.0, 12.0, -2.0, -2.0, -1.0, 13.0, 9.0, -6.0, 2.0, 8.0, 7.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, 13.0, 0.0, -9.0, 11.0, 10.0, 9.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 7.0, 12.0, -2.0, -2.0, -1.0, 2.0, 11.0, 3.0, 0.0, 12.0, -6.0, 9.0, -1.0, 13.0, 8.0, -5.0, 1.0, 7.0, 8.0, -1.0, -1.0, 9.0, 7.0, 0.0, 1.0, 9.0, 7.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4924495442000714, "mean_inference_ms": 2.0286256813008174, "mean_action_processing_ms": 0.12157934486410507, "mean_env_wait_ms": 0.2873323504813177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 567000, "agent_timesteps_total": 566919, "timers": {"learn_time_ms": 2.054, "learn_throughput": 15577.731, "update_time_ms": 4.522}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.425271034240723, "min_q": 1.7519598007202148, "max_q": 9.872010231018066, "mean_td_error": 0.016539528965950012, "model": {}}}, "num_steps_sampled": 567000, "num_agent_steps_sampled": 566919, "num_steps_trained": 167712, "num_agent_steps_trained": 167712, "last_target_update_ts": 567000, "num_target_updates": 1049}, "done": false, "episodes_total": 11097, "training_iteration": 180, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-08", "timestamp": 1626859928, "time_this_iter_s": 1.1402626037597656, "time_total_s": 204.71413445472717, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 204.71413445472717, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 102.88, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 25.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 352.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 353.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 316.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, 11.0, 14.0, -21.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -8.0, 7.0, 6.0, 10.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, 10.0, 13.0, 316.0, 13.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 10.0, -17.0, 12.0, 10.0, 4.0, 12.0, -12.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, 12.0, 14.0, 316.0, 11.0, 12.0, -18.0, 13.0, 8.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -9.0, 12.0, 1.0, 11.0, 12.0, 315.0, 13.0, 13.0, 7.0, 14.0, -17.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 11.0, -14.0, 12.0, 6.0, -13.0, 12.0, 5.0, 11.0, 1.0, -2.0, 11.0, 5.0, 14.0, -3.0, 12.0, -8.0, 1.0, -2.0, 11.0, 5.0, 5.0, -8.0, 13.0, 5.0, 3.0, -4.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 2.0, 9.0, 10.0, -6.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, -1.0, 12.0, -9.0, 13.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 3.0, -7.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 6.0, -9.0, 11.0, 7.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 13.0, -19.0, 13.0, 8.0, 5.0, -6.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 5.0, 13.0, 11.0, -14.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 3.0, -9.0, 12.0, 9.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 5.0, -14.0, 11.0, 13.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 1.0, -2.0, 11.0, 5.0, 4.0, -8.0, 13.0, 6.0, 6.0, 7.0, -3.0, 5.0, 4.0, -8.0, 13.0, 6.0, -5.0, -1.0, 8.0, 13.0, 4.0, -8.0, 13.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4924452148440965, "mean_inference_ms": 2.028486495984228, "mean_action_processing_ms": 0.12157827185485937, "mean_env_wait_ms": 0.28731472477013764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 569160, "agent_timesteps_total": 569079, "timers": {"learn_time_ms": 1.827, "learn_throughput": 17510.924, "update_time_ms": 4.269}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.906049728393555, "min_q": 1.6876254081726074, "max_q": 9.404648780822754, "mean_td_error": 1.173561692237854, "model": {}}}, "num_steps_sampled": 569160, "num_agent_steps_sampled": 569079, "num_steps_trained": 168352, "num_agent_steps_trained": 168352, "last_target_update_ts": 569160, "num_target_updates": 1053}, "done": false, "episodes_total": 11151, "training_iteration": 181, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-09", "timestamp": 1626859929, "time_this_iter_s": 0.9588062763214111, "time_total_s": 205.67294073104858, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 205.67294073104858, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 37.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 89.35, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 22.3375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 352.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 353.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -13.0, 10.0, 7.0, -12.0, 7.0, 13.0, 7.0, 9.0, -14.0, 13.0, 8.0, -6.0, 0.0, 13.0, 13.0, 3.0, 11.0, -12.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, -16.0, 13.0, 5.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 11.0, 7.0, 8.0, -11.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 2.0, -1.0, 2.0, 12.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 11.0, 4.0, 13.0, -13.0, 14.0, -18.0, 7.0, 12.0, 13.0, 4.0, -15.0, 13.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, -8.0, 3.0, 7.0, 8.0, -6.0, 0.0, 13.0, 11.0, 5.0, -1.0, 0.0, 13.0, -16.0, 7.0, 11.0, 13.0, 5.0, -10.0, 7.0, 13.0, -18.0, 8.0, 12.0, 13.0, 5.0, -10.0, 7.0, 3.0, -5.0, 11.0, 6.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 9.0, -18.0, 11.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 4.0, -10.0, 8.0, 8.0, -6.0, 1.0, 12.0, 13.0, 5.0, -10.0, 7.0, 12.0, 315.0, 13.0, 13.0, -8.0, 7.0, 6.0, 10.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, 10.0, 13.0, 316.0, 13.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 10.0, -17.0, 12.0, 10.0, 4.0, 12.0, -12.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, 12.0, 14.0, 316.0, 11.0, 12.0, -18.0, 13.0, 8.0, -13.0, 12.0, 5.0, 11.0, 12.0, 315.0, 13.0, 13.0, -9.0, 12.0, 1.0, 11.0, 12.0, 315.0, 13.0, 13.0, 7.0, 14.0, -17.0, 11.0, 12.0, 315.0, 13.0, 13.0, -13.0, 12.0, 5.0, 11.0, 11.0, -14.0, 12.0, 6.0, -13.0, 12.0, 5.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.492447801235432, "mean_inference_ms": 2.028419258075035, "mean_action_processing_ms": 0.12157067177032166, "mean_env_wait_ms": 0.2872975213628356, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 572400, "agent_timesteps_total": 572319, "timers": {"learn_time_ms": 1.901, "learn_throughput": 16832.764, "update_time_ms": 4.506}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.119513511657715, "min_q": 1.1242036819458008, "max_q": 9.31588077545166, "mean_td_error": 0.5000293850898743, "model": {}}}, "num_steps_sampled": 572400, "num_agent_steps_sampled": 572319, "num_steps_trained": 169312, "num_agent_steps_trained": 169312, "last_target_update_ts": 572400, "num_target_updates": 1059}, "done": false, "episodes_total": 11205, "training_iteration": 182, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-10", "timestamp": 1626859930, "time_this_iter_s": 1.1521759033203125, "time_total_s": 206.8251166343689, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 206.8251166343689, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 11.0, 6.0, 11.0, -13.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -9.0, 9.0, 5.0, 5.0, 7.0, -8.0, 11.0, 14.0, -8.0, 3.0, 6.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 5.0, 5.0, 7.0, -2.0, 4.0, 8.0, -9.0, 12.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 9.0, 5.0, -11.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 11.0, -11.0, 11.0, 4.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 7.0, 8.0, -9.0, 9.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -1.0, 4.0, 12.0, -12.0, 3.0, 12.0, 10.0, -14.0, 11.0, 8.0, 5.0, 7.0, -8.0, 11.0, 9.0, 10.0, -11.0, 7.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, -5.0, 3.0, 11.0, 6.0, 2.0, 8.0, -6.0, 11.0, 9.0, 6.0, -12.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 3.0, 14.0, -9.0, 7.0, -9.0, 11.0, 6.0, 7.0, 5.0, 7.0, -8.0, 11.0, -4.0, 14.0, -7.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, -3.0, 6.0, 0.0, 12.0, 10.0, -6.0, 6.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, -11.0, 14.0, 7.0, 5.0, 6.0, 8.0, -9.0, 10.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 13.0, -13.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, -4.0, 14.0, -6.0, 11.0, 12.0, -11.0, 2.0, 12.0, 9.0, -7.0, 9.0, 4.0, 2.0, 8.0, -6.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 13.0, 5.0, -10.0, 7.0, 3.0, -5.0, 11.0, 6.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 9.0, -18.0, 11.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 5.0, -10.0, 7.0, 8.0, -6.0, 0.0, 13.0, 13.0, 4.0, -10.0, 8.0, 8.0, -6.0, 1.0, 12.0, 13.0, 5.0, -10.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.489483450965516, "mean_inference_ms": 2.0203647420734487, "mean_action_processing_ms": 0.12090609453723088, "mean_env_wait_ms": 0.2858809875531049, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 575640, "agent_timesteps_total": 575586, "timers": {"learn_time_ms": 1.871, "learn_throughput": 17101.939, "update_time_ms": 4.428}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.397825241088867, "min_q": 0.7468265891075134, "max_q": 8.952771186828613, "mean_td_error": 0.9518001675605774, "model": {}}}, "num_steps_sampled": 575640, "num_agent_steps_sampled": 575586, "num_steps_trained": 170272, "num_agent_steps_trained": 170272, "last_target_update_ts": 575640, "num_target_updates": 1065}, "done": false, "episodes_total": 11286, "training_iteration": 183, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-12", "timestamp": 1626859932, "time_this_iter_s": 1.164226770401001, "time_total_s": 207.9893434047699, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985052f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 207.9893434047699, "timesteps_since_restore": 0, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 50.75, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 86.19, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 21.5475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 10.0, -17.0, 10.0, 12.0, 319.0, 12.0, 10.0, 13.0, 10.0, -17.0, 10.0, 12.0, 319.0, 12.0, 10.0, 13.0, 13.0, -4.0, 9.0, -3.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 318.0, 12.0, 11.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -7.0, 10.0, -1.0, 319.0, 12.0, 10.0, 13.0, 9.0, -5.0, 6.0, 5.0, 319.0, 12.0, 10.0, 13.0, 14.0, -20.0, 9.0, 12.0, -2.0, -4.0, 8.0, 13.0, 11.0, -6.0, 11.0, -1.0, 319.0, 12.0, 10.0, 13.0, 11.0, -5.0, 10.0, -1.0, 319.0, 12.0, 10.0, 13.0, 12.0, -6.0, 10.0, -1.0, -2.0, -4.0, 8.0, 13.0, 13.0, -8.0, 11.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, -14.0, 6.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, -4.0, -3.0, 10.0, 12.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 2.0, 12.0, -11.0, 12.0, 13.0, -6.0, 9.0, -1.0, -18.0, 12.0, 8.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 12.0, -6.0, 10.0, -1.0, 319.0, 12.0, 10.0, 13.0, -5.0, 3.0, 11.0, 6.0, 2.0, 8.0, -6.0, 11.0, 9.0, 6.0, -12.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 3.0, 14.0, -9.0, 7.0, -9.0, 11.0, 6.0, 7.0, 5.0, 7.0, -8.0, 11.0, -4.0, 14.0, -7.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, -3.0, 6.0, 0.0, 12.0, 10.0, -6.0, 6.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 12.0, -12.0, 3.0, 12.0, -11.0, 14.0, 7.0, 5.0, 6.0, 8.0, -9.0, 10.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, 5.0, 7.0, -8.0, 11.0, 13.0, -13.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0, -4.0, 14.0, -6.0, 11.0, 12.0, -11.0, 2.0, 12.0, 9.0, -7.0, 9.0, 4.0, 2.0, 8.0, -6.0, 11.0, 12.0, -12.0, 3.0, 12.0, 10.0, -11.0, 11.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48694574595832685, "mean_inference_ms": 2.0150492790560954, "mean_action_processing_ms": 0.12052088700676697, "mean_env_wait_ms": 0.2846625312929487, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 578880, "agent_timesteps_total": 578799, "timers": {"learn_time_ms": 1.904, "learn_throughput": 16809.995, "update_time_ms": 4.313}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.451839447021484, "min_q": 0.7339940071105957, "max_q": 9.145438194274902, "mean_td_error": -9.902952194213867, "model": {}}}, "num_steps_sampled": 578880, "num_agent_steps_sampled": 578799, "num_steps_trained": 171232, "num_agent_steps_trained": 171232, "last_target_update_ts": 578880, "num_target_updates": 1071}, "done": false, "episodes_total": 11340, "training_iteration": 184, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-13", "timestamp": 1626859933, "time_this_iter_s": 1.1715266704559326, "time_total_s": 209.16087007522583, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 209.16087007522583, "timesteps_since_restore": 0, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 49.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 147.44, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 36.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 11.0, 10.0, 321.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 12.0, 7.0, -16.0, 12.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 12.0, 7.0, 11.0, -15.0, 14.0, -6.0, -4.0, 11.0, 3.0, 12.0, 13.0, -13.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 6.0, 12.0, 12.0, -15.0, 14.0, -6.0, -4.0, 11.0, 7.0, 11.0, 12.0, -15.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 320.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 7.0, 12.0, -17.0, 14.0, -14.0, 2.0, 13.0, 13.0, 12.0, 11.0, 319.0, 14.0, -4.0, -2.0, 7.0, 13.0, 12.0, 12.0, 318.0, 5.0, -10.0, 7.0, 13.0, 13.0, 12.0, 11.0, 319.0, 14.0, 7.0, -4.0, -2.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -8.0, -2.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 12.0, 7.0, -15.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 318.0, 12.0, 11.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -7.0, 10.0, -1.0, 319.0, 12.0, 10.0, 13.0, 9.0, -5.0, 6.0, 5.0, 319.0, 12.0, 10.0, 13.0, 14.0, -20.0, 9.0, 12.0, -2.0, -4.0, 8.0, 13.0, 11.0, -6.0, 11.0, -1.0, 319.0, 12.0, 10.0, 13.0, 11.0, -5.0, 10.0, -1.0, 319.0, 12.0, 10.0, 13.0, 12.0, -6.0, 10.0, -1.0, -2.0, -4.0, 8.0, 13.0, 13.0, -8.0, 11.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, -14.0, 6.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, -4.0, -3.0, 10.0, 12.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 2.0, 12.0, -11.0, 12.0, 13.0, -6.0, 9.0, -1.0, -18.0, 12.0, 8.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 13.0, -6.0, 9.0, -1.0, 319.0, 12.0, 10.0, 13.0, 12.0, -6.0, 10.0, -1.0, 319.0, 12.0, 10.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4924005705583304, "mean_inference_ms": 2.0285686557907865, "mean_action_processing_ms": 0.12156448375751554, "mean_env_wait_ms": 0.2873218720058182, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 582120, "agent_timesteps_total": 582039, "timers": {"learn_time_ms": 1.892, "learn_throughput": 16915.5, "update_time_ms": 4.99}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.606441974639893, "min_q": 0.8402510285377502, "max_q": 9.611241340637207, "mean_td_error": 0.5419297218322754, "model": {}}}, "num_steps_sampled": 582120, "num_agent_steps_sampled": 582039, "num_steps_trained": 172192, "num_agent_steps_trained": 172192, "last_target_update_ts": 582120, "num_target_updates": 1077}, "done": false, "episodes_total": 11394, "training_iteration": 185, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-14", "timestamp": 1626859934, "time_this_iter_s": 1.1588449478149414, "time_total_s": 210.31971502304077, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985051e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 210.31971502304077, "timesteps_since_restore": 0, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 51.099999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 45.6, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 11.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 12.0, 7.0, -11.0, -1.0, 4.0, 10.0, 2.0, 9.0, -13.0, 8.0, 11.0, 12.0, -7.0, 8.0, 2.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -5.0, 7.0, 2.0, 7.0, 12.0, 7.0, -11.0, 10.0, -12.0, 11.0, 6.0, -7.0, 10.0, 0.0, 12.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 6.0, 2.0, 7.0, 12.0, 9.0, -13.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 13.0, -16.0, 10.0, 8.0, 7.0, 7.0, 9.0, -8.0, 10.0, -12.0, 11.0, 6.0, 11.0, -5.0, 7.0, 2.0, 2.0, 12.0, 8.0, -7.0, 11.0, -4.0, 11.0, -3.0, 11.0, -4.0, 7.0, 1.0, 7.0, -6.0, 9.0, 5.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 7.0, -16.0, 12.0, 12.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 6.0, -5.0, 6.0, 8.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 7.0, 12.0, 8.0, -12.0, 10.0, -12.0, 11.0, 6.0, 11.0, -2.0, 3.0, 3.0, 2.0, 12.0, 8.0, -7.0, 11.0, -12.0, 11.0, 5.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 12.0, -8.0, 10.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 4.0, -5.0, 5.0, 11.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 7.0, 12.0, 11.0, -15.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 7.0, 13.0, -7.0, 2.0, 8.0, -6.0, 8.0, 5.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -8.0, 11.0, 2.0, 11.0, -4.0, 7.0, 1.0, 7.0, 12.0, 11.0, -15.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -5.0, 11.0, -2.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -8.0, -2.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 12.0, 7.0, -15.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0, 13.0, 12.0, 11.0, 319.0, 14.0, -6.0, -4.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4894212112384828, "mean_inference_ms": 2.0205600304383466, "mean_action_processing_ms": 0.12090109590602913, "mean_env_wait_ms": 0.2859442479319457, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 585360, "agent_timesteps_total": 585279, "timers": {"learn_time_ms": 2.068, "learn_throughput": 15475.352, "update_time_ms": 4.959}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.707096576690674, "min_q": 0.6168978214263916, "max_q": 8.88397216796875, "mean_td_error": 0.7320461273193359, "model": {}}}, "num_steps_sampled": 585360, "num_agent_steps_sampled": 585279, "num_steps_trained": 173152, "num_agent_steps_trained": 173152, "last_target_update_ts": 585360, "num_target_updates": 1083}, "done": false, "episodes_total": 11475, "training_iteration": 186, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-15", "timestamp": 1626859935, "time_this_iter_s": 1.1323773860931396, "time_total_s": 211.4520924091339, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 211.4520924091339, "timesteps_since_restore": 0, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 50.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 6.0, 3.0, -1.0, -1.0, 13.0, 6.0, -3.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 8.0, 6.0, 2.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, -1.0, 14.0, 12.0, -10.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 10.0, 13.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 10.0, 13.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 3.0, 1.0, 12.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 10.0, 13.0, 12.0, -20.0, 6.0, 14.0, -2.0, -3.0, -1.0, 14.0, 5.0, -3.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 4.0, 14.0, 12.0, -15.0, 7.0, 6.0, 3.0, -1.0, 10.0, 13.0, -20.0, 12.0, 7.0, 5.0, 4.0, -1.0, 9.0, 14.0, 9.0, -17.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 5.0, 1.0, 10.0, -1.0, 9.0, 14.0, 12.0, -20.0, 3.0, 1.0, 12.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 5.0, 4.0, -1.0, 9.0, 14.0, 12.0, -20.0, 3.0, 1.0, 12.0, -1.0, 9.0, 14.0, 12.0, -20.0, 11.0, -4.0, 7.0, 1.0, 6.0, -5.0, 6.0, 8.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 7.0, 12.0, 8.0, -12.0, 10.0, -12.0, 11.0, 6.0, 11.0, -2.0, 3.0, 3.0, 2.0, 12.0, 8.0, -7.0, 11.0, -12.0, 11.0, 5.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 12.0, -8.0, 10.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 4.0, -5.0, 5.0, 11.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 7.0, 12.0, 11.0, -15.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 7.0, 13.0, -7.0, 2.0, 8.0, -6.0, 8.0, 5.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -8.0, 11.0, 2.0, 11.0, -4.0, 7.0, 1.0, 7.0, 12.0, 11.0, -15.0, 10.0, -12.0, 11.0, 6.0, 11.0, -4.0, 7.0, 1.0, 2.0, 12.0, 8.0, -7.0, 10.0, -12.0, 11.0, 6.0, 11.0, -5.0, 11.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4868650938411064, "mean_inference_ms": 2.01510024130762, "mean_action_processing_ms": 0.12050922092537165, "mean_env_wait_ms": 0.28472352203520485, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 588600, "agent_timesteps_total": 588519, "timers": {"learn_time_ms": 2.013, "learn_throughput": 15893.347, "update_time_ms": 5.33}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.480881214141846, "min_q": 0.7590600848197937, "max_q": 9.231698036193848, "mean_td_error": 1.3684638738632202, "model": {}}}, "num_steps_sampled": 588600, "num_agent_steps_sampled": 588519, "num_steps_trained": 174112, "num_agent_steps_trained": 174112, "last_target_update_ts": 588600, "num_target_updates": 1089}, "done": false, "episodes_total": 11529, "training_iteration": 187, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-16", "timestamp": 1626859936, "time_this_iter_s": 1.1739189624786377, "time_total_s": 212.62601137161255, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 212.62601137161255, "timesteps_since_restore": 0, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 51.15, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 13.0, -3.0, 13.0, -8.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, 2.0, 10.0, -2.0, 5.0, 4.0, 0.0, 13.0, -2.0, 3.0, 9.0, -5.0, 8.0, 4.0, 0.0, 13.0, -2.0, 4.0, 13.0, -3.0, 1.0, 4.0, 0.0, 13.0, -2.0, -4.0, 11.0, -1.0, 9.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -3.0, 13.0, -3.0, -1.0, 10.0, -2.0, 8.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -3.0, 13.0, -3.0, -8.0, 12.0, -2.0, 13.0, 13.0, -8.0, 13.0, -3.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -3.0, 8.0, -3.0, 13.0, 13.0, -8.0, 13.0, -3.0, -1.0, 9.0, -6.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -4.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -4.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -4.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, 7.0, 6.0, 3.0, -1.0, -1.0, 14.0, 12.0, -10.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 10.0, 13.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 10.0, 13.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 3.0, 1.0, 12.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 10.0, 13.0, 12.0, -20.0, 6.0, 14.0, -2.0, -3.0, -1.0, 14.0, 5.0, -3.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 4.0, 14.0, 12.0, -15.0, 7.0, 6.0, 3.0, -1.0, 10.0, 13.0, -20.0, 12.0, 7.0, 5.0, 4.0, -1.0, 9.0, 14.0, 9.0, -17.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 5.0, 1.0, 10.0, -1.0, 9.0, 14.0, 12.0, -20.0, 3.0, 1.0, 12.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 6.0, 3.0, -1.0, 9.0, 14.0, 12.0, -20.0, 7.0, 5.0, 4.0, -1.0, 9.0, 14.0, 12.0, -20.0, 3.0, 1.0, 12.0, -1.0, 9.0, 14.0, 12.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4923163634269973, "mean_inference_ms": 2.028563737775604, "mean_action_processing_ms": 0.12155302871373007, "mean_env_wait_ms": 0.2873687021740004, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 590760, "agent_timesteps_total": 590733, "timers": {"learn_time_ms": 1.957, "learn_throughput": 16353.656, "update_time_ms": 4.75}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.578066825866699, "min_q": 0.6613274216651917, "max_q": 9.680465698242188, "mean_td_error": 0.20219579339027405, "model": {}}}, "num_steps_sampled": 590760, "num_agent_steps_sampled": 590733, "num_steps_trained": 174752, "num_agent_steps_trained": 174752, "last_target_update_ts": 590760, "num_target_updates": 1093}, "done": false, "episodes_total": 11583, "training_iteration": 188, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-17", "timestamp": 1626859937, "time_this_iter_s": 1.0051021575927734, "time_total_s": 213.63111352920532, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 213.63111352920532, "timesteps_since_restore": 0, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 36.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 6.0, 5.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 11.0, -8.0, 12.0, 0.0, 6.0, 13.0, 8.0, -12.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 2.0, -4.0, 12.0, 5.0, -2.0, 13.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 5.0, -4.0, 12.0, 2.0, 9.0, 9.0, 4.0, -7.0, 3.0, -5.0, 12.0, 5.0, 14.0, 10.0, 7.0, -16.0, 11.0, -4.0, 12.0, -4.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 4.0, -6.0, 12.0, 5.0, 6.0, 4.0, 12.0, -7.0, 3.0, -5.0, 12.0, 5.0, 5.0, 13.0, 8.0, -11.0, 3.0, -5.0, 12.0, 5.0, 14.0, 10.0, 4.0, -13.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, 2.0, 10.0, -2.0, 5.0, 4.0, 0.0, 13.0, -2.0, 3.0, 9.0, -5.0, 8.0, 4.0, 0.0, 13.0, -2.0, 4.0, 13.0, -3.0, 1.0, 4.0, 0.0, 13.0, -2.0, -4.0, 11.0, -1.0, 9.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -3.0, 13.0, -3.0, -1.0, 10.0, -2.0, 8.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -3.0, 13.0, -3.0, -8.0, 12.0, -2.0, 13.0, 13.0, -8.0, 13.0, -3.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -3.0, 8.0, -3.0, 13.0, 13.0, -8.0, 13.0, -3.0, -1.0, 9.0, -6.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -4.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -4.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 8.0, -4.0, 13.0, -2.0, -8.0, 12.0, -2.0, 13.0, 4.0, 0.0, 13.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4923792275867555, "mean_inference_ms": 2.0286367230413003, "mean_action_processing_ms": 0.12155328619963637, "mean_env_wait_ms": 0.28740582395051206, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 594000, "agent_timesteps_total": 593919, "timers": {"learn_time_ms": 1.981, "learn_throughput": 16153.101, "update_time_ms": 4.75}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.1467814445495605, "min_q": 0.8279494643211365, "max_q": 9.604177474975586, "mean_td_error": 2.436248779296875, "model": {}}}, "num_steps_sampled": 594000, "num_agent_steps_sampled": 593919, "num_steps_trained": 175712, "num_agent_steps_trained": 175712, "last_target_update_ts": 594000, "num_target_updates": 1099}, "done": false, "episodes_total": 11637, "training_iteration": 189, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-19", "timestamp": 1626859939, "time_this_iter_s": 1.1819026470184326, "time_total_s": 214.81301617622375, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 214.81301617622375, "timesteps_since_restore": 0, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 49.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.74, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 5.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 6.0, 12.0, -16.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 11.0, 13.0, 315.0, 13.0, 4.0, 13.0, -11.0, 9.0, 9.0, 12.0, -19.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 4.0, 5.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 4.0, 12.0, -14.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 11.0, 13.0, 315.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 1.0, 14.0, -11.0, 11.0, 4.0, 12.0, -14.0, 13.0, 3.0, 6.0, -3.0, 9.0, 11.0, -6.0, -3.0, 13.0, 3.0, 6.0, -3.0, 9.0, -2.0, 12.0, -7.0, 12.0, 3.0, 6.0, -3.0, 9.0, -6.0, 12.0, -4.0, 13.0, 3.0, 6.0, -3.0, 9.0, -7.0, 12.0, -3.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 4.0, 5.0, -3.0, 9.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 11.0, -8.0, 12.0, 0.0, 6.0, 13.0, 8.0, -12.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 2.0, -4.0, 12.0, 5.0, -2.0, 13.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 5.0, -4.0, 12.0, 2.0, 9.0, 9.0, 4.0, -7.0, 3.0, -5.0, 12.0, 5.0, 14.0, 10.0, 7.0, -16.0, 11.0, -4.0, 12.0, -4.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 4.0, -6.0, 12.0, 5.0, 6.0, 4.0, 12.0, -7.0, 3.0, -5.0, 12.0, 5.0, 5.0, 13.0, 8.0, -11.0, 3.0, -5.0, 12.0, 5.0, 14.0, 10.0, 4.0, -13.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0, 3.0, -5.0, 12.0, 5.0, 0.0, 11.0, 9.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4923574315773523, "mean_inference_ms": 2.028671406772933, "mean_action_processing_ms": 0.12155203008965745, "mean_env_wait_ms": 0.2874118472186379, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 597240, "agent_timesteps_total": 597159, "timers": {"learn_time_ms": 1.871, "learn_throughput": 17106.298, "update_time_ms": 4.503}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.802679538726807, "min_q": 0.49601754546165466, "max_q": 9.248019218444824, "mean_td_error": 0.7263374328613281, "model": {}}}, "num_steps_sampled": 597240, "num_agent_steps_sampled": 597159, "num_steps_trained": 176672, "num_agent_steps_trained": 176672, "last_target_update_ts": 597240, "num_target_updates": 1105}, "done": false, "episodes_total": 11691, "training_iteration": 190, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-20", "timestamp": 1626859940, "time_this_iter_s": 1.1436479091644287, "time_total_s": 215.95666408538818, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 215.95666408538818, "timesteps_since_restore": 0, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 50.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 2.0, 9.0, -7.0, 13.0, -14.0, 11.0, 5.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -2.0, 14.0, 6.0, -3.0, 11.0, 2.0, -11.0, 13.0, 13.0, -21.0, 10.0, 13.0, 4.0, 13.0, 5.0, -7.0, 11.0, -15.0, 11.0, 8.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -7.0, 2.0, 8.0, 12.0, 11.0, -8.0, 7.0, 5.0, 13.0, -21.0, 10.0, 13.0, 3.0, 9.0, 9.0, -6.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, 5.0, 2.0, 9.0, -1.0, 11.0, -5.0, 12.0, -3.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 1.0, -7.0, 10.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -20.0, 9.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 10.0, -3.0, -2.0, 10.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 10.0, -21.0, 13.0, 13.0, -3.0, 10.0, 10.0, -2.0, 10.0, -1.0, -2.0, 8.0, 13.0, -21.0, 10.0, 13.0, -2.0, 14.0, 6.0, -3.0, 11.0, 2.0, 9.0, -7.0, -1.0, -3.0, 10.0, 9.0, -3.0, 10.0, 11.0, -3.0, 11.0, 6.0, -10.0, 8.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 6.0, 5.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 6.0, -10.0, 8.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, 5.0, 1.0, 10.0, -1.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, 1.0, 13.0, 6.0, -5.0, 11.0, 5.0, 6.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 12.0, 6.0, 4.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 6.0, 5.0, -7.0, 13.0, -19.0, 10.0, 11.0, -3.0, 10.0, 10.0, -2.0, 3.0, 6.0, -3.0, 9.0, 11.0, -6.0, -3.0, 13.0, 3.0, 6.0, -3.0, 9.0, -2.0, 12.0, -7.0, 12.0, 3.0, 6.0, -3.0, 9.0, -6.0, 12.0, -4.0, 13.0, 3.0, 6.0, -3.0, 9.0, -7.0, 12.0, -3.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 3.0, 6.0, -3.0, 9.0, 8.0, 12.0, -18.0, 13.0, 4.0, 5.0, -3.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48953275751128855, "mean_inference_ms": 2.020831252361501, "mean_action_processing_ms": 0.1208999862681091, "mean_env_wait_ms": 0.28603250388842527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 600480, "agent_timesteps_total": 600426, "timers": {"learn_time_ms": 2.013, "learn_throughput": 15899.749, "update_time_ms": 4.721}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.56441593170166, "min_q": 0.7950273156166077, "max_q": 8.009993553161621, "mean_td_error": -8.777844429016113, "model": {}}}, "num_steps_sampled": 600480, "num_agent_steps_sampled": 600426, "num_steps_trained": 177632, "num_agent_steps_trained": 177632, "last_target_update_ts": 600480, "num_target_updates": 1111}, "done": false, "episodes_total": 11772, "training_iteration": 191, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-21", "timestamp": 1626859941, "time_this_iter_s": 1.1659038066864014, "time_total_s": 217.12256789207458, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 217.12256789207458, "timesteps_since_restore": 0, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 47.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 9.0, 6.0, 9.0, 13.0, 14.0, -13.0, 1.0, 7.0, 12.0, 6.0, -10.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, -5.0, 13.0, 2.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, -2.0, 14.0, -2.0, 5.0, 13.0, 14.0, -21.0, 9.0, -5.0, 14.0, -4.0, 10.0, 13.0, 14.0, -21.0, 9.0, 14.0, 14.0, -1.0, -12.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -12.0, 0.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 13.0, 14.0, -4.0, -8.0, 13.0, 14.0, -20.0, 8.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -11.0, -1.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, -3.0, 10.0, 10.0, -2.0, 10.0, -3.0, -2.0, 10.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 10.0, -21.0, 13.0, 13.0, -3.0, 10.0, 10.0, -2.0, 10.0, -1.0, -2.0, 8.0, 13.0, -21.0, 10.0, 13.0, -2.0, 14.0, 6.0, -3.0, 11.0, 2.0, 9.0, -7.0, -1.0, -3.0, 10.0, 9.0, -3.0, 10.0, 11.0, -3.0, 11.0, 6.0, -10.0, 8.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 6.0, 5.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 6.0, -10.0, 8.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, 5.0, 1.0, 10.0, -1.0, 11.0, 2.0, 9.0, -7.0, 13.0, -21.0, 10.0, 13.0, 1.0, 13.0, 6.0, -5.0, 11.0, 5.0, 6.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 12.0, 6.0, 4.0, -7.0, 13.0, -21.0, 10.0, 13.0, -3.0, 10.0, 10.0, -2.0, 11.0, 6.0, 5.0, -7.0, 13.0, -19.0, 10.0, 11.0, -3.0, 10.0, 10.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4869872366723228, "mean_inference_ms": 2.015446922210094, "mean_action_processing_ms": 0.12051324773232858, "mean_env_wait_ms": 0.2847808305853695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 603720, "agent_timesteps_total": 603639, "timers": {"learn_time_ms": 1.995, "learn_throughput": 16038.253, "update_time_ms": 5.345}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.369650363922119, "min_q": 0.6145370602607727, "max_q": 8.89743709564209, "mean_td_error": 0.04218195006251335, "model": {}}}, "num_steps_sampled": 603720, "num_agent_steps_sampled": 603639, "num_steps_trained": 178592, "num_agent_steps_trained": 178592, "last_target_update_ts": 603720, "num_target_updates": 1117}, "done": false, "episodes_total": 11826, "training_iteration": 192, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-22", "timestamp": 1626859942, "time_this_iter_s": 1.1594123840332031, "time_total_s": 218.2819802761078, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 218.2819802761078, "timesteps_since_restore": 0, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 51.150000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 0.0, -1.0, 9.0, 8.0, 14.0, 0.0, -7.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 3.0, 14.0, -10.0, 8.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 9.0, -2.0, -1.0, 9.0, 0.0, 8.0, -5.0, 12.0, 14.0, -12.0, 8.0, 5.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 9.0, 13.0, -5.0, -2.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 11.0, -20.0, 12.0, 12.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, 0.0, 8.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, 0.0, 8.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 3.0, 13.0, -9.0, 8.0, 7.0, 0.0, -1.0, 9.0, 8.0, 14.0, -14.0, 7.0, 7.0, 0.0, -1.0, 9.0, -3.0, 13.0, -6.0, 11.0, 5.0, -10.0, 9.0, 11.0, 7.0, 13.0, -15.0, 10.0, 5.0, -10.0, 9.0, 11.0, 7.0, 13.0, -13.0, 8.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 0.0, -6.0, 12.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, -5.0, 13.0, -5.0, 12.0, 2.0, 0.0, 4.0, 9.0, 7.0, 13.0, -15.0, 10.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, -5.0, 13.0, 2.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, -2.0, 14.0, -2.0, 5.0, 13.0, 14.0, -21.0, 9.0, -5.0, 14.0, -4.0, 10.0, 13.0, 14.0, -21.0, 9.0, 14.0, 14.0, -1.0, -12.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -12.0, 0.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 13.0, 14.0, -4.0, -8.0, 13.0, 14.0, -20.0, 8.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -11.0, -1.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0, 0.0, 14.0, -4.0, 5.0, 13.0, 14.0, -21.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49242652462633957, "mean_inference_ms": 2.0287063364787814, "mean_action_processing_ms": 0.12156258143183696, "mean_env_wait_ms": 0.28741454662319343, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 606960, "agent_timesteps_total": 606879, "timers": {"learn_time_ms": 1.805, "learn_throughput": 17724.596, "update_time_ms": 4.135}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.317234992980957, "min_q": 0.6886541247367859, "max_q": 8.754586219787598, "mean_td_error": 0.19834889471530914, "model": {}}}, "num_steps_sampled": 606960, "num_agent_steps_sampled": 606879, "num_steps_trained": 179552, "num_agent_steps_trained": 179552, "last_target_update_ts": 606960, "num_target_updates": 1123}, "done": false, "episodes_total": 11880, "training_iteration": 193, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-24", "timestamp": 1626859944, "time_this_iter_s": 1.1017799377441406, "time_total_s": 219.38376021385193, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 219.38376021385193, "timesteps_since_restore": 0, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 51.4, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 9.0, 13.0, -18.0, 11.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, -22.0, 13.0, 11.0, 13.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 5.0, 7.0, -10.0, 13.0, 11.0, 13.0, 11.0, -20.0, -2.0, 10.0, -1.0, 8.0, 8.0, 6.0, -6.0, 7.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 10.0, 8.0, -10.0, 7.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -12.0, 5.0, -19.0, 14.0, 8.0, 12.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 12.0, 13.0, 2.0, -12.0, 12.0, 7.0, -7.0, 3.0, 4.0, 8.0, 12.0, -9.0, 13.0, 9.0, -14.0, 7.0, 13.0, 5.0, -7.0, 4.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 12.0, 13.0, -5.0, -5.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 12.0, 13.0, -13.0, 3.0, -22.0, 14.0, 13.0, 10.0, 4.0, 9.0, 12.0, -10.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -6.0, 2.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 10.0, 5.0, 2.0, -2.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, -7.0, 7.0, 8.0, 7.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -6.0, 2.0, 4.0, 9.0, 12.0, -10.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 12.0, 13.0, 2.0, -12.0, 12.0, 7.0, -7.0, 3.0, 9.0, 8.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, -15.0, 11.0, 8.0, 11.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -9.0, 2.0, 12.0, 7.0, -7.0, 3.0, 9.0, 13.0, 12.0, -19.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 9.0, 11.0, -9.0, 12.0, 12.0, -11.0, 2.0, 3.0, 13.0, -9.0, 8.0, 7.0, 0.0, -1.0, 9.0, 8.0, 14.0, -14.0, 7.0, 7.0, 0.0, -1.0, 9.0, -3.0, 13.0, -6.0, 11.0, 5.0, -10.0, 9.0, 11.0, 7.0, 13.0, -15.0, 10.0, 5.0, -10.0, 9.0, 11.0, 7.0, 13.0, -13.0, 8.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, 7.0, 13.0, -15.0, 10.0, 0.0, -6.0, 12.0, 9.0, 7.0, 13.0, -15.0, 10.0, 7.0, 0.0, -1.0, 9.0, -5.0, 13.0, -5.0, 12.0, 2.0, 0.0, 4.0, 9.0, 7.0, 13.0, -15.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4896512867876126, "mean_inference_ms": 2.020719839458742, "mean_action_processing_ms": 0.12090340861976913, "mean_env_wait_ms": 0.28603191037871717, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 610200, "agent_timesteps_total": 610119, "timers": {"learn_time_ms": 1.927, "learn_throughput": 16609.872, "update_time_ms": 4.832}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.457925796508789, "min_q": 0.7701836824417114, "max_q": 8.693042755126953, "mean_td_error": -10.14103889465332, "model": {}}}, "num_steps_sampled": 610200, "num_agent_steps_sampled": 610119, "num_steps_trained": 180512, "num_agent_steps_trained": 180512, "last_target_update_ts": 610200, "num_target_updates": 1129}, "done": false, "episodes_total": 11961, "training_iteration": 194, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-25", "timestamp": 1626859945, "time_this_iter_s": 1.1722981929779053, "time_total_s": 220.55605840682983, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 220.55605840682983, "timesteps_since_restore": 0, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 50.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -3.0, 13.0, -1.0, 6.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -4.0, 13.0, 5.0, 1.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -14.0, 8.0, 8.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -10.0, 9.0, 3.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -3.0, 13.0, -1.0, 6.0, -13.0, 8.0, 7.0, 13.0, 13.0, 9.0, -14.0, 7.0, -22.0, 13.0, 11.0, 13.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 5.0, 7.0, -10.0, 13.0, 11.0, 13.0, 11.0, -20.0, -2.0, 10.0, -1.0, 8.0, 8.0, 6.0, -6.0, 7.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 10.0, 8.0, -10.0, 7.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -12.0, 5.0, -19.0, 14.0, 8.0, 12.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 12.0, 13.0, 2.0, -12.0, 12.0, 7.0, -7.0, 3.0, 4.0, 8.0, 12.0, -9.0, 13.0, 9.0, -14.0, 7.0, 13.0, 5.0, -7.0, 4.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 12.0, 13.0, -5.0, -5.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 12.0, 13.0, -13.0, 3.0, -22.0, 14.0, 13.0, 10.0, 4.0, 9.0, 12.0, -10.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -6.0, 2.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 10.0, 5.0, 2.0, -2.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, -7.0, 7.0, 8.0, 7.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -6.0, 2.0, 4.0, 9.0, 12.0, -10.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 13.0, 12.0, -14.0, 12.0, 13.0, 2.0, -12.0, 12.0, 7.0, -7.0, 3.0, 9.0, 8.0, 12.0, -14.0, 13.0, 9.0, -14.0, 7.0, -15.0, 11.0, 8.0, 11.0, 4.0, 13.0, 12.0, -14.0, 13.0, 9.0, -9.0, 2.0, 12.0, 7.0, -7.0, 3.0, 9.0, 13.0, 12.0, -19.0, 13.0, 9.0, -14.0, 7.0, 12.0, 7.0, -7.0, 3.0, 4.0, 9.0, 11.0, -9.0, 12.0, 12.0, -11.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49241425641279873, "mean_inference_ms": 2.028504479388703, "mean_action_processing_ms": 0.12160180601169661, "mean_env_wait_ms": 0.28728191144510623, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 612360, "agent_timesteps_total": 612279, "timers": {"learn_time_ms": 1.998, "learn_throughput": 16013.187, "update_time_ms": 4.605}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.6836650371551514, "min_q": 0.7669662833213806, "max_q": 9.174067497253418, "mean_td_error": -9.444785118103027, "model": {}}}, "num_steps_sampled": 612360, "num_agent_steps_sampled": 612279, "num_steps_trained": 181152, "num_agent_steps_trained": 181152, "last_target_update_ts": 612360, "num_target_updates": 1133}, "done": false, "episodes_total": 11988, "training_iteration": 195, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-26", "timestamp": 1626859946, "time_this_iter_s": 1.0084962844848633, "time_total_s": 221.5645546913147, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985052f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 221.5645546913147, "timesteps_since_restore": 0, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 44.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 89.57, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 22.3925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 353.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, 2.0, 14.0, -3.0, 2.0, -4.0, 14.0, 13.0, -8.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, 6.0, 14.0, -11.0, 6.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -6.0, 1.0, 7.0, 13.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, -21.0, 13.0, 10.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, -1.0, 12.0, 5.0, -1.0, -5.0, 14.0, -3.0, 9.0, -10.0, 6.0, 13.0, 6.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, 11.0, 14.0, 13.0, 315.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -2.0, 14.0, 13.0, -10.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -10.0, 6.0, 13.0, 6.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 317.0, 13.0, 12.0, 12.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 10.0, 8.0, 1.0, -4.0, -4.0, 14.0, 11.0, -6.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, -21.0, 13.0, 10.0, 13.0, -5.0, 14.0, -3.0, 9.0, -3.0, 14.0, 13.0, -9.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -2.0, 14.0, 13.0, -10.0, 13.0, -14.0, 6.0, 10.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, -5.0, 1.0, 6.0, 13.0, 13.0, 13.0, -22.0, 11.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -3.0, 13.0, -1.0, 6.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -4.0, 13.0, 5.0, 1.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -14.0, 8.0, 8.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -10.0, 9.0, 3.0, 13.0, -11.0, 9.0, 4.0, 13.0, -11.0, 9.0, 4.0, 13.0, -3.0, 13.0, -1.0, 6.0, -13.0, 8.0, 7.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.493254984873085, "mean_inference_ms": 2.029798330945098, "mean_action_processing_ms": 0.1216660916150172, "mean_env_wait_ms": 0.28777237573964776, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 615600, "agent_timesteps_total": 615546, "timers": {"learn_time_ms": 1.864, "learn_throughput": 17163.831, "update_time_ms": 4.746}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.766753196716309, "min_q": 0.6826281547546387, "max_q": 8.35767650604248, "mean_td_error": -9.81424617767334, "model": {}}}, "num_steps_sampled": 615600, "num_agent_steps_sampled": 615546, "num_steps_trained": 182112, "num_agent_steps_trained": 182112, "last_target_update_ts": 615600, "num_target_updates": 1139}, "done": false, "episodes_total": 12069, "training_iteration": 196, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-27", "timestamp": 1626859947, "time_this_iter_s": 1.13431715965271, "time_total_s": 222.6988718509674, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985059d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 222.6988718509674, "timesteps_since_restore": 0, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 59.06, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 14.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 4.0, 11.0, -14.0, -2.0, 14.0, 10.0, -7.0, 13.0, 5.0, 11.0, -14.0, 5.0, 11.0, 3.0, -4.0, 13.0, 5.0, 11.0, -14.0, 7.0, 14.0, -4.0, -2.0, 13.0, 5.0, 11.0, -14.0, 7.0, -1.0, 11.0, -2.0, 8.0, 5.0, 11.0, -9.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 3.0, 14.0, 0.0, -2.0, 1.0, 6.0, 12.0, -4.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 8.0, -8.0, 11.0, 4.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 0.0, 7.0, 12.0, -4.0, 11.0, 14.0, -8.0, -2.0, 13.0, 11.0, 12.0, 318.0, 11.0, 14.0, -8.0, -2.0, 8.0, -8.0, 11.0, 4.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 0.0, 6.0, 12.0, -3.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, -5.0, 14.0, -3.0, 9.0, 11.0, 14.0, 13.0, 315.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -2.0, 14.0, 13.0, -10.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -10.0, 6.0, 13.0, 6.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 317.0, 13.0, 12.0, 12.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, 10.0, 8.0, 1.0, -4.0, -4.0, 14.0, 11.0, -6.0, -9.0, 9.0, 13.0, 2.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, -21.0, 13.0, 10.0, 13.0, -5.0, 14.0, -3.0, 9.0, -3.0, 14.0, 13.0, -9.0, 316.0, 13.0, 12.0, 13.0, -5.0, 14.0, -3.0, 9.0, -2.0, 14.0, 13.0, -10.0, 13.0, -14.0, 6.0, 10.0, -5.0, 14.0, -3.0, 9.0, -9.0, 9.0, 13.0, 2.0, -5.0, 1.0, 6.0, 13.0, 13.0, 13.0, -22.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48713916950095215, "mean_inference_ms": 2.015441800241937, "mean_action_processing_ms": 0.12050811060366257, "mean_env_wait_ms": 0.2847921342639971, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 618840, "agent_timesteps_total": 618759, "timers": {"learn_time_ms": 1.957, "learn_throughput": 16354.055, "update_time_ms": 4.392}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.230833053588867, "min_q": 0.6901940107345581, "max_q": 8.91453742980957, "mean_td_error": -9.101502418518066, "model": {}}}, "num_steps_sampled": 618840, "num_agent_steps_sampled": 618759, "num_steps_trained": 183072, "num_agent_steps_trained": 183072, "last_target_update_ts": 618840, "num_target_updates": 1145}, "done": false, "episodes_total": 12123, "training_iteration": 197, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-28", "timestamp": 1626859948, "time_this_iter_s": 1.133237600326538, "time_total_s": 223.83210945129395, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 223.83210945129395, "timesteps_since_restore": 0, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 48.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 103.14, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 25.785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 9.0, 2.0, -8.0, 11.0, -15.0, 13.0, 6.0, 13.0, 9.0, 0.0, -7.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 13.0, 12.0, 4.0, -14.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 13.0, 8.0, 7.0, -13.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 8.0, -15.0, 10.0, 12.0, 317.0, 13.0, 12.0, 12.0, 13.0, -5.0, -5.0, 12.0, 317.0, 13.0, 12.0, 13.0, 13.0, -2.0, -9.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 10.0, -19.0, 13.0, 11.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 8.0, 5.0, 11.0, -9.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 3.0, 14.0, 0.0, -2.0, 1.0, 6.0, 12.0, -4.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 8.0, -8.0, 11.0, 4.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 0.0, 7.0, 12.0, -4.0, 11.0, 14.0, -8.0, -2.0, 13.0, 11.0, 12.0, 318.0, 11.0, 14.0, -8.0, -2.0, 8.0, -8.0, 11.0, 4.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 0.0, 6.0, 12.0, -3.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 11.0, 14.0, -8.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49263060446097057, "mean_inference_ms": 2.02898182469449, "mean_action_processing_ms": 0.1215726065662273, "mean_env_wait_ms": 0.2874681885995228, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 622080, "agent_timesteps_total": 621999, "timers": {"learn_time_ms": 2.006, "learn_throughput": 15951.525, "update_time_ms": 5.43}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.455631256103516, "min_q": 0.595848798751831, "max_q": 9.058431625366211, "mean_td_error": -8.866798400878906, "model": {}}}, "num_steps_sampled": 622080, "num_agent_steps_sampled": 621999, "num_steps_trained": 184032, "num_agent_steps_trained": 184032, "last_target_update_ts": 622080, "num_target_updates": 1151}, "done": false, "episodes_total": 12177, "training_iteration": 198, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-29", "timestamp": 1626859949, "time_this_iter_s": 1.1960055828094482, "time_total_s": 225.0281150341034, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 225.0281150341034, "timesteps_since_restore": 0, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 50.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 59.07, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 14.7675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -3.0, 11.0, -3.0, -12.0, 11.0, 13.0, 3.0, 0.0, -10.0, 13.0, 12.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, -2.0, -3.0, 11.0, 9.0, 4.0, 11.0, 13.0, -13.0, -2.0, -7.0, 11.0, 13.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -15.0, 4.0, 13.0, 13.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 1.0, -4.0, 5.0, 13.0, 8.0, -13.0, 11.0, 9.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -16.0, 11.0, 8.0, -6.0, 11.0, 10.0, 0.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 2.0, -2.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, 315.0, 13.0, 13.0, 13.0, 1.0, 3.0, -1.0, 12.0, -1.0, -1.0, 7.0, 10.0, -9.0, 11.0, 13.0, 0.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -2.0, 7.0, 13.0, -3.0, 2.0, -3.0, 12.0, 4.0, 8.0, -5.0, 7.0, 5.0, 315.0, 13.0, 13.0, 13.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 8.0, -5.0, 7.0, 5.0, 316.0, 13.0, 13.0, 12.0, 2.0, -3.0, 11.0, 5.0, 12.0, 1.0, 11.0, -9.0, -12.0, 11.0, 13.0, 3.0, 1.0, -11.0, 13.0, 12.0, 12.0, -12.0, 11.0, 4.0, -1.0, 4.0, 13.0, -1.0, 1.0, -11.0, 13.0, 12.0, 1.0, -3.0, 7.0, 10.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 8.0, -14.0, 11.0, 10.0, 315.0, 13.0, 13.0, 13.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 0.0, -3.0, 11.0, 7.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, 317.0, 13.0, 12.0, 13.0, 13.0, -2.0, -9.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 10.0, -19.0, 13.0, 11.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0, 12.0, 9.0, 2.0, -8.0, 12.0, 317.0, 13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48982434265427416, "mean_inference_ms": 2.0212081127321913, "mean_action_processing_ms": 0.12094221798350172, "mean_env_wait_ms": 0.2861251770339196, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 625320, "agent_timesteps_total": 625239, "timers": {"learn_time_ms": 1.854, "learn_throughput": 17256.072, "update_time_ms": 4.171}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.195710182189941, "min_q": 0.7793540358543396, "max_q": 8.82774543762207, "mean_td_error": 1.8490301370620728, "model": {}}}, "num_steps_sampled": 625320, "num_agent_steps_sampled": 625239, "num_steps_trained": 184992, "num_agent_steps_trained": 184992, "last_target_update_ts": 625320, "num_target_updates": 1157}, "done": false, "episodes_total": 12258, "training_iteration": 199, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-31", "timestamp": 1626859951, "time_this_iter_s": 1.1242902278900146, "time_total_s": 226.1524052619934, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 226.1524052619934, "timesteps_since_restore": 0, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 51.25, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 96.17, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 24.0425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 354.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -9.0, 9.0, 4.0, 10.0, 13.0, 13.0, -21.0, 12.0, 8.0, 11.0, -16.0, 8.0, 12.0, 13.0, -18.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 9.0, 11.0, -17.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 7.0, 13.0, -18.0, 12.0, 8.0, 11.0, -16.0, 13.0, 12.0, 13.0, 316.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 5.0, -3.0, 10.0, 3.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, -9.0, 9.0, 3.0, -11.0, 8.0, 10.0, 8.0, 12.0, 8.0, 11.0, -16.0, 12.0, 12.0, 11.0, -20.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, -5.0, 0.0, 8.0, -16.0, 8.0, 13.0, 10.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 13.0, 313.0, 12.0, 4.0, 11.0, -12.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 12.0, 10.0, 13.0, -20.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, 315.0, 13.0, 13.0, 13.0, 1.0, 3.0, -1.0, 12.0, -1.0, -1.0, 7.0, 10.0, -9.0, 11.0, 13.0, 0.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -2.0, 7.0, 13.0, -3.0, 2.0, -3.0, 12.0, 4.0, 8.0, -5.0, 7.0, 5.0, 315.0, 13.0, 13.0, 13.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 8.0, -5.0, 7.0, 5.0, 316.0, 13.0, 13.0, 12.0, 2.0, -3.0, 11.0, 5.0, 12.0, 1.0, 11.0, -9.0, -12.0, 11.0, 13.0, 3.0, 1.0, -11.0, 13.0, 12.0, 12.0, -12.0, 11.0, 4.0, -1.0, 4.0, 13.0, -1.0, 1.0, -11.0, 13.0, 12.0, 1.0, -3.0, 7.0, 10.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 8.0, -14.0, 11.0, 10.0, 315.0, 13.0, 13.0, 13.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 0.0, -3.0, 11.0, 7.0, 12.0, -12.0, 11.0, 4.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, 11.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4872154111315365, "mean_inference_ms": 2.01565377015473, "mean_action_processing_ms": 0.12054545193010663, "mean_env_wait_ms": 0.2848458389994869, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 628560, "agent_timesteps_total": 628479, "timers": {"learn_time_ms": 1.904, "learn_throughput": 16806.838, "update_time_ms": 4.655}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.958097457885742, "min_q": 0.770028293132782, "max_q": 8.644770622253418, "mean_td_error": 1.230374813079834, "model": {}}}, "num_steps_sampled": 628560, "num_agent_steps_sampled": 628479, "num_steps_trained": 185952, "num_agent_steps_trained": 185952, "last_target_update_ts": 628560, "num_target_updates": 1163}, "done": false, "episodes_total": 12312, "training_iteration": 200, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-32", "timestamp": 1626859952, "time_this_iter_s": 1.1373095512390137, "time_total_s": 227.28971481323242, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 227.28971481323242, "timesteps_since_restore": 0, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 75.85, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 18.9625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 354.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 4.0, 11.0, 9.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -18.0, 13.0, 10.0, 10.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -4.0, 12.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -14.0, 13.0, 11.0, 5.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, 7.0, 14.0, 10.0, -16.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -9.0, 14.0, 11.0, -1.0, 3.0, 13.0, 9.0, -10.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -5.0, 14.0, 5.0, 1.0, -6.0, 13.0, 11.0, -3.0, -3.0, 10.0, 10.0, -2.0, -5.0, 13.0, 10.0, -3.0, -9.0, 14.0, 11.0, -1.0, -5.0, 13.0, 10.0, -3.0, -9.0, 14.0, 11.0, -1.0, -5.0, 13.0, 10.0, -3.0, -3.0, 14.0, 1.0, 3.0, -5.0, 13.0, 10.0, -3.0, -10.0, 14.0, 10.0, 1.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -14.0, 13.0, 11.0, 5.0, -5.0, 13.0, 10.0, -3.0, -3.0, 14.0, 4.0, 0.0, -6.0, 12.0, -2.0, 11.0, -4.0, 14.0, -5.0, 10.0, 0.0, 9.0, 11.0, -5.0, -4.0, 14.0, -5.0, 10.0, -1.0, 13.0, 6.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, 12.0, 9.0, 11.0, -17.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 7.0, 13.0, -18.0, 12.0, 8.0, 11.0, -16.0, 13.0, 12.0, 13.0, 316.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 5.0, -3.0, 10.0, 3.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, -9.0, 9.0, 3.0, -11.0, 8.0, 10.0, 8.0, 12.0, 8.0, 11.0, -16.0, 12.0, 12.0, 11.0, -20.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0, 12.0, -5.0, 0.0, 8.0, -16.0, 8.0, 13.0, 10.0, 12.0, 8.0, 11.0, -16.0, 13.0, 14.0, 13.0, 313.0, 12.0, 4.0, 11.0, -12.0, 13.0, 13.0, 13.0, 314.0, 12.0, 8.0, 11.0, -16.0, 12.0, 10.0, 13.0, -20.0, 12.0, 8.0, 11.0, -16.0, 13.0, 13.0, 13.0, 314.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49262132229513766, "mean_inference_ms": 2.0287085151968003, "mean_action_processing_ms": 0.12157882290584858, "mean_env_wait_ms": 0.2874620098258312, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 631800, "agent_timesteps_total": 631719, "timers": {"learn_time_ms": 1.877, "learn_throughput": 17052.399, "update_time_ms": 5.455}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.689277172088623, "min_q": 0.7463297843933105, "max_q": 8.379278182983398, "mean_td_error": 0.930383026599884, "model": {}}}, "num_steps_sampled": 631800, "num_agent_steps_sampled": 631719, "num_steps_trained": 186912, "num_agent_steps_trained": 186912, "last_target_update_ts": 631800, "num_target_updates": 1169}, "done": false, "episodes_total": 12366, "training_iteration": 201, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-33", "timestamp": 1626859953, "time_this_iter_s": 1.1804969310760498, "time_total_s": 228.47021174430847, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 228.47021174430847, "timesteps_since_restore": 0, "iterations_since_restore": 201, "perf": {"cpu_util_percent": 50.25, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 103.43, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 25.8575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 356.0, 15.0, 355.0, 15.0, 15.0, 15.0, 356.0, 15.0, 355.0, 15.0, 356.0, 15.0, 354.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 354.0, 15.0, 355.0, 15.0, 356.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 356.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 14.0, 316.0, 12.0, 11.0, -2.0, 0.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -11.0, 5.0, 13.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 11.0, -5.0, -3.0, 12.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 10.0, -8.0, 1.0, 12.0, 13.0, 14.0, -10.0, -2.0, 8.0, -2.0, 3.0, 6.0, 14.0, 14.0, 11.0, 317.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 2.0, -2.0, 7.0, 8.0, 13.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 315.0, 12.0, 2.0, -2.0, 3.0, 12.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 6.0, -2.0, 7.0, 4.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 12.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 315.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 9.0, -7.0, 1.0, 12.0, 13.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 13.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, -4.0, 14.0, -5.0, 10.0, -4.0, 12.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -14.0, 13.0, 11.0, 5.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, 7.0, 14.0, 10.0, -16.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -9.0, 14.0, 11.0, -1.0, 3.0, 13.0, 9.0, -10.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -5.0, 14.0, 5.0, 1.0, -6.0, 13.0, 11.0, -3.0, -3.0, 10.0, 10.0, -2.0, -5.0, 13.0, 10.0, -3.0, -9.0, 14.0, 11.0, -1.0, -5.0, 13.0, 10.0, -3.0, -9.0, 14.0, 11.0, -1.0, -5.0, 13.0, 10.0, -3.0, -3.0, 14.0, 1.0, 3.0, -5.0, 13.0, 10.0, -3.0, -10.0, 14.0, 10.0, 1.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0, -14.0, 13.0, 11.0, 5.0, -5.0, 13.0, 10.0, -3.0, -3.0, 14.0, 4.0, 0.0, -6.0, 12.0, -2.0, 11.0, -4.0, 14.0, -5.0, 10.0, 0.0, 9.0, 11.0, -5.0, -4.0, 14.0, -5.0, 10.0, -1.0, 13.0, 6.0, -3.0, -4.0, 14.0, -5.0, 10.0, -5.0, 13.0, 10.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49252948756966236, "mean_inference_ms": 2.028548731209823, "mean_action_processing_ms": 0.12156441499111692, "mean_env_wait_ms": 0.28743253299597354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 633960, "agent_timesteps_total": 633879, "timers": {"learn_time_ms": 1.945, "learn_throughput": 16454.3, "update_time_ms": 4.472}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.895730018615723, "min_q": 0.9821624159812927, "max_q": 7.9446210861206055, "mean_td_error": 1.3793909549713135, "model": {}}}, "num_steps_sampled": 633960, "num_agent_steps_sampled": 633879, "num_steps_trained": 187552, "num_agent_steps_trained": 187552, "last_target_update_ts": 633960, "num_target_updates": 1173}, "done": false, "episodes_total": 12420, "training_iteration": 202, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-34", "timestamp": 1626859954, "time_this_iter_s": 0.9676990509033203, "time_total_s": 229.4379107952118, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 229.4379107952118, "timesteps_since_restore": 0, "iterations_since_restore": 202, "perf": {"cpu_util_percent": 45.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 89.83, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 22.4575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 355.0, 15.0, 356.0, 15.0, 355.0, 15.0, 15.0, 15.0, 356.0, 15.0, 355.0, 15.0, 356.0, 15.0, 354.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 354.0, 15.0, 355.0, 15.0, 356.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 356.0, 15.0, 355.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 10.0, -2.0, 9.0, 13.0, -2.0, -5.0, 9.0, -15.0, 13.0, 8.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 2.0, 4.0, 11.0, -2.0, 11.0, -4.0, 11.0, -3.0, 9.0, 13.0, -2.0, -5.0, 9.0, -15.0, 13.0, 8.0, -3.0, 13.0, 10.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, -1.0, 13.0, 8.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, -6.0, 13.0, 12.0, -4.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 1.0, 13.0, -9.0, 10.0, 12.0, -6.0, 11.0, -2.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 11.0, -3.0, 1.0, 13.0, 5.0, -4.0, 11.0, -4.0, 1.0, 7.0, 13.0, 0.0, 7.0, -5.0, 11.0, -4.0, 1.0, 7.0, 5.0, 13.0, 2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 9.0, -9.0, 3.0, 12.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 6.0, -6.0, 11.0, 4.0, -1.0, 8.0, -1.0, 9.0, 11.0, -4.0, 11.0, -3.0, 9.0, 13.0, -2.0, -5.0, 13.0, 10.0, -1.0, -7.0, 9.0, 13.0, -2.0, -5.0, 13.0, 14.0, 316.0, 12.0, 11.0, -5.0, -3.0, 12.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 10.0, -8.0, 1.0, 12.0, 13.0, 14.0, -10.0, -2.0, 8.0, -2.0, 3.0, 6.0, 14.0, 14.0, 11.0, 317.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 2.0, -2.0, 7.0, 8.0, 13.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 315.0, 12.0, 2.0, -2.0, 3.0, 12.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 6.0, -2.0, 7.0, 4.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 12.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 315.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 9.0, -7.0, 1.0, 12.0, 13.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 13.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 317.0, 12.0, 8.0, -2.0, 3.0, 6.0, 13.0, 14.0, 316.0, 12.0, 8.0, -2.0, 3.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49245524378982025, "mean_inference_ms": 2.0284202209018356, "mean_action_processing_ms": 0.12154786175916871, "mean_env_wait_ms": 0.2873921889927919, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 637200, "agent_timesteps_total": 637119, "timers": {"learn_time_ms": 1.872, "learn_throughput": 17092.574, "update_time_ms": 4.17}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.664638042449951, "min_q": 1.0654373168945312, "max_q": 8.906176567077637, "mean_td_error": 0.7132418155670166, "model": {}}}, "num_steps_sampled": 637200, "num_agent_steps_sampled": 637119, "num_steps_trained": 188512, "num_agent_steps_trained": 188512, "last_target_update_ts": 637200, "num_target_updates": 1179}, "done": false, "episodes_total": 12474, "training_iteration": 203, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-35", "timestamp": 1626859955, "time_this_iter_s": 1.134796380996704, "time_total_s": 230.5727071762085, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 230.5727071762085, "timesteps_since_restore": 0, "iterations_since_restore": 203, "perf": {"cpu_util_percent": 48.4, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 113.03, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -9.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 28.2575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 352.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 7.0, 4.0, 11.0, -7.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 317.0, 11.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -3.0, 0.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 2.0, -2.0, 2.0, -6.0, 9.0, 0.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 1.0, 2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 315.0, 12.0, 13.0, 13.0, 13.0, 5.0, -2.0, -1.0, -6.0, 2.0, 12.0, 7.0, 316.0, 13.0, 12.0, 12.0, 13.0, 2.0, -3.0, 3.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, 9.0, 0.0, 13.0, -7.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -3.0, 0.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 12.0, 9.0, -3.0, -3.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -2.0, 13.0, -8.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, -2.0, -2.0, 6.0, -6.0, 13.0, -4.0, 12.0, 316.0, 12.0, 13.0, 11.0, 11.0, 0.0, -3.0, 7.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 2.0, -2.0, 2.0, 316.0, 14.0, 13.0, 9.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -5.0, 14.0, 12.0, -6.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 315.0, 14.0, 13.0, 12.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -7.0, 6.0, 5.0, 11.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, 318.0, 14.0, 13.0, 11.0, 13.0, 0.0, 7.0, -5.0, 11.0, -4.0, 1.0, 7.0, 5.0, 13.0, 2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 9.0, -9.0, 3.0, 12.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 11.0, -4.0, 1.0, 7.0, 9.0, 13.0, -2.0, -5.0, 6.0, -6.0, 11.0, 4.0, -1.0, 8.0, -1.0, 9.0, 11.0, -4.0, 11.0, -3.0, 9.0, 13.0, -2.0, -5.0, 13.0, 10.0, -1.0, -7.0, 9.0, 13.0, -2.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48941564711662056, "mean_inference_ms": 2.020089208021534, "mean_action_processing_ms": 0.12085989368718612, "mean_env_wait_ms": 0.285903437321612, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 640440, "agent_timesteps_total": 640359, "timers": {"learn_time_ms": 1.901, "learn_throughput": 16833.397, "update_time_ms": 4.464}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.810153961181641, "min_q": 0.8932146430015564, "max_q": 9.322250366210938, "mean_td_error": 2.576964855194092, "model": {}}}, "num_steps_sampled": 640440, "num_agent_steps_sampled": 640359, "num_steps_trained": 189472, "num_agent_steps_trained": 189472, "last_target_update_ts": 640440, "num_target_updates": 1185}, "done": false, "episodes_total": 12555, "training_iteration": 204, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-36", "timestamp": 1626859956, "time_this_iter_s": 1.1151916980743408, "time_total_s": 231.68789887428284, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 231.68789887428284, "timesteps_since_restore": 0, "iterations_since_restore": 204, "perf": {"cpu_util_percent": 52.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 79.28, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 19.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 352.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 356.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, 318.0, 11.0, 11.0, 10.0, -5.0, -1.0, 11.0, 12.0, -20.0, 12.0, 2.0, 12.0, 2.0, -1.0, 11.0, 12.0, -20.0, 12.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -19.0, 9.0, 2.0, 12.0, 2.0, -1.0, 13.0, 7.0, -2.0, -3.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, -3.0, 12.0, 12.0, -6.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 5.0, 10.0, 2.0, -2.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 14.0, 11.0, 318.0, 13.0, 7.0, 12.0, -3.0, -1.0, 13.0, 12.0, -20.0, 10.0, 3.0, -2.0, 2.0, 12.0, 10.0, 13.0, -20.0, 12.0, 9.0, 12.0, -5.0, -1.0, 13.0, 12.0, -19.0, 9.0, 2.0, 12.0, 2.0, -1.0, 10.0, 12.0, -20.0, 13.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 12.0, 14.0, -21.0, 10.0, 9.0, 0.0, 13.0, -7.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -3.0, 0.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 12.0, 9.0, -3.0, -3.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -2.0, 13.0, -8.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, -2.0, -2.0, 6.0, -6.0, 13.0, -4.0, 12.0, 316.0, 12.0, 13.0, 11.0, 11.0, 0.0, -3.0, 7.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 2.0, -2.0, 2.0, 316.0, 14.0, 13.0, 9.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -5.0, 14.0, 12.0, -6.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 315.0, 14.0, 13.0, 12.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -7.0, 6.0, 5.0, 11.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, -6.0, 13.0, -4.0, 12.0, 316.0, 13.0, 13.0, 11.0, 13.0, 5.0, -2.0, -1.0, 318.0, 14.0, 13.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48683955670580586, "mean_inference_ms": 2.0144714062923668, "mean_action_processing_ms": 0.12044726638731836, "mean_env_wait_ms": 0.2846221441604323, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 643680, "agent_timesteps_total": 643599, "timers": {"learn_time_ms": 1.917, "learn_throughput": 16688.973, "update_time_ms": 4.127}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.769192218780518, "min_q": 0.8566558957099915, "max_q": 8.965849876403809, "mean_td_error": 0.6961468458175659, "model": {}}}, "num_steps_sampled": 643680, "num_agent_steps_sampled": 643599, "num_steps_trained": 190432, "num_agent_steps_trained": 190432, "last_target_update_ts": 643680, "num_target_updates": 1191}, "done": false, "episodes_total": 12609, "training_iteration": 205, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-38", "timestamp": 1626859958, "time_this_iter_s": 1.1673946380615234, "time_total_s": 232.85529351234436, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 232.85529351234436, "timesteps_since_restore": 0, "iterations_since_restore": 205, "perf": {"cpu_util_percent": 51.150000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.81, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 5.4525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, 8.0, 14.0, 8.0, -15.0, -8.0, 0.0, 13.0, 10.0, 6.0, -1.0, 3.0, 7.0, 320.0, 13.0, 12.0, 10.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, 5.0, 0.0, 6.0, 4.0, 9.0, -17.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -5.0, 14.0, 6.0, 0.0, 8.0, -16.0, 12.0, 11.0, 4.0, 14.0, -7.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 7.0, -15.0, 13.0, 10.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, 7.0, 14.0, -5.0, -1.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -6.0, 14.0, 6.0, 1.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 7.0, -10.0, 12.0, 6.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, 5.0, 0.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, 12.0, 13.0, -16.0, 6.0, 8.0, -16.0, 12.0, 11.0, 6.0, 0.0, 8.0, 1.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -8.0, 14.0, 5.0, 4.0, 8.0, -16.0, 12.0, 11.0, 2.0, 12.0, 2.0, -1.0, 11.0, 12.0, -20.0, 12.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -19.0, 9.0, 2.0, 12.0, 2.0, -1.0, 13.0, 7.0, -2.0, -3.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, -3.0, 12.0, 12.0, -6.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 5.0, 10.0, 2.0, -2.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 14.0, 11.0, 318.0, 13.0, 7.0, 12.0, -3.0, -1.0, 13.0, 12.0, -20.0, 10.0, 3.0, -2.0, 2.0, 12.0, 10.0, 13.0, -20.0, 12.0, 9.0, 12.0, -5.0, -1.0, 13.0, 12.0, -19.0, 9.0, 2.0, 12.0, 2.0, -1.0, 10.0, 12.0, -20.0, 13.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 13.0, 12.0, -20.0, 10.0, 2.0, 12.0, 2.0, -1.0, 12.0, 14.0, -21.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49228319628698464, "mean_inference_ms": 2.0277660362179235, "mean_action_processing_ms": 0.12149176937950795, "mean_env_wait_ms": 0.2872880492892888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 646920, "agent_timesteps_total": 646839, "timers": {"learn_time_ms": 1.803, "learn_throughput": 17747.564, "update_time_ms": 4.457}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.181496620178223, "min_q": 0.878969132900238, "max_q": 8.736213684082031, "mean_td_error": 1.2118490934371948, "model": {}}}, "num_steps_sampled": 646920, "num_agent_steps_sampled": 646839, "num_steps_trained": 191392, "num_agent_steps_trained": 191392, "last_target_update_ts": 646920, "num_target_updates": 1197}, "done": false, "episodes_total": 12663, "training_iteration": 206, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-39", "timestamp": 1626859959, "time_this_iter_s": 1.1016466617584229, "time_total_s": 233.95694017410278, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 233.95694017410278, "timesteps_since_restore": 0, "iterations_since_restore": 206, "perf": {"cpu_util_percent": 49.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 109.7, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 27.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 5.0, -4.0, 4.0, 11.0, 13.0, 12.0, -21.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 13.0, 13.0, 314.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 6.0, 12.0, -14.0, 14.0, 13.0, 313.0, 13.0, 0.0, 13.0, 7.0, -5.0, 12.0, 3.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 314.0, 13.0, 11.0, 13.0, 12.0, -21.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, 12.0, 2.0, 13.0, -12.0, 9.0, -6.0, -1.0, 13.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, 12.0, 2.0, 13.0, -12.0, 13.0, 0.0, -1.0, 3.0, 14.0, 13.0, 314.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 3.0, -1.0, 2.0, 14.0, 13.0, 313.0, 13.0, 10.0, 13.0, 3.0, -11.0, 11.0, -20.0, 12.0, 12.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, 12.0, 13.0, 12.0, 317.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 314.0, 13.0, -1.0, 13.0, 7.0, -4.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, 13.0, 2.0, 13.0, -13.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, -7.0, -3.0, 12.0, 13.0, 14.0, 13.0, 314.0, 13.0, 12.0, 13.0, 12.0, 317.0, 13.0, 1.0, -1.0, 2.0, 14.0, 13.0, 313.0, 13.0, 9.0, 13.0, -3.0, -4.0, 13.0, -10.0, -1.0, 13.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, -19.0, 12.0, 11.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, -19.0, 12.0, 11.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 7.0, -10.0, 12.0, 6.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, 5.0, 0.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, 12.0, 13.0, -16.0, 6.0, 8.0, -16.0, 12.0, 11.0, 6.0, 0.0, 8.0, 1.0, 8.0, -16.0, 12.0, 11.0, -9.0, 14.0, 6.0, 4.0, 8.0, -16.0, 12.0, 11.0, -8.0, 14.0, 5.0, 4.0, 8.0, -16.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4893896521109146, "mean_inference_ms": 2.019735955743008, "mean_action_processing_ms": 0.12084140998909565, "mean_env_wait_ms": 0.28588184085770224, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 650160, "agent_timesteps_total": 650079, "timers": {"learn_time_ms": 1.843, "learn_throughput": 17359.407, "update_time_ms": 4.623}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.6667375564575195, "min_q": 0.9742658734321594, "max_q": 8.696799278259277, "mean_td_error": -9.9321870803833, "model": {}}}, "num_steps_sampled": 650160, "num_agent_steps_sampled": 650079, "num_steps_trained": 192352, "num_agent_steps_trained": 192352, "last_target_update_ts": 650160, "num_target_updates": 1203}, "done": false, "episodes_total": 12744, "training_iteration": 207, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-40", "timestamp": 1626859960, "time_this_iter_s": 1.1605024337768555, "time_total_s": 235.11744260787964, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 235.11744260787964, "timesteps_since_restore": 0, "iterations_since_restore": 207, "perf": {"cpu_util_percent": 51.25, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 75.88, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 18.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 354.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, -2.0, 10.0, 8.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 10.0, -5.0, -1.0, 11.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -3.0, -7.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, -4.0, 14.0, -5.0, 10.0, -7.0, 13.0, -2.0, 11.0, 9.0, -1.0, 12.0, -5.0, 12.0, 316.0, 12.0, 13.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, 12.0, -22.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, -3.0, 14.0, -6.0, 10.0, -5.0, 13.0, -2.0, 9.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -18.0, 12.0, 8.0, 13.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 8.0, 14.0, -2.0, -5.0, -8.0, 14.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, -7.0, 14.0, 12.0, -4.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 8.0, 14.0, -2.0, -5.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 3.0, -1.0, 2.0, 14.0, 13.0, 313.0, 13.0, 10.0, 13.0, 3.0, -11.0, 11.0, -20.0, 12.0, 12.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, 12.0, 13.0, 12.0, 317.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 314.0, 13.0, -1.0, 13.0, 7.0, -4.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, 13.0, 2.0, 13.0, -13.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, -7.0, -3.0, 12.0, 13.0, 14.0, 13.0, 314.0, 13.0, 12.0, 13.0, 12.0, 317.0, 13.0, 1.0, -1.0, 2.0, 14.0, 13.0, 313.0, 13.0, 9.0, 13.0, -3.0, -4.0, 13.0, -10.0, -1.0, 13.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, -19.0, 12.0, 11.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, 4.0, -1.0, 1.0, 14.0, 13.0, 313.0, 13.0, -2.0, 13.0, 7.0, -3.0, 11.0, -19.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4868281297733171, "mean_inference_ms": 2.014420103201015, "mean_action_processing_ms": 0.12044243087513029, "mean_env_wait_ms": 0.2846271326364029, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 653400, "agent_timesteps_total": 653319, "timers": {"learn_time_ms": 1.971, "learn_throughput": 16236.539, "update_time_ms": 4.998}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.916351079940796, "min_q": 0.6896936297416687, "max_q": 8.122502326965332, "mean_td_error": -9.1848726272583, "model": {}}}, "num_steps_sampled": 653400, "num_agent_steps_sampled": 653319, "num_steps_trained": 193312, "num_agent_steps_trained": 193312, "last_target_update_ts": 653400, "num_target_updates": 1209}, "done": false, "episodes_total": 12798, "training_iteration": 208, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-41", "timestamp": 1626859961, "time_this_iter_s": 1.1775798797607422, "time_total_s": 236.29502248764038, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985416a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 236.29502248764038, "timesteps_since_restore": 0, "iterations_since_restore": 208, "perf": {"cpu_util_percent": 51.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.38, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 13.0, -5.0, 13.0, 13.0, 4.0, -15.0, 13.0, -8.0, 13.0, -3.0, 13.0, 13.0, 6.0, -17.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -5.0, 13.0, -2.0, 9.0, 12.0, 4.0, 0.0, -1.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -10.0, 8.0, 6.0, 11.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -19.0, 13.0, 11.0, 10.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 12.0, 4.0, -14.0, 13.0, -6.0, 13.0, -5.0, 13.0, 12.0, 4.0, 0.0, -1.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -10.0, 8.0, 6.0, 11.0, 11.0, 7.0, -16.0, 13.0, -19.0, 13.0, 11.0, 10.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 6.0, -16.0, 11.0, 10.0, 13.0, -18.0, 10.0, 14.0, 4.0, -16.0, 13.0, -10.0, 8.0, 6.0, 11.0, 14.0, 5.0, -17.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 13.0, 5.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, 7.0, 12.0, -2.0, -2.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, 6.0, 12.0, -14.0, 11.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -7.0, 13.0, -2.0, 11.0, 10.0, -5.0, -1.0, 11.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -3.0, -7.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, -4.0, 14.0, -5.0, 10.0, -7.0, 13.0, -2.0, 11.0, 9.0, -1.0, 12.0, -5.0, 12.0, 316.0, 12.0, 13.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, 12.0, -22.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, -3.0, 14.0, -6.0, 10.0, -5.0, 13.0, -2.0, 9.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -18.0, 12.0, 8.0, 13.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 8.0, 14.0, -2.0, -5.0, -8.0, 14.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, -7.0, 14.0, 12.0, -4.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 11.0, 14.0, -5.0, -5.0, -7.0, 13.0, -2.0, 11.0, 8.0, 14.0, -2.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4923838841431005, "mean_inference_ms": 2.028165867070652, "mean_action_processing_ms": 0.1215050455397205, "mean_env_wait_ms": 0.2873739099765102, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 655560, "agent_timesteps_total": 655480, "timers": {"learn_time_ms": 1.924, "learn_throughput": 16630.246, "update_time_ms": 4.846}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.110910415649414, "min_q": 0.7128763794898987, "max_q": 8.314798355102539, "mean_td_error": -9.91443157196045, "model": {}}}, "num_steps_sampled": 655560, "num_agent_steps_sampled": 655480, "num_steps_trained": 193952, "num_agent_steps_trained": 193952, "last_target_update_ts": 655560, "num_target_updates": 1213}, "done": false, "episodes_total": 12852, "training_iteration": 209, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-42", "timestamp": 1626859962, "time_this_iter_s": 0.9944076538085938, "time_total_s": 237.28943014144897, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 237.28943014144897, "timesteps_since_restore": 0, "iterations_since_restore": 209, "perf": {"cpu_util_percent": 38.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 313.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -2.0, -8.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -1.0, -5.0, 13.0, 8.0, 13.0, 4.0, -2.0, 0.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 7.0, 7.0, -2.0, 3.0, -4.0, -6.0, 13.0, 12.0, 12.0, -1.0, 8.0, -4.0, -2.0, -8.0, 13.0, 12.0, 9.0, 10.0, -7.0, 3.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -1.0, -6.0, 13.0, 9.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 13.0, -10.0, 12.0, 0.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -7.0, 13.0, 13.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 13.0, -12.0, 8.0, 6.0, 13.0, 14.0, 12.0, 313.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, -1.0, 12.0, -2.0, 6.0, -4.0, -7.0, 13.0, 13.0, 8.0, 7.0, -2.0, 2.0, -2.0, -8.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -3.0, -7.0, 13.0, 12.0, 8.0, 7.0, -6.0, 6.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -5.0, -1.0, 13.0, 8.0, 8.0, 13.0, -2.0, -4.0, -4.0, -6.0, 13.0, 12.0, 13.0, 13.0, -6.0, -5.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -10.0, 8.0, 6.0, 11.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -19.0, 13.0, 11.0, 10.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 12.0, 4.0, -14.0, 13.0, -6.0, 13.0, -5.0, 13.0, 12.0, 4.0, 0.0, -1.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -10.0, 8.0, 6.0, 11.0, 11.0, 7.0, -16.0, 13.0, -19.0, 13.0, 11.0, 10.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 6.0, -16.0, 11.0, 10.0, 13.0, -18.0, 10.0, 14.0, 4.0, -16.0, 13.0, -10.0, 8.0, 6.0, 11.0, 14.0, 5.0, -17.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 13.0, 5.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, 7.0, 12.0, -2.0, -2.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0, 6.0, 12.0, -14.0, 11.0, 14.0, 4.0, -16.0, 13.0, -6.0, 13.0, -5.0, 13.0, 14.0, 4.0, -16.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49240977040907047, "mean_inference_ms": 2.0283386444990525, "mean_action_processing_ms": 0.12151358521822134, "mean_env_wait_ms": 0.28741543294061483, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 658800, "agent_timesteps_total": 658719, "timers": {"learn_time_ms": 1.942, "learn_throughput": 16481.173, "update_time_ms": 4.996}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.2744598388671875, "min_q": 0.830974817276001, "max_q": 8.96958065032959, "mean_td_error": -9.951634407043457, "model": {}}}, "num_steps_sampled": 658800, "num_agent_steps_sampled": 658719, "num_steps_trained": 194912, "num_agent_steps_trained": 194912, "last_target_update_ts": 658800, "num_target_updates": 1219}, "done": false, "episodes_total": 12906, "training_iteration": 210, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-43", "timestamp": 1626859963, "time_this_iter_s": 1.124706745147705, "time_total_s": 238.41413688659668, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 238.41413688659668, "timesteps_since_restore": 0, "iterations_since_restore": 210, "perf": {"cpu_util_percent": 51.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -11.0, 14.0, 5.0, 7.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 13.0, -5.0, 10.0, -3.0, -9.0, 14.0, 4.0, 6.0, 7.0, -3.0, 13.0, -2.0, -14.0, 14.0, 7.0, 8.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, 319.0, 13.0, 12.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, 10.0, -5.0, 2.0, 8.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -21.0, 13.0, 11.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -6.0, 9.0, 6.0, 6.0, 7.0, -17.0, 13.0, 12.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, 5.0, 0.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 7.0, -2.0, 13.0, -3.0, -2.0, 12.0, -3.0, 8.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 7.0, -2.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -4.0, 13.0, -6.0, -9.0, 11.0, 6.0, 7.0, 7.0, -2.0, 13.0, -3.0, -14.0, 14.0, 9.0, 6.0, -1.0, -5.0, 13.0, 8.0, 13.0, 4.0, -2.0, 0.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 7.0, 7.0, -2.0, 3.0, -4.0, -6.0, 13.0, 12.0, 12.0, -1.0, 8.0, -4.0, -2.0, -8.0, 13.0, 12.0, 9.0, 10.0, -7.0, 3.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -1.0, -6.0, 13.0, 9.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 13.0, -10.0, 12.0, 0.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -7.0, 13.0, 13.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 13.0, -12.0, 8.0, 6.0, 13.0, 14.0, 12.0, 313.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, -1.0, 12.0, -2.0, 6.0, -4.0, -7.0, 13.0, 13.0, 8.0, 7.0, -2.0, 2.0, -2.0, -8.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -3.0, -7.0, 13.0, 12.0, 8.0, 7.0, -6.0, 6.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -4.0, -6.0, 13.0, 12.0, 8.0, 7.0, -2.0, 2.0, -5.0, -1.0, 13.0, 8.0, 8.0, 13.0, -2.0, -4.0, -4.0, -6.0, 13.0, 12.0, 13.0, 13.0, -6.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49241522284990824, "mean_inference_ms": 2.028492229506134, "mean_action_processing_ms": 0.12152768402874457, "mean_env_wait_ms": 0.2874368454583007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 662040, "agent_timesteps_total": 661959, "timers": {"learn_time_ms": 1.954, "learn_throughput": 16380.801, "update_time_ms": 4.893}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.267916202545166, "min_q": 1.1200848817825317, "max_q": 9.325294494628906, "mean_td_error": -19.780155181884766, "model": {}}}, "num_steps_sampled": 662040, "num_agent_steps_sampled": 661959, "num_steps_trained": 195872, "num_agent_steps_trained": 195872, "last_target_update_ts": 662040, "num_target_updates": 1225}, "done": false, "episodes_total": 12960, "training_iteration": 211, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-45", "timestamp": 1626859965, "time_this_iter_s": 1.1753127574920654, "time_total_s": 239.58944964408875, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 239.58944964408875, "timesteps_since_restore": 0, "iterations_since_restore": 211, "perf": {"cpu_util_percent": 50.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, -6.0, 7.0, 13.0, 14.0, 8.0, -17.0, 10.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, -17.0, 13.0, 7.0, 12.0, 13.0, 9.0, -14.0, 7.0, 8.0, 9.0, -14.0, 12.0, 1.0, -6.0, 7.0, 13.0, 14.0, 5.0, -16.0, 12.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 5.0, 7.0, -9.0, 12.0, 1.0, -6.0, 7.0, 13.0, 14.0, 7.0, -18.0, 12.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 14.0, 5.0, -16.0, 12.0, -16.0, 11.0, 10.0, 10.0, 1.0, -6.0, 7.0, 13.0, 14.0, 7.0, -18.0, 12.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 11.0, 9.0, 2.0, -7.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 12.0, -17.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 10.0, -14.0, 7.0, 12.0, 14.0, 4.0, -2.0, -1.0, 0.0, 10.0, 10.0, -5.0, 11.0, 9.0, 2.0, -7.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 12.0, -12.0, 7.0, 8.0, 13.0, 11.0, -16.0, 7.0, 9.0, 11.0, 10.0, -15.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 9.0, 1.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, -2.0, 11.0, -5.0, 11.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 5.0, 9.0, 10.0, -9.0, 1.0, -6.0, 7.0, 13.0, 14.0, 5.0, -16.0, 12.0, -13.0, 10.0, 10.0, 8.0, 3.0, -6.0, 5.0, 13.0, 13.0, 13.0, -10.0, -1.0, -6.0, 9.0, 10.0, 2.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 3.0, 10.0, 7.0, -5.0, -4.0, -1.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -6.0, 9.0, 6.0, 6.0, 7.0, -17.0, 13.0, 12.0, -9.0, 14.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, 5.0, 0.0, 4.0, 6.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 7.0, -2.0, 13.0, -3.0, -2.0, 12.0, -3.0, 8.0, 12.0, -7.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 7.0, -2.0, 13.0, -3.0, -9.0, 14.0, 4.0, 6.0, 12.0, -4.0, 13.0, -6.0, -9.0, 11.0, 6.0, 7.0, 7.0, -2.0, 13.0, -3.0, -14.0, 14.0, 9.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48958641939862363, "mean_inference_ms": 2.0207458327458996, "mean_action_processing_ms": 0.12089091697423876, "mean_env_wait_ms": 0.28606757830582485, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 665280, "agent_timesteps_total": 665199, "timers": {"learn_time_ms": 1.946, "learn_throughput": 16447.042, "update_time_ms": 4.529}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.133864402770996, "min_q": 0.828778088092804, "max_q": 9.118797302246094, "mean_td_error": -9.26364517211914, "model": {}}}, "num_steps_sampled": 665280, "num_agent_steps_sampled": 665199, "num_steps_trained": 196832, "num_agent_steps_trained": 196832, "last_target_update_ts": 665280, "num_target_updates": 1231}, "done": false, "episodes_total": 13041, "training_iteration": 212, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-46", "timestamp": 1626859966, "time_this_iter_s": 1.1496796607971191, "time_total_s": 240.73912930488586, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 240.73912930488586, "timesteps_since_restore": 0, "iterations_since_restore": 212, "perf": {"cpu_util_percent": 48.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 14.0, 12.0, -17.0, 9.0, -1.0, 10.0, -3.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 0.0, -1.0, 12.0, 4.0, 4.0, -11.0, 11.0, 11.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 5.0, 2.0, 11.0, -3.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 12.0, -1.0, 9.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 13.0, -3.0, 12.0, -7.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 5.0, 10.0, 7.0, -7.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 12.0, -1.0, 9.0, -5.0, 6.0, 14.0, 12.0, -17.0, 5.0, -12.0, 11.0, 11.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 11.0, 11.0, 12.0, -19.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, 3.0, 6.0, -4.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 0.0, 10.0, 10.0, -5.0, 12.0, -17.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 10.0, -14.0, 7.0, 12.0, 14.0, 4.0, -2.0, -1.0, 0.0, 10.0, 10.0, -5.0, 11.0, 9.0, 2.0, -7.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 12.0, -12.0, 7.0, 8.0, 13.0, 11.0, -16.0, 7.0, 9.0, 11.0, 10.0, -15.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 9.0, 1.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, -2.0, 11.0, -5.0, 11.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 5.0, 9.0, 10.0, -9.0, 1.0, -6.0, 7.0, 13.0, 14.0, 5.0, -16.0, 12.0, -13.0, 10.0, 10.0, 8.0, 3.0, -6.0, 5.0, 13.0, 13.0, 13.0, -10.0, -1.0, -6.0, 9.0, 10.0, 2.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 3.0, 10.0, 7.0, -5.0, -4.0, -1.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0, 1.0, -6.0, 7.0, 13.0, 13.0, 11.0, -16.0, 7.0, 0.0, 10.0, 10.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48694434445336854, "mean_inference_ms": 2.0151460980283376, "mean_action_processing_ms": 0.12047929186358304, "mean_env_wait_ms": 0.2847928660101934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 668520, "agent_timesteps_total": 668439, "timers": {"learn_time_ms": 1.856, "learn_throughput": 17242.106, "update_time_ms": 4.675}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.7831573486328125, "min_q": 0.7582902908325195, "max_q": 9.783628463745117, "mean_td_error": -20.470693588256836, "model": {}}}, "num_steps_sampled": 668520, "num_agent_steps_sampled": 668439, "num_steps_trained": 197792, "num_agent_steps_trained": 197792, "last_target_update_ts": 668520, "num_target_updates": 1237}, "done": false, "episodes_total": 13095, "training_iteration": 213, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-47", "timestamp": 1626859967, "time_this_iter_s": 1.145092487335205, "time_total_s": 241.88422179222107, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 241.88422179222107, "timesteps_since_restore": 0, "iterations_since_restore": 213, "perf": {"cpu_util_percent": 50.349999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -16.0, 11.0, 11.0, 9.0, 7.0, 12.0, -13.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -9.0, 9.0, 6.0, 10.0, -19.0, 12.0, 12.0, 8.0, -16.0, 11.0, 12.0, 7.0, 3.0, 12.0, -7.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 8.0, -14.0, 9.0, 12.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -10.0, 9.0, 7.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -5.0, 12.0, -3.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 4.0, -6.0, 6.0, 11.0, 11.0, -19.0, 12.0, 11.0, 4.0, -6.0, 6.0, 11.0, 11.0, -19.0, 12.0, 11.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 0.0, -1.0, 12.0, 4.0, 4.0, -11.0, 11.0, 11.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 5.0, 2.0, 11.0, -3.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 12.0, -1.0, 9.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 13.0, -3.0, 12.0, -7.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 5.0, 10.0, 7.0, -7.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 12.0, -1.0, 9.0, -5.0, 6.0, 14.0, 12.0, -17.0, 5.0, -12.0, 11.0, 11.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 11.0, 11.0, 12.0, -19.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0, 6.0, 14.0, 12.0, -17.0, 10.0, 3.0, 6.0, -4.0, 6.0, 14.0, 12.0, -17.0, 10.0, -1.0, 11.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4924323074595959, "mean_inference_ms": 2.028619538019747, "mean_action_processing_ms": 0.12152716380698844, "mean_env_wait_ms": 0.28748243707569326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 671760, "agent_timesteps_total": 671679, "timers": {"learn_time_ms": 1.945, "learn_throughput": 16450.267, "update_time_ms": 4.266}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.32805061340332, "min_q": 0.789752185344696, "max_q": 9.54372501373291, "mean_td_error": 0.9541757702827454, "model": {}}}, "num_steps_sampled": 671760, "num_agent_steps_sampled": 671679, "num_steps_trained": 198752, "num_agent_steps_trained": 198752, "last_target_update_ts": 671760, "num_target_updates": 1243}, "done": false, "episodes_total": 13149, "training_iteration": 214, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-48", "timestamp": 1626859968, "time_this_iter_s": 1.2102298736572266, "time_total_s": 243.0944516658783, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 243.0944516658783, "timesteps_since_restore": 0, "iterations_since_restore": 214, "perf": {"cpu_util_percent": 50.85, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.8, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 5.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-18.0, 12.0, 8.0, 13.0, 12.0, 9.0, 11.0, -17.0, 14.0, 9.0, -14.0, 6.0, 2.0, 11.0, -6.0, 8.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 10.0, -15.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 12.0, -19.0, 8.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 9.0, 12.0, -15.0, 9.0, 1.0, 12.0, -6.0, 8.0, -19.0, 10.0, 13.0, 11.0, 14.0, 9.0, -14.0, 6.0, 8.0, 10.0, 5.0, -8.0, 12.0, 11.0, 11.0, -19.0, 13.0, 10.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 13.0, -4.0, 10.0, -4.0, 14.0, 9.0, -14.0, 6.0, -16.0, 12.0, 6.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -4.0, 10.0, 13.0, -4.0, 13.0, 13.0, 12.0, 316.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 10.0, 11.0, -18.0, 14.0, 10.0, -15.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 10.0, 11.0, -18.0, 14.0, 9.0, -14.0, 6.0, 322.0, 12.0, 9.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -19.0, 12.0, 13.0, 9.0, 7.0, 12.0, 7.0, -11.0, 14.0, 10.0, -15.0, 6.0, -17.0, 13.0, 6.0, 13.0, 12.0, 11.0, 13.0, -21.0, 14.0, 10.0, -17.0, 8.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -13.0, 5.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 9.0, -16.0, 11.0, 11.0, 11.0, -5.0, 12.0, -3.0, 9.0, -16.0, 11.0, 11.0, 11.0, -19.0, 12.0, 11.0, 4.0, -6.0, 6.0, 11.0, 11.0, -19.0, 12.0, 11.0, 4.0, -6.0, 6.0, 11.0, 11.0, -19.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4896488048541, "mean_inference_ms": 2.0208513793771106, "mean_action_processing_ms": 0.12090747577725817, "mean_env_wait_ms": 0.28611192258163237, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 675000, "agent_timesteps_total": 674919, "timers": {"learn_time_ms": 1.983, "learn_throughput": 16136.205, "update_time_ms": 4.651}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.184506893157959, "min_q": 0.5649327635765076, "max_q": 8.729443550109863, "mean_td_error": 1.1615500450134277, "model": {}}}, "num_steps_sampled": 675000, "num_agent_steps_sampled": 674919, "num_steps_trained": 199712, "num_agent_steps_trained": 199712, "last_target_update_ts": 675000, "num_target_updates": 1249}, "done": false, "episodes_total": 13230, "training_iteration": 215, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-49", "timestamp": 1626859969, "time_this_iter_s": 1.1582958698272705, "time_total_s": 244.25274753570557, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 244.25274753570557, "timesteps_since_restore": 0, "iterations_since_restore": 215, "perf": {"cpu_util_percent": 50.85, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.8, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 5.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -6.0, -3.0, 12.0, 12.0, -5.0, -3.0, 12.0, 11.0, -5.0, -4.0, 12.0, 12.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -3.0, -5.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, 9.0, -18.0, 12.0, 12.0, -5.0, -3.0, 12.0, 11.0, -6.0, -3.0, 12.0, 12.0, -5.0, -3.0, 12.0, 11.0, -6.0, -3.0, 12.0, 12.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 10.0, 13.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 10.0, -15.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 12.0, -19.0, 8.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 9.0, 12.0, -15.0, 9.0, 1.0, 12.0, -6.0, 8.0, -19.0, 10.0, 13.0, 11.0, 14.0, 9.0, -14.0, 6.0, 8.0, 10.0, 5.0, -8.0, 12.0, 11.0, 11.0, -19.0, 13.0, 10.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 13.0, -4.0, 10.0, -4.0, 14.0, 9.0, -14.0, 6.0, -16.0, 12.0, 6.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -4.0, 10.0, 13.0, -4.0, 13.0, 13.0, 12.0, 316.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 10.0, 11.0, -18.0, 14.0, 10.0, -15.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -18.0, 12.0, 8.0, 13.0, 12.0, 10.0, 11.0, -18.0, 14.0, 9.0, -14.0, 6.0, 322.0, 12.0, 9.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -14.0, 6.0, -19.0, 12.0, 13.0, 9.0, 7.0, 12.0, 7.0, -11.0, 14.0, 10.0, -15.0, 6.0, -17.0, 13.0, 6.0, 13.0, 12.0, 11.0, 13.0, -21.0, 14.0, 10.0, -17.0, 8.0, -18.0, 12.0, 8.0, 13.0, 12.0, 11.0, 11.0, -19.0, 14.0, 9.0, -13.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49238062048387105, "mean_inference_ms": 2.028574793103571, "mean_action_processing_ms": 0.12159284918641243, "mean_env_wait_ms": 0.28737384770072777, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 677160, "agent_timesteps_total": 677079, "timers": {"learn_time_ms": 1.968, "learn_throughput": 16263.887, "update_time_ms": 4.513}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.0807108879089355, "min_q": 1.1449158191680908, "max_q": 9.496722221374512, "mean_td_error": -0.11225991696119308, "model": {}}}, "num_steps_sampled": 677160, "num_agent_steps_sampled": 677079, "num_steps_trained": 200352, "num_agent_steps_trained": 200352, "last_target_update_ts": 677160, "num_target_updates": 1253}, "done": false, "episodes_total": 13257, "training_iteration": 216, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-51", "timestamp": 1626859971, "time_this_iter_s": 0.9804587364196777, "time_total_s": 245.23320627212524, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 245.23320627212524, "timesteps_since_restore": 0, "iterations_since_restore": 216, "perf": {"cpu_util_percent": 36.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 13.0, 5.0, 2.0, 5.0, 9.0, -10.0, 11.0, 11.0, -19.0, 13.0, 10.0, -13.0, 13.0, 5.0, 10.0, -7.0, 0.0, 9.0, 13.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 9.0, -3.0, -2.0, 11.0, 6.0, -9.0, 13.0, 5.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, -2.0, -8.0, 13.0, 12.0, -5.0, 13.0, -3.0, 10.0, 5.0, 9.0, -5.0, 6.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 4.0, 9.0, -9.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 3.0, 6.0, -5.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 8.0, 2.0, -6.0, 11.0, 11.0, -15.0, 9.0, 10.0, -12.0, 13.0, 7.0, 7.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, -9.0, 3.0, 12.0, 9.0, 11.0, -15.0, 13.0, 6.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 14.0, -6.0, -5.0, 12.0, -14.0, 12.0, 10.0, 7.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 4.0, 5.0, -5.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 10.0, 4.0, -8.0, 9.0, 11.0, 4.0, 13.0, -13.0, -16.0, 13.0, 6.0, 12.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -17.0, 13.0, 9.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -12.0, 12.0, 3.0, 12.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -11.0, 14.0, 1.0, 11.0, 7.0, 4.0, 11.0, -7.0, 11.0, -4.0, 13.0, -5.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -3.0, -5.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, 9.0, -18.0, 12.0, 12.0, -5.0, -3.0, 12.0, 11.0, -6.0, -3.0, 12.0, 12.0, -5.0, -3.0, 12.0, 11.0, -6.0, -3.0, 12.0, 12.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 10.0, 13.0, -5.0, -3.0, 12.0, 11.0, -5.0, -3.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49318432069380386, "mean_inference_ms": 2.030060026955029, "mean_action_processing_ms": 0.12166473263402641, "mean_env_wait_ms": 0.2878762605826657, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 680400, "agent_timesteps_total": 680319, "timers": {"learn_time_ms": 1.939, "learn_throughput": 16506.915, "update_time_ms": 4.524}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.985650539398193, "min_q": 0.9828383922576904, "max_q": 9.020585060119629, "mean_td_error": 0.9691271781921387, "model": {}}}, "num_steps_sampled": 680400, "num_agent_steps_sampled": 680319, "num_steps_trained": 201312, "num_agent_steps_trained": 201312, "last_target_update_ts": 680400, "num_target_updates": 1259}, "done": false, "episodes_total": 13338, "training_iteration": 217, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-52", "timestamp": 1626859972, "time_this_iter_s": 1.182729721069336, "time_total_s": 246.41593599319458, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 246.41593599319458, "timesteps_since_restore": 0, "iterations_since_restore": 217, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 12.0, 2.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 3.0, 9.0, 10.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 14.0, 2.0, 8.0, -9.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 9.0, 4.0, -6.0, 8.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 14.0, 10.0, 9.0, 12.0, -2.0, 12.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 5.0, 12.0, -12.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 12.0, 2.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 3.0, 9.0, 10.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, 320.0, 13.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 5.0, 9.0, 8.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 12.0, 2.0, 8.0, -7.0, -18.0, 12.0, 12.0, 9.0, 14.0, 0.0, 8.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, -9.0, 3.0, 12.0, 9.0, 11.0, -15.0, 13.0, 6.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 14.0, -6.0, -5.0, 12.0, -14.0, 12.0, 10.0, 7.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 4.0, 5.0, -5.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 10.0, 4.0, -8.0, 9.0, 11.0, 4.0, 13.0, -13.0, -16.0, 13.0, 6.0, 12.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -17.0, 13.0, 9.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -12.0, 12.0, 3.0, 12.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -11.0, 14.0, 1.0, 11.0, 7.0, 4.0, 11.0, -7.0, 11.0, -4.0, 13.0, -5.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0, -13.0, 13.0, 5.0, 10.0, 5.0, 9.0, -10.0, 11.0, 11.0, -11.0, 13.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4871904636317171, "mean_inference_ms": 2.0158372906051123, "mean_action_processing_ms": 0.12053344028351878, "mean_env_wait_ms": 0.2849471117140516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 683640, "agent_timesteps_total": 683559, "timers": {"learn_time_ms": 1.992, "learn_throughput": 16063.014, "update_time_ms": 4.648}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.262459754943848, "min_q": 0.9299944639205933, "max_q": 9.107205390930176, "mean_td_error": 0.8622035980224609, "model": {}}}, "num_steps_sampled": 683640, "num_agent_steps_sampled": 683559, "num_steps_trained": 202272, "num_agent_steps_trained": 202272, "last_target_update_ts": 683640, "num_target_updates": 1265}, "done": false, "episodes_total": 13392, "training_iteration": 218, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-53", "timestamp": 1626859973, "time_this_iter_s": 1.1648313999176025, "time_total_s": 247.58076739311218, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 247.58076739311218, "timesteps_since_restore": 0, "iterations_since_restore": 218, "perf": {"cpu_util_percent": 52.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 103.14, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 25.785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -13.0, 13.0, 8.0, 7.0, 11.0, 11.0, 7.0, -14.0, -8.0, 13.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -19.0, 13.0, 9.0, 12.0, 11.0, 13.0, 13.0, 317.0, -11.0, 12.0, 8.0, 6.0, 11.0, 13.0, 13.0, 317.0, -9.0, 10.0, 4.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -7.0, 12.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -15.0, 14.0, 13.0, 3.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -15.0, 13.0, 7.0, 10.0, 11.0, 13.0, 13.0, 317.0, -10.0, 11.0, 4.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -13.0, 8.0, 8.0, 12.0, 10.0, 14.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -19.0, 13.0, 9.0, 12.0, 11.0, 13.0, 13.0, 317.0, -7.0, 14.0, 8.0, 0.0, 13.0, 9.0, 13.0, -20.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, 3.0, 9.0, 10.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 14.0, 2.0, 8.0, -9.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 9.0, 4.0, -6.0, 8.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 14.0, 10.0, 9.0, 12.0, -2.0, 12.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 5.0, 12.0, -12.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 12.0, 2.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 3.0, 9.0, 10.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, 320.0, 13.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 5.0, 9.0, 8.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0, 12.0, 2.0, 8.0, -7.0, -18.0, 12.0, 12.0, 9.0, 14.0, 0.0, 8.0, -7.0, -18.0, 12.0, 12.0, 9.0, 10.0, 4.0, 12.0, -11.0, -18.0, 12.0, 12.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4927025250393661, "mean_inference_ms": 2.0296122058088444, "mean_action_processing_ms": 0.12159572146753214, "mean_env_wait_ms": 0.28764823778301035, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 686880, "agent_timesteps_total": 686799, "timers": {"learn_time_ms": 1.855, "learn_throughput": 17249.419, "update_time_ms": 4.337}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.443168878555298, "min_q": 0.8600291609764099, "max_q": 9.192609786987305, "mean_td_error": -20.769119262695312, "model": {}}}, "num_steps_sampled": 686880, "num_agent_steps_sampled": 686799, "num_steps_trained": 203232, "num_agent_steps_trained": 203232, "last_target_update_ts": 686880, "num_target_updates": 1271}, "done": false, "episodes_total": 13446, "training_iteration": 219, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-54", "timestamp": 1626859974, "time_this_iter_s": 1.1716008186340332, "time_total_s": 248.75236821174622, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 248.75236821174622, "timesteps_since_restore": 0, "iterations_since_restore": 219, "perf": {"cpu_util_percent": 50.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 45.51, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 11.3775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, 5.0, 4.0, 6.0, -1.0, -6.0, 9.0, 13.0, 11.0, -2.0, 13.0, -7.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -3.0, 9.0, 9.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, 9.0, -9.0, 4.0, -5.0, 13.0, -2.0, 9.0, -1.0, -6.0, 9.0, 13.0, 10.0, 11.0, -6.0, 0.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, 9.0, 4.0, -9.0, 0.0, -1.0, 9.0, 7.0, 7.0, 0.0, -5.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, 7.0, 13.0, -16.0, 0.0, -1.0, 9.0, 7.0, 12.0, -18.0, 8.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, 2.0, 6.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, 5.0, 6.0, -7.0, -5.0, 13.0, -2.0, 9.0, 4.0, -4.0, 2.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, 8.0, 0.0, -5.0, 12.0, 11.0, -3.0, 13.0, -6.0, 9.0, -7.0, 5.0, 8.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, -5.0, 13.0, -3.0, 10.0, -3.0, 11.0, 11.0, -4.0, 10.0, 12.0, -9.0, 2.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, 8.0, -1.0, -3.0, 13.0, -11.0, 4.0, 9.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, 5.0, 11.0, 6.0, -7.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -13.0, 8.0, 8.0, 12.0, 10.0, 14.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -19.0, 13.0, 9.0, 12.0, 11.0, 13.0, 13.0, 317.0, -7.0, 14.0, 8.0, 0.0, 13.0, 9.0, 13.0, -20.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0, -9.0, 14.0, 0.0, 10.0, 11.0, 13.0, 13.0, 317.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48987958068647347, "mean_inference_ms": 2.0219230946278146, "mean_action_processing_ms": 0.12096622012771802, "mean_env_wait_ms": 0.28633796864393957, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 690120, "agent_timesteps_total": 690039, "timers": {"learn_time_ms": 1.943, "learn_throughput": 16466.817, "update_time_ms": 4.456}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.433269023895264, "min_q": 1.2484400272369385, "max_q": 9.478734970092773, "mean_td_error": 0.6870940923690796, "model": {}}}, "num_steps_sampled": 690120, "num_agent_steps_sampled": 690039, "num_steps_trained": 204192, "num_agent_steps_trained": 204192, "last_target_update_ts": 690120, "num_target_updates": 1277}, "done": false, "episodes_total": 13527, "training_iteration": 220, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-55", "timestamp": 1626859975, "time_this_iter_s": 1.183173656463623, "time_total_s": 249.93554186820984, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985412f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 249.93554186820984, "timesteps_since_restore": 0, "iterations_since_restore": 220, "perf": {"cpu_util_percent": 50.65, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, 1.0, 11.0, -5.0, 8.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, 2.0, 7.0, -6.0, 12.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -1.0, 11.0, -8.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 1.0, -3.0, 5.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 11.0, 4.0, -5.0, 5.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, 320.0, 12.0, 10.0, 12.0, -21.0, 13.0, 10.0, 13.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, -19.0, 13.0, 8.0, 13.0, 2.0, 7.0, -6.0, 12.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 9.0, 13.0, -3.0, -4.0, 320.0, 12.0, 10.0, 12.0, 10.0, 13.0, -7.0, -1.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 12.0, -5.0, 13.0, 12.0, 4.0, -3.0, 2.0, 1.0, 11.0, 8.0, -5.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -2.0, 11.0, -4.0, 10.0, 12.0, 4.0, -3.0, 2.0, 4.0, 6.0, 12.0, -7.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 13.0, -2.0, -8.0, 11.0, 7.0, 13.0, -16.0, 0.0, -1.0, 9.0, 7.0, 12.0, -18.0, 8.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, 2.0, 6.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, 5.0, 6.0, -7.0, -5.0, 13.0, -2.0, 9.0, 4.0, -4.0, 2.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, 8.0, 0.0, -5.0, 12.0, 11.0, -3.0, 13.0, -6.0, 9.0, -7.0, 5.0, 8.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, -5.0, 13.0, -3.0, 10.0, -3.0, 11.0, 11.0, -4.0, 10.0, 12.0, -9.0, 2.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, 8.0, -1.0, -3.0, 13.0, -11.0, 4.0, 9.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, 5.0, 11.0, 6.0, -7.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0, 0.0, -1.0, 9.0, 7.0, -1.0, -6.0, 9.0, 13.0, 11.0, -3.0, 13.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48733599904215796, "mean_inference_ms": 2.0162840809443026, "mean_action_processing_ms": 0.12057176716991604, "mean_env_wait_ms": 0.285085171568752, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 693360, "agent_timesteps_total": 693279, "timers": {"learn_time_ms": 1.848, "learn_throughput": 17313.278, "update_time_ms": 4.233}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.682442665100098, "min_q": 1.290619969367981, "max_q": 9.06535530090332, "mean_td_error": 0.27913549542427063, "model": {}}}, "num_steps_sampled": 693360, "num_agent_steps_sampled": 693279, "num_steps_trained": 205152, "num_agent_steps_trained": 205152, "last_target_update_ts": 693360, "num_target_updates": 1283}, "done": false, "episodes_total": 13581, "training_iteration": 221, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-57", "timestamp": 1626859977, "time_this_iter_s": 1.1461474895477295, "time_total_s": 251.08168935775757, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 251.08168935775757, "timesteps_since_restore": 0, "iterations_since_restore": 221, "perf": {"cpu_util_percent": 50.25, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 3.0, 8.0, 13.0, 6.0, -3.0, 12.0, 0.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 10.0, -3.0, 6.0, 2.0, 4.0, -6.0, 4.0, 13.0, -1.0, -2.0, 9.0, 9.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, -2.0, 11.0, 1.0, 5.0, 13.0, -8.0, 11.0, -1.0, 11.0, -3.0, 6.0, 1.0, 8.0, -8.0, 11.0, 4.0, -2.0, 11.0, 1.0, 5.0, 7.0, -8.0, 11.0, 5.0, 4.0, -2.0, 12.0, 1.0, 7.0, -8.0, 11.0, 5.0, 9.0, -8.0, 2.0, 12.0, 4.0, 3.0, 9.0, -1.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 4.0, 3.0, 9.0, -1.0, -1.0, -2.0, 6.0, 12.0, 3.0, -8.0, 12.0, 8.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 7.0, 0.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 6.0, -3.0, 11.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -1.0, 11.0, -8.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 1.0, -3.0, 5.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 11.0, 4.0, -5.0, 5.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, 320.0, 12.0, 10.0, 12.0, -21.0, 13.0, 10.0, 13.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, -19.0, 13.0, 8.0, 13.0, 2.0, 7.0, -6.0, 12.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 9.0, 13.0, -3.0, -4.0, 320.0, 12.0, 10.0, 12.0, 10.0, 13.0, -7.0, -1.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -5.0, 12.0, -5.0, 13.0, 12.0, 4.0, -3.0, 2.0, 1.0, 11.0, 8.0, -5.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 4.0, -3.0, 2.0, -2.0, 11.0, -4.0, 10.0, 12.0, 4.0, -3.0, 2.0, 4.0, 6.0, 12.0, -7.0, 12.0, 4.0, -3.0, 2.0, -5.0, 11.0, -4.0, 13.0, 12.0, 13.0, -2.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4928095666529025, "mean_inference_ms": 2.0298652122406633, "mean_action_processing_ms": 0.1216163905787377, "mean_env_wait_ms": 0.28774989451237293, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 696600, "agent_timesteps_total": 696519, "timers": {"learn_time_ms": 2.043, "learn_throughput": 15664.087, "update_time_ms": 4.434}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.3668293952941895, "min_q": 0.7071345448493958, "max_q": 9.025555610656738, "mean_td_error": 0.9995813369750977, "model": {}}}, "num_steps_sampled": 696600, "num_agent_steps_sampled": 696519, "num_steps_trained": 206112, "num_agent_steps_trained": 206112, "last_target_update_ts": 696600, "num_target_updates": 1289}, "done": false, "episodes_total": 13635, "training_iteration": 222, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-58", "timestamp": 1626859978, "time_this_iter_s": 1.1791155338287354, "time_total_s": 252.2608048915863, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 252.2608048915863, "timesteps_since_restore": 0, "iterations_since_restore": 222, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 6.0, -4.0, 8.0, 5.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 12.0, 6.0, 12.0, -15.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -4.0, -6.0, 12.0, 13.0, 8.0, 13.0, -17.0, 11.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 13.0, -6.0, 12.0, -4.0, -2.0, -7.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 13.0, -9.0, 13.0, -2.0, -3.0, 10.0, 9.0, -1.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -15.0, 6.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, -4.0, 9.0, 7.0, 3.0, -1.0, -8.0, 12.0, 12.0, 9.0, 12.0, -17.0, 11.0, 9.0, -4.0, 8.0, 2.0, -17.0, 8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, 2.0, 5.0, 9.0, -1.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 8.0, 3.0, -7.0, 11.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, 9.0, 8.0, -11.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, 5.0, 12.0, -1.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 14.0, 0.0, -3.0, 4.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 13.0, 5.0, 12.0, -15.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 7.0, -2.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -2.0, -7.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 12.0, 13.0, -8.0, -2.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, 11.0, 8.0, -13.0, -1.0, -8.0, 12.0, 12.0, 9.0, 12.0, -17.0, 11.0, 9.0, 11.0, 8.0, -13.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -2.0, -7.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 7.0, 0.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 6.0, -3.0, 11.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0, 7.0, -8.0, 11.0, 5.0, 11.0, -3.0, 6.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4899579760108325, "mean_inference_ms": 2.021936607080453, "mean_action_processing_ms": 0.12097346245906498, "mean_env_wait_ms": 0.2863738075398852, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 699840, "agent_timesteps_total": 699759, "timers": {"learn_time_ms": 1.914, "learn_throughput": 16718.909, "update_time_ms": 4.78}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.6382036209106445, "min_q": 0.7966611385345459, "max_q": 8.26589298248291, "mean_td_error": 0.09143038094043732, "model": {}}}, "num_steps_sampled": 699840, "num_agent_steps_sampled": 699759, "num_steps_trained": 207072, "num_agent_steps_trained": 207072, "last_target_update_ts": 699840, "num_target_updates": 1295}, "done": false, "episodes_total": 13716, "training_iteration": 223, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-32-59", "timestamp": 1626859979, "time_this_iter_s": 1.3411877155303955, "time_total_s": 253.6019926071167, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 253.6019926071167, "timesteps_since_restore": 0, "iterations_since_restore": 223, "perf": {"cpu_util_percent": 44.75, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, -2.0, -3.0, 13.0, 7.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -13.0, 9.0, 11.0, 12.0, 12.0, -7.0, -2.0, 5.0, -12.0, 13.0, 9.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -19.0, 10.0, 8.0, -17.0, 13.0, 11.0, -2.0, 12.0, -6.0, 11.0, 5.0, -14.0, 13.0, 11.0, 12.0, 5.0, 1.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -19.0, 10.0, 3.0, -12.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 11.0, 12.0, -19.0, 11.0, -1.0, -7.0, 13.0, 10.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 11.0, 11.0, -19.0, 12.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -19.0, 10.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 3.0, -12.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 5.0, -14.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 8.0, 3.0, -7.0, 11.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, 9.0, 8.0, -11.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, 5.0, 12.0, -1.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 14.0, 0.0, -3.0, 4.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 13.0, 5.0, 12.0, -15.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 7.0, -2.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -2.0, -7.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 12.0, 13.0, -8.0, -2.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, 11.0, 8.0, -13.0, -1.0, -8.0, 12.0, 12.0, 9.0, 12.0, -17.0, 11.0, 9.0, 11.0, 8.0, -13.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -2.0, -7.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0, 9.0, -4.0, 8.0, 2.0, -1.0, -8.0, 12.0, 12.0, 0.0, 14.0, -11.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4873949302555435, "mean_inference_ms": 2.0165506569090113, "mean_action_processing_ms": 0.12058987068002322, "mean_env_wait_ms": 0.2851522096993425, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 703080, "agent_timesteps_total": 702999, "timers": {"learn_time_ms": 2.002, "learn_throughput": 15984.581, "update_time_ms": 6.677}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.939444541931152, "min_q": 0.844204306602478, "max_q": 9.25924301147461, "mean_td_error": 1.5596318244934082, "model": {}}}, "num_steps_sampled": 703080, "num_agent_steps_sampled": 702999, "num_steps_trained": 208032, "num_agent_steps_trained": 208032, "last_target_update_ts": 703080, "num_target_updates": 1301}, "done": false, "episodes_total": 13770, "training_iteration": 224, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-01", "timestamp": 1626859981, "time_this_iter_s": 1.2184505462646484, "time_total_s": 254.82044315338135, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985419d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 254.82044315338135, "timesteps_since_restore": 0, "iterations_since_restore": 224, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 69.24, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 17.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -2.0, 12.0, -8.0, 7.0, 10.0, 11.0, -13.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 7.0, -2.0, 11.0, -1.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 12.0, 10.0, -4.0, -3.0, 13.0, 12.0, 10.0, 319.0, 13.0, 11.0, -18.0, 9.0, 13.0, 11.0, 12.0, 318.0, 12.0, 11.0, -5.0, -3.0, 13.0, -2.0, 12.0, -8.0, 7.0, 11.0, 0.0, -3.0, 13.0, 13.0, -4.0, -7.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 5.0, -15.0, 7.0, 11.0, 0.0, -3.0, 0.0, 12.0, -9.0, 12.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, -9.0, -1.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 8.0, 12.0, -15.0, 10.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, -5.0, 9.0, -2.0, 13.0, 11.0, -18.0, 9.0, 13.0, -5.0, 9.0, -2.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 7.0, 13.0, 11.0, -16.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, -9.0, -1.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -13.0, 9.0, 11.0, 12.0, 12.0, -7.0, -2.0, 5.0, -12.0, 13.0, 9.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -19.0, 10.0, 8.0, -17.0, 13.0, 11.0, -2.0, 12.0, -6.0, 11.0, 5.0, -14.0, 13.0, 11.0, 12.0, 5.0, 1.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -19.0, 10.0, 3.0, -12.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 11.0, 12.0, -19.0, 11.0, -1.0, -7.0, 13.0, 10.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 8.0, -17.0, 13.0, 11.0, 11.0, 11.0, -19.0, 12.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -19.0, 10.0, 8.0, -17.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 3.0, -12.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0, 5.0, -14.0, 13.0, 11.0, 12.0, 12.0, -6.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49288782350207666, "mean_inference_ms": 2.0302507482067065, "mean_action_processing_ms": 0.12165862774350696, "mean_env_wait_ms": 0.28782869042372466, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 706320, "agent_timesteps_total": 706239, "timers": {"learn_time_ms": 1.865, "learn_throughput": 17162.295, "update_time_ms": 3.943}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.996777534484863, "min_q": 1.020466685295105, "max_q": 9.494545936584473, "mean_td_error": 0.967167854309082, "model": {}}}, "num_steps_sampled": 706320, "num_agent_steps_sampled": 706239, "num_steps_trained": 208992, "num_agent_steps_trained": 208992, "last_target_update_ts": 706320, "num_target_updates": 1307}, "done": false, "episodes_total": 13824, "training_iteration": 225, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-02", "timestamp": 1626859982, "time_this_iter_s": 1.159766435623169, "time_total_s": 255.98020958900452, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 255.98020958900452, "timesteps_since_restore": 0, "iterations_since_restore": 225, "perf": {"cpu_util_percent": 49.75, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 35.34, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 8.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -15.0, 11.0, 11.0, -15.0, 13.0, 7.0, 10.0, 11.0, 10.0, -5.0, -1.0, 14.0, 319.0, 8.0, 13.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 13.0, -21.0, 11.0, 12.0, 6.0, -7.0, 12.0, 4.0, 12.0, 13.0, -6.0, -4.0, 14.0, -17.0, 7.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 14.0, 1.0, -11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 5.0, 0.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 12.0, 10.0, -6.0, -1.0, 11.0, -20.0, 11.0, 13.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 6.0, 10.0, 0.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 3.0, 0.0, 10.0, 2.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 12.0, 7.0, -3.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 6.0, -1.0, -1.0, 8.0, -14.0, 11.0, 10.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 11.0, -18.0, 11.0, 11.0, 7.0, -5.0, 11.0, 2.0, 12.0, 10.0, -6.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 6.0, 9.0, 2.0, -2.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, -5.0, 9.0, -2.0, 13.0, 11.0, -18.0, 9.0, 13.0, -5.0, 9.0, -2.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0, 7.0, 13.0, 11.0, -16.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, -9.0, -1.0, 7.0, 11.0, 0.0, -3.0, 13.0, 12.0, 10.0, 319.0, 7.0, 11.0, 0.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49001271860014284, "mean_inference_ms": 2.0223449686633495, "mean_action_processing_ms": 0.12102678998079335, "mean_env_wait_ms": 0.2864443032213447, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 709560, "agent_timesteps_total": 709479, "timers": {"learn_time_ms": 1.82, "learn_throughput": 17583.876, "update_time_ms": 4.444}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.268739700317383, "min_q": 1.0946440696716309, "max_q": 8.71411418914795, "mean_td_error": 1.3898940086364746, "model": {}}}, "num_steps_sampled": 709560, "num_agent_steps_sampled": 709479, "num_steps_trained": 209952, "num_agent_steps_trained": 209952, "last_target_update_ts": 709560, "num_target_updates": 1313}, "done": false, "episodes_total": 13905, "training_iteration": 226, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-03", "timestamp": 1626859983, "time_this_iter_s": 1.1214137077331543, "time_total_s": 257.10162329673767, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 257.10162329673767, "timesteps_since_restore": 0, "iterations_since_restore": 226, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 13.0, -19.0, 13.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 7.0, 1.0, -5.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 7.0, 11.0, 12.0, -15.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 4.0, 13.0, -3.0, 1.0, 12.0, 12.0, 1.0, -10.0, 8.0, 14.0, -5.0, -2.0, -6.0, 7.0, 10.0, 4.0, 9.0, 13.0, -12.0, 5.0, 11.0, 12.0, -2.0, -6.0, 10.0, 13.0, -11.0, 3.0, 12.0, 12.0, 2.0, -11.0, 4.0, 13.0, -3.0, 1.0, 12.0, 3.0, 6.0, -6.0, 8.0, 13.0, -19.0, 13.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 6.0, -2.0, -1.0, 3.0, 13.0, -3.0, 2.0, 8.0, 6.0, 11.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 11.0, 5.0, 0.0, -1.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 7.0, 13.0, -3.0, -2.0, 12.0, 12.0, 1.0, -10.0, 4.0, 13.0, -3.0, 1.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 4.0, 13.0, -3.0, 1.0, 12.0, 7.0, -3.0, -1.0, 9.0, 13.0, -13.0, 6.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 7.0, 7.0, 3.0, -2.0, 12.0, 10.0, -6.0, -1.0, 11.0, -20.0, 11.0, 13.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 6.0, 10.0, 0.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 3.0, 0.0, 10.0, 2.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 12.0, 7.0, -3.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 6.0, -1.0, -1.0, 8.0, -14.0, 11.0, 10.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 11.0, -18.0, 11.0, 11.0, 7.0, -5.0, 11.0, 2.0, 12.0, 10.0, -6.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 6.0, 9.0, 2.0, -2.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0, 8.0, -15.0, 11.0, 11.0, 6.0, -7.0, 12.0, 4.0, 11.0, 10.0, -5.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48737238733872945, "mean_inference_ms": 2.0166638468406424, "mean_action_processing_ms": 0.1206262388386212, "mean_env_wait_ms": 0.2851491481581535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 712800, "agent_timesteps_total": 712719, "timers": {"learn_time_ms": 1.792, "learn_throughput": 17861.641, "update_time_ms": 4.47}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.803163528442383, "min_q": 0.735667884349823, "max_q": 8.977526664733887, "mean_td_error": 0.7550804615020752, "model": {}}}, "num_steps_sampled": 712800, "num_agent_steps_sampled": 712719, "num_steps_trained": 210912, "num_agent_steps_trained": 210912, "last_target_update_ts": 712800, "num_target_updates": 1319}, "done": false, "episodes_total": 13959, "training_iteration": 227, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-04", "timestamp": 1626859984, "time_this_iter_s": 1.0952274799346924, "time_total_s": 258.19685077667236, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 258.19685077667236, "timesteps_since_restore": 0, "iterations_since_restore": 227, "perf": {"cpu_util_percent": 48.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 12.0, 12.0, 5.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, 0.0, -1.0, 6.0, 10.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -13.0, 5.0, 12.0, 6.0, 12.0, 6.0, -9.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -10.0, 13.0, 3.0, 9.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, 1.0, 13.0, 10.0, -9.0, 13.0, 2.0, 12.0, -12.0, 6.0, 11.0, 2.0, -4.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 11.0, 4.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -19.0, 13.0, 12.0, 9.0, 13.0, 2.0, 12.0, -12.0, 13.0, -6.0, -2.0, 10.0, -19.0, 13.0, 12.0, 9.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, 0.0, 13.0, -8.0, 10.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, 0.0, 13.0, -7.0, 9.0, 13.0, 2.0, 12.0, -12.0, 6.0, 10.0, 2.0, -3.0, 6.0, 13.0, 10.0, -14.0, 13.0, 2.0, 12.0, -12.0, 11.0, -13.0, 8.0, 9.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -11.0, 4.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 6.0, -15.0, 13.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 11.0, 5.0, 0.0, -1.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 7.0, 13.0, -3.0, -2.0, 12.0, 12.0, 1.0, -10.0, 4.0, 13.0, -3.0, 1.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 12.0, 12.0, 1.0, -10.0, 4.0, 13.0, -3.0, 1.0, 12.0, 7.0, -3.0, -1.0, 9.0, 13.0, -13.0, 6.0, 12.0, 12.0, 1.0, -10.0, 9.0, 13.0, -12.0, 5.0, 7.0, 7.0, 3.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48998467432411674, "mean_inference_ms": 2.0220205039189842, "mean_action_processing_ms": 0.12101687806085842, "mean_env_wait_ms": 0.2863920918799674, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 716040, "agent_timesteps_total": 716040, "timers": {"learn_time_ms": 1.857, "learn_throughput": 17236.349, "update_time_ms": 4.214}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.308126449584961, "min_q": 0.9081854820251465, "max_q": 8.444585800170898, "mean_td_error": 0.855889081954956, "model": {}}}, "num_steps_sampled": 716040, "num_agent_steps_sampled": 716040, "num_steps_trained": 211872, "num_agent_steps_trained": 211872, "last_target_update_ts": 716040, "num_target_updates": 1325}, "done": false, "episodes_total": 14040, "training_iteration": 228, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-05", "timestamp": 1626859985, "time_this_iter_s": 1.1549103260040283, "time_total_s": 259.3517611026764, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791ea60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 259.3517611026764, "timesteps_since_restore": 0, "iterations_since_restore": 228, "perf": {"cpu_util_percent": 51.35, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, 2.0, -11.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -21.0, 11.0, 13.0, 12.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, 2.0, -8.0, 10.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -14.0, 5.0, 13.0, -7.0, 0.0, 9.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 6.0, 5.0, -9.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -1.0, 13.0, 6.0, -3.0, 6.0, 11.0, -15.0, 13.0, -10.0, 5.0, 11.0, 9.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, 11.0, -20.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -14.0, 5.0, 13.0, -9.0, 9.0, 5.0, 10.0, 11.0, -1.0, -8.0, 13.0, 3.0, 4.0, -5.0, 13.0, 11.0, -1.0, -8.0, 13.0, 315.0, 13.0, 13.0, 11.0, 11.0, 12.0, 13.0, 318.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -7.0, -1.0, 11.0, 12.0, 11.0, -11.0, 3.0, 12.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, 1.0, 13.0, 10.0, -9.0, 13.0, 2.0, 12.0, -12.0, 6.0, 11.0, 2.0, -4.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 11.0, 4.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -19.0, 13.0, 12.0, 9.0, 13.0, 2.0, 12.0, -12.0, 13.0, -6.0, -2.0, 10.0, -19.0, 13.0, 12.0, 9.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, 0.0, 13.0, -8.0, 10.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, 0.0, 13.0, -7.0, 9.0, 13.0, 2.0, 12.0, -12.0, 6.0, 10.0, 2.0, -3.0, 6.0, 13.0, 10.0, -14.0, 13.0, 2.0, 12.0, -12.0, 11.0, -13.0, 8.0, 9.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -11.0, 4.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 6.0, -15.0, 13.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48740865308348963, "mean_inference_ms": 2.0165356865612885, "mean_action_processing_ms": 0.12063100960307016, "mean_env_wait_ms": 0.2851308958319621, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 719280, "agent_timesteps_total": 719199, "timers": {"learn_time_ms": 1.922, "learn_throughput": 16646.747, "update_time_ms": 4.252}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.149941921234131, "min_q": 0.8246942162513733, "max_q": 8.648786544799805, "mean_td_error": -0.0661640465259552, "model": {}}}, "num_steps_sampled": 719280, "num_agent_steps_sampled": 719199, "num_steps_trained": 212832, "num_agent_steps_trained": 212832, "last_target_update_ts": 719280, "num_target_updates": 1331}, "done": false, "episodes_total": 14094, "training_iteration": 229, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-06", "timestamp": 1626859986, "time_this_iter_s": 1.1582410335540771, "time_total_s": 260.51000213623047, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 260.51000213623047, "timesteps_since_restore": 0, "iterations_since_restore": 229, "perf": {"cpu_util_percent": 51.75, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, -1.0, -9.0, 13.0, 12.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 12.0, 12.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, -3.0, -3.0, 10.0, 11.0, 0.0, -9.0, 13.0, 11.0, 5.0, -13.0, 11.0, 12.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, 13.0, -7.0, 9.0, 13.0, 2.0, 12.0, -12.0, 6.0, 10.0, 2.0, -3.0, 6.0, 13.0, 10.0, -14.0, 13.0, 2.0, 12.0, -12.0, 11.0, -13.0, 8.0, 9.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -11.0, 4.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 6.0, -15.0, 13.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, 13.0, 2.0, 12.0, -12.0, 11.0, -15.0, 8.0, 11.0, -14.0, 13.0, 10.0, 6.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, 2.0, -11.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -21.0, 11.0, 13.0, 12.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, 2.0, -8.0, 10.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -14.0, 5.0, 13.0, -7.0, 0.0, 9.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 6.0, 5.0, -9.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -1.0, 13.0, 6.0, -3.0, 6.0, 11.0, -15.0, 13.0, -10.0, 5.0, 11.0, 9.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, 11.0, -20.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -14.0, 5.0, 13.0, -9.0, 9.0, 5.0, 10.0, 11.0, -1.0, -8.0, 13.0, 3.0, 4.0, -5.0, 13.0, 11.0, -1.0, -8.0, 13.0, 315.0, 13.0, 13.0, 11.0, 11.0, 12.0, 13.0, 318.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -7.0, -1.0, 11.0, 12.0, 11.0, -11.0, 3.0, 12.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0, -10.0, 5.0, 7.0, 13.0, 11.0, -1.0, -8.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4885524054916655, "mean_inference_ms": 2.0184882358749006, "mean_action_processing_ms": 0.12083304791439041, "mean_env_wait_ms": 0.2857193551884771, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 721440, "agent_timesteps_total": 721359, "timers": {"learn_time_ms": 1.938, "learn_throughput": 16509.555, "update_time_ms": 5.519}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.757059574127197, "min_q": 0.8964458107948303, "max_q": 9.099955558776855, "mean_td_error": 0.28272396326065063, "model": {}}}, "num_steps_sampled": 721440, "num_agent_steps_sampled": 721359, "num_steps_trained": 213472, "num_agent_steps_trained": 213472, "last_target_update_ts": 721440, "num_target_updates": 1335}, "done": false, "episodes_total": 14121, "training_iteration": 230, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-08", "timestamp": 1626859988, "time_this_iter_s": 0.9941043853759766, "time_total_s": 261.50410652160645, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 261.50410652160645, "timesteps_since_restore": 0, "iterations_since_restore": 230, "perf": {"cpu_util_percent": 35.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [2.0, 12.0, -12.0, 13.0, 14.0, -7.0, 13.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 1.0, -10.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 6.0, 14.0, -17.0, 12.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 14.0, 3.0, 13.0, -15.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 6.0, 6.0, 11.0, -8.0, -1.0, -7.0, 12.0, 11.0, 2.0, 11.0, -11.0, 13.0, 11.0, -3.0, 12.0, -5.0, 3.0, -8.0, 8.0, 12.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, -1.0, -8.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 13.0, -18.0, 11.0, 9.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 13.0, -16.0, 10.0, 8.0, 3.0, 12.0, -12.0, 12.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 9.0, 1.0, 12.0, -7.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 11.0, -11.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 9.0, 1.0, 12.0, -7.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 6.0, 1.0, 12.0, -4.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 14.0, -22.0, 13.0, 10.0, 13.0, -19.0, 12.0, 9.0, 2.0, 12.0, -12.0, 13.0, 11.0, 2.0, 12.0, -10.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, -1.0, -8.0, 11.0, 13.0, 3.0, 11.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 4.0, 3.0, 12.0, -4.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 3.0, -7.0, 11.0, 8.0, 0.0, -9.0, 13.0, 11.0, -1.0, -9.0, 13.0, 12.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 12.0, 12.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, -3.0, -3.0, 10.0, 11.0, 0.0, -9.0, 13.0, 11.0, 5.0, -13.0, 11.0, 12.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0, 0.0, -9.0, 13.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49356580901297925, "mean_inference_ms": 2.0313449673670863, "mean_action_processing_ms": 0.12179228841721375, "mean_env_wait_ms": 0.288191247308258, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 724680, "agent_timesteps_total": 724599, "timers": {"learn_time_ms": 1.918, "learn_throughput": 16682.75, "update_time_ms": 5.229}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.5473833084106445, "min_q": 0.8874152898788452, "max_q": 8.385322570800781, "mean_td_error": 0.6438526511192322, "model": {}}}, "num_steps_sampled": 724680, "num_agent_steps_sampled": 724599, "num_steps_trained": 214432, "num_agent_steps_trained": 214432, "last_target_update_ts": 724680, "num_target_updates": 1341}, "done": false, "episodes_total": 14202, "training_iteration": 231, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-09", "timestamp": 1626859989, "time_this_iter_s": 1.1479711532592773, "time_total_s": 262.6520776748657, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 262.6520776748657, "timesteps_since_restore": 0, "iterations_since_restore": 231, "perf": {"cpu_util_percent": 51.75, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 12.0, -9.0, -1.0, 13.0, 13.0, 4.0, -12.0, 10.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 10.0, -17.0, 10.0, 12.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 13.0, 3.0, -11.0, 10.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, -1.0, 0.0, 5.0, 11.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -6.0, -1.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 12.0, 1.0, -8.0, 10.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -19.0, 13.0, 12.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 12.0, 317.0, 13.0, 12.0, 12.0, 8.0, -13.0, 8.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -19.0, 13.0, 12.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 13.0, -16.0, 10.0, 8.0, 3.0, 12.0, -12.0, 12.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 9.0, 1.0, 12.0, -7.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 11.0, -11.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 9.0, 1.0, 12.0, -7.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 6.0, 1.0, 12.0, -4.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 14.0, -22.0, 13.0, 10.0, 13.0, -19.0, 12.0, 9.0, 2.0, 12.0, -12.0, 13.0, 11.0, 2.0, 12.0, -10.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, -1.0, -8.0, 11.0, 13.0, 3.0, 11.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 4.0, 3.0, 12.0, -4.0, 0.0, -9.0, 11.0, 13.0, 2.0, 12.0, -12.0, 13.0, 11.0, -3.0, 12.0, -5.0, 3.0, -7.0, 11.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48754372904562493, "mean_inference_ms": 2.017063594261209, "mean_action_processing_ms": 0.12065116787502939, "mean_env_wait_ms": 0.2852371748828803, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 727920, "agent_timesteps_total": 727839, "timers": {"learn_time_ms": 1.971, "learn_throughput": 16239.093, "update_time_ms": 5.038}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.4460039138793945, "min_q": 0.8960856199264526, "max_q": 9.178718566894531, "mean_td_error": 0.6590673923492432, "model": {}}}, "num_steps_sampled": 727920, "num_agent_steps_sampled": 727839, "num_steps_trained": 215392, "num_agent_steps_trained": 215392, "last_target_update_ts": 727920, "num_target_updates": 1347}, "done": false, "episodes_total": 14256, "training_iteration": 232, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-10", "timestamp": 1626859990, "time_this_iter_s": 1.1753215789794922, "time_total_s": 263.8273992538452, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985416a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 263.8273992538452, "timesteps_since_restore": 0, "iterations_since_restore": 232, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -2.0, 13.0, -10.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 3.0, 2.0, -3.0, 13.0, 14.0, -2.0, 13.0, -10.0, 13.0, -10.0, 1.0, 11.0, 14.0, -1.0, 13.0, -11.0, 3.0, 4.0, -3.0, 11.0, 14.0, -1.0, 13.0, -11.0, 13.0, 0.0, -10.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, 1.0, 13.0, -13.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 13.0, -3.0, -7.0, 12.0, 14.0, 2.0, 13.0, -14.0, 6.0, -1.0, -2.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -2.0, 13.0, -10.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, 2.0, 13.0, -14.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -18.0, 13.0, 6.0, 11.0, 3.0, 6.0, -5.0, 12.0, -9.0, -1.0, 13.0, 13.0, 4.0, -12.0, 10.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 10.0, -17.0, 10.0, 12.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 13.0, 3.0, -11.0, 10.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, -1.0, 0.0, 5.0, 11.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -6.0, -1.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 12.0, 1.0, -8.0, 10.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -19.0, 13.0, 12.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 12.0, 317.0, 13.0, 12.0, 12.0, 8.0, -13.0, 8.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -20.0, 13.0, 13.0, 11.0, 3.0, 6.0, -5.0, 9.0, -19.0, 13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4930863679711271, "mean_inference_ms": 2.0306615067859815, "mean_action_processing_ms": 0.12169383501405706, "mean_env_wait_ms": 0.2879201245213977, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 731160, "agent_timesteps_total": 731079, "timers": {"learn_time_ms": 1.899, "learn_throughput": 16851.785, "update_time_ms": 4.463}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.817423343658447, "min_q": 0.8444250226020813, "max_q": 9.156587600708008, "mean_td_error": 0.6820897459983826, "model": {}}}, "num_steps_sampled": 731160, "num_agent_steps_sampled": 731079, "num_steps_trained": 216352, "num_agent_steps_trained": 216352, "last_target_update_ts": 731160, "num_target_updates": 1353}, "done": false, "episodes_total": 14310, "training_iteration": 233, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-11", "timestamp": 1626859991, "time_this_iter_s": 1.1710474491119385, "time_total_s": 264.99844670295715, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 264.99844670295715, "timesteps_since_restore": 0, "iterations_since_restore": 233, "perf": {"cpu_util_percent": 48.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -21.0, 12.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -21.0, 13.0, 12.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 3.0, 6.0, 11.0, -5.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 4.0, 1.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 9.0, -18.0, 12.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 3.0, 2.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 8.0, -1.0, 11.0, -3.0, -21.0, 13.0, 13.0, 10.0, 10.0, -18.0, 11.0, 12.0, -4.0, 9.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -14.0, 6.0, 11.0, 12.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -13.0, 6.0, 11.0, 11.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 8.0, -1.0, 11.0, -3.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 1.0, 6.0, 11.0, -3.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -6.0, 12.0, -4.0, 13.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -13.0, 6.0, 11.0, 11.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -6.0, -1.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -13.0, 6.0, 11.0, 11.0, -11.0, 11.0, 13.0, 2.0, 8.0, -18.0, 12.0, 13.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -2.0, 13.0, -10.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, 2.0, 13.0, -14.0, 6.0, 0.0, -3.0, 12.0, 14.0, -1.0, 13.0, -11.0, 6.0, 0.0, -3.0, 12.0, 14.0, -18.0, 13.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4902099845969181, "mean_inference_ms": 2.022685742483383, "mean_action_processing_ms": 0.12104405039240404, "mean_env_wait_ms": 0.286536718891822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 734400, "agent_timesteps_total": 734319, "timers": {"learn_time_ms": 1.931, "learn_throughput": 16568.249, "update_time_ms": 4.556}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.579876899719238, "min_q": 0.7574293613433838, "max_q": 8.856673240661621, "mean_td_error": 0.8978063464164734, "model": {}}}, "num_steps_sampled": 734400, "num_agent_steps_sampled": 734319, "num_steps_trained": 217312, "num_agent_steps_trained": 217312, "last_target_update_ts": 734400, "num_target_updates": 1359}, "done": false, "episodes_total": 14391, "training_iteration": 234, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-12", "timestamp": 1626859992, "time_this_iter_s": 1.1394495964050293, "time_total_s": 266.1378962993622, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 266.1378962993622, "timesteps_since_restore": 0, "iterations_since_restore": 234, "perf": {"cpu_util_percent": 50.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 0.0, -6.0, 11.0, 8.0, 11.0, -2.0, -2.0, 10.0, 14.0, -20.0, 11.0, 8.0, 11.0, -2.0, -2.0, 13.0, 13.0, -7.0, -4.0, 13.0, -7.0, 12.0, -3.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 13.0, 13.0, -7.0, -4.0, 13.0, -2.0, -9.0, 13.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 10.0, 14.0, -20.0, 11.0, 13.0, 10.0, -3.0, -5.0, 9.0, 9.0, -15.0, 12.0, 8.0, 12.0, -2.0, -3.0, 10.0, 14.0, -18.0, 9.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 10.0, 9.0, -15.0, 11.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 10.0, 14.0, -5.0, -4.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -7.0, 3.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 10.0, -18.0, 11.0, 12.0, -14.0, 6.0, 11.0, 12.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -13.0, 6.0, 11.0, 11.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 8.0, -1.0, 11.0, -3.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, 1.0, 6.0, 11.0, -3.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -6.0, 12.0, -4.0, 13.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -13.0, 6.0, 11.0, 11.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -6.0, -1.0, 12.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -13.0, 6.0, 11.0, 11.0, -11.0, 11.0, 13.0, 2.0, 8.0, -18.0, 12.0, 13.0, -1.0, 6.0, 11.0, -1.0, -22.0, 13.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4876808925308336, "mean_inference_ms": 2.017039673384667, "mean_action_processing_ms": 0.12064801032712494, "mean_env_wait_ms": 0.2852738174187652, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 737640, "agent_timesteps_total": 737559, "timers": {"learn_time_ms": 1.881, "learn_throughput": 17010.688, "update_time_ms": 4.767}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.941990852355957, "min_q": 0.5530943274497986, "max_q": 9.051651954650879, "mean_td_error": 0.8318817019462585, "model": {}}}, "num_steps_sampled": 737640, "num_agent_steps_sampled": 737559, "num_steps_trained": 218272, "num_agent_steps_trained": 218272, "last_target_update_ts": 737640, "num_target_updates": 1365}, "done": false, "episodes_total": 14445, "training_iteration": 235, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-14", "timestamp": 1626859994, "time_this_iter_s": 1.1603264808654785, "time_total_s": 267.29822278022766, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 267.29822278022766, "timesteps_since_restore": 0, "iterations_since_restore": 235, "perf": {"cpu_util_percent": 50.75, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 95.9, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 23.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 13.0, 12.0, 317.0, 0.0, -9.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -9.0, 14.0, 11.0, -1.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 12.0, 12.0, -9.0, 13.0, 13.0, -2.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -17.0, 13.0, 13.0, 6.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 8.0, -8.0, 6.0, 9.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -7.0, 12.0, -2.0, 12.0, 12.0, 13.0, 11.0, 316.0, 12.0, 5.0, -15.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 13.0, -6.0, 0.0, 8.0, 5.0, -1.0, 12.0, -1.0, 11.0, 12.0, 11.0, -19.0, 13.0, -7.0, 0.0, 9.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 9.0, -6.0, 2.0, 10.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 8.0, -7.0, 4.0, 10.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 8.0, -6.0, 4.0, 9.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -11.0, 2.0, 11.0, 13.0, -13.0, 11.0, 13.0, 4.0, 12.0, 5.0, 11.0, -13.0, -7.0, -2.0, 11.0, 13.0, -20.0, 13.0, 9.0, 13.0, 12.0, 5.0, 11.0, -13.0, -7.0, -2.0, 11.0, 13.0, -15.0, 9.0, 11.0, 10.0, 8.0, 11.0, -2.0, -2.0, 10.0, 14.0, -5.0, -4.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -7.0, 3.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0, 9.0, 9.0, -15.0, 12.0, 8.0, 11.0, -2.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4902649776548128, "mean_inference_ms": 2.0225158400576095, "mean_action_processing_ms": 0.12102856889049901, "mean_env_wait_ms": 0.28653116828662895, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 740880, "agent_timesteps_total": 740826, "timers": {"learn_time_ms": 1.769, "learn_throughput": 18092.3, "update_time_ms": 4.313}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.863182067871094, "min_q": 0.7468361258506775, "max_q": 9.044885635375977, "mean_td_error": 0.09358403086662292, "model": {}}}, "num_steps_sampled": 740880, "num_agent_steps_sampled": 740826, "num_steps_trained": 219232, "num_agent_steps_trained": 219232, "last_target_update_ts": 740880, "num_target_updates": 1371}, "done": false, "episodes_total": 14526, "training_iteration": 236, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-15", "timestamp": 1626859995, "time_this_iter_s": 1.1530358791351318, "time_total_s": 268.4512586593628, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 268.4512586593628, "timesteps_since_restore": 0, "iterations_since_restore": 236, "perf": {"cpu_util_percent": 50.3, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 85.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 21.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 13.0, -7.0, 13.0, -4.0, 8.0, -2.0, 13.0, -4.0, 13.0, -7.0, 13.0, -3.0, 8.0, -3.0, 13.0, -2.0, 8.0, -4.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -3.0, 7.0, -1.0, 12.0, -4.0, 13.0, -7.0, 13.0, -5.0, 13.0, -6.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -6.0, 13.0, -5.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -9.0, 14.0, 11.0, -1.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 12.0, 12.0, -9.0, 13.0, 13.0, -2.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -17.0, 13.0, 13.0, 6.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 8.0, -8.0, 6.0, 9.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -7.0, 12.0, -2.0, 12.0, 12.0, 13.0, 11.0, 316.0, 12.0, 5.0, -15.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 13.0, -6.0, 0.0, 8.0, 5.0, -1.0, 12.0, -1.0, 11.0, 12.0, 11.0, -19.0, 13.0, -7.0, 0.0, 9.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 9.0, -6.0, 2.0, 10.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 8.0, -7.0, 4.0, 10.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 8.0, -6.0, 4.0, 9.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -11.0, 2.0, 11.0, 13.0, -13.0, 11.0, 13.0, 4.0, 12.0, 5.0, 11.0, -13.0, -7.0, -2.0, 11.0, 13.0, -20.0, 13.0, 9.0, 13.0, 12.0, 5.0, 11.0, -13.0, -7.0, -2.0, 11.0, 13.0, -15.0, 9.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4930126758522939, "mean_inference_ms": 2.030262922424229, "mean_action_processing_ms": 0.12171669095781176, "mean_env_wait_ms": 0.2877768780054634, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 743040, "agent_timesteps_total": 742959, "timers": {"learn_time_ms": 1.985, "learn_throughput": 16117.41, "update_time_ms": 4.805}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.311703681945801, "min_q": 0.7177332043647766, "max_q": 8.796646118164062, "mean_td_error": 0.46911564469337463, "model": {}}}, "num_steps_sampled": 743040, "num_agent_steps_sampled": 742959, "num_steps_trained": 219872, "num_agent_steps_trained": 219872, "last_target_update_ts": 743040, "num_target_updates": 1375}, "done": false, "episodes_total": 14553, "training_iteration": 237, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-16", "timestamp": 1626859996, "time_this_iter_s": 0.9747269153594971, "time_total_s": 269.4259855747223, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dae18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 269.4259855747223, "timesteps_since_restore": 0, "iterations_since_restore": 237, "perf": {"cpu_util_percent": 37.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 28.74, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 7.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, -5.0, 12.0, 13.0, 11.0, -1.0, -4.0, 9.0, 1.0, -10.0, 12.0, 13.0, 12.0, -1.0, -7.0, 11.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 12.0, -1.0, -6.0, 10.0, -3.0, -6.0, 12.0, 13.0, 3.0, -1.0, 2.0, 11.0, 2.0, -5.0, 7.0, 12.0, 11.0, -1.0, -7.0, 12.0, -2.0, -7.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 12.0, -1.0, -7.0, 11.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, 2.0, -5.0, 7.0, 12.0, 2.0, -1.0, 2.0, 12.0, -3.0, -6.0, 12.0, 13.0, 2.0, -1.0, 2.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -7.0, -3.0, 13.0, 12.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 3.0, -2.0, 2.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -4.0, -5.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, 8.0, -6.0, 4.0, 9.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -7.0, -2.0, 11.0, 13.0, -15.0, 13.0, 13.0, 4.0, 12.0, 13.0, 11.0, 316.0, -11.0, 2.0, 11.0, 13.0, -13.0, 11.0, 13.0, 4.0, 12.0, 5.0, 11.0, -13.0, -7.0, -2.0, 11.0, 13.0, -20.0, 13.0, 9.0, 13.0, 12.0, 5.0, 11.0, -13.0, -7.0, -2.0, 11.0, 13.0, -15.0, 9.0, 11.0, 10.0, -4.0, 13.0, -7.0, 13.0, -4.0, 8.0, -2.0, 13.0, -4.0, 13.0, -7.0, 13.0, -3.0, 8.0, -3.0, 13.0, -2.0, 8.0, -4.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -3.0, 7.0, -1.0, 12.0, -4.0, 13.0, -7.0, 13.0, -5.0, 13.0, -6.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -4.0, 13.0, -7.0, 13.0, -6.0, 13.0, -5.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4888243491259896, "mean_inference_ms": 2.0186992074439574, "mean_action_processing_ms": 0.12081046151665845, "mean_env_wait_ms": 0.285831390047594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 746280, "agent_timesteps_total": 746199, "timers": {"learn_time_ms": 1.929, "learn_throughput": 16585.652, "update_time_ms": 5.345}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.147559642791748, "min_q": 0.9347490668296814, "max_q": 8.684423446655273, "mean_td_error": 1.412294626235962, "model": {}}}, "num_steps_sampled": 746280, "num_agent_steps_sampled": 746199, "num_steps_trained": 220832, "num_agent_steps_trained": 220832, "last_target_update_ts": 746280, "num_target_updates": 1381}, "done": false, "episodes_total": 14607, "training_iteration": 238, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-17", "timestamp": 1626859997, "time_this_iter_s": 1.127554178237915, "time_total_s": 270.5535397529602, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 270.5535397529602, "timesteps_since_restore": 0, "iterations_since_restore": 238, "perf": {"cpu_util_percent": 50.05, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.46, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 4.615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, -1.0, 11.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, -1.0, -6.0, 10.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, -1.0, -6.0, 10.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, -1.0, -6.0, 10.0, 12.0, 7.0, 14.0, 13.0, -19.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, -1.0, 5.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 11.0, 13.0, -9.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, -2.0, 13.0, 13.0, -9.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 9.0, -4.0, 7.0, 3.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, 12.0, 14.0, 13.0, 314.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -10.0, 5.0, 7.0, 13.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 3.0, -3.0, 7.0, 8.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, -4.0, 4.0, 5.0, 10.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, -15.0, 12.0, 11.0, 7.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, 0.0, -3.0, 11.0, -3.0, 14.0, 13.0, -9.0, -7.0, 10.0, 13.0, -1.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 11.0, -1.0, -7.0, 12.0, -7.0, -3.0, 13.0, 12.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 3.0, -2.0, 2.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -3.0, -6.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0, -4.0, -5.0, 12.0, 13.0, 11.0, -1.0, -7.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4903685705213182, "mean_inference_ms": 2.0222695160941795, "mean_action_processing_ms": 0.12100235992289017, "mean_env_wait_ms": 0.2865418565344273, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 749520, "agent_timesteps_total": 749439, "timers": {"learn_time_ms": 1.921, "learn_throughput": 16656.043, "update_time_ms": 4.622}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.015771865844727, "min_q": 0.9467275738716125, "max_q": 9.04733657836914, "mean_td_error": 1.0506483316421509, "model": {}}}, "num_steps_sampled": 749520, "num_agent_steps_sampled": 749439, "num_steps_trained": 221792, "num_agent_steps_trained": 221792, "last_target_update_ts": 749520, "num_target_updates": 1387}, "done": false, "episodes_total": 14688, "training_iteration": 239, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-18", "timestamp": 1626859998, "time_this_iter_s": 1.1857872009277344, "time_total_s": 271.73932695388794, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 271.73932695388794, "timesteps_since_restore": 0, "iterations_since_restore": 239, "perf": {"cpu_util_percent": 49.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.17, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 6.2925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 12.0, -16.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -9.0, 5.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, 12.0, 11.0, 8.0, -16.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, 0.0, 14.0, 6.0, -5.0, 6.0, -9.0, 5.0, 13.0, 13.0, 14.0, 12.0, 317.0, 6.0, -9.0, 5.0, 13.0, -8.0, 11.0, 8.0, 4.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, 13.0, 14.0, 12.0, 314.0, 6.0, -9.0, 5.0, 13.0, -12.0, 11.0, 12.0, 4.0, 6.0, -10.0, 6.0, 13.0, 13.0, 11.0, 3.0, -12.0, 6.0, -10.0, 6.0, 13.0, 12.0, 12.0, 4.0, -13.0, 3.0, -13.0, 12.0, 13.0, -3.0, 11.0, 7.0, 0.0, 6.0, -10.0, 6.0, 13.0, -1.0, 11.0, 7.0, -2.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -2.0, 13.0, -2.0, 6.0, 6.0, -10.0, 6.0, 13.0, 13.0, 11.0, 3.0, -12.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, 13.0, 10.0, 8.0, -16.0, 6.0, -10.0, 6.0, 13.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, -2.0, 13.0, 13.0, -9.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 9.0, -4.0, 7.0, 3.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, 12.0, 14.0, 13.0, 314.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -10.0, 5.0, 7.0, 13.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 3.0, -3.0, 7.0, 8.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, -4.0, 4.0, 5.0, 10.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, -15.0, 12.0, 11.0, 7.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, 0.0, -3.0, 11.0, -3.0, 14.0, 13.0, -9.0, -7.0, 10.0, 13.0, -1.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0, 0.0, 10.0, 13.0, -8.0, 7.0, -3.0, -1.0, 12.0, -3.0, 14.0, 13.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4878021664588284, "mean_inference_ms": 2.016764938461054, "mean_action_processing_ms": 0.12060214535535721, "mean_env_wait_ms": 0.2852810538732014, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 752760, "agent_timesteps_total": 752679, "timers": {"learn_time_ms": 1.849, "learn_throughput": 17302.565, "update_time_ms": 4.798}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.224393844604492, "min_q": 0.9302496314048767, "max_q": 9.231782913208008, "mean_td_error": 0.34268420934677124, "model": {}}}, "num_steps_sampled": 752760, "num_agent_steps_sampled": 752679, "num_steps_trained": 222752, "num_agent_steps_trained": 222752, "last_target_update_ts": 752760, "num_target_updates": 1393}, "done": false, "episodes_total": 14742, "training_iteration": 240, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-19", "timestamp": 1626859999, "time_this_iter_s": 1.1381466388702393, "time_total_s": 272.8774735927582, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 272.8774735927582, "timesteps_since_restore": 0, "iterations_since_restore": 240, "perf": {"cpu_util_percent": 51.099999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 22.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 352.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 352.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 0.0, 2.0, 3.0, 11.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 7.0, -11.0, 11.0, 8.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -7.0, 3.0, 13.0, 6.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 7.0, 12.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 7.0, 12.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -21.0, 12.0, 11.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -15.0, 12.0, 5.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -16.0, 11.0, 13.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -7.0, -2.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 7.0, 12.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, 316.0, 12.0, 12.0, 12.0, 14.0, -11.0, 3.0, 10.0, 8.0, 8.0, 8.0, -9.0, -12.0, 9.0, 11.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -21.0, 12.0, 11.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -15.0, 12.0, 5.0, -5.0, 4.0, 13.0, 3.0, 315.0, 13.0, 12.0, 12.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 6.0, -10.0, 6.0, 13.0, 13.0, 11.0, 3.0, -12.0, 6.0, -10.0, 6.0, 13.0, 12.0, 12.0, 4.0, -13.0, 3.0, -13.0, 12.0, 13.0, -3.0, 11.0, 7.0, 0.0, 6.0, -10.0, 6.0, 13.0, -1.0, 11.0, 7.0, -2.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, -2.0, 13.0, -2.0, 6.0, 6.0, -10.0, 6.0, 13.0, 13.0, 11.0, 3.0, -12.0, 6.0, -10.0, 6.0, 13.0, -4.0, 11.0, 7.0, 1.0, 6.0, -10.0, 6.0, 13.0, 13.0, 10.0, 8.0, -16.0, 6.0, -10.0, 6.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4904231051611123, "mean_inference_ms": 2.0225642736023497, "mean_action_processing_ms": 0.1210091824365234, "mean_env_wait_ms": 0.28656015543574975, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 756000, "agent_timesteps_total": 755973, "timers": {"learn_time_ms": 1.841, "learn_throughput": 17380.988, "update_time_ms": 4.811}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.593568801879883, "min_q": 0.8288573026657104, "max_q": 9.459065437316895, "mean_td_error": -9.991520881652832, "model": {}}}, "num_steps_sampled": 756000, "num_agent_steps_sampled": 755973, "num_steps_trained": 223712, "num_agent_steps_trained": 223712, "last_target_update_ts": 756000, "num_target_updates": 1399}, "done": false, "episodes_total": 14823, "training_iteration": 241, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-21", "timestamp": 1626860001, "time_this_iter_s": 1.1688411235809326, "time_total_s": 274.0463147163391, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 274.0463147163391, "timesteps_since_restore": 0, "iterations_since_restore": 241, "perf": {"cpu_util_percent": 51.4, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 28.67, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 7.1675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 352.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 352.0, 16.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, 315.0, 13.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -1.0, -6.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -3.0, -3.0, 9.0, 12.0, 11.0, 12.0, -10.0, 2.0, -4.0, -3.0, 10.0, 12.0, 10.0, 14.0, -22.0, 13.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -4.0, 10.0, 13.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 11.0, 14.0, -18.0, 8.0, -5.0, -2.0, 10.0, 12.0, 14.0, 12.0, 10.0, -21.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 9.0, 0.0, -7.0, 13.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, 315.0, 13.0, -3.0, -4.0, 10.0, 12.0, 11.0, 14.0, -18.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, 9.0, -3.0, 13.0, 11.0, 14.0, -18.0, 8.0, -4.0, -4.0, 10.0, 13.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 11.0, 12.0, -10.0, 2.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -12.0, 8.0, 7.0, 12.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -21.0, 12.0, 11.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -15.0, 12.0, 5.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -16.0, 11.0, 13.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -7.0, -2.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 7.0, 12.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, 316.0, 12.0, 12.0, 12.0, 14.0, -11.0, 3.0, 10.0, 8.0, 8.0, 8.0, -9.0, -12.0, 9.0, 11.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -21.0, 12.0, 11.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0, 14.0, -15.0, 12.0, 5.0, -5.0, 4.0, 13.0, 3.0, 315.0, 13.0, 12.0, 12.0, 14.0, -11.0, 3.0, 10.0, -5.0, -4.0, 13.0, 11.0, -12.0, 8.0, 12.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48789722609834674, "mean_inference_ms": 2.0170811557464083, "mean_action_processing_ms": 0.12062844173519269, "mean_env_wait_ms": 0.28530148943565875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 759240, "agent_timesteps_total": 759159, "timers": {"learn_time_ms": 2.021, "learn_throughput": 15830.923, "update_time_ms": 5.377}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.317051887512207, "min_q": 0.6051713824272156, "max_q": 8.757279396057129, "mean_td_error": 0.7026718258857727, "model": {}}}, "num_steps_sampled": 759240, "num_agent_steps_sampled": 759159, "num_steps_trained": 224672, "num_agent_steps_trained": 224672, "last_target_update_ts": 759240, "num_target_updates": 1405}, "done": false, "episodes_total": 14877, "training_iteration": 242, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-22", "timestamp": 1626860002, "time_this_iter_s": 1.1798577308654785, "time_total_s": 275.2261724472046, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 275.2261724472046, "timesteps_since_restore": 0, "iterations_since_restore": 242, "perf": {"cpu_util_percent": 51.349999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 112.84, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 28.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 352.0, 15.0, 352.0, 15.0, 353.0, 354.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 355.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 354.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 11.0, 12.0, 13.0, 317.0, 13.0, 11.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 13.0, 317.0, 13.0, 9.0, 14.0, -21.0, 11.0, 11.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -18.0, 13.0, 6.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 6.0, -9.0, 9.0, 9.0, 14.0, -18.0, 13.0, 6.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 318.0, 13.0, 10.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -18.0, 13.0, 6.0, 14.0, 316.0, 13.0, 9.0, 14.0, -20.0, 12.0, 9.0, 14.0, 316.0, 13.0, 9.0, 14.0, -18.0, 13.0, 6.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 13.0, 317.0, 13.0, 11.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 10.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -1.0, -6.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -3.0, -3.0, 9.0, 12.0, 11.0, 12.0, -10.0, 2.0, -4.0, -3.0, 10.0, 12.0, 10.0, 14.0, -22.0, 13.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -4.0, 10.0, 13.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 11.0, 14.0, -18.0, 8.0, -5.0, -2.0, 10.0, 12.0, 14.0, 12.0, 10.0, -21.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 9.0, 0.0, -7.0, 13.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, 315.0, 13.0, -3.0, -4.0, 10.0, 12.0, 11.0, 14.0, -18.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, 9.0, -3.0, 13.0, 11.0, 14.0, -18.0, 8.0, -4.0, -4.0, 10.0, 13.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0, -4.0, -3.0, 10.0, 12.0, 11.0, 12.0, -10.0, 2.0, -4.0, -3.0, 10.0, 12.0, 12.0, 14.0, -19.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934003637141346, "mean_inference_ms": 2.030580805669093, "mean_action_processing_ms": 0.12166643620693499, "mean_env_wait_ms": 0.287963044542752, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 762480, "agent_timesteps_total": 762399, "timers": {"learn_time_ms": 1.829, "learn_throughput": 17496.315, "update_time_ms": 4.814}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.791289329528809, "min_q": 0.6796970367431641, "max_q": 9.404836654663086, "mean_td_error": 1.2457008361816406, "model": {}}}, "num_steps_sampled": 762480, "num_agent_steps_sampled": 762399, "num_steps_trained": 225632, "num_agent_steps_trained": 225632, "last_target_update_ts": 762480, "num_target_updates": 1411}, "done": false, "episodes_total": 14931, "training_iteration": 243, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-23", "timestamp": 1626860003, "time_this_iter_s": 1.1449546813964844, "time_total_s": 276.3711271286011, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985418c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 276.3711271286011, "timesteps_since_restore": 0, "iterations_since_restore": 243, "perf": {"cpu_util_percent": 49.3, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 180.21, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 45.0525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 354.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 355.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 354.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 314.0, 13.0, 12.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, -10.0, 13.0, -2.0, -3.0, 13.0, 12.0, -7.0, 14.0, 314.0, 13.0, 11.0, -2.0, 13.0, 13.0, -9.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -9.0, 2.0, 13.0, 9.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, -6.0, -5.0, 12.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, 9.0, 14.0, 13.0, 318.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 9.0, 13.0, -3.0, 14.0, 314.0, 13.0, 11.0, -3.0, 13.0, 12.0, -7.0, 14.0, 314.0, 13.0, 11.0, -4.0, 8.0, 12.0, -1.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, -19.0, 13.0, 7.0, 13.0, 317.0, 13.0, 9.0, 14.0, -21.0, 11.0, 11.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -18.0, 13.0, 6.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 6.0, -9.0, 9.0, 9.0, 14.0, -18.0, 13.0, 6.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 318.0, 13.0, 10.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -18.0, 13.0, 6.0, 14.0, 316.0, 13.0, 9.0, 14.0, -20.0, 12.0, 9.0, 14.0, 316.0, 13.0, 9.0, 14.0, -18.0, 13.0, 6.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 13.0, 317.0, 13.0, 11.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 9.0, 14.0, -19.0, 13.0, 7.0, 14.0, 316.0, 13.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49342665565865673, "mean_inference_ms": 2.0306171361098, "mean_action_processing_ms": 0.12166047560388218, "mean_env_wait_ms": 0.2879671632245355, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 764640, "agent_timesteps_total": 764559, "timers": {"learn_time_ms": 1.937, "learn_throughput": 16519.512, "update_time_ms": 4.658}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.686379432678223, "min_q": 0.9489158391952515, "max_q": 9.428455352783203, "mean_td_error": 0.2938082814216614, "model": {}}}, "num_steps_sampled": 764640, "num_agent_steps_sampled": 764559, "num_steps_trained": 226272, "num_agent_steps_trained": 226272, "last_target_update_ts": 764640, "num_target_updates": 1415}, "done": false, "episodes_total": 14985, "training_iteration": 244, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-24", "timestamp": 1626860004, "time_this_iter_s": 0.9902956485748291, "time_total_s": 277.3614227771759, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985412f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 277.3614227771759, "timesteps_since_restore": 0, "iterations_since_restore": 244, "perf": {"cpu_util_percent": 44.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 106.02, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 26.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 354.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 10.0, 8.0, -13.0, 10.0, 7.0, 6.0, -4.0, 6.0, 12.0, 12.0, 316.0, 12.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 2.0, -2.0, 6.0, 9.0, 10.0, 10.0, -18.0, 13.0, 13.0, -13.0, 5.0, 10.0, 10.0, 12.0, 317.0, 13.0, 6.0, -11.0, 10.0, 10.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, -3.0, 12.0, 13.0, -7.0, 13.0, -15.0, 6.0, 11.0, -2.0, 12.0, -7.0, 12.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 12.0, -2.0, -7.0, 12.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -10.0, 5.0, 7.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 11.0, 12.0, 316.0, 13.0, 13.0, 318.0, 11.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 8.0, 12.0, -18.0, 13.0, 12.0, -14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -12.0, 3.0, 11.0, 10.0, 10.0, -18.0, 13.0, 8.0, -11.0, 7.0, 11.0, 10.0, 10.0, -18.0, 13.0, 7.0, -7.0, 4.0, 11.0, 8.0, 12.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 9.0, 13.0, 317.0, 13.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 11.0, -3.0, -6.0, 13.0, 13.0, -15.0, 6.0, 11.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, -10.0, 13.0, -2.0, -3.0, 13.0, 12.0, -7.0, 14.0, 314.0, 13.0, 11.0, -2.0, 13.0, 13.0, -9.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -9.0, 2.0, 13.0, 9.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, -6.0, -5.0, 12.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, 9.0, 14.0, 13.0, 318.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 9.0, 13.0, -3.0, 14.0, 314.0, 13.0, 11.0, -3.0, 13.0, 12.0, -7.0, 14.0, 314.0, 13.0, 11.0, -4.0, 8.0, 12.0, -1.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0, 14.0, 314.0, 13.0, 11.0, -4.0, 14.0, 13.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934256270432739, "mean_inference_ms": 2.0305718809484223, "mean_action_processing_ms": 0.12165273456773001, "mean_env_wait_ms": 0.2879595453736443, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 767880, "agent_timesteps_total": 767799, "timers": {"learn_time_ms": 1.893, "learn_throughput": 16905.912, "update_time_ms": 4.688}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.910888671875, "min_q": 0.6952188611030579, "max_q": 9.312729835510254, "mean_td_error": -8.95143985748291, "model": {}}}, "num_steps_sampled": 767880, "num_agent_steps_sampled": 767799, "num_steps_trained": 227232, "num_agent_steps_trained": 227232, "last_target_update_ts": 767880, "num_target_updates": 1421}, "done": false, "episodes_total": 15039, "training_iteration": 245, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-25", "timestamp": 1626860005, "time_this_iter_s": 1.160388708114624, "time_total_s": 278.5218114852905, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 278.5218114852905, "timesteps_since_restore": 0, "iterations_since_restore": 245, "perf": {"cpu_util_percent": 48.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 102.85, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 25.7125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 352.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 5.0, 9.0, 3.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, -2.0, 9.0, -1.0, 9.0, -3.0, 4.0, 10.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, 12.0, -12.0, 8.0, 7.0, 318.0, 12.0, 10.0, 13.0, 10.0, 1.0, -1.0, 5.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 1.0, 9.0, -1.0, 6.0, -2.0, 4.0, 9.0, 4.0, 318.0, 11.0, 10.0, 13.0, -2.0, 9.0, -1.0, 9.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 0.0, 9.0, -6.0, 12.0, 12.0, -10.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 7.0, 9.0, -2.0, 1.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, -4.0, 9.0, -2.0, 12.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -3.0, 5.0, 13.0, 0.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, 12.0, 2.0, -3.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 5.0, 9.0, 3.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -3.0, 5.0, 9.0, 4.0, 317.0, 13.0, 10.0, 13.0, 3.0, 9.0, -1.0, 4.0, -2.0, 4.0, 9.0, 4.0, -18.0, 9.0, 13.0, 11.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 2.0, 9.0, -1.0, 5.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 2.0, 9.0, -1.0, 5.0, -2.0, 4.0, 1.0, 12.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, 12.0, 2.0, -3.0, 4.0, 318.0, 12.0, 10.0, 13.0, 3.0, 9.0, -2.0, 5.0, -2.0, 4.0, 9.0, 4.0, -16.0, 14.0, 5.0, 12.0, -1.0, 9.0, -1.0, 8.0, -2.0, 6.0, 9.0, 2.0, 319.0, 12.0, 9.0, 12.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 3.0, 10.0, 13.0, -15.0, 6.0, 11.0, 8.0, 12.0, -18.0, 13.0, 12.0, -14.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -12.0, 3.0, 11.0, 10.0, 10.0, -18.0, 13.0, 8.0, -11.0, 7.0, 11.0, 10.0, 10.0, -18.0, 13.0, 7.0, -7.0, 4.0, 11.0, 8.0, 12.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 9.0, 13.0, 317.0, 13.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 10.0, 10.0, -18.0, 13.0, 13.0, -15.0, 6.0, 11.0, 11.0, -3.0, -6.0, 13.0, 13.0, -15.0, 6.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4905392092050421, "mean_inference_ms": 2.0225679245708115, "mean_action_processing_ms": 0.12100640756018768, "mean_env_wait_ms": 0.2865705638445509, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 771120, "agent_timesteps_total": 771120, "timers": {"learn_time_ms": 1.8, "learn_throughput": 17782.129, "update_time_ms": 4.736}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.588179588317871, "min_q": 0.9763827323913574, "max_q": 8.919008255004883, "mean_td_error": 0.15433047711849213, "model": {}}}, "num_steps_sampled": 771120, "num_agent_steps_sampled": 771120, "num_steps_trained": 228192, "num_agent_steps_trained": 228192, "last_target_update_ts": 771120, "num_target_updates": 1427}, "done": false, "episodes_total": 15120, "training_iteration": 246, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-26", "timestamp": 1626860006, "time_this_iter_s": 1.1797268390655518, "time_total_s": 279.7015383243561, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985056a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 279.7015383243561, "timesteps_since_restore": 0, "iterations_since_restore": 246, "perf": {"cpu_util_percent": 50.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 58.93, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 14.7325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, -7.0, 12.0, 12.0, -2.0, 8.0, -6.0, 0.0, 13.0, 0.0, 8.0, 11.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, -3.0, 0.0, 5.0, 13.0, 0.0, 7.0, 12.0, -4.0, 7.0, -10.0, 5.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 1.0, 13.0, 8.0, -7.0, 8.0, -7.0, 1.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -9.0, 3.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 13.0, 7.0, 12.0, -17.0, 10.0, -7.0, -1.0, 13.0, 13.0, 7.0, 12.0, -17.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 13.0, 7.0, 12.0, -17.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, -16.0, 12.0, 11.0, 8.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 0.0, -5.0, 9.0, 11.0, 0.0, 7.0, 12.0, -4.0, 8.0, -1.0, -3.0, 11.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 6.0, -5.0, 1.0, 13.0, -7.0, 13.0, 12.0, -3.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 4.0, -6.0, 5.0, 12.0, 0.0, 7.0, 12.0, -4.0, 8.0, -7.0, 1.0, 13.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -3.0, 5.0, 13.0, 0.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, 12.0, 2.0, -3.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 5.0, 9.0, 3.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -3.0, 5.0, 9.0, 4.0, 317.0, 13.0, 10.0, 13.0, 3.0, 9.0, -1.0, 4.0, -2.0, 4.0, 9.0, 4.0, -18.0, 9.0, 13.0, 11.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 2.0, 9.0, -1.0, 5.0, -2.0, 4.0, 9.0, 4.0, 318.0, 12.0, 10.0, 13.0, 2.0, 9.0, -1.0, 5.0, -2.0, 4.0, 1.0, 12.0, 318.0, 12.0, 10.0, 13.0, 4.0, 9.0, -1.0, 3.0, 12.0, 2.0, -3.0, 4.0, 318.0, 12.0, 10.0, 13.0, 3.0, 9.0, -2.0, 5.0, -2.0, 4.0, 9.0, 4.0, -16.0, 14.0, 5.0, 12.0, -1.0, 9.0, -1.0, 8.0, -2.0, 6.0, 9.0, 2.0, 319.0, 12.0, 9.0, 12.0, 4.0, 9.0, -1.0, 3.0, -2.0, 4.0, 3.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48798475004433955, "mean_inference_ms": 2.0172279276075873, "mean_action_processing_ms": 0.12062942597199776, "mean_env_wait_ms": 0.2853228917465717, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 774360, "agent_timesteps_total": 774279, "timers": {"learn_time_ms": 1.917, "learn_throughput": 16695.824, "update_time_ms": 4.434}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.66982364654541, "min_q": 1.1199595928192139, "max_q": 8.812971115112305, "mean_td_error": 0.6145447492599487, "model": {}}}, "num_steps_sampled": 774360, "num_agent_steps_sampled": 774279, "num_steps_trained": 229152, "num_agent_steps_trained": 229152, "last_target_update_ts": 774360, "num_target_updates": 1433}, "done": false, "episodes_total": 15174, "training_iteration": 247, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-28", "timestamp": 1626860008, "time_this_iter_s": 1.1897814273834229, "time_total_s": 280.8913197517395, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 280.8913197517395, "timesteps_since_restore": 0, "iterations_since_restore": 247, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -10.0, 13.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -9.0, 6.0, 12.0, 6.0, 12.0, 0.0, -10.0, 13.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -6.0, 12.0, 3.0, 6.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, 13.0, 7.0, 5.0, -10.0, 12.0, 0.0, -7.0, 10.0, 14.0, 11.0, 3.0, -13.0, 12.0, 0.0, -7.0, 10.0, 14.0, 8.0, -18.0, 11.0, 12.0, 0.0, -7.0, 10.0, 0.0, 0.0, 12.0, 3.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 7.0, 13.0, -14.0, 9.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 13.0, 8.0, -18.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 8.0, 0.0, 6.0, 1.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -10.0, 13.0, 0.0, 7.0, 12.0, -4.0, -3.0, 0.0, 5.0, 13.0, 0.0, 7.0, 12.0, -4.0, 7.0, -10.0, 5.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 1.0, 13.0, 8.0, -7.0, 8.0, -7.0, 1.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -9.0, 3.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 13.0, 7.0, 12.0, -17.0, 10.0, -7.0, -1.0, 13.0, 13.0, 7.0, 12.0, -17.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 13.0, 7.0, 12.0, -17.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, -16.0, 12.0, 11.0, 8.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 0.0, -5.0, 9.0, 11.0, 0.0, 7.0, 12.0, -4.0, 8.0, -1.0, -3.0, 11.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 6.0, -5.0, 1.0, 13.0, -7.0, 13.0, 12.0, -3.0, 8.0, -6.0, 0.0, 13.0, 0.0, 7.0, 12.0, -4.0, 4.0, -6.0, 5.0, 12.0, 0.0, 7.0, 12.0, -4.0, 8.0, -7.0, 1.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934478735628363, "mean_inference_ms": 2.0307357437487266, "mean_action_processing_ms": 0.12166215239542641, "mean_env_wait_ms": 0.2879739776265587, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 777600, "agent_timesteps_total": 777519, "timers": {"learn_time_ms": 1.878, "learn_throughput": 17040.492, "update_time_ms": 4.058}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.149446487426758, "min_q": 0.8759104013442993, "max_q": 9.17671012878418, "mean_td_error": 0.4682089686393738, "model": {}}}, "num_steps_sampled": 777600, "num_agent_steps_sampled": 777519, "num_steps_trained": 230112, "num_agent_steps_trained": 230112, "last_target_update_ts": 777600, "num_target_updates": 1439}, "done": false, "episodes_total": 15228, "training_iteration": 248, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-29", "timestamp": 1626860009, "time_this_iter_s": 1.1334002017974854, "time_total_s": 282.024719953537, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 282.024719953537, "timesteps_since_restore": 0, "iterations_since_restore": 248, "perf": {"cpu_util_percent": 50.25, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 102.68, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 25.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 355.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 355.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -2.0, 11.0, -5.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, -6.0, 12.0, 1.0, 8.0, 11.0, 13.0, 13.0, 315.0, 11.0, -4.0, 2.0, 6.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 9.0, 12.0, 1.0, -7.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 12.0, 12.0, 13.0, 318.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -4.0, 2.0, 6.0, 5.0, 12.0, -12.0, 10.0, 11.0, 13.0, 13.0, 315.0, 11.0, -15.0, 11.0, 8.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 5.0, 8.0, -9.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, -12.0, 14.0, 4.0, 9.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, -3.0, 14.0, 11.0, -7.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 7.0, -11.0, 11.0, 8.0, 7.0, 12.0, 1.0, -5.0, 11.0, 14.0, 13.0, 314.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, 0.0, 11.0, -7.0, 7.0, 12.0, 1.0, -5.0, 9.0, 14.0, 316.0, 13.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 318.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 6.0, 12.0, 1.0, -4.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, -3.0, 14.0, 10.0, -6.0, 7.0, 12.0, 5.0, -9.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 13.0, 8.0, -18.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -7.0, 10.0, -2.0, 7.0, 6.0, 4.0, 8.0, 0.0, 6.0, 1.0, -2.0, 7.0, 6.0, 4.0, 12.0, 0.0, -10.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4905282297013197, "mean_inference_ms": 2.0226858094932054, "mean_action_processing_ms": 0.12100498578995085, "mean_env_wait_ms": 0.28656702935426653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 780840, "agent_timesteps_total": 780786, "timers": {"learn_time_ms": 1.885, "learn_throughput": 16979.269, "update_time_ms": 4.323}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.517914772033691, "min_q": 0.7630825042724609, "max_q": 9.288956642150879, "mean_td_error": -9.554471969604492, "model": {}}}, "num_steps_sampled": 780840, "num_agent_steps_sampled": 780786, "num_steps_trained": 231072, "num_agent_steps_trained": 231072, "last_target_update_ts": 780840, "num_target_updates": 1445}, "done": false, "episodes_total": 15309, "training_iteration": 249, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-30", "timestamp": 1626860010, "time_this_iter_s": 1.1554715633392334, "time_total_s": 283.1801915168762, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 283.1801915168762, "timesteps_since_restore": 0, "iterations_since_restore": 249, "perf": {"cpu_util_percent": 48.4, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 68.95, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 17.2375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 355.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, -6.0, 2.0, 6.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -8.0, 10.0, 0.0, 8.0, 12.0, -5.0, 14.0, -3.0, -5.0, 9.0, 0.0, 8.0, 12.0, -5.0, 14.0, 0.0, -9.0, 10.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, -1.0, 12.0, 13.0, -9.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 10.0, 0.0, 1.0, 4.0, 0.0, 12.0, 12.0, -9.0, 13.0, -6.0, 10.0, -2.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 12.0, 12.0, -9.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, -5.0, -4.0, 11.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 7.0, 12.0, -4.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 12.0, 12.0, -9.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, -6.0, -4.0, 12.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 3.0, 0.0, -1.0, 13.0, -2.0, 7.0, 12.0, -2.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, -12.0, 14.0, 4.0, 9.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, -3.0, 14.0, 11.0, -7.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 7.0, -11.0, 11.0, 8.0, 7.0, 12.0, 1.0, -5.0, 11.0, 14.0, 13.0, 314.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, 0.0, 11.0, -7.0, 7.0, 12.0, 1.0, -5.0, 9.0, 14.0, 316.0, 13.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 318.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 6.0, 12.0, 1.0, -4.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, -3.0, 14.0, 10.0, -6.0, 7.0, 12.0, 5.0, -9.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48792407222193823, "mean_inference_ms": 2.0171110956258866, "mean_action_processing_ms": 0.12061187746152345, "mean_env_wait_ms": 0.2852950226258153, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 784080, "agent_timesteps_total": 783999, "timers": {"learn_time_ms": 1.817, "learn_throughput": 17607.174, "update_time_ms": 4.243}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.559700965881348, "min_q": 0.5810788869857788, "max_q": 8.080101013183594, "mean_td_error": 0.7768239974975586, "model": {}}}, "num_steps_sampled": 784080, "num_agent_steps_sampled": 783999, "num_steps_trained": 232032, "num_agent_steps_trained": 232032, "last_target_update_ts": 784080, "num_target_updates": 1451}, "done": false, "episodes_total": 15363, "training_iteration": 250, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-31", "timestamp": 1626860011, "time_this_iter_s": 1.1502337455749512, "time_total_s": 284.3304252624512, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 284.3304252624512, "timesteps_since_restore": 0, "iterations_since_restore": 250, "perf": {"cpu_util_percent": 50.4, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 45.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 11.3475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 355.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 14.0, 11.0, 13.0, 315.0, 13.0, 11.0, 13.0, 317.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 0.0, 8.0, 13.0, -6.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 14.0, 316.0, 13.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 318.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 6.0, 12.0, 1.0, -4.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, -3.0, 14.0, 10.0, -6.0, 7.0, 12.0, 5.0, -9.0, 11.0, 13.0, 13.0, 315.0, 11.0, -18.0, 11.0, 11.0, 7.0, 12.0, 1.0, -5.0, 11.0, 13.0, 13.0, 315.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, -6.0, 2.0, 6.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -8.0, 10.0, 0.0, 8.0, 12.0, -5.0, 14.0, -3.0, -5.0, 9.0, 0.0, 8.0, 12.0, -5.0, 14.0, 0.0, -9.0, 10.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, -1.0, 12.0, 13.0, -9.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 10.0, 0.0, 1.0, 4.0, 0.0, 12.0, 12.0, -9.0, 13.0, -6.0, 10.0, -2.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 12.0, 12.0, -9.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, -5.0, -4.0, 11.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 7.0, 12.0, -4.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 12.0, 12.0, -9.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 13.0, -6.0, -4.0, 12.0, 0.0, 8.0, 12.0, -5.0, 13.0, 0.0, -2.0, 4.0, 0.0, 8.0, 12.0, -5.0, 3.0, 0.0, -1.0, 13.0, -2.0, 7.0, 12.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48902629552233806, "mean_inference_ms": 2.0189283562890226, "mean_action_processing_ms": 0.12079151773729815, "mean_env_wait_ms": 0.28587684877855596, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 786240, "agent_timesteps_total": 786159, "timers": {"learn_time_ms": 1.896, "learn_throughput": 16876.789, "update_time_ms": 4.151}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.43965482711792, "min_q": 0.7277365326881409, "max_q": 8.843561172485352, "mean_td_error": 0.6334733963012695, "model": {}}}, "num_steps_sampled": 786240, "num_agent_steps_sampled": 786159, "num_steps_trained": 232672, "num_agent_steps_trained": 232672, "last_target_update_ts": 786240, "num_target_updates": 1455}, "done": false, "episodes_total": 15390, "training_iteration": 251, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-32", "timestamp": 1626860012, "time_this_iter_s": 0.9620702266693115, "time_total_s": 285.2924954891205, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985059d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 285.2924954891205, "timesteps_since_restore": 0, "iterations_since_restore": 251, "perf": {"cpu_util_percent": 40.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 5.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-17.0, 12.0, 12.0, 8.0, -4.0, 9.0, 13.0, -3.0, 6.0, 13.0, 1.0, -5.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 2.0, 13.0, 5.0, -5.0, -17.0, 12.0, 12.0, 8.0, 8.0, -14.0, 13.0, 8.0, 6.0, 13.0, 5.0, -9.0, -8.0, 12.0, 7.0, 4.0, -2.0, 9.0, 8.0, 0.0, 2.0, 13.0, 10.0, -10.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 5.0, 13.0, 4.0, -7.0, -17.0, 12.0, 12.0, 8.0, -3.0, 2.0, 8.0, 8.0, 3.0, 13.0, 6.0, -7.0, -11.0, 12.0, 12.0, 2.0, -3.0, 9.0, 13.0, -4.0, 3.0, 8.0, 8.0, -4.0, -17.0, 12.0, 12.0, 8.0, -6.0, 9.0, 13.0, -1.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -9.0, 4.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 7.0, 12.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -7.0, 11.0, 12.0, -1.0, 6.0, 13.0, 5.0, -9.0, -8.0, 12.0, 3.0, 8.0, -8.0, 9.0, 13.0, 1.0, 6.0, 13.0, 5.0, -9.0, -3.0, 12.0, 12.0, -6.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 1.0, 13.0, 11.0, -10.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, 2.0, 6.0, 8.0, -1.0, -4.0, 10.0, 12.0, -3.0, 6.0, 13.0, 4.0, -8.0, -17.0, 12.0, 12.0, 8.0, -3.0, 2.0, 8.0, 8.0, 8.0, 8.0, 8.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 2.0, 13.0, 5.0, -5.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 7.0, 13.0, -11.0, 6.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 7.0, 12.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 7.0, 8.0, 5.0, -5.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 14.0, 11.0, 13.0, 315.0, 13.0, 11.0, 13.0, 317.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 0.0, 8.0, 13.0, -6.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0, 9.0, 11.0, 13.0, -18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49390388813398217, "mean_inference_ms": 2.031222369451686, "mean_action_processing_ms": 0.12173549202497544, "mean_env_wait_ms": 0.2882229100755208, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 789480, "agent_timesteps_total": 789399, "timers": {"learn_time_ms": 1.884, "learn_throughput": 16985.931, "update_time_ms": 4.077}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.7007622718811035, "min_q": 0.7862339615821838, "max_q": 8.549656867980957, "mean_td_error": 0.7299308776855469, "model": {}}}, "num_steps_sampled": 789480, "num_agent_steps_sampled": 789399, "num_steps_trained": 233632, "num_agent_steps_trained": 233632, "last_target_update_ts": 789480, "num_target_updates": 1461}, "done": false, "episodes_total": 15471, "training_iteration": 252, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-34", "timestamp": 1626860014, "time_this_iter_s": 1.1322722434997559, "time_total_s": 286.42476773262024, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 286.42476773262024, "timesteps_since_restore": 0, "iterations_since_restore": 252, "perf": {"cpu_util_percent": 51.05, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 10.0, 12.0, -18.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 10.0, 12.0, -18.0, 11.0, 11.0, 2.0, -8.0, 10.0, 13.0, 2.0, -10.0, 10.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, 11.0, 2.0, -8.0, 10.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, 9.0, 8.0, 1.0, -3.0, 13.0, 0.0, -5.0, 7.0, 9.0, 2.0, -9.0, 13.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, 0.0, -5.0, 7.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, 11.0, 1.0, -10.0, 13.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, -6.0, -5.0, 13.0, 11.0, -13.0, 4.0, 13.0, 13.0, -4.0, -5.0, 11.0, 3.0, -7.0, 11.0, 8.0, 13.0, -4.0, -5.0, 11.0, -2.0, 2.0, 2.0, 13.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, 14.0, 0.0, -12.0, 13.0, 13.0, -4.0, -7.0, 13.0, 11.0, -14.0, 7.0, 11.0, 6.0, 2.0, -5.0, 12.0, -2.0, 7.0, 3.0, 7.0, 13.0, 7.0, -15.0, 10.0, 11.0, 3.0, -9.0, 10.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, 11.0, 3.0, 5.0, -4.0, 13.0, 7.0, -15.0, 10.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, -6.0, 5.0, 3.0, 13.0, 13.0, -4.0, -5.0, 11.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -7.0, 11.0, 12.0, -1.0, 6.0, 13.0, 5.0, -9.0, -8.0, 12.0, 3.0, 8.0, -8.0, 9.0, 13.0, 1.0, 6.0, 13.0, 5.0, -9.0, -3.0, 12.0, 12.0, -6.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 1.0, 13.0, 11.0, -10.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, 2.0, 6.0, 8.0, -1.0, -4.0, 10.0, 12.0, -3.0, 6.0, 13.0, 4.0, -8.0, -17.0, 12.0, 12.0, 8.0, -3.0, 2.0, 8.0, 8.0, 8.0, 8.0, 8.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 2.0, 13.0, 5.0, -5.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 7.0, 13.0, -11.0, 6.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 7.0, 12.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 7.0, 8.0, 5.0, -5.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0, -17.0, 12.0, 12.0, 8.0, -3.0, 9.0, 13.0, -4.0, 6.0, 13.0, 5.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48775224747546736, "mean_inference_ms": 2.0165325396830913, "mean_action_processing_ms": 0.12057706477320305, "mean_env_wait_ms": 0.2852089898591388, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 792720, "agent_timesteps_total": 792639, "timers": {"learn_time_ms": 1.845, "learn_throughput": 17348.412, "update_time_ms": 4.54}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.376487731933594, "min_q": 1.3883962631225586, "max_q": 9.224898338317871, "mean_td_error": 1.2833974361419678, "model": {}}}, "num_steps_sampled": 792720, "num_agent_steps_sampled": 792639, "num_steps_trained": 234592, "num_agent_steps_trained": 234592, "last_target_update_ts": 792720, "num_target_updates": 1467}, "done": false, "episodes_total": 15525, "training_iteration": 253, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-35", "timestamp": 1626860015, "time_this_iter_s": 1.164189100265503, "time_total_s": 287.58895683288574, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 287.58895683288574, "timesteps_since_restore": 0, "iterations_since_restore": 253, "perf": {"cpu_util_percent": 51.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -24.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 5.0, 14.0, -14.0, 10.0, 6.0, 11.0, 13.0, -15.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 12.0, 14.0, -24.0, 13.0, 12.0, 13.0, 8.0, -18.0, 11.0, 10.0, 2.0, -8.0, 11.0, 14.0, -22.0, 12.0, 7.0, 11.0, 8.0, -11.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 10.0, -5.0, -1.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 12.0, 8.0, -17.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, -2.0, 12.0, -1.0, 6.0, 11.0, 12.0, 4.0, -12.0, 2.0, 5.0, -3.0, 11.0, 12.0, 13.0, 8.0, -18.0, 12.0, 10.0, 1.0, -8.0, 11.0, 14.0, -22.0, 12.0, 12.0, 8.0, 13.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 3.0, -11.0, 9.0, -1.0, -5.0, 12.0, 7.0, 13.0, 8.0, -13.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 6.0, 14.0, 13.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 7.0, -15.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 2.0, 5.0, 10.0, -2.0, 12.0, 13.0, 8.0, -18.0, 12.0, 8.0, -17.0, 12.0, 11.0, 14.0, -22.0, 12.0, 7.0, 13.0, 6.0, -11.0, 11.0, 12.0, 4.0, -12.0, 10.0, 14.0, -21.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 3.0, -11.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 7.0, 13.0, 6.0, -11.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 12.0, 3.0, -12.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 6.0, 11.0, 13.0, -15.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, 14.0, 0.0, -12.0, 13.0, 13.0, -4.0, -7.0, 13.0, 11.0, -14.0, 7.0, 11.0, 6.0, 2.0, -5.0, 12.0, -2.0, 7.0, 3.0, 7.0, 13.0, 7.0, -15.0, 10.0, 11.0, 3.0, -9.0, 10.0, 13.0, -4.0, -5.0, 11.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, 11.0, 3.0, 5.0, -4.0, 13.0, 7.0, -15.0, 10.0, -6.0, 7.0, 1.0, 13.0, 13.0, -4.0, -5.0, 11.0, -6.0, 5.0, 3.0, 13.0, 13.0, -4.0, -5.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4902196175056408, "mean_inference_ms": 2.021749514437377, "mean_action_processing_ms": 0.12094245477738452, "mean_env_wait_ms": 0.28642474628262865, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 795960, "agent_timesteps_total": 795906, "timers": {"learn_time_ms": 1.837, "learn_throughput": 17419.562, "update_time_ms": 4.147}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.65297794342041, "min_q": 0.7727771401405334, "max_q": 9.068451881408691, "mean_td_error": 0.658153772354126, "model": {}}}, "num_steps_sampled": 795960, "num_agent_steps_sampled": 795906, "num_steps_trained": 235552, "num_agent_steps_trained": 235552, "last_target_update_ts": 795960, "num_target_updates": 1473}, "done": false, "episodes_total": 15606, "training_iteration": 254, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-36", "timestamp": 1626860016, "time_this_iter_s": 1.132666826248169, "time_total_s": 288.7216236591339, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 288.7216236591339, "timesteps_since_restore": 0, "iterations_since_restore": 254, "perf": {"cpu_util_percent": 46.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, -9.0, 11.0, 13.0, -14.0, 13.0, 7.0, 9.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 3.0, -12.0, 11.0, 13.0, -3.0, 12.0, 11.0, -5.0, 0.0, -9.0, 11.0, 13.0, 12.0, 12.0, 11.0, -20.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, 12.0, 12.0, 11.0, -20.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 1.0, -10.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 13.0, -13.0, 4.0, 11.0, 7.0, 13.0, 1.0, -6.0, 7.0, -15.0, 10.0, 13.0, -8.0, 7.0, 7.0, 9.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 2.0, -11.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, 14.0, -12.0, 0.0, 13.0, 0.0, -9.0, 11.0, 13.0, -3.0, 12.0, 11.0, -5.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 9.0, -11.0, 11.0, 6.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 7.0, -11.0, 6.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 4.0, -13.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 12.0, 8.0, 13.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 3.0, -11.0, 9.0, -1.0, -5.0, 12.0, 7.0, 13.0, 8.0, -13.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 6.0, 14.0, 13.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 7.0, -15.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 2.0, 5.0, 10.0, -2.0, 12.0, 13.0, 8.0, -18.0, 12.0, 8.0, -17.0, 12.0, 11.0, 14.0, -22.0, 12.0, 7.0, 13.0, 6.0, -11.0, 11.0, 12.0, 4.0, -12.0, 10.0, 14.0, -21.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 3.0, -11.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 7.0, 13.0, 6.0, -11.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 13.0, 8.0, -18.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 12.0, 12.0, 3.0, -12.0, 11.0, 12.0, 4.0, -12.0, 11.0, 14.0, -22.0, 12.0, 6.0, 11.0, 13.0, -15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48767674574909947, "mean_inference_ms": 2.0163817235011736, "mean_action_processing_ms": 0.12056166357789548, "mean_env_wait_ms": 0.2851700164074359, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 799200, "agent_timesteps_total": 799119, "timers": {"learn_time_ms": 1.952, "learn_throughput": 16397.211, "update_time_ms": 4.523}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.724189758300781, "min_q": 0.7725119590759277, "max_q": 8.706318855285645, "mean_td_error": -21.005409240722656, "model": {}}}, "num_steps_sampled": 799200, "num_agent_steps_sampled": 799119, "num_steps_trained": 236512, "num_agent_steps_trained": 236512, "last_target_update_ts": 799200, "num_target_updates": 1479}, "done": false, "episodes_total": 15660, "training_iteration": 255, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-37", "timestamp": 1626860017, "time_this_iter_s": 1.1853291988372803, "time_total_s": 289.9069528579712, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 289.9069528579712, "timesteps_since_restore": 0, "iterations_since_restore": 255, "perf": {"cpu_util_percent": 51.25, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -2.0, -1.0, 5.0, 13.0, 8.0, -19.0, 13.0, 13.0, 5.0, 0.0, -3.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -18.0, 11.0, 13.0, -2.0, 13.0, 0.0, 4.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -2.0, -7.0, 11.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, 5.0, 6.0, 7.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 13.0, 12.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, 8.0, -4.0, 12.0, -1.0, 9.0, -19.0, 12.0, 13.0, -3.0, -6.0, 11.0, 13.0, 9.0, -16.0, 9.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, 12.0, 12.0, 11.0, -20.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 1.0, -10.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 13.0, -13.0, 4.0, 11.0, 7.0, 13.0, 1.0, -6.0, 7.0, -15.0, 10.0, 13.0, -8.0, 7.0, 7.0, 9.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 2.0, -11.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, 14.0, -12.0, 0.0, 13.0, 0.0, -9.0, 11.0, 13.0, -3.0, 12.0, 11.0, -5.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 9.0, -11.0, 11.0, 6.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 7.0, -11.0, 6.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0, 4.0, -13.0, 11.0, 13.0, -1.0, 12.0, 11.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49320142870428524, "mean_inference_ms": 2.030036986122157, "mean_action_processing_ms": 0.12160467933762184, "mean_env_wait_ms": 0.2878734475706015, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 802440, "agent_timesteps_total": 802359, "timers": {"learn_time_ms": 1.886, "learn_throughput": 16971.54, "update_time_ms": 4.4}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.761770248413086, "min_q": 0.6082396507263184, "max_q": 8.582653999328613, "mean_td_error": -10.527925491333008, "model": {}}}, "num_steps_sampled": 802440, "num_agent_steps_sampled": 802359, "num_steps_trained": 237472, "num_agent_steps_trained": 237472, "last_target_update_ts": 802440, "num_target_updates": 1485}, "done": false, "episodes_total": 15714, "training_iteration": 256, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-38", "timestamp": 1626860018, "time_this_iter_s": 1.1799428462982178, "time_total_s": 291.0868957042694, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 291.0868957042694, "timesteps_since_restore": 0, "iterations_since_restore": 256, "perf": {"cpu_util_percent": 50.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.82, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 11.0, 5.0, -9.0, 8.0, 10.0, -16.0, 13.0, 8.0, 6.0, 13.0, -17.0, 13.0, 9.0, 2.0, -9.0, 13.0, 12.0, -13.0, 12.0, 4.0, 6.0, 14.0, -10.0, 5.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 6.0, -12.0, 12.0, 12.0, -11.0, 9.0, 5.0, 3.0, 14.0, -15.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 12.0, -10.0, 10.0, 3.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 0.0, -4.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 11.0, 13.0, 319.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 2.0, 14.0, -14.0, 13.0, 9.0, 9.0, -15.0, 12.0, 12.0, -15.0, 10.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 11.0, 14.0, 318.0, 13.0, 6.0, 6.0, -9.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 3.0, -9.0, 12.0, 12.0, -12.0, 9.0, 6.0, 7.0, 14.0, -19.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 12.0, -15.0, 10.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 0.0, -7.0, 13.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 8.0, 4.0, -9.0, 12.0, 12.0, -11.0, 10.0, 4.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 2.0, -9.0, 13.0, 12.0, -12.0, 10.0, 5.0, 7.0, 9.0, -14.0, 13.0, 8.0, 8.0, -14.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 13.0, 12.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, 8.0, -4.0, 12.0, -1.0, 9.0, -19.0, 12.0, 13.0, -3.0, -6.0, 11.0, 13.0, 9.0, -16.0, 9.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0, -3.0, -1.0, 6.0, 13.0, 9.0, -19.0, 12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49031565626661233, "mean_inference_ms": 2.022323382351203, "mean_action_processing_ms": 0.12095677254212615, "mean_env_wait_ms": 0.28650174541711765, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 805680, "agent_timesteps_total": 805626, "timers": {"learn_time_ms": 1.951, "learn_throughput": 16399.414, "update_time_ms": 5.35}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.070523738861084, "min_q": 0.786990225315094, "max_q": 8.692012786865234, "mean_td_error": -0.09336462616920471, "model": {}}}, "num_steps_sampled": 805680, "num_agent_steps_sampled": 805626, "num_steps_trained": 238432, "num_agent_steps_trained": 238432, "last_target_update_ts": 805680, "num_target_updates": 1491}, "done": false, "episodes_total": 15795, "training_iteration": 257, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-40", "timestamp": 1626860020, "time_this_iter_s": 1.1629669666290283, "time_total_s": 292.24986267089844, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 292.24986267089844, "timesteps_since_restore": 0, "iterations_since_restore": 257, "perf": {"cpu_util_percent": 50.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.82, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 12.0, -10.0, 2.0, 11.0, 13.0, -13.0, 5.0, 10.0, 13.0, -5.0, -5.0, 12.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, 6.0, -16.0, 12.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 14.0, -9.0, 1.0, 9.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -13.0, 5.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 6.0, -12.0, 12.0, 12.0, -11.0, 9.0, 5.0, 3.0, 14.0, -15.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 12.0, -10.0, 10.0, 3.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 0.0, -4.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 11.0, 13.0, 319.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 2.0, 14.0, -14.0, 13.0, 9.0, 9.0, -15.0, 12.0, 12.0, -15.0, 10.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 11.0, 14.0, 318.0, 13.0, 6.0, 6.0, -9.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 3.0, -9.0, 12.0, 12.0, -12.0, 9.0, 6.0, 7.0, 14.0, -19.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 12.0, -15.0, 10.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 0.0, -7.0, 13.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 8.0, 4.0, -9.0, 12.0, 12.0, -11.0, 10.0, 4.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 9.0, -15.0, 12.0, 10.0, -16.0, 13.0, 8.0, 6.0, 14.0, -18.0, 13.0, 9.0, 2.0, -9.0, 13.0, 12.0, -12.0, 10.0, 5.0, 7.0, 9.0, -14.0, 13.0, 8.0, 8.0, -14.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4930722818970103, "mean_inference_ms": 2.030164718243487, "mean_action_processing_ms": 0.12165950001025588, "mean_env_wait_ms": 0.2877542635696371, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 807840, "agent_timesteps_total": 807759, "timers": {"learn_time_ms": 1.941, "learn_throughput": 16483.197, "update_time_ms": 4.247}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.097182273864746, "min_q": 1.0313644409179688, "max_q": 9.523153305053711, "mean_td_error": -9.914978981018066, "model": {}}}, "num_steps_sampled": 807840, "num_agent_steps_sampled": 807759, "num_steps_trained": 239072, "num_agent_steps_trained": 239072, "last_target_update_ts": 807840, "num_target_updates": 1495}, "done": false, "episodes_total": 15822, "training_iteration": 258, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-41", "timestamp": 1626860021, "time_this_iter_s": 0.9938302040100098, "time_total_s": 293.24369287490845, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 293.24369287490845, "timesteps_since_restore": 0, "iterations_since_restore": 258, "perf": {"cpu_util_percent": 37.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 86.19, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 21.5475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 354.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 14.0, 9.0, -9.0, 7.0, 13.0, 12.0, -17.0, 14.0, -18.0, 9.0, 10.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 10.0, -17.0, 11.0, 11.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 11.0, 14.0, 318.0, 11.0, 12.0, 13.0, -18.0, 8.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, -15.0, 7.0, 12.0, 11.0, 14.0, -15.0, 7.0, 9.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, -1.0, 12.0, 12.0, -8.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 9.0, 10.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 10.0, 9.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 4.0, 12.0, -11.0, 10.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 3.0, 12.0, -11.0, 11.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 9.0, 10.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 0.0, 14.0, -9.0, 10.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 11.0, 14.0, 318.0, 11.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 7.0, 7.0, 12.0, -11.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -20.0, 11.0, 10.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 9.0, 13.0, -6.0, -1.0, 14.0, -20.0, 11.0, 10.0, -11.0, 9.0, 7.0, 10.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 1.0, 7.0, -4.0, 11.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, -12.0, 5.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, -17.0, 10.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, -13.0, 6.0, 12.0, 10.0, 14.0, -17.0, 11.0, 7.0, 11.0, 14.0, 318.0, 11.0, -13.0, 7.0, 11.0, 10.0, 9.0, -16.0, 11.0, 11.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 14.0, -9.0, 1.0, 9.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -13.0, 5.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 13.0, -10.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4938569689956459, "mean_inference_ms": 2.031519636122038, "mean_action_processing_ms": 0.1217248917859152, "mean_env_wait_ms": 0.2882491935469177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 811080, "agent_timesteps_total": 811053, "timers": {"learn_time_ms": 1.918, "learn_throughput": 16682.75, "update_time_ms": 4.258}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.341827392578125, "min_q": 0.8787668943405151, "max_q": 9.697792053222656, "mean_td_error": 0.11944464594125748, "model": {}}}, "num_steps_sampled": 811080, "num_agent_steps_sampled": 811053, "num_steps_trained": 240032, "num_agent_steps_trained": 240032, "last_target_update_ts": 811080, "num_target_updates": 1501}, "done": false, "episodes_total": 15903, "training_iteration": 259, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-42", "timestamp": 1626860022, "time_this_iter_s": 1.1509346961975098, "time_total_s": 294.39462757110596, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 294.39462757110596, "timesteps_since_restore": 0, "iterations_since_restore": 259, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 52.29, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 13.0725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 354.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 14.0, -9.0, 12.0, 14.0, 8.0, -19.0, 12.0, -1.0, -3.0, 8.0, 11.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 4.0, 1.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 4.0, 1.0, 12.0, 13.0, 8.0, -18.0, 12.0, -3.0, 2.0, 4.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 14.0, 9.0, -18.0, 10.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -14.0, 8.0, 3.0, 14.0, 1.0, -3.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -1.0, 2.0, 3.0, 11.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 0.0, 3.0, 7.0, 5.0, -1.0, 14.0, -10.0, 12.0, 14.0, 8.0, -19.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -3.0, 4.0, 2.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -3.0, 4.0, 2.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 4.0, 1.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -7.0, 10.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 0.0, 14.0, -9.0, 10.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 11.0, 14.0, 318.0, 11.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 7.0, 7.0, 12.0, -11.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -20.0, 11.0, 10.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 9.0, 13.0, -6.0, -1.0, 14.0, -20.0, 11.0, 10.0, -11.0, 9.0, 7.0, 10.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 1.0, 7.0, -4.0, 11.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, -12.0, 5.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, -17.0, 10.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0, 1.0, 14.0, 9.0, -9.0, -13.0, 6.0, 12.0, 10.0, 14.0, -17.0, 11.0, 7.0, 11.0, 14.0, 318.0, 11.0, -13.0, 7.0, 11.0, 10.0, 9.0, -16.0, 11.0, 11.0, 1.0, 14.0, 9.0, -9.0, 319.0, 13.0, 12.0, 10.0, 14.0, -18.0, 11.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48773428787585843, "mean_inference_ms": 2.016866759128268, "mean_action_processing_ms": 0.12056824749047942, "mean_env_wait_ms": 0.28523774367666127, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 814320, "agent_timesteps_total": 814239, "timers": {"learn_time_ms": 1.807, "learn_throughput": 17709.161, "update_time_ms": 4.043}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.781667232513428, "min_q": 0.7250532507896423, "max_q": 9.116825103759766, "mean_td_error": -9.948324203491211, "model": {}}}, "num_steps_sampled": 814320, "num_agent_steps_sampled": 814239, "num_steps_trained": 240992, "num_agent_steps_trained": 240992, "last_target_update_ts": 814320, "num_target_updates": 1507}, "done": false, "episodes_total": 15957, "training_iteration": 260, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-43", "timestamp": 1626860023, "time_this_iter_s": 1.0977425575256348, "time_total_s": 295.4923701286316, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 295.4923701286316, "timesteps_since_restore": 0, "iterations_since_restore": 260, "perf": {"cpu_util_percent": 48.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -2.0, 11.0, -7.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -2.0, -3.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 7.0, -5.0, 11.0, 2.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, -6.0, -1.0, 10.0, 12.0, 13.0, -12.0, 2.0, 12.0, 11.0, -11.0, 11.0, 4.0, 13.0, 10.0, -6.0, -2.0, 0.0, 13.0, -5.0, 7.0, 13.0, -16.0, 11.0, 7.0, 0.0, -1.0, 10.0, 6.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -9.0, 4.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 0.0, 13.0, -5.0, 7.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -9.0, 4.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, -2.0, -2.0, 12.0, 7.0, 7.0, -4.0, 2.0, 10.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 4.0, 1.0, 12.0, 13.0, 8.0, -18.0, 12.0, -3.0, 2.0, 4.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 14.0, 9.0, -18.0, 10.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -14.0, 8.0, 3.0, 14.0, 1.0, -3.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -1.0, 2.0, 3.0, 11.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 0.0, 3.0, 7.0, 5.0, -1.0, 14.0, -10.0, 12.0, 14.0, 8.0, -19.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -3.0, 4.0, 2.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -3.0, 4.0, 2.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 4.0, 1.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -7.0, 10.0, 13.0, 8.0, -18.0, 12.0, -2.0, 14.0, -9.0, 12.0, 13.0, 8.0, -18.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4931660100259327, "mean_inference_ms": 2.0300362692939844, "mean_action_processing_ms": 0.12158703099960062, "mean_env_wait_ms": 0.28787203790772514, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 817560, "agent_timesteps_total": 817479, "timers": {"learn_time_ms": 1.888, "learn_throughput": 16946.683, "update_time_ms": 4.339}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.692787170410156, "min_q": 0.7890489101409912, "max_q": 9.057451248168945, "mean_td_error": -10.555119514465332, "model": {}}}, "num_steps_sampled": 817560, "num_agent_steps_sampled": 817479, "num_steps_trained": 241952, "num_agent_steps_trained": 241952, "last_target_update_ts": 817560, "num_target_updates": 1513}, "done": false, "episodes_total": 16011, "training_iteration": 261, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-44", "timestamp": 1626860024, "time_this_iter_s": 1.127516746520996, "time_total_s": 296.6198868751526, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985057b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 296.6198868751526, "timesteps_since_restore": 0, "iterations_since_restore": 261, "perf": {"cpu_util_percent": 50.15, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 6.0, 3.0, 8.0, -2.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 7.0, 9.0, 5.0, -6.0, -2.0, -2.0, 7.0, 12.0, -1.0, 11.0, -6.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, -5.0, 14.0, -7.0, 13.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, 0.0, 4.0, 13.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, 12.0, -7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 8.0, 11.0, -8.0, -2.0, -2.0, 7.0, 12.0, 3.0, 13.0, -9.0, 8.0, 1.0, 5.0, 10.0, -1.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, 1.0, 4.0, 12.0, 7.0, 11.0, -14.0, 11.0, 7.0, 3.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 0.0, 7.0, 11.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 2.0, 12.0, -11.0, 12.0, 4.0, 6.0, 8.0, -3.0, -2.0, 12.0, -5.0, 10.0, 7.0, 11.0, -14.0, 11.0, 7.0, 6.0, 8.0, -6.0, 0.0, -2.0, 7.0, 10.0, 7.0, 11.0, -14.0, 11.0, 0.0, 8.0, 8.0, -1.0, -4.0, 12.0, 0.0, 7.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, -1.0, 8.0, 11.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 0.0, 13.0, -5.0, 7.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -9.0, 4.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, -2.0, -2.0, 12.0, 7.0, 7.0, -4.0, 2.0, 10.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0, 11.0, -11.0, 11.0, 4.0, 13.0, -16.0, 11.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4902985867970757, "mean_inference_ms": 2.022153308204257, "mean_action_processing_ms": 0.12092873149329517, "mean_env_wait_ms": 0.2865014720916859, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 820800, "agent_timesteps_total": 820746, "timers": {"learn_time_ms": 1.985, "learn_throughput": 16119.926, "update_time_ms": 4.634}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.681232929229736, "min_q": 0.7412116527557373, "max_q": 9.836225509643555, "mean_td_error": 0.8773086667060852, "model": {}}}, "num_steps_sampled": 820800, "num_agent_steps_sampled": 820746, "num_steps_trained": 242912, "num_agent_steps_trained": 242912, "last_target_update_ts": 820800, "num_target_updates": 1519}, "done": false, "episodes_total": 16092, "training_iteration": 262, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-45", "timestamp": 1626860025, "time_this_iter_s": 1.185767650604248, "time_total_s": 297.80565452575684, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 297.80565452575684, "timesteps_since_restore": 0, "iterations_since_restore": 262, "perf": {"cpu_util_percent": 50.35, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 99.73, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 24.9325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 352.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, -17.0, 9.0, 10.0, 13.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 10.0, 316.0, 13.0, 13.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 6.0, -16.0, 13.0, 12.0, 2.0, -4.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 6.0, -16.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 1.0, -3.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 1.0, -4.0, 5.0, 13.0, 12.0, 318.0, 12.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 11.0, 3.0, 8.0, -7.0, 11.0, 318.0, 13.0, 12.0, -16.0, 9.0, 9.0, 13.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 12.0, 318.0, 13.0, 11.0, -22.0, 14.0, 10.0, 13.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, -15.0, 9.0, 11.0, 10.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, 1.0, 4.0, 12.0, 7.0, 11.0, -14.0, 11.0, 7.0, 3.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 0.0, 7.0, 11.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 2.0, 12.0, -11.0, 12.0, 4.0, 6.0, 8.0, -3.0, -2.0, 12.0, -5.0, 10.0, 7.0, 11.0, -14.0, 11.0, 7.0, 6.0, 8.0, -6.0, 0.0, -2.0, 7.0, 10.0, 7.0, 11.0, -14.0, 11.0, 0.0, 8.0, 8.0, -1.0, -4.0, 12.0, 0.0, 7.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, -1.0, 8.0, 11.0, -3.0, -2.0, -2.0, 7.0, 12.0, 7.0, 11.0, -14.0, 11.0, 4.0, 6.0, 8.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4877794179708049, "mean_inference_ms": 2.0166948245656493, "mean_action_processing_ms": 0.12055532358780947, "mean_env_wait_ms": 0.28524291401258245, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 824040, "agent_timesteps_total": 823959, "timers": {"learn_time_ms": 1.881, "learn_throughput": 17008.963, "update_time_ms": 4.663}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.780531406402588, "min_q": 0.610234260559082, "max_q": 9.787699699401855, "mean_td_error": 0.2533625364303589, "model": {}}}, "num_steps_sampled": 824040, "num_agent_steps_sampled": 823959, "num_steps_trained": 243872, "num_agent_steps_trained": 243872, "last_target_update_ts": 824040, "num_target_updates": 1525}, "done": false, "episodes_total": 16146, "training_iteration": 263, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-47", "timestamp": 1626860027, "time_this_iter_s": 1.1700563430786133, "time_total_s": 298.97571086883545, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 298.97571086883545, "timesteps_since_restore": 0, "iterations_since_restore": 263, "perf": {"cpu_util_percent": 51.650000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 86.17, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 21.5425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 11.0, -4.0, 2.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -10.0, 2.0, 10.0, 13.0, 8.0, 6.0, -2.0, 3.0, -7.0, 2.0, 10.0, 10.0, 8.0, 6.0, -2.0, 3.0, -11.0, 2.0, 11.0, 13.0, 14.0, 11.0, -7.0, -3.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -10.0, 2.0, 10.0, 13.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 14.0, 9.0, -4.0, -4.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, 7.0, 2.0, 9.0, -3.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 13.0, 11.0, -13.0, 4.0, 11.0, 0.0, 12.0, -8.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 10.0, 11.0, -9.0, 3.0, -6.0, 2.0, 9.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, 7.0, 2.0, 9.0, -3.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, -3.0, 12.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, 7.0, 2.0, 9.0, -3.0, 12.0, 11.0, -2.0, -6.0, 7.0, 2.0, 9.0, -3.0, 10.0, 316.0, 13.0, 13.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 6.0, -16.0, 13.0, 12.0, 2.0, -4.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 6.0, -16.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 1.0, -3.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 1.0, -4.0, 5.0, 13.0, 12.0, 318.0, 12.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 11.0, 3.0, 8.0, -7.0, 11.0, 318.0, 13.0, 12.0, -16.0, 9.0, 9.0, 13.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 12.0, 318.0, 13.0, 11.0, -22.0, 14.0, 10.0, 13.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, -15.0, 9.0, 11.0, 10.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0, 11.0, 318.0, 13.0, 12.0, 5.0, -7.0, 5.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49334817975205775, "mean_inference_ms": 2.030451267025578, "mean_action_processing_ms": 0.12160567908242015, "mean_env_wait_ms": 0.2879520094662224, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 827280, "agent_timesteps_total": 827199, "timers": {"learn_time_ms": 1.8, "learn_throughput": 17773.651, "update_time_ms": 4.221}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.078407287597656, "min_q": 0.9317278861999512, "max_q": 10.803849220275879, "mean_td_error": 1.1409692764282227, "model": {}}}, "num_steps_sampled": 827280, "num_agent_steps_sampled": 827199, "num_steps_trained": 244832, "num_agent_steps_trained": 244832, "last_target_update_ts": 827280, "num_target_updates": 1531}, "done": false, "episodes_total": 16200, "training_iteration": 264, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-48", "timestamp": 1626860028, "time_this_iter_s": 1.2004642486572266, "time_total_s": 300.1761751174927, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 300.1761751174927, "timesteps_since_restore": 0, "iterations_since_restore": 264, "perf": {"cpu_util_percent": 47.3, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 0.0, 4.0, 8.0, 3.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -3.0, -6.0, 11.0, 13.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, -15.0, 8.0, 8.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 13.0, 8.0, -20.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, -12.0, 12.0, 12.0, 3.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 4.0, 14.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, 12.0, -21.0, 11.0, 13.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 1.0, 8.0, -8.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 3.0, 8.0, -10.0, -8.0, 5.0, 10.0, 8.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -11.0, 5.0, 10.0, 11.0, 14.0, 4.0, 8.0, -11.0, -6.0, -3.0, 13.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -9.0, 5.0, 8.0, 11.0, 14.0, 4.0, 8.0, -11.0, 14.0, 11.0, -7.0, -3.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -10.0, 2.0, 10.0, 13.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 14.0, 9.0, -4.0, -4.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, 7.0, 2.0, 9.0, -3.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 13.0, 11.0, -13.0, 4.0, 11.0, 0.0, 12.0, -8.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 10.0, 11.0, -9.0, 3.0, -6.0, 2.0, 9.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, 7.0, 2.0, 9.0, -3.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, -3.0, 12.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, -7.0, 2.0, 10.0, 10.0, 12.0, 11.0, -2.0, -6.0, 7.0, 2.0, 9.0, -3.0, 12.0, 11.0, -2.0, -6.0, 7.0, 2.0, 9.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49342438430122937, "mean_inference_ms": 2.0307128921810293, "mean_action_processing_ms": 0.1216259862678029, "mean_env_wait_ms": 0.2879982882193467, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 829440, "agent_timesteps_total": 829359, "timers": {"learn_time_ms": 1.931, "learn_throughput": 16569.476, "update_time_ms": 4.354}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.827052593231201, "min_q": 0.7376930117607117, "max_q": 10.108147621154785, "mean_td_error": 0.8540161848068237, "model": {}}}, "num_steps_sampled": 829440, "num_agent_steps_sampled": 829359, "num_steps_trained": 245472, "num_agent_steps_trained": 245472, "last_target_update_ts": 829440, "num_target_updates": 1535}, "done": false, "episodes_total": 16254, "training_iteration": 265, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-49", "timestamp": 1626860029, "time_this_iter_s": 1.0078017711639404, "time_total_s": 301.1839768886566, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 301.1839768886566, "timesteps_since_restore": 0, "iterations_since_restore": 265, "perf": {"cpu_util_percent": 44.349999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 12.0, 8.0, -12.0, 5.0, 0.0, -3.0, 13.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 4.0, 12.0, -8.0, 7.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, -9.0, -1.0, 12.0, 13.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, -6.0, 9.0, -1.0, 13.0, 13.0, -2.0, -8.0, 12.0, 7.0, 12.0, 8.0, -12.0, 6.0, 0.0, -4.0, 13.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 13.0, -5.0, -6.0, 13.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 6.0, 11.0, -9.0, 7.0, 3.0, 12.0, 9.0, -9.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 13.0, 9.0, -20.0, 13.0, 4.0, 11.0, -3.0, 3.0, 8.0, 11.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 13.0, -4.0, 2.0, 7.0, 12.0, 8.0, -12.0, -5.0, 10.0, -3.0, 13.0, 6.0, 11.0, -9.0, 7.0, 13.0, -4.0, -7.0, 13.0, 7.0, 12.0, 8.0, -12.0, -9.0, -1.0, 12.0, 13.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, -3.0, -6.0, 11.0, 13.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, -15.0, 8.0, 8.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 13.0, 8.0, -20.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, -12.0, 12.0, 12.0, 3.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 4.0, 14.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, 12.0, -21.0, 11.0, 13.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 1.0, 8.0, -8.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 3.0, 8.0, -10.0, -8.0, 5.0, 10.0, 8.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -11.0, 5.0, 10.0, 11.0, 14.0, 4.0, 8.0, -11.0, -6.0, -3.0, 13.0, 11.0, 14.0, 4.0, 8.0, -11.0, -12.0, 5.0, 11.0, 11.0, 14.0, 4.0, 8.0, -11.0, -9.0, 5.0, 8.0, 11.0, 14.0, 4.0, 8.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49347318818757174, "mean_inference_ms": 2.030915811779206, "mean_action_processing_ms": 0.12163672305476876, "mean_env_wait_ms": 0.288038736278382, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 832680, "agent_timesteps_total": 832599, "timers": {"learn_time_ms": 2.021, "learn_throughput": 15834.098, "update_time_ms": 5.711}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.298635959625244, "min_q": 0.986524760723114, "max_q": 9.281805992126465, "mean_td_error": 0.6223200559616089, "model": {}}}, "num_steps_sampled": 832680, "num_agent_steps_sampled": 832599, "num_steps_trained": 246432, "num_agent_steps_trained": 246432, "last_target_update_ts": 832680, "num_target_updates": 1541}, "done": false, "episodes_total": 16308, "training_iteration": 266, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-50", "timestamp": 1626860030, "time_this_iter_s": 1.1992216110229492, "time_total_s": 302.38319849967957, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 302.38319849967957, "timesteps_since_restore": 0, "iterations_since_restore": 266, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.95, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 7.9875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 6.0, -14.0, 11.0, 12.0, 11.0, 1.0, -4.0, 7.0, 12.0, 13.0, 13.0, 316.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 0.0, -3.0, 7.0, 12.0, 13.0, 13.0, 316.0, 8.0, -5.0, 11.0, 1.0, 11.0, 14.0, 318.0, 11.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 13.0, 7.0, 12.0, -17.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 9.0, 6.0, -7.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 12.0, 7.0, 6.0, -10.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 12.0, 13.0, 7.0, -17.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 0.0, -3.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 13.0, 6.0, 12.0, -16.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 2.0, 11.0, 11.0, -9.0, 8.0, -14.0, 9.0, 12.0, 1.0, 6.0, 12.0, -4.0, 5.0, 13.0, 13.0, -16.0, 8.0, -16.0, 11.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 12.0, 13.0, 13.0, 316.0, 8.0, -12.0, 9.0, 10.0, 13.0, -1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -16.0, 11.0, 12.0, 11.0, 1.0, -4.0, 7.0, 14.0, 13.0, 9.0, -21.0, 8.0, -5.0, 11.0, 1.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 12.0, 13.0, 13.0, 316.0, 8.0, -16.0, 11.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -5.0, 9.0, 3.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 13.0, 9.0, -20.0, 13.0, 4.0, 11.0, -3.0, 3.0, 8.0, 11.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0, 7.0, 12.0, 8.0, -12.0, 4.0, 13.0, -4.0, 2.0, 7.0, 12.0, 8.0, -12.0, -5.0, 10.0, -3.0, 13.0, 6.0, 11.0, -9.0, 7.0, 13.0, -4.0, -7.0, 13.0, 7.0, 12.0, 8.0, -12.0, -9.0, -1.0, 12.0, 13.0, 7.0, 12.0, 8.0, -12.0, 4.0, 11.0, -3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49057275471108835, "mean_inference_ms": 2.022958794647609, "mean_action_processing_ms": 0.1209773645758537, "mean_env_wait_ms": 0.28666416329169025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 835920, "agent_timesteps_total": 835866, "timers": {"learn_time_ms": 1.875, "learn_throughput": 17065.191, "update_time_ms": 4.061}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.006409645080566, "min_q": 0.5789103507995605, "max_q": 8.203156471252441, "mean_td_error": -9.923375129699707, "model": {}}}, "num_steps_sampled": 835920, "num_agent_steps_sampled": 835866, "num_steps_trained": 247392, "num_agent_steps_trained": 247392, "last_target_update_ts": 835920, "num_target_updates": 1547}, "done": false, "episodes_total": 16389, "training_iteration": 267, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-51", "timestamp": 1626860031, "time_this_iter_s": 1.1243290901184082, "time_total_s": 303.507527589798, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 303.507527589798, "timesteps_since_restore": 0, "iterations_since_restore": 267, "perf": {"cpu_util_percent": 49.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 6.0, 14.0, -17.0, 12.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 10.0, -11.0, 13.0, 13.0, 11.0, -2.0, -7.0, 3.0, 14.0, -15.0, 13.0, 12.0, 12.0, -2.0, -7.0, 2.0, 14.0, -14.0, 13.0, 12.0, 9.0, -2.0, -4.0, 2.0, 11.0, -10.0, 12.0, 12.0, 9.0, -2.0, -4.0, 4.0, 14.0, -15.0, 12.0, 12.0, 9.0, -2.0, -4.0, 6.0, 10.0, -12.0, 11.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 12.0, -2.0, -7.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 7.0, -2.0, -2.0, 6.0, 14.0, -17.0, 12.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 0.0, -2.0, 5.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 2.0, -7.0, 11.0, 9.0, 3.0, 14.0, -15.0, 13.0, 13.0, 8.0, -2.0, -4.0, 4.0, 14.0, -16.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, -3.0, 8.0, -1.0, 11.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 7.0, -2.0, -2.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 2.0, 11.0, 11.0, -9.0, 8.0, -14.0, 9.0, 12.0, 1.0, 6.0, 12.0, -4.0, 5.0, 13.0, 13.0, -16.0, 8.0, -16.0, 11.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 12.0, 13.0, 13.0, 316.0, 8.0, -12.0, 9.0, 10.0, 13.0, -1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -16.0, 11.0, 12.0, 11.0, 1.0, -4.0, 7.0, 14.0, 13.0, 9.0, -21.0, 8.0, -5.0, 11.0, 1.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 12.0, 13.0, 13.0, 316.0, 8.0, -16.0, 11.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -5.0, 9.0, 3.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0, 11.0, 1.0, -4.0, 7.0, 5.0, 13.0, 13.0, -16.0, 8.0, -14.0, 9.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48792562445722476, "mean_inference_ms": 2.0172454829807673, "mean_action_processing_ms": 0.12059501730319144, "mean_env_wait_ms": 0.2853504089103456, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 839160, "agent_timesteps_total": 839079, "timers": {"learn_time_ms": 1.842, "learn_throughput": 17375.588, "update_time_ms": 4.594}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.492603302001953, "min_q": 0.9051774740219116, "max_q": 9.104324340820312, "mean_td_error": 1.077481985092163, "model": {}}}, "num_steps_sampled": 839160, "num_agent_steps_sampled": 839079, "num_steps_trained": 248352, "num_agent_steps_trained": 248352, "last_target_update_ts": 839160, "num_target_updates": 1553}, "done": false, "episodes_total": 16443, "training_iteration": 268, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-53", "timestamp": 1626860033, "time_this_iter_s": 1.112961769104004, "time_total_s": 304.620489358902, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 304.620489358902, "timesteps_since_restore": 0, "iterations_since_restore": 268, "perf": {"cpu_util_percent": 51.45, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.38, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 4.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 11.0, 4.0, -13.0, 10.0, 11.0, 11.0, -17.0, 13.0, 12.0, -2.0, -8.0, 14.0, 14.0, 314.0, 11.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, -10.0, -1.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, -5.0, -6.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 14.0, 2.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 9.0, -4.0, -3.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 8.0, 12.0, -3.0, -2.0, 5.0, 11.0, -3.0, 2.0, 13.0, 12.0, 3.0, -13.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 13.0, 12.0, 6.0, -16.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 13.0, 3.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -8.0, -2.0, 14.0, 12.0, 4.0, -15.0, 12.0, 9.0, -2.0, -4.0, 3.0, 10.0, -11.0, 13.0, 13.0, 11.0, -2.0, -7.0, 3.0, 14.0, -15.0, 13.0, 12.0, 12.0, -2.0, -7.0, 2.0, 14.0, -14.0, 13.0, 12.0, 9.0, -2.0, -4.0, 2.0, 11.0, -10.0, 12.0, 12.0, 9.0, -2.0, -4.0, 4.0, 14.0, -15.0, 12.0, 12.0, 9.0, -2.0, -4.0, 6.0, 10.0, -12.0, 11.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 12.0, -2.0, -7.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 7.0, -2.0, -2.0, 6.0, 14.0, -17.0, 12.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 0.0, -2.0, 5.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 2.0, -7.0, 11.0, 9.0, 3.0, 14.0, -15.0, 13.0, 13.0, 8.0, -2.0, -4.0, 4.0, 14.0, -16.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, -3.0, 8.0, -1.0, 11.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0, 12.0, 7.0, -2.0, -2.0, 3.0, 14.0, -15.0, 13.0, 12.0, 9.0, -2.0, -4.0, 3.0, 14.0, -15.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934302386034816, "mean_inference_ms": 2.030659164362372, "mean_action_processing_ms": 0.12162017346504658, "mean_env_wait_ms": 0.2880228509928488, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 842400, "agent_timesteps_total": 842319, "timers": {"learn_time_ms": 1.883, "learn_throughput": 16993.243, "update_time_ms": 4.852}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.5504374504089355, "min_q": 0.8392356634140015, "max_q": 10.128101348876953, "mean_td_error": 0.20267942547798157, "model": {}}}, "num_steps_sampled": 842400, "num_agent_steps_sampled": 842319, "num_steps_trained": 249312, "num_agent_steps_trained": 249312, "last_target_update_ts": 842400, "num_target_updates": 1559}, "done": false, "episodes_total": 16497, "training_iteration": 269, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-54", "timestamp": 1626860034, "time_this_iter_s": 1.180412769317627, "time_total_s": 305.8009021282196, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 305.8009021282196, "timesteps_since_restore": 0, "iterations_since_restore": 269, "perf": {"cpu_util_percent": 50.45, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 10.0, -4.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 4.0, 12.0, -14.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 14.0, 3.0, 12.0, -14.0, 11.0, -5.0, -4.0, 13.0, 4.0, 2.0, -1.0, 10.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -8.0, -1.0, 13.0, 11.0, 13.0, 5.0, 12.0, -15.0, 11.0, 0.0, -9.0, 13.0, -10.0, 1.0, 13.0, 11.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 12.0, 0.0, -10.0, 13.0, -8.0, 0.0, 13.0, 10.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -7.0, 14.0, -4.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 14.0, 12.0, -15.0, 4.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 7.0, -3.0, 12.0, -1.0, 11.0, 0.0, -9.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -10.0, 1.0, 13.0, 11.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -10.0, 1.0, 13.0, 11.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -2.0, -7.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -9.0, 2.0, 13.0, 9.0, 13.0, 5.0, 12.0, -15.0, -2.0, -5.0, 9.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 6.0, -15.0, 12.0, 12.0, 11.0, -5.0, -4.0, 13.0, 3.0, 2.0, 13.0, -3.0, 13.0, 5.0, 12.0, -15.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 13.0, 12.0, 6.0, -16.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 13.0, 3.0, -15.0, 13.0, 12.0, -2.0, -8.0, 14.0, 12.0, 4.0, -15.0, 13.0, 12.0, -8.0, -2.0, 14.0, 12.0, 4.0, -15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4905176388143643, "mean_inference_ms": 2.0227544977292116, "mean_action_processing_ms": 0.12095965323190262, "mean_env_wait_ms": 0.2866433556119482, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 845640, "agent_timesteps_total": 845559, "timers": {"learn_time_ms": 1.922, "learn_throughput": 16651.704, "update_time_ms": 4.676}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.660902500152588, "min_q": 0.8756340146064758, "max_q": 10.008419036865234, "mean_td_error": -9.617047309875488, "model": {}}}, "num_steps_sampled": 845640, "num_agent_steps_sampled": 845559, "num_steps_trained": 250272, "num_agent_steps_trained": 250272, "last_target_update_ts": 845640, "num_target_updates": 1565}, "done": false, "episodes_total": 16578, "training_iteration": 270, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-55", "timestamp": 1626860035, "time_this_iter_s": 1.1888904571533203, "time_total_s": 306.9897925853729, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 306.9897925853729, "timesteps_since_restore": 0, "iterations_since_restore": 270, "perf": {"cpu_util_percent": 50.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -14.0, 5.0, 13.0, 11.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 4.0, -8.0, 10.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 4.0, -10.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 11.0, -17.0, 12.0, -14.0, 5.0, 13.0, 11.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -3.0, 5.0, 9.0, 4.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 11.0, -18.0, 13.0, -9.0, 5.0, 13.0, 6.0, 9.0, 11.0, -17.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -3.0, 5.0, 9.0, 4.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -7.0, 14.0, -4.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 14.0, 12.0, -15.0, 4.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 7.0, -3.0, 12.0, -1.0, 11.0, 0.0, -9.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -10.0, 1.0, 13.0, 11.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -10.0, 1.0, 13.0, 11.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -2.0, -7.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -9.0, 2.0, 13.0, 9.0, 13.0, 5.0, 12.0, -15.0, -2.0, -5.0, 9.0, 13.0, -11.0, 1.0, 13.0, 12.0, 13.0, 5.0, 12.0, -15.0, 11.0, -5.0, -4.0, 13.0, -11.0, 1.0, 13.0, 12.0, 6.0, -15.0, 12.0, 12.0, 11.0, -5.0, -4.0, 13.0, 3.0, 2.0, 13.0, -3.0, 13.0, 5.0, 12.0, -15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48793056003636404, "mean_inference_ms": 2.0170727414872873, "mean_action_processing_ms": 0.12058066032199308, "mean_env_wait_ms": 0.28532930428191444, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 848880, "agent_timesteps_total": 848799, "timers": {"learn_time_ms": 1.917, "learn_throughput": 16691.879, "update_time_ms": 4.094}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.443646430969238, "min_q": 0.7259256839752197, "max_q": 9.305619239807129, "mean_td_error": 0.9918656349182129, "model": {}}}, "num_steps_sampled": 848880, "num_agent_steps_sampled": 848799, "num_steps_trained": 251232, "num_agent_steps_trained": 251232, "last_target_update_ts": 848880, "num_target_updates": 1571}, "done": false, "episodes_total": 16632, "training_iteration": 271, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-56", "timestamp": 1626860036, "time_this_iter_s": 1.1185290813446045, "time_total_s": 308.10832166671753, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 308.10832166671753, "timesteps_since_restore": 0, "iterations_since_restore": 271, "perf": {"cpu_util_percent": 50.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -8.0, 1.0, 12.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 5.0, 12.0, -14.0, 12.0, 10.0, -11.0, 4.0, 12.0, 9.0, 10.0, -16.0, 12.0, 12.0, -7.0, 5.0, 5.0, -4.0, 0.0, 10.0, 9.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 9.0, -7.0, 3.0, 10.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 13.0, -19.0, 12.0, 13.0, -7.0, 9.0, 0.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -13.0, 6.0, 12.0, 9.0, 10.0, -16.0, 12.0, 10.0, 9.0, 8.0, -12.0, 9.0, 9.0, -15.0, 12.0, 10.0, -2.0, 2.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 13.0, -19.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 12.0, -7.0, 5.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -9.0, 2.0, 12.0, 9.0, 10.0, -16.0, 12.0, 10.0, -10.0, 8.0, 7.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, 9.0, 8.0, -12.0, 9.0, 10.0, -16.0, 12.0, 10.0, -11.0, 4.0, 12.0, -1.0, 9.0, -3.0, 10.0, 10.0, -7.0, 7.0, 5.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 4.0, -8.0, 10.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 4.0, -10.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 11.0, -17.0, 12.0, -14.0, 5.0, 13.0, 11.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -3.0, 5.0, 9.0, 4.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 11.0, -18.0, 13.0, -9.0, 5.0, 13.0, 6.0, 9.0, 11.0, -17.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -3.0, 5.0, 9.0, 4.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0, -9.0, 5.0, 13.0, 6.0, 9.0, 12.0, -18.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49348102934281207, "mean_inference_ms": 2.030650457737532, "mean_action_processing_ms": 0.12161785924529962, "mean_env_wait_ms": 0.28802556081204594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 851040, "agent_timesteps_total": 850986, "timers": {"learn_time_ms": 1.891, "learn_throughput": 16918.485, "update_time_ms": 4.78}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.596595287322998, "min_q": 0.5564523935317993, "max_q": 9.51683521270752, "mean_td_error": 0.6816534399986267, "model": {}}}, "num_steps_sampled": 851040, "num_agent_steps_sampled": 850986, "num_steps_trained": 251872, "num_agent_steps_trained": 251872, "last_target_update_ts": 851040, "num_target_updates": 1575}, "done": false, "episodes_total": 16686, "training_iteration": 272, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-57", "timestamp": 1626860037, "time_this_iter_s": 1.0008032321929932, "time_total_s": 309.1091248989105, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 309.1091248989105, "timesteps_since_restore": 0, "iterations_since_restore": 272, "perf": {"cpu_util_percent": 45.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 82.8, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 20.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, -7.0, 6.0, 4.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 12.0, -8.0, 12.0, -1.0, 319.0, 12.0, 11.0, 12.0, 13.0, -3.0, 12.0, -7.0, -16.0, 8.0, 11.0, 12.0, -4.0, 14.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 9.0, 2.0, 11.0, -7.0, -15.0, 7.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, -7.0, -1.0, 10.0, 13.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, -15.0, 7.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 10.0, 4.0, -11.0, 12.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, -11.0, 5.0, 11.0, 10.0, 7.0, 3.0, 12.0, -7.0, 319.0, 12.0, 10.0, 13.0, 8.0, 2.0, 12.0, -7.0, -7.0, 12.0, 11.0, -1.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 13.0, 0.0, 12.0, -10.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, -7.0, 14.0, 12.0, -4.0, 319.0, 12.0, 11.0, 12.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 5.0, 12.0, -14.0, 12.0, 10.0, -11.0, 4.0, 12.0, 9.0, 10.0, -16.0, 12.0, 12.0, -7.0, 5.0, 5.0, -4.0, 0.0, 10.0, 9.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 9.0, -7.0, 3.0, 10.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 13.0, -19.0, 12.0, 13.0, -7.0, 9.0, 0.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -13.0, 6.0, 12.0, 9.0, 10.0, -16.0, 12.0, 10.0, 9.0, 8.0, -12.0, 9.0, 9.0, -15.0, 12.0, 10.0, -2.0, 2.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 13.0, -19.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 12.0, -7.0, 5.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, -9.0, 2.0, 12.0, 9.0, 10.0, -16.0, 12.0, 10.0, -10.0, 8.0, 7.0, 9.0, 10.0, -16.0, 12.0, 10.0, -7.0, 7.0, 5.0, 9.0, 10.0, -16.0, 12.0, 10.0, 9.0, 8.0, -12.0, 9.0, 10.0, -16.0, 12.0, 10.0, -11.0, 4.0, 12.0, -1.0, 9.0, -3.0, 10.0, 10.0, -7.0, 7.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49346232231465303, "mean_inference_ms": 2.030641843717667, "mean_action_processing_ms": 0.12162247295305882, "mean_env_wait_ms": 0.28801893137690326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 854280, "agent_timesteps_total": 854199, "timers": {"learn_time_ms": 1.846, "learn_throughput": 17339.224, "update_time_ms": 4.71}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.855801582336426, "min_q": 1.1796813011169434, "max_q": 9.925732612609863, "mean_td_error": 0.33129289746284485, "model": {}}}, "num_steps_sampled": 854280, "num_agent_steps_sampled": 854199, "num_steps_trained": 252832, "num_agent_steps_trained": 252832, "last_target_update_ts": 854280, "num_target_updates": 1581}, "done": false, "episodes_total": 16740, "training_iteration": 273, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-33-58", "timestamp": 1626860038, "time_this_iter_s": 1.1041922569274902, "time_total_s": 310.213317155838, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 310.213317155838, "timesteps_since_restore": 0, "iterations_since_restore": 273, "perf": {"cpu_util_percent": 48.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 82.83, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 20.7075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0, 15.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 12.0, 322.0, 11.0, 10.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 9.0, 5.0, 13.0, -12.0, 13.0, -9.0, 13.0, -2.0, 13.0, 5.0, 13.0, -16.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 12.0, 4.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 10.0, 13.0, 319.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 10.0, 13.0, 319.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 12.0, -8.0, 12.0, -1.0, 319.0, 12.0, 11.0, 12.0, 13.0, -3.0, 12.0, -7.0, -16.0, 8.0, 11.0, 12.0, -4.0, 14.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 9.0, 2.0, 11.0, -7.0, -15.0, 7.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, -7.0, -1.0, 10.0, 13.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, -15.0, 7.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 10.0, 4.0, -11.0, 12.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, -11.0, 5.0, 11.0, 10.0, 7.0, 3.0, 12.0, -7.0, 319.0, 12.0, 10.0, 13.0, 8.0, 2.0, 12.0, -7.0, -7.0, 12.0, 11.0, -1.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, 13.0, 0.0, 12.0, -10.0, 319.0, 12.0, 11.0, 12.0, 8.0, 2.0, 12.0, -7.0, 319.0, 12.0, 11.0, 12.0, -7.0, 14.0, 12.0, -4.0, 319.0, 12.0, 11.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934050821010022, "mean_inference_ms": 2.030540825379879, "mean_action_processing_ms": 0.12161925743085363, "mean_env_wait_ms": 0.28800100091724345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 857520, "agent_timesteps_total": 857439, "timers": {"learn_time_ms": 1.914, "learn_throughput": 16719.95, "update_time_ms": 4.45}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.720615386962891, "min_q": 0.7231490612030029, "max_q": 9.205475807189941, "mean_td_error": 0.17128317058086395, "model": {}}}, "num_steps_sampled": 857520, "num_agent_steps_sampled": 857439, "num_steps_trained": 253792, "num_agent_steps_trained": 253792, "last_target_update_ts": 857520, "num_target_updates": 1587}, "done": false, "episodes_total": 16794, "training_iteration": 274, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-00", "timestamp": 1626860040, "time_this_iter_s": 1.1549432277679443, "time_total_s": 311.36826038360596, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985418c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 311.36826038360596, "timesteps_since_restore": 0, "iterations_since_restore": 274, "perf": {"cpu_util_percent": 50.150000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 106.05, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 26.5125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -1.0, 12.0, -6.0, -3.0, 8.0, 7.0, 3.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 4.0, 8.0, 6.0, 14.0, -14.0, 6.0, 9.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 13.0, 8.0, -17.0, 11.0, 10.0, -15.0, 12.0, 8.0, 2.0, 13.0, -2.0, 2.0, 14.0, 8.0, -18.0, 11.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -14.0, 6.0, 9.0, 13.0, 316.0, 12.0, 11.0, -11.0, 14.0, 10.0, 2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -8.0, 12.0, 5.0, 6.0, 14.0, -3.0, 10.0, -6.0, 13.0, 316.0, 12.0, 11.0, -19.0, 11.0, 12.0, 11.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -7.0, 8.0, 12.0, 2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 13.0, -5.0, -6.0, 13.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -5.0, 2.0, 7.0, 11.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -9.0, 10.0, 3.0, 11.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -9.0, 10.0, 3.0, 11.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 10.0, 13.0, 319.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 10.0, 13.0, 319.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0, 13.0, -9.0, 13.0, -2.0, 13.0, 3.0, 13.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4904465733249733, "mean_inference_ms": 2.0225235201851124, "mean_action_processing_ms": 0.12096359930808154, "mean_env_wait_ms": 0.28659273598011786, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 860760, "agent_timesteps_total": 860704, "timers": {"learn_time_ms": 1.953, "learn_throughput": 16385.4, "update_time_ms": 4.327}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.744131088256836, "min_q": 0.7748640775680542, "max_q": 8.627851486206055, "mean_td_error": 0.6842161417007446, "model": {}}}, "num_steps_sampled": 860760, "num_agent_steps_sampled": 860704, "num_steps_trained": 254752, "num_agent_steps_trained": 254752, "last_target_update_ts": 860760, "num_target_updates": 1593}, "done": false, "episodes_total": 16875, "training_iteration": 275, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-01", "timestamp": 1626860041, "time_this_iter_s": 1.1444318294525146, "time_total_s": 312.5126922130585, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 312.5126922130585, "timesteps_since_restore": 0, "iterations_since_restore": 275, "perf": {"cpu_util_percent": 50.900000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 65.55, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 16.3875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0, 352.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 10.0, -20.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 7.0, 13.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 10.0, -20.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 7.0, -17.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 13.0, 13.0, 5.0, -16.0, 6.0, 13.0, -13.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 7.0, -17.0, 6.0, 13.0, 13.0, -17.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 13.0, 9.0, -13.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -18.0, 13.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -7.0, 8.0, 12.0, 2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 13.0, -5.0, -6.0, 13.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -5.0, 2.0, 7.0, 11.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -9.0, 10.0, 3.0, 11.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -9.0, 10.0, 3.0, 11.0, 14.0, -17.0, 8.0, 10.0, 13.0, 316.0, 12.0, 11.0, -3.0, 8.0, 12.0, -2.0, 14.0, -17.0, 8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4878898079837068, "mean_inference_ms": 2.016830493862473, "mean_action_processing_ms": 0.12057392649161634, "mean_env_wait_ms": 0.2852966607903381, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 864000, "agent_timesteps_total": 863919, "timers": {"learn_time_ms": 1.831, "learn_throughput": 17473.081, "update_time_ms": 4.259}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.565372467041016, "min_q": 0.8799822330474854, "max_q": 9.060267448425293, "mean_td_error": -9.597411155700684, "model": {}}}, "num_steps_sampled": 864000, "num_agent_steps_sampled": 863919, "num_steps_trained": 255712, "num_agent_steps_trained": 255712, "last_target_update_ts": 864000, "num_target_updates": 1599}, "done": false, "episodes_total": 16929, "training_iteration": 276, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-02", "timestamp": 1626860042, "time_this_iter_s": 1.1583952903747559, "time_total_s": 313.6710875034332, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985056a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 313.6710875034332, "timesteps_since_restore": 0, "iterations_since_restore": 276, "perf": {"cpu_util_percent": 50.3, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -16.0, 10.0, 8.0, 13.0, 13.0, 4.0, -13.0, 11.0, -11.0, 5.0, 8.0, 13.0, 11.0, 14.0, -1.0, -9.0, -15.0, 9.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 14.0, 6.0, -14.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 4.0, -11.0, 10.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -19.0, 13.0, 9.0, 12.0, 8.0, 5.0, -8.0, 10.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -14.0, 10.0, 8.0, 11.0, 12.0, 13.0, -19.0, 9.0, -15.0, 9.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -10.0, 6.0, 8.0, 11.0, 11.0, 7.0, -15.0, 12.0, -9.0, 3.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 12.0, -18.0, 9.0, -11.0, 5.0, 8.0, 13.0, 1.0, 13.0, -11.0, 12.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 7.0, 13.0, -16.0, 11.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -14.0, 8.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 7.0, 13.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 10.0, -20.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 7.0, -17.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 13.0, 13.0, 5.0, -16.0, 6.0, 13.0, -13.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 7.0, -17.0, 6.0, 13.0, 13.0, -17.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 13.0, 9.0, -13.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -18.0, 13.0, 12.0, 13.0, 6.0, -16.0, 6.0, 14.0, -14.0, 9.0, 12.0, 13.0, 6.0, -16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4933751390611536, "mean_inference_ms": 2.030228200403511, "mean_action_processing_ms": 0.12160297127248881, "mean_env_wait_ms": 0.28796873979261617, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 867240, "agent_timesteps_total": 867159, "timers": {"learn_time_ms": 1.986, "learn_throughput": 16114.507, "update_time_ms": 4.51}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.420193195343018, "min_q": 0.7775432467460632, "max_q": 9.106730461120605, "mean_td_error": 0.254802942276001, "model": {}}}, "num_steps_sampled": 867240, "num_agent_steps_sampled": 867159, "num_steps_trained": 256672, "num_agent_steps_trained": 256672, "last_target_update_ts": 867240, "num_target_updates": 1605}, "done": false, "episodes_total": 16983, "training_iteration": 277, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-03", "timestamp": 1626860043, "time_this_iter_s": 1.1228630542755127, "time_total_s": 314.79395055770874, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dabf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 314.79395055770874, "timesteps_since_restore": 0, "iterations_since_restore": 277, "perf": {"cpu_util_percent": 50.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-7.0, 6.0, 13.0, 3.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -18.0, 13.0, 12.0, 8.0, 14.0, 3.0, -1.0, -1.0, 13.0, 13.0, 8.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, 13.0, 8.0, -19.0, -12.0, 14.0, 1.0, 12.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, 13.0, 13.0, 315.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -15.0, 13.0, 12.0, 5.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, -1.0, 13.0, -10.0, -10.0, 14.0, 10.0, 1.0, 13.0, 8.0, -1.0, -5.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, 13.0, 8.0, -19.0, -13.0, 8.0, 12.0, 8.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -9.0, 9.0, 12.0, 3.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -11.0, 13.0, 6.0, 7.0, 14.0, 5.0, 12.0, -16.0, 8.0, 12.0, 13.0, -18.0, -12.0, 9.0, 11.0, 7.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -15.0, 13.0, 12.0, 5.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, 12.0, 13.0, 316.0, -9.0, 14.0, -2.0, 12.0, 14.0, 7.0, -1.0, -5.0, 8.0, 13.0, 11.0, -17.0, -11.0, 14.0, 0.0, 12.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -11.0, 14.0, 12.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 6.0, -1.0, -4.0, 2.0, 13.0, 13.0, -13.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -11.0, 5.0, 8.0, 13.0, 12.0, 12.0, -18.0, 9.0, -11.0, 5.0, 8.0, 13.0, 1.0, 13.0, -11.0, 12.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 7.0, 13.0, -16.0, 11.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -14.0, 8.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0, 12.0, 13.0, -19.0, 9.0, -11.0, 5.0, 8.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49035744049423413, "mean_inference_ms": 2.0220548870785513, "mean_action_processing_ms": 0.12094232646869019, "mean_env_wait_ms": 0.28653765976358386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 870480, "agent_timesteps_total": 870399, "timers": {"learn_time_ms": 1.814, "learn_throughput": 17642.353, "update_time_ms": 4.269}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.492507457733154, "min_q": 1.0324338674545288, "max_q": 8.434945106506348, "mean_td_error": 0.3754678964614868, "model": {}}}, "num_steps_sampled": 870480, "num_agent_steps_sampled": 870399, "num_steps_trained": 257632, "num_agent_steps_trained": 257632, "last_target_update_ts": 870480, "num_target_updates": 1611}, "done": false, "episodes_total": 17064, "training_iteration": 278, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-04", "timestamp": 1626860044, "time_this_iter_s": 1.1485178470611572, "time_total_s": 315.9424684047699, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 315.9424684047699, "timesteps_since_restore": 0, "iterations_since_restore": 278, "perf": {"cpu_util_percent": 50.349999999999994, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.78, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -21.0, 12.0, 13.0, 7.0, -17.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 0.0, -10.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 7.0, -17.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 7.0, -17.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 13.0, 13.0, 8.0, -19.0, -12.0, 14.0, 1.0, 12.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, 13.0, 13.0, 315.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -15.0, 13.0, 12.0, 5.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, -1.0, 13.0, -10.0, -10.0, 14.0, 10.0, 1.0, 13.0, 8.0, -1.0, -5.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, 13.0, 8.0, -19.0, -13.0, 8.0, 12.0, 8.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -9.0, 9.0, 12.0, 3.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -11.0, 13.0, 6.0, 7.0, 14.0, 5.0, 12.0, -16.0, 8.0, 12.0, 13.0, -18.0, -12.0, 9.0, 11.0, 7.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -15.0, 13.0, 12.0, 5.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 13.0, 12.0, 13.0, 316.0, -9.0, 14.0, -2.0, 12.0, 14.0, 7.0, -1.0, -5.0, 8.0, 13.0, 11.0, -17.0, -11.0, 14.0, 0.0, 12.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -11.0, 14.0, 12.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0, -10.0, 14.0, 11.0, 0.0, 14.0, 6.0, -1.0, -4.0, 2.0, 13.0, 13.0, -13.0, -10.0, 14.0, 11.0, 0.0, 14.0, 3.0, -1.0, -1.0, 8.0, 13.0, 13.0, -19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49316343455594525, "mean_inference_ms": 2.029844179247076, "mean_action_processing_ms": 0.12163251979073947, "mean_env_wait_ms": 0.287799681855984, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 872640, "agent_timesteps_total": 872559, "timers": {"learn_time_ms": 1.929, "learn_throughput": 16587.087, "update_time_ms": 4.821}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.197396278381348, "min_q": 0.8286473155021667, "max_q": 9.201496124267578, "mean_td_error": 0.4410402476787567, "model": {}}}, "num_steps_sampled": 872640, "num_agent_steps_sampled": 872559, "num_steps_trained": 258272, "num_agent_steps_trained": 258272, "last_target_update_ts": 872640, "num_target_updates": 1615}, "done": false, "episodes_total": 17091, "training_iteration": 279, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-05", "timestamp": 1626860045, "time_this_iter_s": 0.969498872756958, "time_total_s": 316.91196727752686, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 316.91196727752686, "timesteps_since_restore": 0, "iterations_since_restore": 279, "perf": {"cpu_util_percent": 39.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 3.0, 12.0, 4.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -14.0, 11.0, 9.0, 9.0, 5.0, 14.0, 0.0, -4.0, -4.0, 9.0, 11.0, -1.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, -3.0, 9.0, 10.0, -1.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, -18.0, 13.0, 9.0, 11.0, -4.0, 9.0, 11.0, -1.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, -9.0, 14.0, 0.0, 10.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 8.0, 9.0, 2.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, -9.0, 14.0, 12.0, -2.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 5.0, 14.0, -2.0, -2.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, -4.0, 9.0, 11.0, -1.0, -10.0, 8.0, 11.0, 6.0, -15.0, 14.0, 4.0, 12.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 9.0, 8.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, -2.0, -1.0, -10.0, 8.0, 11.0, 6.0, -4.0, 14.0, 9.0, -4.0, -5.0, 9.0, 11.0, 0.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 11.0, 9.0, -8.0, 3.0, -10.0, 8.0, 11.0, 6.0, 1.0, 14.0, -4.0, 4.0, -5.0, 9.0, 11.0, 0.0, -10.0, 8.0, 11.0, 6.0, 0.0, 14.0, 7.0, -6.0, 9.0, 9.0, 11.0, -14.0, -7.0, 3.0, 11.0, 8.0, 5.0, 14.0, 0.0, -4.0, 9.0, 4.0, 11.0, -9.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, 8.0, -18.0, 12.0, 13.0, 7.0, -17.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 7.0, -17.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0, 8.0, -18.0, 12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49395227277398057, "mean_inference_ms": 2.031203322622613, "mean_action_processing_ms": 0.12171210578623037, "mean_env_wait_ms": 0.28829940710836194, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 875880, "agent_timesteps_total": 875826, "timers": {"learn_time_ms": 1.928, "learn_throughput": 16594.675, "update_time_ms": 4.465}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.266956329345703, "min_q": 0.6916866302490234, "max_q": 10.084612846374512, "mean_td_error": 0.2628428339958191, "model": {}}}, "num_steps_sampled": 875880, "num_agent_steps_sampled": 875826, "num_steps_trained": 259232, "num_agent_steps_trained": 259232, "last_target_update_ts": 875880, "num_target_updates": 1621}, "done": false, "episodes_total": 17172, "training_iteration": 280, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-07", "timestamp": 1626860047, "time_this_iter_s": 1.1732244491577148, "time_total_s": 318.08519172668457, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 318.08519172668457, "timesteps_since_restore": 0, "iterations_since_restore": 280, "perf": {"cpu_util_percent": 51.150000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 9.0, 3.0, -3.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 6.0, 9.0, 3.0, -3.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 7.0, 7.0, 2.0, -1.0, 12.0, -11.0, 12.0, 2.0, 9.0, 13.0, -3.0, -4.0, 12.0, -11.0, 12.0, 2.0, 6.0, 12.0, 3.0, -6.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 11.0, -12.0, 12.0, 4.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 6.0, 12.0, 3.0, -6.0, 13.0, -12.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -13.0, 12.0, 4.0, 12.0, 9.0, 0.0, -6.0, 12.0, -12.0, 2.0, 13.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 3.0, 9.0, 6.0, -3.0, 12.0, -11.0, 12.0, 2.0, 9.0, 9.0, 0.0, -3.0, 11.0, -11.0, 13.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 12.0, 9.0, -1.0, -5.0, 12.0, -11.0, 12.0, 2.0, 5.0, 14.0, -2.0, -2.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, -4.0, 9.0, 11.0, -1.0, -10.0, 8.0, 11.0, 6.0, -15.0, 14.0, 4.0, 12.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 9.0, 8.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, -2.0, -1.0, -10.0, 8.0, 11.0, 6.0, -4.0, 14.0, 9.0, -4.0, -5.0, 9.0, 11.0, 0.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 11.0, 9.0, -8.0, 3.0, -10.0, 8.0, 11.0, 6.0, 1.0, 14.0, -4.0, 4.0, -5.0, 9.0, 11.0, 0.0, -10.0, 8.0, 11.0, 6.0, 0.0, 14.0, 7.0, -6.0, 9.0, 9.0, 11.0, -14.0, -7.0, 3.0, 11.0, 8.0, 5.0, 14.0, 0.0, -4.0, 9.0, 4.0, 11.0, -9.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0, -10.0, 8.0, 11.0, 6.0, 5.0, 14.0, 0.0, -4.0, 9.0, 9.0, 11.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4878230987953554, "mean_inference_ms": 2.01686967114794, "mean_action_processing_ms": 0.12057058580237058, "mean_env_wait_ms": 0.2853225513024509, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 879120, "agent_timesteps_total": 879039, "timers": {"learn_time_ms": 1.795, "learn_throughput": 17824.636, "update_time_ms": 4.342}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.286876201629639, "min_q": 0.6972055435180664, "max_q": 9.165533065795898, "mean_td_error": 1.5001869201660156, "model": {}}}, "num_steps_sampled": 879120, "num_agent_steps_sampled": 879039, "num_steps_trained": 260192, "num_agent_steps_trained": 260192, "last_target_update_ts": 879120, "num_target_updates": 1627}, "done": false, "episodes_total": 17226, "training_iteration": 281, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-08", "timestamp": 1626860048, "time_this_iter_s": 1.155050277709961, "time_total_s": 319.24024200439453, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 319.24024200439453, "timesteps_since_restore": 0, "iterations_since_restore": 281, "perf": {"cpu_util_percent": 50.85, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 13.0, -16.0, 7.0, 11.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, -5.0, 14.0, -2.0, 8.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -6.0, 5.0, 7.0, 5.0, 13.0, -3.0, 0.0, 9.0, -9.0, 6.0, 9.0, 11.0, 2.0, 5.0, -3.0, 9.0, -9.0, 6.0, 9.0, -4.0, 4.0, 2.0, 13.0, -6.0, 2.0, 8.0, 11.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 12.0, -12.0, 8.0, 7.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 6.0, -14.0, 11.0, 12.0, 10.0, 3.0, -5.0, 7.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, -1.0, 14.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, -4.0, -4.0, 13.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 12.0, -9.0, 10.0, 2.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 4.0, -3.0, 4.0, 6.0, 9.0, 3.0, -3.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 7.0, 7.0, 2.0, -1.0, 12.0, -11.0, 12.0, 2.0, 9.0, 13.0, -3.0, -4.0, 12.0, -11.0, 12.0, 2.0, 6.0, 12.0, 3.0, -6.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 11.0, -12.0, 12.0, 4.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 6.0, 12.0, 3.0, -6.0, 13.0, -12.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -13.0, 12.0, 4.0, 12.0, 9.0, 0.0, -6.0, 12.0, -12.0, 2.0, 13.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 3.0, 9.0, 6.0, -3.0, 12.0, -11.0, 12.0, 2.0, 9.0, 9.0, 0.0, -3.0, 11.0, -11.0, 13.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 13.0, 9.0, 6.0, -13.0, 12.0, -11.0, 12.0, 2.0, 12.0, 9.0, -1.0, -5.0, 12.0, -11.0, 12.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4933381586009606, "mean_inference_ms": 2.0304424984255216, "mean_action_processing_ms": 0.12161020881183159, "mean_env_wait_ms": 0.28802909089337647, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 882360, "agent_timesteps_total": 882279, "timers": {"learn_time_ms": 2.04, "learn_throughput": 15684.588, "update_time_ms": 5.161}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.724714756011963, "min_q": 0.8717120885848999, "max_q": 8.865135192871094, "mean_td_error": 0.5197280049324036, "model": {}}}, "num_steps_sampled": 882360, "num_agent_steps_sampled": 882279, "num_steps_trained": 261152, "num_agent_steps_trained": 261152, "last_target_update_ts": 882360, "num_target_updates": 1633}, "done": false, "episodes_total": 17280, "training_iteration": 282, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-09", "timestamp": 1626860049, "time_this_iter_s": 1.158318042755127, "time_total_s": 320.39856004714966, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 320.39856004714966, "timesteps_since_restore": 0, "iterations_since_restore": 282, "perf": {"cpu_util_percent": 50.0, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 170.69, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 42.6725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, -5.0, 12.0, -4.0, 12.0, 12.0, -18.0, 12.0, 9.0, 10.0, -19.0, 11.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 1.0, -6.0, 7.0, 13.0, -5.0, 2.0, 7.0, 11.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, -17.0, 7.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 6.0, -5.0, 12.0, 2.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 6.0, -10.0, 7.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 9.0, 8.0, -15.0, 13.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 12.0, 6.0, -13.0, 10.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 11.0, 318.0, 12.0, 9.0, -14.0, 12.0, 8.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, -1.0, 14.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, -4.0, -4.0, 13.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 12.0, -9.0, 10.0, 2.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 3.0, -2.0, 4.0, 9.0, -9.0, 6.0, 9.0, 10.0, 4.0, -3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49046023331558736, "mean_inference_ms": 2.022500491768103, "mean_action_processing_ms": 0.12095874094990929, "mean_env_wait_ms": 0.28663314804464035, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 885600, "agent_timesteps_total": 885519, "timers": {"learn_time_ms": 1.888, "learn_throughput": 16952.676, "update_time_ms": 4.238}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.26850700378418, "min_q": 0.7179917693138123, "max_q": 9.470475196838379, "mean_td_error": 0.6165025234222412, "model": {}}}, "num_steps_sampled": 885600, "num_agent_steps_sampled": 885519, "num_steps_trained": 262112, "num_agent_steps_trained": 262112, "last_target_update_ts": 885600, "num_target_updates": 1639}, "done": false, "episodes_total": 17361, "training_iteration": 283, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-10", "timestamp": 1626860050, "time_this_iter_s": 1.1456985473632812, "time_total_s": 321.54425859451294, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985417b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 321.54425859451294, "timesteps_since_restore": 0, "iterations_since_restore": 283, "perf": {"cpu_util_percent": 50.35, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 109.77, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 27.4425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 15.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0, 15.0, 353.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -8.0, 2.0, 12.0, 11.0, 10.0, -19.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 8.0, 2.0, -6.0, 9.0, -10.0, 4.0, 12.0, 11.0, -5.0, -4.0, 13.0, 9.0, -10.0, 4.0, 12.0, 8.0, 2.0, -8.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 9.0, -17.0, 12.0, 9.0, -10.0, 6.0, 10.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 1.0, -8.0, 11.0, 9.0, -10.0, 4.0, 12.0, 9.0, 11.0, -4.0, -1.0, 9.0, -11.0, 5.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 8.0, 1.0, -5.0, 9.0, -16.0, 10.0, 12.0, 9.0, 7.0, -8.0, 7.0, 9.0, -8.0, 2.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -11.0, 5.0, 12.0, 11.0, 1.0, -10.0, 13.0, 9.0, -17.0, 12.0, 11.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 1.0, -10.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 1.0, -8.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, -12.0, 6.0, 10.0, 9.0, -10.0, 4.0, 12.0, 11.0, -18.0, 10.0, 12.0, 9.0, -10.0, 4.0, 12.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 6.0, -10.0, 7.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 9.0, 8.0, -15.0, 13.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 12.0, 6.0, -13.0, 10.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 11.0, 318.0, 12.0, 9.0, -14.0, 12.0, 8.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0, 12.0, -18.0, 12.0, 9.0, 14.0, 314.0, 12.0, 13.0, 13.0, 12.0, 317.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4878610615404215, "mean_inference_ms": 2.016925047646654, "mean_action_processing_ms": 0.12057328550221821, "mean_env_wait_ms": 0.2853552071835557, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 888840, "agent_timesteps_total": 888759, "timers": {"learn_time_ms": 1.98, "learn_throughput": 16159.908, "update_time_ms": 4.995}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.322125434875488, "min_q": 0.6654329299926758, "max_q": 8.914631843566895, "mean_td_error": -9.993059158325195, "model": {}}}, "num_steps_sampled": 888840, "num_agent_steps_sampled": 888759, "num_steps_trained": 263072, "num_agent_steps_trained": 263072, "last_target_update_ts": 888840, "num_target_updates": 1645}, "done": false, "episodes_total": 17415, "training_iteration": 284, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-11", "timestamp": 1626860051, "time_this_iter_s": 1.1492605209350586, "time_total_s": 322.693519115448, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985411e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 322.693519115448, "timesteps_since_restore": 0, "iterations_since_restore": 284, "perf": {"cpu_util_percent": 50.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.21, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 6.3025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, -5.0, 12.0, 10.0, 11.0, 13.0, 318.0, 11.0, -2.0, -5.0, 12.0, 10.0, 11.0, -1.0, -6.0, 11.0, -3.0, -4.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 13.0, -7.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, 9.0, 2.0, 12.0, -8.0, 11.0, 11.0, 12.0, -19.0, -2.0, -5.0, 12.0, 10.0, 12.0, 12.0, 321.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -7.0, 11.0, 0.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -4.0, 12.0, 9.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, 12.0, 12.0, 322.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -3.0, 12.0, 8.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, 9.0, 13.0, -18.0, 11.0, 11.0, 4.0, 11.0, -11.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -3.0, 13.0, -6.0, 11.0, -4.0, 1.0, 12.0, 6.0, -2.0, 11.0, -5.0, 11.0, -4.0, 2.0, 12.0, 5.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 13.0, -5.0, 9.0, 11.0, -5.0, -4.0, 13.0, 9.0, -10.0, 4.0, 12.0, 8.0, 2.0, -8.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 9.0, -17.0, 12.0, 9.0, -10.0, 6.0, 10.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 1.0, -8.0, 11.0, 9.0, -10.0, 4.0, 12.0, 9.0, 11.0, -4.0, -1.0, 9.0, -11.0, 5.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 8.0, 1.0, -5.0, 9.0, -16.0, 10.0, 12.0, 9.0, 7.0, -8.0, 7.0, 9.0, -8.0, 2.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -11.0, 5.0, 12.0, 11.0, 1.0, -10.0, 13.0, 9.0, -17.0, 12.0, 11.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, 1.0, -10.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 7.0, -14.0, 13.0, 9.0, -10.0, 4.0, 12.0, 9.0, 1.0, -8.0, 13.0, 9.0, -10.0, 4.0, 12.0, 11.0, -12.0, 6.0, 10.0, 9.0, -10.0, 4.0, 12.0, 11.0, -18.0, 10.0, 12.0, 9.0, -10.0, 4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4933727943748389, "mean_inference_ms": 2.0303572804731465, "mean_action_processing_ms": 0.12161061593188602, "mean_env_wait_ms": 0.2880331339241664, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 892080, "agent_timesteps_total": 891999, "timers": {"learn_time_ms": 1.862, "learn_throughput": 17189.77, "update_time_ms": 4.477}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.798242092132568, "min_q": 0.8081043362617493, "max_q": 8.309887886047363, "mean_td_error": 1.0552423000335693, "model": {}}}, "num_steps_sampled": 892080, "num_agent_steps_sampled": 891999, "num_steps_trained": 264032, "num_agent_steps_trained": 264032, "last_target_update_ts": 892080, "num_target_updates": 1651}, "done": false, "episodes_total": 17469, "training_iteration": 285, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-13", "timestamp": 1626860053, "time_this_iter_s": 1.126617670059204, "time_total_s": 323.8201367855072, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985052f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 323.8201367855072, "timesteps_since_restore": 0, "iterations_since_restore": 285, "perf": {"cpu_util_percent": 49.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.83, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 5.4575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 3.0, -2.0, 1.0, 13.0, 0.0, -2.0, 5.0, 12.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, -1.0, -2.0, 7.0, 11.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 1.0, -1.0, 5.0, 10.0, 9.0, -2.0, 12.0, -4.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 2.0, -6.0, 6.0, 13.0, 11.0, -10.0, 1.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -1.0, 12.0, 3.0, 1.0, -1.0, 5.0, 10.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -1.0, 12.0, 3.0, 4.0, -7.0, 5.0, 13.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 5.0, -7.0, 6.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 3.0, -2.0, 1.0, 13.0, 1.0, -2.0, 3.0, 13.0, 1.0, -2.0, 3.0, 13.0, 1.0, -2.0, 3.0, 13.0, 3.0, -7.0, 8.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 13.0, -7.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, 9.0, 2.0, 12.0, -8.0, 11.0, 11.0, 12.0, -19.0, -2.0, -5.0, 12.0, 10.0, 12.0, 12.0, 321.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -7.0, 11.0, 0.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -4.0, 12.0, 9.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, 12.0, 12.0, 322.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -3.0, 12.0, 8.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, 9.0, 13.0, -18.0, 11.0, 11.0, 4.0, 11.0, -11.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -3.0, 13.0, -6.0, 11.0, -4.0, 1.0, 12.0, 6.0, -2.0, 11.0, -5.0, 11.0, -4.0, 2.0, 12.0, 5.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 11.0, -5.0, 11.0, -2.0, -5.0, 12.0, 10.0, -2.0, 13.0, -5.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49338846985177254, "mean_inference_ms": 2.030412513224775, "mean_action_processing_ms": 0.12161128239437638, "mean_env_wait_ms": 0.2880448736455232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 894240, "agent_timesteps_total": 894159, "timers": {"learn_time_ms": 2.045, "learn_throughput": 15648.746, "update_time_ms": 5.663}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.741551399230957, "min_q": 1.1236698627471924, "max_q": 8.705808639526367, "mean_td_error": 0.211850106716156, "model": {}}}, "num_steps_sampled": 894240, "num_agent_steps_sampled": 894159, "num_steps_trained": 264672, "num_agent_steps_trained": 264672, "last_target_update_ts": 894240, "num_target_updates": 1655}, "done": false, "episodes_total": 17523, "training_iteration": 286, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-14", "timestamp": 1626860054, "time_this_iter_s": 1.0268471240997314, "time_total_s": 324.84698390960693, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 324.84698390960693, "timesteps_since_restore": 0, "iterations_since_restore": 286, "perf": {"cpu_util_percent": 44.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 10.0, -5.0, 13.0, -3.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 10.0, -4.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 12.0, -5.0, -5.0, 13.0, -7.0, 14.0, 6.0, 2.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, -5.0, 13.0, 11.0, -5.0, 13.0, -4.0, -13.0, 14.0, 8.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 10.0, -20.0, 13.0, 12.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, 7.0, 14.0, -12.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 9.0, -15.0, 13.0, 8.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 11.0, -10.0, 13.0, 1.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, 7.0, 14.0, -12.0, 6.0, 10.0, -2.0, 13.0, -6.0, -7.0, 14.0, 2.0, 6.0, 9.0, -15.0, 13.0, 8.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 0.0, 8.0, 11.0, -5.0, 13.0, -4.0, -5.0, 14.0, -5.0, 11.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 10.0, -15.0, 8.0, 12.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, -1.0, -2.0, 7.0, 11.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 1.0, -1.0, 5.0, 10.0, 9.0, -2.0, 12.0, -4.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 2.0, -6.0, 6.0, 13.0, 11.0, -10.0, 1.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -1.0, 12.0, 3.0, 1.0, -1.0, 5.0, 10.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -1.0, 12.0, 3.0, 4.0, -7.0, 5.0, 13.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 5.0, -7.0, 6.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 3.0, -2.0, 1.0, 13.0, 1.0, -2.0, 3.0, 13.0, 1.0, -2.0, 3.0, 13.0, 1.0, -2.0, 3.0, 13.0, 3.0, -7.0, 8.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0, 6.0, -7.0, 5.0, 11.0, 1.0, -2.0, 3.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934339437093202, "mean_inference_ms": 2.0305604415318492, "mean_action_processing_ms": 0.12161737725718186, "mean_env_wait_ms": 0.28806970108435276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 897480, "agent_timesteps_total": 897399, "timers": {"learn_time_ms": 1.95, "learn_throughput": 16412.851, "update_time_ms": 5.414}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.743808746337891, "min_q": 0.8804987072944641, "max_q": 9.661540985107422, "mean_td_error": -41.195404052734375, "model": {}}}, "num_steps_sampled": 897480, "num_agent_steps_sampled": 897399, "num_steps_trained": 265632, "num_agent_steps_trained": 265632, "last_target_update_ts": 897480, "num_target_updates": 1661}, "done": false, "episodes_total": 17577, "training_iteration": 287, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-15", "timestamp": 1626860055, "time_this_iter_s": 1.1770505905151367, "time_total_s": 326.02403450012207, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 326.02403450012207, "timesteps_since_restore": 0, "iterations_since_restore": 287, "perf": {"cpu_util_percent": 49.85, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 14.0, -3.0, -1.0, -1.0, 13.0, 11.0, -8.0, 6.0, -3.0, 11.0, 1.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, -3.0, 14.0, 9.0, -5.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 11.0, 12.0, 4.0, -12.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 11.0, 12.0, -2.0, -6.0, 1.0, 9.0, 9.0, -4.0, 6.0, -3.0, 0.0, 12.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 6.0, -3.0, 11.0, 1.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, -9.0, 14.0, -3.0, 13.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 5.0, 12.0, 3.0, -5.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, -1.0, 9.0, 9.0, -2.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 14.0, 13.0, 9.0, -21.0, 7.0, -3.0, 11.0, 0.0, 4.0, 9.0, 11.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, -3.0, 12.0, 0.0, 6.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, -4.0, 14.0, 9.0, -4.0, 6.0, -3.0, 11.0, 1.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, -9.0, 14.0, -3.0, 13.0, -3.0, 14.0, 9.0, -5.0, 6.0, -3.0, 11.0, 1.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 6.0, -2.0, 11.0, 0.0, -9.0, 14.0, -3.0, 13.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 12.0, 6.0, -12.0, 1.0, 9.0, 9.0, -4.0, 6.0, -3.0, 11.0, 1.0, -7.0, 14.0, 2.0, 6.0, 11.0, -10.0, 13.0, 1.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, 7.0, 14.0, -12.0, 6.0, 10.0, -2.0, 13.0, -6.0, -7.0, 14.0, 2.0, 6.0, 9.0, -15.0, 13.0, 8.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 0.0, 8.0, 11.0, -5.0, 13.0, -4.0, -5.0, 14.0, -5.0, 11.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0, 10.0, -15.0, 8.0, 12.0, -7.0, 14.0, 2.0, 6.0, 11.0, -5.0, 13.0, -4.0, -7.0, 14.0, 2.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49043988569271235, "mean_inference_ms": 2.02235361963062, "mean_action_processing_ms": 0.12095720623314833, "mean_env_wait_ms": 0.28661682019506224, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 900720, "agent_timesteps_total": 900639, "timers": {"learn_time_ms": 1.841, "learn_throughput": 17378.513, "update_time_ms": 4.148}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.858623743057251, "min_q": 0.7942614555358887, "max_q": 8.60201358795166, "mean_td_error": -9.813748359680176, "model": {}}}, "num_steps_sampled": 900720, "num_agent_steps_sampled": 900639, "num_steps_trained": 266592, "num_agent_steps_trained": 266592, "last_target_update_ts": 900720, "num_target_updates": 1667}, "done": false, "episodes_total": 17658, "training_iteration": 288, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-16", "timestamp": 1626860056, "time_this_iter_s": 1.0976793766021729, "time_total_s": 327.12171387672424, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e6a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 327.12171387672424, "timesteps_since_restore": 0, "iterations_since_restore": 288, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 10.0, -9.0, 2.0, 12.0, 7.0, 13.0, -7.0, 2.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -2.0, -8.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 2.0, -8.0, 9.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -14.0, 3.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -11.0, 11.0, 1.0, 12.0, 13.0, -5.0, -5.0, 12.0, -16.0, 7.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 4.0, 10.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 7.0, 13.0, -7.0, 2.0, 10.0, -17.0, 10.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -11.0, 0.0, 12.0, 12.0, 12.0, -4.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -16.0, 5.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -7.0, 5.0, 3.0, 7.0, -3.0, 11.0, 0.0, -9.0, 14.0, -3.0, 13.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 5.0, 12.0, 3.0, -5.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, -1.0, 9.0, 9.0, -2.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 14.0, 13.0, 9.0, -21.0, 7.0, -3.0, 11.0, 0.0, 4.0, 9.0, 11.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, -3.0, 12.0, 0.0, 6.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, -4.0, 14.0, 9.0, -4.0, 6.0, -3.0, 11.0, 1.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, -9.0, 14.0, -3.0, 13.0, -3.0, 14.0, 9.0, -5.0, 6.0, -3.0, 11.0, 1.0, 9.0, 9.0, 6.0, -9.0, 1.0, 9.0, 9.0, -4.0, 6.0, -2.0, 11.0, 0.0, -9.0, 14.0, -3.0, 13.0, 1.0, 9.0, 9.0, -4.0, 7.0, -3.0, 11.0, 0.0, 9.0, 12.0, 6.0, -12.0, 1.0, 9.0, 9.0, -4.0, 6.0, -3.0, 11.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4878258515504437, "mean_inference_ms": 2.016738448436515, "mean_action_processing_ms": 0.12056495735016885, "mean_env_wait_ms": 0.2853256767079136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 903960, "agent_timesteps_total": 903879, "timers": {"learn_time_ms": 1.977, "learn_throughput": 16186.802, "update_time_ms": 4.442}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.271485328674316, "min_q": 0.6404047012329102, "max_q": 9.3637113571167, "mean_td_error": -10.534381866455078, "model": {}}}, "num_steps_sampled": 903960, "num_agent_steps_sampled": 903879, "num_steps_trained": 267552, "num_agent_steps_trained": 267552, "last_target_update_ts": 903960, "num_target_updates": 1673}, "done": false, "episodes_total": 17712, "training_iteration": 289, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-17", "timestamp": 1626860057, "time_this_iter_s": 1.1305687427520752, "time_total_s": 328.2522826194763, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 328.2522826194763, "timesteps_since_restore": 0, "iterations_since_restore": 289, "perf": {"cpu_util_percent": 51.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 12.0, 12.0, -5.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -5.0, 12.0, -5.0, 10.0, -14.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 2.0, 12.0, 5.0, 11.0, -4.0, 7.0, 1.0, -3.0, -1.0, 13.0, 6.0, 12.0, -11.0, 10.0, 4.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 2.0, 12.0, 5.0, 11.0, -9.0, 12.0, 1.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 11.0, -15.0, 12.0, 7.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -19.0, 12.0, 9.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, -5.0, 7.0, 7.0, 6.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 7.0, 5.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, 12.0, 13.0, -2.0, -8.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 2.0, -8.0, 9.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -14.0, 3.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -11.0, 11.0, 1.0, 12.0, 13.0, -5.0, -5.0, 12.0, -16.0, 7.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 4.0, 10.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 7.0, 13.0, -7.0, 2.0, 10.0, -17.0, 10.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -11.0, 0.0, 12.0, 12.0, 12.0, -4.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -16.0, 5.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -13.0, 2.0, 12.0, 12.0, 13.0, -5.0, -5.0, 14.0, -7.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4933810919267281, "mean_inference_ms": 2.030234592852749, "mean_action_processing_ms": 0.121598970698971, "mean_env_wait_ms": 0.2880126057909258, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 907200, "agent_timesteps_total": 907119, "timers": {"learn_time_ms": 1.869, "learn_throughput": 17122.447, "update_time_ms": 4.746}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.307249069213867, "min_q": 0.6553403735160828, "max_q": 9.20699691772461, "mean_td_error": -10.481245040893555, "model": {}}}, "num_steps_sampled": 907200, "num_agent_steps_sampled": 907119, "num_steps_trained": 268512, "num_agent_steps_trained": 268512, "last_target_update_ts": 907200, "num_target_updates": 1679}, "done": false, "episodes_total": 17766, "training_iteration": 290, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-18", "timestamp": 1626860058, "time_this_iter_s": 1.133181095123291, "time_total_s": 329.3854637145996, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984daa60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 329.3854637145996, "timesteps_since_restore": 0, "iterations_since_restore": 290, "perf": {"cpu_util_percent": 50.9, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 4.0, 5.0, 10.0, -4.0, -9.0, 13.0, 8.0, 3.0, 10.0, 14.0, -3.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 11.0, 14.0, -5.0, -5.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 11.0, 14.0, -6.0, -4.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, 11.0, -19.0, 7.0, 8.0, -5.0, 5.0, -7.0, 13.0, 3.0, 6.0, 11.0, 13.0, -4.0, -5.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, 6.0, -2.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 9.0, 7.0, 10.0, -11.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -3.0, 7.0, 12.0, -1.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 11.0, 14.0, -8.0, -2.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 13.0, 12.0, -19.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -4.0, 12.0, 4.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -3.0, 7.0, 12.0, -1.0, 11.0, 14.0, -5.0, -5.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 11.0, 14.0, 9.0, -19.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 10.0, 14.0, -3.0, -6.0, 9.0, 8.0, -12.0, 10.0, -14.0, 6.0, 12.0, 11.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, 13.0, -19.0, 12.0, 9.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, -5.0, 7.0, 7.0, 6.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 7.0, 5.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0, -4.0, 0.0, 12.0, 7.0, 13.0, -10.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4904164850740682, "mean_inference_ms": 2.022147609850248, "mean_action_processing_ms": 0.12093909537403562, "mean_env_wait_ms": 0.28660165966838497, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 910440, "agent_timesteps_total": 910359, "timers": {"learn_time_ms": 1.962, "learn_throughput": 16310.729, "update_time_ms": 5.097}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.422191619873047, "min_q": 1.4101040363311768, "max_q": 9.140033721923828, "mean_td_error": 0.9937945604324341, "model": {}}}, "num_steps_sampled": 910440, "num_agent_steps_sampled": 910359, "num_steps_trained": 269472, "num_agent_steps_trained": 269472, "last_target_update_ts": 910440, "num_target_updates": 1685}, "done": false, "episodes_total": 17847, "training_iteration": 291, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-20", "timestamp": 1626860060, "time_this_iter_s": 1.1309819221496582, "time_total_s": 330.51644563674927, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985059d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 330.51644563674927, "timesteps_since_restore": 0, "iterations_since_restore": 291, "perf": {"cpu_util_percent": 50.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 89.36, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 22.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 14.0, 11.0, -10.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, -17.0, 14.0, 7.0, 11.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, -12.0, 14.0, 10.0, 3.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 2.0, 14.0, 6.0, -7.0, -19.0, 14.0, 7.0, 13.0, 7.0, 14.0, 8.0, -14.0, 315.0, 14.0, 11.0, 13.0, 4.0, 14.0, 11.0, -14.0, 315.0, 14.0, 11.0, 13.0, 3.0, 14.0, 9.0, -11.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 12.0, 14.0, 9.0, -20.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 6.0, 7.0, -5.0, 7.0, 9.0, 14.0, 11.0, -19.0, -15.0, 14.0, 4.0, 12.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, -4.0, 14.0, 11.0, -6.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 1.0, 14.0, 11.0, -11.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 12.0, 12.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 316.0, 14.0, 10.0, 13.0, 9.0, 7.0, 10.0, -11.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -3.0, 7.0, 12.0, -1.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 11.0, 14.0, -8.0, -2.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 13.0, 12.0, -19.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -4.0, 12.0, 4.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -3.0, 7.0, 12.0, -1.0, 11.0, 14.0, -5.0, -5.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 11.0, 14.0, 9.0, -19.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 10.0, 14.0, -3.0, -6.0, 9.0, 8.0, -12.0, 10.0, -14.0, 6.0, 12.0, 11.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0, -9.0, 13.0, 8.0, 3.0, 9.0, 14.0, -2.0, -6.0, 7.0, 8.0, -5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4878518635637867, "mean_inference_ms": 2.0165926359203104, "mean_action_processing_ms": 0.12055138715618384, "mean_env_wait_ms": 0.28533445565812454, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 913680, "agent_timesteps_total": 913599, "timers": {"learn_time_ms": 1.806, "learn_throughput": 17722.255, "update_time_ms": 4.57}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.147413730621338, "min_q": 1.0166102647781372, "max_q": 8.545852661132812, "mean_td_error": 0.9507046341896057, "model": {}}}, "num_steps_sampled": 913680, "num_agent_steps_sampled": 913599, "num_steps_trained": 270432, "num_agent_steps_trained": 270432, "last_target_update_ts": 913680, "num_target_updates": 1691}, "done": false, "episodes_total": 17901, "training_iteration": 292, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-21", "timestamp": 1626860061, "time_this_iter_s": 1.188642978668213, "time_total_s": 331.7050886154175, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985419d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 331.7050886154175, "timesteps_since_restore": 0, "iterations_since_restore": 292, "perf": {"cpu_util_percent": 49.45, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 79.22, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 19.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -2.0, 6.0, 9.0, 11.0, -5.0, -4.0, 13.0, 7.0, 12.0, -12.0, 8.0, 4.0, 1.0, -1.0, 11.0, 2.0, -1.0, 1.0, 13.0, 6.0, 3.0, 9.0, -3.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 2.0, 5.0, -4.0, 12.0, 2.0, -1.0, 1.0, 13.0, 6.0, -9.0, 9.0, 9.0, 7.0, 7.0, -11.0, 12.0, 6.0, -12.0, 11.0, 10.0, 2.0, -1.0, 1.0, 13.0, -1.0, 7.0, -3.0, 12.0, 2.0, -5.0, 6.0, 12.0, 11.0, -5.0, -4.0, 13.0, 5.0, 11.0, -9.0, 8.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, -4.0, -2.0, 8.0, 13.0, 5.0, 2.0, -4.0, 12.0, 2.0, -1.0, 1.0, 13.0, 9.0, -18.0, 13.0, 11.0, 3.0, 8.0, -9.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -5.0, 6.0, 12.0, 5.0, 3.0, -4.0, 11.0, 2.0, -1.0, 1.0, 13.0, -6.0, 12.0, -3.0, 12.0, 2.0, -1.0, 1.0, 13.0, 0.0, 7.0, -3.0, 11.0, -12.0, 12.0, 7.0, 8.0, 11.0, -5.0, -4.0, 13.0, 7.0, -6.0, 2.0, 12.0, 6.0, -12.0, 11.0, 10.0, 1.0, -1.0, 2.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 5.0, 7.0, 4.0, -1.0, 2.0, -1.0, 1.0, 13.0, 8.0, -1.0, -4.0, 12.0, 2.0, -1.0, 1.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, -12.0, 14.0, 10.0, 3.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 2.0, 14.0, 6.0, -7.0, -19.0, 14.0, 7.0, 13.0, 7.0, 14.0, 8.0, -14.0, 315.0, 14.0, 11.0, 13.0, 4.0, 14.0, 11.0, -14.0, 315.0, 14.0, 11.0, 13.0, 3.0, 14.0, 9.0, -11.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 12.0, 14.0, 9.0, -20.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 6.0, 7.0, -5.0, 7.0, 9.0, 14.0, 11.0, -19.0, -15.0, 14.0, 4.0, 12.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, -4.0, 14.0, 11.0, -6.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 1.0, 14.0, 11.0, -11.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 12.0, 12.0, 9.0, 14.0, 11.0, -19.0, 315.0, 14.0, 11.0, 13.0, 9.0, 14.0, 11.0, -19.0, 316.0, 14.0, 10.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.493445968999559, "mean_inference_ms": 2.03029414635717, "mean_action_processing_ms": 0.12161116719574715, "mean_env_wait_ms": 0.2880625717113039, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 915840, "agent_timesteps_total": 915759, "timers": {"learn_time_ms": 2.137, "learn_throughput": 14976.147, "update_time_ms": 5.063}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.183663368225098, "min_q": 0.7199327945709229, "max_q": 9.230767250061035, "mean_td_error": 0.7225379943847656, "model": {}}}, "num_steps_sampled": 915840, "num_agent_steps_sampled": 915759, "num_steps_trained": 271072, "num_agent_steps_trained": 271072, "last_target_update_ts": 915840, "num_target_updates": 1695}, "done": false, "episodes_total": 17955, "training_iteration": 293, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-22", "timestamp": 1626860062, "time_this_iter_s": 1.0293323993682861, "time_total_s": 332.73442101478577, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 332.73442101478577, "timesteps_since_restore": 0, "iterations_since_restore": 293, "perf": {"cpu_util_percent": 43.95, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 106.06, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 26.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 353.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 354.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 356.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 9.0, -1.0, -6.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 13.0, 317.0, 10.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 12.0, 0.0, -6.0, 9.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 13.0, 319.0, 9.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, -16.0, 6.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 12.0, 320.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -13.0, 7.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 6.0, 3.0, 9.0, -3.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 2.0, 5.0, -4.0, 12.0, 2.0, -1.0, 1.0, 13.0, 6.0, -9.0, 9.0, 9.0, 7.0, 7.0, -11.0, 12.0, 6.0, -12.0, 11.0, 10.0, 2.0, -1.0, 1.0, 13.0, -1.0, 7.0, -3.0, 12.0, 2.0, -5.0, 6.0, 12.0, 11.0, -5.0, -4.0, 13.0, 5.0, 11.0, -9.0, 8.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, -4.0, -2.0, 8.0, 13.0, 5.0, 2.0, -4.0, 12.0, 2.0, -1.0, 1.0, 13.0, 9.0, -18.0, 13.0, 11.0, 3.0, 8.0, -9.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -5.0, 6.0, 12.0, 5.0, 3.0, -4.0, 11.0, 2.0, -1.0, 1.0, 13.0, -6.0, 12.0, -3.0, 12.0, 2.0, -1.0, 1.0, 13.0, 0.0, 7.0, -3.0, 11.0, -12.0, 12.0, 7.0, 8.0, 11.0, -5.0, -4.0, 13.0, 7.0, -6.0, 2.0, 12.0, 6.0, -12.0, 11.0, 10.0, 1.0, -1.0, 2.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 11.0, -5.0, -4.0, 13.0, 2.0, -1.0, 1.0, 13.0, 5.0, 7.0, 4.0, -1.0, 2.0, -1.0, 1.0, 13.0, 8.0, -1.0, -4.0, 12.0, 2.0, -1.0, 1.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934528405778895, "mean_inference_ms": 2.030422925367196, "mean_action_processing_ms": 0.12161401971838401, "mean_env_wait_ms": 0.2880945816093445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 919080, "agent_timesteps_total": 918999, "timers": {"learn_time_ms": 1.939, "learn_throughput": 16499.204, "update_time_ms": 4.831}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.702880620956421, "min_q": 1.0576359033584595, "max_q": 8.825207710266113, "mean_td_error": 0.9612850546836853, "model": {}}}, "num_steps_sampled": 919080, "num_agent_steps_sampled": 918999, "num_steps_trained": 272032, "num_agent_steps_trained": 272032, "last_target_update_ts": 919080, "num_target_updates": 1701}, "done": false, "episodes_total": 18009, "training_iteration": 294, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-23", "timestamp": 1626860063, "time_this_iter_s": 1.138401985168457, "time_total_s": 333.8728229999542, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 333.8728229999542, "timesteps_since_restore": 0, "iterations_since_restore": 294, "perf": {"cpu_util_percent": 49.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 106.13, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 26.5325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 352.0, 15.0, 353.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 354.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 15.0, 15.0, 352.0, 15.0, 352.0, 356.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0, 15.0, 352.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-19.0, 14.0, 11.0, 9.0, -3.0, 0.0, 8.0, 10.0, -12.0, 4.0, 11.0, 12.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -6.0, 2.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -19.0, 11.0, 11.0, 12.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, -7.0, 13.0, 13.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, 317.0, 14.0, 11.0, 12.0, -4.0, 0.0, 8.0, 11.0, 317.0, 14.0, 11.0, 12.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 10.0, 12.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, 13.0, 317.0, 11.0, 12.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -10.0, 0.0, 12.0, 13.0, -4.0, 0.0, 8.0, 11.0, 13.0, -6.0, 11.0, -3.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, 317.0, 14.0, 11.0, 12.0, -4.0, 0.0, 8.0, 11.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 13.0, 317.0, 10.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 12.0, 0.0, -6.0, 9.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 13.0, 319.0, 9.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, -16.0, 6.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 12.0, 320.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -13.0, 7.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0, 8.0, -17.0, 11.0, 13.0, 12.0, 316.0, 11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934075312101267, "mean_inference_ms": 2.0302791666734086, "mean_action_processing_ms": 0.12160385145317663, "mean_env_wait_ms": 0.28808467898789725, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 922320, "agent_timesteps_total": 922239, "timers": {"learn_time_ms": 1.952, "learn_throughput": 16393.005, "update_time_ms": 4.555}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.521511077880859, "min_q": 0.7795072197914124, "max_q": 8.7218599319458, "mean_td_error": 1.0774328708648682, "model": {}}}, "num_steps_sampled": 922320, "num_agent_steps_sampled": 922239, "num_steps_trained": 272992, "num_agent_steps_trained": 272992, "last_target_update_ts": 922320, "num_target_updates": 1707}, "done": false, "episodes_total": 18063, "training_iteration": 295, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-24", "timestamp": 1626860064, "time_this_iter_s": 1.1335785388946533, "time_total_s": 335.0064015388489, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985058c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 335.0064015388489, "timesteps_since_restore": 0, "iterations_since_restore": 295, "perf": {"cpu_util_percent": 50.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 28.53, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 7.1325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 12.0, -8.0, 9.0, -9.0, 4.0, 11.0, 14.0, -8.0, -4.0, 13.0, -1.0, 12.0, 13.0, -9.0, 14.0, -8.0, -4.0, 13.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, 3.0, -8.0, 13.0, 12.0, -1.0, 7.0, -3.0, 13.0, -3.0, -6.0, 11.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, -9.0, 13.0, 12.0, -1.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -4.0, 12.0, -5.0, 11.0, -2.0, -6.0, 12.0, 13.0, -20.0, 11.0, 11.0, 12.0, -1.0, 12.0, -8.0, 12.0, -2.0, -6.0, 11.0, 13.0, -8.0, -3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 12.0, -2.0, -1.0, 6.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 6.0, -2.0, -1.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 12.0, -8.0, 13.0, -2.0, -7.0, 11.0, 7.0, -8.0, 3.0, 13.0, 5.0, -1.0, 12.0, -1.0, 12.0, -2.0, -1.0, 6.0, 7.0, -8.0, 3.0, 13.0, 8.0, 13.0, 10.0, -16.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -11.0, 7.0, 7.0, 11.0, 10.0, -18.0, 12.0, 7.0, 6.0, -11.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 13.0, -7.0, -4.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -8.0, 12.0, -1.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 13.0, -2.0, -7.0, 11.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, -1.0, 12.0, 13.0, -9.0, 11.0, -2.0, -6.0, 12.0, 7.0, -10.0, 5.0, 13.0, 13.0, 13.0, 12.0, 316.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 13.0, 13.0, 317.0, 9.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 12.0, -8.0, 11.0, -2.0, -6.0, 12.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, 13.0, 317.0, 11.0, 12.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, -10.0, 0.0, 12.0, 13.0, -4.0, 0.0, 8.0, 11.0, 13.0, -6.0, 11.0, -3.0, -4.0, 0.0, 8.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 0.0, 8.0, 11.0, 317.0, 14.0, 11.0, 12.0, -4.0, 0.0, 8.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4904480853855135, "mean_inference_ms": 2.02207859020055, "mean_action_processing_ms": 0.12093187530424658, "mean_env_wait_ms": 0.2866608620105744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 925560, "agent_timesteps_total": 925479, "timers": {"learn_time_ms": 1.907, "learn_throughput": 16780.992, "update_time_ms": 4.325}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.673361301422119, "min_q": 0.7600642442703247, "max_q": 9.307570457458496, "mean_td_error": 0.7432771921157837, "model": {}}}, "num_steps_sampled": 925560, "num_agent_steps_sampled": 925479, "num_steps_trained": 273952, "num_agent_steps_trained": 273952, "last_target_update_ts": 925560, "num_target_updates": 1713}, "done": false, "episodes_total": 18144, "training_iteration": 296, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-25", "timestamp": 1626860065, "time_this_iter_s": 1.1339316368103027, "time_total_s": 336.1403331756592, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985051e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 336.1403331756592, "timesteps_since_restore": 0, "iterations_since_restore": 296, "perf": {"cpu_util_percent": 50.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -7.0, 14.0, 11.0, -3.0, 9.0, -8.0, 13.0, 1.0, -9.0, 14.0, 11.0, -1.0, 4.0, -8.0, 6.0, 13.0, -2.0, 14.0, 6.0, -3.0, 8.0, -7.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 0.0, -6.0, 13.0, 8.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -17.0, 14.0, 6.0, 12.0, 14.0, -15.0, 13.0, 3.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, 0.0, 0.0, 5.0, 10.0, 7.0, -16.0, 12.0, 12.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -8.0, 14.0, 11.0, -2.0, 9.0, -8.0, 13.0, 1.0, 1.0, 14.0, 6.0, -6.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 7.0, -16.0, 12.0, 12.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, 12.0, -2.0, -1.0, 6.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 6.0, -2.0, -1.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 12.0, -8.0, 13.0, -2.0, -7.0, 11.0, 7.0, -8.0, 3.0, 13.0, 5.0, -1.0, 12.0, -1.0, 12.0, -2.0, -1.0, 6.0, 7.0, -8.0, 3.0, 13.0, 8.0, 13.0, 10.0, -16.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -11.0, 7.0, 7.0, 11.0, 10.0, -18.0, 12.0, 7.0, 6.0, -11.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 13.0, -7.0, -4.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -8.0, 12.0, -1.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 13.0, -2.0, -7.0, 11.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, -1.0, 12.0, 13.0, -9.0, 11.0, -2.0, -6.0, 12.0, 7.0, -10.0, 5.0, 13.0, 13.0, 13.0, 12.0, 316.0, 11.0, -2.0, -6.0, 12.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 7.0, -3.0, 13.0, 13.0, 317.0, 9.0, 7.0, -8.0, 3.0, 13.0, 12.0, -1.0, 12.0, -8.0, 11.0, -2.0, -6.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48786789377572615, "mean_inference_ms": 2.0165030840147127, "mean_action_processing_ms": 0.12053574007665381, "mean_env_wait_ms": 0.28538421668070335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 928800, "agent_timesteps_total": 928719, "timers": {"learn_time_ms": 1.973, "learn_throughput": 16222.41, "update_time_ms": 4.499}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.256336212158203, "min_q": 0.6596678495407104, "max_q": 9.312776565551758, "mean_td_error": -9.941194534301758, "model": {}}}, "num_steps_sampled": 928800, "num_agent_steps_sampled": 928719, "num_steps_trained": 274912, "num_agent_steps_trained": 274912, "last_target_update_ts": 928800, "num_target_updates": 1719}, "done": false, "episodes_total": 18198, "training_iteration": 297, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-27", "timestamp": 1626860067, "time_this_iter_s": 1.1761071681976318, "time_total_s": 337.3164403438568, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dabf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 337.3164403438568, "timesteps_since_restore": 0, "iterations_since_restore": 297, "perf": {"cpu_util_percent": 49.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, 12.0, 13.0, 315.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, 13.0, -9.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, 13.0, -9.0, 14.0, 14.0, -21.0, 8.0, 14.0, -4.0, 13.0, -8.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, 13.0, -9.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, 10.0, 0.0, -9.0, 4.0, 14.0, -16.0, 13.0, 14.0, -6.0, 2.0, 5.0, 14.0, 8.0, -18.0, 11.0, 14.0, -5.0, 9.0, -3.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, -6.0, 12.0, 3.0, 6.0, 4.0, 14.0, -16.0, 13.0, 9.0, -2.0, 9.0, -1.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 14.0, 14.0, 1.0, -14.0, 14.0, -3.0, -2.0, 6.0, 3.0, 14.0, -15.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 14.0, 14.0, -8.0, -5.0, 14.0, -3.0, -2.0, 6.0, -2.0, 14.0, 6.0, -3.0, 8.0, -7.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 0.0, -6.0, 13.0, 8.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -17.0, 14.0, 6.0, 12.0, 14.0, -15.0, 13.0, 3.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, 0.0, 0.0, 5.0, 10.0, 7.0, -16.0, 12.0, 12.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -8.0, 14.0, 11.0, -2.0, 9.0, -8.0, 13.0, 1.0, 1.0, 14.0, 6.0, -6.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0, -2.0, 14.0, 6.0, -3.0, 7.0, -16.0, 12.0, 12.0, -2.0, 14.0, 6.0, -3.0, 9.0, -8.0, 13.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49338328528344816, "mean_inference_ms": 2.0299862066091316, "mean_action_processing_ms": 0.12157246885549287, "mean_env_wait_ms": 0.2880577947026551, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 932040, "agent_timesteps_total": 931959, "timers": {"learn_time_ms": 1.854, "learn_throughput": 17258.513, "update_time_ms": 4.313}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.452517509460449, "min_q": 0.7168145775794983, "max_q": 8.908995628356934, "mean_td_error": 0.6166816353797913, "model": {}}}, "num_steps_sampled": 932040, "num_agent_steps_sampled": 931959, "num_steps_trained": 275872, "num_agent_steps_trained": 275872, "last_target_update_ts": 932040, "num_target_updates": 1725}, "done": false, "episodes_total": 18252, "training_iteration": 298, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-28", "timestamp": 1626860068, "time_this_iter_s": 1.087843894958496, "time_total_s": 338.4042842388153, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e6a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 338.4042842388153, "timesteps_since_restore": 0, "iterations_since_restore": 298, "perf": {"cpu_util_percent": 51.150000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.93, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 7.9825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 3.0, -12.0, 12.0, 13.0, 13.0, 11.0, 317.0, -3.0, 6.0, 6.0, 6.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -3.0, 12.0, 2.0, 4.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 14.0, -3.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, 11.0, 317.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 14.0, 11.0, 315.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, 2.0, 6.0, -4.0, 11.0, 12.0, 1.0, -11.0, 13.0, 13.0, 8.0, -2.0, -4.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -2.0, 12.0, 11.0, -6.0, 11.0, 3.0, -12.0, 13.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 12.0, 14.0, -3.0, -8.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 11.0, 3.0, -12.0, 13.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 12.0, 14.0, 11.0, 315.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 11.0, 4.0, -13.0, 13.0, 13.0, 13.0, -3.0, -8.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 12.0, 14.0, -2.0, -9.0, 12.0, 8.0, -2.0, -3.0, 4.0, 6.0, 6.0, -1.0, 13.0, 13.0, -2.0, -9.0, -7.0, 6.0, 3.0, 13.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 11.0, 3.0, -12.0, 13.0, 13.0, 13.0, -2.0, -9.0, -2.0, 12.0, 11.0, -6.0, 12.0, 9.0, -4.0, -2.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, 11.0, 318.0, -10.0, 1.0, 11.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, -6.0, 12.0, 3.0, 6.0, 4.0, 14.0, -16.0, 13.0, 9.0, -2.0, 9.0, -1.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 14.0, 14.0, 1.0, -14.0, 14.0, -3.0, -2.0, 6.0, 3.0, 14.0, -15.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 4.0, 14.0, -16.0, 13.0, 14.0, -3.0, -2.0, 6.0, 14.0, 14.0, -8.0, -5.0, 14.0, -3.0, -2.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4903744349429715, "mean_inference_ms": 2.0216868466865585, "mean_action_processing_ms": 0.12089340066322542, "mean_env_wait_ms": 0.2865912444132397, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 935280, "agent_timesteps_total": 935199, "timers": {"learn_time_ms": 1.841, "learn_throughput": 17386.392, "update_time_ms": 4.3}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.042078018188477, "min_q": 0.7951986789703369, "max_q": 8.487269401550293, "mean_td_error": 0.9038746356964111, "model": {}}}, "num_steps_sampled": 935280, "num_agent_steps_sampled": 935199, "num_steps_trained": 276832, "num_agent_steps_trained": 276832, "last_target_update_ts": 935280, "num_target_updates": 1731}, "done": false, "episodes_total": 18333, "training_iteration": 299, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-29", "timestamp": 1626860069, "time_this_iter_s": 1.1090245246887207, "time_total_s": 339.513308763504, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dae18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 339.513308763504, "timesteps_since_restore": 0, "iterations_since_restore": 299, "perf": {"cpu_util_percent": 51.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.92, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"learned": -13.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 7.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -2.0, -9.0, 13.0, 13.0, -1.0, -10.0, 13.0, 12.0, -3.0, -6.0, 12.0, 13.0, -1.0, -10.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, -2.0, -4.0, 11.0, 10.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 14.0, -2.0, -10.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 12.0, -5.0, -5.0, 13.0, 9.0, -12.0, 7.0, 11.0, 13.0, -2.0, -9.0, 13.0, 14.0, 12.0, 315.0, 12.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 14.0, -3.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, 11.0, 317.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 14.0, 11.0, 315.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, 2.0, 6.0, -4.0, 11.0, 12.0, 1.0, -11.0, 13.0, 13.0, 8.0, -2.0, -4.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -2.0, 12.0, 11.0, -6.0, 11.0, 3.0, -12.0, 13.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 12.0, 14.0, -3.0, -8.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 11.0, 3.0, -12.0, 13.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 12.0, 14.0, 11.0, 315.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 11.0, 4.0, -13.0, 13.0, 13.0, 13.0, -3.0, -8.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 12.0, 14.0, -2.0, -9.0, 12.0, 8.0, -2.0, -3.0, 4.0, 6.0, 6.0, -1.0, 13.0, 13.0, -2.0, -9.0, -7.0, 6.0, 3.0, 13.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 11.0, 3.0, -12.0, 13.0, 13.0, 13.0, -2.0, -9.0, -2.0, 12.0, 11.0, -6.0, 12.0, 9.0, -4.0, -2.0, 13.0, 13.0, -2.0, -9.0, -4.0, 1.0, 13.0, 5.0, 12.0, 3.0, -12.0, 12.0, 13.0, 13.0, 11.0, 318.0, -10.0, 1.0, 11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49318183403757593, "mean_inference_ms": 2.0295573865715464, "mean_action_processing_ms": 0.12158566036602288, "mean_env_wait_ms": 0.28783899963852316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 937440, "agent_timesteps_total": 937359, "timers": {"learn_time_ms": 2.114, "learn_throughput": 15135.232, "update_time_ms": 4.76}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.879054069519043, "min_q": 0.8655110597610474, "max_q": 8.973506927490234, "mean_td_error": 0.7329831123352051, "model": {}}}, "num_steps_sampled": 937440, "num_agent_steps_sampled": 937359, "num_steps_trained": 277472, "num_agent_steps_trained": 277472, "last_target_update_ts": 937440, "num_target_updates": 1735}, "done": false, "episodes_total": 18360, "training_iteration": 300, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-30", "timestamp": 1626860070, "time_this_iter_s": 0.9954590797424316, "time_total_s": 340.50876784324646, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 340.50876784324646, "timesteps_since_restore": 0, "iterations_since_restore": 300, "perf": {"cpu_util_percent": 38.7, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.12, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 6.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 13.0, -5.0, -5.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, 316.0, 10.0, 12.0, 5.0, 11.0, -13.0, 12.0, -3.0, -4.0, 11.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, -5.0, -4.0, 13.0, 11.0, 14.0, -4.0, -6.0, 11.0, 7.0, 11.0, -15.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 9.0, 0.0, -6.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -5.0, -5.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, -5.0, -4.0, 13.0, 11.0, 14.0, -4.0, -6.0, 11.0, 13.0, -18.0, 8.0, 12.0, -5.0, -4.0, 13.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 12.0, -6.0, -3.0, 12.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 13.0, -5.0, -4.0, 11.0, 14.0, 1.0, -6.0, 6.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 13.0, 317.0, 10.0, 12.0, 1.0, -5.0, 8.0, 11.0, 13.0, -5.0, 11.0, -4.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -7.0, -3.0, 11.0, 5.0, 12.0, -14.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 14.0, -2.0, -10.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 12.0, -5.0, -5.0, 13.0, 9.0, -12.0, 7.0, 11.0, 13.0, -2.0, -9.0, 13.0, 14.0, 12.0, 315.0, 12.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0, 13.0, -2.0, -9.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49394056951406945, "mean_inference_ms": 2.030659378420976, "mean_action_processing_ms": 0.12166068768583954, "mean_env_wait_ms": 0.28829470787454375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 940680, "agent_timesteps_total": 940599, "timers": {"learn_time_ms": 1.869, "learn_throughput": 17119.171, "update_time_ms": 4.341}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.581568241119385, "min_q": 0.863237738609314, "max_q": 8.901991844177246, "mean_td_error": 0.1690511554479599, "model": {}}}, "num_steps_sampled": 940680, "num_agent_steps_sampled": 940599, "num_steps_trained": 278432, "num_agent_steps_trained": 278432, "last_target_update_ts": 940680, "num_target_updates": 1741}, "done": false, "episodes_total": 18441, "training_iteration": 301, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-31", "timestamp": 1626860071, "time_this_iter_s": 1.1484804153442383, "time_total_s": 341.6572482585907, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 341.6572482585907, "timesteps_since_restore": 0, "iterations_since_restore": 301, "perf": {"cpu_util_percent": 51.25, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -14.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 12.0, 7.0, -11.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 3.0, -9.0, 10.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 2.0, 3.0, 12.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 8.0, 3.0, -4.0, 8.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 0.0, 4.0, 13.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 12.0, 4.0, -9.0, 8.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 3.0, -9.0, 10.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 4.0, 12.0, -5.0, 4.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 1.0, 7.0, 9.0, -2.0, 11.0, 1.0, 9.0, -6.0, 4.0, 5.0, 8.0, -2.0, 11.0, 8.0, -10.0, 6.0, 11.0, 10.0, 4.0, -10.0, 11.0, 2.0, -4.0, 6.0, 4.0, 5.0, 8.0, -2.0, 9.0, 4.0, -9.0, 11.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 12.0, -6.0, -3.0, 12.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 13.0, -5.0, -4.0, 11.0, 14.0, 1.0, -6.0, 6.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0, 13.0, 317.0, 10.0, 12.0, 1.0, -5.0, 8.0, 11.0, 13.0, -5.0, 11.0, -4.0, 5.0, 11.0, -13.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -7.0, -3.0, 11.0, 5.0, 12.0, -14.0, 12.0, 0.0, -4.0, 8.0, 11.0, 14.0, -4.0, -6.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48781382910490945, "mean_inference_ms": 2.0162399849918278, "mean_action_processing_ms": 0.12050948976067176, "mean_env_wait_ms": 0.28531956178223816, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 943920, "agent_timesteps_total": 943839, "timers": {"learn_time_ms": 2.025, "learn_throughput": 15799.801, "update_time_ms": 4.544}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.217125415802002, "min_q": 1.2132749557495117, "max_q": 9.590629577636719, "mean_td_error": 0.17378132045269012, "model": {}}}, "num_steps_sampled": 943920, "num_agent_steps_sampled": 943839, "num_steps_trained": 279392, "num_agent_steps_trained": 279392, "last_target_update_ts": 943920, "num_target_updates": 1747}, "done": false, "episodes_total": 18495, "training_iteration": 302, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-32", "timestamp": 1626860072, "time_this_iter_s": 1.2104201316833496, "time_total_s": 342.86766839027405, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 342.86766839027405, "timesteps_since_restore": 0, "iterations_since_restore": 302, "perf": {"cpu_util_percent": 48.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -3.0, 9.0, 10.0, -1.0, 14.0, 11.0, 12.0, -22.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -2.0, 2.0, 7.0, 8.0, 7.0, -1.0, 9.0, 0.0, 5.0, 6.0, -5.0, 9.0, 7.0, -4.0, 9.0, 3.0, -8.0, 14.0, 2.0, 7.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 7.0, 12.0, 9.0, -13.0, -1.0, 11.0, 6.0, -1.0, 6.0, -1.0, 9.0, 1.0, -1.0, 14.0, 2.0, 0.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -3.0, 9.0, 9.0, 0.0, 9.0, 12.0, 7.0, -13.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 8.0, 13.0, 8.0, -14.0, -1.0, 11.0, 2.0, 3.0, 9.0, -4.0, 11.0, -1.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 9.0, -1.0, 10.0, -3.0, -1.0, 11.0, 6.0, -1.0, 9.0, 12.0, 8.0, -14.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -3.0, 11.0, 8.0, -1.0, 9.0, 9.0, 9.0, -12.0, -1.0, 11.0, 6.0, -1.0, 6.0, -1.0, 9.0, 1.0, -1.0, 1.0, 7.0, 8.0, 6.0, -1.0, 9.0, 1.0, -3.0, 14.0, 4.0, 0.0, 3.0, -1.0, 9.0, 4.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, 4.0, 5.0, 8.0, -2.0, 11.0, 3.0, -9.0, 10.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 2.0, 3.0, 12.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 8.0, 3.0, -4.0, 8.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 0.0, 4.0, 13.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 12.0, 4.0, -9.0, 8.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 3.0, -9.0, 10.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 4.0, 12.0, -5.0, 4.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 1.0, 7.0, 9.0, -2.0, 11.0, 1.0, 9.0, -6.0, 4.0, 5.0, 8.0, -2.0, 11.0, 8.0, -10.0, 6.0, 11.0, 10.0, 4.0, -10.0, 11.0, 2.0, -4.0, 6.0, 4.0, 5.0, 8.0, -2.0, 9.0, 4.0, -9.0, 11.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0, 4.0, 5.0, 8.0, -2.0, 11.0, 1.0, -4.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4933490058424036, "mean_inference_ms": 2.029770249041933, "mean_action_processing_ms": 0.12155772996773619, "mean_env_wait_ms": 0.28800798670698513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 947160, "agent_timesteps_total": 947079, "timers": {"learn_time_ms": 1.951, "learn_throughput": 16399.615, "update_time_ms": 4.782}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.181088447570801, "min_q": 0.6173534393310547, "max_q": 8.904508590698242, "mean_td_error": -10.381414413452148, "model": {}}}, "num_steps_sampled": 947160, "num_agent_steps_sampled": 947079, "num_steps_trained": 280352, "num_agent_steps_trained": 280352, "last_target_update_ts": 947160, "num_target_updates": 1753}, "done": false, "episodes_total": 18549, "training_iteration": 303, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-34", "timestamp": 1626860074, "time_this_iter_s": 1.1664268970489502, "time_total_s": 344.034095287323, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985419d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 344.034095287323, "timesteps_since_restore": 0, "iterations_since_restore": 303, "perf": {"cpu_util_percent": 50.45, "ram_util_percent": 14.3}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 92.74, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 23.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 4.0, -13.0, 11.0, -13.0, 13.0, 12.0, 3.0, 8.0, 12.0, 11.0, -16.0, 11.0, 3.0, -11.0, 12.0, 315.0, 13.0, 12.0, 13.0, 6.0, 13.0, -8.0, 4.0, 13.0, 7.0, -18.0, 13.0, 315.0, 13.0, 12.0, 13.0, 9.0, 9.0, -13.0, 10.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 0.0, 12.0, -5.0, 8.0, 11.0, 13.0, -8.0, -1.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 11.0, -15.0, 12.0, 13.0, 4.0, -13.0, 11.0, 316.0, 13.0, 11.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 9.0, 5.0, -9.0, 10.0, 13.0, 8.0, -19.0, 13.0, -13.0, 13.0, 12.0, 3.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 0.0, -10.0, 12.0, 315.0, 13.0, 12.0, 13.0, 11.0, 14.0, -15.0, 5.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 10.0, 8.0, -10.0, 7.0, 14.0, 8.0, 12.0, -19.0, 315.0, 13.0, 12.0, 13.0, 11.0, 13.0, -14.0, 5.0, 13.0, 3.0, -12.0, 11.0, -2.0, 12.0, 12.0, -7.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 6.0, 13.0, -8.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 9.0, 13.0, -6.0, -1.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 9.0, 10.0, -14.0, 10.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 9.0, 9.0, -14.0, 11.0, 10.0, 4.0, -12.0, 13.0, 315.0, 13.0, 12.0, 13.0, 6.0, 13.0, -8.0, 4.0, 13.0, 8.0, -17.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 0.0, -11.0, 13.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 9.0, -1.0, 10.0, -3.0, -1.0, 11.0, 6.0, -1.0, 9.0, 12.0, 8.0, -14.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -3.0, 11.0, 8.0, -1.0, 9.0, 9.0, 9.0, -12.0, -1.0, 11.0, 6.0, -1.0, 6.0, -1.0, 9.0, 1.0, -1.0, 1.0, 7.0, 8.0, 6.0, -1.0, 9.0, 1.0, -3.0, 14.0, 4.0, 0.0, 3.0, -1.0, 9.0, 4.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0, -1.0, 11.0, 6.0, -1.0, 7.0, -1.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4903341965182826, "mean_inference_ms": 2.0216548669832037, "mean_action_processing_ms": 0.12087857209467368, "mean_env_wait_ms": 0.2865553102381118, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 950400, "agent_timesteps_total": 950319, "timers": {"learn_time_ms": 1.854, "learn_throughput": 17261.62, "update_time_ms": 3.944}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.136407852172852, "min_q": 0.7751691937446594, "max_q": 8.68252182006836, "mean_td_error": 0.16325417160987854, "model": {}}}, "num_steps_sampled": 950400, "num_agent_steps_sampled": 950319, "num_steps_trained": 281312, "num_agent_steps_trained": 281312, "last_target_update_ts": 950400, "num_target_updates": 1759}, "done": false, "episodes_total": 18630, "training_iteration": 304, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-35", "timestamp": 1626860075, "time_this_iter_s": 1.1274478435516357, "time_total_s": 345.16154313087463, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985416a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 345.16154313087463, "timesteps_since_restore": 0, "iterations_since_restore": 304, "perf": {"cpu_util_percent": 50.75, "ram_util_percent": 14.25}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 62.32, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 15.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0, 15.0, 353.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 9.0, 8.0, -12.0, 10.0, 13.0, -7.0, -4.0, 13.0, 8.0, 8.0, -11.0, 10.0, 13.0, -7.0, -4.0, 13.0, 10.0, 9.0, -14.0, 10.0, 13.0, 0.0, -10.0, 12.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 12.0, -7.0, 3.0, 13.0, -7.0, -4.0, 13.0, 3.0, 10.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 9.0, 10.0, -14.0, 10.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 2.0, 11.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 9.0, -11.0, 10.0, 13.0, -5.0, -6.0, 13.0, 7.0, 6.0, -7.0, 9.0, 6.0, 9.0, -6.0, 6.0, 8.0, 14.0, -7.0, 0.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 6.0, 14.0, -11.0, 6.0, 7.0, 10.0, -11.0, 9.0, 12.0, 4.0, -11.0, 10.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 8.0, 12.0, -7.0, 2.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -6.0, -4.0, 12.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 0.0, -10.0, 12.0, 315.0, 13.0, 12.0, 13.0, 11.0, 14.0, -15.0, 5.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 10.0, 8.0, -10.0, 7.0, 14.0, 8.0, 12.0, -19.0, 315.0, 13.0, 12.0, 13.0, 11.0, 13.0, -14.0, 5.0, 13.0, 3.0, -12.0, 11.0, -2.0, 12.0, 12.0, -7.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 6.0, 13.0, -8.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 9.0, 13.0, -6.0, -1.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 9.0, 10.0, -14.0, 10.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 9.0, 9.0, -14.0, 11.0, 10.0, 4.0, -12.0, 13.0, 315.0, 13.0, 12.0, 13.0, 6.0, 13.0, -8.0, 4.0, 13.0, 8.0, -17.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 0.0, -11.0, 13.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0, 13.0, 4.0, -13.0, 11.0, 315.0, 13.0, 12.0, 13.0, 7.0, 13.0, -9.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48779610415998403, "mean_inference_ms": 2.0161901698291573, "mean_action_processing_ms": 0.1204896614458319, "mean_env_wait_ms": 0.28528920695339927, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 953640, "agent_timesteps_total": 953559, "timers": {"learn_time_ms": 2.004, "learn_throughput": 15966.896, "update_time_ms": 4.855}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.562375545501709, "min_q": 2.3733327388763428, "max_q": 9.690706253051758, "mean_td_error": 0.3809630870819092, "model": {}}}, "num_steps_sampled": 953640, "num_agent_steps_sampled": 953559, "num_steps_trained": 282272, "num_agent_steps_trained": 282272, "last_target_update_ts": 953640, "num_target_updates": 1765}, "done": false, "episodes_total": 18684, "training_iteration": 305, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-36", "timestamp": 1626860076, "time_this_iter_s": 1.1693787574768066, "time_total_s": 346.33092188835144, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 346.33092188835144, "timesteps_since_restore": 0, "iterations_since_restore": 305, "perf": {"cpu_util_percent": 51.900000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, 10.0, 1.0, -2.0, 6.0, -10.0, 9.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, 8.0, -13.0, 7.0, 13.0, -2.0, -1.0, 12.0, 6.0, 8.0, -16.0, 10.0, 13.0, -2.0, 1.0, 10.0, 6.0, 12.0, -9.0, 11.0, 1.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, 13.0, 1.0, -5.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -3.0, -3.0, 12.0, 9.0, -12.0, 11.0, 8.0, 8.0, -7.0, 5.0, 12.0, 5.0, 12.0, -9.0, 10.0, 2.0, -14.0, 7.0, 12.0, 10.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -8.0, 5.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -13.0, 6.0, 12.0, 10.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -8.0, 11.0, 10.0, 2.0, -2.0, -1.0, 12.0, 6.0, -8.0, 8.0, 2.0, 13.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, 12.0, -1.0, -2.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -10.0, 11.0, 6.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 12.0, -7.0, 3.0, 13.0, -7.0, -4.0, 13.0, 3.0, 10.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 9.0, 10.0, -14.0, 10.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 2.0, 11.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 9.0, -11.0, 10.0, 13.0, -5.0, -6.0, 13.0, 7.0, 6.0, -7.0, 9.0, 6.0, 9.0, -6.0, 6.0, 8.0, 14.0, -7.0, 0.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 6.0, 14.0, -11.0, 6.0, 7.0, 10.0, -11.0, 9.0, 12.0, 4.0, -11.0, 10.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 8.0, 12.0, -7.0, 2.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -6.0, -4.0, 12.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0, 7.0, 6.0, -7.0, 9.0, 13.0, -7.0, -4.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49337095800306713, "mean_inference_ms": 2.0298298117218674, "mean_action_processing_ms": 0.12154125991101203, "mean_env_wait_ms": 0.287988399514188, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 956880, "agent_timesteps_total": 956799, "timers": {"learn_time_ms": 1.917, "learn_throughput": 16693.124, "update_time_ms": 4.98}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.202390670776367, "min_q": 0.8470764756202698, "max_q": 8.752650260925293, "mean_td_error": -9.654840469360352, "model": {}}}, "num_steps_sampled": 956880, "num_agent_steps_sampled": 956799, "num_steps_trained": 283232, "num_agent_steps_trained": 283232, "last_target_update_ts": 956880, "num_target_updates": 1771}, "done": false, "episodes_total": 18738, "training_iteration": 306, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-37", "timestamp": 1626860077, "time_this_iter_s": 1.1904430389404297, "time_total_s": 347.52136492729187, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 347.52136492729187, "timesteps_since_restore": 0, "iterations_since_restore": 306, "perf": {"cpu_util_percent": 47.2, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 13.0, 2.0, -6.0, 14.0, -3.0, 2.0, 2.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, -12.0, 10.0, 8.0, 9.0, 10.0, -3.0, 1.0, 7.0, 8.0, 13.0, 4.0, -10.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 1.0, -5.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 8.0, 9.0, -7.0, 5.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 0.0, 5.0, 11.0, -1.0, 3.0, 11.0, -7.0, 8.0, 6.0, 13.0, 2.0, -6.0, 9.0, -3.0, 1.0, 8.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, -6.0, 9.0, 1.0, 11.0, 6.0, 13.0, 2.0, -6.0, 8.0, -3.0, 1.0, 9.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, -1.0, 13.0, 9.0, -6.0, 6.0, -3.0, 1.0, 11.0, 6.0, 13.0, 2.0, -6.0, 6.0, -3.0, 6.0, 6.0, 6.0, 13.0, 1.0, -5.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, -12.0, 10.0, 9.0, 8.0, 7.0, 11.0, -9.0, 6.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 1.0, -5.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, -7.0, 13.0, 1.0, 8.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, 8.0, -13.0, 7.0, 13.0, -2.0, -1.0, 12.0, 6.0, 8.0, -16.0, 10.0, 13.0, -2.0, 1.0, 10.0, 6.0, 12.0, -9.0, 11.0, 1.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, 13.0, 1.0, -5.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -3.0, -3.0, 12.0, 9.0, -12.0, 11.0, 8.0, 8.0, -7.0, 5.0, 12.0, 5.0, 12.0, -9.0, 10.0, 2.0, -14.0, 7.0, 12.0, 10.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -8.0, 5.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -13.0, 6.0, 12.0, 10.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -8.0, 11.0, 10.0, 2.0, -2.0, -1.0, 12.0, 6.0, -8.0, 8.0, 2.0, 13.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, 12.0, -1.0, -2.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -10.0, 11.0, 6.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0, -2.0, -1.0, 12.0, 6.0, -12.0, 11.0, 8.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49339178678313866, "mean_inference_ms": 2.02990945029697, "mean_action_processing_ms": 0.12153853727226535, "mean_env_wait_ms": 0.2879911286346413, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 959040, "agent_timesteps_total": 958959, "timers": {"learn_time_ms": 2.011, "learn_throughput": 15912.19, "update_time_ms": 4.949}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.982223987579346, "min_q": 0.7986271381378174, "max_q": 8.751075744628906, "mean_td_error": -20.156875610351562, "model": {}}}, "num_steps_sampled": 959040, "num_agent_steps_sampled": 958959, "num_steps_trained": 283872, "num_agent_steps_trained": 283872, "last_target_update_ts": 959040, "num_target_updates": 1775}, "done": false, "episodes_total": 18792, "training_iteration": 307, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-38", "timestamp": 1626860078, "time_this_iter_s": 0.9731042385101318, "time_total_s": 348.494469165802, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dad90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 348.494469165802, "timesteps_since_restore": 0, "iterations_since_restore": 307, "perf": {"cpu_util_percent": 44.400000000000006, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 7.0, 8.0, 12.0, 10.0, 11.0, -18.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -4.0, 9.0, 11.0, -1.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -7.0, 9.0, 11.0, 2.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -17.0, 9.0, 11.0, 12.0, -13.0, 3.0, 12.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 10.0, 11.0, -5.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 2.0, 5.0, 11.0, -14.0, 9.0, 11.0, 9.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -17.0, 10.0, 11.0, 11.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, 8.0, -17.0, 11.0, 13.0, 2.0, 11.0, 11.0, -9.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -12.0, 9.0, 11.0, 7.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, 14.0, -6.0, 4.0, 3.0, -3.0, 3.0, 2.0, 13.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 1.0, -5.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 8.0, 9.0, -7.0, 5.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 0.0, 5.0, 11.0, -1.0, 3.0, 11.0, -7.0, 8.0, 6.0, 13.0, 2.0, -6.0, 9.0, -3.0, 1.0, 8.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, -6.0, 9.0, 1.0, 11.0, 6.0, 13.0, 2.0, -6.0, 8.0, -3.0, 1.0, 9.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, -1.0, 13.0, 9.0, -6.0, 6.0, -3.0, 1.0, 11.0, 6.0, 13.0, 2.0, -6.0, 6.0, -3.0, 6.0, 6.0, 6.0, 13.0, 1.0, -5.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, -12.0, 10.0, 9.0, 8.0, 7.0, 11.0, -9.0, 6.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 1.0, -5.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0, -7.0, 13.0, 1.0, 8.0, 10.0, -3.0, 1.0, 7.0, 6.0, 13.0, 2.0, -6.0, 10.0, -3.0, 1.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934052196586719, "mean_inference_ms": 2.029980487608713, "mean_action_processing_ms": 0.12154833400532379, "mean_env_wait_ms": 0.28799585901999575, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 962280, "agent_timesteps_total": 962199, "timers": {"learn_time_ms": 1.899, "learn_throughput": 16849.458, "update_time_ms": 4.203}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.6219706535339355, "min_q": 0.7845754027366638, "max_q": 9.217426300048828, "mean_td_error": 1.1436793804168701, "model": {}}}, "num_steps_sampled": 962280, "num_agent_steps_sampled": 962199, "num_steps_trained": 284832, "num_agent_steps_trained": 284832, "last_target_update_ts": 962280, "num_target_updates": 1781}, "done": false, "episodes_total": 18846, "training_iteration": 308, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-40", "timestamp": 1626860080, "time_this_iter_s": 1.1635730266571045, "time_total_s": 349.6580421924591, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791e510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 349.6580421924591, "timesteps_since_restore": 0, "iterations_since_restore": 308, "perf": {"cpu_util_percent": 50.05, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 12.0, 10.0, -1.0, -11.0, 9.0, 8.0, 9.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -17.0, 12.0, 9.0, 11.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -10.0, 9.0, 7.0, 9.0, -12.0, 8.0, 7.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -3.0, 4.0, 8.0, 6.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -4.0, 5.0, 8.0, 6.0, -10.0, 9.0, 4.0, 12.0, 9.0, 5.0, -4.0, 5.0, -13.0, 9.0, 8.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -11.0, 13.0, 1.0, 12.0, -6.0, 12.0, 10.0, -1.0, -12.0, 14.0, 1.0, 12.0, -10.0, 9.0, 4.0, 12.0, -3.0, 12.0, 9.0, -3.0, -9.0, 9.0, 4.0, 11.0, 7.0, -1.0, -3.0, 12.0, 1.0, 7.0, 8.0, -1.0, -8.0, 5.0, 6.0, 12.0, -10.0, 9.0, 4.0, 12.0, -4.0, 12.0, 9.0, -2.0, -9.0, 9.0, 4.0, 11.0, -12.0, 13.0, 7.0, 7.0, -17.0, 12.0, 9.0, 11.0, -8.0, 8.0, 4.0, 11.0, -8.0, 12.0, -1.0, 12.0, -4.0, 12.0, 8.0, -1.0, -9.0, 9.0, 4.0, 11.0, -2.0, 3.0, 12.0, 2.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -8.0, 13.0, -2.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -3.0, 11.0, 10.0, -3.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, 9.0, -1.0, 8.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, 0.0, 7.0, 9.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 11.0, 2.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 11.0, 11.0, -1.0, -9.0, 9.0, 4.0, 11.0, -2.0, 2.0, 12.0, 3.0, -5.0, 12.0, 9.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 5.0, 8.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -13.0, 12.0, 4.0, 12.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -17.0, 10.0, 11.0, 11.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, 8.0, -17.0, 11.0, 13.0, 2.0, 11.0, 11.0, -9.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, -12.0, 9.0, 11.0, 7.0, -3.0, 3.0, 2.0, 13.0, -1.0, 9.0, 11.0, -4.0, -3.0, 3.0, 2.0, 13.0, 14.0, -6.0, 4.0, 3.0, -3.0, 3.0, 2.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49048412203941266, "mean_inference_ms": 2.022213847612916, "mean_action_processing_ms": 0.12090298384558353, "mean_env_wait_ms": 0.2866082587444774, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 965520, "agent_timesteps_total": 965439, "timers": {"learn_time_ms": 1.917, "learn_throughput": 16688.766, "update_time_ms": 4.5}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.188897132873535, "min_q": 0.7848638296127319, "max_q": 9.307783126831055, "mean_td_error": -9.744314193725586, "model": {}}}, "num_steps_sampled": 965520, "num_agent_steps_sampled": 965439, "num_steps_trained": 285792, "num_agent_steps_trained": 285792, "last_target_update_ts": 965520, "num_target_updates": 1787}, "done": false, "episodes_total": 18927, "training_iteration": 309, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-41", "timestamp": 1626860081, "time_this_iter_s": 1.1966519355773926, "time_total_s": 350.8546941280365, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 350.8546941280365, "timesteps_since_restore": 0, "iterations_since_restore": 309, "perf": {"cpu_util_percent": 49.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -6.0, 10.0, 3.0, 9.0, -1.0, 0.0, 7.0, 10.0, -12.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 10.0, -15.0, 13.0, 7.0, 1.0, -1.0, 13.0, 2.0, 9.0, -7.0, 10.0, 3.0, 5.0, -16.0, 13.0, 13.0, 10.0, -12.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 13.0, -21.0, 10.0, 13.0, 9.0, -16.0, 13.0, 9.0, 12.0, -10.0, 13.0, 0.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -9.0, 13.0, 3.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 4.0, -15.0, 13.0, 13.0, 13.0, -20.0, 10.0, 12.0, 6.0, -17.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 4.0, -1.0, 13.0, -1.0, 10.0, -17.0, 13.0, 9.0, 5.0, -16.0, 13.0, 13.0, 13.0, -19.0, 10.0, 11.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 9.0, -16.0, 13.0, 9.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, -3.0, -1.0, 12.0, 7.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 7.0, -1.0, -3.0, 12.0, 1.0, 7.0, 8.0, -1.0, -8.0, 5.0, 6.0, 12.0, -10.0, 9.0, 4.0, 12.0, -4.0, 12.0, 9.0, -2.0, -9.0, 9.0, 4.0, 11.0, -12.0, 13.0, 7.0, 7.0, -17.0, 12.0, 9.0, 11.0, -8.0, 8.0, 4.0, 11.0, -8.0, 12.0, -1.0, 12.0, -4.0, 12.0, 8.0, -1.0, -9.0, 9.0, 4.0, 11.0, -2.0, 3.0, 12.0, 2.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -8.0, 13.0, -2.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -3.0, 11.0, 10.0, -3.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, 9.0, -1.0, 8.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, 0.0, 7.0, 9.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 11.0, 2.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 11.0, 11.0, -1.0, -9.0, 9.0, 4.0, 11.0, -2.0, 2.0, 12.0, 3.0, -5.0, 12.0, 9.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 5.0, 8.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -10.0, 9.0, 4.0, 12.0, -6.0, 12.0, 10.0, -1.0, -9.0, 9.0, 4.0, 11.0, -13.0, 12.0, 4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48790235610807287, "mean_inference_ms": 2.016645283553993, "mean_action_processing_ms": 0.12050426437184489, "mean_env_wait_ms": 0.2853317643370415, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 968760, "agent_timesteps_total": 968679, "timers": {"learn_time_ms": 1.825, "learn_throughput": 17534.029, "update_time_ms": 4.199}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 3.532121181488037, "min_q": 0.6911612153053284, "max_q": 8.59752082824707, "mean_td_error": 1.576136589050293, "model": {}}}, "num_steps_sampled": 968760, "num_agent_steps_sampled": 968679, "num_steps_trained": 286752, "num_agent_steps_trained": 286752, "last_target_update_ts": 968760, "num_target_updates": 1793}, "done": false, "episodes_total": 18981, "training_iteration": 310, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-42", "timestamp": 1626860082, "time_this_iter_s": 1.1086127758026123, "time_total_s": 351.9633069038391, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984dab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 351.9633069038391, "timesteps_since_restore": 0, "iterations_since_restore": 310, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.76, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 5.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-7.0, 14.0, 12.0, -4.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -17.0, 14.0, 6.0, 12.0, -1.0, 3.0, 13.0, 0.0, -20.0, 13.0, 12.0, 10.0, -1.0, 3.0, 13.0, 0.0, -8.0, 14.0, 12.0, -3.0, -1.0, 3.0, 13.0, 0.0, -20.0, 14.0, 13.0, 8.0, -3.0, -5.0, 13.0, 10.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, 13.0, 314.0, 13.0, 13.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -21.0, 14.0, 12.0, 10.0, -1.0, -7.0, 13.0, 10.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -20.0, 13.0, 12.0, 10.0, -1.0, -2.0, 13.0, 5.0, -9.0, 14.0, 13.0, -3.0, -6.0, 2.0, 10.0, 9.0, -20.0, 12.0, 13.0, 10.0, -1.0, -2.0, 13.0, 5.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -7.0, 14.0, -2.0, 10.0, -1.0, 3.0, 13.0, 0.0, 315.0, 14.0, 13.0, 11.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, -2.0, 13.0, 5.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -20.0, 12.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 2.0, 13.0, 1.0, -9.0, 14.0, 13.0, -3.0, -2.0, 4.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, 10.0, -12.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 13.0, -21.0, 10.0, 13.0, 9.0, -16.0, 13.0, 9.0, 12.0, -10.0, 13.0, 0.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -9.0, 13.0, 3.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 4.0, -15.0, 13.0, 13.0, 13.0, -20.0, 10.0, 12.0, 6.0, -17.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 4.0, -1.0, 13.0, -1.0, 10.0, -17.0, 13.0, 9.0, 5.0, -16.0, 13.0, 13.0, 13.0, -19.0, 10.0, 11.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, 9.0, -16.0, 13.0, 9.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0, 8.0, -10.0, 13.0, 4.0, -3.0, -1.0, 12.0, 7.0, 8.0, -10.0, 13.0, 4.0, 5.0, -16.0, 13.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49339100841069156, "mean_inference_ms": 2.0299994917951643, "mean_action_processing_ms": 0.12154601905339284, "mean_env_wait_ms": 0.2879852860434481, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 972000, "agent_timesteps_total": 971919, "timers": {"learn_time_ms": 1.849, "learn_throughput": 17307.92, "update_time_ms": 4.465}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.015786170959473, "min_q": 0.8057234883308411, "max_q": 9.2232027053833, "mean_td_error": 0.33081454038619995, "model": {}}}, "num_steps_sampled": 972000, "num_agent_steps_sampled": 971919, "num_steps_trained": 287712, "num_agent_steps_trained": 287712, "last_target_update_ts": 972000, "num_target_updates": 1799}, "done": false, "episodes_total": 19035, "training_iteration": 311, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-43", "timestamp": 1626860083, "time_this_iter_s": 1.1184837818145752, "time_total_s": 353.0817906856537, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 353.0817906856537, "timesteps_since_restore": 0, "iterations_since_restore": 311, "perf": {"cpu_util_percent": 51.55, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.14, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 6.285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 10.0, 11.0, -18.0, 10.0, 13.0, 13.0, -21.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -18.0, 12.0, 10.0, 11.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -16.0, 7.0, 12.0, 12.0, 8.0, 6.0, 12.0, -11.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 12.0, -19.0, 11.0, 13.0, 13.0, -22.0, -14.0, 7.0, 10.0, 12.0, 9.0, 10.0, 12.0, -16.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -18.0, 12.0, 10.0, 11.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 13.0, 12.0, 13.0, 315.0, -2.0, 8.0, 10.0, -1.0, 6.0, 4.0, 8.0, -3.0, 11.0, 13.0, 13.0, -22.0, 13.0, 11.0, 10.0, -19.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 6.0, 10.0, 1.0, 9.0, 6.0, 12.0, -12.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 11.0, 1.0, 10.0, -7.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 9.0, -1.0, 12.0, -5.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 10.0, 1.0, 11.0, -7.0, 11.0, 13.0, 13.0, -22.0, -13.0, 12.0, 9.0, 7.0, 9.0, 9.0, -16.0, 13.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 12.0, 13.0, -21.0, -2.0, 8.0, 10.0, -1.0, 11.0, 11.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 13.0, 12.0, 13.0, 315.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 13.0, -11.0, 3.0, 10.0, -2.0, 8.0, 10.0, -1.0, 13.0, 9.0, 11.0, -18.0, 13.0, -11.0, 3.0, 10.0, -2.0, 8.0, 10.0, -1.0, 11.0, 11.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -17.0, 10.0, 10.0, 12.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, -1.0, 3.0, 13.0, 0.0, -7.0, 14.0, -2.0, 10.0, -1.0, 3.0, 13.0, 0.0, 315.0, 14.0, 13.0, 11.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, -2.0, 13.0, 5.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -20.0, 12.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 2.0, 13.0, 1.0, -9.0, 14.0, 13.0, -3.0, -2.0, 4.0, 13.0, 0.0, -22.0, 14.0, 13.0, 10.0, -1.0, 3.0, 13.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49044220916632447, "mean_inference_ms": 2.022056313727996, "mean_action_processing_ms": 0.12088862059677222, "mean_env_wait_ms": 0.2865887827128224, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 975240, "agent_timesteps_total": 975159, "timers": {"learn_time_ms": 2.096, "learn_throughput": 15267.455, "update_time_ms": 5.072}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.591002464294434, "min_q": 0.6020755767822266, "max_q": 9.523893356323242, "mean_td_error": -9.798351287841797, "model": {}}}, "num_steps_sampled": 975240, "num_agent_steps_sampled": 975159, "num_steps_trained": 288672, "num_agent_steps_trained": 288672, "last_target_update_ts": 975240, "num_target_updates": 1805}, "done": false, "episodes_total": 19116, "training_iteration": 312, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-44", "timestamp": 1626860084, "time_this_iter_s": 1.1744537353515625, "time_total_s": 354.25624442100525, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 354.25624442100525, "timesteps_since_restore": 0, "iterations_since_restore": 312, "perf": {"cpu_util_percent": 47.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 103.37, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 25.8425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 354.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 11.0, 0.0, 7.0, -3.0, 4.0, 6.0, 11.0, -6.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 4.0, 14.0, 2.0, -5.0, 13.0, 322.0, 11.0, 9.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, 9.0, -9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -9.0, 9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 320.0, 11.0, 10.0, 2.0, 11.0, -7.0, 9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 5.0, 10.0, 6.0, -6.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, -15.0, 8.0, 9.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 4.0, 6.0, -4.0, 9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -9.0, 9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 4.0, 13.0, -6.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, -2.0, 8.0, 10.0, -1.0, 11.0, 1.0, 10.0, -7.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 9.0, -1.0, 12.0, -5.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 10.0, 1.0, 11.0, -7.0, 11.0, 13.0, 13.0, -22.0, -13.0, 12.0, 9.0, 7.0, 9.0, 9.0, -16.0, 13.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 12.0, 13.0, -21.0, -2.0, 8.0, 10.0, -1.0, 11.0, 11.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 13.0, 12.0, 13.0, 315.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 13.0, -11.0, 3.0, 10.0, -2.0, 8.0, 10.0, -1.0, 13.0, 9.0, 11.0, -18.0, 13.0, -11.0, 3.0, 10.0, -2.0, 8.0, 10.0, -1.0, 11.0, 11.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -17.0, 10.0, 10.0, 12.0, 12.0, 10.0, 11.0, -18.0, 11.0, 13.0, 13.0, -22.0, -2.0, 8.0, 10.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4878664513402606, "mean_inference_ms": 2.0166282623034975, "mean_action_processing_ms": 0.12049609726262223, "mean_env_wait_ms": 0.2853290834380966, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 978480, "agent_timesteps_total": 978399, "timers": {"learn_time_ms": 1.886, "learn_throughput": 16967.249, "update_time_ms": 4.368}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.6799774169921875, "min_q": 0.890754759311676, "max_q": 9.14985179901123, "mean_td_error": 0.7637828588485718, "model": {}}}, "num_steps_sampled": 978480, "num_agent_steps_sampled": 978399, "num_steps_trained": 289632, "num_agent_steps_trained": 289632, "last_target_update_ts": 978480, "num_target_updates": 1811}, "done": false, "episodes_total": 19170, "training_iteration": 313, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-46", "timestamp": 1626860086, "time_this_iter_s": 1.1475846767425537, "time_total_s": 355.4038290977478, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998541950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 355.4038290977478, "timesteps_since_restore": 0, "iterations_since_restore": 313, "perf": {"cpu_util_percent": 50.1, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 89.79, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 22.4475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 354.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0, 355.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 12.0, -20.0, 10.0, 5.0, 9.0, 6.0, -5.0, 13.0, 12.0, -20.0, 10.0, 4.0, 12.0, -12.0, 11.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 9.0, 12.0, -14.0, 8.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 12.0, 12.0, -18.0, 9.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, -13.0, 12.0, 10.0, 6.0, 9.0, 13.0, 10.0, -17.0, 7.0, 13.0, -17.0, 12.0, 9.0, 13.0, 10.0, -17.0, 12.0, 12.0, -18.0, 9.0, 4.0, 13.0, 10.0, -12.0, 13.0, 12.0, -20.0, 10.0, 0.0, -1.0, 10.0, 6.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, -13.0, 13.0, 6.0, 9.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 11.0, 10.0, -15.0, 13.0, 13.0, -18.0, 7.0, 5.0, 9.0, -10.0, 11.0, 13.0, 12.0, -20.0, 10.0, 0.0, 6.0, -4.0, 13.0, -13.0, 12.0, 6.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -19.0, 9.0, 4.0, 8.0, -10.0, 13.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -19.0, 9.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 7.0, 13.0, -16.0, 11.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 4.0, 14.0, 2.0, -5.0, 13.0, 322.0, 11.0, 9.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, 9.0, -9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -9.0, 9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 320.0, 11.0, 10.0, 2.0, 11.0, -7.0, 9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 5.0, 10.0, 6.0, -6.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, -15.0, 8.0, 9.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 4.0, 6.0, -4.0, 9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -9.0, 9.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0, 13.0, 321.0, 11.0, 10.0, 4.0, 13.0, -6.0, 4.0, 13.0, 321.0, 11.0, 10.0, 2.0, 13.0, -4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934223699129828, "mean_inference_ms": 2.0302445257401875, "mean_action_processing_ms": 0.12155709652966572, "mean_env_wait_ms": 0.28802483108206395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 980640, "agent_timesteps_total": 980559, "timers": {"learn_time_ms": 2.0, "learn_throughput": 15999.062, "update_time_ms": 4.314}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.083057880401611, "min_q": 0.6537730097770691, "max_q": 8.969913482666016, "mean_td_error": 0.2686045169830322, "model": {}}}, "num_steps_sampled": 980640, "num_agent_steps_sampled": 980559, "num_steps_trained": 290272, "num_agent_steps_trained": 290272, "last_target_update_ts": 980640, "num_target_updates": 1815}, "done": false, "episodes_total": 19224, "training_iteration": 314, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-47", "timestamp": 1626860087, "time_this_iter_s": 0.9859325885772705, "time_total_s": 356.3897616863251, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99985410d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 356.3897616863251, "timesteps_since_restore": 0, "iterations_since_restore": 314, "perf": {"cpu_util_percent": 45.3, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 14.0, -10.0, 13.0, 13.0, 3.0, -4.0, 3.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, 8.0, 14.0, 13.0, -20.0, 13.0, 7.0, 11.0, -16.0, -2.0, 14.0, -8.0, 11.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 13.0, 4.0, 10.0, -12.0, -2.0, 14.0, -10.0, 13.0, 13.0, 1.0, 10.0, -9.0, -4.0, 14.0, -8.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -1.0, 14.0, -11.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 13.0, 3.0, 11.0, -12.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -6.0, 14.0, -6.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 7.0, 10.0, -10.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 13.0, 6.0, 10.0, -14.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 12.0, 12.0, -18.0, 9.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, -13.0, 12.0, 10.0, 6.0, 9.0, 13.0, 10.0, -17.0, 7.0, 13.0, -17.0, 12.0, 9.0, 13.0, 10.0, -17.0, 12.0, 12.0, -18.0, 9.0, 4.0, 13.0, 10.0, -12.0, 13.0, 12.0, -20.0, 10.0, 0.0, -1.0, 10.0, 6.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, -13.0, 13.0, 6.0, 9.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 11.0, 10.0, -15.0, 13.0, 13.0, -18.0, 7.0, 5.0, 9.0, -10.0, 11.0, 13.0, 12.0, -20.0, 10.0, 0.0, 6.0, -4.0, 13.0, -13.0, 12.0, 6.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -19.0, 9.0, 4.0, 8.0, -10.0, 13.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -19.0, 9.0, 9.0, 13.0, 10.0, -17.0, 13.0, 12.0, -20.0, 10.0, 7.0, 13.0, -16.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934552315788552, "mean_inference_ms": 2.030340953488341, "mean_action_processing_ms": 0.12156514574529982, "mean_env_wait_ms": 0.2880332375934093, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 983880, "agent_timesteps_total": 983799, "timers": {"learn_time_ms": 1.94, "learn_throughput": 16491.501, "update_time_ms": 4.948}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.936145782470703, "min_q": 0.9420986175537109, "max_q": 9.27624797821045, "mean_td_error": 1.712780475616455, "model": {}}}, "num_steps_sampled": 983880, "num_agent_steps_sampled": 983799, "num_steps_trained": 291232, "num_agent_steps_trained": 291232, "last_target_update_ts": 983880, "num_target_updates": 1821}, "done": false, "episodes_total": 19278, "training_iteration": 315, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-48", "timestamp": 1626860088, "time_this_iter_s": 1.1579344272613525, "time_total_s": 357.5476961135864, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 357.5476961135864, "timesteps_since_restore": 0, "iterations_since_restore": 315, "perf": {"cpu_util_percent": 48.8, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 96.12, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -14.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 24.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 4.0, 9.0, 7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 9.0, 10.0, 7.0, -11.0, 13.0, 12.0, 12.0, 316.0, 5.0, 3.0, 9.0, -2.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 7.0, 8.0, 12.0, -12.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 14.0, 3.0, 5.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 9.0, 9.0, 4.0, -7.0, 13.0, 12.0, 12.0, 316.0, 8.0, 5.0, 11.0, -9.0, 13.0, 12.0, 12.0, 316.0, 4.0, 11.0, 12.0, -12.0, 10.0, -2.0, -3.0, 10.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 11.0, 4.0, -13.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, -2.0, -8.0, -11.0, 12.0, 11.0, 3.0, 13.0, 12.0, 12.0, 316.0, -2.0, 14.0, -8.0, 11.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 13.0, 4.0, 10.0, -12.0, -2.0, 14.0, -10.0, 13.0, 13.0, 1.0, 10.0, -9.0, -4.0, 14.0, -8.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -1.0, 14.0, -11.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 13.0, 3.0, 11.0, -12.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -6.0, 14.0, -6.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 7.0, 10.0, -10.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 13.0, 6.0, 10.0, -14.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0, -2.0, 14.0, -10.0, 13.0, 8.0, 3.0, 10.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4934325735368191, "mean_inference_ms": 2.0303276782206208, "mean_action_processing_ms": 0.12156310109189615, "mean_env_wait_ms": 0.2880101190681056, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 987120, "agent_timesteps_total": 987039, "timers": {"learn_time_ms": 1.922, "learn_throughput": 16651.704, "update_time_ms": 4.295}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.494341850280762, "min_q": 0.6916830539703369, "max_q": 9.604120254516602, "mean_td_error": 0.5432724952697754, "model": {}}}, "num_steps_sampled": 987120, "num_agent_steps_sampled": 987039, "num_steps_trained": 292192, "num_agent_steps_trained": 292192, "last_target_update_ts": 987120, "num_target_updates": 1827}, "done": false, "episodes_total": 19332, "training_iteration": 316, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-49", "timestamp": 1626860089, "time_this_iter_s": 1.1386559009552002, "time_total_s": 358.6863520145416, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998505730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 358.6863520145416, "timesteps_since_restore": 0, "iterations_since_restore": 316, "perf": {"cpu_util_percent": 50.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 45.43, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 11.3575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 7.0, 13.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 3.0, 12.0, 7.0, -7.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 11.0, 13.0, -7.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, -7.0, 14.0, 10.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, -1.0, 10.0, -1.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 8.0, 11.0, -1.0, -3.0, 12.0, 13.0, 316.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -19.0, 10.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 11.0, 12.0, -7.0, -1.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 5.0, 13.0, 0.0, -3.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, -2.0, 8.0, 2.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -7.0, -1.0, 11.0, 12.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 4.0, 13.0, 0.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 13.0, 11.0, 4.0, 14.0, -2.0, -1.0, 7.0, 13.0, -18.0, 13.0, -9.0, 11.0, 11.0, 2.0, 6.0, 13.0, -2.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 11.0, -12.0, 7.0, 9.0, -18.0, 9.0, 11.0, 13.0, -8.0, 12.0, 0.0, 11.0, 8.0, 13.0, -19.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 11.0, 4.0, -13.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, 12.0, 316.0, 4.0, 9.0, 9.0, -7.0, 13.0, 12.0, -2.0, -8.0, -11.0, 12.0, 11.0, 3.0, 13.0, 12.0, 12.0, 316.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49053255443869936, "mean_inference_ms": 2.022476766028186, "mean_action_processing_ms": 0.12091087126364775, "mean_env_wait_ms": 0.2866409139753388, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 990360, "agent_timesteps_total": 990279, "timers": {"learn_time_ms": 1.942, "learn_throughput": 16478.34, "update_time_ms": 5.392}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.6841535568237305, "min_q": 0.6048240661621094, "max_q": 9.628793716430664, "mean_td_error": 0.7856642007827759, "model": {}}}, "num_steps_sampled": 990360, "num_agent_steps_sampled": 990279, "num_steps_trained": 293152, "num_agent_steps_trained": 293152, "last_target_update_ts": 990360, "num_target_updates": 1833}, "done": false, "episodes_total": 19413, "training_iteration": 317, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-50", "timestamp": 1626860090, "time_this_iter_s": 1.1900081634521484, "time_total_s": 359.8763601779938, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 359.8763601779938, "timesteps_since_restore": 0, "iterations_since_restore": 317, "perf": {"cpu_util_percent": 50.35, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -9.0, -1.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -16.0, 6.0, 13.0, -18.0, 9.0, 11.0, 14.0, 3.0, -7.0, 5.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -15.0, 5.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -15.0, 5.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -9.0, -1.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -13.0, 3.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -8.0, -2.0, 319.0, 14.0, 9.0, 12.0, 12.0, 13.0, -16.0, 6.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 8.0, -8.0, 3.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -8.0, -2.0, 13.0, -18.0, 9.0, 11.0, 12.0, 10.0, -14.0, 7.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -15.0, 5.0, 13.0, -18.0, 9.0, 11.0, 12.0, 11.0, -8.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 12.0, -8.0, -1.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -8.0, -2.0, 13.0, -18.0, 9.0, 11.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -19.0, 10.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 11.0, 12.0, -7.0, -1.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 5.0, 13.0, 0.0, -3.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, -2.0, 8.0, 2.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -7.0, -1.0, 11.0, 12.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 4.0, 13.0, 0.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 13.0, 11.0, 4.0, 14.0, -2.0, -1.0, 7.0, 13.0, -18.0, 13.0, -9.0, 11.0, 11.0, 2.0, 6.0, 13.0, -2.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 11.0, -12.0, 7.0, 9.0, -18.0, 9.0, 11.0, 13.0, -8.0, 12.0, 0.0, 11.0, 8.0, 13.0, -19.0, 13.0, -18.0, 9.0, 11.0, 13.0, 6.0, 14.0, -3.0, -2.0, 7.0, 13.0, -18.0, 13.0, -18.0, 9.0, 11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48793555114537285, "mean_inference_ms": 2.0170048606711246, "mean_action_processing_ms": 0.12050797318221625, "mean_env_wait_ms": 0.2853648077467625, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 993600, "agent_timesteps_total": 993519, "timers": {"learn_time_ms": 1.857, "learn_throughput": 17227.942, "update_time_ms": 4.502}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.181265354156494, "min_q": 0.6547486186027527, "max_q": 9.018190383911133, "mean_td_error": 0.755394458770752, "model": {}}}, "num_steps_sampled": 993600, "num_agent_steps_sampled": 993519, "num_steps_trained": 294112, "num_agent_steps_trained": 294112, "last_target_update_ts": 993600, "num_target_updates": 1839}, "done": false, "episodes_total": 19467, "training_iteration": 318, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-51", "timestamp": 1626860091, "time_this_iter_s": 1.1109514236450195, "time_total_s": 360.9873116016388, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99b791ea60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 360.9873116016388, "timesteps_since_restore": 0, "iterations_since_restore": 318, "perf": {"cpu_util_percent": 50.6, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.39, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 13.0, -5.0, -6.0, -14.0, 13.0, 10.0, 6.0, 8.0, 13.0, -10.0, 4.0, 4.0, 7.0, -4.0, 8.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -9.0, 11.0, 7.0, 6.0, 3.0, 9.0, -5.0, 8.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 12.0, -10.0, 0.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -10.0, -1.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 9.0, 6.0, -10.0, 10.0, -10.0, 11.0, 7.0, 7.0, 9.0, 13.0, -5.0, -2.0, -10.0, 11.0, 7.0, 7.0, 7.0, 14.0, -10.0, 4.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 7.0, 5.0, -3.0, 6.0, 2.0, 12.0, 2.0, -1.0, 13.0, 13.0, -5.0, -6.0, 9.0, 11.0, 9.0, -14.0, 13.0, 13.0, -5.0, -6.0, -11.0, 13.0, 9.0, 4.0, 13.0, 13.0, -5.0, -6.0, -4.0, 11.0, 7.0, 1.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 14.0, 3.0, -7.0, 5.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -15.0, 5.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -15.0, 5.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -9.0, -1.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -13.0, 3.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -8.0, -2.0, 319.0, 14.0, 9.0, 12.0, 12.0, 13.0, -16.0, 6.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -10.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 8.0, -8.0, 3.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -8.0, -2.0, 13.0, -18.0, 9.0, 11.0, 12.0, 10.0, -14.0, 7.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -15.0, 5.0, 13.0, -18.0, 9.0, 11.0, 12.0, 11.0, -8.0, 0.0, 13.0, -18.0, 9.0, 11.0, 12.0, 12.0, -8.0, -1.0, 13.0, -18.0, 9.0, 11.0, 12.0, 13.0, -8.0, -2.0, 13.0, -18.0, 9.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49344563052110063, "mean_inference_ms": 2.0303722298659483, "mean_action_processing_ms": 0.12155857282985309, "mean_env_wait_ms": 0.2880177208914258, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 996840, "agent_timesteps_total": 996759, "timers": {"learn_time_ms": 1.93, "learn_throughput": 16576.025, "update_time_ms": 4.789}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 4.993288993835449, "min_q": 0.9755668044090271, "max_q": 9.270597457885742, "mean_td_error": 1.005517840385437, "model": {}}}, "num_steps_sampled": 996840, "num_agent_steps_sampled": 996759, "num_steps_trained": 295072, "num_agent_steps_trained": 295072, "last_target_update_ts": 996840, "num_target_updates": 1845}, "done": false, "episodes_total": 19521, "training_iteration": 319, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-53", "timestamp": 1626860093, "time_this_iter_s": 1.1718857288360596, "time_total_s": 362.15919733047485, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f99984da950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 362.15919733047485, "timesteps_since_restore": 0, "iterations_since_restore": 319, "perf": {"cpu_util_percent": 51.4, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-8.0, 13.0, -2.0, 12.0, -14.0, 11.0, 11.0, 7.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 3.0, 8.0, 13.0, -9.0, -8.0, 13.0, -2.0, 12.0, -6.0, 4.0, 6.0, 11.0, 7.0, 5.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -7.0, 13.0, -3.0, 12.0, -14.0, 6.0, 11.0, 12.0, -8.0, 10.0, 9.0, 4.0, -8.0, 13.0, -2.0, 12.0, -14.0, 11.0, 11.0, 7.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 10.0, -13.0, 13.0, 5.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -17.0, 8.0, 11.0, 13.0, 13.0, -3.0, 5.0, 0.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 11.0, 11.0, 7.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 10.0, -13.0, 13.0, 5.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 7.0, 5.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -15.0, 6.0, 11.0, 13.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -16.0, 11.0, 12.0, 8.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, 11.0, 0.0, -8.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -8.0, 13.0, -2.0, 12.0, -14.0, 6.0, 11.0, 12.0, 4.0, 8.0, 13.0, -10.0, -7.0, 13.0, -3.0, 12.0, -14.0, 11.0, 11.0, 7.0, 13.0, -7.0, 4.0, 5.0, -10.0, 11.0, 7.0, 7.0, 9.0, 13.0, -5.0, -2.0, -10.0, 11.0, 7.0, 7.0, 7.0, 14.0, -10.0, 4.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 7.0, 5.0, -3.0, 6.0, 2.0, 12.0, 2.0, -1.0, 13.0, 13.0, -5.0, -6.0, 9.0, 11.0, 9.0, -14.0, 13.0, 13.0, -5.0, -6.0, -11.0, 13.0, 9.0, 4.0, 13.0, 13.0, -5.0, -6.0, -4.0, 11.0, 7.0, 1.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0, 13.0, 13.0, -5.0, -6.0, -10.0, 11.0, 7.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49047440167680195, "mean_inference_ms": 2.022278367631316, "mean_action_processing_ms": 0.12089424092770758, "mean_env_wait_ms": 0.28660046315833054, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 1000080, "agent_timesteps_total": 999999, "timers": {"learn_time_ms": 2.031, "learn_throughput": 15755.474, "update_time_ms": 4.337}, "info": {"learner": {"learned": {"cur_lr": 0.0005000000237487257, "mean_q": 5.925244331359863, "min_q": 0.7279142141342163, "max_q": 9.541768074035645, "mean_td_error": 1.4834259748458862, "model": {}}}, "num_steps_sampled": 1000080, "num_agent_steps_sampled": 999999, "num_steps_trained": 296032, "num_agent_steps_trained": 296032, "last_target_update_ts": 1000080, "num_target_updates": 1851}, "done": true, "episodes_total": 19602, "training_iteration": 320, "experiment_id": "b38e8cd34e87459e8748a81e713eb5ad", "date": "2021-07-21_11-34-54", "timestamp": 1626860094, "time_this_iter_s": 1.1533143520355225, "time_total_s": 363.3125116825104, "pid": 13776, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "q_masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9998571d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "replay_sequence_length": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 363.3125116825104, "timesteps_since_restore": 0, "iterations_since_restore": 320, "perf": {"cpu_util_percent": 50.75, "ram_util_percent": 14.2}, "trial_id": "fe451_00000"}
