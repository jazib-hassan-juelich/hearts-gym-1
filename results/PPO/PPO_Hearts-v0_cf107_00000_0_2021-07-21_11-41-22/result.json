{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.074074074074074, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7685185185185186}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 13.0, -3.0, 7.0, 9.0, 5.0, 9.0, -8.0, 5.0, 10.0, 7.0, -7.0, 10.0, 9.0, 9.0, -13.0, -5.0, 1.0, 10.0, 9.0, -15.0, 10.0, 12.0, 8.0, 8.0, 11.0, 4.0, -8.0, 9.0, 10.0, -12.0, 8.0, -9.0, 9.0, 7.0, 8.0, -8.0, 7.0, 9.0, 7.0, 14.0, -12.0, 3.0, 10.0, 12.0, 6.0, 10.0, -13.0, -9.0, 8.0, 12.0, 4.0, 11.0, 14.0, 10.0, -19.0, -15.0, 11.0, 8.0, 11.0, -7.0, 8.0, 8.0, 6.0, 14.0, 14.0, -7.0, -6.0, -13.0, 8.0, 12.0, 8.0, 10.0, 13.0, -11.0, 3.0, 13.0, 2.0, -12.0, 12.0, 0.0, -6.0, 13.0, 8.0, 4.0, 10.0, -3.0, 4.0, 9.0, 14.0, 10.0, -18.0, 8.0, -11.0, 13.0, 5.0, 13.0, 8.0, -3.0, -3.0, 4.0, -10.0, 9.0, 13.0, 6.0, -4.0, 12.0, 1.0, 3.0, 9.0, 6.0, -3.0, 7.0, 2.0, -4.0, 10.0, 7.0, -8.0, 10.0, 6.0, -3.0, 5.0, 5.0, 8.0, 4.0, -2.0, 6.0, 7.0, 13.0, -13.0, 7.0, 8.0, 1.0, 12.0, 8.0, -6.0, 8.0, 4.0, 11.0, -8.0, 1.0, -7.0, 8.0, 13.0, 11.0, 6.0, -3.0, 1.0, 1.0, 10.0, -5.0, 9.0, 5.0, -15.0, 13.0, 12.0, 7.0, 3.0, 7.0, -2.0, 9.0, 4.0, -5.0, 7.0, -13.0, 11.0, 7.0, 10.0, 11.0, 6.0, 9.0, -11.0, 13.0, 7.0, 0.0, -5.0, 5.0, -5.0, 7.0, 8.0, -1.0, 10.0, 8.0, -2.0, 14.0, -12.0, 8.0, 5.0, 3.0, 3.0, 13.0, -4.0, 11.0, 7.0, 0.0, -3.0, 14.0, 5.0, -14.0, 10.0, -1.0, 5.0, 9.0, 2.0, 6.0, 10.0, 5.0, -6.0, 8.0, 9.0, -8.0, 6.0, 3.0, -7.0, 7.0, 12.0, 8.0, 9.0, 7.0, -9.0, 0.0, 14.0, -9.0, 11.0, -16.0, 12.0, 8.0, 11.0, 3.0, 11.0, 10.0, -9.0, 9.0, 14.0, 8.0, -16.0, 5.0, 10.0, 8.0, -8.0, 9.0, 11.0, 9.0, -14.0, 8.0, -10.0, 6.0, 11.0, -12.0, 10.0, 12.0, 5.0, 11.0, -15.0, 10.0, 9.0, 5.0, 3.0, -2.0, 10.0, -11.0, 5.0, 8.0, 13.0, 4.0, 13.0, 11.0, -13.0, 14.0, 9.0, 10.0, -18.0, -10.0, 8.0, 9.0, 8.0, 13.0, 4.0, 9.0, -11.0, 9.0, -4.0, 5.0, 6.0, 0.0, -4.0, 12.0, 7.0, 11.0, 8.0, -6.0, 2.0, 8.0, 6.0, -8.0, 9.0, -10.0, 8.0, 7.0, 10.0, 7.0, 8.0, -5.0, 5.0, 13.0, 6.0, 4.0, -7.0, -12.0, 9.0, 10.0, 8.0, 10.0, 11.0, 7.0, -13.0, 13.0, -15.0, 4.0, 13.0, -8.0, 2.0, 13.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21029718018421614, "mean_inference_ms": 1.3996785970293883, "mean_action_processing_ms": 0.08482051769936307, "mean_env_wait_ms": 0.18038037118934586, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 5400, "agent_timesteps_total": 5319, "timers": {"sample_time_ms": 443.806, "sample_throughput": 12167.484, "learn_time_ms": 6759.895, "learn_throughput": 798.829, "update_time_ms": 12.51}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 34.05374526977539, "policy_loss": -0.062443092465400696, "vf_loss": 34.113067626953125, "vf_explained_var": 0.0968812108039856, "kl": 0.015615872107446194, "entropy": 1.0322730541229248, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 5400, "num_agent_steps_sampled": 5319, "num_steps_trained": 5400, "num_agent_steps_trained": 5319}, "done": false, "episodes_total": 81, "training_iteration": 1, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-41-41", "timestamp": 1626860501, "time_this_iter_s": 7.306577682495117, "time_total_s": 7.306577682495117, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae679d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.306577682495117, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 23.818181818181817, "ram_util_percent": 14.0}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -4.0, 3.0, 5.0, 13.0, -7.0, 5.0, 4.0, 5.0, -2.0, 10.0, 2.0, -19.0, 11.0, 11.0, 12.0, 13.0, 12.0, 4.0, -14.0, 14.0, 0.0, -4.0, 5.0, 5.0, -3.0, 7.0, 6.0, 4.0, 12.0, 7.0, -8.0, -4.0, 12.0, 5.0, 2.0, 12.0, 5.0, -11.0, 9.0, 11.0, 10.0, -2.0, -4.0, 5.0, -3.0, 7.0, 6.0, -1.0, 10.0, 4.0, 2.0, 10.0, -6.0, 3.0, 8.0, 7.0, 12.0, 10.0, -14.0, 11.0, -5.0, 6.0, 3.0, -8.0, 13.0, 7.0, 3.0, 13.0, -13.0, 9.0, 6.0, 2.0, 10.0, 5.0, -2.0, 6.0, 9.0, 8.0, -8.0, -9.0, 10.0, 7.0, 7.0, -3.0, 9.0, 11.0, -2.0, 1.0, 11.0, -9.0, 12.0, 2.0, 7.0, -5.0, 11.0, -4.0, 12.0, 10.0, -3.0, 11.0, 9.0, -12.0, 7.0, 7.0, 10.0, -12.0, 10.0, 11.0, 3.0, 10.0, -9.0, -4.0, 9.0, 10.0, 0.0, 13.0, 3.0, -7.0, 6.0, 4.0, 11.0, -10.0, 10.0, -1.0, 10.0, -7.0, 13.0, -4.0, 7.0, 12.0, 0.0, 12.0, 4.0, 10.0, -11.0, 1.0, 10.0, 7.0, -3.0, 8.0, 10.0, 6.0, -9.0, 11.0, 12.0, -6.0, -2.0, 9.0, 6.0, -12.0, 12.0, 11.0, 9.0, -5.0, 0.0, 3.0, -3.0, 9.0, 6.0, -2.0, 11.0, 4.0, 2.0, 13.0, -1.0, -7.0, 10.0, 7.0, 6.0, -4.0, 6.0, 5.0, 11.0, -12.0, 11.0, 12.0, 6.0, 5.0, -8.0, -5.0, 5.0, 2.0, 13.0, 12.0, -12.0, 6.0, 9.0, 1.0, 8.0, 12.0, -6.0, -2.0, 13.0, -3.0, 7.0, 11.0, 5.0, 3.0, -4.0, 2.0, 11.0, -8.0, 10.0, -13.0, 10.0, 7.0, 11.0, 7.0, -4.0, 0.0, 12.0, 10.0, 10.0, 1.0, -6.0, 3.0, 12.0, -8.0, 8.0, 11.0, 12.0, -14.0, 6.0, -4.0, 11.0, 8.0, 0.0, 14.0, 4.0, 6.0, -9.0, 10.0, 10.0, 6.0, -11.0, 4.0, 11.0, 7.0, -7.0, 12.0, 11.0, 7.0, -15.0, 13.0, 5.0, 9.0, -12.0, 5.0, 11.0, 5.0, -6.0, 6.0, 7.0, 13.0, -11.0, 10.0, 11.0, -12.0, 6.0, 13.0, -1.0, -4.0, 7.0, 5.0, 5.0, -4.0, 9.0, 11.0, 12.0, -12.0, 4.0, 10.0, 12.0, -17.0, 10.0, 10.0, 0.0, -8.0, 13.0, 5.0, 10.0, -5.0, 5.0, -14.0, 10.0, 6.0, 13.0, 12.0, 11.0, 8.0, -16.0, 14.0, 7.0, 4.0, -10.0, 5.0, 10.0, -9.0, 9.0, 7.0, 11.0, -6.0, 3.0, -5.0, 13.0, 7.0, 0.0, 3.0, 9.0, -10.0, 13.0, 1.0, 11.0, -4.0, 7.0, 5.0, -11.0, 11.0, 10.0, -6.0, 9.0, 6.0, 6.0, 5.0, 10.0, -2.0, 2.0, 3.0, 10.0, -4.0, 6.0, 1.0, 12.0, 6.0, -4.0, -7.0, 13.0, 3.0, 6.0, 13.0, 3.0, 5.0, -6.0, 6.0, 9.0, -7.0, 7.0, 3.0, 11.0, -6.0, 7.0, -2.0, 13.0, 7.0, -3.0, 14.0, -13.0, 6.0, 8.0, 5.0, 12.0, -8.0, 6.0, -19.0, 12.0, 12.0, 10.0, -8.0, 14.0, 11.0, -2.0, 10.0, 5.0, -11.0, 11.0, 1.0, 13.0, -3.0, 4.0, 5.0, 12.0, -6.0, 4.0, 11.0, -2.0, 0.0, 6.0, 10.0, -8.0, 10.0, 3.0, 5.0, 11.0, 6.0, -7.0, 4.0, 13.0, -8.0, 6.0, 9.0, 7.0, 6.0, -7.0, 11.0, 4.0, 1.0, -1.0, 7.0, 12.0, -9.0, 5.0, -1.0, -1.0, 12.0, 5.0, -5.0, 11.0, 7.0, 2.0, 8.0, -3.0, 12.0, -2.0, 8.0, 12.0, -10.0, 5.0, 6.0, 9.0, 9.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22028418935830552, "mean_inference_ms": 1.287050587192647, "mean_action_processing_ms": 0.0783529287782019, "mean_env_wait_ms": 0.1799741411865325, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 10800, "agent_timesteps_total": 10719, "timers": {"sample_time_ms": 399.4, "sample_throughput": 13520.277, "learn_time_ms": 6720.226, "learn_throughput": 803.544, "update_time_ms": 11.838}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 26.811464309692383, "policy_loss": -0.0735989436507225, "vf_loss": 26.882020950317383, "vf_explained_var": 0.10331998020410538, "kl": 0.015204059891402721, "entropy": 1.0406044721603394, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 10800, "num_agent_steps_sampled": 10719, "num_steps_trained": 10800, "num_agent_steps_trained": 10719}, "done": false, "episodes_total": 189, "training_iteration": 2, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-41-49", "timestamp": 1626860509, "time_this_iter_s": 7.124950647354126, "time_total_s": 14.431528329849243, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.431528329849243, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 21.79, "ram_util_percent": 14.0}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.546296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 6.886574074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, -4.0, 11.0, 8.0, 10.0, 9.0, 10.0, -14.0, 1.0, 12.0, -6.0, 8.0, 6.0, -12.0, 12.0, 9.0, 6.0, -4.0, 7.0, 6.0, 14.0, 12.0, 3.0, -14.0, 6.0, 12.0, 10.0, -13.0, 5.0, -15.0, 12.0, 13.0, 11.0, -6.0, 5.0, 5.0, 9.0, 10.0, -10.0, 6.0, -1.0, 12.0, 10.0, -6.0, 9.0, 11.0, -13.0, 8.0, 9.0, 13.0, -5.0, -2.0, 13.0, 9.0, 9.0, -16.0, 2.0, 11.0, -11.0, 13.0, 9.0, -11.0, 8.0, 9.0, 7.0, -3.0, 8.0, 3.0, 14.0, -11.0, 9.0, 3.0, -14.0, 13.0, 4.0, 12.0, 6.0, 12.0, 8.0, -11.0, 9.0, 10.0, -10.0, 6.0, 9.0, -1.0, -2.0, 9.0, 2.0, 12.0, -5.0, 6.0, -7.0, 7.0, 12.0, 3.0, 11.0, -1.0, 6.0, -1.0, 8.0, 11.0, 5.0, -9.0, -16.0, 12.0, 11.0, 8.0, 3.0, -9.0, 13.0, 8.0, 11.0, -10.0, 6.0, 8.0, 9.0, 10.0, 6.0, -10.0, 319.0, 13.0, 11.0, 12.0, 13.0, -15.0, 12.0, 5.0, 9.0, -7.0, 5.0, 8.0, 5.0, 13.0, 10.0, -13.0, 7.0, 13.0, 11.0, -16.0, 5.0, -10.0, 12.0, 8.0, -11.0, 10.0, 10.0, 6.0, 5.0, 14.0, -8.0, 4.0, 4.0, -2.0, 8.0, 5.0, 12.0, -9.0, 13.0, -1.0, 7.0, -7.0, 11.0, 4.0, 8.0, 11.0, 5.0, -9.0, -14.0, 12.0, 11.0, 6.0, 12.0, -4.0, 0.0, 7.0, 5.0, 12.0, 11.0, -13.0, 11.0, 11.0, 9.0, -16.0, 318.0, 13.0, 11.0, 12.0, 3.0, -3.0, 13.0, 2.0, 11.0, -10.0, 10.0, 4.0, 13.0, 13.0, 9.0, 317.0, -12.0, 13.0, 7.0, 7.0, 8.0, -15.0, 11.0, 11.0, 9.0, -3.0, 6.0, 3.0, 10.0, 9.0, 11.0, -15.0, 4.0, 12.0, 11.0, -12.0, 6.0, -9.0, 7.0, 11.0, 11.0, -4.0, 11.0, -3.0, 11.0, 13.0, 9.0, -18.0, 9.0, 13.0, 5.0, -12.0, 13.0, 1.0, 13.0, -12.0, 11.0, -1.0, 0.0, 5.0, 12.0, -6.0, -2.0, 11.0, 12.0, 6.0, 12.0, -15.0, 11.0, -18.0, 12.0, 10.0, -5.0, 13.0, -1.0, 8.0, 8.0, 10.0, 6.0, -9.0, -13.0, 12.0, 7.0, 9.0, 6.0, -10.0, 13.0, 6.0, 7.0, -3.0, 5.0, 6.0, 8.0, -2.0, 2.0, 7.0, -8.0, 13.0, 8.0, 2.0, 6.0, -8.0, 13.0, 4.0, 7.0, -1.0, 6.0, 3.0, 10.0, 10.0, 10.0, -15.0, 13.0, 11.0, -11.0, 2.0, 7.0, -14.0, 13.0, 9.0, 0.0, -2.0, 11.0, 6.0, 8.0, 7.0, 8.0, -8.0, -2.0, 12.0, -1.0, 6.0, 12.0, -13.0, 13.0, 3.0, 11.0, -6.0, 2.0, 8.0, 14.0, -10.0, 9.0, 2.0, -16.0, 13.0, 11.0, 7.0, 13.0, -11.0, 5.0, 8.0, 7.0, 9.0, -9.0, 8.0, 14.0, 12.0, 10.0, 318.0, 1.0, 12.0, 10.0, -8.0, 7.0, -9.0, 13.0, 4.0, 2.0, 0.0, 5.0, 8.0, 12.0, 6.0, 6.0, -9.0, -2.0, 13.0, -8.0, 12.0, 0.0, -1.0, 6.0, 10.0, -7.0, 11.0, 5.0, 6.0, 8.0, 7.0, 11.0, -11.0, 13.0, 4.0, 4.0, -6.0, 3.0, -10.0, 13.0, 9.0, -5.0, 11.0, 7.0, 2.0, 8.0, 11.0, 8.0, -12.0, 12.0, -15.0, 12.0, 6.0, 12.0, -13.0, 8.0, 8.0, -7.0, 10.0, 11.0, 1.0, 5.0, 11.0, 7.0, -8.0, 14.0, 9.0, 10.0, -18.0, 9.0, -9.0, 11.0, 4.0, 9.0, -8.0, 10.0, 4.0, 8.0, 13.0, 5.0, -11.0, -7.0, 3.0, 13.0, 6.0, 7.0, -4.0, 3.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22094358598310998, "mean_inference_ms": 1.2442591509610688, "mean_action_processing_ms": 0.0763202893386496, "mean_env_wait_ms": 0.17988954342953598, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 16200, "agent_timesteps_total": 16119, "timers": {"sample_time_ms": 383.091, "sample_throughput": 14095.877, "learn_time_ms": 6674.154, "learn_throughput": 809.091, "update_time_ms": 11.479}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 833.8253173828125, "policy_loss": -0.0282116886228323, "vf_loss": 833.852294921875, "vf_explained_var": 0.053931836038827896, "kl": 0.006220918148756027, "entropy": 0.9613556265830994, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 16200, "num_agent_steps_sampled": 16119, "num_steps_trained": 16200, "num_agent_steps_trained": 16119}, "done": false, "episodes_total": 297, "training_iteration": 3, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-41-56", "timestamp": 1626860516, "time_this_iter_s": 7.031279563903809, "time_total_s": 21.46280789375305, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702187b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21.46280789375305, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 21.66, "ram_util_percent": 14.0}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.824074074074073, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 329.0}, "policy_reward_mean": {"learned": 7.706018518518518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 317.0, 12.0, 12.0, 9.0, 12.0, 12.0, -18.0, -14.0, 9.0, 12.0, 8.0, 8.0, 12.0, 3.0, -8.0, 14.0, 329.0, 11.0, 13.0, 13.0, 11.0, -14.0, 5.0, 4.0, 7.0, 11.0, -7.0, 9.0, 7.0, 0.0, -1.0, 7.0, -12.0, 7.0, 13.0, 5.0, 13.0, -8.0, 5.0, 12.0, 7.0, 10.0, -14.0, 13.0, 6.0, -1.0, -3.0, -4.0, 4.0, 5.0, 10.0, 12.0, -12.0, 10.0, 5.0, -10.0, 8.0, 7.0, 10.0, 1.0, 12.0, 5.0, -3.0, 14.0, -4.0, -4.0, 9.0, -3.0, -1.0, 7.0, 12.0, 8.0, 12.0, -15.0, 10.0, -5.0, 7.0, 2.0, 11.0, 14.0, 317.0, 10.0, 13.0, 9.0, 4.0, 10.0, -8.0, 4.0, 12.0, 8.0, -9.0, -12.0, 12.0, 6.0, 9.0, 14.0, -6.0, 12.0, -5.0, 10.0, 2.0, -4.0, 7.0, -7.0, 6.0, 4.0, 12.0, -4.0, 8.0, 1.0, 10.0, 14.0, -20.0, 8.0, 13.0, 8.0, 3.0, 7.0, -3.0, 5.0, 4.0, -1.0, 7.0, -6.0, 4.0, 8.0, 9.0, 14.0, 316.0, 11.0, 13.0, 10.0, -3.0, 11.0, -3.0, 2.0, 4.0, 12.0, -3.0, 8.0, 9.0, 9.0, -11.0, 6.0, 2.0, 8.0, -1.0, 12.0, 2.0, -10.0, 11.0, 6.0, 9.0, -3.0, 3.0, -9.0, 13.0, 0.0, 11.0, 14.0, -21.0, 12.0, 10.0, 0.0, 7.0, 0.0, 8.0, -10.0, 12.0, 7.0, 6.0, -1.0, 6.0, 4.0, 6.0, 13.0, 318.0, 11.0, 12.0, 9.0, 9.0, 4.0, -7.0, 5.0, 7.0, 10.0, -7.0, 13.0, 1.0, 5.0, -4.0, 14.0, -20.0, 9.0, 12.0, 13.0, 6.0, -16.0, 12.0, -13.0, 5.0, 12.0, 11.0, -10.0, 13.0, 1.0, 11.0, 12.0, 5.0, -11.0, 9.0, 4.0, 13.0, -8.0, 6.0, 5.0, 6.0, 12.0, -8.0, 4.0, 13.0, 1.0, -3.0, 13.0, -5.0, -3.0, 10.0, 7.0, 11.0, -1.0, -2.0, -7.0, 5.0, 5.0, 12.0, 7.0, 12.0, -2.0, -2.0, 9.0, -17.0, 10.0, 13.0, 8.0, 4.0, 5.0, -2.0, 5.0, 7.0, -7.0, 10.0, 0.0, 8.0, 2.0, 5.0, 0.0, -3.0, 6.0, 12.0, 10.0, 9.0, 7.0, -11.0, 8.0, 12.0, 6.0, -11.0, 7.0, 3.0, -2.0, 7.0, -4.0, 6.0, 2.0, 11.0, 4.0, -3.0, 8.0, 6.0, 0.0, 13.0, -2.0, 4.0, 13.0, 4.0, -1.0, -1.0, -5.0, -3.0, 11.0, 12.0, 7.0, 7.0, 4.0, -3.0, -8.0, 12.0, -1.0, 12.0, -16.0, 13.0, 9.0, 9.0, 10.0, -5.0, 12.0, -2.0, 11.0, -3.0, -5.0, 12.0, -12.0, 12.0, 12.0, 3.0, 12.0, 12.0, -1.0, -8.0, -4.0, -6.0, 12.0, 13.0, 11.0, 8.0, 12.0, -16.0, -15.0, 13.0, 12.0, 5.0, 5.0, 8.0, 9.0, -7.0, -2.0, -4.0, 9.0, 12.0, 13.0, 1.0, 11.0, -10.0, 2.0, 11.0, 9.0, -7.0, -7.0, 8.0, 4.0, 10.0, -6.0, 6.0, 3.0, 12.0, 9.0, 9.0, -15.0, 12.0, 8.0, 9.0, 12.0, -14.0, -9.0, 9.0, 2.0, 13.0, 13.0, -3.0, -8.0, 13.0, 13.0, 0.0, 10.0, -8.0, 2.0, 9.0, -3.0, 7.0, 4.0, 14.0, -3.0, 0.0, 9.0, -4.0, -3.0, 13.0, 12.0, 12.0, -12.0, 3.0, -5.0, 13.0, -2.0, 9.0, 2.0, 12.0, 2.0, -1.0, -4.0, 1.0, 7.0, 11.0, 3.0, 12.0, -6.0, 6.0, 1.0, 9.0, -2.0, 7.0, 0.0, 13.0, -10.0, 12.0, 14.0, 5.0, -16.0, 12.0, 11.0, 6.0, 5.0, -7.0, 5.0, 9.0, 8.0, -7.0, -1.0, 7.0, -1.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2216462449149505, "mean_inference_ms": 1.231472507762023, "mean_action_processing_ms": 0.07569357189881012, "mean_env_wait_ms": 0.1798240410976769, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 21600, "agent_timesteps_total": 21519, "timers": {"sample_time_ms": 395.572, "sample_throughput": 13651.121, "learn_time_ms": 6694.897, "learn_throughput": 806.585, "update_time_ms": 11.733}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 307.5739440917969, "policy_loss": -0.023130202665925026, "vf_loss": 307.5954284667969, "vf_explained_var": 0.010645659640431404, "kl": 0.008257236331701279, "entropy": 0.9348700046539307, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 21600, "num_agent_steps_sampled": 21519, "num_steps_trained": 21600, "num_agent_steps_trained": 21519}, "done": false, "episodes_total": 405, "training_iteration": 4, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-42-03", "timestamp": 1626860523, "time_this_iter_s": 7.289225816726685, "time_total_s": 28.752033710479736, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702061e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 28.752033710479736, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 20.636363636363633, "ram_util_percent": 14.08181818181818}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 9.0, 7.0, 12.0, 6.0, 8.0, 5.0, -4.0, 5.0, 5.0, 11.0, -6.0, 11.0, 1.0, 12.0, -9.0, 5.0, 3.0, 12.0, -5.0, -11.0, 13.0, 0.0, 13.0, 4.0, -12.0, 12.0, 11.0, 6.0, -9.0, 11.0, 7.0, 5.0, -8.0, 7.0, 11.0, 12.0, 8.0, -3.0, -2.0, 12.0, 5.0, 12.0, -14.0, 9.0, -4.0, 6.0, 4.0, 0.0, 8.0, -4.0, 11.0, 11.0, 8.0, -3.0, -1.0, 9.0, 5.0, 11.0, -10.0, 10.0, -3.0, 8.0, 0.0, 2.0, -2.0, 2.0, 13.0, 11.0, 9.0, 1.0, -6.0, 7.0, -4.0, 12.0, 0.0, -11.0, 10.0, 10.0, 6.0, -4.0, 12.0, -2.0, 9.0, 7.0, -4.0, 0.0, 12.0, 12.0, 12.0, 11.0, 319.0, -2.0, 2.0, 11.0, 4.0, -10.0, 9.0, 8.0, 8.0, 11.0, 1.0, -10.0, 13.0, 12.0, -4.0, 5.0, 2.0, 11.0, -7.0, 4.0, 7.0, 3.0, 5.0, 10.0, -3.0, -7.0, 6.0, 4.0, 12.0, 7.0, 12.0, 9.0, -13.0, -13.0, 6.0, 11.0, 11.0, 2.0, 5.0, 12.0, -4.0, -11.0, 9.0, 5.0, 12.0, 11.0, 4.0, 8.0, -8.0, 9.0, 6.0, 7.0, -7.0, 8.0, 10.0, -13.0, 10.0, 10.0, 5.0, -8.0, 8.0, -7.0, 10.0, 10.0, 2.0, 12.0, 7.0, 5.0, -9.0, 0.0, 5.0, 11.0, -1.0, 3.0, 13.0, 3.0, -4.0, 11.0, 10.0, 3.0, -9.0, 12.0, 9.0, 0.0, -6.0, -2.0, 13.0, -2.0, 6.0, 10.0, 13.0, -20.0, 12.0, -5.0, 9.0, 3.0, 8.0, 11.0, 6.0, -7.0, 5.0, -10.0, 12.0, 3.0, 10.0, -10.0, 13.0, 0.0, 12.0, 9.0, -3.0, 7.0, 2.0, 8.0, 7.0, -7.0, 7.0, 1.0, -5.0, 10.0, 9.0, 10.0, 8.0, 1.0, -4.0, 11.0, -13.0, 6.0, 11.0, -3.0, 1.0, 11.0, 6.0, -4.0, 13.0, -6.0, 12.0, -7.0, 9.0, 2.0, 11.0, 14.0, 9.0, 11.0, 322.0, 12.0, -9.0, 3.0, 9.0, 1.0, -7.0, 12.0, 9.0, 10.0, 6.0, 2.0, -3.0, 11.0, -8.0, 9.0, 3.0, 12.0, 11.0, 2.0, -10.0, 2.0, -9.0, 9.0, 13.0, -7.0, 13.0, -3.0, 12.0, 11.0, 9.0, -9.0, 4.0, 11.0, 4.0, -9.0, 9.0, 1.0, 12.0, -7.0, 9.0, -14.0, 13.0, 4.0, 12.0, 8.0, 9.0, 10.0, -12.0, -1.0, 9.0, 1.0, 6.0, 2.0, 11.0, 4.0, -2.0, 6.0, 7.0, 4.0, -2.0, 8.0, -11.0, 6.0, 12.0, -6.0, 12.0, 3.0, 6.0, 3.0, -7.0, 9.0, 10.0, 7.0, 13.0, -17.0, 12.0, 10.0, 2.0, -2.0, 5.0, -4.0, 2.0, 5.0, 12.0, -1.0, -5.0, 11.0, 10.0, 0.0, 12.0, 6.0, -3.0, 8.0, -4.0, 9.0, 2.0, 5.0, -3.0, 2.0, 11.0, -2.0, 13.0, -6.0, 10.0, 12.0, 7.0, 1.0, -5.0, -1.0, 6.0, 5.0, 5.0, 11.0, -16.0, 11.0, 9.0, 1.0, 13.0, -4.0, 5.0, 11.0, 14.0, -7.0, -3.0, 10.0, 9.0, -2.0, -2.0, -3.0, 4.0, 5.0, 9.0, -19.0, 13.0, 12.0, 9.0, 12.0, 8.0, -15.0, 10.0, 8.0, -12.0, 6.0, 13.0, 2.0, 11.0, 6.0, -4.0, 8.0, -8.0, 8.0, 7.0, 9.0, 13.0, -4.0, -3.0, -7.0, 9.0, 10.0, 3.0, -4.0, 9.0, 10.0, 0.0, 0.0, -2.0, 5.0, 12.0, 12.0, 7.0, -1.0, -3.0, 10.0, 5.0, 11.0, -11.0, 11.0, -9.0, 9.0, 4.0, -20.0, 13.0, 12.0, 10.0, 11.0, 13.0, -19.0, 10.0, 0.0, -3.0, 11.0, 7.0, -11.0, 4.0, 11.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22173727084005407, "mean_inference_ms": 1.223726472301683, "mean_action_processing_ms": 0.07508017800071022, "mean_env_wait_ms": 0.18011759268473138, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 27000, "agent_timesteps_total": 26919, "timers": {"sample_time_ms": 388.281, "sample_throughput": 13907.44, "learn_time_ms": 6651.09, "learn_throughput": 811.897, "update_time_ms": 11.727}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 437.3644104003906, "policy_loss": -0.025985540822148323, "vf_loss": 437.3887939453125, "vf_explained_var": 0.027935441583395004, "kl": 0.008364856243133545, "entropy": 0.8605945706367493, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 27000, "num_agent_steps_sampled": 26919, "num_steps_trained": 27000, "num_agent_steps_trained": 26919}, "done": false, "episodes_total": 513, "training_iteration": 5, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-42-10", "timestamp": 1626860530, "time_this_iter_s": 6.936130046844482, "time_total_s": 35.68816375732422, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 35.68816375732422, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 22.950000000000003, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.530092592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [316.0, 14.0, 12.0, 10.0, 12.0, -13.0, 13.0, 3.0, 12.0, 7.0, 7.0, -11.0, 5.0, -10.0, 12.0, 8.0, 0.0, 0.0, 12.0, 3.0, 14.0, -11.0, 2.0, 10.0, 11.0, 8.0, -13.0, 9.0, 2.0, 8.0, 12.0, -7.0, 7.0, 12.0, -17.0, 13.0, 13.0, -12.0, 5.0, 9.0, 3.0, 7.0, -3.0, 8.0, 9.0, 10.0, 12.0, -16.0, 3.0, -4.0, 3.0, 13.0, 14.0, -11.0, 2.0, 10.0, 13.0, -5.0, 10.0, -3.0, 3.0, 0.0, 13.0, -1.0, -1.0, 13.0, 12.0, -9.0, 13.0, -12.0, 12.0, 2.0, 13.0, 11.0, 6.0, -15.0, 5.0, 4.0, 13.0, -7.0, -8.0, 13.0, 2.0, 8.0, 8.0, 6.0, 5.0, -4.0, 13.0, 3.0, 9.0, -10.0, -6.0, 8.0, 10.0, 3.0, -12.0, 7.0, 7.0, 13.0, 13.0, -13.0, 10.0, 5.0, 13.0, 4.0, 6.0, -8.0, -7.0, 7.0, 13.0, 2.0, -19.0, 11.0, 10.0, 13.0, 11.0, -4.0, 11.0, -3.0, 13.0, 9.0, -3.0, -4.0, -7.0, 2.0, 13.0, 7.0, 1.0, 5.0, -4.0, 13.0, 9.0, 0.0, 9.0, -3.0, 9.0, 3.0, 9.0, -6.0, -8.0, 2.0, 13.0, 8.0, 0.0, 11.0, -4.0, 8.0, 8.0, -2.0, -4.0, 13.0, 11.0, 10.0, -3.0, -3.0, 4.0, 1.0, 11.0, -1.0, -7.0, 13.0, 10.0, -1.0, 7.0, 6.0, 13.0, -11.0, 11.0, 5.0, 11.0, -12.0, 9.0, 4.0, 12.0, -10.0, 4.0, -4.0, 2.0, 13.0, 11.0, -10.0, 9.0, 5.0, 9.0, 11.0, -8.0, 3.0, 4.0, 11.0, 12.0, -12.0, 2.0, 8.0, -8.0, 13.0, 13.0, -14.0, 9.0, 7.0, 12.0, 11.0, -9.0, 1.0, -9.0, 8.0, 12.0, 4.0, -19.0, 13.0, 10.0, 11.0, 13.0, -17.0, 9.0, 10.0, 10.0, 9.0, -7.0, 3.0, 6.0, 8.0, 11.0, -10.0, -4.0, 14.0, 3.0, 2.0, 13.0, -13.0, 13.0, 2.0, 13.0, 10.0, 8.0, -16.0, 4.0, 10.0, 3.0, -2.0, 2.0, -1.0, 12.0, 2.0, 9.0, -9.0, 4.0, 11.0, 13.0, 12.0, 9.0, -19.0, 4.0, 0.0, 13.0, -2.0, 3.0, 12.0, 12.0, -12.0, -12.0, 6.0, 10.0, 11.0, 6.0, 11.0, -7.0, 5.0, -2.0, 6.0, 13.0, -2.0, -4.0, -2.0, 8.0, 13.0, 13.0, -14.0, 6.0, 10.0, 5.0, 9.0, -7.0, 8.0, 3.0, 8.0, 13.0, -9.0, -12.0, 14.0, 6.0, 7.0, 12.0, -13.0, 5.0, 11.0, 5.0, 12.0, -5.0, 3.0, -7.0, 2.0, 11.0, 9.0, 0.0, -3.0, 10.0, 8.0, 13.0, -9.0, 11.0, 0.0, 12.0, 8.0, -7.0, 2.0, -2.0, 11.0, 13.0, -7.0, -1.0, 14.0, 12.0, -10.0, 13.0, -7.0, 1.0, 8.0, 9.0, 10.0, -5.0, 1.0, 8.0, -8.0, 11.0, 4.0, 4.0, 14.0, 10.0, -13.0, 12.0, -10.0, 13.0, 0.0, 14.0, 8.0, -14.0, 7.0, -10.0, 6.0, 13.0, 6.0, 0.0, 14.0, -11.0, 12.0, 13.0, -14.0, 13.0, 3.0, 13.0, 4.0, -8.0, 6.0, -9.0, 9.0, 13.0, 2.0, 3.0, -3.0, 3.0, 12.0, 13.0, -14.0, 11.0, 5.0, 2.0, 8.0, -2.0, 7.0, 9.0, 7.0, 13.0, -14.0, -2.0, -1.0, 6.0, 12.0, 6.0, 9.0, 10.0, -10.0, -3.0, 10.0, 0.0, 8.0, 13.0, 11.0, 0.0, -9.0, 5.0, 12.0, 12.0, -14.0, 8.0, -3.0, 13.0, -3.0, 13.0, -9.0, 10.0, 1.0, 6.0, 10.0, 12.0, -13.0, -14.0, 13.0, 12.0, 4.0, 7.0, -8.0, 11.0, 5.0, 4.0, 12.0, -9.0, 8.0, 3.0, 7.0, 12.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22136314021054737, "mean_inference_ms": 1.2123408214484277, "mean_action_processing_ms": 0.07444317394450345, "mean_env_wait_ms": 0.17969537061440188, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 32400, "agent_timesteps_total": 32319, "timers": {"sample_time_ms": 383.956, "sample_throughput": 14064.106, "learn_time_ms": 6648.484, "learn_throughput": 812.215, "update_time_ms": 11.665}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 126.3753890991211, "policy_loss": -0.03694017976522446, "vf_loss": 126.40994262695312, "vf_explained_var": 0.07499893009662628, "kl": 0.011813690885901451, "entropy": 0.8876304030418396, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 32400, "num_agent_steps_sampled": 32319, "num_steps_trained": 32400, "num_agent_steps_trained": 32319}, "done": false, "episodes_total": 621, "training_iteration": 6, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-42-17", "timestamp": 1626860537, "time_this_iter_s": 7.092691898345947, "time_total_s": 42.780855655670166, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 42.780855655670166, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 21.53, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 14.0, -8.0, -2.0, 12.0, -11.0, 12.0, 2.0, 14.0, -16.0, 5.0, 12.0, -7.0, 11.0, 1.0, 10.0, 6.0, 9.0, -4.0, 4.0, 11.0, -3.0, 10.0, -3.0, 10.0, -15.0, 11.0, 9.0, 0.0, 9.0, -6.0, 12.0, 11.0, 13.0, 0.0, -9.0, -7.0, 1.0, 8.0, 13.0, 13.0, -4.0, 1.0, 5.0, 13.0, 12.0, 0.0, -10.0, 11.0, 14.0, -10.0, 0.0, -12.0, 7.0, 8.0, 12.0, 13.0, -7.0, 0.0, 9.0, 3.0, 6.0, -4.0, 10.0, 13.0, -14.0, 11.0, 5.0, 11.0, -1.0, -3.0, 8.0, 11.0, -13.0, 10.0, 7.0, -2.0, -5.0, 11.0, 11.0, -1.0, 14.0, 7.0, -5.0, 12.0, -12.0, 11.0, 4.0, 5.0, -7.0, 9.0, 8.0, 5.0, 6.0, -7.0, 11.0, 11.0, 14.0, -6.0, -4.0, 11.0, 3.0, -3.0, 4.0, 14.0, -9.0, 1.0, 9.0, -10.0, 9.0, 10.0, 6.0, 11.0, 14.0, -16.0, 6.0, 8.0, 7.0, -1.0, 1.0, 14.0, -10.0, 4.0, 7.0, 6.0, 12.0, 7.0, -10.0, 12.0, 3.0, 9.0, -9.0, 11.0, 6.0, 7.0, -9.0, 11.0, -13.0, 8.0, 9.0, -2.0, 13.0, 10.0, -6.0, 0.0, 13.0, -4.0, 6.0, 10.0, 5.0, 7.0, -7.0, 13.0, -12.0, 6.0, 9.0, 11.0, 9.0, 0.0, -5.0, 12.0, 9.0, 6.0, -12.0, 11.0, -12.0, 12.0, 4.0, 7.0, -8.0, 10.0, 6.0, 1.0, 11.0, 6.0, -3.0, 13.0, 14.0, -5.0, -7.0, 9.0, -14.0, 12.0, 8.0, 13.0, -19.0, 9.0, 12.0, 10.0, 14.0, -1.0, -8.0, 13.0, 13.0, -8.0, -3.0, 10.0, 1.0, -2.0, 6.0, 14.0, -14.0, 9.0, 6.0, 4.0, 13.0, -6.0, 4.0, 14.0, 13.0, -7.0, -5.0, 9.0, -14.0, 13.0, 7.0, 12.0, -17.0, 9.0, 11.0, 0.0, 6.0, -4.0, 13.0, 13.0, 9.0, -7.0, 0.0, 13.0, -11.0, 5.0, 8.0, 8.0, -10.0, 6.0, 11.0, 11.0, 8.0, -14.0, 10.0, 10.0, 8.0, -12.0, 9.0, 12.0, 5.0, -2.0, 0.0, 14.0, 1.0, 10.0, -10.0, 3.0, 6.0, -4.0, 10.0, 13.0, 13.0, 0.0, -11.0, 9.0, 4.0, 12.0, -10.0, -2.0, 6.0, 1.0, 10.0, 0.0, 6.0, 11.0, -2.0, 13.0, 14.0, -8.0, -4.0, 13.0, -1.0, 11.0, -8.0, 13.0, -8.0, 3.0, 7.0, 8.0, 0.0, 10.0, -3.0, 7.0, 6.0, 10.0, -8.0, 11.0, 1.0, 7.0, -4.0, 14.0, 320.0, 10.0, 11.0, 12.0, 3.0, 4.0, -4.0, 11.0, 14.0, -13.0, 3.0, 3.0, -6.0, 11.0, 7.0, 10.0, -13.0, 6.0, 12.0, -17.0, 13.0, 12.0, 7.0, 12.0, 14.0, 6.0, -17.0, 9.0, 4.0, -4.0, 6.0, 13.0, -15.0, 8.0, 9.0, 6.0, -4.0, 4.0, 9.0, 11.0, 8.0, 10.0, -14.0, 8.0, -14.0, 12.0, 9.0, 11.0, -6.0, 9.0, 1.0, 5.0, -1.0, 0.0, 11.0, 11.0, 14.0, -3.0, -7.0, 10.0, -16.0, 12.0, 9.0, 14.0, 3.0, -13.0, 11.0, 13.0, 7.0, 5.0, -10.0, 7.0, 14.0, -12.0, 6.0, 7.0, 8.0, 11.0, -11.0, 13.0, -18.0, 9.0, 11.0, 11.0, 12.0, -6.0, -2.0, 10.0, 14.0, -8.0, -1.0, 8.0, 6.0, 4.0, -3.0, 14.0, 9.0, -4.0, -4.0, 4.0, -2.0, 3.0, 10.0, 4.0, 14.0, -9.0, 6.0, 9.0, -9.0, 11.0, 4.0, -2.0, -2.0, 13.0, 6.0, -7.0, 13.0, -2.0, 11.0, 7.0, 14.0, -8.0, 2.0, 7.0, 10.0, -10.0, 8.0, 14.0, -13.0, 7.0, 7.0, 9.0, 4.0, 7.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22134189170562907, "mean_inference_ms": 1.2045192073092201, "mean_action_processing_ms": 0.07400919356340963, "mean_env_wait_ms": 0.1791800616120108, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 37800, "agent_timesteps_total": 37719, "timers": {"sample_time_ms": 378.154, "sample_throughput": 14279.884, "learn_time_ms": 6641.457, "learn_throughput": 813.075, "update_time_ms": 11.61}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 240.60072326660156, "policy_loss": -0.03301199898123741, "vf_loss": 240.63156127929688, "vf_explained_var": 0.06776058673858643, "kl": 0.010995998047292233, "entropy": 0.9478013515472412, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 37800, "num_agent_steps_sampled": 37719, "num_steps_trained": 37800, "num_agent_steps_trained": 37719}, "done": false, "episodes_total": 729, "training_iteration": 7, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-42-24", "timestamp": 1626860544, "time_this_iter_s": 7.0363054275512695, "time_total_s": 49.817161083221436, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70204488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 49.817161083221436, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 21.38, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.305555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 5.326388888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, -1.0, 7.0, 9.0, -6.0, 14.0, 10.0, -3.0, 8.0, 9.0, -13.0, 11.0, 13.0, 7.0, -8.0, 3.0, -1.0, -1.0, 7.0, 10.0, -15.0, 9.0, 11.0, 10.0, -13.0, 8.0, 9.0, 11.0, 14.0, -2.0, 13.0, -10.0, -10.0, 4.0, 12.0, 9.0, 0.0, 14.0, 4.0, -3.0, 4.0, 8.0, 6.0, -3.0, 12.0, 12.0, -1.0, -8.0, -4.0, 4.0, 5.0, 10.0, -15.0, 12.0, 7.0, 11.0, -13.0, 12.0, 4.0, 12.0, 12.0, 12.0, -22.0, 13.0, -4.0, 6.0, 6.0, 7.0, -3.0, 11.0, -4.0, 11.0, -15.0, 13.0, 7.0, 10.0, 13.0, 1.0, 2.0, -1.0, 12.0, -5.0, 1.0, 7.0, 2.0, 13.0, 9.0, -9.0, 7.0, -14.0, 9.0, 13.0, 12.0, 11.0, -6.0, -2.0, -2.0, 7.0, 11.0, -1.0, -11.0, 4.0, 12.0, 10.0, 12.0, 2.0, -11.0, 12.0, 13.0, 10.0, -2.0, -6.0, 0.0, 1.0, 5.0, 9.0, -3.0, 8.0, 11.0, -1.0, 10.0, -11.0, 6.0, 10.0, 12.0, 13.0, 12.0, 319.0, 12.0, -16.0, 8.0, 11.0, -2.0, 11.0, -1.0, 7.0, -11.0, 14.0, 9.0, 3.0, 5.0, -10.0, 13.0, 7.0, -5.0, 0.0, 10.0, 10.0, -3.0, 11.0, 9.0, -2.0, -15.0, 13.0, 11.0, 6.0, 10.0, -1.0, -5.0, 11.0, 5.0, -7.0, 7.0, 10.0, -13.0, 14.0, 5.0, 9.0, -15.0, 14.0, 6.0, 10.0, 8.0, 2.0, -1.0, 6.0, -7.0, 2.0, 11.0, 9.0, -15.0, 8.0, 11.0, 11.0, 2.0, 13.0, -11.0, 11.0, 14.0, 4.0, -15.0, 12.0, -3.0, 13.0, 0.0, 5.0, -14.0, 10.0, 10.0, 9.0, -2.0, 11.0, 7.0, -1.0, 8.0, 2.0, -5.0, 10.0, -6.0, 5.0, 7.0, 9.0, -3.0, 12.0, 9.0, -3.0, -1.0, 10.0, 12.0, -6.0, 11.0, 6.0, 3.0, -5.0, -10.0, 7.0, 12.0, 6.0, -15.0, 6.0, 13.0, 11.0, 12.0, 5.0, 5.0, -7.0, 11.0, 5.0, -10.0, 9.0, -1.0, -3.0, 9.0, 10.0, -6.0, 11.0, 11.0, -1.0, 0.0, -8.0, 11.0, 12.0, 8.0, -9.0, 8.0, 8.0, 11.0, -11.0, 10.0, 5.0, -15.0, 9.0, 11.0, 10.0, 12.0, 320.0, 11.0, 12.0, 2.0, -7.0, 7.0, 13.0, -3.0, 3.0, 5.0, 10.0, -1.0, 6.0, 11.0, -1.0, 7.0, 9.0, -11.0, 10.0, 12.0, 0.0, -5.0, 8.0, -12.0, 12.0, 10.0, 5.0, -19.0, 14.0, 10.0, 10.0, 4.0, 11.0, -12.0, 12.0, 13.0, -5.0, -2.0, 9.0, -3.0, 7.0, 1.0, 10.0, 1.0, 7.0, -3.0, 10.0, 0.0, -3.0, 7.0, 11.0, 12.0, -3.0, 13.0, -7.0, -5.0, 6.0, 3.0, 11.0, -13.0, 13.0, 10.0, 5.0, -4.0, 13.0, 7.0, -1.0, 7.0, 5.0, -1.0, 4.0, 10.0, -11.0, 6.0, 10.0, 1.0, 8.0, 10.0, -4.0, 12.0, 9.0, -13.0, 7.0, 14.0, 1.0, 8.0, -8.0, 8.0, -6.0, 4.0, 9.0, -7.0, 13.0, 12.0, -3.0, 10.0, -12.0, 6.0, 11.0, 8.0, -1.0, 13.0, -5.0, 10.0, -15.0, 8.0, 12.0, 1.0, 13.0, -10.0, 11.0, 6.0, 5.0, 9.0, -5.0, 13.0, 1.0, 7.0, -6.0, -5.0, 11.0, 5.0, 4.0, 0.0, 8.0, -4.0, 11.0, 11.0, 10.0, -16.0, 10.0, 12.0, 13.0, -3.0, -7.0, -7.0, 8.0, 4.0, 10.0, -1.0, 8.0, -4.0, 12.0, -14.0, 14.0, 4.0, 11.0, 13.0, -4.0, -4.0, 10.0, -4.0, 7.0, 6.0, 6.0, -13.0, 12.0, 4.0, 12.0, 8.0, 11.0, -16.0, 12.0, 13.0, 8.0, 13.0, -19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22144320053773742, "mean_inference_ms": 1.2034688432848666, "mean_action_processing_ms": 0.07370962403761364, "mean_env_wait_ms": 0.17910032673646756, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 43200, "agent_timesteps_total": 43119, "timers": {"sample_time_ms": 375.38, "sample_throughput": 14385.437, "learn_time_ms": 6654.921, "learn_throughput": 811.43, "update_time_ms": 11.377}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 450.4947204589844, "policy_loss": -0.028381703421473503, "vf_loss": 450.52130126953125, "vf_explained_var": 0.07945530116558075, "kl": 0.009011947549879551, "entropy": 0.8773723840713501, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 43200, "num_agent_steps_sampled": 43119, "num_steps_trained": 43200, "num_agent_steps_trained": 43119}, "done": false, "episodes_total": 837, "training_iteration": 8, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-42-31", "timestamp": 1626860551, "time_this_iter_s": 7.208563327789307, "time_total_s": 57.02572441101074, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 57.02572441101074, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 21.209999999999997, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 14.0, 4.0, 3.0, 6.0, 0.0, 12.0, -3.0, 6.0, -5.0, 2.0, 12.0, 12.0, 12.0, 12.0, 318.0, 9.0, 8.0, -6.0, 4.0, 12.0, 2.0, 10.0, -9.0, 6.0, 5.0, -7.0, 11.0, 9.0, -4.0, 10.0, 0.0, -4.0, 8.0, 7.0, 4.0, 14.0, -5.0, 8.0, -2.0, 3.0, 11.0, -5.0, 6.0, -8.0, 7.0, 10.0, 6.0, -1.0, 8.0, 6.0, 2.0, 14.0, -6.0, 8.0, -1.0, 6.0, 11.0, -12.0, 10.0, 11.0, 9.0, 7.0, -12.0, 9.0, 13.0, 6.0, -13.0, 10.0, 3.0, -5.0, 7.0, 4.0, 6.0, -8.0, 13.0, 10.0, 6.0, 11.0, -12.0, 2.0, 13.0, 10.0, -10.0, 11.0, -1.0, -5.0, 10.0, 13.0, -1.0, -2.0, 5.0, -9.0, 12.0, 10.0, 2.0, 13.0, 12.0, 4.0, -14.0, 14.0, -20.0, 10.0, 11.0, 0.0, 10.0, -8.0, 13.0, 0.0, 12.0, 10.0, -7.0, -9.0, 14.0, -1.0, 11.0, 7.0, -12.0, 9.0, 11.0, 3.0, 4.0, -4.0, 12.0, 0.0, 12.0, 10.0, -7.0, 14.0, 7.0, 3.0, -9.0, -11.0, 4.0, 10.0, 12.0, -14.0, 10.0, 8.0, 11.0, -12.0, 13.0, 11.0, 3.0, 6.0, 7.0, -9.0, 11.0, 3.0, -10.0, 10.0, 12.0, 0.0, 12.0, -8.0, 11.0, 10.0, 5.0, 13.0, -13.0, -8.0, 10.0, 6.0, 7.0, 10.0, -14.0, 9.0, 10.0, 5.0, 9.0, -1.0, 2.0, 11.0, 7.0, 12.0, -15.0, -2.0, 13.0, 3.0, 1.0, 12.0, 1.0, 4.0, -2.0, 4.0, 13.0, -14.0, 12.0, 8.0, 12.0, 9.0, -14.0, -12.0, 13.0, 10.0, 4.0, 9.0, 5.0, -3.0, 4.0, 7.0, 8.0, -13.0, 13.0, 13.0, 8.0, 11.0, -17.0, 7.0, 13.0, 8.0, -13.0, 14.0, -6.0, -5.0, 12.0, 3.0, -8.0, 8.0, 12.0, 4.0, 9.0, 12.0, -10.0, -2.0, 5.0, 3.0, 9.0, 14.0, -7.0, 13.0, -5.0, -6.0, 9.0, 1.0, 11.0, 12.0, 12.0, 8.0, -17.0, 5.0, -3.0, 11.0, 2.0, 5.0, -12.0, 12.0, 10.0, 2.0, 11.0, -8.0, 10.0, 3.0, 13.0, 12.0, -13.0, -7.0, 14.0, -3.0, 11.0, 9.0, 1.0, 11.0, -6.0, -13.0, 10.0, 10.0, 8.0, 7.0, 10.0, 11.0, -13.0, 12.0, -11.0, 11.0, 3.0, 13.0, 3.0, 8.0, -9.0, -14.0, 12.0, 6.0, 11.0, 12.0, 8.0, 1.0, -6.0, 12.0, 9.0, -7.0, 1.0, 5.0, 13.0, 7.0, -10.0, -1.0, -1.0, 13.0, 4.0, 11.0, 13.0, 3.0, -12.0, -4.0, 13.0, 5.0, 1.0, 13.0, -6.0, 10.0, -2.0, 5.0, 2.0, -4.0, 12.0, -6.0, 10.0, 0.0, 11.0, -3.0, 9.0, 5.0, 4.0, 9.0, -1.0, 11.0, -4.0, -3.0, -2.0, 9.0, 11.0, 13.0, 5.0, 13.0, -16.0, -2.0, 13.0, 2.0, 2.0, 12.0, -19.0, 11.0, 11.0, 9.0, 9.0, -4.0, 1.0, 9.0, 13.0, 11.0, -18.0, 10.0, 13.0, -8.0, 0.0, 7.0, -11.0, 8.0, 11.0, -2.0, 7.0, -2.0, 12.0, 7.0, 13.0, 5.0, -10.0, 13.0, -14.0, 4.0, 12.0, 1.0, 6.0, -4.0, 12.0, -3.0, 11.0, 11.0, -4.0, 7.0, 8.0, 12.0, -12.0, 14.0, -12.0, 0.0, 13.0, 7.0, -8.0, 7.0, 9.0, 6.0, 7.0, -9.0, 11.0, -6.0, 4.0, 10.0, 7.0, -10.0, 13.0, 2.0, 10.0, 7.0, -7.0, 9.0, 6.0, -20.0, 11.0, 13.0, 11.0, 10.0, -5.0, 6.0, 4.0, 11.0, 9.0, 5.0, -10.0, -15.0, 11.0, 11.0, 8.0, -4.0, -2.0, 9.0, 12.0, 10.0, 13.0, 12.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22120559316302468, "mean_inference_ms": 1.2007199100178472, "mean_action_processing_ms": 0.0734083877103143, "mean_env_wait_ms": 0.17900558801318736, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 48600, "agent_timesteps_total": 48519, "timers": {"sample_time_ms": 373.561, "sample_throughput": 14455.458, "learn_time_ms": 6637.329, "learn_throughput": 813.58, "update_time_ms": 11.268}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 237.5817413330078, "policy_loss": -0.034523360431194305, "vf_loss": 237.6139678955078, "vf_explained_var": 0.11680500209331512, "kl": 0.011530178599059582, "entropy": 0.8308782577514648, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 48600, "num_agent_steps_sampled": 48519, "num_steps_trained": 48600, "num_agent_steps_trained": 48519}, "done": false, "episodes_total": 945, "training_iteration": 9, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-42-38", "timestamp": 1626860558, "time_this_iter_s": 6.952569246292114, "time_total_s": 63.978293657302856, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 63.978293657302856, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 21.95, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 13.0, 0.0, 3.0, -4.0, 6.0, 6.0, 7.0, -10.0, 13.0, 5.0, 7.0, 8.0, 1.0, -7.0, 13.0, 8.0, 12.0, -13.0, 8.0, 12.0, -8.0, -2.0, 13.0, -1.0, 10.0, -1.0, 7.0, -2.0, 0.0, 4.0, 13.0, 14.0, 8.0, 3.0, -10.0, 11.0, -9.0, 9.0, 4.0, -18.0, 13.0, 8.0, 12.0, -3.0, -2.0, 7.0, 13.0, 11.0, 12.0, -16.0, 8.0, 13.0, -8.0, 6.0, 4.0, -4.0, 14.0, 1.0, 4.0, 11.0, -16.0, 7.0, 13.0, 14.0, 6.0, 11.0, -16.0, 13.0, 5.0, -10.0, 7.0, -1.0, 4.0, 7.0, 5.0, 9.0, 9.0, -16.0, 13.0, 14.0, 6.0, 2.0, -7.0, 14.0, -15.0, 6.0, 10.0, -14.0, 13.0, 5.0, 11.0, 12.0, 9.0, -13.0, 7.0, 8.0, 12.0, 8.0, -13.0, 14.0, -7.0, 1.0, 7.0, -1.0, 7.0, 6.0, 3.0, 9.0, 3.0, -10.0, 13.0, -3.0, 8.0, 5.0, 5.0, 7.0, 6.0, -2.0, 4.0, -1.0, 10.0, 8.0, -2.0, 9.0, -13.0, 6.0, 13.0, 10.0, 13.0, -18.0, 10.0, 0.0, -4.0, 9.0, 10.0, 8.0, 6.0, 8.0, -7.0, 9.0, -5.0, 4.0, 7.0, 13.0, 11.0, 8.0, -17.0, -1.0, 5.0, 3.0, 8.0, -10.0, 13.0, 11.0, 1.0, 12.0, -6.0, -3.0, 12.0, 13.0, 11.0, -13.0, 4.0, 0.0, 5.0, 3.0, 7.0, 4.0, -1.0, 8.0, 4.0, 8.0, 10.0, -14.0, 11.0, 12.0, 0.0, 3.0, 0.0, -4.0, 9.0, 3.0, 7.0, 5.0, -1.0, 5.0, 6.0, -1.0, -2.0, 10.0, 8.0, 14.0, 4.0, -9.0, 6.0, 14.0, -10.0, 4.0, 7.0, -15.0, 14.0, 9.0, 7.0, 11.0, -15.0, 6.0, 13.0, 12.0, -4.0, 7.0, 0.0, -1.0, 3.0, 7.0, 6.0, -6.0, 13.0, 0.0, 8.0, 13.0, 9.0, -18.0, 11.0, 8.0, 10.0, -7.0, 4.0, 13.0, 6.0, -12.0, 8.0, 13.0, -4.0, 2.0, 4.0, 13.0, 8.0, -17.0, 11.0, -3.0, 11.0, 5.0, 2.0, 12.0, 7.0, -10.0, 6.0, -8.0, 14.0, 2.0, 7.0, 8.0, -10.0, 4.0, 13.0, 11.0, 12.0, 2.0, -10.0, 14.0, -6.0, 0.0, 7.0, -8.0, 13.0, 8.0, 2.0, 13.0, -15.0, 8.0, 9.0, 13.0, 11.0, 10.0, -19.0, 12.0, -9.0, 7.0, 5.0, -11.0, 13.0, 5.0, 8.0, 11.0, 9.0, 12.0, -17.0, 9.0, 11.0, -11.0, 6.0, 14.0, -7.0, 3.0, 5.0, -1.0, 4.0, 6.0, 6.0, 11.0, -14.0, 7.0, 11.0, 10.0, 6.0, -12.0, 11.0, -1.0, 2.0, 8.0, 6.0, -9.0, 13.0, 6.0, 5.0, -2.0, 6.0, 12.0, -1.0, 12.0, 12.0, 1.0, -10.0, 12.0, -14.0, 6.0, 11.0, -1.0, 13.0, 8.0, -5.0, -3.0, 6.0, 4.0, 8.0, 11.0, 11.0, -12.0, 5.0, 14.0, 3.0, 10.0, -12.0, 8.0, 12.0, -2.0, -3.0, 10.0, -8.0, 12.0, 1.0, 9.0, -5.0, 5.0, 6.0, 14.0, 6.0, -10.0, 5.0, -1.0, 8.0, 1.0, 7.0, -5.0, 7.0, 0.0, 13.0, 11.0, -1.0, 0.0, 5.0, 14.0, -11.0, 11.0, 1.0, -9.0, 13.0, 5.0, 6.0, 11.0, -5.0, 3.0, 6.0, 13.0, 8.0, 7.0, -13.0, 14.0, -11.0, 5.0, 7.0, -4.0, 6.0, 5.0, 8.0, 12.0, 6.0, -16.0, 13.0, 7.0, 13.0, -9.0, 4.0, 14.0, 2.0, -11.0, 10.0, -5.0, 13.0, 4.0, 3.0, 10.0, -10.0, 4.0, 11.0, 13.0, 11.0, -1.0, -8.0, 12.0, 5.0, 4.0, -6.0, -6.0, 7.0, 6.0, 8.0, 11.0, -8.0, -1.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22138253082993326, "mean_inference_ms": 1.1984509758221404, "mean_action_processing_ms": 0.07324047792224178, "mean_env_wait_ms": 0.17913333058174097, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 54000, "agent_timesteps_total": 53919, "timers": {"sample_time_ms": 371.146, "sample_throughput": 14549.532, "learn_time_ms": 6648.604, "learn_throughput": 812.201, "update_time_ms": 11.416}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 32.02789306640625, "policy_loss": -0.08829235285520554, "vf_loss": 32.11296463012695, "vf_explained_var": 0.16003409028053284, "kl": 0.016094161197543144, "entropy": 0.8693889379501343, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 54000, "num_agent_steps_sampled": 53919, "num_steps_trained": 54000, "num_agent_steps_trained": 53919}, "done": false, "episodes_total": 1053, "training_iteration": 10, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-42-46", "timestamp": 1626860566, "time_this_iter_s": 7.198098182678223, "time_total_s": 71.17639183998108, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 71.17639183998108, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 21.550000000000004, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, -8.0, 11.0, 12.0, 12.0, 13.0, -8.0, -2.0, 7.0, 3.0, -8.0, 13.0, 3.0, 2.0, 12.0, -2.0, -5.0, 11.0, -3.0, 12.0, 8.0, 12.0, -15.0, 10.0, 4.0, -4.0, 8.0, 7.0, 9.0, -18.0, 12.0, 12.0, 7.0, -3.0, 4.0, 7.0, 8.0, 11.0, -4.0, 0.0, -1.0, 3.0, 0.0, 13.0, 6.0, -1.0, 11.0, -1.0, 6.0, 8.0, -6.0, 7.0, 7.0, -11.0, 8.0, 11.0, 7.0, -4.0, 3.0, 9.0, 4.0, 3.0, 10.0, -2.0, 2.0, 4.0, -3.0, 12.0, 8.0, 13.0, -13.0, 7.0, -2.0, 9.0, 3.0, 5.0, 5.0, 1.0, 10.0, -1.0, -1.0, 6.0, -2.0, 12.0, 8.0, 9.0, -9.0, 7.0, -9.0, 5.0, 7.0, 12.0, -4.0, -2.0, 10.0, 11.0, 0.0, 4.0, -2.0, 13.0, 6.0, 10.0, -7.0, 6.0, -6.0, 9.0, 9.0, 3.0, 6.0, 1.0, 13.0, -5.0, 8.0, 7.0, -4.0, 4.0, 12.0, 10.0, 3.0, -10.0, -2.0, -7.0, 11.0, 13.0, 5.0, -14.0, 13.0, 11.0, -1.0, 8.0, -4.0, 12.0, 4.0, -5.0, 5.0, 11.0, 3.0, -6.0, 8.0, 10.0, 2.0, -12.0, 12.0, 13.0, 8.0, 10.0, -10.0, 7.0, 9.0, 13.0, -6.0, -1.0, -11.0, 7.0, 12.0, 7.0, 8.0, -1.0, 12.0, -4.0, -12.0, 11.0, 5.0, 11.0, -7.0, 4.0, 7.0, 11.0, 5.0, -14.0, 11.0, 13.0, 8.0, -3.0, 12.0, -2.0, 3.0, 7.0, -7.0, 12.0, 10.0, 14.0, -10.0, 1.0, 12.0, -16.0, 6.0, 13.0, 3.0, 4.0, 9.0, -1.0, 6.0, 7.0, -5.0, 7.0, 4.0, 5.0, -5.0, 11.0, -9.0, 6.0, 7.0, 11.0, -8.0, 1.0, 10.0, 12.0, 5.0, 7.0, -4.0, 7.0, 7.0, 14.0, 10.0, -16.0, 10.0, 9.0, 3.0, -7.0, 9.0, 2.0, 10.0, -6.0, 2.0, 6.0, -5.0, 12.0, 4.0, 8.0, -9.0, 12.0, 3.0, -7.0, 10.0, 9.0, -8.0, 8.0, 2.0, 13.0, 8.0, -15.0, 11.0, 11.0, 7.0, 14.0, -12.0, 6.0, -7.0, 7.0, 7.0, 8.0, 8.0, -5.0, 0.0, 12.0, 0.0, 8.0, -4.0, 11.0, 9.0, -9.0, 5.0, 10.0, 5.0, -5.0, 2.0, 13.0, 5.0, -16.0, 13.0, 13.0, 2.0, 5.0, -4.0, 12.0, 13.0, -7.0, 3.0, 6.0, 5.0, 4.0, -7.0, 13.0, 10.0, -4.0, 12.0, -3.0, 2.0, 11.0, -5.0, 7.0, 6.0, 13.0, 6.0, -10.0, -12.0, 6.0, 12.0, 9.0, -6.0, -3.0, 13.0, 11.0, 3.0, -10.0, 10.0, 12.0, 7.0, -13.0, 11.0, 10.0, -8.0, -1.0, 11.0, 13.0, -8.0, -1.0, 11.0, 13.0, 6.0, 4.0, -7.0, 12.0, 14.0, 5.0, -9.0, 5.0, -3.0, 6.0, 5.0, 7.0, -2.0, -6.0, 12.0, 11.0, 2.0, 5.0, -3.0, 11.0, 12.0, 12.0, 5.0, -14.0, -2.0, -2.0, 6.0, 13.0, 10.0, -5.0, 12.0, -2.0, 9.0, 10.0, -4.0, 0.0, 12.0, 12.0, -12.0, 3.0, -5.0, 12.0, 3.0, 5.0, 8.0, -13.0, 13.0, 7.0, 2.0, 7.0, -6.0, 12.0, 9.0, 14.0, -9.0, 1.0, 6.0, -15.0, 11.0, 13.0, 6.0, -14.0, 13.0, 10.0, -2.0, 11.0, -3.0, 9.0, 8.0, 9.0, 5.0, -7.0, 7.0, -11.0, 8.0, 11.0, -10.0, 2.0, 11.0, 12.0, 4.0, -13.0, 12.0, 12.0, 12.0, 7.0, 2.0, -6.0, 8.0, -15.0, 9.0, 13.0, 6.0, 3.0, 7.0, -1.0, 2.0, 5.0, -3.0, 11.0, 8.0, 12.0, -6.0, 1.0, -5.0, 6.0, 3.0, 11.0, 8.0, -3.0, 12.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22095414837825286, "mean_inference_ms": 1.1941791653948057, "mean_action_processing_ms": 0.0730699485616918, "mean_env_wait_ms": 0.17919429996211955, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 59400, "agent_timesteps_total": 59319, "timers": {"sample_time_ms": 361.62, "sample_throughput": 14932.808, "learn_time_ms": 6633.943, "learn_throughput": 813.995, "update_time_ms": 11.235}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 29.402996063232422, "policy_loss": -0.08797568827867508, "vf_loss": 29.487791061401367, "vf_explained_var": 0.14424216747283936, "kl": 0.015914157032966614, "entropy": 0.8547011017799377, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 59400, "num_agent_steps_sampled": 59319, "num_steps_trained": 59400, "num_agent_steps_trained": 59319}, "done": false, "episodes_total": 1161, "training_iteration": 11, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-42-53", "timestamp": 1626860573, "time_this_iter_s": 7.054131031036377, "time_total_s": 78.23052287101746, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 78.23052287101746, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 21.536363636363635, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 5.0, 11.0, 4.0, 6.0, 12.0, -9.0, 6.0, 12.0, 10.0, -6.0, -1.0, 7.0, 12.0, -6.0, 2.0, -9.0, 12.0, 6.0, 6.0, 12.0, 0.0, 10.0, -7.0, 6.0, 10.0, 11.0, -12.0, 11.0, 14.0, -17.0, 7.0, 9.0, -4.0, 9.0, 1.0, 0.0, 0.0, 11.0, 4.0, 13.0, 9.0, 9.0, -16.0, 13.0, 12.0, -7.0, -3.0, -7.0, 8.0, 8.0, 6.0, -6.0, 2.0, 9.0, 10.0, -8.0, 12.0, 1.0, 10.0, 13.0, 7.0, -7.0, 2.0, -4.0, 13.0, 12.0, -6.0, -7.0, 5.0, 12.0, 5.0, 7.0, 11.0, -9.0, 6.0, 10.0, 9.0, -8.0, 4.0, 12.0, 9.0, 11.0, -17.0, 12.0, 10.0, -4.0, -3.0, -8.0, 8.0, 4.0, 11.0, 3.0, 12.0, -7.0, 7.0, 12.0, 3.0, 12.0, -12.0, 13.0, 12.0, -5.0, -5.0, 13.0, 9.0, 10.0, -17.0, 13.0, 12.0, -5.0, -5.0, -4.0, 1.0, 11.0, 7.0, -2.0, 12.0, -5.0, 10.0, -5.0, 13.0, -3.0, 10.0, 12.0, 13.0, 4.0, -14.0, 13.0, 5.0, 12.0, -15.0, -7.0, 8.0, 7.0, 7.0, 9.0, 12.0, 1.0, -7.0, -2.0, 5.0, 12.0, 0.0, -8.0, 12.0, 3.0, 8.0, 7.0, 12.0, -10.0, 6.0, -1.0, 10.0, -4.0, 10.0, 12.0, 7.0, 7.0, -11.0, -5.0, 7.0, 4.0, 9.0, -8.0, 5.0, 10.0, 8.0, -1.0, 12.0, 0.0, 4.0, 4.0, 14.0, -9.0, 6.0, -5.0, 11.0, 8.0, 1.0, 9.0, 8.0, 11.0, -13.0, -1.0, 7.0, 1.0, 8.0, 12.0, 14.0, -12.0, 1.0, 7.0, 10.0, 9.0, -11.0, 5.0, 12.0, -9.0, 7.0, 9.0, -6.0, 3.0, 9.0, 10.0, 13.0, -8.0, 0.0, -6.0, 7.0, 10.0, 4.0, 12.0, 12.0, -5.0, -4.0, 5.0, 1.0, -2.0, 11.0, -2.0, 13.0, 5.0, -1.0, 12.0, 10.0, 12.0, -19.0, 13.0, 12.0, -4.0, -6.0, 9.0, 12.0, 1.0, -7.0, 14.0, 13.0, -14.0, 2.0, -8.0, 12.0, 5.0, 6.0, 14.0, 9.0, -5.0, -3.0, -7.0, 5.0, 11.0, 6.0, 11.0, 14.0, -13.0, 3.0, 10.0, -5.0, 13.0, -3.0, -8.0, 6.0, 7.0, 10.0, -1.0, 10.0, 11.0, -5.0, 12.0, 13.0, -12.0, 2.0, 9.0, 12.0, 8.0, -14.0, -1.0, 6.0, 6.0, 4.0, 12.0, 7.0, 5.0, -9.0, 14.0, 11.0, -4.0, -6.0, -8.0, 12.0, 6.0, 5.0, -5.0, 6.0, 8.0, 6.0, 5.0, -8.0, 9.0, 9.0, -1.0, 11.0, 0.0, 5.0, -6.0, 8.0, 11.0, 2.0, 6.0, 7.0, 11.0, -9.0, -2.0, 10.0, 12.0, -5.0, 12.0, 12.0, 0.0, -9.0, -7.0, 8.0, 8.0, 6.0, 9.0, 12.0, 0.0, -6.0, 13.0, 0.0, 12.0, -10.0, 11.0, 11.0, 2.0, -9.0, 12.0, 12.0, 7.0, -16.0, 3.0, 5.0, 11.0, -4.0, 14.0, -2.0, 12.0, -9.0, 12.0, 13.0, -4.0, -6.0, 10.0, 10.0, 12.0, -17.0, 8.0, 11.0, 7.0, -11.0, 13.0, 9.0, 0.0, -7.0, 11.0, 9.0, -12.0, 7.0, -8.0, 11.0, 4.0, 8.0, 6.0, 10.0, -13.0, 12.0, 9.0, -4.0, 0.0, 10.0, 12.0, 12.0, -7.0, -2.0, 8.0, -11.0, 13.0, 5.0, -3.0, 8.0, 5.0, 5.0, 13.0, 6.0, 11.0, -15.0, 10.0, 7.0, -6.0, 4.0, 13.0, -15.0, 12.0, 5.0, -4.0, 12.0, 4.0, 3.0, -6.0, 0.0, 10.0, 11.0, 12.0, 11.0, 10.0, -18.0, -8.0, 11.0, 0.0, 12.0, 8.0, 4.0, 6.0, -3.0, -4.0, 7.0, 11.0, 1.0, 13.0, 13.0, -10.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21994251654480465, "mean_inference_ms": 1.1930935091600676, "mean_action_processing_ms": 0.07302543317317073, "mean_env_wait_ms": 0.17937940566081922, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 64800, "agent_timesteps_total": 64746, "timers": {"sample_time_ms": 361.285, "sample_throughput": 14946.646, "learn_time_ms": 6644.604, "learn_throughput": 812.69, "update_time_ms": 11.336}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 31.702655792236328, "policy_loss": -0.08048103004693985, "vf_loss": 31.780126571655273, "vf_explained_var": 0.17584611475467682, "kl": 0.015065672807395458, "entropy": 0.7813547849655151, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 64800, "num_agent_steps_sampled": 64746, "num_steps_trained": 64800, "num_agent_steps_trained": 64746}, "done": false, "episodes_total": 1269, "training_iteration": 12, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-00", "timestamp": 1626860580, "time_this_iter_s": 7.251058101654053, "time_total_s": 85.48158097267151, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 85.48158097267151, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 20.75, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 6.0, 4.0, -9.0, 11.0, 8.0, 4.0, -8.0, 7.0, 3.0, 8.0, -3.0, 14.0, 12.0, -12.0, 1.0, 7.0, 14.0, 6.0, -12.0, 12.0, -2.0, -7.0, 12.0, 13.0, -4.0, 7.0, -1.0, 6.0, 14.0, 12.0, -17.0, 12.0, 8.0, -9.0, 4.0, -2.0, 11.0, 11.0, -5.0, -4.0, 3.0, 6.0, 10.0, 12.0, 0.0, 7.0, -4.0, 5.0, -7.0, 8.0, 9.0, 13.0, 8.0, -14.0, 8.0, 6.0, 6.0, -9.0, 12.0, 13.0, -2.0, 1.0, 3.0, -9.0, 14.0, -3.0, 13.0, 8.0, 3.0, -3.0, 7.0, 2.0, -3.0, 6.0, 10.0, 8.0, 8.0, -11.0, 10.0, 8.0, -2.0, 10.0, -1.0, 14.0, 9.0, 6.0, -14.0, 8.0, 13.0, -13.0, 7.0, 8.0, 1.0, -4.0, 10.0, 8.0, -2.0, 7.0, 2.0, 11.0, 7.0, 6.0, -9.0, 10.0, 5.0, 1.0, -1.0, 14.0, -4.0, 7.0, -2.0, 12.0, 13.0, 6.0, -16.0, 6.0, 1.0, -2.0, 10.0, 7.0, 14.0, 13.0, -19.0, 9.0, 3.0, -2.0, 5.0, 10.0, 0.0, -5.0, 10.0, 14.0, 11.0, -3.0, -7.0, 12.0, -11.0, 7.0, 7.0, 6.0, 4.0, 9.0, -4.0, 7.0, 12.0, 5.0, -9.0, 10.0, 8.0, -3.0, 0.0, 10.0, 9.0, -9.0, 5.0, 9.0, 12.0, 6.0, -12.0, 11.0, 5.0, 5.0, -6.0, 12.0, 4.0, 5.0, -6.0, 8.0, 11.0, 6.0, -10.0, 8.0, 5.0, 5.0, -3.0, 6.0, 5.0, 9.0, -5.0, 14.0, -5.0, 3.0, 3.0, 13.0, 8.0, 2.0, -8.0, 11.0, -2.0, 9.0, -3.0, 8.0, -4.0, 7.0, 4.0, -6.0, 11.0, -1.0, 11.0, 13.0, 0.0, -4.0, 6.0, 14.0, -3.0, 2.0, 2.0, 12.0, 7.0, 6.0, -10.0, 11.0, -3.0, -4.0, 11.0, 9.0, -5.0, 0.0, 11.0, 11.0, 9.0, 12.0, -17.0, 5.0, 3.0, -2.0, 9.0, 8.0, -3.0, 7.0, 3.0, 12.0, 9.0, -17.0, 11.0, 13.0, -1.0, 6.0, -3.0, 5.0, 13.0, 8.0, -11.0, 10.0, 12.0, -9.0, 2.0, 10.0, -1.0, 11.0, -5.0, 9.0, -7.0, 9.0, 4.0, 10.0, 12.0, -10.0, 3.0, 12.0, 4.0, 8.0, -9.0, 8.0, 7.0, 8.0, -8.0, 12.0, 12.0, 9.0, -18.0, 8.0, 5.0, -8.0, 10.0, 8.0, -4.0, 2.0, 9.0, 7.0, 8.0, 6.0, -6.0, 12.0, -5.0, 10.0, -2.0, 9.0, 12.0, -1.0, -5.0, 10.0, 8.0, -5.0, 2.0, 5.0, 3.0, -4.0, 11.0, 12.0, 9.0, 10.0, -16.0, 11.0, 4.0, -7.0, 7.0, 12.0, 0.0, -5.0, 8.0, 13.0, 6.0, 7.0, -11.0, 8.0, 9.0, 9.0, -11.0, 7.0, 4.0, -8.0, 12.0, 8.0, 11.0, 7.0, -11.0, 13.0, 9.0, 0.0, -7.0, 11.0, 9.0, -12.0, 7.0, -8.0, 11.0, 4.0, 8.0, 6.0, 10.0, -13.0, 12.0, 9.0, -4.0, 0.0, 10.0, 12.0, 12.0, -7.0, -2.0, 8.0, -11.0, 13.0, 5.0, -3.0, 8.0, 5.0, 5.0, 13.0, 6.0, 11.0, -15.0, 10.0, 7.0, -6.0, 4.0, 13.0, -15.0, 12.0, 5.0, -4.0, 12.0, 4.0, 3.0, -6.0, 0.0, 10.0, 11.0, 12.0, 11.0, 10.0, -18.0, -8.0, 11.0, 0.0, 12.0, 8.0, 4.0, 6.0, -3.0, -4.0, 7.0, 11.0, 1.0, 13.0, 13.0, -10.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21927451665831024, "mean_inference_ms": 1.189948965939349, "mean_action_processing_ms": 0.07295568639709715, "mean_env_wait_ms": 0.17893223489404825, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 70200, "agent_timesteps_total": 70119, "timers": {"sample_time_ms": 360.895, "sample_throughput": 14962.791, "learn_time_ms": 6636.619, "learn_throughput": 813.667, "update_time_ms": 11.385}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 29.814359664916992, "policy_loss": -0.08632750064134598, "vf_loss": 29.897268295288086, "vf_explained_var": 0.1628788262605667, "kl": 0.017096450552344322, "entropy": 0.8603664636611938, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 70200, "num_agent_steps_sampled": 70119, "num_steps_trained": 70200, "num_agent_steps_trained": 70119}, "done": false, "episodes_total": 1350, "training_iteration": 13, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-07", "timestamp": 1626860587, "time_this_iter_s": 6.937866449356079, "time_total_s": 92.41944742202759, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 92.41944742202759, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 21.32, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 369.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.444444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 335.0}, "policy_reward_mean": {"learned": 5.361111111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 369.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 6.0, -8.0, 12.0, 12.0, 9.0, -18.0, 12.0, 12.0, 14.0, -10.0, -1.0, 13.0, 10.0, -1.0, -7.0, 11.0, 0.0, -8.0, 12.0, 8.0, -12.0, 12.0, 7.0, 8.0, -1.0, 3.0, 5.0, 1.0, 11.0, -5.0, 8.0, 8.0, 6.0, 11.0, -10.0, -9.0, 11.0, 6.0, 7.0, 11.0, 9.0, 12.0, -17.0, 8.0, 12.0, -8.0, 3.0, 6.0, 1.0, -4.0, 12.0, 11.0, 4.0, -13.0, 13.0, 7.0, 9.0, -12.0, 11.0, 8.0, 7.0, -6.0, 6.0, -3.0, 7.0, 8.0, 3.0, 12.0, 8.0, -17.0, 12.0, 7.0, 9.0, 6.0, -7.0, 3.0, -2.0, 8.0, 6.0, 12.0, -7.0, -2.0, 12.0, -17.0, 13.0, 6.0, 13.0, 12.0, 6.0, 6.0, -9.0, 4.0, -3.0, 7.0, 7.0, 5.0, 10.0, -12.0, 12.0, 12.0, 6.0, -14.0, 11.0, 6.0, 7.0, 5.0, -3.0, 4.0, -3.0, 9.0, 5.0, -2.0, 6.0, 11.0, 0.0, 14.0, -13.0, 7.0, 7.0, -4.0, 14.0, 3.0, 2.0, 9.0, 11.0, -8.0, 3.0, 11.0, -11.0, 11.0, 4.0, 7.0, 0.0, 11.0, -3.0, 12.0, 9.0, -16.0, 10.0, 8.0, 7.0, 7.0, -7.0, 13.0, -1.0, 7.0, -4.0, 11.0, 12.0, 12.0, 322.0, 11.0, -2.0, 0.0, 6.0, 4.0, -4.0, 7.0, 8.0, 5.0, 7.0, -9.0, 12.0, -7.0, 12.0, 7.0, 3.0, 12.0, 9.0, -11.0, 5.0, 9.0, -11.0, 12.0, 5.0, -3.0, 14.0, -2.0, 6.0, 8.0, 9.0, -15.0, 13.0, 11.0, 9.0, -13.0, 8.0, 4.0, 12.0, -9.0, 8.0, 12.0, -13.0, 5.0, 11.0, 13.0, 6.0, 12.0, -16.0, 11.0, 9.0, -13.0, 8.0, 5.0, -12.0, 9.0, 13.0, -2.0, -7.0, 12.0, 12.0, 10.0, 8.0, 12.0, -15.0, 7.0, 8.0, 4.0, -4.0, 4.0, -4.0, 11.0, 4.0, -2.0, 1.0, 4.0, 12.0, -10.0, 10.0, 12.0, 3.0, 12.0, 14.0, -14.0, 3.0, 9.0, 1.0, -8.0, 13.0, 12.0, -7.0, 7.0, 3.0, 6.0, 12.0, -13.0, 10.0, 6.0, 9.0, 6.0, -6.0, 8.0, 11.0, -9.0, 5.0, 7.0, 6.0, -10.0, 12.0, -14.0, 9.0, 7.0, 13.0, 7.0, -8.0, 7.0, 9.0, 3.0, -2.0, 7.0, 7.0, 13.0, 8.0, -7.0, 1.0, 12.0, 10.0, -17.0, 10.0, 5.0, 12.0, -9.0, 7.0, 6.0, 6.0, -4.0, 7.0, 12.0, -1.0, 13.0, -9.0, 11.0, 9.0, 12.0, -17.0, 11.0, -2.0, 9.0, -3.0, 9.0, -2.0, 6.0, 2.0, 12.0, -15.0, 12.0, 6.0, 11.0, 12.0, 11.0, 335.0, 5.0, 9.0, 11.0, -10.0, 4.0, 12.0, -9.0, 8.0, 8.0, 4.0, -9.0, 12.0, -5.0, 6.0, 12.0, 2.0, 12.0, 14.0, -13.0, 2.0, 2.0, 11.0, 8.0, -6.0, 11.0, 6.0, -9.0, 7.0, 11.0, 9.0, -18.0, 13.0, 8.0, 14.0, -1.0, -6.0, 13.0, 11.0, 10.0, -19.0, 9.0, 8.0, -13.0, 11.0, 12.0, 11.0, 10.0, -18.0, 7.0, 3.0, 9.0, -4.0, 9.0, 11.0, -7.0, 2.0, 10.0, 2.0, -9.0, 12.0, 10.0, 10.0, -17.0, 12.0, 6.0, 8.0, 10.0, -9.0, -2.0, 9.0, -4.0, 12.0, 9.0, 5.0, 7.0, -6.0, 11.0, 10.0, -19.0, 13.0, 6.0, 8.0, 9.0, -8.0, 9.0, -7.0, 10.0, 3.0, 11.0, 1.0, -6.0, 9.0, 4.0, 12.0, -5.0, 4.0, 10.0, 6.0, 10.0, -11.0, 10.0, 8.0, -3.0, 0.0, 11.0, 5.0, 3.0, -4.0, 7.0, 6.0, -5.0, 7.0, 6.0, -7.0, 5.0, 11.0, 9.0, 12.0, -8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21986843017681426, "mean_inference_ms": 1.1876488655002864, "mean_action_processing_ms": 0.07267457429707631, "mean_env_wait_ms": 0.17892065475326469, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 75600, "agent_timesteps_total": 75519, "timers": {"sample_time_ms": 352.164, "sample_throughput": 15333.752, "learn_time_ms": 6633.721, "learn_throughput": 814.023, "update_time_ms": 11.384}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 505.37213134765625, "policy_loss": -0.041513364762067795, "vf_loss": 505.41192626953125, "vf_explained_var": 0.08128909021615982, "kl": 0.008504830300807953, "entropy": 0.7790340185165405, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 75600, "num_agent_steps_sampled": 75519, "num_steps_trained": 75600, "num_agent_steps_trained": 75519}, "done": false, "episodes_total": 1458, "training_iteration": 14, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-14", "timestamp": 1626860594, "time_this_iter_s": 7.173282146453857, "time_total_s": 99.59272956848145, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 99.59272956848145, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 21.189999999999998, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 3.0, 1.0, 11.0, -8.0, 7.0, 5.0, 11.0, -10.0, 14.0, 0.0, 11.0, 2.0, -10.0, 12.0, 11.0, 12.0, 2.0, 3.0, -2.0, -9.0, 1.0, 12.0, 11.0, 6.0, 13.0, -14.0, 10.0, -11.0, 9.0, 4.0, 13.0, -4.0, 6.0, 2.0, 11.0, -9.0, 14.0, 6.0, 4.0, -14.0, 14.0, 4.0, 11.0, 12.0, -11.0, 10.0, 4.0, -1.0, 5.0, 0.0, 11.0, -3.0, 2.0, 7.0, 9.0, -7.0, 14.0, -2.0, 10.0, 3.0, -1.0, 1.0, 12.0, 0.0, 2.0, 10.0, 3.0, 8.0, -10.0, 4.0, 13.0, 7.0, 9.0, -12.0, 11.0, 1.0, -4.0, 9.0, 9.0, -4.0, 6.0, 1.0, 12.0, -1.0, -6.0, 9.0, 13.0, -14.0, 13.0, 5.0, 11.0, -17.0, 11.0, 9.0, 12.0, 11.0, 9.0, -4.0, -1.0, -2.0, -1.0, 8.0, 10.0, 4.0, 9.0, -10.0, 12.0, 2.0, -11.0, 11.0, 13.0, -6.0, 4.0, 10.0, 7.0, -10.0, 4.0, 9.0, 12.0, 10.0, 8.0, -15.0, 12.0, 8.0, -10.0, 5.0, 12.0, -1.0, 3.0, 7.0, 6.0, 11.0, -14.0, 8.0, 10.0, 7.0, 14.0, -17.0, 11.0, -2.0, -2.0, 6.0, 13.0, 0.0, 5.0, 8.0, 2.0, 7.0, -10.0, 10.0, 8.0, -12.0, 10.0, 11.0, 6.0, 3.0, -5.0, 9.0, 8.0, 14.0, 4.0, -14.0, 11.0, 7.0, 12.0, -10.0, 6.0, -11.0, 8.0, 9.0, 9.0, -3.0, -3.0, 9.0, 12.0, -2.0, 7.0, -1.0, 11.0, -15.0, 10.0, 8.0, 12.0, 5.0, 14.0, -3.0, -1.0, -1.0, -7.0, 11.0, 12.0, 12.0, 4.0, 10.0, -11.0, 4.0, 4.0, -6.0, 13.0, -14.0, 14.0, 3.0, 12.0, 6.0, -6.0, 6.0, 9.0, -3.0, 5.0, 11.0, 2.0, -7.0, 8.0, 9.0, 5.0, 11.0, 9.0, -16.0, 11.0, -6.0, -4.0, 12.0, 13.0, -1.0, 1.0, 3.0, 12.0, 6.0, -2.0, 2.0, 9.0, -8.0, 14.0, 1.0, 8.0, 1.0, -6.0, 12.0, 8.0, 11.0, 5.0, 3.0, -4.0, 8.0, -2.0, -3.0, 12.0, -11.0, 9.0, 5.0, 12.0, 1.0, -8.0, 10.0, 12.0, 7.0, 7.0, 2.0, -1.0, 3.0, 10.0, -5.0, 7.0, -10.0, 14.0, 8.0, 3.0, -2.0, -1.0, 5.0, 13.0, 13.0, 4.0, -12.0, 10.0, -2.0, -5.0, 9.0, 13.0, -17.0, 14.0, 5.0, 13.0, 1.0, -1.0, 8.0, 7.0, 12.0, 6.0, -14.0, 11.0, -7.0, 10.0, -1.0, 13.0, -10.0, 14.0, -2.0, 13.0, 5.0, -8.0, 7.0, 11.0, -2.0, 7.0, 10.0, 0.0, 5.0, 2.0, -3.0, 11.0, 12.0, 9.0, -19.0, 13.0, -1.0, -2.0, 12.0, 6.0, -5.0, 5.0, 5.0, 10.0, 0.0, 2.0, 0.0, 13.0, -9.0, 7.0, 5.0, 12.0, -14.0, 11.0, 6.0, 12.0, -3.0, 7.0, 4.0, 7.0, -2.0, -5.0, 9.0, 13.0, -8.0, 7.0, 10.0, 6.0, -2.0, -3.0, 7.0, 13.0, 8.0, 5.0, 9.0, -7.0, 6.0, -12.0, 11.0, 10.0, -9.0, 10.0, 4.0, 10.0, 7.0, -10.0, 10.0, 8.0, -2.0, 7.0, 1.0, 9.0, -10.0, 9.0, 5.0, 11.0, -10.0, 3.0, 11.0, 11.0, 0.0, -6.0, 12.0, 9.0, -2.0, 4.0, 1.0, 12.0, 10.0, -14.0, 8.0, 11.0, -13.0, 14.0, 2.0, 12.0, -3.0, -4.0, 11.0, 11.0, 0.0, -3.0, 10.0, 8.0, -7.0, 2.0, 7.0, 13.0, 1.0, 14.0, -12.0, 12.0, 0.0, -7.0, 9.0, 13.0, -2.0, 5.0, 4.0, 8.0, 8.0, 1.0, -3.0, 9.0, 7.0, 14.0, -17.0, 11.0, 0.0, -4.0, 6.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.220230157786662, "mean_inference_ms": 1.1862315330301514, "mean_action_processing_ms": 0.07260499400782511, "mean_env_wait_ms": 0.17891980103797775, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 81000, "agent_timesteps_total": 80919, "timers": {"sample_time_ms": 351.174, "sample_throughput": 15376.978, "learn_time_ms": 6650.122, "learn_throughput": 812.015, "update_time_ms": 11.406}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 28.58958625793457, "policy_loss": -0.08262936770915985, "vf_loss": 28.668766021728516, "vf_explained_var": 0.1997097134590149, "kl": 0.01726982556283474, "entropy": 0.822485089302063, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 81000, "num_agent_steps_sampled": 80919, "num_steps_trained": 81000, "num_agent_steps_trained": 80919}, "done": false, "episodes_total": 1566, "training_iteration": 15, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-21", "timestamp": 1626860601, "time_this_iter_s": 7.083940029144287, "time_total_s": 106.67666959762573, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702068c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 106.67666959762573, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 21.74, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 12.0, -15.0, 12.0, 10.0, 13.0, 11.0, -19.0, -8.0, 9.0, 11.0, 3.0, -11.0, 8.0, 10.0, 8.0, -6.0, 11.0, 2.0, 8.0, 6.0, 14.0, -8.0, 3.0, -12.0, 6.0, 10.0, 11.0, 0.0, -7.0, 10.0, 12.0, 12.0, 10.0, 1.0, -8.0, 10.0, -6.0, -2.0, 13.0, -17.0, 13.0, 11.0, 8.0, -9.0, 10.0, 6.0, 8.0, 12.0, 13.0, 3.0, -13.0, 6.0, 13.0, -2.0, -2.0, -11.0, 6.0, 12.0, 8.0, 12.0, -5.0, 11.0, -3.0, 9.0, -7.0, 6.0, 7.0, 9.0, 14.0, -10.0, 2.0, 8.0, 7.0, 10.0, -10.0, 0.0, -9.0, 11.0, 13.0, -1.0, 12.0, -9.0, 13.0, 12.0, 13.0, -1.0, -9.0, -11.0, 7.0, 11.0, 8.0, 11.0, -10.0, 11.0, 3.0, 5.0, 10.0, -8.0, 8.0, 10.0, 13.0, -2.0, -6.0, -10.0, 13.0, 10.0, 2.0, 6.0, 11.0, 9.0, -11.0, 10.0, 12.0, -13.0, 6.0, 10.0, 13.0, -16.0, 8.0, -8.0, 3.0, 7.0, 13.0, 3.0, -1.0, 6.0, 7.0, 9.0, 12.0, -14.0, 8.0, 12.0, -4.0, -3.0, 10.0, 13.0, -19.0, 10.0, 11.0, 3.0, -5.0, 10.0, 7.0, -10.0, 9.0, 10.0, 6.0, 4.0, 13.0, 4.0, -6.0, 11.0, -7.0, 4.0, 7.0, 11.0, 4.0, 13.0, -13.0, -4.0, 13.0, 0.0, 6.0, 12.0, 13.0, 6.0, -16.0, -9.0, 8.0, 13.0, 3.0, -11.0, 8.0, 10.0, 8.0, 4.0, -7.0, 6.0, 12.0, 10.0, 13.0, 6.0, -14.0, -10.0, 3.0, 10.0, 12.0, 13.0, -3.0, 8.0, -3.0, -2.0, 11.0, 10.0, -4.0, 11.0, -4.0, 12.0, -4.0, 6.0, 14.0, 12.0, -17.0, 5.0, -7.0, 10.0, 7.0, 12.0, 11.0, 332.0, 12.0, 12.0, 12.0, -1.0, -8.0, 6.0, -15.0, 11.0, 13.0, 6.0, -5.0, 10.0, 4.0, 11.0, 11.0, -15.0, 8.0, 6.0, 12.0, 5.0, -8.0, 1.0, -8.0, 10.0, 12.0, -1.0, 12.0, 10.0, -6.0, 9.0, 13.0, 8.0, -15.0, 9.0, 12.0, -14.0, 8.0, -10.0, 4.0, 10.0, 11.0, 4.0, 9.0, 4.0, -2.0, -3.0, 10.0, 6.0, 2.0, 11.0, 12.0, -16.0, 8.0, 5.0, 10.0, 13.0, -13.0, 5.0, -3.0, 6.0, 7.0, -6.0, 9.0, 6.0, 6.0, 10.0, 13.0, -11.0, 3.0, -8.0, 0.0, 12.0, 11.0, 4.0, -6.0, 11.0, 6.0, -1.0, 4.0, 10.0, 2.0, 10.0, 8.0, -6.0, 3.0, -14.0, 11.0, 10.0, 8.0, -10.0, 6.0, 11.0, 8.0, 11.0, -12.0, 12.0, 4.0, 13.0, 13.0, 2.0, -13.0, -10.0, 13.0, 12.0, 0.0, 3.0, 9.0, -8.0, 11.0, -1.0, 12.0, -4.0, 8.0, 9.0, 8.0, 3.0, -5.0, 10.0, 5.0, 12.0, -12.0, 9.0, 10.0, 2.0, -6.0, 11.0, 13.0, 4.0, -13.0, 10.0, 12.0, -15.0, 8.0, 11.0, -4.0, 10.0, -2.0, -12.0, 9.0, 10.0, 8.0, 8.0, 6.0, 11.0, -10.0, 10.0, 13.0, -11.0, 3.0, 6.0, 7.0, 10.0, -8.0, 2.0, 7.0, -2.0, 8.0, 8.0, -1.0, -5.0, 13.0, 11.0, 11.0, 8.0, -15.0, 3.0, -11.0, 10.0, 13.0, 4.0, -7.0, 10.0, 8.0, -3.0, 11.0, 6.0, 1.0, 9.0, 12.0, -14.0, 8.0, -13.0, 10.0, 5.0, 13.0, 7.0, -13.0, 12.0, 9.0, -5.0, 11.0, -4.0, 13.0, 11.0, 7.0, 4.0, -7.0, -10.0, 12.0, 8.0, 5.0, 13.0, 8.0, 3.0, -9.0, -1.0, 10.0, -7.0, 13.0, 5.0, 13.0, -14.0, 11.0, -3.0, 5.0, 10.0, 3.0, 6.0, 11.0, 6.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.220500595436342, "mean_inference_ms": 1.1857628900947108, "mean_action_processing_ms": 0.07258222979998964, "mean_env_wait_ms": 0.17904023708036443, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 86400, "agent_timesteps_total": 86319, "timers": {"sample_time_ms": 350.966, "sample_throughput": 15386.11, "learn_time_ms": 6657.752, "learn_throughput": 811.085, "update_time_ms": 11.208}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 89.3141860961914, "policy_loss": -0.05187522992491722, "vf_loss": 89.36327362060547, "vf_explained_var": 0.14395356178283691, "kl": 0.013922568410634995, "entropy": 0.8343191146850586, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 86400, "num_agent_steps_sampled": 86319, "num_steps_trained": 86400, "num_agent_steps_trained": 86319}, "done": false, "episodes_total": 1674, "training_iteration": 16, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-29", "timestamp": 1626860609, "time_this_iter_s": 7.162919998168945, "time_total_s": 113.83958959579468, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 113.83958959579468, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 21.39, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 6.0, 10.0, -7.0, 0.0, 11.0, 7.0, -3.0, 13.0, -2.0, 10.0, -6.0, 13.0, -15.0, 4.0, 13.0, -9.0, 9.0, 3.0, 12.0, 2.0, 6.0, -5.0, 12.0, 12.0, 9.0, -9.0, 3.0, 7.0, -9.0, 8.0, 9.0, -11.0, 10.0, 11.0, 5.0, 2.0, 7.0, 10.0, -4.0, 12.0, 6.0, -7.0, 4.0, 14.0, -12.0, 7.0, 6.0, 7.0, 14.0, -14.0, 8.0, -12.0, 11.0, 7.0, 9.0, 13.0, 2.0, -8.0, 8.0, 12.0, -9.0, 4.0, 8.0, 1.0, 9.0, -2.0, 7.0, -6.0, 8.0, 7.0, 6.0, 14.0, -4.0, -6.0, 11.0, 12.0, 7.0, 7.0, -11.0, 6.0, 6.0, 11.0, -8.0, 8.0, 3.0, -8.0, 12.0, -2.0, 6.0, 10.0, 1.0, -1.0, 3.0, 6.0, 7.0, 8.0, -6.0, 5.0, 8.0, 9.0, 5.0, -7.0, 8.0, 8.0, 8.0, -11.0, 10.0, 3.0, -7.0, 6.0, 13.0, 8.0, -12.0, 11.0, 8.0, 12.0, 3.0, -8.0, 8.0, 12.0, 6.0, -4.0, 1.0, -1.0, -7.0, 13.0, 10.0, 4.0, 7.0, 10.0, -6.0, 2.0, -3.0, 6.0, 10.0, 9.0, 8.0, 1.0, -3.0, 0.0, 4.0, 6.0, 5.0, 9.0, 2.0, 12.0, -8.0, 6.0, 3.0, 10.0, -4.0, 11.0, -4.0, -2.0, 10.0, -3.0, 4.0, 4.0, 10.0, -8.0, 6.0, 4.0, 13.0, -10.0, 7.0, 11.0, 7.0, 9.0, 8.0, -12.0, 10.0, -4.0, -3.0, 12.0, 10.0, 4.0, 5.0, 13.0, -7.0, 8.0, 10.0, -8.0, 5.0, 10.0, 6.0, 5.0, -6.0, -5.0, 2.0, 5.0, 13.0, 1.0, 10.0, -7.0, 11.0, 6.0, 4.0, -8.0, 13.0, 13.0, -1.0, -8.0, 11.0, 12.0, -19.0, 11.0, 11.0, 12.0, 3.0, 9.0, -9.0, 6.0, 8.0, -5.0, 6.0, 13.0, 5.0, 5.0, -8.0, 13.0, -17.0, 8.0, 11.0, 5.0, 8.0, 13.0, -11.0, -8.0, 7.0, 8.0, 8.0, 13.0, 7.0, -7.0, 2.0, 12.0, -13.0, 7.0, 9.0, -7.0, 11.0, 13.0, -2.0, 12.0, 2.0, -6.0, 7.0, 13.0, 6.0, -2.0, -2.0, 12.0, -19.0, 13.0, 9.0, 9.0, 12.0, 3.0, -9.0, -1.0, 12.0, -5.0, 9.0, 13.0, -4.0, -3.0, 9.0, -1.0, 7.0, 1.0, 8.0, 5.0, 4.0, 7.0, -1.0, 12.0, 2.0, -7.0, 8.0, 11.0, 4.0, -3.0, 3.0, 11.0, 0.0, 12.0, -8.0, -13.0, 14.0, 1.0, 13.0, -13.0, 12.0, 7.0, 9.0, 13.0, -1.0, -4.0, 7.0, -1.0, 5.0, 8.0, 3.0, -7.0, 11.0, 5.0, 6.0, 3.0, 12.0, -4.0, 4.0, 10.0, 5.0, -6.0, 6.0, 14.0, 3.0, -6.0, 4.0, 8.0, 7.0, -7.0, 7.0, 5.0, 0.0, -2.0, 12.0, 14.0, -16.0, 8.0, 9.0, -6.0, 3.0, 6.0, 12.0, -4.0, 1.0, 11.0, 7.0, 4.0, 6.0, 8.0, -3.0, 11.0, 7.0, 2.0, -5.0, -12.0, 3.0, 12.0, 12.0, -2.0, -1.0, 11.0, 7.0, -7.0, 7.0, 3.0, 12.0, 11.0, -1.0, -5.0, 10.0, -6.0, 1.0, 12.0, 8.0, 10.0, 5.0, -6.0, 6.0, -3.0, 12.0, -7.0, 13.0, 14.0, -7.0, -5.0, 13.0, 0.0, -4.0, 13.0, 6.0, -4.0, 2.0, 9.0, 8.0, 3.0, 3.0, -3.0, 12.0, 12.0, 7.0, -5.0, 1.0, 14.0, 322.0, 9.0, 11.0, 11.0, -7.0, 7.0, 4.0, -12.0, 7.0, 10.0, 10.0, 12.0, 6.0, 3.0, -6.0, -6.0, 10.0, 6.0, 5.0, -6.0, 7.0, 7.0, 7.0, 1.0, 7.0, -4.0, 11.0, 6.0, 8.0, -5.0, 6.0, 14.0, -17.0, 13.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2208134803654408, "mean_inference_ms": 1.1853361575820307, "mean_action_processing_ms": 0.07256061886666704, "mean_env_wait_ms": 0.17906675766941535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 91800, "agent_timesteps_total": 91719, "timers": {"sample_time_ms": 351.758, "sample_throughput": 15351.446, "learn_time_ms": 6655.886, "learn_throughput": 811.312, "update_time_ms": 11.169}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 236.85118103027344, "policy_loss": -0.028768369928002357, "vf_loss": 236.87782287597656, "vf_explained_var": 0.10183974355459213, "kl": 0.010532880201935768, "entropy": 0.7945961356163025, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 91800, "num_agent_steps_sampled": 91719, "num_steps_trained": 91800, "num_agent_steps_trained": 91719}, "done": false, "episodes_total": 1782, "training_iteration": 17, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-36", "timestamp": 1626860616, "time_this_iter_s": 7.032248497009277, "time_total_s": 120.87183809280396, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 120.87183809280396, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 22.381818181818183, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 13.0, 8.0, -7.0, 10.0, 2.0, 12.0, -9.0, 6.0, 13.0, -2.0, -2.0, -1.0, 7.0, 6.0, 3.0, 6.0, 11.0, 9.0, -11.0, 13.0, 7.0, 2.0, -7.0, 13.0, 12.0, -20.0, 10.0, 10.0, -5.0, 3.0, 7.0, 322.0, 13.0, 12.0, 9.0, 12.0, 3.0, 6.0, -6.0, 7.0, 9.0, -13.0, 12.0, 12.0, -6.0, 3.0, 6.0, 8.0, 10.0, -9.0, 6.0, 13.0, -1.0, -10.0, 13.0, 14.0, 12.0, -3.0, -8.0, 12.0, -3.0, 4.0, 2.0, 8.0, 12.0, -10.0, 5.0, 14.0, 10.0, -14.0, 5.0, 13.0, -5.0, 12.0, -5.0, 11.0, -9.0, 7.0, 6.0, -11.0, 11.0, 12.0, 3.0, 0.0, 3.0, 11.0, 1.0, 10.0, -2.0, 12.0, -5.0, 13.0, -4.0, 1.0, 5.0, -2.0, 13.0, -7.0, 11.0, 14.0, 8.0, -14.0, 7.0, 3.0, 8.0, -1.0, 5.0, -1.0, 10.0, 3.0, 3.0, 7.0, -2.0, 4.0, 6.0, 13.0, -9.0, 7.0, 4.0, 9.0, 10.0, -1.0, -3.0, 12.0, -2.0, 8.0, -3.0, 3.0, 14.0, -14.0, 12.0, 12.0, 5.0, -10.0, 8.0, 5.0, 10.0, 12.0, -12.0, 6.0, 12.0, 3.0, -6.0, 5.0, 13.0, 0.0, -3.0, -2.0, 4.0, 0.0, 13.0, 13.0, 10.0, -6.0, -2.0, 13.0, -7.0, 8.0, 1.0, 6.0, -6.0, 8.0, 7.0, 10.0, -7.0, 3.0, 9.0, 14.0, 10.0, -1.0, -8.0, 12.0, -2.0, 6.0, -1.0, 6.0, 11.0, -9.0, 7.0, 12.0, 4.0, -9.0, 8.0, 12.0, 10.0, -20.0, 13.0, 13.0, 10.0, 4.0, -12.0, -15.0, 11.0, 11.0, 8.0, 11.0, -12.0, 4.0, 12.0, 6.0, -3.0, 11.0, 1.0, 12.0, -2.0, 6.0, -1.0, 4.0, 7.0, -7.0, 11.0, 14.0, 8.0, -15.0, 8.0, 8.0, 12.0, 12.0, -17.0, 0.0, 11.0, 9.0, -5.0, -5.0, 10.0, 3.0, 7.0, -1.0, 7.0, 5.0, 4.0, 2.0, 12.0, -2.0, 3.0, 13.0, -1.0, 5.0, -2.0, -5.0, 13.0, -5.0, 12.0, 9.0, 9.0, -7.0, 4.0, 6.0, 9.0, -12.0, 12.0, 11.0, -3.0, 5.0, 2.0, 7.0, 14.0, 4.0, -10.0, 12.0, -6.0, 1.0, 8.0, 6.0, 11.0, 1.0, -3.0, 13.0, -6.0, 0.0, 8.0, 6.0, 14.0, -8.0, 3.0, 10.0, -8.0, 7.0, 6.0, 12.0, -1.0, -8.0, 12.0, 13.0, 11.0, 2.0, -11.0, 1.0, 11.0, 7.0, -4.0, -1.0, 7.0, 1.0, 8.0, 6.0, 10.0, -13.0, 12.0, 12.0, 5.0, 9.0, -11.0, 4.0, 13.0, 4.0, -6.0, 3.0, 6.0, -2.0, 8.0, 5.0, -1.0, -1.0, 12.0, -1.0, 10.0, 9.0, -3.0, 8.0, 12.0, 9.0, -14.0, 13.0, 10.0, -14.0, 6.0, 4.0, -3.0, 12.0, 2.0, 14.0, -8.0, 1.0, 8.0, 8.0, -9.0, 3.0, 13.0, 12.0, 10.0, -14.0, 7.0, 2.0, 8.0, -7.0, 12.0, 12.0, -4.0, 6.0, 1.0, 3.0, 11.0, 9.0, -8.0, 7.0, 5.0, -5.0, 8.0, 14.0, 11.0, -8.0, -2.0, 12.0, -1.0, 10.0, -6.0, 8.0, 10.0, 5.0, -8.0, 10.0, 10.0, 5.0, -10.0, 0.0, 11.0, -6.0, 10.0, 13.0, -5.0, 1.0, 6.0, 8.0, -4.0, 5.0, 6.0, 8.0, 4.0, -5.0, 8.0, 3.0, 11.0, -11.0, 12.0, 13.0, -3.0, 3.0, 2.0, 5.0, 14.0, -15.0, 11.0, 12.0, 2.0, -10.0, 11.0, 9.0, -3.0, -3.0, 12.0, 11.0, -4.0, 9.0, -1.0, 9.0, 11.0, -14.0, 9.0, 8.0, -7.0, 7.0, 7.0, 9.0, -2.0, 12.0, -4.0, 13.0, -2.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22098051126861018, "mean_inference_ms": 1.185551719320652, "mean_action_processing_ms": 0.0726249862985249, "mean_env_wait_ms": 0.179322284512238, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 97200, "agent_timesteps_total": 97119, "timers": {"sample_time_ms": 351.575, "sample_throughput": 15359.448, "learn_time_ms": 6653.048, "learn_throughput": 811.658, "update_time_ms": 11.234}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 113.26918029785156, "policy_loss": -0.03777569904923439, "vf_loss": 113.3041763305664, "vf_explained_var": 0.17871521413326263, "kl": 0.013865694403648376, "entropy": 0.754855751991272, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 97200, "num_agent_steps_sampled": 97119, "num_steps_trained": 97200, "num_agent_steps_trained": 97119}, "done": false, "episodes_total": 1890, "training_iteration": 18, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-43", "timestamp": 1626860623, "time_this_iter_s": 7.169030666351318, "time_total_s": 128.04086875915527, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 128.04086875915527, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 20.89, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.203703703703702, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.550925925925926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, -2.0, 5.0, 11.0, 3.0, 14.0, -1.0, -1.0, 14.0, -8.0, 7.0, 2.0, 8.0, 0.0, 2.0, 5.0, -5.0, 3.0, 4.0, 13.0, -3.0, 10.0, 2.0, 6.0, 10.0, -11.0, 5.0, 11.0, 6.0, 9.0, -8.0, 8.0, -9.0, 7.0, 5.0, 12.0, 4.0, 14.0, 7.0, -10.0, 9.0, 6.0, 1.0, -1.0, 13.0, 14.0, 316.0, 11.0, 13.0, -8.0, 0.0, 10.0, 12.0, 9.0, -9.0, 3.0, 13.0, 6.0, 4.0, -8.0, 10.0, 8.0, 7.0, -10.0, 13.0, -7.0, -2.0, 11.0, -9.0, 9.0, 2.0, 13.0, 13.0, 2.0, 3.0, -3.0, 8.0, 13.0, -12.0, 6.0, -2.0, 8.0, 2.0, 7.0, -5.0, 10.0, 5.0, 5.0, 10.0, -7.0, 5.0, 8.0, 5.0, -5.0, 7.0, 8.0, -8.0, 8.0, 3.0, 12.0, -4.0, 14.0, 10.0, -5.0, 9.0, -13.0, 11.0, 9.0, 10.0, 9.0, -16.0, 12.0, -2.0, 6.0, 2.0, 9.0, 11.0, 11.0, 8.0, -15.0, 14.0, -1.0, 6.0, -4.0, 5.0, 0.0, 6.0, 4.0, -1.0, 4.0, 1.0, 11.0, 0.0, 12.0, -8.0, 11.0, 13.0, 6.0, 4.0, -7.0, 5.0, 6.0, 11.0, -7.0, 8.0, -7.0, 2.0, 12.0, -4.0, 14.0, -6.0, 11.0, 14.0, 0.0, -3.0, 4.0, 9.0, -7.0, 12.0, 1.0, 2.0, -5.0, 7.0, 11.0, 10.0, 12.0, 1.0, -8.0, 13.0, -18.0, 11.0, 9.0, 10.0, -4.0, 4.0, 5.0, -9.0, 9.0, 4.0, 11.0, -10.0, 13.0, 0.0, 12.0, 14.0, 1.0, -4.0, 4.0, 11.0, 12.0, 2.0, -10.0, 4.0, 8.0, -9.0, 12.0, 5.0, 13.0, -16.0, 13.0, 13.0, 7.0, 1.0, -5.0, 13.0, 6.0, -14.0, 10.0, -14.0, 9.0, 8.0, 12.0, 0.0, 14.0, 4.0, -3.0, 14.0, -7.0, 4.0, 5.0, 12.0, 13.0, -1.0, -9.0, 12.0, -1.0, -8.0, 12.0, -9.0, 12.0, 9.0, 3.0, 14.0, -11.0, 4.0, 8.0, 9.0, 14.0, -15.0, 7.0, -7.0, 12.0, -2.0, 12.0, -7.0, 10.0, 5.0, 7.0, 12.0, 6.0, -5.0, 2.0, 11.0, 10.0, -16.0, 10.0, -1.0, 12.0, -8.0, 12.0, -4.0, 8.0, 10.0, 1.0, 9.0, -11.0, 5.0, 12.0, 7.0, 5.0, -4.0, 7.0, -2.0, 13.0, 1.0, 3.0, -12.0, 11.0, 5.0, 11.0, 14.0, -4.0, 6.0, -1.0, 12.0, 13.0, -6.0, -4.0, 11.0, -7.0, -1.0, 12.0, -11.0, 14.0, 0.0, 12.0, 14.0, -12.0, 9.0, 4.0, 12.0, 7.0, 5.0, -9.0, 8.0, 5.0, -9.0, 11.0, -11.0, 13.0, 8.0, 5.0, 13.0, -16.0, 11.0, 7.0, 6.0, 14.0, -11.0, 6.0, 6.0, -2.0, 4.0, 7.0, -11.0, 14.0, 0.0, 12.0, 13.0, 6.0, 6.0, -10.0, 4.0, 0.0, 5.0, 6.0, -6.0, 12.0, -1.0, 10.0, -7.0, 13.0, 0.0, 9.0, 14.0, -13.0, 6.0, 9.0, -4.0, 9.0, 6.0, 4.0, 8.0, -1.0, -1.0, 9.0, -5.0, 14.0, 4.0, 2.0, 14.0, -9.0, 9.0, 1.0, 11.0, 10.0, -3.0, -3.0, 0.0, 7.0, -2.0, 10.0, 8.0, 12.0, 4.0, -9.0, 11.0, 6.0, 2.0, -3.0, 9.0, 14.0, -19.0, 11.0, 11.0, -7.0, -1.0, 12.0, 11.0, 13.0, -18.0, 9.0, 12.0, -12.0, 10.0, 5.0, 9.0, 13.0, 4.0, -11.0, 0.0, -4.0, 10.0, 9.0, -2.0, 8.0, 8.0, 1.0, 14.0, -16.0, 10.0, 7.0, 9.0, -1.0, 1.0, 6.0, -6.0, 9.0, -1.0, 13.0, 5.0, 14.0, 3.0, -7.0, 14.0, 12.0, 1.0, -12.0, 10.0, 8.0, 6.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22105975183911436, "mean_inference_ms": 1.1846923179499715, "mean_action_processing_ms": 0.07260235675456156, "mean_env_wait_ms": 0.179276739619293, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 102600, "agent_timesteps_total": 102519, "timers": {"sample_time_ms": 350.738, "sample_throughput": 15396.091, "learn_time_ms": 6664.343, "learn_throughput": 810.282, "update_time_ms": 11.303}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 229.2440948486328, "policy_loss": -0.034758418798446655, "vf_loss": 229.27647399902344, "vf_explained_var": 0.13429535925388336, "kl": 0.011850236915051937, "entropy": 0.7997894883155823, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 102600, "num_agent_steps_sampled": 102519, "num_steps_trained": 102600, "num_agent_steps_trained": 102519}, "done": false, "episodes_total": 1998, "training_iteration": 19, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-50", "timestamp": 1626860630, "time_this_iter_s": 7.060371398925781, "time_total_s": 135.10124015808105, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022dc80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 135.10124015808105, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 21.28, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 4.0, 8.0, -9.0, 9.0, 13.0, 7.0, -14.0, -6.0, 7.0, 3.0, 11.0, -1.0, 4.0, 10.0, 2.0, 7.0, -8.0, 7.0, 9.0, 14.0, -2.0, -6.0, 9.0, 9.0, 6.0, 7.0, -7.0, 0.0, 7.0, 13.0, -5.0, 2.0, -5.0, 7.0, 11.0, 11.0, -1.0, -3.0, 8.0, 8.0, 13.0, -11.0, 5.0, -1.0, 5.0, 5.0, 6.0, 7.0, 5.0, 8.0, -5.0, 11.0, -1.0, 4.0, 1.0, 0.0, 8.0, 1.0, 6.0, -5.0, -4.0, 12.0, 12.0, 12.0, 0.0, -5.0, 8.0, 10.0, 13.0, -7.0, -1.0, 13.0, 7.0, -3.0, -2.0, -6.0, 5.0, 12.0, 4.0, 11.0, 3.0, 9.0, -8.0, 13.0, 13.0, 8.0, -19.0, -12.0, 9.0, 6.0, 12.0, -3.0, 13.0, -2.0, 7.0, 8.0, -7.0, 10.0, 4.0, 9.0, 0.0, 4.0, 2.0, -6.0, 9.0, 1.0, 11.0, 0.0, 12.0, 11.0, -8.0, -8.0, -2.0, 13.0, 12.0, 9.0, 13.0, -7.0, 0.0, 7.0, 9.0, 4.0, -5.0, 14.0, 14.0, -22.0, 9.0, 11.0, 4.0, 6.0, -6.0, 14.0, 13.0, -5.0, -7.0, -4.0, 12.0, 8.0, -1.0, 0.0, -5.0, 13.0, 7.0, 1.0, 8.0, 7.0, -1.0, 11.0, -5.0, 3.0, 6.0, 13.0, 4.0, -11.0, 9.0, 13.0, 5.0, 9.0, -12.0, 0.0, -6.0, 12.0, 9.0, 13.0, -2.0, 2.0, 2.0, 9.0, -7.0, 2.0, 11.0, 0.0, 8.0, -4.0, 11.0, -3.0, 5.0, 11.0, 2.0, 8.0, -1.0, -2.0, 10.0, -13.0, 11.0, 6.0, 11.0, -3.0, 3.0, 12.0, 3.0, 3.0, -6.0, 9.0, 9.0, 12.0, 13.0, -2.0, -8.0, -10.0, 5.0, 8.0, 12.0, -2.0, 1.0, 4.0, 12.0, 10.0, -10.0, 12.0, 3.0, 9.0, 12.0, -4.0, -2.0, -1.0, 4.0, 1.0, 11.0, -4.0, -4.0, 11.0, 12.0, 11.0, -15.0, 6.0, 13.0, 12.0, 12.0, -11.0, 2.0, -7.0, 13.0, -1.0, 10.0, 11.0, 8.0, 10.0, -14.0, 11.0, -9.0, 11.0, 2.0, 9.0, -1.0, -2.0, 9.0, 0.0, -8.0, 10.0, 13.0, -2.0, 8.0, 8.0, 1.0, 10.0, 7.0, 3.0, -5.0, -3.0, 14.0, 9.0, -5.0, 5.0, 13.0, -6.0, 3.0, 13.0, 5.0, 3.0, -6.0, 10.0, -7.0, 12.0, 0.0, 5.0, 12.0, 0.0, -2.0, 6.0, -13.0, 9.0, 13.0, 0.0, 2.0, 4.0, 9.0, 2.0, -7.0, 8.0, 12.0, 10.0, -1.0, -4.0, 10.0, 6.0, -9.0, 7.0, 11.0, -1.0, 8.0, 9.0, -1.0, 2.0, 11.0, -10.0, 12.0, 11.0, -1.0, 8.0, -3.0, -5.0, 12.0, -4.0, 12.0, -2.0, -1.0, 12.0, 6.0, 11.0, 0.0, 9.0, -5.0, 10.0, 13.0, -4.0, -4.0, -10.0, 7.0, 9.0, 9.0, -7.0, 6.0, 10.0, 6.0, 11.0, -17.0, 13.0, 8.0, 11.0, 13.0, 9.0, -18.0, -9.0, 11.0, 2.0, 11.0, -5.0, 9.0, 9.0, 2.0, 8.0, 1.0, 13.0, -7.0, 5.0, -1.0, 4.0, 7.0, -8.0, 8.0, 7.0, 8.0, -11.0, 7.0, 8.0, 11.0, 10.0, -1.0, 2.0, 4.0, 7.0, 12.0, -12.0, 8.0, -9.0, 4.0, 12.0, 8.0, -2.0, 7.0, 1.0, 9.0, 12.0, -13.0, 8.0, 8.0, 10.0, 13.0, -16.0, 8.0, 7.0, 11.0, 11.0, -14.0, 0.0, 6.0, -3.0, 12.0, 0.0, -6.0, 9.0, 12.0, -2.0, 13.0, 8.0, -4.0, -8.0, 11.0, 0.0, 12.0, -3.0, 8.0, 0.0, 10.0, 5.0, -10.0, 13.0, 7.0, 11.0, 13.0, 7.0, -16.0, -12.0, 10.0, 12.0, 5.0, 14.0, 3.0, 11.0, -13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22107034838054954, "mean_inference_ms": 1.1835429166261506, "mean_action_processing_ms": 0.07253862371252867, "mean_env_wait_ms": 0.17929626698329623, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 108000, "agent_timesteps_total": 107919, "timers": {"sample_time_ms": 350.584, "sample_throughput": 15402.88, "learn_time_ms": 6660.314, "learn_throughput": 810.773, "update_time_ms": 11.248}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 25.6314754486084, "policy_loss": -0.10124129056930542, "vf_loss": 25.72874641418457, "vf_explained_var": 0.16032260656356812, "kl": 0.019882025197148323, "entropy": 0.8398848176002502, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 108000, "num_agent_steps_sampled": 107919, "num_steps_trained": 108000, "num_agent_steps_trained": 107919}, "done": false, "episodes_total": 2106, "training_iteration": 20, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-43-57", "timestamp": 1626860637, "time_this_iter_s": 7.151296854019165, "time_total_s": 142.25253701210022, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702d86a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 142.25253701210022, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 21.58, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -9.0, 11.0, -1.0, 11.0, 13.0, 3.0, -12.0, 9.0, 9.0, 5.0, -8.0, 3.0, 12.0, -7.0, 7.0, 14.0, 2.0, -9.0, 8.0, 12.0, 12.0, -14.0, 5.0, 14.0, -6.0, 2.0, 5.0, 13.0, 12.0, -15.0, 5.0, 14.0, 7.0, -8.0, 2.0, 8.0, 12.0, 3.0, -8.0, 2.0, -3.0, 7.0, 9.0, 12.0, 5.0, -4.0, 2.0, 9.0, 9.0, 9.0, -12.0, 12.0, 12.0, 7.0, -16.0, 5.0, -2.0, 1.0, 11.0, 13.0, 9.0, -10.0, 3.0, 13.0, 2.0, -11.0, 11.0, 13.0, 11.0, -11.0, 2.0, 14.0, -6.0, 10.0, -3.0, 12.0, 5.0, -5.0, 3.0, 8.0, -1.0, 9.0, -1.0, 7.0, 5.0, -3.0, 6.0, 6.0, -7.0, 5.0, 11.0, 13.0, 10.0, 6.0, -14.0, 14.0, 8.0, 10.0, -17.0, 13.0, 13.0, -15.0, 4.0, -11.0, 13.0, 4.0, 9.0, 14.0, 11.0, -9.0, -1.0, 9.0, 10.0, 1.0, -5.0, 14.0, 11.0, -17.0, 7.0, 6.0, -1.0, -1.0, 11.0, 8.0, 12.0, -13.0, 8.0, 14.0, 6.0, -7.0, 2.0, 9.0, 11.0, -10.0, 5.0, 14.0, 9.0, 4.0, -12.0, 12.0, 13.0, -14.0, 4.0, 14.0, -2.0, 8.0, -5.0, 14.0, 11.0, 3.0, -13.0, 5.0, 11.0, 4.0, -5.0, 7.0, 11.0, -12.0, 9.0, 14.0, -4.0, 1.0, 4.0, 14.0, 12.0, -3.0, -8.0, 13.0, -6.0, 4.0, 4.0, 9.0, -6.0, 6.0, 6.0, 5.0, 3.0, -3.0, 10.0, 12.0, 13.0, 2.0, -12.0, 5.0, -4.0, 5.0, 9.0, 13.0, 10.0, -9.0, 1.0, 14.0, 9.0, -12.0, 4.0, 10.0, 12.0, -8.0, 1.0, 10.0, -7.0, 7.0, 5.0, 7.0, 11.0, -6.0, 3.0, 11.0, -5.0, 5.0, 4.0, 3.0, 13.0, -6.0, 5.0, 7.0, 6.0, -3.0, 5.0, 12.0, 6.0, -9.0, 6.0, 9.0, 7.0, 9.0, -10.0, -8.0, 12.0, 7.0, 4.0, 3.0, 5.0, -2.0, 9.0, 10.0, 12.0, -8.0, 1.0, 11.0, -6.0, 9.0, 1.0, 7.0, 12.0, 4.0, -8.0, 9.0, 9.0, 4.0, -7.0, 14.0, 12.0, -17.0, 6.0, 6.0, -4.0, 10.0, 3.0, 12.0, 13.0, 3.0, -13.0, 3.0, 13.0, 0.0, -1.0, 7.0, 11.0, -9.0, 6.0, 11.0, 14.0, 9.0, -19.0, 13.0, 9.0, -13.0, 6.0, 9.0, -6.0, 11.0, 1.0, 8.0, 9.0, -4.0, 2.0, 14.0, 6.0, 3.0, -8.0, 8.0, 12.0, 1.0, -6.0, 2.0, 10.0, -7.0, 10.0, 12.0, -4.0, 10.0, -3.0, 9.0, 7.0, 10.0, -11.0, 12.0, 13.0, -19.0, 9.0, 12.0, -4.0, 11.0, -4.0, 10.0, 11.0, -2.0, -4.0, 14.0, 8.0, 5.0, -12.0, 14.0, 12.0, -17.0, 6.0, 5.0, -6.0, 7.0, 9.0, 5.0, 13.0, -6.0, 3.0, 14.0, -9.0, 1.0, 9.0, 12.0, 13.0, 4.0, -14.0, 8.0, -3.0, 5.0, 5.0, 13.0, -1.0, -3.0, 6.0, 14.0, 6.0, -7.0, 2.0, 12.0, 8.0, 4.0, -9.0, 8.0, 10.0, -2.0, -1.0, 12.0, 9.0, -11.0, 5.0, 14.0, 10.0, 5.0, -14.0, 13.0, 9.0, 12.0, -19.0, 13.0, -9.0, 2.0, 9.0, 8.0, 11.0, -6.0, 2.0, 10.0, 1.0, 11.0, -7.0, 12.0, 13.0, 12.0, 317.0, 6.0, -6.0, 6.0, 9.0, 12.0, -1.0, 6.0, -2.0, 7.0, 10.0, 5.0, -7.0, 12.0, 11.0, -13.0, 5.0, 5.0, 4.0, -4.0, 10.0, 11.0, 2.0, -2.0, 4.0, 14.0, -14.0, 11.0, 4.0, 8.0, 8.0, 2.0, -3.0, 9.0, 12.0, 0.0, -6.0, 13.0, -3.0, 6.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2211011762345848, "mean_inference_ms": 1.183402734096775, "mean_action_processing_ms": 0.07255774559892653, "mean_env_wait_ms": 0.17928908151163844, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 113400, "agent_timesteps_total": 113319, "timers": {"sample_time_ms": 351.208, "sample_throughput": 15375.522, "learn_time_ms": 6661.713, "learn_throughput": 810.602, "update_time_ms": 11.492}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 228.3606414794922, "policy_loss": -0.0295917596668005, "vf_loss": 228.3879852294922, "vf_explained_var": 0.15013286471366882, "kl": 0.011173304170370102, "entropy": 0.7732763886451721, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 113400, "num_agent_steps_sampled": 113319, "num_steps_trained": 113400, "num_agent_steps_trained": 113319}, "done": false, "episodes_total": 2214, "training_iteration": 21, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-44-04", "timestamp": 1626860644, "time_this_iter_s": 7.080136775970459, "time_total_s": 149.33267378807068, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 149.33267378807068, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 21.36, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 12.0, 7.0, -14.0, 8.0, -10.0, 12.0, 5.0, 4.0, 12.0, 7.0, -8.0, -18.0, 14.0, 10.0, 9.0, 13.0, -9.0, -2.0, 13.0, -2.0, 8.0, 5.0, 4.0, -3.0, 0.0, 5.0, 13.0, 12.0, 5.0, -11.0, 9.0, 13.0, -20.0, 10.0, 12.0, -3.0, 1.0, 6.0, 11.0, 5.0, -9.0, 11.0, 8.0, -4.0, 14.0, -4.0, 9.0, 13.0, 6.0, 8.0, -12.0, 8.0, 12.0, -5.0, 0.0, 10.0, 13.0, -4.0, -4.0, -6.0, 13.0, 6.0, 2.0, 12.0, 8.0, 8.0, -13.0, -5.0, 8.0, 7.0, 5.0, 0.0, 14.0, 8.0, -7.0, 8.0, 12.0, 9.0, -14.0, 5.0, -4.0, 7.0, 7.0, -13.0, 11.0, 11.0, 6.0, 2.0, -6.0, 6.0, 13.0, 11.0, 8.0, -3.0, -1.0, 9.0, 2.0, 13.0, -9.0, -6.0, 7.0, 8.0, 6.0, 8.0, -1.0, 1.0, 7.0, -7.0, 8.0, 10.0, 4.0, -7.0, 7.0, 6.0, 9.0, 9.0, -9.0, 8.0, 7.0, 0.0, -6.0, 12.0, 9.0, 13.0, 2.0, 7.0, -7.0, 13.0, 4.0, 7.0, -9.0, -6.0, 6.0, 4.0, 11.0, 8.0, 13.0, -4.0, -2.0, 11.0, 1.0, -3.0, 6.0, 13.0, 6.0, 10.0, -14.0, -7.0, 8.0, 9.0, 5.0, 10.0, -1.0, -6.0, 12.0, 8.0, 12.0, 10.0, -15.0, 11.0, -11.0, 11.0, 4.0, -6.0, 9.0, 10.0, 2.0, 12.0, 13.0, -3.0, -7.0, 4.0, 12.0, 5.0, -6.0, 4.0, 8.0, 12.0, -9.0, -5.0, 11.0, 3.0, 6.0, 5.0, 14.0, 3.0, -7.0, -6.0, 9.0, 5.0, 7.0, 8.0, 12.0, 6.0, -11.0, 14.0, -3.0, -1.0, 5.0, 6.0, 14.0, -2.0, -3.0, 7.0, 9.0, -13.0, 12.0, 13.0, -8.0, 6.0, 4.0, -5.0, 7.0, 9.0, 4.0, 11.0, 14.0, -5.0, -5.0, 12.0, 5.0, -9.0, 7.0, 8.0, 7.0, -4.0, 4.0, 0.0, 4.0, 6.0, 5.0, 9.0, 0.0, 7.0, -1.0, 6.0, 13.0, 11.0, -15.0, 11.0, -6.0, 2.0, 8.0, -12.0, 11.0, 11.0, 5.0, 6.0, 13.0, -3.0, -1.0, -1.0, 11.0, 6.0, -1.0, 12.0, 6.0, 5.0, -8.0, -2.0, 7.0, 1.0, 9.0, -1.0, 12.0, 9.0, -5.0, -2.0, 1.0, 11.0, 5.0, 4.0, 12.0, -3.0, 2.0, -10.0, 6.0, 7.0, 12.0, 7.0, 14.0, 0.0, -6.0, 5.0, 13.0, 10.0, -13.0, 12.0, -8.0, 8.0, 3.0, -5.0, 10.0, 6.0, 4.0, 9.0, 13.0, 1.0, -8.0, 7.0, 11.0, 2.0, -5.0, -8.0, 7.0, 12.0, 4.0, 10.0, -12.0, 10.0, 7.0, 4.0, 7.0, 6.0, -2.0, 6.0, 1.0, -3.0, 11.0, 12.0, 1.0, -5.0, 7.0, -2.0, 0.0, 11.0, 6.0, -12.0, 14.0, 5.0, 8.0, 7.0, 5.0, 6.0, -3.0, 11.0, 1.0, 13.0, -10.0, -10.0, 8.0, 10.0, 7.0, 8.0, 6.0, 10.0, -9.0, 7.0, 8.0, -8.0, 8.0, 12.0, 11.0, 5.0, -13.0, -7.0, 12.0, 2.0, 8.0, 12.0, 14.0, -6.0, -5.0, -11.0, 12.0, 4.0, 10.0, 13.0, -17.0, 11.0, 8.0, -1.0, 12.0, 1.0, 3.0, 8.0, 14.0, -2.0, -5.0, 4.0, 9.0, -7.0, 9.0, 13.0, -7.0, -3.0, 12.0, 13.0, -7.0, 4.0, 5.0, 9.0, 14.0, -20.0, 12.0, -3.0, 6.0, 6.0, 6.0, 13.0, -9.0, 6.0, 5.0, -1.0, 10.0, 4.0, 2.0, 12.0, 14.0, 2.0, -13.0, 12.0, -1.0, -8.0, 12.0, 13.0, -15.0, 13.0, 4.0, -7.0, 9.0, 6.0, 7.0, 7.0, 12.0, 4.0, -8.0, -6.0, 6.0, 10.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2211791483644666, "mean_inference_ms": 1.1834597239870368, "mean_action_processing_ms": 0.07253035995649178, "mean_env_wait_ms": 0.17927745076646864, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 118800, "agent_timesteps_total": 118719, "timers": {"sample_time_ms": 351.982, "sample_throughput": 15341.679, "learn_time_ms": 6658.866, "learn_throughput": 810.949, "update_time_ms": 11.282}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 27.949676513671875, "policy_loss": -0.10110092908143997, "vf_loss": 28.0468692779541, "vf_explained_var": 0.128261998295784, "kl": 0.019521407783031464, "entropy": 0.7939724326133728, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 118800, "num_agent_steps_sampled": 118719, "num_steps_trained": 118800, "num_agent_steps_trained": 118719}, "done": false, "episodes_total": 2322, "training_iteration": 22, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-44-11", "timestamp": 1626860651, "time_this_iter_s": 7.219623327255249, "time_total_s": 156.55229711532593, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022da60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 156.55229711532593, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 20.972727272727273, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.453703703703702, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 6.113425925925926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 10.0, 12.0, -11.0, -6.0, 3.0, 13.0, 5.0, -12.0, 13.0, 9.0, 5.0, 8.0, -6.0, 6.0, 7.0, -2.0, 12.0, -6.0, 11.0, 12.0, 9.0, 6.0, -12.0, 0.0, 13.0, -5.0, 7.0, 12.0, 318.0, 12.0, 13.0, 8.0, 9.0, 2.0, -4.0, 12.0, 10.0, 5.0, -12.0, -5.0, 11.0, 8.0, 1.0, 9.0, 7.0, -10.0, 9.0, 3.0, 9.0, -3.0, 6.0, -1.0, 2.0, 13.0, 1.0, -12.0, 9.0, 11.0, 7.0, 11.0, -19.0, 10.0, 13.0, -10.0, 12.0, 6.0, 7.0, 13.0, 7.0, 8.0, -13.0, -10.0, 14.0, 9.0, 2.0, 8.0, -1.0, 4.0, 4.0, 4.0, 13.0, 8.0, -10.0, 11.0, -7.0, 13.0, -2.0, -6.0, 11.0, 5.0, 5.0, 12.0, -16.0, 10.0, 9.0, -10.0, 11.0, 7.0, 7.0, 12.0, 8.0, 5.0, -10.0, 12.0, 7.0, -8.0, 4.0, 9.0, 8.0, -4.0, 2.0, 3.0, 13.0, 5.0, -6.0, 14.0, 12.0, 6.0, -17.0, -4.0, 12.0, 5.0, 2.0, 13.0, -14.0, 7.0, 9.0, -15.0, 12.0, 10.0, 8.0, 5.0, 3.0, 13.0, -6.0, -5.0, 11.0, -3.0, 12.0, 11.0, 7.0, -12.0, 9.0, 10.0, 13.0, -3.0, -5.0, -2.0, 8.0, 5.0, 4.0, -6.0, 10.0, 8.0, 3.0, 9.0, -4.0, 1.0, 9.0, -12.0, 9.0, 6.0, 12.0, 3.0, 7.0, 13.0, -8.0, 2.0, 12.0, -8.0, 9.0, 9.0, 12.0, -13.0, 7.0, -6.0, 12.0, 4.0, 5.0, 10.0, 9.0, 5.0, -9.0, 7.0, 13.0, -12.0, 7.0, 13.0, -3.0, -8.0, 13.0, -6.0, 10.0, 3.0, 8.0, 5.0, 5.0, -7.0, 12.0, 0.0, 12.0, 2.0, 1.0, 13.0, 319.0, 11.0, 13.0, -10.0, 13.0, 11.0, 1.0, 13.0, 12.0, 5.0, -15.0, -6.0, 14.0, -2.0, 9.0, 4.0, -6.0, 4.0, 13.0, -16.0, 11.0, 12.0, 8.0, 11.0, -15.0, 9.0, 10.0, -12.0, 14.0, 7.0, 6.0, 12.0, 2.0, -8.0, 9.0, 5.0, 13.0, -10.0, 7.0, 5.0, 8.0, 8.0, -6.0, -12.0, 14.0, 7.0, 6.0, 13.0, 318.0, 11.0, 13.0, 0.0, 10.0, 12.0, -7.0, 12.0, 8.0, 6.0, -11.0, -7.0, 13.0, 3.0, 6.0, 9.0, 5.0, -4.0, 5.0, -1.0, 9.0, 11.0, -4.0, 12.0, 11.0, 7.0, -15.0, -2.0, 4.0, 6.0, 7.0, 4.0, 13.0, -8.0, 6.0, 3.0, 10.0, 5.0, -3.0, 14.0, 8.0, 0.0, -7.0, -1.0, 9.0, 4.0, 3.0, -12.0, 12.0, 6.0, 9.0, -17.0, 12.0, 11.0, 9.0, -2.0, 10.0, 2.0, 5.0, -6.0, 8.0, 2.0, 11.0, 13.0, -21.0, 10.0, 13.0, 5.0, 11.0, 11.0, -12.0, 10.0, 8.0, 8.0, -11.0, -13.0, 11.0, 9.0, 8.0, 9.0, -6.0, 3.0, 9.0, 2.0, 12.0, -4.0, 5.0, 12.0, -2.0, 8.0, -3.0, -5.0, 7.0, 5.0, 8.0, 8.0, -7.0, 5.0, 9.0, 7.0, 8.0, -11.0, 11.0, -10.0, 8.0, 11.0, 6.0, -9.0, 13.0, 9.0, 2.0, 12.0, 5.0, -9.0, 7.0, 8.0, 8.0, 6.0, -7.0, 10.0, 11.0, 2.0, -8.0, -10.0, 13.0, 5.0, 7.0, 9.0, 3.0, -4.0, 7.0, -3.0, 11.0, 12.0, -5.0, -4.0, 5.0, 8.0, 6.0, -14.0, 14.0, 5.0, 10.0, 12.0, -12.0, 9.0, 6.0, 13.0, 13.0, 1.0, -12.0, -2.0, 12.0, 2.0, 3.0, -12.0, 9.0, 10.0, 8.0, 13.0, -3.0, -4.0, 9.0, -7.0, 10.0, 9.0, 3.0, 13.0, 12.0, -13.0, 3.0, 7.0, 12.0, -9.0, 5.0, 11.0, 10.0, -17.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22127445482605643, "mean_inference_ms": 1.1839149791415338, "mean_action_processing_ms": 0.07250013872469481, "mean_env_wait_ms": 0.17927673241149925, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 124200, "agent_timesteps_total": 124119, "timers": {"sample_time_ms": 352.677, "sample_throughput": 15311.464, "learn_time_ms": 6669.519, "learn_throughput": 809.654, "update_time_ms": 11.265}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 644.9683227539062, "policy_loss": -0.02652219869196415, "vf_loss": 644.9930419921875, "vf_explained_var": 0.06809049844741821, "kl": 0.008904214948415756, "entropy": 0.7549636960029602, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 124200, "num_agent_steps_sampled": 124119, "num_steps_trained": 124200, "num_agent_steps_trained": 124119}, "done": false, "episodes_total": 2430, "training_iteration": 23, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-44-19", "timestamp": 1626860659, "time_this_iter_s": 7.058189392089844, "time_total_s": 163.61048650741577, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022d730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 163.61048650741577, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 21.36, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 368.0, "episode_reward_min": 15.0, "episode_reward_mean": 37.23148148148148, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 9.30787037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.0, 15.0, 15.0, 15.0, 368.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 319.0, 12.0, 13.0, 10.0, 11.0, -2.0, -4.0, 8.0, 8.0, -6.0, 5.0, 14.0, 10.0, 7.0, -16.0, 12.0, 331.0, 12.0, 13.0, -7.0, 7.0, 10.0, 5.0, 3.0, 10.0, -3.0, 5.0, 14.0, 13.0, -13.0, 1.0, -7.0, 4.0, 12.0, 6.0, -7.0, 3.0, 9.0, 10.0, 329.0, 13.0, 12.0, 12.0, 14.0, 12.0, -9.0, -2.0, 10.0, -16.0, 13.0, 8.0, 11.0, 7.0, -8.0, 5.0, -15.0, 14.0, 9.0, 7.0, 14.0, 8.0, -13.0, 6.0, -16.0, 11.0, 12.0, 8.0, -5.0, 11.0, 8.0, 1.0, -13.0, 12.0, 12.0, 4.0, 0.0, 6.0, 5.0, 4.0, 10.0, -18.0, 10.0, 13.0, -11.0, 12.0, 10.0, 4.0, -20.0, 14.0, 9.0, 12.0, 14.0, 12.0, -4.0, -7.0, 7.0, -11.0, 11.0, 8.0, 13.0, 4.0, -2.0, 0.0, 4.0, 10.0, -5.0, 6.0, 14.0, 10.0, -11.0, 2.0, 1.0, -5.0, 11.0, 8.0, 6.0, 11.0, -1.0, -1.0, -16.0, 12.0, 12.0, 7.0, 11.0, 7.0, 6.0, -9.0, 11.0, -20.0, 11.0, 13.0, 13.0, -1.0, -1.0, 4.0, 7.0, -4.0, 6.0, 6.0, 14.0, -6.0, -4.0, 11.0, 4.0, -5.0, 12.0, 4.0, 12.0, 7.0, -6.0, 2.0, -12.0, 11.0, 9.0, 7.0, 14.0, 12.0, -10.0, -1.0, 1.0, -7.0, 12.0, 9.0, -1.0, 7.0, 12.0, -3.0, -2.0, 7.0, -2.0, 12.0, 14.0, 6.0, 11.0, -16.0, 1.0, -5.0, 11.0, 8.0, -8.0, 11.0, 7.0, 5.0, -14.0, 10.0, 7.0, 12.0, 14.0, 12.0, -17.0, 6.0, 9.0, -10.0, 8.0, 8.0, 7.0, -7.0, 12.0, 3.0, -2.0, 5.0, 9.0, 3.0, 14.0, 11.0, 10.0, -20.0, 11.0, -7.0, 8.0, 3.0, -7.0, 13.0, 4.0, 5.0, -13.0, 9.0, 11.0, 8.0, 14.0, 9.0, -9.0, 1.0, 11.0, -16.0, 12.0, 8.0, -4.0, 1.0, 12.0, 6.0, -21.0, 14.0, 9.0, 13.0, 14.0, 4.0, 9.0, -12.0, 11.0, -19.0, 10.0, 13.0, -10.0, 11.0, 7.0, 7.0, 11.0, -13.0, 10.0, 7.0, 14.0, 13.0, -2.0, -10.0, 5.0, -4.0, 8.0, 6.0, -3.0, 12.0, 4.0, 2.0, 5.0, -8.0, 12.0, 6.0, 0.0, 9.0, 10.0, -4.0, -3.0, 7.0, 5.0, 6.0, -5.0, 7.0, 11.0, 2.0, 3.0, -2.0, 9.0, 5.0, 13.0, 11.0, -18.0, 9.0, 11.0, -14.0, 9.0, 9.0, -5.0, 7.0, 10.0, 3.0, 3.0, -9.0, 9.0, 12.0, -3.0, 13.0, 7.0, -2.0, 11.0, 319.0, 13.0, 13.0, 6.0, 12.0, -10.0, 7.0, 6.0, -9.0, 9.0, 9.0, 10.0, 13.0, -5.0, -3.0, 9.0, -15.0, 13.0, 8.0, -8.0, 11.0, 9.0, 3.0, -14.0, 13.0, 9.0, 7.0, 14.0, 8.0, -14.0, 7.0, 0.0, -6.0, 13.0, 8.0, 8.0, 5.0, 8.0, -6.0, -14.0, 13.0, 4.0, 12.0, 14.0, -3.0, 0.0, 4.0, -7.0, 11.0, 7.0, 4.0, -6.0, 12.0, 2.0, 7.0, -8.0, 14.0, -3.0, 12.0, 14.0, -7.0, 10.0, -2.0, 13.0, -2.0, -1.0, 5.0, 10.0, 3.0, -3.0, 5.0, 3.0, -3.0, 12.0, 3.0, 14.0, 11.0, 11.0, -21.0, 11.0, -9.0, 12.0, 1.0, 9.0, 11.0, -2.0, -3.0, 315.0, 14.0, 11.0, 12.0, 13.0, 9.0, -9.0, 2.0, 3.0, -13.0, 12.0, 13.0, -9.0, 4.0, 12.0, 8.0, -7.0, 8.0, 9.0, 5.0, 14.0, 13.0, -16.0, 4.0, 11.0, 320.0, 11.0, 13.0, -5.0, 12.0, 11.0, -3.0, 5.0, 4.0, -2.0, 8.0, 14.0, 12.0, 316.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22105347325108135, "mean_inference_ms": 1.1835463213830653, "mean_action_processing_ms": 0.07246503051799247, "mean_env_wait_ms": 0.17928133053020248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 129600, "agent_timesteps_total": 129519, "timers": {"sample_time_ms": 353.413, "sample_throughput": 15279.556, "learn_time_ms": 6667.88, "learn_throughput": 809.853, "update_time_ms": 11.018}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 1385.31787109375, "policy_loss": -0.030968615785241127, "vf_loss": 1385.3468017578125, "vf_explained_var": 0.04627525061368942, "kl": 0.010069476440548897, "entropy": 0.6766866445541382, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 129600, "num_agent_steps_sampled": 129519, "num_steps_trained": 129600, "num_agent_steps_trained": 129519}, "done": false, "episodes_total": 2538, "training_iteration": 24, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-44-26", "timestamp": 1626860666, "time_this_iter_s": 7.1694655418396, "time_total_s": 170.77995204925537, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022d620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 170.77995204925537, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 21.419999999999998, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-8.0, 14.0, -3.0, 12.0, -2.0, 11.0, 13.0, -7.0, 9.0, 9.0, 2.0, -5.0, 9.0, 7.0, 3.0, -4.0, -2.0, 8.0, -3.0, 12.0, -11.0, 10.0, 7.0, 9.0, 14.0, 10.0, 7.0, -16.0, 3.0, 12.0, -12.0, 12.0, -3.0, 3.0, 3.0, 12.0, -11.0, 11.0, 2.0, 13.0, 13.0, 4.0, 1.0, -3.0, 5.0, 10.0, -13.0, 13.0, -3.0, 4.0, 2.0, 12.0, 7.0, -5.0, 12.0, 1.0, 8.0, 10.0, 2.0, -5.0, 5.0, 3.0, -5.0, 12.0, -7.0, 8.0, 2.0, 12.0, -14.0, 11.0, 6.0, 12.0, -3.0, 11.0, 9.0, -2.0, -4.0, 13.0, 4.0, 2.0, 11.0, 8.0, -1.0, -3.0, -10.0, 11.0, 3.0, 11.0, 12.0, 11.0, -7.0, -1.0, 7.0, -6.0, 2.0, 12.0, 11.0, 5.0, 2.0, -3.0, 12.0, -6.0, 11.0, -2.0, 14.0, 11.0, -8.0, -2.0, 2.0, 12.0, -11.0, 12.0, -3.0, 10.0, -2.0, 10.0, -15.0, 8.0, 9.0, 13.0, 4.0, 9.0, 8.0, -6.0, 11.0, 4.0, -8.0, 8.0, 12.0, 4.0, -7.0, 6.0, 5.0, 4.0, -6.0, 12.0, 9.0, 10.0, 6.0, -10.0, 13.0, -9.0, 6.0, 5.0, -5.0, 5.0, 2.0, 13.0, -1.0, 12.0, -6.0, 10.0, 14.0, 6.0, 9.0, -14.0, 4.0, -5.0, 4.0, 12.0, -7.0, 6.0, 4.0, 12.0, 0.0, 9.0, -5.0, 11.0, 8.0, 6.0, 2.0, -1.0, 11.0, -9.0, 5.0, 8.0, -10.0, 9.0, 5.0, 11.0, 8.0, 11.0, -3.0, -1.0, 6.0, 6.0, 11.0, -8.0, 4.0, -1.0, 5.0, 7.0, 12.0, 8.0, -3.0, -2.0, 4.0, 9.0, -5.0, 7.0, 14.0, 6.0, 0.0, -5.0, 5.0, 7.0, -3.0, 6.0, 12.0, 7.0, 1.0, -5.0, 7.0, 4.0, -2.0, 6.0, -8.0, 12.0, 0.0, 11.0, 11.0, -2.0, 4.0, 2.0, 11.0, 9.0, -1.0, -4.0, 4.0, 10.0, -3.0, 4.0, 9.0, 11.0, -7.0, 2.0, 8.0, -4.0, 3.0, 8.0, -4.0, 5.0, 4.0, 10.0, -11.0, 10.0, 13.0, 3.0, 9.0, 9.0, 8.0, -11.0, 6.0, 6.0, -6.0, 9.0, -13.0, 14.0, 2.0, 12.0, -10.0, 8.0, 4.0, 13.0, 9.0, 11.0, -12.0, 7.0, 11.0, -14.0, 12.0, 6.0, 12.0, -4.0, -4.0, 11.0, -13.0, 13.0, 4.0, 11.0, 9.0, 10.0, 7.0, -11.0, 5.0, 4.0, -1.0, 7.0, -3.0, 9.0, -1.0, 10.0, 2.0, -5.0, 11.0, 7.0, 1.0, 12.0, -6.0, 8.0, 0.0, 7.0, 9.0, -1.0, -1.0, 8.0, 1.0, 7.0, -7.0, 3.0, 7.0, 12.0, 9.0, 11.0, -8.0, 3.0, 2.0, -9.0, 9.0, 13.0, -5.0, 10.0, 4.0, 6.0, 3.0, -6.0, 6.0, 12.0, 9.0, 10.0, 8.0, -12.0, 4.0, 8.0, -8.0, 11.0, -9.0, 10.0, 1.0, 13.0, 3.0, 7.0, -7.0, 12.0, 5.0, 11.0, 5.0, -6.0, 12.0, -6.0, 3.0, 6.0, -3.0, 2.0, 6.0, 10.0, -12.0, 12.0, 12.0, 3.0, 7.0, 12.0, -12.0, 8.0, 6.0, -6.0, 3.0, 12.0, -6.0, 13.0, -3.0, 11.0, -6.0, 13.0, 3.0, 5.0, 4.0, 10.0, -6.0, 7.0, 12.0, 8.0, 10.0, -15.0, 9.0, 6.0, 3.0, -3.0, -3.0, 11.0, -4.0, 11.0, 5.0, 4.0, -7.0, 13.0, 12.0, 6.0, -6.0, 3.0, -2.0, 10.0, -4.0, 11.0, 2.0, 14.0, 8.0, -9.0, 7.0, 4.0, 10.0, -6.0, 13.0, -15.0, 11.0, 6.0, 11.0, 8.0, 0.0, -4.0, 8.0, 7.0, -6.0, 6.0, -7.0, 11.0, 6.0, 5.0, -7.0, 12.0, 3.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2205488817346801, "mean_inference_ms": 1.1837863881154655, "mean_action_processing_ms": 0.07244517866457542, "mean_env_wait_ms": 0.17936968637958695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 135000, "agent_timesteps_total": 134946, "timers": {"sample_time_ms": 353.846, "sample_throughput": 15260.87, "learn_time_ms": 6667.537, "learn_throughput": 809.894, "update_time_ms": 10.97}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 26.968347549438477, "policy_loss": -0.10178563743829727, "vf_loss": 27.066091537475586, "vf_explained_var": 0.09758718311786652, "kl": 0.02020694501698017, "entropy": 0.7291132211685181, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 135000, "num_agent_steps_sampled": 134946, "num_steps_trained": 135000, "num_agent_steps_trained": 134946}, "done": false, "episodes_total": 2646, "training_iteration": 25, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-44-33", "timestamp": 1626860673, "time_this_iter_s": 7.095334768295288, "time_total_s": 177.87528681755066, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 177.87528681755066, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 21.69, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 10.0, 5.0, 5.0, -1.0, 14.0, -4.0, 6.0, 0.0, 9.0, 7.0, -1.0, 2.0, 12.0, -12.0, 13.0, 3.0, -7.0, 10.0, 9.0, 1.0, -1.0, 8.0, 7.0, -11.0, 11.0, 3.0, 12.0, 1.0, 13.0, 11.0, -10.0, -3.0, 13.0, -3.0, 8.0, 2.0, 8.0, -3.0, 8.0, 8.0, 13.0, -12.0, 6.0, 4.0, 9.0, -6.0, 8.0, -11.0, 13.0, 6.0, 7.0, 2.0, 14.0, -6.0, 5.0, 7.0, -2.0, 7.0, 3.0, 8.0, 13.0, -19.0, 13.0, 13.0, 10.0, -1.0, -7.0, 7.0, 11.0, 12.0, -15.0, -3.0, 13.0, 1.0, 4.0, 9.0, 13.0, 10.0, -17.0, -3.0, -1.0, 8.0, 11.0, -6.0, 12.0, 1.0, 8.0, 2.0, 14.0, -12.0, 11.0, 3.0, -5.0, 9.0, 8.0, 5.0, 12.0, -15.0, 13.0, -9.0, 14.0, 1.0, 9.0, 5.0, -2.0, 9.0, 3.0, 6.0, 8.0, -12.0, 13.0, -10.0, 13.0, 5.0, 7.0, -1.0, -2.0, 11.0, 7.0, -4.0, 13.0, -2.0, 8.0, -1.0, 9.0, -6.0, 13.0, -3.0, -2.0, 12.0, 8.0, 8.0, 12.0, 6.0, -11.0, 4.0, 14.0, 1.0, -4.0, -4.0, -2.0, 11.0, 10.0, -7.0, 8.0, 1.0, 13.0, -11.0, 10.0, 5.0, 11.0, 4.0, 5.0, -2.0, 8.0, -6.0, 13.0, 3.0, 5.0, 6.0, 11.0, -3.0, 1.0, 0.0, -5.0, 9.0, 11.0, -3.0, 13.0, 3.0, 2.0, 5.0, 13.0, 11.0, -14.0, 4.0, -6.0, 8.0, 9.0, -3.0, 11.0, -6.0, 13.0, 8.0, 11.0, -11.0, 7.0, 4.0, -2.0, 6.0, 7.0, 5.0, 11.0, -14.0, 13.0, 7.0, -11.0, 9.0, 10.0, 8.0, -8.0, 10.0, 5.0, -5.0, 6.0, 1.0, 13.0, 4.0, 14.0, -8.0, 5.0, -6.0, -1.0, 10.0, 12.0, 8.0, 13.0, -6.0, 0.0, 4.0, 14.0, -8.0, 5.0, 0.0, -3.0, 8.0, 10.0, 8.0, 13.0, 3.0, -9.0, -6.0, 13.0, 7.0, 1.0, 2.0, -10.0, 11.0, 12.0, 1.0, 14.0, -13.0, 13.0, 7.0, 13.0, -11.0, 6.0, -1.0, -3.0, 10.0, 9.0, -2.0, 12.0, -5.0, 10.0, 9.0, 11.0, -7.0, 2.0, 7.0, 0.0, 1.0, 7.0, -9.0, 9.0, 3.0, 12.0, 13.0, 14.0, -2.0, -10.0, 7.0, 9.0, 8.0, -9.0, 5.0, 13.0, -11.0, 8.0, -6.0, 14.0, 3.0, 4.0, -3.0, 13.0, 8.0, -3.0, -1.0, 13.0, 4.0, -1.0, 13.0, 12.0, 1.0, -11.0, -2.0, -1.0, 9.0, 9.0, -5.0, 13.0, 3.0, 4.0, 13.0, 7.0, -1.0, -4.0, 4.0, 5.0, 11.0, -5.0, -8.0, 8.0, 7.0, 8.0, -11.0, 6.0, 10.0, 10.0, 8.0, 0.0, 11.0, -4.0, -12.0, 12.0, 12.0, 3.0, 7.0, 12.0, -12.0, 8.0, 6.0, -6.0, 3.0, 12.0, -6.0, 13.0, -3.0, 11.0, -6.0, 13.0, 3.0, 5.0, 4.0, 10.0, -6.0, 7.0, 12.0, 8.0, 10.0, -15.0, 9.0, 6.0, 3.0, -3.0, -3.0, 11.0, -4.0, 11.0, 5.0, 4.0, -7.0, 13.0, 12.0, 6.0, -6.0, 3.0, -2.0, 10.0, -4.0, 11.0, 2.0, 14.0, 8.0, -9.0, 7.0, 4.0, 10.0, -6.0, 13.0, -15.0, 11.0, 6.0, 11.0, 8.0, 0.0, -4.0, 8.0, 7.0, -6.0, 6.0, -7.0, 11.0, 6.0, 5.0, -7.0, 12.0, 3.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22018516390833973, "mean_inference_ms": 1.1831459069064503, "mean_action_processing_ms": 0.07251034017974638, "mean_env_wait_ms": 0.1793667116286916, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 140400, "agent_timesteps_total": 140319, "timers": {"sample_time_ms": 353.937, "sample_throughput": 15256.949, "learn_time_ms": 6651.869, "learn_throughput": 811.802, "update_time_ms": 11.154}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 31.838478088378906, "policy_loss": -0.09153249859809875, "vf_loss": 31.92523193359375, "vf_explained_var": 0.16886456310749054, "kl": 0.01594107784330845, "entropy": 0.7458434700965881, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 140400, "num_agent_steps_sampled": 140319, "num_steps_trained": 140400, "num_agent_steps_trained": 140319}, "done": false, "episodes_total": 2727, "training_iteration": 26, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-44-40", "timestamp": 1626860680, "time_this_iter_s": 7.022914171218872, "time_total_s": 184.89820098876953, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 184.89820098876953, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 21.92, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.805555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 7.701388888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 12.0, 12.0, -19.0, 10.0, -14.0, 6.0, 13.0, 12.0, 9.0, -12.0, 6.0, 6.0, -5.0, 8.0, 6.0, 10.0, 12.0, -19.0, 12.0, 7.0, -12.0, 12.0, 8.0, 1.0, 12.0, -5.0, 7.0, 7.0, -11.0, 11.0, 8.0, 13.0, 8.0, -5.0, -1.0, -8.0, 12.0, -2.0, 13.0, -10.0, 14.0, 5.0, 6.0, 11.0, 3.0, 11.0, -10.0, 8.0, 4.0, -4.0, 7.0, 9.0, -8.0, 7.0, 7.0, -7.0, 14.0, 5.0, 3.0, 11.0, 318.0, 13.0, 12.0, 12.0, 7.0, -16.0, 12.0, -12.0, 7.0, 8.0, 12.0, -1.0, 8.0, 4.0, 4.0, -2.0, 9.0, -2.0, 10.0, 13.0, 9.0, -1.0, -6.0, 7.0, -8.0, 7.0, 9.0, 9.0, 4.0, -10.0, 12.0, 11.0, 4.0, -2.0, 2.0, 13.0, 13.0, -19.0, 8.0, 5.0, 7.0, -10.0, 13.0, 12.0, 4.0, -3.0, 2.0, 12.0, 318.0, 11.0, 13.0, 12.0, 7.0, -5.0, 1.0, 10.0, -14.0, 13.0, 6.0, 11.0, 10.0, -11.0, 5.0, 7.0, -15.0, 11.0, 12.0, 11.0, -5.0, 13.0, -4.0, 8.0, -9.0, 4.0, 12.0, -1.0, 11.0, 4.0, 1.0, 10.0, -10.0, 4.0, 11.0, 11.0, 5.0, -4.0, 3.0, 4.0, -9.0, 11.0, 9.0, 6.0, 12.0, -16.0, 13.0, 11.0, -4.0, 0.0, 8.0, 11.0, 5.0, 10.0, -11.0, 6.0, 7.0, -6.0, 8.0, -5.0, 9.0, 8.0, 3.0, 10.0, -11.0, 12.0, 4.0, 13.0, 7.0, -16.0, 11.0, 10.0, 6.0, -2.0, 1.0, -15.0, 10.0, 8.0, 12.0, 9.0, 12.0, 5.0, -11.0, 10.0, 4.0, -3.0, 4.0, 9.0, -13.0, 11.0, 8.0, -5.0, 4.0, 5.0, 11.0, 11.0, -15.0, 11.0, 8.0, 12.0, 14.0, -19.0, 8.0, 7.0, -8.0, 4.0, 12.0, 11.0, 10.0, -12.0, 6.0, 9.0, -12.0, 11.0, 7.0, -3.0, 7.0, 9.0, 2.0, 10.0, -12.0, 12.0, 5.0, 11.0, 7.0, -12.0, 9.0, 11.0, 3.0, 6.0, -5.0, 13.0, 3.0, 10.0, -11.0, 13.0, -14.0, 12.0, 4.0, 12.0, 9.0, -13.0, 7.0, 13.0, 317.0, 13.0, 11.0, 12.0, 11.0, 10.0, -18.0, 7.0, -7.0, 7.0, 8.0, 12.0, 11.0, 3.0, -11.0, 8.0, 12.0, -7.0, 2.0, 5.0, -6.0, 6.0, 10.0, 9.0, -8.0, 11.0, 3.0, 8.0, 9.0, -14.0, 12.0, 11.0, -16.0, 8.0, 12.0, 13.0, 6.0, -9.0, 5.0, 7.0, -8.0, 8.0, 8.0, 12.0, 4.0, 12.0, -13.0, 13.0, 316.0, 11.0, 13.0, 11.0, 14.0, -3.0, -7.0, 12.0, -10.0, 1.0, 12.0, 13.0, 1.0, -12.0, 13.0, 10.0, -10.0, 6.0, 9.0, 11.0, 8.0, -16.0, 12.0, 10.0, -13.0, 6.0, 12.0, -12.0, 9.0, 10.0, 8.0, 11.0, -11.0, 6.0, 9.0, 10.0, 6.0, 9.0, -10.0, 8.0, -7.0, 11.0, 3.0, 12.0, 7.0, -12.0, 8.0, 10.0, 13.0, 332.0, 12.0, 9.0, 7.0, -5.0, 4.0, 7.0, -13.0, 8.0, 13.0, 12.0, 4.0, -12.0, 11.0, 2.0, 7.0, -5.0, 11.0, 12.0, 11.0, 11.0, -19.0, 9.0, -19.0, 12.0, 13.0, 8.0, 10.0, -16.0, 13.0, 9.0, -18.0, 11.0, 13.0, 12.0, 4.0, -12.0, 11.0, 6.0, -15.0, 12.0, 12.0, -14.0, 14.0, 8.0, 7.0, 10.0, 9.0, -15.0, 11.0, 12.0, 9.0, -17.0, 11.0, 9.0, -14.0, 12.0, 8.0, 6.0, 7.0, 9.0, -7.0, 12.0, -15.0, 7.0, 11.0, 11.0, 7.0, 11.0, -14.0, 8.0, -8.0, 9.0, 6.0, -2.0, 14.0, -4.0, 7.0, 13.0, -17.0, 6.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2207531859334916, "mean_inference_ms": 1.1836388938280336, "mean_action_processing_ms": 0.07239868795123668, "mean_env_wait_ms": 0.17947995544237713, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 145800, "agent_timesteps_total": 145719, "timers": {"sample_time_ms": 353.901, "sample_throughput": 15258.494, "learn_time_ms": 6654.732, "learn_throughput": 811.453, "update_time_ms": 11.186}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 1057.935302734375, "policy_loss": -0.02787316031754017, "vf_loss": 1057.9610595703125, "vf_explained_var": 0.07284367084503174, "kl": 0.006688262335956097, "entropy": 0.6839876770973206, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 145800, "num_agent_steps_sampled": 145719, "num_steps_trained": 145800, "num_agent_steps_trained": 145719}, "done": false, "episodes_total": 2835, "training_iteration": 27, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-44-47", "timestamp": 1626860687, "time_this_iter_s": 7.0566229820251465, "time_total_s": 191.95482397079468, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 191.95482397079468, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 21.67, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 11.0, -3.0, 8.0, 14.0, -1.0, -6.0, 8.0, -6.0, 9.0, 5.0, 7.0, 12.0, 12.0, -12.0, 3.0, 0.0, 9.0, -6.0, 12.0, 13.0, 2.0, 8.0, -8.0, 0.0, 11.0, 10.0, -6.0, 12.0, -1.0, 2.0, 2.0, 1.0, -6.0, 9.0, 11.0, 14.0, -2.0, 11.0, -8.0, 0.0, 10.0, -1.0, 6.0, 12.0, 14.0, 7.0, -18.0, 5.0, 13.0, -10.0, 7.0, 13.0, 4.0, -10.0, 8.0, -6.0, 6.0, 8.0, 7.0, 4.0, 13.0, -2.0, 0.0, -4.0, 11.0, -3.0, 11.0, 14.0, 1.0, -2.0, 2.0, -6.0, 7.0, 4.0, 10.0, 11.0, -3.0, -2.0, 9.0, -4.0, 10.0, -2.0, 11.0, 14.0, 4.0, -10.0, 7.0, 11.0, 6.0, 13.0, -15.0, 7.0, 12.0, -11.0, 7.0, -1.0, 6.0, -2.0, 12.0, 12.0, 4.0, 7.0, -8.0, 8.0, 6.0, 11.0, -10.0, 5.0, 13.0, -2.0, -1.0, 2.0, -10.0, 12.0, 11.0, 12.0, 6.0, 8.0, -11.0, 13.0, 7.0, 4.0, -9.0, 7.0, 6.0, -3.0, 5.0, -1.0, 12.0, -8.0, 12.0, 14.0, 0.0, 5.0, -4.0, 6.0, 12.0, 10.0, -13.0, 7.0, 7.0, -6.0, 7.0, -2.0, 8.0, -3.0, 12.0, 14.0, 5.0, -12.0, 8.0, 9.0, 12.0, 2.0, -8.0, 11.0, 7.0, -8.0, 5.0, 2.0, 8.0, -7.0, 12.0, 14.0, 331.0, 11.0, 11.0, 6.0, 4.0, 10.0, -5.0, 4.0, 10.0, -7.0, 8.0, 2.0, 12.0, -7.0, 8.0, 13.0, 4.0, 7.0, -9.0, 6.0, 10.0, 10.0, -11.0, 11.0, 6.0, -11.0, 9.0, -13.0, 11.0, 6.0, 11.0, 14.0, 3.0, 6.0, -8.0, -5.0, 6.0, 13.0, 1.0, 10.0, 14.0, -11.0, 2.0, -2.0, 9.0, -4.0, 12.0, 12.0, 1.0, -3.0, 5.0, -8.0, 6.0, 12.0, 5.0, 13.0, 13.0, -4.0, -7.0, -2.0, 13.0, -3.0, 7.0, 14.0, 0.0, -11.0, 12.0, -1.0, 6.0, 4.0, 6.0, 9.0, -5.0, 12.0, -1.0, -1.0, 8.0, -4.0, 12.0, 14.0, -3.0, 11.0, -7.0, 9.0, 5.0, 7.0, -6.0, 10.0, 14.0, -3.0, -6.0, 7.0, 6.0, -5.0, 7.0, 13.0, 0.0, 11.0, -9.0, 10.0, 6.0, 9.0, -10.0, 9.0, 13.0, -3.0, -4.0, -12.0, 11.0, 4.0, 12.0, 14.0, -3.0, 10.0, -6.0, 9.0, 6.0, -10.0, 10.0, 12.0, 4.0, -4.0, 3.0, 2.0, 13.0, -7.0, 7.0, 14.0, 0.0, -12.0, 13.0, -6.0, 8.0, 7.0, 6.0, 9.0, 11.0, -8.0, 3.0, -18.0, 11.0, 10.0, 12.0, 14.0, 2.0, 2.0, -3.0, 14.0, 11.0, 1.0, -11.0, 9.0, 14.0, -14.0, 6.0, 0.0, 13.0, -6.0, 8.0, 14.0, 6.0, 6.0, -11.0, 10.0, 5.0, 11.0, -11.0, 12.0, 13.0, -9.0, -1.0, -1.0, 7.0, -2.0, 11.0, 13.0, -2.0, 12.0, -8.0, 9.0, 10.0, 9.0, -13.0, 9.0, 8.0, 12.0, -14.0, 0.0, 8.0, -2.0, 9.0, 11.0, 0.0, 8.0, -4.0, 9.0, 7.0, 11.0, -12.0, 11.0, 5.0, -2.0, 1.0, -9.0, 12.0, 5.0, 7.0, 14.0, 2.0, -10.0, 9.0, 11.0, 10.0, 2.0, -8.0, 12.0, 9.0, 10.0, -16.0, 1.0, 9.0, -6.0, 11.0, 14.0, 7.0, -10.0, 4.0, 6.0, 12.0, -13.0, 10.0, 13.0, 7.0, 12.0, -17.0, -8.0, 6.0, 11.0, 6.0, 14.0, -15.0, 8.0, 8.0, 9.0, 10.0, 10.0, -14.0, 11.0, 10.0, -3.0, -3.0, -13.0, 10.0, 7.0, 11.0, 13.0, 2.0, 13.0, -13.0, 0.0, 5.0, 9.0, 1.0, 11.0, -1.0, 11.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22082994042034898, "mean_inference_ms": 1.182953959655873, "mean_action_processing_ms": 0.07234233949609255, "mean_env_wait_ms": 0.17943575833334044, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 151200, "agent_timesteps_total": 151119, "timers": {"sample_time_ms": 353.845, "sample_throughput": 15260.938, "learn_time_ms": 6656.168, "learn_throughput": 811.278, "update_time_ms": 11.297}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 246.41603088378906, "policy_loss": -0.03170304745435715, "vf_loss": 246.4447021484375, "vf_explained_var": 0.13250011205673218, "kl": 0.010014704428613186, "entropy": 0.6861394047737122, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 151200, "num_agent_steps_sampled": 151119, "num_steps_trained": 151200, "num_agent_steps_trained": 151119}, "done": false, "episodes_total": 2943, "training_iteration": 28, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-44-54", "timestamp": 1626860694, "time_this_iter_s": 7.187797546386719, "time_total_s": 199.1426215171814, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021dc80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 199.1426215171814, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 20.96363636363636, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 12.0, 5.0, 7.0, -4.0, 12.0, -4.0, 11.0, 10.0, 8.0, -11.0, 8.0, 3.0, 13.0, 9.0, -10.0, 9.0, 13.0, -17.0, 10.0, 12.0, 13.0, 7.0, -17.0, 5.0, 14.0, -10.0, 6.0, 7.0, 10.0, 11.0, -13.0, 4.0, 12.0, -10.0, 9.0, -2.0, 8.0, 11.0, -2.0, -4.0, 4.0, 4.0, 11.0, 9.0, 4.0, 12.0, -10.0, -2.0, 10.0, 8.0, -1.0, 14.0, 7.0, -2.0, -4.0, 6.0, 14.0, -16.0, 11.0, 9.0, 4.0, -5.0, 7.0, -1.0, 14.0, -7.0, 9.0, 14.0, 13.0, 7.0, -19.0, 6.0, 12.0, -12.0, 9.0, 6.0, 11.0, 3.0, -5.0, -15.0, 13.0, 8.0, 9.0, 9.0, 12.0, -16.0, 10.0, 10.0, -4.0, -4.0, 13.0, -7.0, 7.0, 11.0, 4.0, -2.0, 13.0, 11.0, -7.0, 3.0, 9.0, 9.0, -6.0, 11.0, 6.0, -14.0, 12.0, 6.0, -5.0, 10.0, 4.0, 9.0, 12.0, -1.0, -5.0, 11.0, 7.0, -2.0, -1.0, -8.0, 6.0, 7.0, 10.0, 1.0, 12.0, 11.0, -9.0, -9.0, 12.0, 5.0, 7.0, 3.0, 8.0, -7.0, 11.0, 3.0, 8.0, -8.0, 12.0, 9.0, -10.0, 11.0, 5.0, 10.0, 14.0, -17.0, 8.0, 6.0, 5.0, -3.0, 7.0, -3.0, -1.0, 8.0, 11.0, 8.0, 3.0, 11.0, -7.0, -1.0, 12.0, -7.0, 11.0, 7.0, 12.0, -11.0, 7.0, 3.0, 14.0, -10.0, 8.0, 14.0, 3.0, 10.0, -12.0, 6.0, 8.0, -7.0, 8.0, 10.0, 3.0, -10.0, 12.0, 9.0, 2.0, -2.0, 6.0, 9.0, 4.0, 11.0, -9.0, -12.0, 13.0, 4.0, 10.0, 7.0, 6.0, -11.0, 13.0, 7.0, 8.0, -8.0, 8.0, 4.0, 8.0, 11.0, -8.0, -15.0, 11.0, 8.0, 11.0, 9.0, 8.0, -4.0, 2.0, -4.0, 13.0, 1.0, 5.0, 4.0, -7.0, 11.0, 7.0, 12.0, 11.0, -17.0, 9.0, 8.0, 6.0, -2.0, 3.0, 10.0, 14.0, -4.0, -5.0, 3.0, 11.0, -9.0, 10.0, 4.0, 14.0, 7.0, -10.0, 5.0, 5.0, 6.0, -1.0, -2.0, 12.0, 0.0, 5.0, 9.0, -3.0, 5.0, 4.0, -14.0, 11.0, 8.0, 10.0, 8.0, 11.0, -12.0, 8.0, 9.0, -2.0, -3.0, 11.0, 12.0, 9.0, 11.0, -17.0, 1.0, 12.0, -8.0, 10.0, -1.0, 5.0, 10.0, 1.0, 10.0, 14.0, 5.0, -14.0, 7.0, -7.0, 4.0, 11.0, 1.0, 7.0, 12.0, -5.0, 11.0, 5.0, -11.0, 10.0, 9.0, 8.0, -7.0, 5.0, 12.0, -8.0, 12.0, -1.0, -13.0, 12.0, 7.0, 9.0, 10.0, 10.0, -11.0, 6.0, 5.0, 14.0, -16.0, 12.0, 2.0, 11.0, -5.0, 7.0, -14.0, 11.0, 13.0, 5.0, 13.0, 8.0, 3.0, -9.0, -7.0, 0.0, 10.0, 12.0, 13.0, 5.0, 12.0, -15.0, -13.0, 12.0, 8.0, 8.0, 14.0, 11.0, -15.0, 5.0, 7.0, 13.0, -10.0, 5.0, 7.0, -7.0, 4.0, 11.0, 6.0, 14.0, -15.0, 10.0, -2.0, 12.0, 7.0, -2.0, 8.0, 14.0, -11.0, 4.0, 8.0, -7.0, 11.0, 3.0, -12.0, 12.0, 6.0, 9.0, -7.0, 4.0, 5.0, 13.0, 11.0, 13.0, -15.0, 6.0, -15.0, 10.0, 11.0, 9.0, 9.0, 13.0, -18.0, 11.0, 9.0, 11.0, -11.0, 6.0, 3.0, 14.0, -11.0, 9.0, 9.0, 10.0, 6.0, -10.0, 3.0, 12.0, 8.0, -8.0, 8.0, 3.0, 6.0, -2.0, -3.0, 3.0, 9.0, 6.0, 4.0, 8.0, -7.0, 10.0, 0.0, 13.0, -8.0, 10.0, 13.0, 11.0, -6.0, -3.0, 5.0, 1.0, -2.0, 11.0, 4.0, -6.0, 10.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22092111954278668, "mean_inference_ms": 1.182628706776602, "mean_action_processing_ms": 0.07232934727628242, "mean_env_wait_ms": 0.17941801269455657, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 156600, "agent_timesteps_total": 156519, "timers": {"sample_time_ms": 353.754, "sample_throughput": 15264.852, "learn_time_ms": 6662.823, "learn_throughput": 810.467, "update_time_ms": 11.26}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 27.000905990600586, "policy_loss": -0.0907389223575592, "vf_loss": 27.086326599121094, "vf_explained_var": 0.16761277616024017, "kl": 0.017733726650476456, "entropy": 0.66558837890625, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 156600, "num_agent_steps_sampled": 156519, "num_steps_trained": 156600, "num_agent_steps_trained": 156519}, "done": false, "episodes_total": 3051, "training_iteration": 29, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-01", "timestamp": 1626860701, "time_this_iter_s": 7.126331567764282, "time_total_s": 206.26895308494568, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021d268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 206.26895308494568, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 21.43, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 12.0, -12.0, 8.0, 10.0, -19.0, 13.0, 11.0, 12.0, 12.0, 2.0, -11.0, 11.0, 11.0, 4.0, -11.0, 12.0, 6.0, -6.0, 3.0, 3.0, 6.0, -3.0, 9.0, 11.0, -3.0, 3.0, 4.0, -7.0, -2.0, 12.0, 12.0, 10.0, 13.0, -9.0, 1.0, 0.0, -5.0, 8.0, 12.0, -12.0, 11.0, 5.0, 11.0, 12.0, -9.0, 1.0, 11.0, 8.0, 9.0, -13.0, 11.0, 7.0, -12.0, 13.0, 7.0, 8.0, 10.0, 7.0, -10.0, -9.0, 11.0, 7.0, 6.0, 10.0, 12.0, -14.0, 7.0, 7.0, 10.0, -8.0, 6.0, -8.0, 6.0, 11.0, 6.0, 11.0, 10.0, -14.0, 8.0, 9.0, 14.0, -5.0, -3.0, 7.0, 10.0, -14.0, 12.0, 2.0, 12.0, 10.0, -9.0, 2.0, -3.0, 13.0, 3.0, 10.0, 13.0, -4.0, -4.0, 8.0, -11.0, 6.0, 12.0, 8.0, 13.0, 3.0, -9.0, 12.0, 9.0, -14.0, 8.0, 9.0, 12.0, 11.0, -17.0, 4.0, -8.0, 8.0, 11.0, -12.0, 11.0, 11.0, 5.0, 5.0, 9.0, 4.0, -3.0, 10.0, 14.0, -9.0, 0.0, 8.0, -6.0, 13.0, 0.0, -11.0, 7.0, 13.0, 6.0, 11.0, 6.0, 4.0, -6.0, -7.0, 12.0, 10.0, 0.0, 10.0, 9.0, -7.0, 3.0, 8.0, 7.0, 6.0, -6.0, -2.0, 8.0, 11.0, -2.0, 12.0, 12.0, -9.0, 0.0, 8.0, 7.0, -5.0, 5.0, -6.0, 9.0, -1.0, 13.0, 12.0, 9.0, 5.0, -11.0, 10.0, 13.0, 9.0, -17.0, 1.0, -3.0, 4.0, 13.0, 8.0, 7.0, 8.0, -8.0, -5.0, 9.0, 13.0, -2.0, 10.0, 12.0, -10.0, 3.0, 3.0, -6.0, 6.0, 12.0, 12.0, -2.0, 4.0, 1.0, 8.0, -8.0, 8.0, 7.0, 8.0, 8.0, -9.0, 8.0, -2.0, 9.0, -5.0, 13.0, -6.0, 7.0, 10.0, 4.0, 8.0, 5.0, 7.0, -5.0, 10.0, 11.0, -13.0, 7.0, 7.0, 9.0, -7.0, 6.0, 4.0, 12.0, 5.0, -6.0, 5.0, 7.0, 4.0, -1.0, 9.0, 13.0, -13.0, 6.0, 3.0, 9.0, -5.0, 8.0, 6.0, -1.0, 9.0, 1.0, -3.0, -5.0, 11.0, 12.0, 8.0, 8.0, -4.0, 3.0, 7.0, -2.0, -1.0, 11.0, -9.0, 5.0, 7.0, 12.0, 2.0, 10.0, 13.0, -10.0, 11.0, 13.0, -4.0, -5.0, -7.0, 6.0, 8.0, 8.0, 10.0, 8.0, 4.0, -7.0, -13.0, 9.0, 8.0, 11.0, -3.0, 11.0, 0.0, 7.0, 3.0, 8.0, -7.0, 11.0, 4.0, 13.0, 6.0, -8.0, -4.0, 9.0, 12.0, -2.0, 11.0, 11.0, -6.0, -1.0, 7.0, -11.0, 9.0, 10.0, -2.0, 12.0, 12.0, -7.0, 5.0, 12.0, 3.0, -5.0, 11.0, 13.0, -12.0, 3.0, 13.0, 13.0, -17.0, 6.0, 5.0, 2.0, -3.0, 11.0, 11.0, 3.0, -7.0, 8.0, -3.0, 7.0, 9.0, 2.0, 1.0, -3.0, 5.0, 12.0, 13.0, -4.0, 5.0, 1.0, -7.0, 7.0, 8.0, 7.0, 11.0, 13.0, -7.0, -2.0, 4.0, -4.0, 2.0, 13.0, 318.0, 13.0, 10.0, 13.0, -2.0, -5.0, 12.0, 10.0, 9.0, 13.0, -8.0, 1.0, 7.0, -8.0, 12.0, 4.0, 9.0, 5.0, 5.0, -4.0, 12.0, 3.0, 3.0, -3.0, 12.0, 8.0, -4.0, -1.0, 3.0, -7.0, 12.0, 7.0, -6.0, 8.0, 9.0, 4.0, 10.0, 11.0, 6.0, -12.0, 11.0, 13.0, -12.0, 3.0, 2.0, 11.0, -7.0, 9.0, 12.0, 10.0, 3.0, -10.0, 10.0, 7.0, 4.0, -6.0, 8.0, 13.0, -9.0, 3.0, 4.0, -11.0, 13.0, 9.0, -1.0, 1.0, 9.0, 6.0, 6.0, 7.0, -10.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22091735873228566, "mean_inference_ms": 1.1824282002891804, "mean_action_processing_ms": 0.07231087017670872, "mean_env_wait_ms": 0.17939078759787175, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 162000, "agent_timesteps_total": 161919, "timers": {"sample_time_ms": 354.002, "sample_throughput": 15254.133, "learn_time_ms": 6667.872, "learn_throughput": 809.854, "update_time_ms": 11.123}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 232.01319885253906, "policy_loss": -0.03204909339547157, "vf_loss": 232.04237365722656, "vf_explained_var": 0.09817009419202805, "kl": 0.009526737965643406, "entropy": 0.7148872017860413, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 162000, "num_agent_steps_sampled": 161919, "num_steps_trained": 162000, "num_agent_steps_trained": 161919}, "done": false, "episodes_total": 3159, "training_iteration": 30, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-09", "timestamp": 1626860709, "time_this_iter_s": 7.21343994140625, "time_total_s": 213.48239302635193, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021d0d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 213.48239302635193, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 21.19, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 12.0, 1.0, -6.0, 7.0, 10.0, 6.0, -8.0, 6.0, 7.0, 7.0, -5.0, 11.0, -4.0, 12.0, -4.0, 3.0, 13.0, 9.0, -10.0, -7.0, 3.0, 8.0, 11.0, 3.0, -9.0, 13.0, 8.0, 5.0, 13.0, -14.0, 11.0, 14.0, 13.0, -18.0, 6.0, 7.0, 4.0, -9.0, 13.0, 7.0, -13.0, 12.0, 9.0, 7.0, 10.0, -6.0, 4.0, 13.0, 11.0, -8.0, -1.0, 12.0, -3.0, 9.0, -3.0, 6.0, -10.0, 13.0, 6.0, 9.0, 0.0, 10.0, -4.0, 14.0, 6.0, -9.0, 4.0, 3.0, 12.0, -5.0, 5.0, 6.0, 3.0, 7.0, -1.0, 10.0, 10.0, -9.0, 4.0, 4.0, 11.0, 8.0, -8.0, 12.0, 4.0, 9.0, -10.0, -5.0, 7.0, 8.0, 5.0, 12.0, 5.0, 9.0, -11.0, -8.0, 12.0, 10.0, 1.0, 13.0, -10.0, 1.0, 11.0, 6.0, -8.0, 9.0, 8.0, 9.0, 7.0, 4.0, -5.0, 14.0, -10.0, 0.0, 11.0, 11.0, -12.0, 8.0, 8.0, -11.0, 10.0, 8.0, 8.0, 4.0, 9.0, 5.0, -3.0, -11.0, 11.0, 9.0, 6.0, -13.0, 12.0, 8.0, 8.0, 13.0, -4.0, 8.0, -2.0, 7.0, 1.0, 11.0, -4.0, 8.0, 12.0, -11.0, 6.0, -8.0, 9.0, 8.0, 6.0, 1.0, -3.0, 7.0, 10.0, 8.0, 3.0, 8.0, -4.0, 9.0, 9.0, -7.0, 4.0, 13.0, -21.0, 10.0, 13.0, -9.0, -1.0, 13.0, 12.0, 10.0, 2.0, 12.0, -9.0, 8.0, -5.0, 2.0, 10.0, 13.0, 4.0, 10.0, -12.0, 4.0, 6.0, 12.0, -7.0, 6.0, 8.0, -1.0, 2.0, 8.0, 7.0, 4.0, -4.0, 6.0, 8.0, 10.0, -9.0, 10.0, -1.0, 13.0, -7.0, 12.0, 7.0, -9.0, 5.0, 8.0, 8.0, 11.0, -12.0, 10.0, 7.0, -15.0, 13.0, -5.0, 3.0, 4.0, 13.0, -11.0, 8.0, 6.0, 12.0, -14.0, 7.0, 9.0, 13.0, 9.0, 12.0, -12.0, 6.0, 2.0, -5.0, 8.0, 10.0, 11.0, 0.0, -7.0, 11.0, 9.0, 11.0, -11.0, 6.0, -3.0, 6.0, 4.0, 8.0, 2.0, 3.0, 13.0, -3.0, 11.0, 6.0, 9.0, -11.0, 13.0, 2.0, 10.0, -10.0, 11.0, 13.0, 3.0, -12.0, 6.0, 3.0, 8.0, -2.0, 1.0, 12.0, -6.0, 8.0, 3.0, 13.0, -11.0, 10.0, -8.0, 10.0, 4.0, 9.0, -7.0, -2.0, 13.0, 11.0, 10.0, -1.0, -5.0, 11.0, -6.0, 8.0, 1.0, 12.0, 4.0, 14.0, -8.0, 5.0, -8.0, 1.0, 13.0, 9.0, 8.0, 0.0, 12.0, -5.0, -1.0, 10.0, -5.0, 11.0, -5.0, 7.0, 6.0, 7.0, 7.0, -1.0, 12.0, -3.0, 12.0, 4.0, -7.0, 6.0, -3.0, -1.0, 11.0, 8.0, 10.0, 1.0, -4.0, 8.0, 7.0, -4.0, 4.0, 8.0, 2.0, 9.0, -7.0, 11.0, 4.0, 13.0, 10.0, -12.0, 11.0, 9.0, -15.0, 10.0, 6.0, -16.0, 12.0, 13.0, 2.0, 5.0, -2.0, 10.0, 9.0, 7.0, 11.0, -12.0, 10.0, 6.0, 8.0, -9.0, 5.0, 0.0, 12.0, -2.0, 13.0, 0.0, 12.0, -10.0, -5.0, 12.0, 4.0, 4.0, -4.0, 6.0, 1.0, 12.0, -9.0, 8.0, 8.0, 8.0, 6.0, 5.0, -7.0, 11.0, 9.0, 8.0, -7.0, 5.0, -7.0, 9.0, 7.0, 6.0, 4.0, -5.0, 10.0, 6.0, 2.0, 6.0, -1.0, 8.0, 2.0, 13.0, -10.0, 10.0, -7.0, 4.0, 7.0, 11.0, 1.0, 11.0, -9.0, 12.0, 2.0, 7.0, 12.0, -6.0, -9.0, 8.0, 12.0, 4.0, -5.0, 14.0, 7.0, -1.0, 8.0, -16.0, 12.0, 11.0, 10.0, 3.0, 12.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2210508492821058, "mean_inference_ms": 1.1830445282964515, "mean_action_processing_ms": 0.0723484252020323, "mean_env_wait_ms": 0.1794797069621536, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 167400, "agent_timesteps_total": 167319, "timers": {"sample_time_ms": 354.495, "sample_throughput": 15232.957, "learn_time_ms": 6668.117, "learn_throughput": 809.824, "update_time_ms": 10.877}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 28.354799270629883, "policy_loss": -0.10083997249603271, "vf_loss": 28.450231552124023, "vf_explained_var": 0.12951166927814484, "kl": 0.01801360212266445, "entropy": 0.7354943752288818, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 167400, "num_agent_steps_sampled": 167319, "num_steps_trained": 167400, "num_agent_steps_trained": 167319}, "done": false, "episodes_total": 3267, "training_iteration": 31, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-16", "timestamp": 1626860716, "time_this_iter_s": 7.096019506454468, "time_total_s": 220.5784125328064, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 220.5784125328064, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 21.279999999999998, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.26851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.31712962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 5.0, -8.0, 4.0, -7.0, 12.0, 1.0, 9.0, -2.0, 9.0, 1.0, 7.0, 5.0, -3.0, 1.0, 12.0, 11.0, -11.0, 10.0, 5.0, 12.0, 12.0, -14.0, 5.0, -1.0, 6.0, 6.0, 4.0, 12.0, -13.0, 10.0, 6.0, 14.0, -9.0, 10.0, 0.0, 4.0, 13.0, -8.0, 6.0, 10.0, 10.0, -4.0, -1.0, 9.0, -13.0, 9.0, 10.0, 14.0, 3.0, 8.0, -10.0, 8.0, 14.0, -15.0, 8.0, -2.0, 5.0, 3.0, 9.0, 11.0, -2.0, -5.0, 11.0, 12.0, -10.0, 11.0, 2.0, 11.0, 11.0, 6.0, -13.0, 14.0, -7.0, 10.0, -2.0, 13.0, 319.0, 11.0, 11.0, 14.0, 0.0, -4.0, 5.0, 3.0, 14.0, -10.0, 8.0, 13.0, 12.0, 8.0, -18.0, 12.0, -2.0, -6.0, 11.0, 10.0, -7.0, 11.0, 1.0, 5.0, 13.0, -14.0, 11.0, 11.0, 12.0, 1.0, -9.0, 4.0, -10.0, 12.0, 9.0, 12.0, -13.0, 9.0, 7.0, 12.0, -7.0, 4.0, 6.0, 11.0, 4.0, 8.0, -8.0, 1.0, -6.0, 12.0, 8.0, 14.0, 12.0, 12.0, 315.0, 6.0, 14.0, 7.0, -12.0, 13.0, 9.0, -8.0, 1.0, 10.0, -6.0, 11.0, 0.0, 10.0, -9.0, 5.0, 9.0, 12.0, 6.0, 3.0, -6.0, -1.0, 3.0, 3.0, 10.0, 7.0, -5.0, 5.0, 8.0, 13.0, 7.0, -3.0, -2.0, -7.0, 10.0, 9.0, 3.0, -2.0, 9.0, 4.0, 4.0, 4.0, -1.0, 6.0, 6.0, 14.0, -15.0, 11.0, 5.0, 6.0, -4.0, 5.0, 8.0, 12.0, 10.0, -14.0, 7.0, 13.0, -11.0, 9.0, 4.0, 14.0, 0.0, -4.0, 5.0, 7.0, -8.0, 11.0, 5.0, 13.0, 11.0, 8.0, -17.0, 5.0, -6.0, 4.0, 12.0, 13.0, 5.0, 7.0, -10.0, 12.0, 13.0, 3.0, -13.0, -1.0, 11.0, 6.0, -1.0, 12.0, -3.0, 0.0, 6.0, 9.0, -9.0, 13.0, 2.0, 13.0, 11.0, 5.0, -14.0, -4.0, 10.0, 8.0, 1.0, 6.0, -3.0, 8.0, 4.0, 12.0, 3.0, 10.0, -10.0, 9.0, 12.0, 2.0, -8.0, 12.0, 9.0, 8.0, -14.0, -1.0, -2.0, 7.0, 11.0, 12.0, 5.0, -2.0, 0.0, 7.0, 13.0, 0.0, -5.0, -1.0, 11.0, 1.0, 4.0, 13.0, -9.0, 11.0, 0.0, 12.0, -14.0, 12.0, 5.0, -6.0, 12.0, -2.0, 11.0, 8.0, 9.0, -9.0, 7.0, -14.0, 9.0, 12.0, 8.0, 13.0, 10.0, -4.0, -4.0, 6.0, 7.0, -7.0, 9.0, 11.0, 6.0, 7.0, -9.0, -10.0, 9.0, 7.0, 9.0, 14.0, 4.0, -4.0, 1.0, 5.0, 13.0, 7.0, -10.0, 13.0, 3.0, -4.0, 3.0, 1.0, -1.0, 4.0, 11.0, 11.0, -12.0, 12.0, 4.0, -10.0, 13.0, 2.0, 10.0, 13.0, 7.0, 0.0, -5.0, 6.0, -9.0, 6.0, 12.0, 14.0, 10.0, -10.0, 1.0, 5.0, 13.0, 9.0, -12.0, -2.0, 12.0, 8.0, -3.0, 9.0, 12.0, 4.0, -10.0, 13.0, 4.0, -6.0, 4.0, 12.0, 13.0, -10.0, 0.0, -1.0, -8.0, 12.0, 12.0, 6.0, -1.0, 1.0, 9.0, 14.0, -17.0, 12.0, 6.0, 7.0, 6.0, -8.0, 10.0, 0.0, 2.0, 9.0, 4.0, 10.0, -18.0, 12.0, 11.0, 14.0, 8.0, -5.0, -2.0, 13.0, 7.0, 11.0, -16.0, 13.0, 11.0, 0.0, -9.0, -8.0, 6.0, 6.0, 11.0, 13.0, 6.0, 12.0, -16.0, 1.0, 13.0, -9.0, 10.0, 14.0, 4.0, 6.0, -9.0, 5.0, -7.0, 6.0, 11.0, 13.0, -4.0, 9.0, -3.0, 8.0, 13.0, 7.0, -13.0, 14.0, 10.0, 0.0, -9.0, 5.0, -3.0, 3.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2211331638303801, "mean_inference_ms": 1.1829578248882007, "mean_action_processing_ms": 0.07233388371759965, "mean_env_wait_ms": 0.17944745754739955, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 172800, "agent_timesteps_total": 172719, "timers": {"sample_time_ms": 354.809, "sample_throughput": 15219.454, "learn_time_ms": 6664.492, "learn_throughput": 810.264, "update_time_ms": 10.99}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 422.54815673828125, "policy_loss": -0.04017185419797897, "vf_loss": 422.5856628417969, "vf_explained_var": 0.10894755274057388, "kl": 0.008977597579360008, "entropy": 0.6565954089164734, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 172800, "num_agent_steps_sampled": 172719, "num_steps_trained": 172800, "num_agent_steps_trained": 172719}, "done": false, "episodes_total": 3375, "training_iteration": 32, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-23", "timestamp": 1626860723, "time_this_iter_s": 7.194265365600586, "time_total_s": 227.77267789840698, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae678c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 227.77267789840698, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 21.318181818181817, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 323.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 4.0, 3.0, -5.0, 8.0, -12.0, 12.0, 7.0, -3.0, -2.0, 13.0, 7.0, -11.0, 14.0, 1.0, 11.0, 12.0, -3.0, 7.0, -1.0, 9.0, -14.0, 8.0, 12.0, 5.0, 10.0, -7.0, 7.0, 10.0, -15.0, 8.0, 12.0, 12.0, 2.0, 6.0, -5.0, -1.0, 2.0, 3.0, 11.0, -12.0, 4.0, 11.0, 12.0, -6.0, 14.0, 10.0, -3.0, 11.0, -4.0, 5.0, 3.0, 13.0, -19.0, 10.0, 11.0, -10.0, 6.0, 7.0, 12.0, -3.0, 7.0, 0.0, 11.0, -2.0, 6.0, 0.0, 11.0, 14.0, -6.0, -4.0, 11.0, 13.0, -15.0, 12.0, 5.0, -10.0, 13.0, 6.0, 6.0, 13.0, 11.0, -3.0, -6.0, 9.0, -2.0, -3.0, 11.0, -2.0, -2.0, 13.0, 6.0, 12.0, 5.0, 4.0, -6.0, 7.0, 11.0, -14.0, 11.0, 13.0, 0.0, 7.0, -5.0, -7.0, 9.0, 10.0, 3.0, 8.0, -13.0, 7.0, 13.0, 10.0, 8.0, 11.0, -14.0, 13.0, -2.0, -4.0, 8.0, -10.0, 1.0, 12.0, 12.0, -11.0, 14.0, 11.0, 1.0, 12.0, 4.0, 10.0, -11.0, 10.0, -10.0, 6.0, 9.0, -5.0, 3.0, 13.0, 4.0, 7.0, 8.0, -11.0, 11.0, 12.0, -6.0, 7.0, 2.0, 6.0, 2.0, -4.0, 11.0, 10.0, 6.0, -2.0, 1.0, 7.0, -12.0, 7.0, 13.0, 12.0, 11.0, -16.0, 8.0, 9.0, -12.0, 11.0, 7.0, -2.0, 0.0, 11.0, 6.0, 3.0, 9.0, 6.0, -3.0, 0.0, 5.0, 2.0, 8.0, 13.0, 3.0, -12.0, 11.0, -13.0, 11.0, 12.0, 5.0, -1.0, -3.0, 8.0, 11.0, 14.0, 8.0, -5.0, -2.0, -7.0, 2.0, 12.0, 8.0, 11.0, -1.0, 12.0, -7.0, 11.0, 8.0, -15.0, 11.0, 12.0, 6.0, -13.0, 10.0, 14.0, -11.0, 2.0, 10.0, 6.0, 4.0, -3.0, 8.0, 10.0, 8.0, 6.0, -9.0, 11.0, 7.0, 6.0, -9.0, 14.0, -17.0, 7.0, 11.0, 12.0, 1.0, 12.0, -10.0, 11.0, 323.0, 11.0, 11.0, 14.0, -3.0, 6.0, -2.0, -8.0, 2.0, 9.0, 12.0, -11.0, 10.0, 12.0, 4.0, -10.0, 13.0, -1.0, 13.0, 12.0, 6.0, 12.0, -15.0, 14.0, -17.0, 8.0, 10.0, 0.0, -2.0, 12.0, 5.0, -1.0, -4.0, 7.0, 13.0, 8.0, 8.0, -12.0, 11.0, 14.0, -7.0, -4.0, 12.0, 4.0, -9.0, 12.0, 8.0, 10.0, 10.0, -4.0, -1.0, -7.0, 7.0, 4.0, 11.0, 10.0, 0.0, 13.0, -8.0, -7.0, -1.0, 12.0, 11.0, 3.0, 13.0, 1.0, -2.0, 10.0, 13.0, -18.0, 10.0, 12.0, -7.0, 3.0, 7.0, -4.0, 5.0, 7.0, 7.0, -2.0, -4.0, 9.0, 12.0, 8.0, -3.0, 2.0, 8.0, 13.0, -3.0, -6.0, 11.0, -7.0, 6.0, 12.0, 4.0, -9.0, 8.0, 3.0, 13.0, 12.0, -7.0, 5.0, 5.0, 9.0, -3.0, -2.0, 11.0, -7.0, 7.0, 11.0, 4.0, -7.0, 8.0, 1.0, 13.0, 11.0, -2.0, 7.0, -1.0, 14.0, -14.0, 4.0, 11.0, 1.0, 6.0, -4.0, 12.0, 13.0, -17.0, 6.0, 13.0, 12.0, -1.0, 6.0, -2.0, 10.0, -2.0, 11.0, -4.0, -2.0, -1.0, 10.0, 8.0, -9.0, 14.0, 2.0, 8.0, 9.0, 7.0, 11.0, -12.0, 11.0, -5.0, 12.0, -3.0, 7.0, 1.0, 9.0, -2.0, 7.0, 13.0, -4.0, -1.0, 13.0, 0.0, 6.0, -4.0, 11.0, 8.0, -11.0, 7.0, -2.0, 6.0, 9.0, 2.0, -2.0, 14.0, 4.0, -1.0, 14.0, 0.0, -4.0, 5.0, 13.0, -6.0, -2.0, 10.0, -14.0, 10.0, 13.0, 6.0, -8.0, 9.0, 2.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22119227190741195, "mean_inference_ms": 1.182902264413235, "mean_action_processing_ms": 0.07231854589553963, "mean_env_wait_ms": 0.17947594863850594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 178200, "agent_timesteps_total": 178119, "timers": {"sample_time_ms": 355.121, "sample_throughput": 15206.066, "learn_time_ms": 6667.922, "learn_throughput": 809.848, "update_time_ms": 11.014}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 236.56263732910156, "policy_loss": -0.034984417259693146, "vf_loss": 236.59402465820312, "vf_explained_var": 0.11702017486095428, "kl": 0.011926502920687199, "entropy": 0.642509937286377, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 178200, "num_agent_steps_sampled": 178119, "num_steps_trained": 178200, "num_agent_steps_trained": 178119}, "done": false, "episodes_total": 3483, "training_iteration": 33, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-30", "timestamp": 1626860730, "time_this_iter_s": 7.101929187774658, "time_total_s": 234.87460708618164, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae677b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 234.87460708618164, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 21.509999999999998, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 1.0, -2.0, 9.0, -7.0, 5.0, 11.0, 6.0, 6.0, 14.0, -11.0, 6.0, 6.0, -10.0, 8.0, 11.0, -9.0, 14.0, 3.0, 7.0, 8.0, -11.0, 11.0, 7.0, 0.0, -7.0, 9.0, 13.0, 13.0, -17.0, 6.0, 13.0, -13.0, 8.0, 12.0, 8.0, 9.0, 4.0, 6.0, -4.0, 3.0, -10.0, 9.0, 13.0, 10.0, 0.0, -8.0, 13.0, 6.0, -13.0, 12.0, 10.0, -10.0, 8.0, 5.0, 12.0, -3.0, -3.0, 8.0, 13.0, 13.0, 6.0, -15.0, 11.0, 7.0, 9.0, 10.0, -11.0, -9.0, 13.0, 11.0, 0.0, -2.0, 7.0, -3.0, 13.0, 13.0, -9.0, 0.0, 11.0, 5.0, 5.0, 11.0, -6.0, 8.0, 8.0, -10.0, 9.0, 2.0, 6.0, -5.0, 12.0, 10.0, -6.0, 2.0, 9.0, 8.0, 9.0, -13.0, 11.0, -5.0, 14.0, 8.0, -2.0, 6.0, -8.0, 6.0, 11.0, 0.0, -8.0, 10.0, 13.0, 8.0, 6.0, 12.0, -11.0, -7.0, 3.0, 8.0, 11.0, 6.0, 12.0, 5.0, -8.0, 13.0, -2.0, 11.0, -7.0, -9.0, 4.0, 13.0, 7.0, 8.0, 7.0, 8.0, -8.0, 2.0, -8.0, 8.0, 13.0, 3.0, 3.0, -2.0, 11.0, 8.0, 3.0, -3.0, 7.0, -9.0, 10.0, 7.0, 7.0, -5.0, -3.0, 11.0, 12.0, 9.0, -12.0, 5.0, 13.0, 4.0, 9.0, -10.0, 12.0, 10.0, 4.0, -8.0, 9.0, -5.0, 12.0, -5.0, 13.0, 13.0, 13.0, 10.0, 320.0, 5.0, 9.0, -9.0, 10.0, 6.0, 2.0, 11.0, -4.0, -11.0, 14.0, 8.0, 4.0, 9.0, -16.0, 9.0, 13.0, 1.0, 9.0, 12.0, -7.0, -16.0, 9.0, 11.0, 11.0, -14.0, 6.0, 10.0, 13.0, 2.0, -5.0, 6.0, 12.0, 9.0, 7.0, -7.0, 6.0, 3.0, 7.0, 11.0, -6.0, 0.0, -9.0, 11.0, 13.0, 12.0, 12.0, -2.0, -7.0, 6.0, 9.0, -8.0, 8.0, -5.0, 1.0, 12.0, 7.0, 5.0, 13.0, -13.0, 10.0, 6.0, -13.0, 11.0, 11.0, -12.0, 9.0, 13.0, 5.0, 4.0, 12.0, 11.0, -12.0, 8.0, 14.0, 2.0, -9.0, 6.0, -14.0, 10.0, 13.0, 6.0, 4.0, -7.0, 12.0, 4.0, 3.0, 12.0, -4.0, 6.0, 12.0, -13.0, 10.0, 4.0, -8.0, 10.0, 9.0, -7.0, 8.0, 7.0, 7.0, 5.0, 13.0, -13.0, 10.0, 3.0, 5.0, -5.0, 12.0, 5.0, -1.0, 3.0, 8.0, 1.0, 9.0, 12.0, -7.0, -15.0, 13.0, 6.0, 11.0, -1.0, 7.0, -2.0, 11.0, 13.0, -21.0, 10.0, 13.0, -8.0, 9.0, 11.0, 3.0, 8.0, -8.0, 6.0, 9.0, 7.0, 14.0, -9.0, 3.0, 9.0, -8.0, 10.0, 4.0, 6.0, 9.0, -12.0, 12.0, -8.0, 13.0, 7.0, 3.0, 5.0, 1.0, -4.0, 13.0, 5.0, -4.0, 1.0, 13.0, 8.0, 4.0, 12.0, -9.0, 9.0, 14.0, -13.0, 5.0, -10.0, 3.0, 9.0, 13.0, 7.0, -14.0, 9.0, 13.0, 8.0, 4.0, -5.0, 8.0, 10.0, 12.0, 11.0, -18.0, 3.0, -11.0, 10.0, 13.0, 13.0, 7.0, -18.0, 13.0, 2.0, 14.0, -10.0, 9.0, -15.0, 14.0, 11.0, 5.0, 6.0, 12.0, -8.0, 5.0, 10.0, -9.0, 3.0, 11.0, 8.0, 6.0, -1.0, 2.0, -7.0, -1.0, 10.0, 13.0, -16.0, 9.0, 9.0, 13.0, 7.0, -12.0, 7.0, 13.0, 9.0, -11.0, 12.0, 5.0, 6.0, 8.0, 9.0, -8.0, 6.0, 13.0, 5.0, -9.0, 10.0, -6.0, -2.0, 13.0, 5.0, 9.0, -10.0, 11.0, -3.0, 12.0, 6.0, 0.0, -18.0, 10.0, 10.0, 13.0, 9.0, -4.0, -3.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2211995036448797, "mean_inference_ms": 1.18264533063282, "mean_action_processing_ms": 0.07232735385749461, "mean_env_wait_ms": 0.17950719671657542, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 183600, "agent_timesteps_total": 183519, "timers": {"sample_time_ms": 355.084, "sample_throughput": 15207.668, "learn_time_ms": 6655.874, "learn_throughput": 811.313, "update_time_ms": 11.198}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 231.1559295654297, "policy_loss": -0.04158211126923561, "vf_loss": 231.1942901611328, "vf_explained_var": 0.13283571600914001, "kl": 0.010695072822272778, "entropy": 0.6821498274803162, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 183600, "num_agent_steps_sampled": 183519, "num_steps_trained": 183600, "num_agent_steps_trained": 183519}, "done": false, "episodes_total": 3591, "training_iteration": 34, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-37", "timestamp": 1626860737, "time_this_iter_s": 7.042150259017944, "time_total_s": 241.91675734519958, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701fac80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 241.91675734519958, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 22.339999999999996, "ram_util_percent": 14.11}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 7.0, -5.0, 13.0, 4.0, 8.0, -5.0, 8.0, 6.0, 8.0, -9.0, 10.0, 9.0, 7.0, -12.0, 11.0, 2.0, 11.0, -4.0, 6.0, 1.0, 13.0, -7.0, 8.0, 9.0, 11.0, -18.0, 13.0, 14.0, -2.0, -4.0, 7.0, -8.0, -1.0, 11.0, 13.0, 9.0, 6.0, 8.0, -8.0, 5.0, 9.0, -11.0, 12.0, 9.0, -11.0, 9.0, 8.0, -18.0, 10.0, 10.0, 13.0, -3.0, 13.0, -7.0, 12.0, -1.0, 10.0, 11.0, -5.0, 7.0, 7.0, 10.0, -9.0, 2.0, 8.0, -4.0, 9.0, 5.0, 8.0, -7.0, 9.0, 0.0, 12.0, -10.0, 13.0, 8.0, 8.0, 6.0, -7.0, -10.0, 5.0, 10.0, 10.0, 7.0, 3.0, -6.0, 11.0, 8.0, 10.0, -14.0, 11.0, 13.0, 12.0, -7.0, -3.0, -16.0, 8.0, 11.0, 12.0, 7.0, 9.0, -5.0, 4.0, 9.0, 5.0, 3.0, -2.0, 8.0, -3.0, 9.0, 1.0, -13.0, 7.0, 12.0, 9.0, 2.0, 6.0, -4.0, 11.0, 13.0, 9.0, -19.0, 12.0, 7.0, 3.0, 11.0, -6.0, -10.0, 3.0, 10.0, 12.0, 2.0, -7.0, 11.0, 9.0, 12.0, 6.0, 6.0, -9.0, 13.0, 8.0, -16.0, 10.0, -19.0, 11.0, 10.0, 13.0, 3.0, 13.0, -4.0, 3.0, 3.0, 8.0, 8.0, -4.0, 12.0, -2.0, -7.0, 12.0, -6.0, 7.0, 10.0, 4.0, 1.0, 7.0, -4.0, 11.0, 14.0, 0.0, 11.0, -10.0, 4.0, -9.0, 12.0, 8.0, -10.0, 9.0, 13.0, 3.0, 8.0, 10.0, -7.0, 4.0, -4.0, 5.0, 3.0, 11.0, 8.0, -3.0, 7.0, 3.0, -7.0, 5.0, 8.0, 9.0, 4.0, 7.0, -6.0, 10.0, 12.0, 1.0, -11.0, 13.0, 9.0, 6.0, -12.0, 12.0, -11.0, 9.0, 8.0, 9.0, 13.0, 7.0, 0.0, -5.0, -7.0, 6.0, 11.0, 5.0, 5.0, 5.0, 10.0, -5.0, -7.0, 5.0, 10.0, 7.0, 4.0, 4.0, -5.0, 12.0, 6.0, 7.0, 12.0, -10.0, 13.0, -4.0, -2.0, 8.0, 5.0, -11.0, 12.0, 9.0, 2.0, 12.0, -4.0, 5.0, 8.0, 3.0, 6.0, -2.0, 6.0, 12.0, 9.0, -12.0, -12.0, 12.0, 7.0, 8.0, 9.0, 6.0, -4.0, 4.0, -5.0, 7.0, 11.0, 2.0, 9.0, -4.0, 4.0, 6.0, -9.0, 5.0, 12.0, 7.0, 9.0, 7.0, -8.0, 7.0, 9.0, 8.0, 8.0, -10.0, 14.0, 9.0, -5.0, -3.0, -9.0, 10.0, 12.0, 2.0, 3.0, 8.0, -7.0, 11.0, 10.0, 4.0, 3.0, -2.0, 14.0, 12.0, -6.0, -5.0, 1.0, 6.0, -2.0, 10.0, 13.0, -10.0, 8.0, 4.0, 10.0, 8.0, -16.0, 13.0, 13.0, -2.0, -2.0, 6.0, 3.0, 11.0, 10.0, -9.0, 13.0, 3.0, -7.0, 6.0, 0.0, 11.0, -3.0, 7.0, 5.0, 8.0, 9.0, -7.0, -16.0, 9.0, 9.0, 13.0, 8.0, 10.0, 2.0, -5.0, 13.0, 10.0, -17.0, 9.0, 14.0, 10.0, -8.0, -1.0, -17.0, 9.0, 10.0, 13.0, 9.0, 7.0, -8.0, 7.0, -5.0, 5.0, 4.0, 11.0, 8.0, -6.0, 9.0, 4.0, -14.0, 11.0, 10.0, 8.0, -3.0, 13.0, 11.0, -6.0, 13.0, 11.0, 8.0, -17.0, 8.0, -9.0, 10.0, 6.0, 5.0, 9.0, -8.0, 9.0, 9.0, 1.0, -5.0, 10.0, 13.0, 7.0, -10.0, 5.0, 8.0, 9.0, 4.0, -6.0, 7.0, 8.0, 11.0, -11.0, 9.0, 1.0, -6.0, 11.0, 9.0, 4.0, -2.0, 4.0, 9.0, 6.0, 5.0, -5.0, -12.0, 8.0, 10.0, 9.0, 8.0, 14.0, 2.0, -9.0, 1.0, -7.0, 11.0, 10.0, 13.0, -10.0, 6.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22122734166005437, "mean_inference_ms": 1.1824689553209486, "mean_action_processing_ms": 0.07232763801209074, "mean_env_wait_ms": 0.17952953313538436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 189000, "agent_timesteps_total": 188919, "timers": {"sample_time_ms": 354.933, "sample_throughput": 15214.129, "learn_time_ms": 6653.638, "learn_throughput": 811.586, "update_time_ms": 11.086}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 28.52177619934082, "policy_loss": -0.09021114557981491, "vf_loss": 28.606189727783203, "vf_explained_var": 0.15562734007835388, "kl": 0.01933484710752964, "entropy": 0.6238858699798584, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 189000, "num_agent_steps_sampled": 188919, "num_steps_trained": 189000, "num_agent_steps_trained": 188919}, "done": false, "episodes_total": 3699, "training_iteration": 35, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-44", "timestamp": 1626860744, "time_this_iter_s": 7.063632965087891, "time_total_s": 248.98039031028748, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701fa158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 248.98039031028748, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 21.6, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 12.0, 5.0, 11.0, 10.0, 11.0, 8.0, -14.0, 10.0, 12.0, 2.0, -9.0, 7.0, 9.0, 8.0, -9.0, -19.0, 11.0, 11.0, 12.0, -6.0, 10.0, 3.0, 8.0, 12.0, -10.0, 3.0, 10.0, 7.0, -3.0, 10.0, 1.0, 6.0, 13.0, -14.0, 10.0, -5.0, 7.0, 6.0, 7.0, 1.0, -11.0, 13.0, 12.0, 9.0, 13.0, -12.0, 5.0, -19.0, 14.0, 10.0, 10.0, 8.0, 7.0, 8.0, -8.0, 11.0, -1.0, -7.0, 12.0, 14.0, 0.0, 5.0, -4.0, -17.0, 11.0, 8.0, 13.0, 9.0, -4.0, 2.0, 8.0, 14.0, -17.0, 7.0, 11.0, 9.0, -3.0, 5.0, 4.0, -6.0, 14.0, -6.0, 13.0, 5.0, -7.0, 8.0, 9.0, 13.0, 9.0, 3.0, -10.0, 9.0, -1.0, 10.0, -3.0, -14.0, 14.0, 6.0, 9.0, -9.0, 5.0, 7.0, 12.0, 11.0, -2.0, 7.0, -1.0, 2.0, 13.0, -12.0, 12.0, -13.0, 10.0, 7.0, 11.0, -3.0, 7.0, 7.0, 4.0, 11.0, -1.0, 6.0, -1.0, 4.0, 14.0, -6.0, 3.0, -7.0, 12.0, 1.0, 9.0, 11.0, -10.0, 8.0, 6.0, 9.0, 11.0, -13.0, 8.0, 8.0, -2.0, -1.0, 10.0, 5.0, 12.0, -1.0, -1.0, 2.0, 13.0, 7.0, -7.0, 3.0, -12.0, 12.0, 12.0, 4.0, -3.0, 10.0, 4.0, -19.0, 14.0, 10.0, 10.0, 12.0, -11.0, 6.0, 8.0, 14.0, 3.0, 6.0, -8.0, 9.0, -5.0, 5.0, 6.0, -18.0, 14.0, 10.0, 9.0, -2.0, 6.0, 6.0, 5.0, 14.0, 3.0, 5.0, -7.0, 9.0, -6.0, 6.0, 6.0, -3.0, 9.0, 2.0, 7.0, 7.0, -14.0, 10.0, 12.0, 3.0, 7.0, 10.0, -5.0, -6.0, 14.0, 4.0, 3.0, -18.0, 14.0, 9.0, 10.0, -4.0, 0.0, 12.0, 7.0, 0.0, 9.0, -2.0, 8.0, -4.0, 13.0, 2.0, 4.0, -9.0, 14.0, 0.0, 10.0, -1.0, -3.0, 7.0, 12.0, 7.0, 12.0, 13.0, -17.0, 7.0, 13.0, 11.0, -16.0, 0.0, 10.0, -8.0, 13.0, 7.0, -6.0, 6.0, 8.0, 8.0, -8.0, 3.0, 12.0, 7.0, 0.0, 1.0, 7.0, -14.0, 14.0, 9.0, 6.0, -5.0, 4.0, 4.0, 12.0, 7.0, -15.0, 11.0, 12.0, 14.0, -8.0, 8.0, 1.0, 4.0, 13.0, -11.0, 9.0, 5.0, 11.0, 7.0, -8.0, 12.0, 4.0, 1.0, -2.0, 10.0, 0.0, 1.0, 4.0, -16.0, 11.0, 12.0, 8.0, 1.0, 4.0, 13.0, -3.0, 13.0, -1.0, -5.0, 8.0, 7.0, 13.0, 5.0, -10.0, 6.0, 13.0, -11.0, 7.0, 5.0, -2.0, 8.0, 4.0, 12.0, 1.0, -9.0, 11.0, 9.0, 11.0, -4.0, -1.0, -20.0, 13.0, 10.0, 12.0, 8.0, -2.0, 8.0, 1.0, 14.0, 0.0, 7.0, -6.0, 14.0, -2.0, 5.0, -2.0, -17.0, 13.0, 9.0, 10.0, 7.0, -10.0, 8.0, 10.0, 5.0, 7.0, 13.0, -10.0, 14.0, -6.0, 5.0, 2.0, -12.0, 12.0, 8.0, 7.0, -4.0, 3.0, 8.0, 8.0, 13.0, -8.0, -1.0, 11.0, 9.0, -2.0, 4.0, 4.0, 2.0, 13.0, 8.0, -8.0, 8.0, -13.0, 7.0, 13.0, 12.0, 12.0, 3.0, -12.0, 14.0, 12.0, -1.0, -10.0, -14.0, 10.0, 10.0, 9.0, -4.0, 12.0, 8.0, -1.0, 14.0, -9.0, 3.0, 7.0, 14.0, -1.0, -5.0, 7.0, -15.0, 14.0, 5.0, 11.0, 6.0, -8.0, 6.0, 11.0, 13.0, -16.0, 6.0, 12.0, 5.0, 14.0, -14.0, 10.0, -15.0, 13.0, 8.0, 9.0, 7.0, 10.0, -9.0, 7.0, 1.0, -11.0, 12.0, 13.0, 6.0, 13.0, -5.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22123636878096498, "mean_inference_ms": 1.1823741197763864, "mean_action_processing_ms": 0.07233365019702662, "mean_env_wait_ms": 0.17947545277918278, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 194400, "agent_timesteps_total": 194319, "timers": {"sample_time_ms": 353.778, "sample_throughput": 15263.826, "learn_time_ms": 6673.071, "learn_throughput": 809.223, "update_time_ms": 11.101}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 33.16122817993164, "policy_loss": -0.09102402627468109, "vf_loss": 33.24689865112305, "vf_explained_var": 0.1560031622648239, "kl": 0.01784498244524002, "entropy": 0.6443585753440857, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 194400, "num_agent_steps_sampled": 194319, "num_steps_trained": 194400, "num_agent_steps_trained": 194319}, "done": false, "episodes_total": 3807, "training_iteration": 36, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-52", "timestamp": 1626860752, "time_this_iter_s": 7.210782289505005, "time_total_s": 256.1911725997925, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701fa840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 256.1911725997925, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 21.240000000000002, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 1.0, 8.0, -7.0, -10.0, 10.0, 3.0, 12.0, -4.0, 7.0, 1.0, 11.0, 5.0, 9.0, 9.0, -8.0, 9.0, 12.0, 8.0, -14.0, 11.0, 6.0, -5.0, 3.0, 14.0, 2.0, -6.0, 5.0, -3.0, 7.0, 5.0, 6.0, 2.0, 10.0, 10.0, -7.0, -8.0, 10.0, 1.0, 12.0, -8.0, 12.0, 4.0, 7.0, 12.0, 5.0, 12.0, -14.0, 3.0, 2.0, 11.0, -1.0, 10.0, -5.0, 5.0, 5.0, 12.0, -19.0, 9.0, 13.0, 7.0, -1.0, 12.0, -3.0, 1.0, 7.0, -6.0, 13.0, 3.0, -2.0, 6.0, 8.0, 10.0, -4.0, -3.0, 12.0, 11.0, -3.0, 12.0, -5.0, 6.0, 11.0, -1.0, -1.0, 9.0, 10.0, -10.0, 6.0, -8.0, 4.0, 8.0, 11.0, 4.0, 9.0, 9.0, -7.0, 10.0, 0.0, -6.0, 11.0, -3.0, 9.0, 4.0, 5.0, -7.0, -1.0, 13.0, 10.0, 9.0, 1.0, 13.0, -8.0, -10.0, 7.0, 13.0, 5.0, 5.0, -7.0, 11.0, 6.0, 5.0, 4.0, 9.0, -3.0, 3.0, 11.0, -7.0, 8.0, 9.0, 0.0, -4.0, 10.0, 5.0, -4.0, 9.0, 5.0, -3.0, -5.0, 10.0, 13.0, 13.0, -9.0, 6.0, 5.0, 2.0, 2.0, 13.0, -2.0, 11.0, 7.0, 4.0, -7.0, 4.0, 3.0, 10.0, -2.0, -9.0, 6.0, 7.0, 11.0, 10.0, 321.0, 12.0, 13.0, 3.0, 7.0, -7.0, 12.0, 13.0, -7.0, 12.0, -3.0, 13.0, -8.0, 6.0, 4.0, 11.0, 9.0, -7.0, 2.0, -13.0, 11.0, 10.0, 7.0, 10.0, 5.0, 8.0, -8.0, 13.0, -4.0, -6.0, 12.0, 3.0, 11.0, -1.0, 2.0, 6.0, 12.0, -14.0, 11.0, -1.0, 2.0, 2.0, 12.0, 13.0, 5.0, 8.0, -11.0, 10.0, 12.0, -9.0, 2.0, 9.0, -6.0, 5.0, 7.0, 11.0, 4.0, 7.0, -7.0, 13.0, -3.0, 11.0, -6.0, -7.0, 5.0, 7.0, 10.0, -6.0, 3.0, 6.0, 12.0, -4.0, -1.0, 10.0, 10.0, -6.0, 6.0, 6.0, 9.0, -12.0, 5.0, 9.0, 13.0, 11.0, -4.0, 6.0, 2.0, 11.0, -18.0, 9.0, 13.0, -6.0, 11.0, 7.0, 3.0, 9.0, 11.0, -3.0, -2.0, -8.0, 11.0, 5.0, 7.0, 11.0, -5.0, -3.0, 12.0, 9.0, -10.0, 11.0, 5.0, 12.0, 6.0, 7.0, -10.0, 9.0, 8.0, 10.0, -12.0, 10.0, -6.0, 13.0, -2.0, -13.0, 5.0, 11.0, 12.0, 7.0, 7.0, 13.0, -12.0, 11.0, -4.0, 1.0, 7.0, -2.0, 4.0, 3.0, 10.0, 8.0, -7.0, 11.0, 3.0, -13.0, 11.0, 13.0, 4.0, -2.0, 11.0, 10.0, -4.0, 11.0, -3.0, 9.0, -2.0, -11.0, 11.0, 13.0, 2.0, 1.0, 12.0, -1.0, 3.0, -8.0, 12.0, 4.0, 7.0, 9.0, 1.0, 9.0, -4.0, -10.0, 7.0, 7.0, 11.0, 0.0, 10.0, -6.0, 11.0, -9.0, 12.0, 4.0, 8.0, 9.0, 6.0, -5.0, 5.0, -6.0, 4.0, 11.0, 6.0, 12.0, 12.0, -2.0, -7.0, 6.0, -5.0, 12.0, 2.0, 9.0, 9.0, -8.0, 5.0, 8.0, 8.0, 12.0, -13.0, 7.0, 8.0, 7.0, -7.0, 4.0, -5.0, 9.0, 7.0, -7.0, 3.0, 9.0, 10.0, 4.0, -9.0, 12.0, 8.0, 3.0, 8.0, -2.0, 6.0, -8.0, 12.0, 8.0, 3.0, 10.0, -18.0, 13.0, 10.0, -9.0, 8.0, 9.0, 7.0, -4.0, -2.0, 13.0, 8.0, -7.0, 8.0, 5.0, 9.0, 0.0, -2.0, 7.0, 10.0, -5.0, -1.0, 11.0, 10.0, -17.0, 11.0, 13.0, 8.0, 11.0, -9.0, 7.0, 6.0, 13.0, -9.0, 13.0, -2.0, 4.0, 11.0, 12.0, -12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22106362699688595, "mean_inference_ms": 1.1828379696497315, "mean_action_processing_ms": 0.07233508275933707, "mean_env_wait_ms": 0.17952952175221223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 199800, "agent_timesteps_total": 199722, "timers": {"sample_time_ms": 354.135, "sample_throughput": 15248.402, "learn_time_ms": 6675.708, "learn_throughput": 808.903, "update_time_ms": 11.062}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 211.8249053955078, "policy_loss": -0.03162892907857895, "vf_loss": 211.85345458984375, "vf_explained_var": 0.08452015370130539, "kl": 0.010281356051564217, "entropy": 0.6126949787139893, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 199800, "num_agent_steps_sampled": 199722, "num_steps_trained": 199800, "num_agent_steps_trained": 199722}, "done": false, "episodes_total": 3915, "training_iteration": 37, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-45-59", "timestamp": 1626860759, "time_this_iter_s": 7.088934421539307, "time_total_s": 263.2801070213318, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 263.2801070213318, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 21.909090909090907, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-16.0, 12.0, 8.0, 11.0, 4.0, -5.0, 5.0, 11.0, -2.0, 3.0, 5.0, 9.0, -10.0, 7.0, 6.0, 12.0, 7.0, 12.0, 1.0, -5.0, 8.0, 7.0, -6.0, 6.0, 11.0, -10.0, 5.0, 9.0, 11.0, -9.0, 9.0, 4.0, -13.0, 14.0, 3.0, 11.0, 11.0, 9.0, -16.0, 11.0, -6.0, 10.0, 4.0, 7.0, -6.0, 2.0, 11.0, 8.0, -9.0, 12.0, 2.0, 10.0, 12.0, 1.0, 10.0, -8.0, 10.0, -5.0, 7.0, 3.0, -2.0, 11.0, 11.0, -5.0, -18.0, 14.0, 12.0, 7.0, 8.0, 14.0, -5.0, -2.0, 8.0, -16.0, 10.0, 13.0, 9.0, 10.0, 3.0, -7.0, -15.0, 12.0, 5.0, 13.0, 13.0, 12.0, -20.0, 10.0, 5.0, 6.0, -6.0, 10.0, 5.0, 4.0, 8.0, -2.0, -2.0, -6.0, 11.0, 12.0, -7.0, 9.0, 11.0, 2.0, 0.0, -2.0, 9.0, 8.0, 4.0, 8.0, 8.0, -5.0, 6.0, 13.0, 0.0, -4.0, 14.0, 12.0, -20.0, 9.0, -6.0, 8.0, 12.0, 1.0, -2.0, 1.0, 5.0, 11.0, -8.0, 11.0, 3.0, 9.0, 12.0, -4.0, 2.0, 5.0, 6.0, -6.0, 4.0, 11.0, 14.0, -5.0, -1.0, 7.0, 2.0, -7.0, 12.0, 8.0, 13.0, 13.0, -8.0, -3.0, -5.0, 10.0, 11.0, -1.0, 9.0, -6.0, 3.0, 9.0, 0.0, 12.0, 9.0, -6.0, 9.0, 8.0, -8.0, 6.0, 3.0, 13.0, 9.0, -10.0, -6.0, 6.0, 13.0, 2.0, -17.0, 13.0, 7.0, 12.0, 13.0, 12.0, -19.0, 9.0, 2.0, 12.0, 11.0, -10.0, -9.0, 13.0, 6.0, 5.0, 12.0, -7.0, -1.0, 11.0, 14.0, 11.0, 6.0, -16.0, -10.0, 7.0, 10.0, 8.0, 14.0, -6.0, -3.0, 10.0, 8.0, -13.0, 10.0, 10.0, 13.0, -1.0, -8.0, 11.0, 5.0, -9.0, 10.0, 9.0, 9.0, -5.0, 6.0, 5.0, -12.0, 13.0, 6.0, 8.0, 14.0, 7.0, -17.0, 11.0, 9.0, -4.0, 6.0, 4.0, -11.0, 9.0, 8.0, 9.0, 4.0, 13.0, 4.0, -6.0, 11.0, 13.0, 5.0, -14.0, 2.0, -7.0, 7.0, 13.0, 11.0, -12.0, 5.0, 11.0, 11.0, -4.0, -2.0, 10.0, -10.0, 8.0, 6.0, 11.0, -8.0, 10.0, 5.0, 8.0, -4.0, 10.0, 3.0, 6.0, 2.0, 12.0, -9.0, 10.0, 13.0, 9.0, 10.0, -17.0, 10.0, -14.0, 11.0, 8.0, -2.0, -8.0, 13.0, 12.0, 7.0, -11.0, 8.0, 11.0, 13.0, 11.0, -12.0, 3.0, 5.0, -8.0, 10.0, 8.0, 12.0, -4.0, 6.0, 1.0, 1.0, 13.0, 2.0, -1.0, 10.0, 14.0, -19.0, 10.0, -10.0, 12.0, 9.0, 4.0, 9.0, 7.0, 5.0, -6.0, -11.0, 11.0, 10.0, 5.0, 10.0, 14.0, 8.0, -17.0, 7.0, -8.0, 12.0, 4.0, 7.0, -3.0, 11.0, 0.0, 4.0, -9.0, 7.0, 13.0, 14.0, -16.0, 10.0, 7.0, -5.0, 12.0, -2.0, 10.0, 6.0, -6.0, 5.0, 10.0, 7.0, -3.0, 6.0, 5.0, 13.0, 14.0, 4.0, -16.0, 9.0, -3.0, 6.0, 3.0, -8.0, 2.0, 13.0, 8.0, 7.0, -4.0, 3.0, 9.0, 14.0, 5.0, 10.0, -14.0, -2.0, 11.0, -3.0, 9.0, 14.0, -2.0, 10.0, -7.0, 5.0, 12.0, 8.0, -10.0, 11.0, 12.0, -20.0, 12.0, 11.0, -13.0, 10.0, 7.0, -3.0, -7.0, 13.0, 12.0, 6.0, 12.0, 2.0, -5.0, 11.0, 13.0, -8.0, -1.0, -10.0, 14.0, 6.0, 5.0, 0.0, 3.0, 0.0, 12.0, 4.0, -1.0, 1.0, 11.0, 12.0, 7.0, -13.0, 9.0, 10.0, 3.0, -10.0, 12.0, 12.0, -12.0, 9.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22063485820734405, "mean_inference_ms": 1.182752366395376, "mean_action_processing_ms": 0.0723560255573968, "mean_env_wait_ms": 0.17958378445264706, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 205200, "agent_timesteps_total": 205173, "timers": {"sample_time_ms": 353.911, "sample_throughput": 15258.07, "learn_time_ms": 6676.405, "learn_throughput": 808.818, "update_time_ms": 10.964}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 37.2347297668457, "policy_loss": -0.0882248803973198, "vf_loss": 37.31771469116211, "vf_explained_var": 0.15525728464126587, "kl": 0.017476750537753105, "entropy": 0.6388289928436279, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 205200, "num_agent_steps_sampled": 205173, "num_steps_trained": 205200, "num_agent_steps_trained": 205173}, "done": false, "episodes_total": 4023, "training_iteration": 38, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-46-06", "timestamp": 1626860766, "time_this_iter_s": 7.1961729526519775, "time_total_s": 270.47627997398376, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 270.47627997398376, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 20.630000000000003, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.46, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 6.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 15.0, 355.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 6.0, -4.0, 6.0, -6.0, 0.0, 12.0, 9.0, 10.0, 11.0, 1.0, 6.0, -16.0, 8.0, 11.0, 12.0, -6.0, 4.0, 12.0, 5.0, 9.0, -4.0, 6.0, 4.0, 9.0, 9.0, 10.0, -13.0, -8.0, 0.0, 11.0, 12.0, 9.0, 5.0, 3.0, -2.0, -4.0, 7.0, 12.0, 0.0, -18.0, 12.0, 11.0, 10.0, 5.0, -4.0, 7.0, 7.0, -4.0, 4.0, 8.0, 7.0, 9.0, -5.0, 0.0, 11.0, -5.0, 6.0, 9.0, 5.0, 5.0, 9.0, 13.0, -12.0, 6.0, -8.0, 10.0, 7.0, -2.0, 13.0, 5.0, -1.0, -17.0, 14.0, 13.0, 5.0, 9.0, 8.0, 11.0, -13.0, 14.0, -4.0, 12.0, -7.0, 12.0, 9.0, 5.0, -11.0, -7.0, 10.0, 7.0, 5.0, 9.0, -6.0, 8.0, 4.0, 12.0, 6.0, -7.0, 4.0, -4.0, -3.0, 12.0, 10.0, 8.0, -1.0, 5.0, 3.0, 13.0, -11.0, 11.0, 2.0, 13.0, -12.0, 12.0, 2.0, 9.0, -6.0, 6.0, 6.0, -14.0, 12.0, 13.0, 4.0, 6.0, -10.0, 12.0, 7.0, 10.0, -3.0, 6.0, 2.0, 12.0, 7.0, -10.0, 6.0, -18.0, 9.0, 12.0, 12.0, 9.0, -2.0, 1.0, 7.0, 11.0, -9.0, 10.0, 3.0, 4.0, -1.0, 9.0, 3.0, -1.0, 5.0, 9.0, 3.0, 9.0, 10.0, 3.0, -7.0, 2.0, -4.0, 9.0, 8.0, 14.0, -5.0, 0.0, 6.0, 11.0, 3.0, 11.0, -10.0, -14.0, 7.0, 12.0, 10.0, 9.0, -4.0, 11.0, -1.0, 8.0, -2.0, 13.0, -4.0, 7.0, -9.0, 8.0, 9.0, 13.0, -13.0, 4.0, 11.0, -7.0, 6.0, 13.0, 3.0, -11.0, 4.0, 12.0, 10.0, 9.0, -9.0, 6.0, 9.0, -7.0, 3.0, 12.0, 7.0, -12.0, 6.0, 12.0, 9.0, 14.0, -5.0, -3.0, 9.0, -5.0, 5.0, 7.0, 8.0, 7.0, 0.0, 11.0, -3.0, 3.0, -2.0, 5.0, 9.0, 12.0, -10.0, 11.0, 2.0, -13.0, 10.0, 11.0, 7.0, -5.0, 6.0, 4.0, 10.0, -11.0, 8.0, 11.0, 7.0, -15.0, 8.0, 12.0, 10.0, 8.0, 5.0, 9.0, 6.0, 12.0, 7.0, 9.0, -13.0, 319.0, 12.0, 12.0, 12.0, -10.0, 11.0, 9.0, 5.0, 9.0, -1.0, 12.0, -5.0, -12.0, 12.0, 10.0, 5.0, 4.0, -3.0, 7.0, 8.0, 9.0, 9.0, -8.0, 5.0, -15.0, 6.0, 12.0, 12.0, 13.0, -12.0, 7.0, 7.0, 10.0, 12.0, 7.0, -14.0, 317.0, 14.0, 11.0, 12.0, 8.0, -3.0, 7.0, 3.0, 10.0, -17.0, 13.0, 9.0, 318.0, 12.0, 12.0, 12.0, -6.0, 12.0, 8.0, 1.0, -3.0, 12.0, -3.0, 9.0, -19.0, 10.0, 11.0, 13.0, 6.0, -6.0, 9.0, 6.0, 13.0, 14.0, 4.0, -16.0, 9.0, -3.0, 6.0, 3.0, -8.0, 2.0, 13.0, 8.0, 7.0, -4.0, 3.0, 9.0, 14.0, 5.0, 10.0, -14.0, -2.0, 11.0, -3.0, 9.0, 14.0, -2.0, 10.0, -7.0, 5.0, 12.0, 8.0, -10.0, 11.0, 12.0, -20.0, 12.0, 11.0, -13.0, 10.0, 7.0, -3.0, -7.0, 13.0, 12.0, 6.0, 12.0, 2.0, -5.0, 11.0, 13.0, -8.0, -1.0, -10.0, 14.0, 6.0, 5.0, 0.0, 3.0, 0.0, 12.0, 4.0, -1.0, 1.0, 11.0, 12.0, 7.0, -13.0, 9.0, 10.0, 3.0, -10.0, 12.0, 12.0, -12.0, 9.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22040173163496543, "mean_inference_ms": 1.181848714361751, "mean_action_processing_ms": 0.07238163251967347, "mean_env_wait_ms": 0.17959669883973908, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 210600, "agent_timesteps_total": 210519, "timers": {"sample_time_ms": 353.994, "sample_throughput": 15254.496, "learn_time_ms": 6677.767, "learn_throughput": 808.654, "update_time_ms": 11.048}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 669.7250366210938, "policy_loss": -0.029655147343873978, "vf_loss": 669.7522583007812, "vf_explained_var": 0.0771583542227745, "kl": 0.007987410761415958, "entropy": 0.693282425403595, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 210600, "num_agent_steps_sampled": 210519, "num_steps_trained": 210600, "num_agent_steps_trained": 210519}, "done": false, "episodes_total": 4104, "training_iteration": 39, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-46-13", "timestamp": 1626860773, "time_this_iter_s": 7.1492908000946045, "time_total_s": 277.62557077407837, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 277.62557077407837, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 22.27, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.555555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 6.888888888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -18.0, 12.0, 12.0, 12.0, -5.0, 1.0, 7.0, 11.0, -6.0, 2.0, 8.0, 11.0, -9.0, 12.0, 1.0, 12.0, 318.0, 12.0, 13.0, 13.0, 10.0, 1.0, -9.0, 9.0, -4.0, 0.0, 10.0, 7.0, -9.0, 13.0, 4.0, 8.0, -14.0, 10.0, 11.0, 11.0, 8.0, -12.0, 8.0, 13.0, 7.0, -9.0, 4.0, 12.0, -6.0, 11.0, -2.0, 1.0, -2.0, 5.0, 11.0, 12.0, 12.0, -11.0, 2.0, 5.0, 8.0, -5.0, 7.0, 13.0, -11.0, 10.0, 3.0, 13.0, -17.0, 11.0, 8.0, 13.0, 11.0, 4.0, -13.0, 13.0, -1.0, 8.0, -5.0, 12.0, -8.0, 12.0, -1.0, 14.0, -9.0, -2.0, 12.0, 12.0, -3.0, 6.0, 0.0, 11.0, -8.0, 11.0, 1.0, 3.0, -9.0, 13.0, 8.0, 14.0, -5.0, -1.0, 7.0, 11.0, -3.0, 1.0, 6.0, -3.0, -1.0, 6.0, 13.0, 8.0, -6.0, 11.0, 2.0, 8.0, -13.0, 8.0, 12.0, 12.0, 9.0, 2.0, -8.0, -1.0, 12.0, 1.0, 3.0, 10.0, -14.0, 11.0, 8.0, 10.0, -3.0, -5.0, 13.0, 12.0, -5.0, 2.0, 6.0, 12.0, 1.0, -2.0, 4.0, 6.0, 3.0, 12.0, -6.0, 4.0, 8.0, -3.0, 6.0, 12.0, -2.0, 3.0, 2.0, 13.0, -15.0, 7.0, 10.0, 11.0, 317.0, 13.0, 13.0, 12.0, -6.0, -2.0, 11.0, 11.0, -7.0, 7.0, 4.0, -4.0, 9.0, 5.0, 5.0, 7.0, -17.0, 12.0, 13.0, 9.0, 13.0, -10.0, 3.0, 11.0, 8.0, -6.0, 2.0, 11.0, -3.0, 5.0, 2.0, 0.0, -4.0, 6.0, 13.0, 7.0, -13.0, 12.0, 9.0, 13.0, 9.0, -12.0, 5.0, 13.0, 1.0, -7.0, 8.0, 7.0, -9.0, 13.0, 4.0, 7.0, 4.0, 10.0, -6.0, 9.0, -3.0, 7.0, 2.0, 13.0, 13.0, -9.0, -2.0, 3.0, -13.0, 12.0, 13.0, 12.0, 317.0, 12.0, 13.0, -4.0, 9.0, 7.0, 3.0, 11.0, -9.0, 5.0, 8.0, 7.0, -4.0, 13.0, -1.0, 8.0, -10.0, 5.0, 12.0, 13.0, 9.0, 3.0, -10.0, 12.0, -2.0, 7.0, -2.0, 3.0, -7.0, 11.0, 8.0, 14.0, 315.0, 12.0, 12.0, 6.0, 12.0, -9.0, 6.0, 10.0, 3.0, -5.0, 7.0, 10.0, -8.0, 9.0, 4.0, 9.0, -3.0, -4.0, 13.0, 13.0, 11.0, -5.0, -4.0, -15.0, 12.0, 11.0, 7.0, -7.0, 6.0, 13.0, 3.0, 5.0, 3.0, -5.0, 12.0, 13.0, 10.0, -15.0, 7.0, 11.0, 7.0, -7.0, 4.0, 8.0, -13.0, 12.0, 8.0, 14.0, 1.0, 12.0, -12.0, 13.0, 10.0, -13.0, 5.0, 13.0, 11.0, -5.0, -4.0, 7.0, 10.0, 12.0, -14.0, 12.0, -1.0, -7.0, 11.0, 7.0, -3.0, 1.0, 10.0, 11.0, -2.0, 5.0, 1.0, 6.0, -8.0, 9.0, 8.0, 14.0, -8.0, -3.0, 12.0, 8.0, -5.0, 5.0, 7.0, 11.0, -11.0, 7.0, 8.0, -6.0, -5.0, 13.0, 13.0, 7.0, 0.0, -1.0, 9.0, 14.0, 11.0, -12.0, 2.0, 13.0, 6.0, -9.0, 5.0, 11.0, -14.0, 11.0, 7.0, 4.0, -10.0, 8.0, 13.0, 14.0, -3.0, 0.0, 4.0, -2.0, -2.0, 11.0, 8.0, 3.0, -14.0, 13.0, 13.0, 13.0, -2.0, -8.0, 12.0, 11.0, 10.0, -17.0, 11.0, 12.0, 11.0, -2.0, -6.0, 3.0, -3.0, 12.0, 3.0, 13.0, -17.0, 8.0, 11.0, 12.0, 11.0, -19.0, 11.0, -4.0, 9.0, 2.0, 8.0, 3.0, -9.0, 10.0, 11.0, 12.0, -14.0, 6.0, 11.0, 7.0, -3.0, 6.0, 5.0, 10.0, 6.0, -3.0, 2.0, 10.0, -9.0, 7.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22071473123148444, "mean_inference_ms": 1.1825574149213656, "mean_action_processing_ms": 0.07234389729848506, "mean_env_wait_ms": 0.17962118826701945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 216000, "agent_timesteps_total": 215919, "timers": {"sample_time_ms": 354.21, "sample_throughput": 15245.205, "learn_time_ms": 6649.84, "learn_throughput": 812.05, "update_time_ms": 11.282}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 291.7254943847656, "policy_loss": -0.029099658131599426, "vf_loss": 291.75128173828125, "vf_explained_var": 0.1053425744175911, "kl": 0.011141168884932995, "entropy": 0.6051828861236572, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 216000, "num_agent_steps_sampled": 215919, "num_steps_trained": 216000, "num_agent_steps_trained": 215919}, "done": false, "episodes_total": 4212, "training_iteration": 40, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-46-20", "timestamp": 1626860780, "time_this_iter_s": 6.9445178508758545, "time_total_s": 284.5700886249542, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 284.5700886249542, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 21.93, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 2.0, -5.0, 12.0, 5.0, 13.0, -15.0, 12.0, 9.0, 13.0, 5.0, -12.0, 8.0, 2.0, 12.0, -7.0, 7.0, 1.0, -5.0, 12.0, 8.0, 6.0, 5.0, -4.0, 11.0, -2.0, 1.0, 5.0, 10.0, -13.0, 7.0, 11.0, 4.0, 2.0, -3.0, 12.0, 6.0, -8.0, 4.0, 13.0, 9.0, 12.0, 2.0, -8.0, 10.0, 13.0, 10.0, -18.0, 11.0, 2.0, -11.0, 13.0, 5.0, 4.0, -6.0, 12.0, 10.0, 11.0, 2.0, -8.0, 8.0, 6.0, 7.0, -6.0, 8.0, -13.0, 13.0, 7.0, 6.0, 7.0, -11.0, 13.0, 14.0, -1.0, 2.0, 0.0, -2.0, 12.0, 10.0, -5.0, 12.0, 1.0, -8.0, 10.0, 2.0, 8.0, 12.0, -7.0, -6.0, 13.0, 2.0, 6.0, -3.0, 12.0, 11.0, -5.0, 9.0, 2.0, -9.0, 13.0, 6.0, 12.0, -14.0, 11.0, 2.0, 14.0, 8.0, -9.0, 5.0, 4.0, 12.0, -6.0, 5.0, 4.0, -7.0, 13.0, -12.0, 8.0, 9.0, 10.0, 5.0, 14.0, 4.0, -8.0, 12.0, 5.0, 5.0, -7.0, 7.0, -7.0, 9.0, 6.0, -1.0, 8.0, 11.0, -3.0, 13.0, 10.0, 0.0, -8.0, 11.0, 12.0, -18.0, 10.0, 12.0, 2.0, -5.0, 6.0, -16.0, 13.0, 5.0, 13.0, 11.0, 11.0, 10.0, -17.0, 5.0, 13.0, 5.0, -8.0, 10.0, 8.0, 8.0, -11.0, 5.0, -8.0, 9.0, 9.0, 10.0, 12.0, 2.0, -9.0, 12.0, 12.0, -10.0, 1.0, 4.0, 8.0, -5.0, 8.0, -2.0, 12.0, 7.0, -2.0, 12.0, 12.0, 1.0, -10.0, 8.0, 13.0, -12.0, 6.0, 6.0, -11.0, 7.0, 13.0, 6.0, 4.0, 7.0, -2.0, 6.0, 11.0, 10.0, -12.0, 5.0, 9.0, -6.0, 7.0, 6.0, 4.0, -4.0, 9.0, 6.0, -12.0, 10.0, 11.0, 12.0, 12.0, 1.0, -10.0, 11.0, 10.0, -9.0, 3.0, 11.0, -12.0, 3.0, 13.0, 11.0, 6.0, -15.0, 13.0, 14.0, 11.0, -1.0, -9.0, 12.0, 9.0, -7.0, 1.0, 10.0, 2.0, -10.0, 13.0, 9.0, 5.0, -10.0, 11.0, 4.0, 12.0, 8.0, -9.0, 10.0, 3.0, -6.0, 8.0, 10.0, 7.0, -11.0, 9.0, -12.0, 9.0, 10.0, 8.0, 13.0, 12.0, 1.0, -11.0, 8.0, 4.0, -7.0, 10.0, 14.0, 2.0, -14.0, 13.0, -12.0, 12.0, 6.0, 9.0, 4.0, -3.0, 6.0, 8.0, -10.0, 7.0, 5.0, 13.0, 12.0, 5.0, -15.0, 13.0, -12.0, 6.0, 8.0, 13.0, 3.0, 12.0, 8.0, -8.0, 4.0, 13.0, 3.0, -5.0, 9.0, 8.0, 13.0, -15.0, 8.0, 11.0, -16.0, 12.0, 8.0, -4.0, 0.0, 11.0, 11.0, 0.0, -3.0, 7.0, 10.0, 1.0, -5.0, 9.0, 1.0, -2.0, 3.0, 13.0, 11.0, -5.0, 2.0, 7.0, 6.0, 9.0, -5.0, 5.0, 12.0, 4.0, -4.0, 3.0, -10.0, 6.0, 8.0, 11.0, 9.0, 10.0, 6.0, -10.0, 13.0, 12.0, -3.0, -7.0, 3.0, 8.0, 10.0, -6.0, 8.0, -11.0, 5.0, 13.0, 8.0, -2.0, 5.0, 4.0, 11.0, 8.0, 5.0, -9.0, 12.0, 8.0, 6.0, -11.0, 3.0, 8.0, 12.0, -8.0, 11.0, -3.0, 3.0, 4.0, 8.0, 12.0, -12.0, 7.0, 4.0, 8.0, -7.0, 10.0, -5.0, 3.0, 6.0, 11.0, 9.0, 11.0, 6.0, -11.0, 13.0, -2.0, 7.0, -3.0, 5.0, 3.0, -6.0, 13.0, 5.0, -11.0, 9.0, 12.0, 8.0, 9.0, 6.0, -8.0, 12.0, 12.0, -13.0, 4.0, 8.0, 4.0, -9.0, 12.0, -5.0, 14.0, -5.0, 11.0, 13.0, 12.0, -6.0, -4.0, 10.0, 13.0, -3.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22088156052382393, "mean_inference_ms": 1.1825822825901862, "mean_action_processing_ms": 0.07237139886796479, "mean_env_wait_ms": 0.17971371043317233, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 221400, "agent_timesteps_total": 221319, "timers": {"sample_time_ms": 354.07, "sample_throughput": 15251.234, "learn_time_ms": 6645.209, "learn_throughput": 812.616, "update_time_ms": 11.329}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 35.22547912597656, "policy_loss": -0.08811794221401215, "vf_loss": 35.308013916015625, "vf_explained_var": 0.15606807172298431, "kl": 0.018590595573186874, "entropy": 0.6520158648490906, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 221400, "num_agent_steps_sampled": 221319, "num_steps_trained": 221400, "num_agent_steps_trained": 221319}, "done": false, "episodes_total": 4320, "training_iteration": 41, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-46-27", "timestamp": 1626860787, "time_this_iter_s": 7.039965629577637, "time_total_s": 291.61005425453186, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 291.61005425453186, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 21.559999999999995, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 366.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.39814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 327.0}, "policy_reward_mean": {"learned": 5.349537037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 10.0, 10.0, -12.0, -16.0, 6.0, 12.0, 13.0, 11.0, 13.0, 6.0, -15.0, -7.0, 5.0, 6.0, 11.0, 10.0, 9.0, 7.0, -11.0, 7.0, 6.0, 9.0, -7.0, 7.0, -11.0, 8.0, 11.0, 5.0, 11.0, -12.0, 11.0, -14.0, 13.0, 12.0, 4.0, -4.0, 10.0, -4.0, 13.0, 13.0, -4.0, 4.0, 2.0, -1.0, 5.0, 0.0, 11.0, -4.0, -5.0, 11.0, 13.0, -5.0, 3.0, 7.0, 10.0, 11.0, 0.0, -2.0, 6.0, -2.0, 6.0, 0.0, 11.0, -19.0, 14.0, 10.0, 10.0, 8.0, -8.0, 2.0, 13.0, 11.0, 13.0, 11.0, -20.0, -11.0, 6.0, 10.0, 10.0, 8.0, -5.0, 10.0, 2.0, -4.0, 10.0, -4.0, 13.0, 11.0, 7.0, 5.0, -8.0, -4.0, -3.0, 11.0, 11.0, 327.0, 14.0, 13.0, 12.0, 12.0, 8.0, -4.0, -1.0, 7.0, 6.0, 6.0, -4.0, 7.0, -1.0, 4.0, 5.0, -8.0, 7.0, 11.0, 5.0, 12.0, 10.0, -6.0, -1.0, 10.0, 12.0, 7.0, -14.0, -6.0, 4.0, 5.0, 12.0, -1.0, 14.0, -2.0, 4.0, 11.0, 5.0, 2.0, -3.0, 11.0, 7.0, -4.0, 1.0, 9.0, -10.0, 6.0, 10.0, 316.0, 14.0, 12.0, 13.0, 7.0, 7.0, 2.0, -1.0, -4.0, 12.0, -4.0, 11.0, -6.0, -2.0, 11.0, 12.0, 7.0, -12.0, 11.0, 9.0, -6.0, 5.0, 3.0, 13.0, -6.0, 13.0, 12.0, -4.0, 13.0, -16.0, 11.0, 7.0, 5.0, 12.0, -13.0, 11.0, 11.0, 6.0, -1.0, -1.0, -8.0, 12.0, 12.0, -1.0, 8.0, -6.0, 7.0, 6.0, -8.0, 13.0, 11.0, -1.0, 13.0, -7.0, -1.0, 10.0, 5.0, 12.0, 6.0, -8.0, 6.0, -8.0, 12.0, 5.0, -23.0, 14.0, 11.0, 13.0, -6.0, 3.0, 9.0, 9.0, 9.0, -8.0, 4.0, 10.0, -5.0, 3.0, 6.0, 11.0, 14.0, -1.0, 12.0, -10.0, 12.0, -9.0, -1.0, 13.0, 1.0, -3.0, 4.0, 13.0, 6.0, -12.0, 10.0, 11.0, 5.0, -10.0, 12.0, 8.0, -6.0, 10.0, -2.0, 13.0, 10.0, -1.0, -7.0, 13.0, -2.0, -4.0, 10.0, 11.0, -6.0, 14.0, 10.0, -3.0, 9.0, -6.0, 7.0, 5.0, 0.0, -2.0, 8.0, 9.0, 12.0, 3.0, -5.0, 5.0, -15.0, 9.0, 13.0, 8.0, -10.0, 7.0, 6.0, 12.0, 14.0, -1.0, 5.0, -3.0, -8.0, 7.0, 5.0, 11.0, 10.0, -9.0, 9.0, 5.0, 11.0, -11.0, 4.0, 11.0, 2.0, 11.0, 4.0, -2.0, 13.0, -2.0, -7.0, 11.0, 1.0, 8.0, 10.0, -4.0, 11.0, -9.0, 2.0, 11.0, 11.0, 12.0, 9.0, -17.0, -7.0, 5.0, 10.0, 7.0, -2.0, 11.0, 10.0, -4.0, 5.0, -8.0, 6.0, 12.0, -9.0, 3.0, 9.0, 12.0, 6.0, 2.0, -2.0, 9.0, 3.0, 10.0, 12.0, -10.0, -2.0, 4.0, 3.0, 10.0, 11.0, -2.0, 4.0, 2.0, 7.0, -12.0, 10.0, 10.0, -17.0, 13.0, 12.0, 7.0, 10.0, -5.0, -3.0, 13.0, 12.0, -6.0, 10.0, -1.0, 0.0, 12.0, -8.0, 11.0, -4.0, -2.0, 11.0, 10.0, 12.0, -9.0, 1.0, 11.0, -1.0, 12.0, -4.0, 8.0, 6.0, 13.0, 10.0, -14.0, -6.0, 13.0, 13.0, -5.0, 4.0, 9.0, 4.0, -2.0, 1.0, 6.0, 12.0, -4.0, 8.0, -10.0, 7.0, 10.0, -17.0, 10.0, 11.0, 11.0, 12.0, -9.0, 7.0, 5.0, 10.0, 12.0, -1.0, -6.0, 13.0, 3.0, -13.0, 12.0, 7.0, 9.0, 12.0, -13.0, 8.0, -11.0, 8.0, 10.0, 6.0, 10.0, 2.0, -3.0, -7.0, 7.0, 4.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22081882455935936, "mean_inference_ms": 1.181648894743401, "mean_action_processing_ms": 0.07230964309021089, "mean_env_wait_ms": 0.17963054478900323, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 226800, "agent_timesteps_total": 226719, "timers": {"sample_time_ms": 351.79, "sample_throughput": 15350.07, "learn_time_ms": 6645.421, "learn_throughput": 812.59, "update_time_ms": 11.287}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 141.1956024169922, "policy_loss": -0.032554734498262405, "vf_loss": 141.2251434326172, "vf_explained_var": 0.13001547753810883, "kl": 0.010041463188827038, "entropy": 0.5916958451271057, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 226800, "num_agent_steps_sampled": 226719, "num_steps_trained": 226800, "num_agent_steps_trained": 226719}, "done": false, "episodes_total": 4428, "training_iteration": 42, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-46-34", "timestamp": 1626860794, "time_this_iter_s": 7.1656553745269775, "time_total_s": 298.77570962905884, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702060d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 298.77570962905884, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 22.01, "ram_util_percent": 14.120000000000001}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 33.861111111111114, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 8.465277777777779}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 13.0, 13.0, -8.0, -9.0, 9.0, 4.0, 11.0, 14.0, -14.0, 9.0, 6.0, 1.0, 3.0, 12.0, -1.0, 1.0, 12.0, 13.0, -11.0, 8.0, 3.0, 7.0, -3.0, 3.0, 11.0, -11.0, 12.0, 2.0, 4.0, 10.0, -1.0, -9.0, 9.0, 10.0, 5.0, -3.0, 11.0, -2.0, 9.0, 14.0, -17.0, 13.0, 5.0, -10.0, 3.0, 9.0, 13.0, 2.0, 6.0, -2.0, 9.0, -11.0, 5.0, 9.0, 12.0, 10.0, 13.0, -20.0, 12.0, -6.0, 7.0, 1.0, 13.0, -11.0, 13.0, 10.0, 3.0, -9.0, 10.0, 2.0, 12.0, -3.0, 12.0, -7.0, 13.0, 2.0, 3.0, 11.0, -1.0, -13.0, 12.0, 7.0, 9.0, 4.0, 5.0, 8.0, -2.0, 4.0, 3.0, -2.0, 10.0, -2.0, 6.0, 13.0, -2.0, -4.0, 1.0, 10.0, 8.0, -9.0, 9.0, 7.0, 8.0, 8.0, -14.0, 9.0, 12.0, -4.0, 12.0, 9.0, -2.0, -16.0, 11.0, 7.0, 13.0, -3.0, 9.0, -2.0, 11.0, 7.0, -11.0, 11.0, 8.0, 6.0, 7.0, 8.0, -6.0, -17.0, 10.0, 10.0, 12.0, -6.0, 4.0, 5.0, 12.0, 4.0, 4.0, -5.0, 12.0, -14.0, 10.0, 6.0, 13.0, -2.0, 11.0, -3.0, 9.0, -2.0, 12.0, 7.0, -2.0, 14.0, 1.0, -10.0, 10.0, -22.0, 11.0, 13.0, 13.0, -7.0, 13.0, -4.0, 13.0, -8.0, 9.0, 4.0, 10.0, 0.0, 7.0, -3.0, 11.0, -21.0, 11.0, 12.0, 13.0, 0.0, 8.0, 13.0, -6.0, 12.0, 11.0, 8.0, -16.0, 6.0, 5.0, 10.0, -6.0, 5.0, 6.0, 5.0, -1.0, 319.0, 12.0, 11.0, 13.0, -11.0, 10.0, 5.0, 11.0, 0.0, -5.0, 7.0, 13.0, -3.0, 8.0, 11.0, -1.0, 7.0, 7.0, 8.0, -7.0, 7.0, 7.0, 2.0, -1.0, 9.0, -16.0, 12.0, 10.0, -1.0, 9.0, 9.0, -2.0, 318.0, 13.0, 12.0, 11.0, -5.0, 7.0, 5.0, 8.0, 4.0, 7.0, 5.0, -1.0, 1.0, 6.0, 12.0, -4.0, -20.0, 13.0, 9.0, 13.0, -3.0, 9.0, 4.0, 5.0, -5.0, 3.0, 5.0, 12.0, -7.0, 3.0, 7.0, 12.0, 7.0, 5.0, -2.0, 5.0, -3.0, 11.0, -4.0, 11.0, -3.0, 13.0, -7.0, 12.0, 316.0, 12.0, 13.0, 13.0, -1.0, 8.0, -2.0, 10.0, -10.0, 2.0, 10.0, 13.0, 11.0, 5.0, -6.0, 5.0, -13.0, 6.0, 9.0, 13.0, 0.0, 13.0, -11.0, 13.0, -6.0, -2.0, 10.0, 13.0, 8.0, -1.0, -3.0, 11.0, -9.0, 2.0, 9.0, 13.0, -13.0, 9.0, 12.0, 7.0, 11.0, 12.0, 12.0, 321.0, 14.0, -19.0, 9.0, 11.0, -16.0, 7.0, 11.0, 13.0, -9.0, 12.0, -1.0, 13.0, 12.0, 12.0, 0.0, -9.0, 4.0, -13.0, 12.0, 12.0, -12.0, 6.0, 12.0, 9.0, -2.0, 12.0, 13.0, -8.0, -8.0, 7.0, 3.0, 13.0, 6.0, -3.0, 4.0, 8.0, -16.0, 11.0, 8.0, 12.0, 320.0, 11.0, 12.0, 13.0, 4.0, 5.0, 7.0, -1.0, 13.0, -2.0, -7.0, 11.0, -4.0, 7.0, 7.0, 5.0, -6.0, 13.0, -5.0, 13.0, 7.0, 11.0, 4.0, -7.0, 10.0, -1.0, 12.0, -6.0, -3.0, 9.0, 11.0, -2.0, -11.0, 9.0, 9.0, 8.0, -8.0, 4.0, 6.0, 13.0, 6.0, 8.0, -7.0, 8.0, 1.0, 4.0, 11.0, -1.0, -10.0, 12.0, 3.0, 10.0, 12.0, 10.0, 5.0, -12.0, 14.0, 314.0, 13.0, 11.0, -14.0, 8.0, 8.0, 13.0, -3.0, 13.0, -2.0, 7.0, -7.0, 2.0, 8.0, 12.0, 11.0, -6.0, 12.0, -2.0, -8.0, 11.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22074670371967717, "mean_inference_ms": 1.180981949290078, "mean_action_processing_ms": 0.07226587077461055, "mean_env_wait_ms": 0.17955847353668045, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 232200, "agent_timesteps_total": 232119, "timers": {"sample_time_ms": 350.572, "sample_throughput": 15403.378, "learn_time_ms": 6673.848, "learn_throughput": 809.128, "update_time_ms": 11.308}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 888.1784057617188, "policy_loss": -0.02809985913336277, "vf_loss": 888.2039184570312, "vf_explained_var": 0.029869550839066505, "kl": 0.008656470105051994, "entropy": 0.6469503045082092, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 232200, "num_agent_steps_sampled": 232119, "num_steps_trained": 232200, "num_agent_steps_trained": 232119}, "done": false, "episodes_total": 4536, "training_iteration": 43, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-46-42", "timestamp": 1626860802, "time_this_iter_s": 7.372197151184082, "time_total_s": 306.1479067802429, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae678c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 306.1479067802429, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 20.854545454545455, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.574074074074073, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 6.893518518518518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 8.0, 7.0, 3.0, 317.0, 13.0, 12.0, 12.0, 12.0, 11.0, -18.0, 10.0, -9.0, 8.0, 3.0, 13.0, -3.0, 8.0, 5.0, 5.0, -10.0, 8.0, 10.0, 7.0, 9.0, 5.0, -2.0, 3.0, -3.0, 12.0, 13.0, -7.0, 11.0, -5.0, 7.0, 2.0, -9.0, 10.0, 2.0, 12.0, 8.0, 6.0, -10.0, 11.0, -12.0, 9.0, 7.0, 11.0, 12.0, 9.0, 7.0, -13.0, -5.0, 10.0, 3.0, 7.0, 13.0, 11.0, 319.0, 13.0, 12.0, 12.0, 13.0, 317.0, 5.0, 10.0, 2.0, -2.0, -15.0, 12.0, 12.0, 6.0, 9.0, 7.0, -11.0, 10.0, -6.0, 11.0, 2.0, 8.0, -10.0, 8.0, 11.0, 6.0, 5.0, 11.0, -10.0, 9.0, 13.0, -3.0, -7.0, 12.0, -9.0, 9.0, 4.0, 11.0, -10.0, 6.0, 12.0, 7.0, 8.0, 10.0, 4.0, -7.0, 2.0, 9.0, 7.0, -3.0, -3.0, 13.0, 13.0, -8.0, -7.0, 5.0, 12.0, 5.0, 12.0, 11.0, -11.0, 3.0, -12.0, 7.0, 7.0, 13.0, 7.0, 9.0, -11.0, 10.0, -11.0, 10.0, 3.0, 13.0, -1.0, 7.0, 3.0, 6.0, 10.0, 12.0, 8.0, -15.0, -10.0, 8.0, 11.0, 6.0, 7.0, -4.0, 6.0, 6.0, -20.0, 13.0, 10.0, 12.0, 12.0, 10.0, -18.0, 11.0, -9.0, 11.0, 4.0, 9.0, -2.0, 4.0, 6.0, 7.0, -1.0, 12.0, 12.0, -8.0, 4.0, 13.0, -7.0, 5.0, -18.0, 14.0, 6.0, 13.0, 9.0, 2.0, -3.0, 7.0, 13.0, 9.0, -15.0, 8.0, -12.0, 10.0, 7.0, 10.0, 12.0, 13.0, 11.0, -21.0, -2.0, 2.0, 5.0, 10.0, 0.0, 11.0, -3.0, 7.0, 12.0, 11.0, -13.0, 5.0, 10.0, 14.0, -16.0, 7.0, -4.0, 12.0, 6.0, 1.0, -7.0, 12.0, 6.0, 4.0, 12.0, 10.0, -19.0, 12.0, -10.0, 12.0, 4.0, 9.0, 11.0, -6.0, 4.0, 6.0, 7.0, -1.0, 1.0, 8.0, 11.0, 10.0, -18.0, 12.0, 1.0, 14.0, 2.0, -2.0, -2.0, 5.0, 12.0, 0.0, 12.0, 3.0, -8.0, 8.0, -12.0, 10.0, 12.0, 5.0, 11.0, 13.0, 11.0, -20.0, -5.0, 4.0, 12.0, 4.0, 0.0, 11.0, -3.0, 7.0, 6.0, 7.0, -11.0, 13.0, -12.0, 13.0, 11.0, 3.0, -5.0, 9.0, 3.0, 8.0, -6.0, 5.0, 3.0, 13.0, 6.0, -5.0, 1.0, 13.0, 10.0, 12.0, -14.0, 7.0, 7.0, -9.0, 11.0, 6.0, -8.0, 12.0, 10.0, 1.0, 7.0, 12.0, -14.0, 10.0, -9.0, 9.0, 2.0, 13.0, 11.0, 13.0, -16.0, 7.0, -4.0, 13.0, 1.0, 5.0, 5.0, 13.0, -14.0, 11.0, 8.0, 13.0, 9.0, -15.0, 7.0, -11.0, 13.0, 6.0, -4.0, 12.0, 5.0, 2.0, 11.0, 3.0, -12.0, 13.0, -9.0, 6.0, 10.0, 8.0, -3.0, 5.0, 8.0, 5.0, -5.0, 10.0, 2.0, 8.0, 9.0, 12.0, -11.0, 5.0, 10.0, 12.0, 13.0, 319.0, -2.0, 1.0, 11.0, 5.0, -9.0, 11.0, 4.0, 9.0, -2.0, 12.0, -7.0, 12.0, -2.0, 12.0, 10.0, -5.0, -3.0, 5.0, 12.0, 1.0, 3.0, -4.0, 3.0, 13.0, 2.0, 10.0, -8.0, 11.0, -3.0, 13.0, 13.0, -8.0, 11.0, -8.0, 7.0, 5.0, -7.0, 4.0, 6.0, 12.0, -7.0, 8.0, 7.0, 7.0, -2.0, 12.0, 13.0, -8.0, 10.0, -11.0, 12.0, 4.0, -8.0, 12.0, 7.0, 4.0, 9.0, 11.0, -17.0, 12.0, 10.0, 13.0, -18.0, 10.0, -3.0, 3.0, 10.0, 5.0, -1.0, 7.0, 7.0, 2.0, 9.0, 11.0, -14.0, 9.0, 11.0, 14.0, -20.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22077774937011688, "mean_inference_ms": 1.1805891115255163, "mean_action_processing_ms": 0.0722442628670828, "mean_env_wait_ms": 0.17951252573585266, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 237600, "agent_timesteps_total": 237519, "timers": {"sample_time_ms": 350.502, "sample_throughput": 15406.487, "learn_time_ms": 6709.906, "learn_throughput": 804.78, "update_time_ms": 11.37}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 846.568603515625, "policy_loss": -0.03132781758904457, "vf_loss": 846.5970458984375, "vf_explained_var": 0.019499141722917557, "kl": 0.009658296592533588, "entropy": 0.6014286279678345, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 237600, "num_agent_steps_sampled": 237519, "num_steps_trained": 237600, "num_agent_steps_trained": 237519}, "done": false, "episodes_total": 4644, "training_iteration": 44, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-46-49", "timestamp": 1626860809, "time_this_iter_s": 7.406214714050293, "time_total_s": 313.5541214942932, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 313.5541214942932, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 21.39090909090909, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 4.530092592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-8.0, 3.0, 11.0, 9.0, -13.0, 12.0, 5.0, 11.0, -4.0, 7.0, 9.0, 3.0, 14.0, 8.0, 4.0, -11.0, 1.0, 3.0, 13.0, -2.0, 0.0, 11.0, 1.0, 3.0, 1.0, 14.0, 9.0, -9.0, 12.0, -4.0, 3.0, 4.0, -13.0, 4.0, 11.0, 13.0, 10.0, 12.0, -1.0, -6.0, -10.0, 9.0, 8.0, 8.0, 11.0, 9.0, -1.0, -4.0, -5.0, 5.0, 4.0, 11.0, 9.0, 11.0, -4.0, -1.0, -5.0, 9.0, 5.0, 6.0, 14.0, 13.0, -2.0, -10.0, 314.0, 12.0, 13.0, 13.0, 11.0, 11.0, -5.0, -2.0, 6.0, -5.0, 8.0, 6.0, 13.0, 12.0, -10.0, 0.0, -9.0, 0.0, 12.0, 12.0, 13.0, 9.0, -4.0, -3.0, -6.0, 9.0, 6.0, 6.0, 12.0, 12.0, 8.0, -17.0, 8.0, -1.0, -3.0, 11.0, -1.0, 12.0, -6.0, 10.0, 12.0, 7.0, 9.0, -13.0, 13.0, 13.0, 0.0, -11.0, -5.0, 7.0, 9.0, 4.0, 12.0, 11.0, -2.0, -6.0, 6.0, 11.0, 7.0, -9.0, 9.0, 12.0, 6.0, -12.0, 6.0, -1.0, -2.0, 12.0, 9.0, 13.0, -16.0, 9.0, 9.0, 7.0, -11.0, 10.0, 14.0, -8.0, 5.0, 4.0, -8.0, 2.0, 9.0, 12.0, 9.0, 11.0, -7.0, 2.0, -12.0, 9.0, 8.0, 10.0, 14.0, 12.0, -16.0, 5.0, 11.0, -14.0, 12.0, 6.0, 9.0, 12.0, -1.0, -5.0, -12.0, 13.0, 7.0, 7.0, 12.0, 9.0, 5.0, -11.0, 5.0, 3.0, 13.0, -6.0, 9.0, 12.0, -3.0, -3.0, -5.0, 2.0, 7.0, 11.0, 9.0, 7.0, -9.0, 8.0, 6.0, 6.0, -8.0, 11.0, -6.0, 8.0, 10.0, 3.0, -6.0, 6.0, 12.0, 3.0, 12.0, 8.0, -10.0, 5.0, -14.0, 7.0, 10.0, 12.0, 14.0, 6.0, -3.0, -2.0, 9.0, -1.0, -5.0, 12.0, 10.0, 8.0, -7.0, 4.0, -2.0, -4.0, 8.0, 13.0, 7.0, 12.0, -2.0, -2.0, -9.0, 8.0, 7.0, 9.0, 11.0, 12.0, -15.0, 7.0, -2.0, -2.0, 8.0, 11.0, 6.0, 13.0, -4.0, 0.0, -5.0, 6.0, 12.0, 2.0, 13.0, 13.0, -7.0, -4.0, -7.0, -1.0, 12.0, 11.0, 9.0, 9.0, -4.0, 1.0, -6.0, -1.0, 9.0, 13.0, 13.0, 10.0, 0.0, -8.0, 10.0, 9.0, -9.0, 5.0, -8.0, 7.0, 6.0, 10.0, 5.0, 9.0, 12.0, -11.0, -6.0, 13.0, -2.0, 10.0, 11.0, 0.0, 11.0, -7.0, 14.0, 7.0, -2.0, -4.0, -4.0, 8.0, 12.0, -1.0, 10.0, 12.0, 2.0, -9.0, 9.0, 0.0, -7.0, 13.0, -2.0, 12.0, -6.0, 11.0, -5.0, 9.0, 7.0, 4.0, 12.0, 10.0, -14.0, 7.0, -10.0, 1.0, 12.0, 12.0, 14.0, 11.0, -3.0, -7.0, -8.0, 0.0, 11.0, 12.0, 12.0, 9.0, 5.0, -11.0, 5.0, 1.0, -2.0, 11.0, 11.0, 6.0, -7.0, 5.0, 8.0, -11.0, 12.0, 6.0, 8.0, 14.0, -6.0, -1.0, 7.0, -1.0, 12.0, -3.0, 13.0, 11.0, -5.0, -4.0, -3.0, 6.0, 9.0, 3.0, 9.0, 11.0, 6.0, -11.0, -1.0, 5.0, 9.0, 2.0, 11.0, 11.0, -2.0, -5.0, -11.0, 5.0, 9.0, 12.0, 10.0, 11.0, 6.0, -12.0, -4.0, 10.0, -2.0, 11.0, 9.0, 12.0, 0.0, -6.0, -7.0, 14.0, 1.0, 7.0, 13.0, 12.0, -10.0, 0.0, 9.0, -5.0, -2.0, 13.0, 13.0, 13.0, -7.0, -4.0, -7.0, 3.0, 7.0, 12.0, 14.0, 12.0, -10.0, -1.0, 8.0, 0.0, 12.0, -5.0, 8.0, 14.0, 10.0, -17.0, -10.0, 9.0, 8.0, 8.0, 11.0, 12.0, -13.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2207775653418332, "mean_inference_ms": 1.1806456594860324, "mean_action_processing_ms": 0.07222683006390565, "mean_env_wait_ms": 0.17946773689895779, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 243000, "agent_timesteps_total": 242919, "timers": {"sample_time_ms": 350.434, "sample_throughput": 15409.478, "learn_time_ms": 6727.783, "learn_throughput": 802.642, "update_time_ms": 11.61}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 137.50021362304688, "policy_loss": -0.04715118184685707, "vf_loss": 137.54302978515625, "vf_explained_var": 0.14616599678993225, "kl": 0.014395132660865784, "entropy": 0.6216691732406616, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 243000, "num_agent_steps_sampled": 242919, "num_steps_trained": 243000, "num_agent_steps_trained": 242919}, "done": false, "episodes_total": 4752, "training_iteration": 45, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-46-57", "timestamp": 1626860817, "time_this_iter_s": 7.248157739639282, "time_total_s": 320.8022792339325, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae676a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 320.8022792339325, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 20.490000000000002, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 10.0, 8.0, -1.0, -2.0, 12.0, 6.0, -1.0, -13.0, 3.0, 12.0, 13.0, 7.0, -3.0, 1.0, 10.0, 4.0, 6.0, 8.0, -3.0, 10.0, 12.0, 7.0, -14.0, 0.0, 11.0, -6.0, 10.0, 8.0, -4.0, 1.0, 10.0, -16.0, 8.0, 12.0, 11.0, 11.0, 13.0, 1.0, -10.0, 2.0, 7.0, -7.0, 13.0, -5.0, 11.0, 12.0, -3.0, -15.0, 9.0, 12.0, 9.0, 7.0, -6.0, 4.0, 10.0, 2.0, 8.0, -4.0, 9.0, 8.0, 13.0, 1.0, -7.0, -15.0, 10.0, 11.0, 9.0, 7.0, 12.0, 5.0, -9.0, 1.0, 3.0, -2.0, 13.0, -7.0, 10.0, 2.0, 10.0, -13.0, 9.0, 11.0, 8.0, -2.0, 13.0, 6.0, -2.0, 6.0, 3.0, -7.0, 13.0, -11.0, 11.0, 12.0, 3.0, 3.0, 7.0, 8.0, -3.0, 10.0, 5.0, 9.0, -9.0, 7.0, 10.0, -7.0, 5.0, -2.0, 13.0, -6.0, 10.0, -1.0, 11.0, 8.0, -3.0, 12.0, 9.0, 3.0, -9.0, 13.0, -7.0, -4.0, 13.0, 8.0, 11.0, 2.0, -6.0, -14.0, 9.0, 9.0, 11.0, -2.0, 14.0, -3.0, 6.0, -3.0, 3.0, 2.0, 13.0, 3.0, -3.0, 12.0, 3.0, -1.0, 8.0, -3.0, 11.0, 14.0, 9.0, 2.0, -10.0, 3.0, 10.0, -6.0, 8.0, 9.0, 11.0, 2.0, -7.0, -1.0, 9.0, -4.0, 11.0, 9.0, -2.0, 4.0, 4.0, -3.0, 9.0, -4.0, 13.0, 8.0, -1.0, 4.0, 4.0, -16.0, 11.0, 10.0, 10.0, 10.0, 8.0, 8.0, -11.0, -12.0, 10.0, 5.0, 12.0, 2.0, -5.0, 11.0, 7.0, -4.0, 12.0, -2.0, 9.0, 7.0, -10.0, 12.0, 6.0, 6.0, 1.0, -5.0, 13.0, -5.0, 6.0, 6.0, 8.0, -14.0, 9.0, 9.0, 11.0, 12.0, -1.0, 2.0, 2.0, 9.0, 4.0, -10.0, 12.0, 9.0, 4.0, 6.0, -4.0, -15.0, 9.0, 9.0, 12.0, -4.0, 12.0, 3.0, 4.0, 0.0, 5.0, -3.0, 13.0, 7.0, 11.0, 6.0, -9.0, -16.0, 8.0, 10.0, 13.0, 10.0, 12.0, 5.0, -12.0, 6.0, 11.0, -10.0, 8.0, 6.0, -1.0, 0.0, 10.0, -15.0, 10.0, 7.0, 13.0, 12.0, 10.0, 1.0, -8.0, -1.0, 10.0, -7.0, 13.0, 3.0, -6.0, 6.0, 12.0, 3.0, 13.0, 9.0, -10.0, 10.0, 9.0, 4.0, -8.0, 3.0, 3.0, -4.0, 13.0, -8.0, 12.0, 0.0, 11.0, -9.0, 13.0, 7.0, 4.0, 11.0, 0.0, 10.0, -6.0, 0.0, 6.0, -4.0, 13.0, -7.0, 10.0, 2.0, 10.0, -12.0, 10.0, 8.0, 9.0, 13.0, 14.0, 5.0, -17.0, -8.0, 10.0, 8.0, 5.0, -11.0, 9.0, 5.0, 12.0, 5.0, 13.0, -10.0, 7.0, 13.0, 9.0, -1.0, -6.0, 4.0, 2.0, -4.0, 13.0, 5.0, -3.0, 9.0, 4.0, -12.0, 6.0, 8.0, 13.0, 12.0, 13.0, -17.0, 7.0, 11.0, 8.0, -12.0, 8.0, -1.0, -2.0, 9.0, 9.0, -8.0, 10.0, 2.0, 11.0, -1.0, 12.0, 5.0, -1.0, -12.0, 3.0, 12.0, 12.0, -6.0, 11.0, -1.0, 11.0, 318.0, 13.0, 11.0, 12.0, 11.0, 13.0, -10.0, 1.0, -4.0, 10.0, -4.0, 13.0, 8.0, -3.0, -1.0, 11.0, -12.0, 9.0, 8.0, 10.0, -1.0, 14.0, 2.0, 0.0, 2.0, 6.0, -5.0, 12.0, -7.0, 7.0, 4.0, 11.0, -16.0, 8.0, 10.0, 13.0, -4.0, 13.0, 4.0, 2.0, 4.0, 9.0, -7.0, 9.0, -2.0, 13.0, -5.0, 9.0, -7.0, 12.0, 3.0, 7.0, 3.0, 0.0, 9.0, 3.0, -17.0, 9.0, 11.0, 12.0, -2.0, 9.0, 10.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22076005785992128, "mean_inference_ms": 1.1800797343109652, "mean_action_processing_ms": 0.07219986604507062, "mean_env_wait_ms": 0.17945382189554793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 248400, "agent_timesteps_total": 248319, "timers": {"sample_time_ms": 350.238, "sample_throughput": 15418.107, "learn_time_ms": 6730.19, "learn_throughput": 802.355, "update_time_ms": 11.571}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 144.03150939941406, "policy_loss": -0.03920025750994682, "vf_loss": 144.06727600097656, "vf_explained_var": 0.13890522718429565, "kl": 0.01147865317761898, "entropy": 0.5807687640190125, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 248400, "num_agent_steps_sampled": 248319, "num_steps_trained": 248400, "num_agent_steps_trained": 248319}, "done": false, "episodes_total": 4860, "training_iteration": 46, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-47-04", "timestamp": 1626860824, "time_this_iter_s": 7.227556943893433, "time_total_s": 328.0298361778259, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70222c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 328.0298361778259, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 21.12, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.018518518518519, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7546296296296298}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, -13.0, 11.0, 13.0, -12.0, 9.0, 8.0, 10.0, -7.0, 14.0, 6.0, 2.0, 13.0, -18.0, 10.0, 10.0, 7.0, 2.0, 8.0, -2.0, 8.0, 13.0, -7.0, 1.0, 4.0, 14.0, -11.0, 8.0, 13.0, -14.0, 6.0, 10.0, 6.0, 0.0, 12.0, -3.0, -5.0, -1.0, 8.0, 13.0, 0.0, 12.0, 7.0, -4.0, 12.0, 3.0, -8.0, 8.0, 11.0, 10.0, -17.0, 11.0, -18.0, 14.0, 8.0, 11.0, -15.0, 13.0, 10.0, 7.0, 11.0, -16.0, 9.0, 11.0, 10.0, -11.0, 12.0, 4.0, 6.0, -4.0, 7.0, 6.0, 9.0, 10.0, -5.0, 1.0, 12.0, -16.0, 10.0, 9.0, 7.0, -16.0, 11.0, 13.0, -17.0, 14.0, 12.0, 6.0, -1.0, -1.0, 6.0, 11.0, 12.0, 1.0, -8.0, 10.0, -9.0, 12.0, 3.0, 9.0, 8.0, 14.0, 0.0, -7.0, 6.0, -4.0, 10.0, 3.0, -1.0, -4.0, 12.0, 8.0, 8.0, -13.0, 7.0, 13.0, -5.0, 4.0, 5.0, 11.0, -16.0, 14.0, 11.0, 6.0, -3.0, -3.0, 10.0, 11.0, -12.0, 7.0, 7.0, 13.0, -14.0, 14.0, 8.0, 7.0, 11.0, -3.0, 7.0, 0.0, -1.0, -1.0, 8.0, 9.0, -13.0, 10.0, 7.0, 11.0, -16.0, 14.0, 8.0, 9.0, 10.0, 14.0, -11.0, 2.0, 11.0, -4.0, -5.0, 13.0, 5.0, -10.0, 11.0, 9.0, -10.0, 14.0, 3.0, 8.0, -5.0, 11.0, 3.0, 6.0, 0.0, -2.0, 9.0, 8.0, 11.0, 6.0, -15.0, 13.0, -8.0, 14.0, 6.0, 3.0, 4.0, 11.0, -7.0, 7.0, 13.0, -4.0, -4.0, 10.0, 10.0, 5.0, -12.0, 12.0, 9.0, 6.0, -4.0, 4.0, 7.0, -3.0, 8.0, 3.0, 12.0, -5.0, -3.0, 11.0, 10.0, 4.0, 12.0, -11.0, -8.0, 9.0, 9.0, 5.0, -14.0, 14.0, 3.0, 12.0, 6.0, -1.0, -2.0, 12.0, 10.0, -6.0, -2.0, 13.0, -12.0, 8.0, 7.0, 12.0, -6.0, 11.0, 9.0, 1.0, 10.0, -1.0, 8.0, -2.0, 9.0, 1.0, 6.0, -1.0, -11.0, 13.0, 0.0, 13.0, -8.0, 14.0, 4.0, 5.0, -2.0, -5.0, 10.0, 12.0, -12.0, 3.0, 12.0, 12.0, -9.0, 9.0, 12.0, 3.0, 2.0, 14.0, -8.0, 7.0, 12.0, -6.0, -2.0, 11.0, 5.0, -13.0, 12.0, 11.0, 1.0, 8.0, -7.0, 13.0, -11.0, 14.0, 10.0, 2.0, -5.0, -1.0, 11.0, 10.0, 9.0, -16.0, 11.0, 11.0, -7.0, 10.0, 7.0, 5.0, -6.0, 13.0, 5.0, 3.0, 12.0, -2.0, 8.0, -3.0, -11.0, 11.0, 4.0, 11.0, 9.0, 14.0, 7.0, -15.0, 13.0, 12.0, 10.0, -20.0, 12.0, -17.0, 11.0, 9.0, -6.0, 1.0, 11.0, 9.0, -11.0, 12.0, 1.0, 13.0, 1.0, 0.0, 3.0, 12.0, 13.0, -18.0, 9.0, 11.0, 10.0, -16.0, 13.0, 8.0, -4.0, -2.0, 8.0, 13.0, 1.0, 0.0, 10.0, 4.0, 13.0, 2.0, 3.0, -3.0, 9.0, -13.0, 11.0, 8.0, -3.0, 14.0, -5.0, 9.0, 7.0, 13.0, -11.0, 6.0, 11.0, 2.0, -9.0, 11.0, 11.0, -9.0, 2.0, 11.0, -4.0, 14.0, 1.0, 4.0, -6.0, 13.0, 6.0, 3.0, 13.0, -6.0, -4.0, 12.0, 4.0, 5.0, -2.0, 8.0, -7.0, 7.0, 8.0, 7.0, 5.0, 10.0, -3.0, 3.0, 0.0, -8.0, 10.0, 13.0, -4.0, 6.0, 2.0, 11.0, 5.0, 1.0, 12.0, -3.0, -9.0, 10.0, 12.0, 2.0, 12.0, -7.0, -3.0, 13.0, -8.0, 4.0, 13.0, 6.0, 7.0, 9.0, -9.0, 8.0, 10.0, 7.0, -9.0, 7.0, 13.0, -1.0, -9.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22078788178056877, "mean_inference_ms": 1.180222390757338, "mean_action_processing_ms": 0.07219688922055635, "mean_env_wait_ms": 0.17947947314844448, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 253800, "agent_timesteps_total": 253719, "timers": {"sample_time_ms": 350.249, "sample_throughput": 15417.596, "learn_time_ms": 6738.188, "learn_throughput": 801.402, "update_time_ms": 11.759}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 32.07586669921875, "policy_loss": -0.09596161544322968, "vf_loss": 32.16545104980469, "vf_explained_var": 0.19991528987884521, "kl": 0.021240776404738426, "entropy": 0.6530706882476807, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 253800, "num_agent_steps_sampled": 253719, "num_steps_trained": 253800, "num_agent_steps_trained": 253719}, "done": false, "episodes_total": 4968, "training_iteration": 47, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-47-11", "timestamp": 1626860831, "time_this_iter_s": 7.17956018447876, "time_total_s": 335.2093963623047, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70222158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 335.2093963623047, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 21.545454545454543, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.48148148148148, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 6.12037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 14.0, -19.0, 7.0, 5.0, 9.0, 3.0, -2.0, 14.0, -19.0, 7.0, 13.0, 9.0, 13.0, 0.0, -7.0, 3.0, 11.0, 12.0, -11.0, -12.0, 11.0, 7.0, 9.0, -5.0, 12.0, 10.0, -2.0, -12.0, 8.0, 6.0, 13.0, 13.0, 8.0, -7.0, 1.0, -3.0, 13.0, -1.0, 6.0, 6.0, 8.0, 4.0, -3.0, -17.0, 8.0, 12.0, 12.0, 14.0, 12.0, 10.0, -21.0, -1.0, 13.0, 1.0, 2.0, 4.0, -1.0, 3.0, 9.0, 3.0, 12.0, 5.0, -5.0, 10.0, 14.0, -15.0, 6.0, 6.0, -4.0, 1.0, 12.0, 9.0, -13.0, 7.0, 12.0, 3.0, 13.0, -6.0, 5.0, 13.0, 14.0, 7.0, -19.0, -11.0, 13.0, 2.0, 11.0, 3.0, 12.0, 8.0, -8.0, 10.0, 7.0, 0.0, -2.0, 11.0, 14.0, -20.0, 10.0, -2.0, 7.0, 3.0, 7.0, -1.0, -1.0, 5.0, 12.0, -11.0, 11.0, 2.0, 13.0, 12.0, 14.0, 8.0, -19.0, 8.0, 11.0, -2.0, -2.0, -5.0, -1.0, 9.0, 12.0, 2.0, 12.0, 2.0, -1.0, 1.0, -1.0, 3.0, 12.0, 1.0, 13.0, -11.0, 12.0, -2.0, -2.0, 7.0, 12.0, 1.0, 6.0, 10.0, -2.0, 13.0, 0.0, -9.0, 11.0, 322.0, 13.0, 10.0, 11.0, 2.0, 8.0, 6.0, -1.0, 5.0, 6.0, 5.0, -1.0, 13.0, 14.0, -5.0, -7.0, -4.0, 9.0, -1.0, 11.0, 4.0, -9.0, 7.0, 13.0, -11.0, 13.0, 0.0, 13.0, 13.0, 0.0, 7.0, -5.0, -3.0, 11.0, 5.0, 2.0, -5.0, 11.0, 10.0, -1.0, 10.0, 7.0, 2.0, -4.0, 13.0, 0.0, -9.0, 11.0, -12.0, 13.0, 3.0, 11.0, 12.0, -14.0, 4.0, 13.0, 10.0, 4.0, -1.0, 2.0, 12.0, 14.0, -22.0, 11.0, 8.0, -4.0, 0.0, 11.0, 14.0, -9.0, 0.0, 10.0, 11.0, 3.0, 3.0, -2.0, 10.0, 14.0, -16.0, 7.0, 10.0, 7.0, -9.0, 7.0, 1.0, 14.0, 2.0, -2.0, -2.0, 12.0, 6.0, -1.0, 7.0, -4.0, 1.0, 11.0, -6.0, 9.0, 0.0, 12.0, 8.0, -10.0, 10.0, 7.0, 3.0, 6.0, 7.0, -1.0, 13.0, 14.0, 11.0, 319.0, 3.0, 13.0, 7.0, -8.0, 4.0, 7.0, 7.0, -3.0, 7.0, 4.0, -2.0, 6.0, 12.0, 14.0, -18.0, 7.0, -1.0, 11.0, 1.0, 4.0, 14.0, -15.0, 7.0, 9.0, 6.0, 4.0, -2.0, 7.0, 12.0, 14.0, -18.0, 7.0, 10.0, 13.0, -10.0, 2.0, 2.0, -9.0, 9.0, 13.0, 10.0, 7.0, -1.0, -1.0, 13.0, 14.0, 317.0, 12.0, -7.0, 5.0, 8.0, 9.0, 4.0, 8.0, 4.0, -1.0, 11.0, 5.0, -2.0, 1.0, 8.0, -4.0, 10.0, 1.0, 10.0, 13.0, 0.0, -8.0, -3.0, -3.0, 9.0, 12.0, 1.0, 9.0, 7.0, -2.0, 13.0, 14.0, -11.0, -1.0, 4.0, 12.0, -9.0, 8.0, -7.0, -1.0, 11.0, 12.0, 5.0, -8.0, 5.0, 13.0, 13.0, 14.0, -19.0, 7.0, 11.0, 8.0, 1.0, -5.0, 2.0, -8.0, 8.0, 13.0, 6.0, 13.0, -2.0, -2.0, 13.0, 14.0, -22.0, 10.0, -4.0, 4.0, 4.0, 11.0, -3.0, -2.0, 7.0, 13.0, 1.0, 10.0, 6.0, -2.0, 11.0, 14.0, -17.0, 7.0, 10.0, 8.0, 8.0, -11.0, 3.0, 6.0, 8.0, -2.0, 5.0, 3.0, 8.0, -1.0, 7.0, -8.0, 4.0, 12.0, -3.0, 4.0, 4.0, 10.0, -2.0, -2.0, 7.0, 12.0, -1.0, 12.0, 5.0, -1.0, 12.0, -5.0, -5.0, 13.0, -4.0, 4.0, 9.0, 6.0, 6.0, 5.0, 5.0, -1.0, -13.0, 6.0, 9.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22072806989620963, "mean_inference_ms": 1.1796313250373927, "mean_action_processing_ms": 0.07219068492514788, "mean_env_wait_ms": 0.17943824450472967, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 259200, "agent_timesteps_total": 259119, "timers": {"sample_time_ms": 349.408, "sample_throughput": 15454.704, "learn_time_ms": 6750.134, "learn_throughput": 799.984, "update_time_ms": 11.953}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 551.0810546875, "policy_loss": -0.02373473346233368, "vf_loss": 551.1019897460938, "vf_explained_var": 0.055335454642772675, "kl": 0.006256708409637213, "entropy": 0.5926615595817566, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 259200, "num_agent_steps_sampled": 259119, "num_steps_trained": 259200, "num_agent_steps_trained": 259119}, "done": false, "episodes_total": 5076, "training_iteration": 48, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-47-18", "timestamp": 1626860838, "time_this_iter_s": 7.31431770324707, "time_total_s": 342.52371406555176, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70222840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 342.52371406555176, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 20.360000000000003, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 5.314814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 11.0, 1.0, -9.0, -3.0, 13.0, 10.0, -5.0, -6.0, 4.0, 7.0, 10.0, 14.0, 7.0, -8.0, 2.0, 8.0, 11.0, -16.0, 12.0, 8.0, 12.0, -16.0, 11.0, 11.0, 5.0, -7.0, 6.0, 13.0, 9.0, 8.0, -15.0, 1.0, 12.0, 9.0, -7.0, 8.0, 12.0, -14.0, 9.0, 11.0, 10.0, 4.0, -10.0, 13.0, 14.0, -13.0, 1.0, 9.0, 4.0, -2.0, 4.0, 13.0, 13.0, 12.0, 315.0, -5.0, 12.0, -2.0, 10.0, -4.0, 14.0, 3.0, 2.0, 2.0, 13.0, -5.0, 5.0, 12.0, 11.0, -4.0, -4.0, 11.0, 10.0, 2.0, -8.0, 0.0, -1.0, 10.0, 6.0, 3.0, 13.0, -14.0, 13.0, 13.0, -1.0, -10.0, 13.0, -13.0, 11.0, 9.0, 8.0, 13.0, 9.0, 3.0, -10.0, 13.0, 12.0, -6.0, -4.0, 13.0, 11.0, 11.0, -20.0, 10.0, -5.0, 0.0, 10.0, -11.0, 12.0, 10.0, 4.0, 7.0, 12.0, 9.0, -13.0, 13.0, 14.0, -22.0, 10.0, 9.0, -5.0, 4.0, 7.0, -6.0, 11.0, 5.0, 5.0, 5.0, 12.0, -3.0, 1.0, 10.0, 14.0, -19.0, 10.0, 12.0, 9.0, 7.0, -13.0, 0.0, 6.0, 7.0, 2.0, 3.0, 10.0, -5.0, 7.0, 10.0, 13.0, -19.0, 11.0, 10.0, 9.0, 6.0, -10.0, 12.0, 9.0, -11.0, 5.0, -4.0, 12.0, 7.0, 0.0, 10.0, 14.0, -21.0, 12.0, -9.0, 11.0, 8.0, 5.0, 13.0, 10.0, 4.0, -12.0, 6.0, 0.0, -4.0, 13.0, -2.0, 12.0, -5.0, 10.0, 10.0, 11.0, -15.0, 9.0, 6.0, 12.0, -10.0, 7.0, -2.0, 14.0, -9.0, 12.0, 13.0, 13.0, 314.0, 13.0, 9.0, 10.0, -11.0, 7.0, 14.0, 6.0, -12.0, 7.0, 12.0, 0.0, -3.0, 6.0, 14.0, 10.0, -18.0, 9.0, 12.0, 4.0, -14.0, 13.0, 13.0, 14.0, -11.0, -1.0, 9.0, 6.0, 11.0, -11.0, 13.0, 12.0, -8.0, -2.0, 0.0, 11.0, -4.0, 8.0, 12.0, 14.0, -13.0, 2.0, 14.0, 6.0, -9.0, 4.0, -3.0, 14.0, -6.0, 10.0, 12.0, -12.0, 2.0, 13.0, 13.0, 8.0, -14.0, 8.0, 11.0, 2.0, 6.0, -4.0, 10.0, 13.0, -20.0, 12.0, 13.0, 10.0, -14.0, 6.0, 12.0, 9.0, 3.0, -9.0, 7.0, -4.0, 4.0, 8.0, 0.0, 13.0, -9.0, 11.0, 8.0, 10.0, -16.0, 13.0, 13.0, 14.0, 2.0, -14.0, 2.0, -2.0, 4.0, 11.0, -2.0, 14.0, -9.0, 12.0, 10.0, -13.0, 9.0, 9.0, 12.0, 10.0, 7.0, -14.0, 11.0, 0.0, 1.0, 3.0, -1.0, 13.0, 8.0, -5.0, 6.0, 13.0, -12.0, 8.0, -5.0, 0.0, 11.0, 9.0, 13.0, 13.0, -9.0, -2.0, -3.0, 14.0, -6.0, 10.0, 0.0, 8.0, 6.0, 1.0, 12.0, 4.0, -7.0, 6.0, 4.0, -1.0, 9.0, 3.0, 11.0, 12.0, -19.0, 11.0, -5.0, 12.0, 4.0, 4.0, 12.0, 14.0, -7.0, -4.0, 13.0, -11.0, 3.0, 10.0, -2.0, 13.0, 11.0, -7.0, 10.0, 11.0, -19.0, 13.0, 14.0, 10.0, -13.0, 4.0, 12.0, 3.0, 11.0, -11.0, 14.0, 13.0, -22.0, 10.0, 12.0, 11.0, -17.0, 9.0, 6.0, 9.0, 8.0, -8.0, 9.0, -9.0, 8.0, 7.0, -5.0, 14.0, -7.0, 13.0, 13.0, -10.0, 0.0, 12.0, 9.0, 14.0, -9.0, 1.0, 4.0, -2.0, 7.0, 6.0, 13.0, 12.0, -8.0, -2.0, 12.0, -9.0, 4.0, 8.0, 13.0, 8.0, 3.0, -9.0, 4.0, 12.0, 8.0, -9.0, -2.0, 12.0, -3.0, 8.0, 13.0, 10.0, -16.0, 8.0, 13.0, 12.0, -8.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22067791035517978, "mean_inference_ms": 1.179321789218328, "mean_action_processing_ms": 0.07216307293858036, "mean_env_wait_ms": 0.17939211967463736, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 264600, "agent_timesteps_total": 264519, "timers": {"sample_time_ms": 348.829, "sample_throughput": 15480.359, "learn_time_ms": 6768.559, "learn_throughput": 797.806, "update_time_ms": 11.96}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 451.1492004394531, "policy_loss": -0.035105783492326736, "vf_loss": 451.1805419921875, "vf_explained_var": 0.09720143675804138, "kl": 0.00819083396345377, "entropy": 0.5868954658508301, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 264600, "num_agent_steps_sampled": 264519, "num_steps_trained": 264600, "num_agent_steps_trained": 264519}, "done": false, "episodes_total": 5184, "training_iteration": 49, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-47-26", "timestamp": 1626860846, "time_this_iter_s": 7.328659296035767, "time_total_s": 349.8523733615875, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 349.8523733615875, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 21.389999999999997, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -16.0, 13.0, 9.0, 3.0, -3.0, 2.0, 13.0, 6.0, 9.0, -12.0, 12.0, -9.0, 9.0, 8.0, 7.0, 0.0, -9.0, 13.0, 11.0, -12.0, 8.0, 8.0, 11.0, 13.0, 10.0, -17.0, 9.0, -11.0, 9.0, 8.0, 9.0, 1.0, -8.0, 11.0, 11.0, 2.0, 12.0, 4.0, -3.0, 5.0, -2.0, 6.0, 6.0, -13.0, 10.0, 7.0, 11.0, 6.0, -13.0, 11.0, 11.0, 7.0, 12.0, -10.0, 6.0, 6.0, 12.0, 12.0, -15.0, -17.0, 10.0, 13.0, 9.0, 7.0, 3.0, 12.0, -7.0, 6.0, -6.0, 12.0, 3.0, -12.0, 13.0, 7.0, 7.0, -12.0, 3.0, 13.0, 11.0, 9.0, -8.0, 8.0, 6.0, -2.0, 5.0, 4.0, 8.0, 8.0, 10.0, -7.0, 4.0, -5.0, 10.0, 13.0, -3.0, 5.0, -8.0, 10.0, 8.0, 7.0, 13.0, 6.0, -11.0, -13.0, 14.0, 2.0, 12.0, 3.0, 1.0, -1.0, 12.0, 5.0, 10.0, 13.0, -13.0, -10.0, 8.0, 5.0, 12.0, -12.0, 9.0, 12.0, 6.0, -11.0, 2.0, 13.0, 11.0, 9.0, 5.0, -11.0, 12.0, -6.0, 10.0, 7.0, 4.0, 14.0, 12.0, 7.0, -18.0, -10.0, 3.0, 13.0, 9.0, 6.0, 4.0, 11.0, -6.0, 8.0, 9.0, -9.0, 7.0, -12.0, 12.0, 8.0, 7.0, -7.0, 8.0, 6.0, 8.0, 6.0, -15.0, 13.0, 11.0, -8.0, 6.0, 13.0, 4.0, 7.0, 13.0, -10.0, 5.0, -11.0, 2.0, 13.0, 11.0, 4.0, -12.0, 13.0, 10.0, 9.0, 9.0, 7.0, -10.0, -14.0, 13.0, 8.0, 8.0, 2.0, 8.0, -3.0, 8.0, 7.0, -5.0, 5.0, 8.0, 12.0, -14.0, 5.0, 12.0, -18.0, 11.0, 10.0, 12.0, -18.0, 9.0, 13.0, 11.0, 3.0, -13.0, 12.0, 13.0, 7.0, -7.0, 3.0, 12.0, 9.0, 13.0, -14.0, 7.0, 6.0, 8.0, -9.0, 10.0, 12.0, -2.0, 5.0, 0.0, -12.0, 10.0, 7.0, 10.0, -9.0, 9.0, 6.0, 9.0, -6.0, 7.0, 5.0, 9.0, 5.0, -16.0, 13.0, 13.0, 7.0, 9.0, -13.0, 12.0, 11.0, 10.0, 5.0, -11.0, -6.0, 10.0, 3.0, 8.0, -1.0, 10.0, -6.0, 12.0, -9.0, 9.0, 12.0, 3.0, -13.0, 12.0, 9.0, 7.0, -6.0, 7.0, 8.0, 6.0, 7.0, 11.0, 9.0, -12.0, 7.0, -5.0, 7.0, 6.0, 7.0, 13.0, 8.0, -13.0, 12.0, 3.0, 3.0, -3.0, 9.0, -13.0, 13.0, 6.0, 12.0, -6.0, 4.0, 5.0, 11.0, 9.0, 7.0, -12.0, -5.0, 10.0, -1.0, 11.0, 6.0, -6.0, 12.0, 3.0, 6.0, -8.0, 6.0, 11.0, -7.0, 14.0, 0.0, 8.0, 13.0, 8.0, 0.0, -6.0, 3.0, -2.0, 2.0, 12.0, 1.0, -4.0, 5.0, 13.0, 14.0, 2.0, -6.0, 5.0, -11.0, 11.0, 8.0, 7.0, -5.0, 10.0, 3.0, 7.0, 4.0, 12.0, 6.0, -7.0, 13.0, 11.0, 6.0, -15.0, -14.0, 5.0, 12.0, 12.0, 13.0, 315.0, 13.0, 13.0, 5.0, -5.0, 8.0, 7.0, 8.0, -1.0, -1.0, 9.0, -17.0, 8.0, 13.0, 11.0, 5.0, 7.0, -4.0, 7.0, 3.0, 2.0, 11.0, -1.0, -5.0, 7.0, 10.0, 3.0, -11.0, 7.0, 12.0, 7.0, 4.0, -8.0, 13.0, 6.0, -4.0, 7.0, -1.0, 13.0, 14.0, 12.0, -18.0, 7.0, 2.0, 3.0, -1.0, 11.0, 0.0, -4.0, 12.0, 7.0, -9.0, 11.0, 2.0, 11.0, 14.0, 9.0, 4.0, -12.0, -5.0, 12.0, 11.0, -3.0, -2.0, 11.0, -5.0, 11.0, -13.0, 10.0, 6.0, 12.0, -16.0, 11.0, 8.0, 12.0, -10.0, 0.0, 13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22049865489841716, "mean_inference_ms": 1.1791018037371113, "mean_action_processing_ms": 0.07215136345376513, "mean_env_wait_ms": 0.1793461426358991, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 270000, "agent_timesteps_total": 269946, "timers": {"sample_time_ms": 348.445, "sample_throughput": 15497.427, "learn_time_ms": 6797.633, "learn_throughput": 794.394, "update_time_ms": 11.743}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 211.6370849609375, "policy_loss": -0.03808382898569107, "vf_loss": 211.67076110839844, "vf_explained_var": 0.11228585988283157, "kl": 0.009771358221769333, "entropy": 0.5545603036880493, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 270000, "num_agent_steps_sampled": 269946, "num_steps_trained": 270000, "num_agent_steps_trained": 269946}, "done": false, "episodes_total": 5292, "training_iteration": 50, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-47-33", "timestamp": 1626860853, "time_this_iter_s": 7.235063552856445, "time_total_s": 357.08743691444397, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae677b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 357.08743691444397, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 21.009090909090908, "ram_util_percent": 14.109090909090908}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.26851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 5.31712962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 13.0, -4.0, -8.0, 1.0, 14.0, -7.0, 7.0, 10.0, 0.0, -7.0, 12.0, 2.0, 14.0, -9.0, 8.0, -2.0, 14.0, -7.0, 10.0, -7.0, 14.0, 5.0, 3.0, 11.0, -1.0, 12.0, -7.0, -18.0, 14.0, 8.0, 11.0, -2.0, 12.0, -5.0, 10.0, 7.0, 14.0, -12.0, 6.0, 13.0, -1.0, 7.0, -4.0, -14.0, 11.0, 8.0, 10.0, 13.0, 10.0, -5.0, -3.0, -10.0, 14.0, 4.0, 7.0, 8.0, 13.0, -19.0, 13.0, 8.0, 6.0, 6.0, -5.0, 12.0, 10.0, -5.0, -2.0, 4.0, 13.0, -6.0, 4.0, 11.0, -12.0, 3.0, 13.0, -14.0, 12.0, 9.0, 8.0, 14.0, 11.0, -6.0, -4.0, -16.0, 13.0, 10.0, 8.0, 10.0, 9.0, -14.0, 10.0, 5.0, 13.0, -14.0, 11.0, 14.0, 12.0, -3.0, -8.0, 4.0, 14.0, -8.0, 5.0, 4.0, -3.0, 1.0, 13.0, -16.0, 14.0, 9.0, 8.0, 14.0, -2.0, -6.0, 9.0, -1.0, 10.0, 11.0, -5.0, 14.0, 14.0, 314.0, 12.0, -1.0, 14.0, -6.0, 8.0, 14.0, 11.0, -4.0, -6.0, -2.0, 12.0, -2.0, 7.0, 11.0, 7.0, -15.0, 12.0, -11.0, 13.0, 6.0, 7.0, 13.0, 8.0, 2.0, -8.0, -5.0, 13.0, 12.0, -5.0, 13.0, -1.0, 0.0, 3.0, -12.0, 13.0, 7.0, 7.0, 0.0, 11.0, -6.0, 10.0, -19.0, 14.0, 12.0, 8.0, 11.0, -1.0, -4.0, 9.0, -3.0, 13.0, -8.0, 13.0, -2.0, 12.0, -6.0, 11.0, -12.0, 11.0, 9.0, 7.0, 12.0, -6.0, -3.0, 12.0, -10.0, 12.0, 5.0, 8.0, 12.0, 7.0, 1.0, -5.0, 7.0, 13.0, -1.0, -4.0, 9.0, -10.0, 6.0, 10.0, -10.0, 9.0, 8.0, 8.0, 12.0, 11.0, -7.0, -1.0, 7.0, 13.0, 2.0, -7.0, 13.0, 14.0, 313.0, 13.0, -11.0, 10.0, 8.0, 8.0, 13.0, 9.0, -2.0, -5.0, -2.0, 14.0, -4.0, 7.0, 10.0, 0.0, -8.0, 13.0, -14.0, 14.0, 7.0, 8.0, 11.0, 4.0, 3.0, -3.0, 2.0, 13.0, -7.0, 7.0, 7.0, 12.0, -15.0, 11.0, 4.0, 13.0, -9.0, 7.0, 11.0, 11.0, -5.0, -2.0, -2.0, 14.0, -4.0, 7.0, 12.0, 0.0, -9.0, 12.0, -11.0, 10.0, 9.0, 7.0, 14.0, 2.0, 3.0, -4.0, 1.0, 14.0, -7.0, 7.0, 11.0, 0.0, -9.0, 13.0, 3.0, -4.0, 8.0, 8.0, -1.0, 13.0, -6.0, 9.0, -15.0, 14.0, 8.0, 8.0, 13.0, 0.0, 13.0, -11.0, -13.0, 14.0, 6.0, 8.0, 13.0, 11.0, 0.0, -9.0, 2.0, 14.0, 8.0, -9.0, 10.0, 0.0, -8.0, 13.0, -13.0, 14.0, 7.0, 7.0, 14.0, 11.0, -5.0, -5.0, -6.0, 14.0, 0.0, 7.0, 8.0, -2.0, 12.0, -3.0, -6.0, 9.0, 4.0, 8.0, 0.0, 9.0, -1.0, 7.0, -1.0, 14.0, 9.0, -7.0, 12.0, -1.0, -9.0, 13.0, -6.0, 9.0, 7.0, 5.0, 14.0, 10.0, -1.0, -8.0, -6.0, 13.0, 1.0, 7.0, 7.0, 12.0, -15.0, 11.0, -14.0, 13.0, 5.0, 11.0, 13.0, 10.0, -7.0, -1.0, -16.0, 14.0, 11.0, 6.0, 11.0, -2.0, 13.0, -7.0, -13.0, 13.0, 9.0, 6.0, 14.0, 9.0, -5.0, -3.0, -17.0, 14.0, 10.0, 8.0, 11.0, 11.0, -16.0, 9.0, -17.0, 13.0, 7.0, 12.0, 14.0, 11.0, -6.0, -4.0, -15.0, 14.0, 10.0, 6.0, 10.0, 7.0, -14.0, 12.0, -7.0, 9.0, 7.0, 6.0, 13.0, 8.0, 0.0, -6.0, 4.0, 13.0, -12.0, 10.0, 10.0, -15.0, 7.0, 13.0, -11.0, 12.0, 8.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2201482786005538, "mean_inference_ms": 1.1787201181011537, "mean_action_processing_ms": 0.07213301493242615, "mean_env_wait_ms": 0.17931363284028437, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 275400, "agent_timesteps_total": 275400, "timers": {"sample_time_ms": 347.321, "sample_throughput": 15547.562, "learn_time_ms": 6811.321, "learn_throughput": 792.798, "update_time_ms": 11.807}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 457.0467834472656, "policy_loss": -0.031808771193027496, "vf_loss": 457.0746765136719, "vf_explained_var": 0.1640971153974533, "kl": 0.00871956255286932, "entropy": 0.5929158926010132, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 275400, "num_agent_steps_sampled": 275400, "num_steps_trained": 275400, "num_agent_steps_trained": 275400}, "done": false, "episodes_total": 5400, "training_iteration": 51, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-47-40", "timestamp": 1626860860, "time_this_iter_s": 7.175393342971802, "time_total_s": 364.26283025741577, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 364.26283025741577, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 22.050000000000004, "ram_util_percent": 14.12}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 9.0, -11.0, 6.0, 13.0, 7.0, -4.0, -1.0, 5.0, 13.0, -11.0, 8.0, 11.0, 7.0, -5.0, 2.0, 14.0, 9.0, 3.0, -11.0, 7.0, -13.0, 10.0, 11.0, 4.0, 7.0, 8.0, -4.0, 3.0, 13.0, 10.0, -11.0, 7.0, 0.0, 6.0, 2.0, 9.0, 8.0, -10.0, 8.0, 12.0, 4.0, 9.0, -10.0, 6.0, -6.0, 7.0, 8.0, 3.0, 9.0, -7.0, 10.0, 11.0, 2.0, -2.0, 4.0, 5.0, 14.0, -8.0, 4.0, 5.0, 13.0, -13.0, 10.0, 7.0, 12.0, -1.0, -3.0, 9.0, 13.0, 4.0, -11.0, 9.0, -10.0, 8.0, 8.0, 13.0, 8.0, -7.0, 1.0, 7.0, 7.0, -11.0, 12.0, 10.0, 6.0, -14.0, 13.0, 5.0, 13.0, 10.0, -13.0, 5.0, 0.0, 8.0, 2.0, 1.0, 10.0, -7.0, 11.0, 11.0, 4.0, -10.0, 10.0, -7.0, 7.0, 13.0, 2.0, 3.0, 10.0, 8.0, -6.0, 11.0, -1.0, 6.0, -1.0, 4.0, -2.0, 5.0, 8.0, 5.0, 14.0, -4.0, 0.0, 1.0, 10.0, -8.0, 12.0, 7.0, 14.0, 2.0, -8.0, 1.0, 13.0, -12.0, 13.0, 14.0, 7.0, 3.0, -9.0, 7.0, 0.0, 2.0, 6.0, 7.0, -4.0, 11.0, 1.0, 12.0, 8.0, -15.0, 10.0, 7.0, -5.0, 5.0, 8.0, 4.0, -5.0, 8.0, 8.0, 12.0, 5.0, 5.0, -7.0, 7.0, -8.0, 8.0, 8.0, -2.0, 13.0, -9.0, 13.0, 13.0, 8.0, 3.0, -9.0, -7.0, 14.0, 6.0, 2.0, 10.0, -9.0, 6.0, 8.0, 4.0, 13.0, 9.0, -11.0, 7.0, -3.0, 7.0, 4.0, 10.0, 6.0, -9.0, 8.0, 2.0, 13.0, 9.0, -9.0, 5.0, 0.0, 7.0, 3.0, 9.0, 9.0, 9.0, -12.0, 13.0, 14.0, -4.0, -8.0, 5.0, 12.0, -14.0, 12.0, 11.0, 14.0, -17.0, 7.0, 11.0, 12.0, 6.0, -14.0, 7.0, -5.0, 5.0, 8.0, 9.0, -3.0, 1.0, 8.0, 6.0, 14.0, 8.0, -13.0, 9.0, 12.0, 2.0, -8.0, 9.0, 9.0, 10.0, -13.0, 13.0, 4.0, 8.0, -10.0, 8.0, -6.0, 6.0, 7.0, 11.0, 6.0, -5.0, 3.0, 13.0, 12.0, 3.0, -13.0, 2.0, 0.0, 6.0, 7.0, -1.0, 12.0, -4.0, 8.0, 12.0, 11.0, -8.0, 0.0, 6.0, 8.0, -4.0, 5.0, 11.0, 6.0, -7.0, 5.0, 7.0, 13.0, -7.0, 2.0, 9.0, -1.0, 4.0, 3.0, 6.0, 14.0, -5.0, 0.0, 12.0, 7.0, 8.0, -12.0, 4.0, 13.0, -10.0, 8.0, 8.0, 14.0, 5.0, -12.0, 13.0, 4.0, -12.0, 10.0, 7.0, 13.0, 8.0, -13.0, 5.0, 14.0, 3.0, -7.0, 10.0, 9.0, 4.0, -8.0, 12.0, -3.0, 0.0, 6.0, -6.0, 13.0, 1.0, 7.0, 7.0, 12.0, -15.0, 11.0, -14.0, 13.0, 5.0, 11.0, 13.0, 10.0, -7.0, -1.0, -16.0, 14.0, 11.0, 6.0, 11.0, -2.0, 13.0, -7.0, -13.0, 13.0, 9.0, 6.0, 14.0, 9.0, -5.0, -3.0, -17.0, 14.0, 10.0, 8.0, 11.0, 11.0, -16.0, 9.0, -17.0, 13.0, 7.0, 12.0, 14.0, 11.0, -6.0, -4.0, -15.0, 14.0, 10.0, 6.0, 10.0, 7.0, -14.0, 12.0, -7.0, 9.0, 7.0, 6.0, 13.0, 8.0, 0.0, -6.0, 4.0, 13.0, -12.0, 10.0, 10.0, -15.0, 7.0, 13.0, -11.0, 12.0, 8.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21996043986039915, "mean_inference_ms": 1.1778895989322284, "mean_action_processing_ms": 0.07209246825802335, "mean_env_wait_ms": 0.17925015256353466, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 280800, "agent_timesteps_total": 280719, "timers": {"sample_time_ms": 347.851, "sample_throughput": 15523.881, "learn_time_ms": 6808.932, "learn_throughput": 793.076, "update_time_ms": 12.036}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 28.813077926635742, "policy_loss": -0.09249716997146606, "vf_loss": 28.897579193115234, "vf_explained_var": 0.18795955181121826, "kl": 0.01777336187660694, "entropy": 0.5891045331954956, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 280800, "num_agent_steps_sampled": 280719, "num_steps_trained": 280800, "num_agent_steps_trained": 280719}, "done": false, "episodes_total": 5481, "training_iteration": 52, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-47-47", "timestamp": 1626860867, "time_this_iter_s": 7.161011695861816, "time_total_s": 371.4238419532776, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70221c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 371.4238419532776, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 21.08, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 9.0, -4.0, 3.0, 0.0, 13.0, -5.0, 7.0, 6.0, 14.0, 11.0, -16.0, 13.0, 0.0, -6.0, 8.0, 12.0, 13.0, -11.0, 1.0, 6.0, 13.0, 7.0, -11.0, 0.0, 13.0, 13.0, -11.0, 14.0, 2.0, -8.0, 7.0, -3.0, 13.0, 3.0, 2.0, 10.0, 13.0, -3.0, -5.0, -6.0, 12.0, 11.0, -2.0, 13.0, -5.0, 9.0, -2.0, 8.0, 12.0, 5.0, -10.0, -11.0, 13.0, 8.0, 5.0, 8.0, 13.0, 4.0, -10.0, 12.0, 7.0, -6.0, 2.0, 6.0, 12.0, -1.0, -2.0, -9.0, 13.0, 9.0, 2.0, 1.0, 14.0, 6.0, -6.0, 13.0, 13.0, -10.0, -1.0, 12.0, 13.0, -17.0, 7.0, 10.0, 11.0, 6.0, -12.0, 5.0, -2.0, 7.0, 5.0, 14.0, -2.0, 7.0, -4.0, 11.0, 13.0, 3.0, -12.0, 9.0, 9.0, 12.0, -15.0, -9.0, 14.0, 0.0, 10.0, 8.0, 3.0, 6.0, -2.0, 11.0, 12.0, -6.0, -2.0, 3.0, 13.0, 5.0, -6.0, -4.0, 9.0, 7.0, 3.0, 12.0, 6.0, -9.0, 6.0, -5.0, 13.0, -3.0, 10.0, 0.0, 13.0, 8.0, -6.0, -12.0, 14.0, 11.0, 2.0, 12.0, -3.0, 11.0, -5.0, -1.0, 13.0, 5.0, -2.0, 0.0, 12.0, 10.0, -7.0, 0.0, 11.0, 8.0, -4.0, 13.0, 1.0, -8.0, 9.0, 13.0, 13.0, 0.0, -11.0, 5.0, 13.0, 8.0, -11.0, 11.0, 0.0, 4.0, 0.0, 13.0, 14.0, -16.0, 4.0, 6.0, 12.0, -13.0, 10.0, 3.0, 12.0, 6.0, -6.0, -11.0, 14.0, 0.0, 12.0, 9.0, 2.0, -4.0, 8.0, 12.0, 13.0, -19.0, 9.0, 1.0, 13.0, -6.0, 7.0, -12.0, 10.0, 7.0, 10.0, 8.0, -15.0, 11.0, 11.0, -9.0, 9.0, 6.0, 9.0, 12.0, -4.0, 8.0, -1.0, -2.0, 13.0, 11.0, -7.0, 13.0, 6.0, -8.0, 4.0, -1.0, 13.0, 4.0, -1.0, -14.0, 14.0, 8.0, 7.0, 5.0, 12.0, 7.0, -9.0, 11.0, 1.0, -5.0, 8.0, -6.0, 9.0, 11.0, 1.0, 12.0, 6.0, 10.0, -13.0, 0.0, 11.0, 7.0, -3.0, 13.0, -2.0, -7.0, 11.0, 3.0, 13.0, -8.0, 7.0, -2.0, 12.0, -2.0, 7.0, 12.0, 8.0, 10.0, -15.0, 14.0, -2.0, 11.0, -8.0, 8.0, -4.0, 2.0, 9.0, -14.0, 12.0, 9.0, 8.0, 9.0, -5.0, 5.0, 6.0, 8.0, -13.0, 9.0, 11.0, -6.0, 9.0, 4.0, 8.0, -20.0, 13.0, 9.0, 13.0, 3.0, -5.0, 7.0, 10.0, 10.0, 2.0, 9.0, -6.0, 8.0, 12.0, 5.0, -10.0, -2.0, 13.0, 10.0, -6.0, -6.0, 12.0, 0.0, 9.0, 9.0, -14.0, 10.0, 10.0, 14.0, 9.0, -12.0, 4.0, 3.0, 13.0, 3.0, -4.0, 9.0, -8.0, 7.0, 7.0, 8.0, 2.0, -5.0, 10.0, 9.0, 11.0, -17.0, 12.0, -8.0, 12.0, 8.0, 3.0, 11.0, 11.0, 1.0, -8.0, 13.0, -2.0, -5.0, 9.0, 12.0, 13.0, -1.0, -9.0, 1.0, 13.0, -4.0, 5.0, -14.0, 9.0, 9.0, 11.0, 14.0, -1.0, -4.0, 6.0, 13.0, 13.0, -6.0, -5.0, 7.0, 13.0, -7.0, 2.0, -9.0, 14.0, 5.0, 5.0, 13.0, 0.0, 9.0, -7.0, 13.0, 13.0, -7.0, -4.0, 4.0, 12.0, 8.0, -9.0, -7.0, 9.0, 6.0, 7.0, 9.0, 6.0, 8.0, -8.0, -2.0, 13.0, 3.0, 1.0, 0.0, 13.0, 7.0, -5.0, 0.0, 10.0, 12.0, -7.0, 13.0, -2.0, -3.0, 7.0, -13.0, 14.0, 11.0, 3.0, 9.0, 11.0, 8.0, -13.0, -7.0, 10.0, 8.0, 4.0, 12.0, 3.0, -4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2201846968103227, "mean_inference_ms": 1.1781383771119065, "mean_action_processing_ms": 0.07209316882947817, "mean_env_wait_ms": 0.17932269423668518, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 286200, "agent_timesteps_total": 286119, "timers": {"sample_time_ms": 348.058, "sample_throughput": 15514.67, "learn_time_ms": 6829.486, "learn_throughput": 790.689, "update_time_ms": 12.038}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 26.2500057220459, "policy_loss": -0.09006021171808243, "vf_loss": 26.332855224609375, "vf_explained_var": 0.20535986125469208, "kl": 0.016030745580792427, "entropy": 0.568825900554657, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 286200, "num_agent_steps_sampled": 286119, "num_steps_trained": 286200, "num_agent_steps_trained": 286119}, "done": false, "episodes_total": 5589, "training_iteration": 53, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-47-55", "timestamp": 1626860875, "time_this_iter_s": 7.587734222412109, "time_total_s": 379.0115761756897, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70221158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 379.0115761756897, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 21.29090909090909, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 40.157407407407405, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 10.039351851851851}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 354.0, 15.0, 356.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 9.0, 9.0, 0.0, 13.0, 13.0, 11.0, 317.0, 14.0, -5.0, 3.0, 3.0, 13.0, 14.0, 318.0, 11.0, 9.0, 6.0, 8.0, -8.0, 13.0, 14.0, 313.0, 12.0, 13.0, 8.0, -9.0, 3.0, 10.0, -1.0, 9.0, -3.0, -1.0, 5.0, 10.0, 1.0, 12.0, 9.0, 11.0, -17.0, 3.0, -1.0, 7.0, 6.0, 8.0, 10.0, -12.0, 9.0, -1.0, 9.0, 7.0, 0.0, -1.0, 11.0, 1.0, 4.0, 14.0, -9.0, 6.0, 4.0, 13.0, 14.0, 318.0, 11.0, 8.0, -6.0, 13.0, 0.0, -1.0, 11.0, 6.0, -1.0, 14.0, 8.0, -9.0, 2.0, 0.0, -4.0, 10.0, 9.0, 7.0, -6.0, 10.0, 4.0, 3.0, 11.0, -10.0, 11.0, 13.0, -6.0, 8.0, 0.0, 5.0, -1.0, 7.0, 4.0, 10.0, -6.0, 11.0, 0.0, -2.0, 8.0, 3.0, 6.0, 11.0, 12.0, 4.0, -12.0, 14.0, 14.0, 317.0, 10.0, 9.0, 4.0, 11.0, -9.0, -3.0, 12.0, 7.0, -1.0, 14.0, -10.0, 3.0, 8.0, 12.0, 14.0, 316.0, 12.0, 10.0, -6.0, 12.0, -1.0, 14.0, 8.0, -11.0, 4.0, 13.0, -5.0, 6.0, 1.0, 12.0, 12.0, -21.0, 12.0, 10.0, 7.0, 9.0, -11.0, 10.0, 9.0, -9.0, 5.0, 8.0, 11.0, -12.0, 8.0, 0.0, 6.0, -2.0, 11.0, 12.0, 0.0, 7.0, -4.0, 13.0, 13.0, 10.0, -21.0, 13.0, 2.0, -8.0, 8.0, -1.0, 11.0, 8.0, -3.0, 11.0, -13.0, 11.0, 6.0, 12.0, 11.0, 9.0, -17.0, 14.0, 9.0, -14.0, 6.0, 7.0, 14.0, -17.0, 11.0, 12.0, -15.0, 7.0, 11.0, 11.0, 13.0, -14.0, 5.0, 4.0, 10.0, -7.0, 8.0, 9.0, -9.0, 5.0, 10.0, -2.0, 4.0, 10.0, 3.0, -3.0, 13.0, -8.0, 13.0, 14.0, -8.0, 1.0, 8.0, 9.0, 14.0, 2.0, -10.0, -4.0, 8.0, 9.0, 2.0, 14.0, 7.0, -5.0, -1.0, 4.0, 10.0, -11.0, 12.0, 14.0, 14.0, 316.0, 11.0, 12.0, 6.0, 12.0, -15.0, 12.0, 8.0, -10.0, 5.0, 9.0, -2.0, 2.0, 6.0, 9.0, -4.0, 7.0, 3.0, 9.0, 0.0, 5.0, 1.0, 9.0, 13.0, -11.0, 4.0, 9.0, 7.0, 6.0, -7.0, 13.0, 14.0, 318.0, 10.0, 4.0, 7.0, 12.0, -8.0, 13.0, 8.0, 0.0, -6.0, 7.0, -8.0, 9.0, 7.0, 9.0, 14.0, -16.0, 8.0, -1.0, 7.0, 7.0, 2.0, 12.0, 6.0, -14.0, 11.0, 14.0, -12.0, 5.0, 8.0, 9.0, 10.0, -12.0, 8.0, 12.0, -10.0, 12.0, 1.0, -6.0, 13.0, 4.0, 4.0, 14.0, -9.0, 4.0, 6.0, 8.0, -11.0, 6.0, 12.0, -3.0, 9.0, 13.0, -4.0, 13.0, 12.0, 0.0, -10.0, 14.0, 12.0, 0.0, -11.0, -6.0, 14.0, 9.0, -2.0, 12.0, -15.0, 9.0, 9.0, 13.0, 13.0, -15.0, 4.0, 13.0, -4.0, 7.0, -1.0, 13.0, 5.0, -11.0, 8.0, -1.0, 3.0, 8.0, 5.0, 11.0, 12.0, 10.0, -18.0, 10.0, -8.0, 5.0, 8.0, -3.0, 12.0, -5.0, 11.0, -5.0, 8.0, 12.0, 0.0, 0.0, 9.0, 2.0, 4.0, 13.0, -9.0, 3.0, 8.0, 11.0, -6.0, 2.0, 8.0, 4.0, 8.0, 12.0, -9.0, -2.0, 13.0, 0.0, 4.0, 14.0, 6.0, -8.0, 3.0, 8.0, 10.0, -10.0, 7.0, 11.0, -15.0, 7.0, 12.0, 14.0, 4.0, -8.0, 5.0, 9.0, -3.0, 10.0, -1.0, 14.0, 14.0, -12.0, -1.0, 5.0, -5.0, 9.0, 6.0, 7.0, 12.0, 10.0, -14.0, 10.0, -3.0, 8.0, 0.0, -7.0, 5.0, 9.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22026070131588746, "mean_inference_ms": 1.1778159722112866, "mean_action_processing_ms": 0.07206529164591662, "mean_env_wait_ms": 0.17929369339490348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 291600, "agent_timesteps_total": 291519, "timers": {"sample_time_ms": 347.266, "sample_throughput": 15550.052, "learn_time_ms": 6848.603, "learn_throughput": 788.482, "update_time_ms": 11.876}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 1695.477783203125, "policy_loss": -0.02921346202492714, "vf_loss": 1695.504150390625, "vf_explained_var": 0.028428232297301292, "kl": 0.007048244588077068, "entropy": 0.5576058626174927, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 291600, "num_agent_steps_sampled": 291519, "num_steps_trained": 291600, "num_agent_steps_trained": 291519}, "done": false, "episodes_total": 5697, "training_iteration": 54, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-48-03", "timestamp": 1626860883, "time_this_iter_s": 7.591604948043823, "time_total_s": 386.6031811237335, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70221840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 386.6031811237335, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 21.163636363636364, "ram_util_percent": 14.109090909090908}, "trial_id": "cf107_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 313.0}, "policy_reward_mean": {"learned": 4.530092592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 10.0, -7.0, 12.0, 0.0, 4.0, 2.0, 9.0, -13.0, 8.0, 12.0, 8.0, -8.0, 9.0, 13.0, 1.0, 11.0, 9.0, -11.0, 6.0, 13.0, 7.0, -15.0, 10.0, 3.0, 13.0, 11.0, -12.0, 12.0, 3.0, 5.0, -5.0, -2.0, 14.0, -4.0, 7.0, 10.0, 6.0, -12.0, 11.0, -7.0, 5.0, 12.0, 5.0, 4.0, 6.0, -8.0, 13.0, 14.0, -4.0, -8.0, 13.0, 12.0, 6.0, -14.0, 11.0, 11.0, 1.0, -4.0, 7.0, -1.0, 8.0, 0.0, 8.0, 14.0, -2.0, -6.0, 9.0, 14.0, 8.0, -16.0, 9.0, 11.0, -13.0, 13.0, 4.0, -7.0, 11.0, 3.0, 8.0, 14.0, 5.0, -12.0, 8.0, 13.0, 7.0, -14.0, 9.0, -1.0, -5.0, 11.0, 10.0, 11.0, -10.0, 5.0, 9.0, 10.0, 6.0, -13.0, 12.0, 13.0, 5.0, -7.0, 4.0, -13.0, 10.0, 9.0, 9.0, -6.0, 11.0, 3.0, 7.0, 10.0, -1.0, -7.0, 13.0, 11.0, 5.0, 6.0, -7.0, -15.0, 13.0, 7.0, 10.0, 12.0, 8.0, 7.0, -12.0, 8.0, 9.0, -13.0, 11.0, 13.0, 5.0, -8.0, 5.0, -13.0, 9.0, 6.0, 13.0, 9.0, -3.0, 1.0, 8.0, 14.0, 4.0, -16.0, 13.0, 12.0, 11.0, -19.0, 11.0, -7.0, 7.0, 12.0, 3.0, 13.0, -7.0, 4.0, 5.0, 14.0, -4.0, -2.0, 7.0, 13.0, 6.0, -14.0, 10.0, -18.0, 11.0, 11.0, 11.0, -1.0, 4.0, 7.0, 5.0, 11.0, 9.0, -18.0, 13.0, 13.0, 6.0, -10.0, 6.0, 3.0, 4.0, 13.0, -5.0, 0.0, 6.0, 0.0, 9.0, 14.0, 8.0, -12.0, 5.0, 12.0, 5.0, 11.0, -13.0, 11.0, 7.0, 7.0, -10.0, 8.0, -4.0, 9.0, 2.0, 14.0, 7.0, -2.0, -4.0, 12.0, 4.0, -9.0, 8.0, -11.0, 13.0, 2.0, 11.0, 2.0, -3.0, 10.0, 6.0, 13.0, 7.0, -16.0, 11.0, -4.0, 9.0, -2.0, 12.0, -4.0, 0.0, 13.0, 6.0, -1.0, 13.0, -5.0, 8.0, 14.0, 3.0, -8.0, 6.0, -1.0, 11.0, -1.0, 6.0, -8.0, 7.0, 7.0, 9.0, 6.0, -5.0, 5.0, 9.0, 10.0, 0.0, -1.0, 6.0, 13.0, 5.0, -13.0, 10.0, -4.0, 12.0, 12.0, -5.0, 9.0, -9.0, 10.0, 5.0, 14.0, -7.0, -1.0, 9.0, 14.0, 9.0, -18.0, 10.0, -6.0, 2.0, 12.0, 7.0, -3.0, 10.0, 0.0, 8.0, 9.0, 10.0, 2.0, -6.0, 13.0, 6.0, -7.0, 3.0, -10.0, 8.0, 7.0, 10.0, 8.0, -8.0, 8.0, 7.0, 9.0, -6.0, 3.0, 9.0, -2.0, 6.0, 1.0, 10.0, -5.0, -2.0, 10.0, 12.0, 2.0, 6.0, 13.0, -6.0, 14.0, 10.0, -11.0, 2.0, 12.0, 13.0, -20.0, 10.0, -10.0, 10.0, 11.0, 4.0, -9.0, 10.0, 8.0, 6.0, 12.0, 14.0, -13.0, 2.0, 0.0, 7.0, 0.0, 8.0, -12.0, 8.0, 12.0, 7.0, -10.0, 6.0, 7.0, 12.0, 11.0, 9.0, -3.0, -2.0, -3.0, 9.0, -1.0, 10.0, 3.0, 12.0, 10.0, -10.0, -2.0, 6.0, 2.0, 9.0, 13.0, 13.0, 313.0, 13.0, 13.0, 5.0, -12.0, 9.0, -5.0, 14.0, -4.0, 10.0, 3.0, 13.0, -14.0, 13.0, 14.0, -5.0, -2.0, 8.0, 11.0, 7.0, -14.0, 11.0, 6.0, -10.0, 11.0, 8.0, 3.0, 6.0, -4.0, 10.0, 14.0, 9.0, -19.0, 11.0, 10.0, 6.0, -13.0, 12.0, -17.0, 12.0, 10.0, 10.0, 8.0, -9.0, 6.0, 10.0, 12.0, 4.0, 8.0, -9.0, 12.0, 5.0, -13.0, 11.0, -13.0, 12.0, 5.0, 11.0, 5.0, 10.0, -9.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22029713764297335, "mean_inference_ms": 1.1776652046175384, "mean_action_processing_ms": 0.0720721239234969, "mean_env_wait_ms": 0.17930109238479852, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 297000, "agent_timesteps_total": 296919, "timers": {"sample_time_ms": 346.82, "sample_throughput": 15570.053, "learn_time_ms": 6878.307, "learn_throughput": 785.077, "update_time_ms": 11.766}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 88.37033081054688, "policy_loss": -0.049294207245111465, "vf_loss": 88.41410827636719, "vf_explained_var": 0.16137129068374634, "kl": 0.012277304194867611, "entropy": 0.5544502139091492, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 297000, "num_agent_steps_sampled": 296919, "num_steps_trained": 297000, "num_agent_steps_trained": 296919}, "done": false, "episodes_total": 5805, "training_iteration": 55, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-48-10", "timestamp": 1626860890, "time_this_iter_s": 7.541977405548096, "time_total_s": 394.1451585292816, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 394.1451585292816, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 20.990909090909092, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 4.0, 3.0, 12.0, 10.0, 9.0, -10.0, 6.0, 11.0, 14.0, 6.0, -16.0, 13.0, -17.0, 7.0, 12.0, -1.0, 11.0, -7.0, 12.0, -2.0, 14.0, -3.0, 6.0, 13.0, -6.0, 4.0, 4.0, -5.0, 10.0, 2.0, 8.0, -9.0, 8.0, 6.0, 10.0, 10.0, 14.0, -14.0, 5.0, 12.0, 10.0, 9.0, -16.0, 13.0, 6.0, 10.0, -14.0, -7.0, 1.0, 11.0, 10.0, 10.0, 14.0, 4.0, -13.0, -4.0, 1.0, 9.0, 9.0, -14.0, 11.0, 6.0, 12.0, 13.0, 12.0, 321.0, 10.0, 5.0, 14.0, -5.0, 1.0, 9.0, 5.0, -1.0, 2.0, 14.0, 1.0, -13.0, 13.0, 13.0, -3.0, -5.0, 10.0, 9.0, 9.0, -4.0, 1.0, 13.0, 14.0, 9.0, -21.0, 14.0, 4.0, -13.0, 10.0, 2.0, -4.0, 10.0, 7.0, 10.0, 14.0, 5.0, -14.0, 10.0, -1.0, -6.0, 12.0, 14.0, -11.0, 10.0, 2.0, 13.0, -9.0, -2.0, 13.0, 10.0, 14.0, 3.0, -12.0, 13.0, 3.0, -6.0, 5.0, 13.0, 2.0, 12.0, -12.0, 7.0, -8.0, 9.0, 7.0, 9.0, 9.0, 5.0, -8.0, 13.0, 13.0, -8.0, -3.0, 13.0, 9.0, -19.0, 12.0, 2.0, 6.0, -1.0, 8.0, 10.0, 14.0, -9.0, 0.0, 8.0, 9.0, -5.0, 3.0, 13.0, 2.0, -12.0, 12.0, -1.0, 4.0, 2.0, 10.0, 5.0, 14.0, -6.0, 2.0, 10.0, 12.0, -15.0, 8.0, 13.0, 8.0, -16.0, 10.0, 4.0, -7.0, 10.0, 8.0, 5.0, 14.0, 7.0, -11.0, 8.0, 12.0, 8.0, -13.0, 13.0, -15.0, 4.0, 13.0, -10.0, 2.0, 12.0, 11.0, 9.0, 6.0, -3.0, 3.0, 12.0, 14.0, 8.0, -19.0, 14.0, 3.0, 10.0, -12.0, 4.0, -10.0, 11.0, 10.0, 4.0, 14.0, 8.0, -11.0, 11.0, 13.0, 10.0, -19.0, 14.0, -10.0, 1.0, 10.0, -4.0, 2.0, 13.0, 4.0, 9.0, 9.0, -6.0, 3.0, 13.0, 14.0, -3.0, -9.0, 13.0, -2.0, -8.0, 12.0, 8.0, 2.0, -4.0, 9.0, 9.0, 14.0, 11.0, 320.0, 10.0, 6.0, 8.0, -9.0, 14.0, 2.0, -13.0, 12.0, 12.0, 5.0, -12.0, 10.0, -15.0, 14.0, 8.0, 8.0, 13.0, 10.0, 6.0, -14.0, 14.0, 1.0, -10.0, 10.0, 4.0, -11.0, 11.0, 11.0, 9.0, 7.0, 6.0, -7.0, 10.0, 13.0, -10.0, 2.0, 13.0, 9.0, -12.0, 5.0, -6.0, 6.0, 7.0, 8.0, 4.0, 14.0, -6.0, 3.0, 12.0, 12.0, -5.0, -4.0, 13.0, -3.0, -5.0, 10.0, 9.0, 4.0, -8.0, 10.0, 5.0, 9.0, -7.0, 8.0, 13.0, 13.0, -7.0, -4.0, 13.0, 3.0, -12.0, 11.0, 8.0, 11.0, -15.0, 11.0, 6.0, 14.0, -5.0, 0.0, 11.0, 11.0, -10.0, 3.0, 13.0, 6.0, 7.0, -11.0, 0.0, -3.0, 11.0, 7.0, 2.0, 14.0, -7.0, 6.0, -14.0, 6.0, 12.0, 11.0, 14.0, -3.0, 12.0, -8.0, -10.0, 10.0, 11.0, 4.0, 4.0, 14.0, -4.0, 1.0, 6.0, 9.0, -3.0, 3.0, 14.0, -5.0, -6.0, 12.0, 0.0, 5.0, -2.0, 12.0, 10.0, 9.0, -4.0, 0.0, 13.0, -3.0, 13.0, -8.0, 11.0, 12.0, 2.0, -10.0, 5.0, 2.0, -2.0, 10.0, 10.0, 14.0, -11.0, 2.0, 8.0, 8.0, 11.0, -12.0, 14.0, -13.0, 12.0, 2.0, -1.0, 0.0, 6.0, 10.0, 0.0, 14.0, -6.0, 7.0, 14.0, 12.0, 6.0, -17.0, -15.0, 13.0, 5.0, 12.0, 7.0, 10.0, -13.0, 11.0, 5.0, 14.0, -13.0, 9.0, 12.0, 11.0, 12.0, -20.0, 13.0, -15.0, 5.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22026668199905877, "mean_inference_ms": 1.177129154630212, "mean_action_processing_ms": 0.07204659637648046, "mean_env_wait_ms": 0.17926588876685248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 302400, "agent_timesteps_total": 302319, "timers": {"sample_time_ms": 346.135, "sample_throughput": 15600.856, "learn_time_ms": 6909.772, "learn_throughput": 781.502, "update_time_ms": 11.848}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 312.5704345703125, "policy_loss": -0.030086612328886986, "vf_loss": 312.5968017578125, "vf_explained_var": 0.12533719837665558, "kl": 0.008283432573080063, "entropy": 0.5894102454185486, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 302400, "num_agent_steps_sampled": 302319, "num_steps_trained": 302400, "num_agent_steps_trained": 302319}, "done": false, "episodes_total": 5913, "training_iteration": 56, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-48-18", "timestamp": 1626860898, "time_this_iter_s": 7.541826963424683, "time_total_s": 401.6869854927063, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 401.6869854927063, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 21.227272727272727, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.055555555555555, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.763888888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 13.0, -13.0, 8.0, 14.0, 10.0, -8.0, -1.0, -3.0, 14.0, 7.0, -3.0, 12.0, 8.0, -13.0, 8.0, 0.0, 0.0, 6.0, 9.0, -1.0, 2.0, 8.0, 6.0, -18.0, 12.0, 11.0, 10.0, 14.0, -3.0, 2.0, 3.0, 4.0, 14.0, 1.0, -4.0, -6.0, 12.0, 6.0, 3.0, -1.0, 14.0, 11.0, -9.0, 6.0, -4.0, 10.0, 3.0, 12.0, 13.0, -3.0, -7.0, -3.0, 11.0, 5.0, 2.0, -15.0, 13.0, 12.0, 5.0, 12.0, -2.0, 1.0, 4.0, -2.0, 9.0, 10.0, -2.0, -11.0, 11.0, 10.0, 5.0, 12.0, 4.0, 10.0, -11.0, 9.0, 14.0, -10.0, 2.0, 13.0, 11.0, 8.0, -17.0, 13.0, 13.0, -1.0, -10.0, 2.0, 13.0, 3.0, -3.0, 8.0, -6.0, 7.0, 7.0, 4.0, -6.0, 12.0, 5.0, -7.0, 7.0, 11.0, 4.0, 0.0, 9.0, 11.0, -5.0, 10.0, 9.0, -8.0, 4.0, 8.0, 11.0, 6.0, -10.0, 8.0, 8.0, -6.0, 5.0, -1.0, 8.0, 12.0, -4.0, 11.0, 11.0, 7.0, -13.0, -6.0, 7.0, 10.0, 4.0, 13.0, 3.0, 9.0, -10.0, -3.0, 12.0, 10.0, -4.0, 10.0, -1.0, 3.0, 3.0, 11.0, 11.0, 11.0, -18.0, -1.0, 4.0, 9.0, 3.0, 8.0, 1.0, 10.0, -4.0, 12.0, 14.0, -13.0, 2.0, 12.0, 12.0, -12.0, 3.0, -4.0, 13.0, 1.0, 5.0, -5.0, 14.0, -4.0, 10.0, 9.0, 12.0, -12.0, 6.0, 12.0, 6.0, -4.0, 1.0, 0.0, 13.0, -3.0, 5.0, 7.0, 5.0, 10.0, -7.0, 12.0, -17.0, 8.0, 12.0, 6.0, 13.0, -3.0, -1.0, 8.0, 13.0, -5.0, -1.0, -3.0, 11.0, -3.0, 10.0, 13.0, 14.0, 7.0, -19.0, -1.0, 3.0, 7.0, 6.0, 8.0, 11.0, -9.0, 5.0, 2.0, 13.0, 10.0, -10.0, 12.0, -6.0, 7.0, 2.0, 12.0, 12.0, -12.0, 3.0, -10.0, 9.0, 9.0, 7.0, 4.0, 3.0, 10.0, -2.0, 9.0, -7.0, 6.0, 7.0, -3.0, 11.0, 11.0, -4.0, 8.0, 12.0, 7.0, -12.0, -6.0, 13.0, -3.0, 11.0, 12.0, 4.0, -4.0, 3.0, -4.0, 8.0, 7.0, 4.0, 10.0, 12.0, 6.0, -13.0, -1.0, 8.0, 12.0, -4.0, 12.0, 6.0, -6.0, 3.0, -12.0, 9.0, 8.0, 10.0, 12.0, 14.0, 1.0, -12.0, 1.0, 13.0, -7.0, 8.0, 10.0, 9.0, -8.0, 4.0, 11.0, 13.0, -21.0, 12.0, 8.0, 13.0, -12.0, 6.0, 8.0, 8.0, 9.0, -10.0, 10.0, 9.0, 11.0, -14.0, -4.0, 13.0, 10.0, -4.0, 13.0, 13.0, 3.0, -14.0, 12.0, 9.0, -17.0, 11.0, 13.0, 11.0, 1.0, -9.0, -4.0, 13.0, 2.0, 4.0, -4.0, 6.0, 9.0, 4.0, -18.0, 14.0, 7.0, 12.0, 9.0, -2.0, 1.0, 7.0, 6.0, 8.0, -6.0, 7.0, 10.0, 12.0, -8.0, 1.0, 1.0, 8.0, 9.0, -3.0, 10.0, 9.0, 2.0, -6.0, 4.0, 14.0, 2.0, -5.0, 14.0, 6.0, 7.0, -12.0, 5.0, 9.0, 8.0, -7.0, 7.0, 10.0, -5.0, 3.0, 13.0, 3.0, 11.0, -12.0, -12.0, 13.0, 9.0, 5.0, 1.0, 9.0, -5.0, 10.0, 12.0, 13.0, 8.0, -17.0, 9.0, 7.0, 12.0, -13.0, -11.0, 12.0, 3.0, 11.0, -2.0, 12.0, 12.0, -7.0, 11.0, 13.0, -9.0, 0.0, 11.0, 8.0, 12.0, -16.0, 13.0, 13.0, -13.0, 2.0, 4.0, 6.0, -3.0, 8.0, 9.0, 14.0, 6.0, -14.0, 5.0, 10.0, 7.0, -7.0, 11.0, 7.0, -8.0, 5.0, -7.0, 9.0, 4.0, 9.0, 12.0, -2.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2202815425098665, "mean_inference_ms": 1.17705529657183, "mean_action_processing_ms": 0.072038282069798, "mean_env_wait_ms": 0.17926948144190846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 307800, "agent_timesteps_total": 307719, "timers": {"sample_time_ms": 345.348, "sample_throughput": 15636.419, "learn_time_ms": 6950.337, "learn_throughput": 776.941, "update_time_ms": 11.818}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 29.32038116455078, "policy_loss": -0.08553950488567352, "vf_loss": 29.398332595825195, "vf_explained_var": 0.14889013767242432, "kl": 0.01685142330825329, "entropy": 0.5691941976547241, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 307800, "num_agent_steps_sampled": 307719, "num_steps_trained": 307800, "num_agent_steps_trained": 307719}, "done": false, "episodes_total": 6021, "training_iteration": 57, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-48-26", "timestamp": 1626860906, "time_this_iter_s": 7.577269792556763, "time_total_s": 409.26425528526306, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 409.26425528526306, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 21.62727272727273, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 7.0, 0.0, 11.0, -17.0, 12.0, 12.0, 8.0, -5.0, 3.0, 10.0, 7.0, 13.0, 8.0, -15.0, 9.0, -5.0, 8.0, 10.0, 2.0, -12.0, 13.0, 12.0, 2.0, -11.0, 13.0, 6.0, 7.0, 11.0, 11.0, 6.0, -13.0, -6.0, 9.0, 6.0, 6.0, -12.0, 11.0, 12.0, 4.0, 12.0, -15.0, 8.0, 10.0, 11.0, 11.0, -17.0, 10.0, -5.0, -1.0, 12.0, 9.0, -5.0, 14.0, -3.0, 9.0, 6.0, -13.0, 11.0, 11.0, 10.0, -8.0, 4.0, 9.0, 8.0, 11.0, -13.0, 9.0, -8.0, 11.0, 7.0, 5.0, 9.0, 12.0, 1.0, -7.0, -8.0, 9.0, 5.0, 9.0, 12.0, 11.0, 8.0, -16.0, -11.0, 9.0, 12.0, 5.0, 5.0, 9.0, 9.0, -8.0, 14.0, 14.0, 315.0, 11.0, 9.0, -9.0, 7.0, 8.0, 9.0, 7.0, 7.0, -8.0, -6.0, 14.0, 6.0, 1.0, 9.0, 13.0, -17.0, 10.0, 11.0, -16.0, 12.0, 8.0, -7.0, 8.0, 5.0, 9.0, -3.0, 11.0, 9.0, -2.0, 10.0, 6.0, -13.0, 12.0, -1.0, 13.0, -1.0, 4.0, -5.0, 5.0, 4.0, 11.0, -6.0, 5.0, 6.0, 10.0, 8.0, 5.0, -4.0, 6.0, -9.0, 2.0, 11.0, 11.0, -11.0, 12.0, 7.0, 7.0, 4.0, 14.0, 3.0, -6.0, 13.0, 13.0, -16.0, 5.0, 6.0, -8.0, 4.0, 13.0, 3.0, -12.0, 12.0, 12.0, -9.0, 12.0, 1.0, 11.0, 4.0, 14.0, -12.0, 9.0, -15.0, 13.0, 10.0, 7.0, -12.0, 3.0, 12.0, 12.0, -7.0, 8.0, 6.0, 8.0, 7.0, 13.0, -4.0, -1.0, -6.0, 8.0, 13.0, 0.0, -7.0, 4.0, 12.0, 6.0, -1.0, 5.0, 10.0, 1.0, -3.0, 9.0, 6.0, 3.0, 3.0, -8.0, 13.0, 7.0, -4.0, 7.0, 5.0, 7.0, -5.0, 12.0, -2.0, 10.0, 0.0, 7.0, 4.0, 4.0, 8.0, 13.0, 10.0, -16.0, -6.0, -1.0, 10.0, 12.0, -6.0, 12.0, 4.0, 5.0, 11.0, -10.0, 6.0, 8.0, -1.0, -5.0, 9.0, 12.0, -12.0, 8.0, 12.0, 7.0, -10.0, 11.0, 7.0, 7.0, 3.0, 4.0, -2.0, 10.0, -6.0, 5.0, 11.0, 5.0, 5.0, -5.0, 12.0, 3.0, -6.0, 3.0, 11.0, 7.0, 12.0, -2.0, 4.0, 1.0, 4.0, 10.0, -5.0, 6.0, 6.0, 8.0, 12.0, -11.0, -1.0, -1.0, 6.0, 11.0, 14.0, 14.0, -19.0, 6.0, 9.0, 7.0, 12.0, -13.0, -15.0, 12.0, 12.0, 6.0, -6.0, 14.0, -2.0, 9.0, 7.0, 11.0, -14.0, 11.0, 5.0, 12.0, 12.0, -14.0, -7.0, 6.0, 7.0, 9.0, 2.0, 12.0, 11.0, -10.0, 8.0, 12.0, 10.0, -15.0, -12.0, 4.0, 11.0, 12.0, -8.0, -1.0, 12.0, 12.0, -6.0, 7.0, 7.0, 7.0, 7.0, 8.0, -8.0, 8.0, -6.0, 1.0, 11.0, 9.0, -10.0, 13.0, 1.0, 11.0, -9.0, 12.0, 4.0, 8.0, -5.0, 8.0, 12.0, 0.0, 7.0, -7.0, 10.0, 5.0, 11.0, 8.0, -11.0, 7.0, -12.0, 5.0, 9.0, 13.0, 7.0, 10.0, 5.0, -7.0, -8.0, 4.0, 13.0, 6.0, -11.0, 13.0, 2.0, 11.0, -7.0, 1.0, 12.0, 9.0, 9.0, 9.0, -12.0, 9.0, -10.0, 4.0, 8.0, 13.0, 2.0, 13.0, 8.0, -8.0, -8.0, 6.0, 6.0, 11.0, 10.0, 11.0, 1.0, -7.0, -13.0, 8.0, 13.0, 7.0, -12.0, 3.0, 12.0, 12.0, -2.0, -1.0, 7.0, 11.0, 12.0, 10.0, -13.0, 6.0, 5.0, -7.0, 9.0, 8.0, -11.0, 6.0, 12.0, 8.0, -6.0, 4.0, 9.0, 8.0, 7.0, 8.0, -9.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22024368055200327, "mean_inference_ms": 1.176529826985842, "mean_action_processing_ms": 0.07201657167061469, "mean_env_wait_ms": 0.1791848693261032, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 313200, "agent_timesteps_total": 313119, "timers": {"sample_time_ms": 345.209, "sample_throughput": 15642.687, "learn_time_ms": 6968.61, "learn_throughput": 774.903, "update_time_ms": 11.755}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 238.19992065429688, "policy_loss": -0.02693675085902214, "vf_loss": 238.22348022460938, "vf_explained_var": 0.15450024604797363, "kl": 0.007524219341576099, "entropy": 0.5199811458587646, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 313200, "num_agent_steps_sampled": 313119, "num_steps_trained": 313200, "num_agent_steps_trained": 313119}, "done": false, "episodes_total": 6129, "training_iteration": 58, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-48-33", "timestamp": 1626860913, "time_this_iter_s": 7.493027448654175, "time_total_s": 416.75728273391724, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70215c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 416.75728273391724, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 20.840000000000003, "ram_util_percent": 14.11}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.574074074074073, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.893518518518518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 11.0, 11.0, 320.0, 4.0, -10.0, 10.0, 11.0, 9.0, -3.0, 5.0, 4.0, 6.0, 10.0, -12.0, 11.0, 7.0, 9.0, -3.0, 2.0, -16.0, 13.0, 10.0, 8.0, 12.0, 13.0, 2.0, -12.0, -3.0, 12.0, 1.0, 5.0, 6.0, 10.0, 3.0, -4.0, 11.0, 7.0, -11.0, 8.0, 13.0, 14.0, -15.0, 3.0, 5.0, 11.0, 2.0, -3.0, 7.0, 11.0, -10.0, 7.0, 14.0, 4.0, -3.0, 0.0, 14.0, 13.0, -14.0, 2.0, -5.0, -1.0, 10.0, 11.0, 7.0, 9.0, 7.0, -8.0, 13.0, -7.0, 2.0, 7.0, -5.0, 8.0, 7.0, 5.0, -10.0, 12.0, 4.0, 9.0, -3.0, 12.0, 12.0, -6.0, 14.0, -12.0, 1.0, 12.0, 8.0, -3.0, 9.0, 1.0, -6.0, 7.0, 4.0, 10.0, 3.0, 4.0, -4.0, 12.0, 11.0, 7.0, -1.0, -2.0, 6.0, 14.0, -10.0, 5.0, -6.0, 0.0, 10.0, 11.0, 13.0, 11.0, 2.0, -11.0, -2.0, 7.0, 0.0, 10.0, 4.0, 13.0, -6.0, 4.0, -5.0, 7.0, 2.0, 11.0, 12.0, 10.0, -16.0, 9.0, 13.0, 3.0, 8.0, -9.0, 12.0, -7.0, 3.0, 7.0, 13.0, 9.0, -18.0, 11.0, 13.0, 8.0, 6.0, -12.0, -4.0, 4.0, 11.0, 4.0, -6.0, 14.0, 0.0, 7.0, -5.0, -2.0, 12.0, 10.0, 12.0, 6.0, 8.0, -11.0, 12.0, -12.0, 9.0, 6.0, 8.0, -7.0, 8.0, 6.0, -15.0, 7.0, 11.0, 12.0, 11.0, 11.0, -14.0, 7.0, -10.0, 5.0, 10.0, 10.0, 7.0, 13.0, -8.0, 3.0, -17.0, 7.0, 13.0, 12.0, 5.0, -4.0, 5.0, 9.0, -2.0, 8.0, 2.0, 7.0, 9.0, -5.0, 5.0, 6.0, -4.0, -3.0, 10.0, 12.0, 13.0, 13.0, -2.0, -9.0, 321.0, 11.0, 11.0, 12.0, -7.0, 8.0, 12.0, 2.0, -2.0, 12.0, 1.0, 4.0, 9.0, 13.0, 1.0, -8.0, -1.0, 5.0, 10.0, 1.0, 6.0, -9.0, 12.0, 6.0, -8.0, 10.0, 5.0, 8.0, 13.0, -4.0, 6.0, 0.0, 6.0, 12.0, -13.0, 10.0, 13.0, 0.0, 4.0, -2.0, -6.0, 0.0, 11.0, 10.0, 8.0, 7.0, 6.0, -6.0, 13.0, 12.0, -10.0, 0.0, 12.0, 14.0, 1.0, -12.0, 13.0, 6.0, -10.0, 6.0, 12.0, 10.0, -8.0, 1.0, 320.0, 14.0, 9.0, 11.0, 11.0, 13.0, 320.0, 11.0, 12.0, 12.0, -3.0, -6.0, 13.0, 13.0, -20.0, 9.0, 2.0, -7.0, 11.0, 9.0, 14.0, 13.0, 0.0, -12.0, -12.0, 4.0, 11.0, 12.0, 7.0, 10.0, -4.0, 2.0, 12.0, -7.0, 3.0, 7.0, -5.0, 13.0, 6.0, 1.0, -14.0, 10.0, 7.0, 12.0, -12.0, 13.0, 6.0, 8.0, -18.0, 14.0, 9.0, 10.0, 12.0, 9.0, 6.0, -12.0, -3.0, 7.0, 0.0, 11.0, 12.0, 11.0, -4.0, -4.0, -4.0, 3.0, 10.0, 6.0, 12.0, 11.0, 0.0, -8.0, -5.0, 12.0, -1.0, 9.0, 4.0, -4.0, 6.0, 9.0, 12.0, 8.0, -8.0, 3.0, 12.0, -13.0, 11.0, 5.0, 3.0, 11.0, 3.0, -2.0, 12.0, 12.0, -12.0, 3.0, 12.0, 11.0, -5.0, -3.0, 7.0, 13.0, -14.0, 9.0, -8.0, -2.0, 12.0, 13.0, 12.0, 9.0, 10.0, -16.0, -15.0, 12.0, 6.0, 12.0, 8.0, -1.0, 3.0, 5.0, -13.0, 4.0, 12.0, 12.0, 12.0, 10.0, -13.0, 6.0, 13.0, 13.0, 8.0, -19.0, 7.0, 14.0, -6.0, 0.0, 12.0, 9.0, -2.0, -4.0, 7.0, 6.0, 5.0, -3.0, 11.0, 8.0, 10.0, -14.0, 12.0, 6.0, -14.0, 11.0, -6.0, 9.0, 3.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2203021881738814, "mean_inference_ms": 1.1764299269164045, "mean_action_processing_ms": 0.07202703117040622, "mean_env_wait_ms": 0.17919277598375863, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 318600, "agent_timesteps_total": 318519, "timers": {"sample_time_ms": 345.802, "sample_throughput": 15615.875, "learn_time_ms": 6981.948, "learn_throughput": 773.423, "update_time_ms": 12.027}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 768.9402465820312, "policy_loss": -0.02561534196138382, "vf_loss": 768.96240234375, "vf_explained_var": 0.04618127644062042, "kl": 0.007718836888670921, "entropy": 0.5520625114440918, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 318600, "num_agent_steps_sampled": 318519, "num_steps_trained": 318600, "num_agent_steps_trained": 318519}, "done": false, "episodes_total": 6237, "training_iteration": 59, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-48-41", "timestamp": 1626860921, "time_this_iter_s": 7.479490518569946, "time_total_s": 424.2367732524872, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70215158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 424.2367732524872, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 21.345454545454544, "ram_util_percent": 14.109090909090908}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.40740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 6.101851851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 14.0, 5.0, 9.0, 8.0, 9.0, -2.0, 0.0, -7.0, 6.0, 8.0, 8.0, 8.0, -4.0, 9.0, 2.0, 8.0, 13.0, 4.0, -10.0, 6.0, 9.0, -12.0, 12.0, 5.0, 13.0, 6.0, -9.0, 12.0, -6.0, 10.0, -1.0, -13.0, 8.0, 7.0, 13.0, 3.0, 13.0, 0.0, -1.0, 14.0, 13.0, -19.0, 7.0, -5.0, 14.0, 4.0, 2.0, 9.0, 12.0, 5.0, -11.0, 12.0, 6.0, -10.0, 7.0, 11.0, 12.0, -17.0, 9.0, -4.0, 6.0, 1.0, 12.0, 3.0, 11.0, 6.0, -5.0, 12.0, 11.0, -7.0, -1.0, 9.0, 9.0, -12.0, 9.0, -2.0, 5.0, 6.0, 6.0, -18.0, 11.0, 9.0, 13.0, 7.0, 1.0, 8.0, -1.0, 2.0, 12.0, -7.0, 8.0, -11.0, 14.0, 5.0, 7.0, -2.0, 8.0, 6.0, 3.0, 4.0, 13.0, 3.0, -5.0, 11.0, 6.0, -7.0, 5.0, -1.0, 0.0, 10.0, 6.0, 7.0, 10.0, 1.0, -3.0, 8.0, 8.0, -6.0, 5.0, 6.0, 12.0, 4.0, -7.0, 12.0, -12.0, 4.0, 11.0, -12.0, 12.0, 7.0, 8.0, 11.0, 8.0, -11.0, 7.0, 11.0, 12.0, -15.0, 7.0, -5.0, 5.0, 11.0, 4.0, -16.0, 12.0, 6.0, 13.0, 7.0, 11.0, -9.0, 6.0, -7.0, 12.0, 9.0, 1.0, 12.0, -8.0, 11.0, 0.0, -9.0, 7.0, 9.0, 8.0, 12.0, 10.0, 1.0, -8.0, 5.0, 8.0, -4.0, 6.0, -1.0, 3.0, 10.0, 3.0, 11.0, 4.0, 3.0, -3.0, 8.0, 6.0, 7.0, -6.0, 8.0, 14.0, 4.0, -11.0, 5.0, -3.0, 7.0, 6.0, -16.0, 14.0, 5.0, 12.0, 10.0, 6.0, -13.0, 12.0, 9.0, 9.0, -11.0, 8.0, -7.0, 7.0, 3.0, 12.0, -2.0, 12.0, 7.0, -2.0, 7.0, 12.0, -2.0, -2.0, -14.0, 13.0, 8.0, 8.0, 5.0, -7.0, 6.0, 11.0, 319.0, 12.0, 10.0, 13.0, 7.0, 8.0, 7.0, -7.0, 5.0, 1.0, -4.0, 13.0, -9.0, 8.0, 7.0, 9.0, -9.0, 5.0, 12.0, 7.0, 6.0, 12.0, 0.0, -3.0, 9.0, 13.0, 4.0, -11.0, 7.0, -2.0, 4.0, 6.0, -8.0, 8.0, 4.0, 11.0, 12.0, 5.0, 3.0, -5.0, 9.0, 11.0, -6.0, 1.0, -4.0, 11.0, 10.0, -2.0, -4.0, 12.0, 12.0, -5.0, 8.0, 7.0, -5.0, 5.0, 10.0, 10.0, -11.0, 6.0, -2.0, 2.0, 9.0, 6.0, 0.0, 11.0, 5.0, -1.0, 12.0, 3.0, -3.0, 3.0, 0.0, 13.0, -3.0, 5.0, -8.0, 3.0, 8.0, 12.0, -9.0, 11.0, 5.0, 8.0, 11.0, 9.0, -17.0, 12.0, 5.0, 12.0, -10.0, 8.0, 9.0, -9.0, 3.0, 12.0, -15.0, 14.0, 9.0, 7.0, 11.0, 3.0, -11.0, 12.0, 7.0, 11.0, -11.0, 8.0, 3.0, -6.0, 12.0, 6.0, 0.0, 6.0, 11.0, -2.0, 5.0, 7.0, 9.0, -6.0, 9.0, 9.0, -9.0, 6.0, -9.0, 10.0, 11.0, 3.0, -14.0, 8.0, 8.0, 13.0, 7.0, 8.0, -7.0, 7.0, 13.0, 13.0, 317.0, 11.0, -9.0, 7.0, 4.0, 13.0, 12.0, 8.0, 2.0, -7.0, 7.0, 11.0, -11.0, 8.0, 3.0, 10.0, 5.0, -3.0, 12.0, -6.0, 8.0, 1.0, -11.0, 7.0, 11.0, 8.0, 8.0, 13.0, -4.0, -2.0, 7.0, 13.0, -12.0, 7.0, -1.0, 0.0, 11.0, 5.0, -8.0, 10.0, 7.0, 6.0, 11.0, 13.0, -8.0, -1.0, 7.0, -3.0, 5.0, 6.0, 12.0, -5.0, 9.0, -1.0, -5.0, 12.0, 9.0, -1.0, 11.0, 13.0, 316.0, 13.0, 8.0, 12.0, -17.0, 12.0, 7.0, -11.0, 7.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2203180023341131, "mean_inference_ms": 1.1764723150608736, "mean_action_processing_ms": 0.07199956923488225, "mean_env_wait_ms": 0.17915599895294662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 324000, "agent_timesteps_total": 323919, "timers": {"sample_time_ms": 346.196, "sample_throughput": 15598.089, "learn_time_ms": 7016.929, "learn_throughput": 769.567, "update_time_ms": 12.206}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 575.2510986328125, "policy_loss": -0.024341298267245293, "vf_loss": 575.272216796875, "vf_explained_var": 0.05791821703314781, "kl": 0.007207173388451338, "entropy": 0.532475471496582, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 324000, "num_agent_steps_sampled": 323919, "num_steps_trained": 324000, "num_agent_steps_trained": 323919}, "done": false, "episodes_total": 6345, "training_iteration": 60, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-48-48", "timestamp": 1626860928, "time_this_iter_s": 7.58599853515625, "time_total_s": 431.82277178764343, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70215840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 431.82277178764343, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 20.90909090909091, "ram_util_percent": 14.1}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 40.083333333333336, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 10.020833333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 12.0, 318.0, 12.0, 4.0, 13.0, 5.0, -7.0, 6.0, 14.0, -8.0, 3.0, 14.0, 13.0, -10.0, -2.0, 12.0, 12.0, 317.0, 12.0, -5.0, 13.0, 11.0, -4.0, 3.0, 7.0, -1.0, 6.0, 10.0, 8.0, 11.0, -14.0, 13.0, -1.0, -5.0, 8.0, -9.0, 14.0, 10.0, 0.0, 10.0, 8.0, -9.0, 6.0, 10.0, 6.0, -8.0, 7.0, 10.0, -1.0, -6.0, 12.0, 3.0, 13.0, 9.0, -10.0, -8.0, 14.0, 11.0, -2.0, 10.0, 4.0, -3.0, 4.0, 12.0, -1.0, -1.0, 5.0, 4.0, 6.0, 13.0, -8.0, 0.0, 13.0, -6.0, 8.0, 13.0, 10.0, -11.0, 3.0, 13.0, -1.0, -9.0, 12.0, -4.0, 11.0, -3.0, 11.0, -16.0, 9.0, 10.0, 12.0, -6.0, 11.0, -1.0, 11.0, 10.0, 10.0, -17.0, 12.0, 3.0, 12.0, 13.0, -13.0, -7.0, 14.0, 11.0, -3.0, 4.0, -11.0, 10.0, 12.0, 11.0, 12.0, 0.0, -8.0, -13.0, 11.0, 10.0, 7.0, 4.0, 10.0, -10.0, 11.0, 14.0, 11.0, -15.0, 5.0, 13.0, 12.0, 315.0, 12.0, 3.0, 11.0, -6.0, 7.0, 1.0, 10.0, -8.0, 12.0, 14.0, 5.0, 8.0, -12.0, 10.0, -1.0, -6.0, 12.0, 10.0, 10.0, 10.0, -15.0, -8.0, 14.0, 10.0, -1.0, 11.0, 11.0, 3.0, -10.0, 13.0, 10.0, -19.0, 11.0, 5.0, 11.0, -2.0, 1.0, 13.0, 8.0, -14.0, 8.0, 9.0, 14.0, 1.0, -9.0, 13.0, -1.0, -9.0, 12.0, 9.0, 14.0, 5.0, -13.0, -1.0, 8.0, -4.0, 12.0, 14.0, 9.0, -9.0, 1.0, 13.0, 12.0, 317.0, 12.0, -11.0, 13.0, 12.0, 1.0, 3.0, 7.0, -6.0, 11.0, 9.0, 12.0, 5.0, -11.0, 12.0, -3.0, -6.0, 12.0, -16.0, 12.0, 12.0, 7.0, 11.0, 3.0, -10.0, 11.0, 14.0, 2.0, -5.0, 4.0, 11.0, 13.0, -7.0, -2.0, -5.0, 14.0, 9.0, -3.0, 13.0, 11.0, -14.0, 5.0, 13.0, 12.0, -1.0, -9.0, -4.0, 13.0, -7.0, 13.0, 11.0, 12.0, 12.0, -20.0, -5.0, 13.0, -5.0, 12.0, -4.0, 12.0, 6.0, 1.0, 12.0, 12.0, -19.0, 10.0, 5.0, 13.0, -10.0, 7.0, 321.0, 13.0, 11.0, 11.0, 7.0, 12.0, 4.0, -8.0, 10.0, 0.0, -5.0, 10.0, -6.0, 12.0, 12.0, -3.0, 2.0, 10.0, -9.0, 12.0, 13.0, 12.0, -17.0, 7.0, 11.0, -2.0, -4.0, 10.0, 0.0, 14.0, -2.0, 3.0, -8.0, 13.0, 11.0, -1.0, 11.0, 7.0, 5.0, -8.0, 13.0, -2.0, -7.0, 11.0, -5.0, 13.0, -1.0, 8.0, -8.0, 8.0, 8.0, 7.0, 14.0, 12.0, -16.0, 5.0, 13.0, 11.0, -21.0, 12.0, 8.0, 12.0, 13.0, -18.0, 317.0, 14.0, 11.0, 11.0, 7.0, 12.0, 7.0, -11.0, 12.0, 12.0, -7.0, -2.0, 10.0, 12.0, -2.0, -5.0, 0.0, 6.0, 10.0, -1.0, 12.0, 11.0, -12.0, 4.0, 12.0, -2.0, -5.0, 10.0, 2.0, 13.0, 9.0, -9.0, -6.0, 13.0, -4.0, 12.0, 8.0, 11.0, 2.0, -6.0, 13.0, 13.0, 315.0, 12.0, 10.0, 12.0, -9.0, 2.0, 13.0, 9.0, -14.0, 7.0, 14.0, 11.0, -14.0, 4.0, 13.0, -1.0, -9.0, 12.0, -10.0, 14.0, 5.0, 6.0, -7.0, 14.0, -4.0, 12.0, 11.0, -8.0, 11.0, 1.0, 12.0, -1.0, -8.0, 12.0, 12.0, 13.0, 12.0, 317.0, -9.0, 13.0, -1.0, 12.0, 7.0, 13.0, -9.0, 4.0, 12.0, 12.0, -5.0, -4.0, 12.0, 13.0, 10.0, -20.0, 0.0, 9.0, -1.0, 7.0, 14.0, 6.0, -13.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22030362264281053, "mean_inference_ms": 1.1766013619659663, "mean_action_processing_ms": 0.07199714570044213, "mean_env_wait_ms": 0.17916037213189445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 329400, "agent_timesteps_total": 329319, "timers": {"sample_time_ms": 346.665, "sample_throughput": 15577.006, "learn_time_ms": 7057.846, "learn_throughput": 765.106, "update_time_ms": 12.156}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 1438.0826416015625, "policy_loss": -0.02900508977472782, "vf_loss": 1438.10791015625, "vf_explained_var": 0.04033995419740677, "kl": 0.008556339889764786, "entropy": 0.5809542536735535, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 329400, "num_agent_steps_sampled": 329319, "num_steps_trained": 329400, "num_agent_steps_trained": 329319}, "done": false, "episodes_total": 6453, "training_iteration": 61, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-48-56", "timestamp": 1626860936, "time_this_iter_s": 7.592986822128296, "time_total_s": 439.41575860977173, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae677b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 439.41575860977173, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 21.10909090909091, "ram_util_percent": 14.109090909090908}, "trial_id": "cf107_00000"}
{"episode_reward_max": 366.0, "episode_reward_min": 15.0, "episode_reward_mean": 33.93518518518518, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 328.0}, "policy_reward_mean": {"learned": 8.483796296296296}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, -1.0, 8.0, 4.0, 3.0, 10.0, 4.0, -2.0, 14.0, 9.0, 11.0, -19.0, 13.0, 3.0, -7.0, 6.0, 12.0, 8.0, -18.0, 13.0, 8.0, 11.0, -6.0, 2.0, -2.0, 4.0, 7.0, 6.0, 8.0, 9.0, -6.0, 4.0, 8.0, 7.0, -13.0, 13.0, 7.0, 8.0, -11.0, 11.0, 13.0, 13.0, 11.0, 317.0, 13.0, 5.0, 10.0, -13.0, 13.0, 6.0, -12.0, 8.0, -11.0, 12.0, 3.0, 11.0, 12.0, 7.0, 11.0, -15.0, 9.0, 7.0, -10.0, 9.0, 13.0, -7.0, -4.0, 13.0, -3.0, 14.0, -4.0, 8.0, 14.0, -16.0, 6.0, 11.0, 5.0, 7.0, 9.0, -6.0, 13.0, -7.0, -4.0, 13.0, -8.0, 14.0, -2.0, 11.0, 14.0, 11.0, 10.0, -20.0, 12.0, 3.0, 4.0, -4.0, 11.0, -6.0, -1.0, 11.0, 3.0, -3.0, 13.0, 2.0, 14.0, 13.0, 11.0, 328.0, 11.0, 14.0, 5.0, -15.0, 10.0, 6.0, -13.0, 12.0, 7.0, 12.0, 12.0, -16.0, 14.0, 11.0, 10.0, -20.0, 13.0, 8.0, -9.0, 3.0, 12.0, 3.0, 13.0, -13.0, 8.0, 13.0, 4.0, -10.0, 13.0, 11.0, 7.0, -16.0, 14.0, 9.0, 7.0, -15.0, 12.0, 11.0, 8.0, -16.0, 13.0, 10.0, -13.0, 5.0, 14.0, 14.0, 11.0, 314.0, 5.0, 9.0, -5.0, 6.0, -9.0, 8.0, 4.0, 12.0, 3.0, 13.0, 10.0, -11.0, 6.0, 13.0, 10.0, -14.0, 8.0, 7.0, 4.0, -4.0, 12.0, 3.0, -9.0, 9.0, 4.0, 12.0, -10.0, 9.0, 14.0, 9.0, 8.0, -16.0, 9.0, 13.0, -4.0, -3.0, 13.0, -13.0, 4.0, 11.0, 1.0, 10.0, 12.0, -8.0, 9.0, 13.0, 12.0, -19.0, 3.0, 8.0, -8.0, 12.0, 11.0, -2.0, -7.0, 13.0, 4.0, 10.0, -11.0, 12.0, 13.0, -6.0, 9.0, -1.0, 6.0, 10.0, 6.0, -7.0, 12.0, 5.0, 12.0, -14.0, 8.0, 10.0, -13.0, 10.0, 13.0, 13.0, 10.0, 317.0, 12.0, 4.0, -6.0, 5.0, 13.0, 7.0, -16.0, 11.0, 13.0, 9.0, -10.0, 3.0, 14.0, -7.0, 11.0, -3.0, 13.0, 4.0, -6.0, 4.0, 13.0, -2.0, -8.0, 12.0, 9.0, 12.0, 11.0, -17.0, -5.0, 12.0, 10.0, -2.0, 13.0, 4.0, 3.0, -5.0, 11.0, -8.0, 7.0, 5.0, 4.0, 13.0, -11.0, 9.0, 14.0, 11.0, 6.0, -16.0, 7.0, 9.0, 7.0, -8.0, 11.0, 7.0, 12.0, -15.0, -12.0, 10.0, 7.0, 10.0, 11.0, 6.0, 7.0, -9.0, 5.0, 8.0, 11.0, -9.0, 4.0, 6.0, 10.0, -5.0, -1.0, 12.0, -6.0, 10.0, -9.0, 13.0, 8.0, 3.0, 9.0, 8.0, 7.0, -9.0, 11.0, 12.0, 1.0, -9.0, 8.0, 10.0, -9.0, 6.0, 8.0, 11.0, 12.0, -16.0, 2.0, 9.0, 8.0, -4.0, 13.0, 6.0, -16.0, 12.0, 4.0, 12.0, 3.0, -4.0, 14.0, 14.0, 11.0, 316.0, 14.0, 14.0, -19.0, 6.0, 12.0, 11.0, -16.0, 8.0, 316.0, 14.0, 12.0, 12.0, 14.0, 6.0, 11.0, -16.0, 12.0, 13.0, -16.0, 6.0, 9.0, -6.0, 6.0, 6.0, 0.0, 10.0, -5.0, 10.0, 14.0, -8.0, 10.0, -1.0, -4.0, 1.0, 7.0, 11.0, -5.0, 4.0, 5.0, 11.0, -20.0, 14.0, 9.0, 12.0, 14.0, 9.0, 10.0, -18.0, 13.0, 9.0, -17.0, 10.0, 11.0, -7.0, 8.0, 3.0, -18.0, 12.0, 12.0, 9.0, 13.0, 10.0, 11.0, -19.0, 6.0, 9.0, 11.0, -11.0, 11.0, 2.0, 13.0, -11.0, -18.0, 14.0, 11.0, 8.0, -2.0, 13.0, 6.0, -2.0, 11.0, 6.0, 5.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22022996381171597, "mean_inference_ms": 1.1765866588823386, "mean_action_processing_ms": 0.07199627004033476, "mean_env_wait_ms": 0.17915865637320014, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 334800, "agent_timesteps_total": 334719, "timers": {"sample_time_ms": 346.954, "sample_throughput": 15564.04, "learn_time_ms": 7096.144, "learn_throughput": 760.977, "update_time_ms": 12.066}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 1265.89501953125, "policy_loss": -0.03745727986097336, "vf_loss": 1265.9290771484375, "vf_explained_var": 0.058869704604148865, "kl": 0.007997481152415276, "entropy": 0.5306447148323059, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 334800, "num_agent_steps_sampled": 334719, "num_steps_trained": 334800, "num_agent_steps_trained": 334719}, "done": false, "episodes_total": 6561, "training_iteration": 62, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-49-03", "timestamp": 1626860943, "time_this_iter_s": 7.532824993133545, "time_total_s": 446.9485836029053, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae676a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 446.9485836029053, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 22.009090909090904, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -3.0, 10.0, -6.0, 14.0, 5.0, 5.0, -9.0, -11.0, 4.0, 10.0, 12.0, 9.0, 8.0, -10.0, 8.0, 13.0, -17.0, 7.0, 12.0, -1.0, -4.0, 11.0, 9.0, -6.0, 1.0, 12.0, 8.0, 14.0, 6.0, 2.0, -7.0, 14.0, -9.0, 2.0, 8.0, -3.0, 13.0, -5.0, 10.0, -7.0, 8.0, 6.0, 8.0, 9.0, 6.0, -11.0, 11.0, 10.0, 5.0, -9.0, 9.0, -19.0, 10.0, 13.0, 11.0, -12.0, 13.0, 11.0, 3.0, 12.0, 10.0, -13.0, 6.0, 12.0, -7.0, -2.0, 12.0, 2.0, 8.0, -4.0, 9.0, -10.0, 9.0, 11.0, 5.0, 11.0, -18.0, 9.0, 13.0, 14.0, -16.0, 11.0, 6.0, 14.0, 12.0, 9.0, -20.0, -5.0, 13.0, 6.0, 1.0, -7.0, 9.0, 2.0, 11.0, 13.0, -14.0, 6.0, 10.0, -4.0, 10.0, -1.0, 10.0, 6.0, -6.0, 10.0, 5.0, 9.0, 9.0, -13.0, 10.0, 14.0, -2.0, -4.0, 7.0, -19.0, 13.0, 11.0, 10.0, 13.0, 6.0, 11.0, -15.0, 8.0, 8.0, -12.0, 11.0, 12.0, -3.0, -3.0, 9.0, -2.0, 12.0, 7.0, -2.0, 8.0, 13.0, -2.0, -4.0, 12.0, 4.0, 7.0, -8.0, 13.0, 7.0, -7.0, 2.0, 1.0, 12.0, 11.0, -9.0, 13.0, 13.0, 6.0, -17.0, 8.0, 9.0, 1.0, -3.0, 13.0, 2.0, 6.0, -6.0, 0.0, 11.0, 9.0, -5.0, -12.0, 6.0, 11.0, 10.0, 14.0, 8.0, 0.0, -7.0, 8.0, -10.0, 7.0, 10.0, 1.0, 12.0, 7.0, -5.0, -9.0, 9.0, 10.0, 5.0, 9.0, 9.0, 5.0, -8.0, 14.0, -7.0, -2.0, 10.0, 7.0, 6.0, 8.0, -6.0, -5.0, 2.0, 10.0, 8.0, -5.0, 8.0, 2.0, 10.0, 9.0, 10.0, -3.0, -1.0, 0.0, 9.0, 11.0, -5.0, 7.0, 2.0, 10.0, -4.0, 13.0, 12.0, -10.0, 0.0, 13.0, -12.0, 5.0, 9.0, 8.0, 9.0, 9.0, -11.0, 8.0, 3.0, 11.0, -7.0, 13.0, 10.0, -12.0, 4.0, 14.0, 9.0, 2.0, -10.0, -19.0, 11.0, 11.0, 12.0, -7.0, 7.0, 6.0, 9.0, 12.0, 8.0, -7.0, 2.0, 13.0, -12.0, 7.0, 7.0, 0.0, 13.0, 11.0, -9.0, -6.0, 7.0, 12.0, 2.0, 12.0, 8.0, -14.0, 9.0, 14.0, -15.0, 10.0, 6.0, 14.0, 10.0, 13.0, -22.0, -10.0, 10.0, 11.0, 4.0, 14.0, 11.0, 0.0, -10.0, 14.0, -20.0, 10.0, 11.0, 1.0, 4.0, 13.0, -3.0, 12.0, 8.0, 6.0, -11.0, 12.0, -14.0, 5.0, 12.0, 13.0, -21.0, 12.0, 11.0, -16.0, 13.0, 8.0, 10.0, 13.0, -13.0, 11.0, 4.0, 4.0, 12.0, -7.0, 6.0, 13.0, 4.0, 0.0, -2.0, -3.0, 10.0, 13.0, -5.0, -9.0, 8.0, 10.0, 6.0, 13.0, 10.0, -12.0, 4.0, 9.0, -18.0, 11.0, 13.0, -4.0, 11.0, 9.0, -1.0, 10.0, 4.0, 12.0, -11.0, 12.0, 10.0, -11.0, 4.0, 12.0, -15.0, 7.0, 11.0, 0.0, 11.0, 12.0, -8.0, 8.0, -13.0, 11.0, 9.0, 0.0, 5.0, 2.0, 8.0, 13.0, -1.0, 10.0, -7.0, -7.0, 10.0, 13.0, -1.0, 8.0, -1.0, 6.0, 2.0, 14.0, 8.0, -14.0, 7.0, 13.0, -4.0, 1.0, 5.0, -17.0, 12.0, 11.0, 9.0, -12.0, 14.0, 9.0, 4.0, -4.0, 7.0, 6.0, 6.0, 13.0, -10.0, 2.0, 10.0, -11.0, 10.0, 6.0, 10.0, 7.0, -7.0, 10.0, 5.0, -1.0, 9.0, -2.0, 9.0, 13.0, -7.0, -2.0, 11.0, -21.0, 12.0, 13.0, 11.0, -7.0, 7.0, 11.0, 4.0, -5.0, 8.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21999198344935672, "mean_inference_ms": 1.1763261259666427, "mean_action_processing_ms": 0.07198580700416762, "mean_env_wait_ms": 0.17914777723889014, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 340200, "agent_timesteps_total": 340146, "timers": {"sample_time_ms": 346.914, "sample_throughput": 15565.839, "learn_time_ms": 7103.248, "learn_throughput": 760.216, "update_time_ms": 12.112}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 34.0910530090332, "policy_loss": -0.09529315680265427, "vf_loss": 34.178306579589844, "vf_explained_var": 0.15033909678459167, "kl": 0.017865538597106934, "entropy": 0.5804560780525208, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 340200, "num_agent_steps_sampled": 340146, "num_steps_trained": 340200, "num_agent_steps_trained": 340146}, "done": false, "episodes_total": 6669, "training_iteration": 63, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-49-11", "timestamp": 1626860951, "time_this_iter_s": 7.652505397796631, "time_total_s": 454.6010890007019, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 454.6010890007019, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 20.330000000000002, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 6.0, 10.0, -6.0, -3.0, 13.0, -8.0, 13.0, -1.0, 7.0, 9.0, 0.0, 10.0, -2.0, 10.0, -3.0, -5.0, 7.0, 8.0, 5.0, 10.0, 11.0, -17.0, 11.0, 13.0, 4.0, 11.0, -13.0, 0.0, 6.0, 7.0, 2.0, -5.0, 10.0, -2.0, 12.0, 9.0, 6.0, 9.0, -9.0, 3.0, 13.0, 7.0, -8.0, 1.0, 12.0, -10.0, 12.0, 10.0, -12.0, 13.0, 4.0, 13.0, 7.0, -13.0, 8.0, -4.0, 12.0, 10.0, -3.0, 7.0, -10.0, 7.0, 11.0, 13.0, 8.0, -7.0, 1.0, -1.0, 11.0, 8.0, -3.0, 8.0, -8.0, 10.0, 5.0, 6.0, -8.0, 11.0, 6.0, 2.0, 6.0, 9.0, -2.0, -12.0, 9.0, 11.0, 7.0, -6.0, 13.0, 9.0, -1.0, 13.0, 11.0, -3.0, -6.0, 10.0, -7.0, 7.0, 5.0, 14.0, -6.0, -2.0, 9.0, 11.0, 12.0, 11.0, -19.0, 5.0, 6.0, 8.0, -4.0, 7.0, -8.0, 9.0, 7.0, 10.0, 7.0, -8.0, 6.0, 3.0, 2.0, 13.0, -3.0, -6.0, 12.0, 8.0, 1.0, -5.0, 12.0, 11.0, -3.0, -1.0, 12.0, 7.0, -3.0, 14.0, 6.0, -13.0, 8.0, 12.0, 0.0, 8.0, -5.0, 4.0, -6.0, 11.0, 6.0, 1.0, -1.0, 9.0, 6.0, -12.0, 12.0, 12.0, 3.0, 13.0, -16.0, 8.0, 10.0, 4.0, 11.0, -13.0, 13.0, 9.0, 12.0, 11.0, -17.0, 9.0, 0.0, 9.0, -3.0, -5.0, 6.0, 7.0, 7.0, 6.0, 1.0, -4.0, 12.0, -1.0, 3.0, 3.0, 10.0, 4.0, -6.0, 6.0, 11.0, 12.0, 5.0, -7.0, 5.0, 12.0, -18.0, 12.0, 9.0, 2.0, -4.0, 7.0, 10.0, 12.0, 12.0, 10.0, -19.0, 13.0, 4.0, 8.0, -10.0, 14.0, -7.0, 3.0, 5.0, 13.0, 8.0, 1.0, -7.0, 4.0, -6.0, 12.0, 5.0, 0.0, 7.0, 3.0, 5.0, 14.0, 11.0, -6.0, -4.0, 10.0, -19.0, 13.0, 11.0, -12.0, 12.0, 8.0, 7.0, 4.0, 12.0, -2.0, 1.0, -5.0, 3.0, 13.0, 4.0, -13.0, 7.0, 8.0, 13.0, 12.0, -2.0, 12.0, -7.0, 12.0, 10.0, 0.0, -7.0, -1.0, 9.0, 2.0, 5.0, -2.0, 7.0, 5.0, 5.0, -12.0, 4.0, 13.0, 10.0, 13.0, 7.0, -13.0, 8.0, 12.0, 3.0, -8.0, 8.0, 13.0, -12.0, 11.0, 3.0, 2.0, 6.0, 9.0, -2.0, 12.0, 12.0, -7.0, -2.0, 13.0, 9.0, 11.0, -18.0, 0.0, 7.0, 0.0, 8.0, 12.0, 4.0, 8.0, -9.0, -9.0, 11.0, 7.0, 6.0, 9.0, -1.0, -1.0, 8.0, 1.0, 10.0, -8.0, 12.0, 10.0, -1.0, 8.0, -2.0, 14.0, 7.0, 0.0, -6.0, 12.0, 6.0, -8.0, 5.0, 0.0, 11.0, 12.0, -8.0, 8.0, -13.0, 11.0, 9.0, 0.0, 5.0, 2.0, 8.0, 13.0, -1.0, 10.0, -7.0, -7.0, 10.0, 13.0, -1.0, 8.0, -1.0, 6.0, 2.0, 14.0, 8.0, -14.0, 7.0, 13.0, -4.0, 1.0, 5.0, -17.0, 12.0, 11.0, 9.0, -12.0, 14.0, 9.0, 4.0, -4.0, 7.0, 6.0, 6.0, 13.0, -10.0, 2.0, 10.0, -11.0, 10.0, 6.0, 10.0, 7.0, -7.0, 10.0, 5.0, -1.0, 9.0, -2.0, 9.0, 13.0, -7.0, -2.0, 11.0, -21.0, 12.0, 13.0, 11.0, -7.0, 7.0, 11.0, 4.0, -5.0, 8.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.219793520557326, "mean_inference_ms": 1.175070643938755, "mean_action_processing_ms": 0.07195756171229746, "mean_env_wait_ms": 0.1790054253765754, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 345600, "agent_timesteps_total": 345519, "timers": {"sample_time_ms": 346.821, "sample_throughput": 15570.007, "learn_time_ms": 7088.966, "learn_throughput": 761.747, "update_time_ms": 12.247}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 28.84476089477539, "policy_loss": -0.08223690092563629, "vf_loss": 28.920066833496094, "vf_explained_var": 0.19295567274093628, "kl": 0.015399085357785225, "entropy": 0.5090218782424927, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 345600, "num_agent_steps_sampled": 345519, "num_steps_trained": 345600, "num_agent_steps_trained": 345519}, "done": false, "episodes_total": 6750, "training_iteration": 64, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-49-19", "timestamp": 1626860959, "time_this_iter_s": 7.4522483348846436, "time_total_s": 462.05333733558655, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70223c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 462.05333733558655, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 20.94545454545455, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 11.0, 10.0, -1.0, 12.0, 5.0, -14.0, 12.0, 6.0, 14.0, 9.0, -14.0, 8.0, -14.0, 11.0, 10.0, -11.0, 12.0, 2.0, 12.0, -3.0, 1.0, 4.0, 13.0, 8.0, 4.0, 10.0, -7.0, -6.0, 7.0, 12.0, 2.0, -6.0, 13.0, 11.0, -3.0, 9.0, 13.0, -17.0, 10.0, 4.0, 9.0, 11.0, -9.0, 0.0, -7.0, 11.0, 11.0, 6.0, 11.0, -15.0, 13.0, 12.0, 3.0, -13.0, 13.0, 6.0, 14.0, -3.0, -2.0, 6.0, -2.0, -1.0, 12.0, 7.0, -2.0, -2.0, 12.0, 8.0, 8.0, -10.0, 9.0, -6.0, 14.0, 10.0, -3.0, 8.0, 13.0, 12.0, -18.0, 3.0, 12.0, -11.0, 11.0, 3.0, 7.0, 11.0, -6.0, 11.0, 4.0, 5.0, -5.0, 7.0, -1.0, 10.0, -1.0, -12.0, 13.0, 12.0, 2.0, 0.0, 6.0, 11.0, -2.0, 10.0, 9.0, 9.0, -13.0, 7.0, -1.0, 12.0, -3.0, 1.0, 10.0, -8.0, 12.0, 9.0, 7.0, -13.0, 12.0, 6.0, 14.0, -4.0, -1.0, -8.0, 12.0, 3.0, 8.0, 1.0, -1.0, 11.0, 4.0, -3.0, 5.0, 3.0, 10.0, 12.0, 3.0, -5.0, 5.0, -3.0, 8.0, 12.0, -2.0, -7.0, 12.0, -3.0, 13.0, -7.0, 6.0, 6.0, 10.0, 11.0, 6.0, 8.0, -10.0, -13.0, 8.0, 10.0, 10.0, 6.0, 12.0, -16.0, 13.0, 11.0, 4.0, -12.0, 12.0, 12.0, 9.0, 9.0, -15.0, 10.0, 12.0, -8.0, 1.0, 7.0, -1.0, -3.0, 12.0, 0.0, 12.0, 9.0, -6.0, 8.0, 12.0, -6.0, 1.0, 5.0, 12.0, -14.0, 12.0, 3.0, 13.0, -13.0, 12.0, -6.0, 5.0, 10.0, 6.0, 7.0, -5.0, 9.0, 4.0, -8.0, 11.0, 10.0, 2.0, 8.0, 11.0, 6.0, -10.0, 11.0, 4.0, 10.0, -10.0, 8.0, -5.0, 5.0, 7.0, 8.0, -6.0, 12.0, 1.0, 7.0, -1.0, -4.0, 13.0, -3.0, 9.0, 4.0, 5.0, 8.0, -7.0, 5.0, 9.0, -4.0, 6.0, 12.0, 1.0, 0.0, 13.0, -9.0, 11.0, 12.0, -1.0, 12.0, -8.0, 7.0, 10.0, -3.0, 1.0, -8.0, 9.0, 12.0, 2.0, -10.0, 10.0, 3.0, 12.0, -4.0, 1.0, 7.0, 11.0, -7.0, 13.0, 9.0, 0.0, -2.0, 8.0, 6.0, 3.0, -5.0, 13.0, 6.0, 1.0, -4.0, 3.0, 5.0, 11.0, 12.0, 9.0, 8.0, -14.0, 6.0, 12.0, 10.0, -13.0, 2.0, -2.0, 6.0, 9.0, -4.0, 9.0, 1.0, 9.0, 7.0, 13.0, 11.0, -16.0, -11.0, 13.0, 10.0, 3.0, -12.0, 13.0, 12.0, 2.0, -5.0, 8.0, 1.0, 11.0, 13.0, -5.0, 8.0, -1.0, -14.0, 13.0, 11.0, 5.0, 6.0, 12.0, -15.0, 12.0, -3.0, 5.0, 2.0, 11.0, 5.0, 0.0, 10.0, 0.0, 7.0, 6.0, 9.0, -7.0, -11.0, 12.0, 3.0, 11.0, -3.0, 1.0, 4.0, 13.0, -2.0, 9.0, 5.0, 3.0, 9.0, -1.0, -2.0, 9.0, 5.0, 10.0, -12.0, 12.0, 7.0, 8.0, 8.0, -8.0, 8.0, 14.0, 10.0, -17.0, -2.0, 12.0, 1.0, 4.0, -12.0, 12.0, 3.0, 12.0, -7.0, 5.0, 6.0, 11.0, 7.0, 14.0, -2.0, -4.0, -13.0, 7.0, 12.0, 9.0, 2.0, 12.0, 11.0, -10.0, 10.0, 2.0, -10.0, 13.0, 5.0, 13.0, -5.0, 2.0, -4.0, 1.0, 12.0, 6.0, -7.0, 12.0, 12.0, -2.0, -8.0, 7.0, 4.0, 12.0, 3.0, 12.0, 10.0, -10.0, -5.0, 10.0, 12.0, -2.0, 2.0, 11.0, -10.0, 12.0, 14.0, 1.0, 10.0, -10.0, 11.0, 9.0, -8.0, 3.0, 7.0, -1.0, 11.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22008556324160494, "mean_inference_ms": 1.1758977755766107, "mean_action_processing_ms": 0.07194419096894082, "mean_env_wait_ms": 0.1791148796510038, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 351000, "agent_timesteps_total": 350919, "timers": {"sample_time_ms": 347.735, "sample_throughput": 15529.063, "learn_time_ms": 7095.373, "learn_throughput": 761.059, "update_time_ms": 12.293}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 28.349685668945312, "policy_loss": -0.0928075760602951, "vf_loss": 28.434743881225586, "vf_explained_var": 0.1908932775259018, "kl": 0.017229847609996796, "entropy": 0.5460919737815857, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 351000, "num_agent_steps_sampled": 350919, "num_steps_trained": 351000, "num_agent_steps_trained": 350919}, "done": false, "episodes_total": 6858, "training_iteration": 65, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-49-26", "timestamp": 1626860966, "time_this_iter_s": 7.624040365219116, "time_total_s": 469.67737770080566, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70223268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 469.67737770080566, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 20.963636363636365, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, 13.0, -13.0, 12.0, 14.0, -13.0, 4.0, 10.0, -8.0, 11.0, 5.0, 7.0, 9.0, 6.0, 11.0, -11.0, 7.0, 13.0, -1.0, -4.0, 9.0, -9.0, 5.0, 10.0, -4.0, 12.0, 1.0, 6.0, 10.0, 2.0, 10.0, -7.0, -9.0, 12.0, -1.0, 13.0, -3.0, 10.0, 11.0, -3.0, -6.0, 5.0, 5.0, 11.0, 5.0, 2.0, 12.0, -4.0, 7.0, 10.0, -13.0, 11.0, 14.0, 6.0, -13.0, 8.0, -1.0, 11.0, -6.0, 11.0, 12.0, -14.0, 7.0, 10.0, 4.0, 12.0, -14.0, 13.0, 14.0, 5.0, -15.0, 11.0, 13.0, 8.0, -5.0, -1.0, 12.0, -5.0, 11.0, -3.0, 10.0, 7.0, 5.0, -7.0, 14.0, 12.0, -8.0, -3.0, 8.0, -6.0, 4.0, 9.0, 14.0, 6.0, 10.0, -15.0, 10.0, 3.0, 8.0, -6.0, 8.0, 6.0, -11.0, 12.0, 12.0, 9.0, -3.0, -3.0, 14.0, 13.0, 6.0, -18.0, -5.0, 5.0, 5.0, 10.0, 11.0, 6.0, 11.0, -13.0, 12.0, -1.0, 8.0, -4.0, 9.0, -6.0, 6.0, 6.0, 13.0, 7.0, -5.0, 0.0, 9.0, 8.0, -10.0, 8.0, 12.0, 10.0, -5.0, -2.0, 14.0, 4.0, 10.0, -13.0, 10.0, 13.0, -20.0, 12.0, 9.0, 11.0, 4.0, -9.0, 12.0, -1.0, -9.0, 13.0, 13.0, 3.0, -6.0, 5.0, -1.0, 13.0, -10.0, 13.0, 14.0, 2.0, -10.0, 9.0, 4.0, -6.0, 6.0, 11.0, 9.0, -11.0, 9.0, 8.0, -6.0, 9.0, 10.0, 2.0, 10.0, 10.0, -9.0, 4.0, 2.0, 10.0, -2.0, 5.0, -11.0, 6.0, 10.0, 10.0, -14.0, 10.0, 12.0, 7.0, 9.0, 13.0, -15.0, 8.0, 12.0, -4.0, -4.0, 11.0, 14.0, 1.0, 7.0, -7.0, 14.0, -1.0, -4.0, 6.0, -3.0, 4.0, 10.0, 4.0, 3.0, -7.0, 12.0, 7.0, -8.0, 6.0, 6.0, 11.0, 4.0, 12.0, 4.0, -5.0, 9.0, 2.0, -6.0, 10.0, -7.0, 6.0, 6.0, 10.0, -12.0, 6.0, 11.0, 10.0, -12.0, 11.0, 6.0, 10.0, 9.0, 10.0, -14.0, 10.0, -6.0, -1.0, 12.0, 10.0, 14.0, 0.0, 9.0, -8.0, 5.0, 12.0, -14.0, 12.0, 9.0, 11.0, -16.0, 11.0, 10.0, 11.0, -2.0, -4.0, 9.0, -13.0, 10.0, 9.0, -13.0, 12.0, 4.0, 12.0, 9.0, 12.0, -17.0, 11.0, -9.0, 12.0, 2.0, 10.0, 13.0, 9.0, -7.0, 0.0, -12.0, 11.0, 6.0, 10.0, 14.0, 10.0, 12.0, -21.0, -5.0, 7.0, 3.0, 10.0, 14.0, 10.0, -4.0, -5.0, -14.0, 12.0, 4.0, 13.0, 9.0, 8.0, -14.0, 12.0, -6.0, 13.0, -3.0, 11.0, 14.0, 3.0, -12.0, 10.0, -7.0, 12.0, -3.0, 13.0, 11.0, 11.0, -18.0, 11.0, -5.0, 6.0, 5.0, 9.0, 12.0, 13.0, 6.0, -16.0, 10.0, -14.0, 6.0, 13.0, 14.0, 12.0, 6.0, -17.0, 13.0, -2.0, -7.0, 11.0, 12.0, 2.0, -7.0, 8.0, -2.0, 12.0, 2.0, 3.0, 14.0, 12.0, 8.0, -19.0, 8.0, 10.0, 0.0, -3.0, -3.0, 4.0, 10.0, 4.0, 1.0, -5.0, 9.0, 10.0, 9.0, 12.0, 10.0, -16.0, -8.0, 9.0, 2.0, 12.0, 9.0, -10.0, 8.0, 8.0, -13.0, 13.0, 2.0, 13.0, 14.0, -17.0, 12.0, 6.0, -3.0, 6.0, 9.0, 3.0, 11.0, -15.0, 11.0, 8.0, -10.0, 11.0, 1.0, 13.0, 10.0, 11.0, -5.0, -1.0, -8.0, 10.0, 2.0, 11.0, 7.0, -11.0, 11.0, 8.0, 3.0, 12.0, -13.0, 13.0, 14.0, 9.0, -18.0, 10.0, -3.0, 8.0, 2.0, 8.0, -12.0, 6.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2201357664211079, "mean_inference_ms": 1.1758186627151135, "mean_action_processing_ms": 0.07193491223683018, "mean_env_wait_ms": 0.17911430091878142, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 356400, "agent_timesteps_total": 356319, "timers": {"sample_time_ms": 348.742, "sample_throughput": 15484.232, "learn_time_ms": 7087.63, "learn_throughput": 761.891, "update_time_ms": 12.231}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 31.59619903564453, "policy_loss": -0.06640153378248215, "vf_loss": 31.655881881713867, "vf_explained_var": 0.23606033623218536, "kl": 0.0149446502327919, "entropy": 0.49478620290756226, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 356400, "num_agent_steps_sampled": 356319, "num_steps_trained": 356400, "num_agent_steps_trained": 356319}, "done": false, "episodes_total": 6966, "training_iteration": 66, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-49-34", "timestamp": 1626860974, "time_this_iter_s": 7.482572555541992, "time_total_s": 477.15995025634766, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702230d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 477.15995025634766, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 21.672727272727276, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 368.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.85185185185185, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 7.712962962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 368.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 8.0, 11.0, -9.0, -2.0, 6.0, 10.0, 1.0, -11.0, 11.0, 2.0, 13.0, 9.0, 14.0, 12.0, -20.0, -14.0, 13.0, 13.0, 3.0, -1.0, 5.0, 8.0, 3.0, 12.0, 8.0, 1.0, -6.0, 13.0, 13.0, 10.0, -21.0, 3.0, 9.0, 12.0, -9.0, -7.0, 8.0, 9.0, 5.0, 5.0, 14.0, 3.0, -7.0, 13.0, 12.0, 318.0, 12.0, 11.0, -6.0, 5.0, 5.0, -2.0, 2.0, 8.0, 7.0, 5.0, -1.0, 6.0, 5.0, -3.0, 13.0, 8.0, -3.0, 8.0, -2.0, 6.0, 3.0, -4.0, -2.0, 10.0, 11.0, 12.0, 13.0, -13.0, 3.0, 12.0, 13.0, -5.0, -5.0, 7.0, -1.0, 3.0, 6.0, -2.0, 9.0, 2.0, 6.0, -6.0, 13.0, 2.0, 6.0, 13.0, 14.0, 316.0, 12.0, 1.0, 10.0, 12.0, -8.0, -9.0, 7.0, 8.0, 9.0, -14.0, 14.0, 3.0, 12.0, -15.0, 12.0, 12.0, 6.0, 0.0, -2.0, 6.0, 11.0, -12.0, 4.0, 13.0, 10.0, -7.0, 12.0, 4.0, 6.0, 3.0, 9.0, -8.0, 11.0, 4.0, 9.0, 12.0, -10.0, -16.0, 12.0, 10.0, 9.0, 9.0, 8.0, -11.0, 9.0, -2.0, 11.0, -6.0, 12.0, -6.0, 2.0, 11.0, 8.0, -7.0, 9.0, 8.0, 5.0, 5.0, 13.0, -8.0, 5.0, 12.0, 8.0, -17.0, 12.0, 7.0, -15.0, 12.0, 11.0, -4.0, 8.0, 3.0, 8.0, 7.0, 8.0, 4.0, -4.0, 11.0, 9.0, 10.0, -15.0, 7.0, 7.0, 9.0, -8.0, 4.0, 10.0, -5.0, 6.0, 7.0, 11.0, 1.0, -4.0, -1.0, 5.0, -2.0, 13.0, 6.0, -4.0, 7.0, 6.0, -2.0, 1.0, 9.0, 7.0, -10.0, 10.0, 2.0, 13.0, -5.0, 8.0, 0.0, 12.0, -3.0, 8.0, 3.0, 7.0, -3.0, 4.0, 1.0, 13.0, 2.0, 12.0, 4.0, -3.0, -15.0, 8.0, 10.0, 12.0, 11.0, -9.0, 12.0, 1.0, 10.0, 2.0, -5.0, 8.0, 9.0, 6.0, -13.0, 13.0, 8.0, 14.0, 12.0, -19.0, 4.0, 8.0, 13.0, -10.0, -6.0, 5.0, 10.0, 6.0, -6.0, 7.0, 3.0, 11.0, 13.0, 13.0, 12.0, 317.0, -14.0, 11.0, 12.0, 6.0, -10.0, 8.0, 9.0, 8.0, 3.0, -3.0, 4.0, 11.0, 6.0, 12.0, 7.0, -10.0, 2.0, 8.0, 11.0, -6.0, 8.0, -8.0, 4.0, 11.0, 12.0, 11.0, 3.0, -11.0, -5.0, 11.0, -3.0, 12.0, 5.0, -1.0, 12.0, -1.0, -4.0, -2.0, 8.0, 13.0, 13.0, 13.0, -17.0, 6.0, 5.0, 13.0, 12.0, -15.0, -10.0, 6.0, 12.0, 7.0, -11.0, 11.0, 11.0, 4.0, 1.0, 11.0, 6.0, -3.0, -14.0, 11.0, 12.0, 6.0, -9.0, 2.0, 9.0, 13.0, 9.0, 9.0, -3.0, 0.0, 5.0, 12.0, 1.0, -3.0, 13.0, 12.0, 331.0, 12.0, 4.0, -5.0, 11.0, 5.0, -1.0, 7.0, 1.0, 8.0, -12.0, 14.0, 0.0, 13.0, -3.0, 2.0, 12.0, 4.0, 11.0, -14.0, 13.0, 5.0, -8.0, 8.0, 3.0, 12.0, -7.0, 8.0, 4.0, 10.0, -2.0, 12.0, -7.0, 12.0, 1.0, -1.0, 9.0, 6.0, -11.0, 11.0, 2.0, 13.0, 13.0, 14.0, -16.0, 4.0, 13.0, 13.0, 316.0, 12.0, 10.0, -9.0, 11.0, 3.0, -3.0, 5.0, 10.0, 3.0, 9.0, 9.0, -10.0, 7.0, 12.0, 14.0, 10.0, -21.0, 1.0, 10.0, 12.0, -8.0, -7.0, 6.0, 10.0, 6.0, 13.0, 12.0, -1.0, -9.0, 14.0, 12.0, 9.0, -20.0, 4.0, 13.0, 13.0, -15.0, -4.0, 3.0, 3.0, 13.0, -13.0, 13.0, 9.0, 6.0, -7.0, 10.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22022029778017124, "mean_inference_ms": 1.175859445874907, "mean_action_processing_ms": 0.07196480840285682, "mean_env_wait_ms": 0.17912734306580116, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 361800, "agent_timesteps_total": 361719, "timers": {"sample_time_ms": 349.632, "sample_throughput": 15444.798, "learn_time_ms": 7085.259, "learn_throughput": 762.146, "update_time_ms": 12.248}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 1003.6544189453125, "policy_loss": -0.022550256922841072, "vf_loss": 1003.674072265625, "vf_explained_var": 0.06747706234455109, "kl": 0.006815707311034203, "entropy": 0.524857759475708, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 361800, "num_agent_steps_sampled": 361719, "num_steps_trained": 361800, "num_agent_steps_trained": 361719}, "done": false, "episodes_total": 7074, "training_iteration": 67, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-49-41", "timestamp": 1626860981, "time_this_iter_s": 7.561948299407959, "time_total_s": 484.7218985557556, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 484.7218985557556, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 21.154545454545453, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.26851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 333.0}, "policy_reward_mean": {"learned": 4.56712962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, -2.0, 12.0, 7.0, -4.0, 14.0, -5.0, 10.0, 14.0, 8.0, -11.0, 4.0, 6.0, 13.0, -5.0, 1.0, 0.0, 6.0, 12.0, -3.0, 0.0, 13.0, -6.0, 8.0, 14.0, 9.0, 5.0, -13.0, 7.0, 6.0, -10.0, 12.0, 12.0, 8.0, -11.0, 6.0, 6.0, 13.0, 8.0, -12.0, 10.0, 9.0, 0.0, -4.0, -4.0, 4.0, 10.0, 5.0, -3.0, 5.0, 3.0, 10.0, 6.0, 13.0, 10.0, -14.0, 14.0, 2.0, -11.0, 10.0, 4.0, 9.0, -5.0, 7.0, 9.0, 5.0, -10.0, 11.0, 0.0, 14.0, 11.0, -10.0, 9.0, 12.0, -16.0, 10.0, 13.0, 4.0, -8.0, 6.0, -5.0, 7.0, 6.0, 7.0, 5.0, 14.0, 10.0, -14.0, 14.0, 3.0, -5.0, 4.0, 8.0, 14.0, 9.0, -16.0, 11.0, -8.0, 6.0, 6.0, 2.0, 13.0, 10.0, -10.0, 5.0, 9.0, -9.0, 10.0, 11.0, 6.0, -6.0, 4.0, -7.0, 6.0, 10.0, 6.0, 5.0, 14.0, 10.0, -14.0, 9.0, 3.0, 11.0, -8.0, 8.0, 7.0, -6.0, 6.0, -2.0, 4.0, 2.0, 11.0, 3.0, 14.0, 10.0, -12.0, 9.0, 4.0, 6.0, -4.0, 9.0, 9.0, -9.0, 6.0, 11.0, -15.0, 8.0, 11.0, 7.0, 13.0, 9.0, -14.0, 8.0, 8.0, 8.0, -9.0, 7.0, 7.0, -4.0, 5.0, 6.0, -8.0, 11.0, 6.0, 1.0, 14.0, -10.0, 10.0, 10.0, 8.0, 4.0, -7.0, 13.0, 14.0, 3.0, -15.0, 9.0, 8.0, 2.0, -4.0, 11.0, 14.0, -4.0, -6.0, 7.0, 8.0, 4.0, -4.0, 12.0, 1.0, -7.0, 9.0, -4.0, 6.0, 1.0, 12.0, 4.0, 14.0, -2.0, -1.0, 14.0, 13.0, -7.0, -5.0, 8.0, 13.0, -4.0, -2.0, 8.0, 13.0, 4.0, -10.0, -12.0, 12.0, 11.0, 4.0, 8.0, 8.0, -10.0, 9.0, 6.0, 9.0, -4.0, 4.0, -2.0, 7.0, 6.0, 4.0, -9.0, 14.0, 0.0, 10.0, 5.0, 10.0, 6.0, -6.0, 8.0, 12.0, -9.0, 4.0, 6.0, 10.0, 3.0, -4.0, -11.0, 14.0, 10.0, 2.0, 14.0, 5.0, 2.0, -6.0, 8.0, 4.0, -8.0, 11.0, 9.0, -10.0, 5.0, 11.0, 10.0, 14.0, 10.0, 333.0, 9.0, 7.0, 12.0, -13.0, 10.0, 2.0, -4.0, 7.0, 7.0, -9.0, 7.0, 10.0, 6.0, 14.0, -5.0, 0.0, 8.0, 7.0, 2.0, -2.0, 4.0, 14.0, -4.0, 1.0, -8.0, 11.0, 1.0, 11.0, 5.0, 14.0, 10.0, -14.0, 9.0, 9.0, -4.0, 1.0, -1.0, 3.0, 7.0, 6.0, -12.0, 10.0, 11.0, 6.0, 4.0, 14.0, -15.0, 12.0, 14.0, 7.0, -13.0, 7.0, 11.0, 5.0, -7.0, 6.0, -8.0, 10.0, 1.0, 12.0, -9.0, 14.0, 10.0, 0.0, 4.0, 6.0, 11.0, -6.0, 7.0, 11.0, -7.0, 4.0, 9.0, 10.0, 3.0, -7.0, 12.0, 13.0, -7.0, -3.0, 13.0, 11.0, -1.0, -8.0, 2.0, -6.0, 9.0, 10.0, -13.0, 11.0, 11.0, 6.0, 7.0, 14.0, 9.0, -15.0, 13.0, 11.0, -7.0, -2.0, 11.0, -3.0, 10.0, -3.0, 12.0, -7.0, 3.0, 7.0, -2.0, 14.0, 9.0, -6.0, 10.0, 12.0, -18.0, 11.0, 7.0, 7.0, -4.0, 5.0, 11.0, -9.0, 2.0, 11.0, 10.0, 12.0, 10.0, -17.0, 5.0, 9.0, -4.0, 5.0, 12.0, 0.0, -7.0, 10.0, 7.0, -11.0, 12.0, 7.0, 1.0, 12.0, -3.0, 5.0, 6.0, 11.0, 7.0, -9.0, 8.0, 4.0, 5.0, -2.0, 9.0, -8.0, 8.0, 6.0, 3.0, 14.0, 9.0, -11.0, 13.0, 14.0, -9.0, -3.0, 13.0, 3.0, -10.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22024420103696857, "mean_inference_ms": 1.175890419392921, "mean_action_processing_ms": 0.07196097701997571, "mean_env_wait_ms": 0.17913132844688023, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 367200, "agent_timesteps_total": 367119, "timers": {"sample_time_ms": 350.41, "sample_throughput": 15410.505, "learn_time_ms": 7093.565, "learn_throughput": 761.253, "update_time_ms": 12.42}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 242.8599853515625, "policy_loss": -0.030841294676065445, "vf_loss": 242.88661193847656, "vf_explained_var": 0.16642536222934723, "kl": 0.00944520253688097, "entropy": 0.5547008514404297, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 367200, "num_agent_steps_sampled": 367119, "num_steps_trained": 367200, "num_agent_steps_trained": 367119}, "done": false, "episodes_total": 7182, "training_iteration": 68, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-49-49", "timestamp": 1626860989, "time_this_iter_s": 7.5908002853393555, "time_total_s": 492.31269884109497, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 492.31269884109497, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 22.118181818181817, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 37.138888888888886, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 9.284722222222221}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 13.0, 13.0, -20.0, -9.0, 12.0, 7.0, 5.0, 13.0, 0.0, 7.0, -5.0, 6.0, 11.0, 6.0, -8.0, -9.0, 11.0, 13.0, 0.0, -11.0, 13.0, 11.0, 2.0, -2.0, 0.0, 5.0, 12.0, 5.0, 11.0, -12.0, 11.0, 6.0, -5.0, 10.0, 4.0, -14.0, 9.0, 7.0, 13.0, -1.0, 0.0, 5.0, 11.0, 9.0, 14.0, -6.0, -2.0, 11.0, 10.0, -11.0, 5.0, 3.0, 12.0, -12.0, 12.0, 7.0, -13.0, 10.0, 11.0, 11.0, 14.0, 318.0, 13.0, -2.0, -2.0, 13.0, 6.0, 0.0, 12.0, 11.0, -8.0, 13.0, -13.0, 3.0, 12.0, 6.0, 12.0, -6.0, 3.0, 5.0, -2.0, 13.0, -1.0, -8.0, 13.0, 12.0, -2.0, 12.0, -2.0, -8.0, 13.0, 10.0, -9.0, 1.0, 13.0, 11.0, 9.0, 10.0, -15.0, 5.0, 8.0, 7.0, -5.0, 6.0, 3.0, -4.0, 10.0, 8.0, 13.0, -11.0, 5.0, 9.0, -3.0, 13.0, -4.0, -8.0, 13.0, -2.0, 12.0, 8.0, -11.0, 7.0, 11.0, -3.0, 14.0, 7.0, -3.0, 7.0, 13.0, -10.0, 5.0, -7.0, 12.0, 8.0, 2.0, 11.0, 0.0, -6.0, 10.0, -10.0, 6.0, 8.0, 11.0, 5.0, 9.0, 13.0, -12.0, -2.0, 13.0, -8.0, 12.0, 8.0, 4.0, 9.0, -6.0, 3.0, 14.0, 0.0, -2.0, 12.0, 10.0, -18.0, 11.0, 11.0, 12.0, 12.0, 321.0, 11.0, 0.0, -7.0, 11.0, 10.0, -9.0, 10.0, 4.0, 12.0, 13.0, 11.0, 318.0, -12.0, 9.0, 12.0, 6.0, -6.0, 11.0, 5.0, 5.0, -6.0, 14.0, 2.0, 5.0, 12.0, 12.0, 7.0, -16.0, 13.0, 6.0, 13.0, -17.0, -4.0, -2.0, 9.0, 12.0, -16.0, 14.0, 4.0, 13.0, 11.0, 11.0, 9.0, -16.0, 2.0, 12.0, 8.0, -7.0, 12.0, 0.0, -9.0, 12.0, -11.0, 6.0, 8.0, 12.0, -18.0, 13.0, 9.0, 11.0, 10.0, 8.0, 4.0, -7.0, -7.0, 4.0, 6.0, 12.0, 9.0, 14.0, 1.0, -9.0, -6.0, -3.0, 11.0, 13.0, 7.0, 13.0, -6.0, 1.0, 8.0, -15.0, 10.0, 12.0, 12.0, -5.0, -3.0, 11.0, 5.0, -3.0, 10.0, 3.0, -2.0, 14.0, 4.0, -1.0, -6.0, -2.0, 12.0, 11.0, 10.0, 13.0, 13.0, 317.0, 9.0, 11.0, -8.0, 3.0, 1.0, 14.0, -13.0, 13.0, -6.0, 1.0, 10.0, 10.0, 6.0, 11.0, -9.0, 7.0, -21.0, 13.0, 11.0, 12.0, 13.0, 11.0, 5.0, -14.0, 12.0, 5.0, -8.0, 6.0, -11.0, 14.0, 5.0, 7.0, 1.0, 8.0, -5.0, 11.0, 14.0, 11.0, 6.0, -16.0, 7.0, -12.0, 10.0, 10.0, 9.0, 14.0, -12.0, 4.0, 12.0, 13.0, 7.0, -17.0, -13.0, 12.0, 10.0, 6.0, 12.0, 6.0, 7.0, -10.0, 11.0, 14.0, -17.0, 7.0, 11.0, 12.0, 3.0, -11.0, -16.0, 14.0, 13.0, 4.0, 7.0, 1.0, 10.0, -3.0, 9.0, 14.0, -12.0, 4.0, 1.0, 11.0, -9.0, 12.0, 12.0, 13.0, 6.0, -16.0, -10.0, 6.0, 11.0, 8.0, 9.0, 4.0, -8.0, 10.0, 11.0, 13.0, 11.0, 332.0, -11.0, 12.0, 7.0, 7.0, 13.0, 1.0, 4.0, -3.0, 13.0, 14.0, 318.0, 10.0, 4.0, 13.0, -7.0, 5.0, 1.0, 11.0, 12.0, -9.0, 7.0, 3.0, -5.0, 10.0, 10.0, 14.0, 319.0, 12.0, 1.0, 11.0, 5.0, -2.0, 13.0, 11.0, -1.0, -8.0, 9.0, -15.0, 9.0, 12.0, 7.0, 9.0, 10.0, -11.0, -12.0, 8.0, 6.0, 13.0, -3.0, 10.0, 8.0, 0.0, -11.0, 5.0, 9.0, 12.0, 9.0, -3.0, 7.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22025585549501941, "mean_inference_ms": 1.176029919855633, "mean_action_processing_ms": 0.07195260446709481, "mean_env_wait_ms": 0.17913578312424136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 372600, "agent_timesteps_total": 372519, "timers": {"sample_time_ms": 350.888, "sample_throughput": 15389.521, "learn_time_ms": 7105.596, "learn_throughput": 759.964, "update_time_ms": 12.136}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 1243.16845703125, "policy_loss": -0.02634953148663044, "vf_loss": 1243.1912841796875, "vf_explained_var": 0.05290897563099861, "kl": 0.007807162590324879, "entropy": 0.5159692764282227, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 372600, "num_agent_steps_sampled": 372519, "num_steps_trained": 372600, "num_agent_steps_trained": 372519}, "done": false, "episodes_total": 7290, "training_iteration": 69, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-49-57", "timestamp": 1626860997, "time_this_iter_s": 7.59484338760376, "time_total_s": 499.90754222869873, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 499.90754222869873, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 20.479999999999997, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 37.03703703703704, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 9.25925925925926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 6.0, 10.0, -13.0, 5.0, -9.0, 9.0, 10.0, 12.0, -9.0, 7.0, 5.0, -9.0, 9.0, 7.0, 8.0, 14.0, -3.0, 12.0, -8.0, 3.0, 4.0, -5.0, 13.0, 7.0, 11.0, 1.0, -4.0, -9.0, 8.0, 5.0, 11.0, 13.0, -12.0, 12.0, 2.0, -16.0, 9.0, 11.0, 11.0, 8.0, -6.0, 9.0, 4.0, -7.0, 7.0, 10.0, 5.0, 13.0, 12.0, 11.0, 318.0, 5.0, -12.0, 9.0, 13.0, -14.0, 7.0, 11.0, 11.0, -8.0, 10.0, 11.0, 2.0, 14.0, -2.0, 12.0, -9.0, 2.0, -7.0, 7.0, 13.0, 7.0, -5.0, 2.0, 11.0, -11.0, 13.0, 1.0, 12.0, 14.0, -3.0, 12.0, -8.0, -12.0, 4.0, 11.0, 12.0, 3.0, 8.0, 10.0, -6.0, -5.0, 8.0, 4.0, 8.0, 14.0, -4.0, 11.0, -6.0, 13.0, -17.0, 7.0, 12.0, -8.0, 7.0, 6.0, 10.0, -8.0, 8.0, 10.0, 5.0, 13.0, 12.0, 12.0, 317.0, -16.0, 11.0, 8.0, 12.0, 8.0, -6.0, 5.0, 8.0, -5.0, 13.0, 5.0, 2.0, 14.0, 2.0, 5.0, -6.0, 8.0, -7.0, 11.0, 3.0, -10.0, 6.0, 11.0, 8.0, -10.0, 13.0, 4.0, 8.0, 14.0, 2.0, 9.0, -10.0, 4.0, -13.0, 11.0, 13.0, 9.0, 8.0, -13.0, 11.0, -15.0, 13.0, 5.0, 12.0, 13.0, -11.0, 11.0, 2.0, 5.0, 2.0, -5.0, 13.0, 3.0, 10.0, 7.0, -5.0, -4.0, 13.0, 5.0, 1.0, 14.0, 12.0, 11.0, 319.0, 12.0, -16.0, 6.0, 13.0, 9.0, 8.0, 2.0, -4.0, -9.0, 13.0, 6.0, 5.0, -4.0, 8.0, 12.0, -1.0, 2.0, -11.0, 13.0, 11.0, 8.0, -6.0, 10.0, 3.0, -10.0, 8.0, 6.0, 11.0, 13.0, -5.0, 2.0, 5.0, 0.0, -2.0, 11.0, 6.0, 3.0, 4.0, 10.0, -2.0, -8.0, 8.0, 5.0, 10.0, 13.0, 12.0, 12.0, 318.0, 12.0, -9.0, 7.0, 5.0, -14.0, 12.0, 5.0, 12.0, -6.0, 8.0, 6.0, 7.0, 0.0, 10.0, 11.0, -6.0, -1.0, -7.0, 10.0, 13.0, 13.0, -6.0, -5.0, 13.0, -9.0, 13.0, 6.0, 5.0, 6.0, -6.0, 12.0, 3.0, 6.0, -1.0, -3.0, 13.0, 4.0, -12.0, 11.0, 12.0, -6.0, 8.0, 5.0, 8.0, 14.0, -11.0, 9.0, 3.0, 2.0, 3.0, -3.0, 13.0, -10.0, 7.0, 8.0, 10.0, -9.0, 7.0, 6.0, 11.0, 12.0, 12.0, 12.0, 318.0, 7.0, 9.0, 8.0, -9.0, -9.0, 2.0, 12.0, 10.0, -10.0, 8.0, 6.0, 11.0, 13.0, 13.0, 12.0, 318.0, -14.0, 11.0, 6.0, 12.0, 12.0, -6.0, 11.0, -2.0, -12.0, 13.0, 4.0, 10.0, 0.0, 13.0, 11.0, -9.0, 0.0, -7.0, 9.0, 13.0, 12.0, 8.0, -16.0, 11.0, -10.0, 13.0, 3.0, 9.0, 13.0, 13.0, 12.0, 318.0, 8.0, -15.0, 10.0, 12.0, 12.0, -12.0, 2.0, 13.0, -6.0, 9.0, 3.0, 9.0, 10.0, 8.0, 12.0, -15.0, 8.0, -1.0, 11.0, -3.0, 1.0, 9.0, 10.0, -5.0, -8.0, 9.0, 5.0, 9.0, -4.0, 5.0, 12.0, 2.0, 12.0, -15.0, 5.0, 13.0, 12.0, 11.0, 10.0, -18.0, -13.0, 13.0, 7.0, 8.0, 0.0, 12.0, 12.0, -9.0, -13.0, 7.0, 8.0, 13.0, 12.0, -4.0, -6.0, 13.0, -8.0, 8.0, 5.0, 10.0, 11.0, 10.0, -7.0, 1.0, -15.0, 6.0, 11.0, 13.0, 7.0, -9.0, 6.0, 11.0, -7.0, 7.0, 5.0, 10.0, 11.0, -1.0, 12.0, -7.0, 8.0, -16.0, 10.0, 13.0, 7.0, -13.0, 9.0, 12.0, -8.0, 8.0, 6.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2202923939478675, "mean_inference_ms": 1.1762895916279275, "mean_action_processing_ms": 0.07195600836044289, "mean_env_wait_ms": 0.179124435316911, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 378000, "agent_timesteps_total": 377919, "timers": {"sample_time_ms": 350.976, "sample_throughput": 15385.66, "learn_time_ms": 7106.999, "learn_throughput": 759.814, "update_time_ms": 11.969}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 849.560791015625, "policy_loss": -0.0383526049554348, "vf_loss": 849.595947265625, "vf_explained_var": 0.07571643590927124, "kl": 0.007153181824833155, "entropy": 0.5020876526832581, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 378000, "num_agent_steps_sampled": 377919, "num_steps_trained": 378000, "num_agent_steps_trained": 377919}, "done": false, "episodes_total": 7398, "training_iteration": 70, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-50-04", "timestamp": 1626861004, "time_this_iter_s": 7.6072773933410645, "time_total_s": 507.5148196220398, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 507.5148196220398, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 21.136363636363637, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 0.0, 1.0, 3.0, 7.0, -1.0, -2.0, 11.0, 12.0, -14.0, 13.0, 4.0, 9.0, 8.0, -2.0, 0.0, 9.0, 2.0, 8.0, -4.0, 7.0, 0.0, -3.0, 11.0, 2.0, 4.0, 11.0, -2.0, 12.0, 7.0, 11.0, -15.0, 7.0, 7.0, 9.0, -8.0, 6.0, 6.0, -10.0, 13.0, 5.0, 5.0, 13.0, -8.0, 3.0, 7.0, -5.0, 10.0, 7.0, 12.0, 5.0, -9.0, 6.0, -1.0, -3.0, 13.0, 6.0, 8.0, 13.0, -12.0, 4.0, 4.0, -2.0, 9.0, 1.0, 12.0, -8.0, 10.0, 8.0, 5.0, -7.0, 9.0, 7.0, -3.0, 13.0, -2.0, 0.0, -5.0, 8.0, 12.0, 7.0, -3.0, 3.0, 8.0, 5.0, 1.0, -3.0, 12.0, 2.0, 7.0, 12.0, -6.0, 3.0, 9.0, -9.0, 12.0, 0.0, 14.0, -3.0, 4.0, 10.0, 3.0, -11.0, 13.0, -9.0, 5.0, 13.0, 6.0, 5.0, 5.0, -5.0, 10.0, 8.0, 8.0, 9.0, -10.0, -4.0, 5.0, 2.0, 12.0, 7.0, 0.0, 12.0, -4.0, 2.0, 7.0, -4.0, 10.0, 13.0, 5.0, 7.0, -10.0, 0.0, 6.0, -4.0, 13.0, 7.0, 6.0, 11.0, -9.0, 3.0, 3.0, -4.0, 13.0, 2.0, 11.0, -7.0, 9.0, 5.0, 4.0, -6.0, 12.0, 12.0, 4.0, 13.0, -14.0, 5.0, 9.0, -5.0, 6.0, 6.0, 9.0, 8.0, -8.0, -1.0, 13.0, -8.0, 11.0, 4.0, 6.0, 13.0, -8.0, 14.0, 3.0, -12.0, 10.0, 7.0, -3.0, 4.0, 7.0, 5.0, -11.0, 10.0, 11.0, -7.0, 6.0, 8.0, 8.0, 4.0, 12.0, 3.0, -4.0, 6.0, 9.0, -9.0, 9.0, -14.0, 10.0, 6.0, 13.0, -1.0, 2.0, 6.0, 8.0, 4.0, 6.0, -4.0, 9.0, 8.0, 10.0, 5.0, -8.0, -12.0, 2.0, 13.0, 12.0, 2.0, 11.0, 13.0, -11.0, 10.0, -14.0, 8.0, 11.0, -4.0, -1.0, 11.0, 9.0, -9.0, 12.0, 2.0, 10.0, 8.0, -11.0, 11.0, 7.0, 0.0, -4.0, 9.0, 10.0, 7.0, -3.0, 9.0, 2.0, 8.0, -1.0, -3.0, 11.0, 3.0, 5.0, 13.0, -6.0, -1.0, 11.0, -6.0, 11.0, 12.0, 5.0, 4.0, -6.0, 8.0, 0.0, -3.0, 10.0, 4.0, 9.0, 13.0, -11.0, 9.0, 7.0, -7.0, 6.0, 12.0, 9.0, -11.0, 5.0, -13.0, 3.0, 12.0, 13.0, 12.0, -3.0, 13.0, -7.0, 8.0, 4.0, 11.0, -8.0, 6.0, 6.0, -8.0, 11.0, 13.0, 318.0, 11.0, 13.0, 13.0, 0.0, 13.0, -11.0, 8.0, 4.0, 11.0, -8.0, -4.0, 14.0, -6.0, 11.0, -6.0, 0.0, 8.0, 13.0, -8.0, 4.0, 13.0, 6.0, 10.0, -3.0, -2.0, 10.0, 0.0, 13.0, 3.0, -1.0, 13.0, -14.0, 4.0, 12.0, -7.0, 7.0, 13.0, 2.0, 13.0, -12.0, 8.0, 6.0, 11.0, 1.0, -6.0, 9.0, -5.0, 2.0, 7.0, 11.0, -9.0, 3.0, 11.0, 10.0, 4.0, 7.0, 11.0, -7.0, -4.0, 12.0, 10.0, -3.0, -1.0, 8.0, -1.0, 9.0, 12.0, -1.0, 7.0, -3.0, 7.0, -7.0, 5.0, 10.0, 4.0, 9.0, -4.0, 6.0, 5.0, 8.0, -11.0, 13.0, 8.0, 1.0, 13.0, -7.0, -10.0, 7.0, 9.0, 9.0, 7.0, -4.0, 6.0, 6.0, 8.0, 13.0, -17.0, 11.0, -1.0, 10.0, 13.0, -7.0, 14.0, -21.0, 11.0, 11.0, 10.0, 7.0, 10.0, -12.0, 2.0, 7.0, -4.0, 10.0, 13.0, -4.0, 12.0, -6.0, 8.0, -9.0, 6.0, 10.0, 7.0, -14.0, 11.0, 11.0, -13.0, 10.0, 5.0, 13.0, 10.0, 4.0, 6.0, -5.0, -13.0, 9.0, 8.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22030514250339445, "mean_inference_ms": 1.1760163684068723, "mean_action_processing_ms": 0.07195549660001704, "mean_env_wait_ms": 0.179113833083173, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 383400, "agent_timesteps_total": 383319, "timers": {"sample_time_ms": 350.233, "sample_throughput": 15418.29, "learn_time_ms": 7102.232, "learn_throughput": 760.324, "update_time_ms": 12.112}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 230.39364624023438, "policy_loss": -0.03222615644335747, "vf_loss": 230.42112731933594, "vf_explained_var": 0.11301147937774658, "kl": 0.010561934672296047, "entropy": 0.48586753010749817, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 383400, "num_agent_steps_sampled": 383319, "num_steps_trained": 383400, "num_agent_steps_trained": 383319}, "done": false, "episodes_total": 7506, "training_iteration": 71, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-50-12", "timestamp": 1626861012, "time_this_iter_s": 7.541071891784668, "time_total_s": 515.0558915138245, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 515.0558915138245, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 21.509090909090904, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 33.925925925925924, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 8.481481481481481}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 10.0, 7.0, 11.0, -14.0, 12.0, 12.0, 5.0, 3.0, 3.0, -3.0, 12.0, -10.0, 9.0, 10.0, 6.0, 12.0, 14.0, 320.0, 10.0, -12.0, 10.0, 12.0, 5.0, 2.0, 9.0, 10.0, -6.0, 11.0, 12.0, -11.0, 3.0, 7.0, 6.0, 12.0, -10.0, -15.0, 12.0, 13.0, 5.0, -3.0, 0.0, 6.0, 12.0, 6.0, 5.0, 11.0, -7.0, 12.0, 14.0, 318.0, 12.0, -2.0, 12.0, 7.0, -2.0, 7.0, -3.0, -1.0, 12.0, 6.0, 10.0, 6.0, -7.0, -11.0, 9.0, 11.0, 6.0, -9.0, 9.0, 8.0, 7.0, 10.0, 8.0, -10.0, 7.0, 7.0, -7.0, 9.0, 6.0, 1.0, 9.0, -7.0, 12.0, -19.0, 11.0, 12.0, 11.0, -4.0, 8.0, 2.0, 9.0, 8.0, -3.0, 4.0, 6.0, -13.0, 10.0, 13.0, 5.0, -14.0, 11.0, 9.0, 9.0, -16.0, 8.0, 12.0, 11.0, 7.0, -1.0, 2.0, 7.0, -10.0, 14.0, -2.0, 13.0, -13.0, 12.0, 6.0, 10.0, 9.0, 9.0, 7.0, -10.0, 11.0, 0.0, 0.0, 4.0, -14.0, 5.0, 13.0, 11.0, -8.0, 6.0, 13.0, 4.0, 11.0, 8.0, -10.0, 6.0, 11.0, 2.0, 5.0, -3.0, -10.0, 6.0, 12.0, 7.0, -12.0, 6.0, 11.0, 10.0, 7.0, 9.0, -9.0, 8.0, 6.0, 13.0, -10.0, 6.0, -13.0, 10.0, 11.0, 7.0, -13.0, 13.0, 4.0, 11.0, 7.0, -10.0, 9.0, 9.0, 5.0, 0.0, 2.0, 8.0, -13.0, 9.0, 12.0, 7.0, 13.0, 8.0, -17.0, 11.0, -12.0, 8.0, 6.0, 13.0, -11.0, 12.0, 10.0, 4.0, 4.0, 4.0, 9.0, -2.0, -8.0, 8.0, 5.0, 10.0, 7.0, -6.0, 4.0, 10.0, 3.0, 11.0, -9.0, 10.0, -13.0, 8.0, 13.0, 7.0, -10.0, 8.0, 12.0, 5.0, -10.0, 8.0, 5.0, 12.0, 7.0, -2.0, 2.0, 8.0, -10.0, 5.0, 13.0, 7.0, -15.0, 12.0, 8.0, 10.0, -14.0, 9.0, 10.0, 10.0, 6.0, -1.0, 10.0, 0.0, 12.0, 14.0, 318.0, 12.0, 318.0, 12.0, 11.0, 13.0, -11.0, 8.0, 10.0, 8.0, 11.0, 9.0, 5.0, -10.0, -12.0, 5.0, 11.0, 11.0, -10.0, 5.0, 13.0, 7.0, -7.0, 8.0, 3.0, 11.0, 3.0, -3.0, 4.0, 11.0, -17.0, 10.0, 11.0, 11.0, -14.0, 12.0, 6.0, 11.0, 1.0, 8.0, -1.0, 7.0, 6.0, -4.0, 1.0, 12.0, 11.0, 13.0, 11.0, 321.0, 9.0, 11.0, 4.0, -9.0, 2.0, 8.0, -5.0, 10.0, 11.0, 7.0, -10.0, 7.0, -2.0, 14.0, -8.0, 11.0, -17.0, 12.0, 12.0, 8.0, -3.0, 8.0, 5.0, 5.0, 7.0, 13.0, -9.0, 4.0, -4.0, 14.0, -6.0, 11.0, -8.0, 11.0, 6.0, 6.0, 4.0, 8.0, -4.0, 7.0, 7.0, 8.0, 8.0, -8.0, -3.0, 14.0, -7.0, 11.0, -12.0, 8.0, 12.0, 7.0, 7.0, -7.0, 8.0, 7.0, 11.0, -2.0, 2.0, 4.0, -12.0, 10.0, 5.0, 12.0, -10.0, 6.0, 6.0, 13.0, -1.0, 8.0, -3.0, 11.0, 6.0, -6.0, 4.0, 11.0, -5.0, 13.0, -5.0, 12.0, -12.0, 5.0, 13.0, 9.0, -14.0, 8.0, 9.0, 12.0, 8.0, -3.0, 1.0, 9.0, 12.0, 13.0, -9.0, -1.0, -16.0, 13.0, 9.0, 9.0, -2.0, 8.0, -4.0, 13.0, 10.0, -7.0, 4.0, 8.0, 12.0, 14.0, 319.0, 11.0, -7.0, 3.0, 13.0, 6.0, 8.0, 8.0, 3.0, -4.0, 6.0, -4.0, 0.0, 13.0, -4.0, 13.0, -6.0, 12.0, -17.0, 12.0, 13.0, 7.0, 11.0, -4.0, -3.0, 11.0, 7.0, -13.0, 10.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22028539008741935, "mean_inference_ms": 1.175751807247096, "mean_action_processing_ms": 0.07194006765583826, "mean_env_wait_ms": 0.17909275309590125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 388800, "agent_timesteps_total": 388719, "timers": {"sample_time_ms": 349.833, "sample_throughput": 15435.949, "learn_time_ms": 7102.023, "learn_throughput": 760.347, "update_time_ms": 12.053}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 921.5123291015625, "policy_loss": -0.02504059672355652, "vf_loss": 921.5338745117188, "vf_explained_var": 0.08259880542755127, "kl": 0.007653533946722746, "entropy": 0.5210471749305725, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 388800, "num_agent_steps_sampled": 388719, "num_steps_trained": 388800, "num_agent_steps_trained": 388719}, "done": false, "episodes_total": 7614, "training_iteration": 72, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-50-19", "timestamp": 1626861019, "time_this_iter_s": 7.541642189025879, "time_total_s": 522.5975337028503, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70206840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 522.5975337028503, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 21.07272727272727, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.51851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 330.0}, "policy_reward_mean": {"learned": 6.12962962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 10.0, 13.0, -16.0, -2.0, 13.0, -8.0, 12.0, 9.0, 13.0, -12.0, 5.0, -11.0, 12.0, 1.0, 13.0, 0.0, 10.0, -3.0, 8.0, -13.0, 11.0, 10.0, 7.0, 12.0, 4.0, -11.0, 10.0, -1.0, 4.0, 1.0, 11.0, -9.0, 7.0, 13.0, 4.0, -2.0, 11.0, 6.0, 0.0, 5.0, 13.0, -7.0, 4.0, -13.0, 9.0, 6.0, 13.0, -7.0, 12.0, 13.0, -3.0, -13.0, 13.0, 5.0, 10.0, 11.0, 9.0, -15.0, 10.0, 6.0, -13.0, 12.0, 10.0, -4.0, 13.0, 12.0, -6.0, -11.0, 12.0, 6.0, 8.0, 13.0, 5.0, -5.0, 2.0, -8.0, 10.0, 0.0, 13.0, 8.0, 13.0, -19.0, 13.0, 6.0, 0.0, -3.0, 12.0, 9.0, 9.0, -12.0, 9.0, 6.0, -9.0, 5.0, 13.0, 12.0, 10.0, -20.0, 13.0, -2.0, 13.0, 5.0, -1.0, 12.0, 6.0, -12.0, 9.0, 5.0, -9.0, 6.0, 13.0, 12.0, -1.0, 0.0, 4.0, -13.0, 11.0, 10.0, 7.0, -12.0, 8.0, 6.0, 13.0, 8.0, 12.0, -13.0, 8.0, 11.0, 10.0, 8.0, -14.0, -7.0, 11.0, 8.0, 3.0, 7.0, 13.0, -16.0, 11.0, -11.0, 6.0, 7.0, 13.0, -2.0, 9.0, -3.0, 11.0, 5.0, -6.0, 7.0, 9.0, 8.0, 14.0, -5.0, -2.0, -6.0, 10.0, -2.0, 13.0, 13.0, 3.0, 8.0, -9.0, -12.0, 11.0, 4.0, 12.0, 6.0, 11.0, 1.0, -3.0, -7.0, 6.0, 5.0, 11.0, -1.0, 10.0, 3.0, 3.0, 5.0, -1.0, 9.0, 2.0, 10.0, 13.0, 9.0, -17.0, 8.0, -10.0, 4.0, 13.0, 11.0, 13.0, 0.0, -9.0, -15.0, 13.0, 6.0, 11.0, -3.0, 8.0, 10.0, 0.0, 4.0, -6.0, 4.0, 13.0, 9.0, 12.0, -18.0, 12.0, -7.0, 14.0, 11.0, -3.0, 13.0, 14.0, 4.0, -16.0, 13.0, 11.0, 330.0, 13.0, -3.0, 7.0, 13.0, -2.0, -20.0, 13.0, 10.0, 12.0, 7.0, 14.0, -16.0, 10.0, -4.0, 5.0, 1.0, 13.0, -4.0, 6.0, 5.0, 8.0, -10.0, 12.0, 10.0, 3.0, 7.0, 7.0, -9.0, 10.0, -2.0, 11.0, -6.0, 12.0, -1.0, 9.0, 13.0, -6.0, 6.0, -2.0, 4.0, 7.0, 13.0, 14.0, -14.0, 2.0, -5.0, 9.0, -2.0, 13.0, -7.0, 10.0, -1.0, 13.0, -2.0, 13.0, 4.0, 0.0, -10.0, 12.0, 10.0, 3.0, 7.0, -12.0, 7.0, 13.0, 7.0, 13.0, -15.0, 10.0, -13.0, 11.0, 9.0, 8.0, -9.0, 3.0, 10.0, 11.0, 7.0, 11.0, -16.0, 13.0, 13.0, -18.0, 7.0, 13.0, -8.0, 13.0, 3.0, 7.0, 13.0, 13.0, 317.0, 11.0, 8.0, -14.0, 12.0, 9.0, 10.0, 11.0, -19.0, 13.0, 8.0, -1.0, 10.0, -2.0, 0.0, 9.0, -3.0, 9.0, -9.0, 9.0, 3.0, 12.0, -3.0, 10.0, 13.0, -5.0, -2.0, -1.0, 9.0, 9.0, 12.0, 14.0, 0.0, -11.0, -3.0, 6.0, -1.0, 13.0, 13.0, 9.0, -15.0, 8.0, -15.0, 13.0, 12.0, 5.0, 13.0, 12.0, -15.0, 5.0, 5.0, -11.0, 8.0, 13.0, 13.0, -11.0, 11.0, 2.0, -13.0, 13.0, 6.0, 9.0, 8.0, 13.0, -16.0, 10.0, -7.0, 2.0, 7.0, 13.0, -7.0, 11.0, 10.0, 1.0, -6.0, 8.0, 4.0, 9.0, 8.0, 14.0, -1.0, -6.0, 13.0, 10.0, -21.0, 13.0, 13.0, 12.0, 315.0, 12.0, -16.0, 13.0, 8.0, 10.0, 10.0, 14.0, 11.0, -20.0, 8.0, -7.0, 3.0, 11.0, 8.0, 10.0, 13.0, -16.0, 6.0, 11.0, 6.0, -8.0, 5.0, 12.0, -6.0, 4.0, -13.0, 8.0, 8.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22029546380955337, "mean_inference_ms": 1.1755908889069357, "mean_action_processing_ms": 0.07192963228190705, "mean_env_wait_ms": 0.17909643796876124, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 394200, "agent_timesteps_total": 394119, "timers": {"sample_time_ms": 349.973, "sample_throughput": 15429.741, "learn_time_ms": 7094.387, "learn_throughput": 761.165, "update_time_ms": 12.02}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 581.7135009765625, "policy_loss": -0.029904088005423546, "vf_loss": 581.739990234375, "vf_explained_var": 0.09711338579654694, "kl": 0.0078124371357262135, "entropy": 0.5241051316261292, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 394200, "num_agent_steps_sampled": 394119, "num_steps_trained": 394200, "num_agent_steps_trained": 394119}, "done": false, "episodes_total": 7722, "training_iteration": 73, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-50-27", "timestamp": 1626861027, "time_this_iter_s": 7.6025307178497314, "time_total_s": 530.2000644207001, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae676a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 530.2000644207001, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 21.154545454545453, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12962962962963, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.532407407407407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -1.0, -3.0, 7.0, 7.0, -6.0, 10.0, 4.0, 4.0, 13.0, 8.0, -10.0, -7.0, 5.0, 6.0, 11.0, 11.0, 12.0, -13.0, 5.0, 7.0, 8.0, 2.0, -2.0, -4.0, 14.0, -5.0, 10.0, 6.0, 14.0, -7.0, 2.0, 10.0, 6.0, -13.0, 12.0, 318.0, 13.0, 11.0, 11.0, -13.0, 13.0, 5.0, 10.0, 8.0, 13.0, -14.0, 8.0, 5.0, -4.0, 7.0, 7.0, 14.0, -14.0, 8.0, 7.0, -6.0, 5.0, 5.0, 11.0, 0.0, 6.0, 11.0, -2.0, 7.0, 10.0, -8.0, 6.0, 3.0, 12.0, -12.0, 12.0, -18.0, 13.0, 11.0, 9.0, 2.0, 13.0, 9.0, -9.0, 6.0, -6.0, 4.0, 11.0, 9.0, 11.0, -11.0, 6.0, -2.0, -7.0, 12.0, 12.0, -9.0, 12.0, 9.0, 3.0, -1.0, 12.0, 0.0, 4.0, 14.0, -7.0, 4.0, 4.0, -9.0, 13.0, 3.0, 8.0, 1.0, 10.0, -8.0, 12.0, -5.0, 11.0, 1.0, 8.0, 4.0, -5.0, 8.0, 8.0, -8.0, 14.0, 1.0, 8.0, -1.0, 12.0, 6.0, -2.0, 12.0, -1.0, 2.0, 2.0, 12.0, 6.0, -12.0, 9.0, -10.0, 7.0, 8.0, 10.0, 8.0, 11.0, 6.0, -10.0, 12.0, 9.0, -15.0, 9.0, 6.0, -1.0, 8.0, 2.0, -13.0, 13.0, 6.0, 9.0, 8.0, 10.0, -5.0, 2.0, 10.0, -5.0, 5.0, 5.0, 8.0, 6.0, 4.0, -3.0, -13.0, 10.0, 6.0, 12.0, 12.0, 12.0, -3.0, -6.0, -3.0, 13.0, 2.0, 3.0, 9.0, -11.0, 9.0, 8.0, -5.0, 13.0, -2.0, 9.0, -12.0, 10.0, 6.0, 11.0, -4.0, 10.0, 3.0, 6.0, -9.0, 12.0, 6.0, 6.0, -18.0, 13.0, 7.0, 13.0, -13.0, 5.0, 10.0, 13.0, -5.0, 12.0, -2.0, 10.0, 14.0, -15.0, 9.0, 7.0, 7.0, 13.0, 0.0, -5.0, 4.0, 12.0, -6.0, 5.0, 11.0, -1.0, 2.0, 3.0, 13.0, -18.0, 9.0, 11.0, -5.0, 13.0, -2.0, 9.0, 9.0, 12.0, -3.0, -3.0, -3.0, 6.0, 11.0, 1.0, 13.0, -19.0, 10.0, 11.0, -13.0, 12.0, 11.0, 5.0, 5.0, 12.0, -5.0, 3.0, 6.0, -5.0, 2.0, 12.0, 13.0, -1.0, 11.0, -8.0, -18.0, 12.0, 12.0, 9.0, -11.0, 11.0, 9.0, 6.0, 10.0, 5.0, -11.0, 11.0, 14.0, 6.0, -12.0, 7.0, -5.0, 13.0, -6.0, 13.0, 7.0, 11.0, -9.0, 6.0, 11.0, -5.0, 4.0, 5.0, 14.0, -15.0, 10.0, 6.0, -14.0, 12.0, 6.0, 11.0, -7.0, 11.0, 0.0, 11.0, 11.0, 12.0, -11.0, 3.0, -6.0, 12.0, 12.0, -3.0, -3.0, 4.0, 6.0, 8.0, -12.0, 10.0, 11.0, 6.0, -5.0, 12.0, 7.0, 1.0, 7.0, -14.0, 11.0, 11.0, -17.0, 12.0, 9.0, 11.0, 12.0, 12.0, -4.0, -5.0, -6.0, 9.0, 5.0, 7.0, 13.0, -15.0, 11.0, 6.0, -2.0, 8.0, 12.0, -3.0, -13.0, 9.0, 8.0, 11.0, -3.0, 9.0, 3.0, 6.0, 13.0, 3.0, 1.0, -2.0, -18.0, 13.0, 11.0, 9.0, -8.0, 7.0, 11.0, 5.0, 7.0, -5.0, 1.0, 12.0, 4.0, 4.0, -3.0, 10.0, -4.0, 13.0, -2.0, 8.0, 1.0, 6.0, -2.0, 10.0, 7.0, 9.0, -14.0, 13.0, 10.0, -11.0, 12.0, 4.0, -15.0, 14.0, 12.0, 4.0, -2.0, 13.0, -1.0, 5.0, -4.0, 8.0, -1.0, 12.0, -11.0, 11.0, 10.0, 5.0, -12.0, 12.0, 2.0, 13.0, -8.0, 10.0, 11.0, 2.0, -2.0, 12.0, 4.0, 1.0, 13.0, 12.0, -3.0, -7.0, -4.0, 13.0, -4.0, 10.0, 6.0, 8.0, 9.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2203106305361209, "mean_inference_ms": 1.1756278657114836, "mean_action_processing_ms": 0.07193646838341546, "mean_env_wait_ms": 0.17911968191539016, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 399600, "agent_timesteps_total": 399519, "timers": {"sample_time_ms": 350.675, "sample_throughput": 15398.861, "learn_time_ms": 7082.319, "learn_throughput": 762.462, "update_time_ms": 12.008}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 227.06092834472656, "policy_loss": -0.03186484053730965, "vf_loss": 227.08822631835938, "vf_explained_var": 0.13739414513111115, "kl": 0.010134825482964516, "entropy": 0.5149946212768555, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 399600, "num_agent_steps_sampled": 399519, "num_steps_trained": 399600, "num_agent_steps_trained": 399519}, "done": false, "episodes_total": 7830, "training_iteration": 74, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-50-34", "timestamp": 1626861034, "time_this_iter_s": 7.3490869998931885, "time_total_s": 537.5491514205933, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 537.5491514205933, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 22.61, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.72222222222222, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 7.680555555555555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -15.0, 10.0, 6.0, -4.0, 7.0, 6.0, 6.0, -3.0, 12.0, -6.0, 12.0, 5.0, 5.0, 11.0, -6.0, 3.0, -11.0, 13.0, 10.0, 9.0, 9.0, 6.0, -9.0, -11.0, 11.0, 3.0, 12.0, -8.0, 6.0, 6.0, 11.0, 13.0, -12.0, 11.0, 3.0, 6.0, 5.0, 13.0, -9.0, 322.0, 11.0, 10.0, 12.0, 10.0, -18.0, 10.0, 13.0, 2.0, -7.0, 8.0, 12.0, 12.0, 8.0, -8.0, 3.0, -7.0, -2.0, 11.0, 13.0, 6.0, -10.0, 8.0, 11.0, -11.0, 12.0, 4.0, 10.0, 13.0, 2.0, 8.0, -8.0, -15.0, 11.0, 11.0, 8.0, 5.0, 6.0, 9.0, -5.0, -4.0, 9.0, 11.0, -1.0, 13.0, 8.0, 13.0, 322.0, 1.0, 12.0, -11.0, 13.0, -5.0, 7.0, 8.0, 5.0, 0.0, -8.0, 13.0, 10.0, 9.0, 5.0, -1.0, 2.0, -14.0, 12.0, 4.0, 13.0, 2.0, 12.0, 11.0, -10.0, -1.0, 2.0, 11.0, 3.0, 14.0, -4.0, 13.0, -8.0, -17.0, 12.0, 9.0, 11.0, 7.0, -12.0, 13.0, 7.0, -14.0, 6.0, 13.0, 10.0, -2.0, 8.0, 8.0, 1.0, 318.0, 12.0, 10.0, 12.0, 7.0, 1.0, 12.0, -5.0, 10.0, -10.0, 4.0, 11.0, 13.0, 5.0, -10.0, 7.0, -7.0, 12.0, -3.0, 13.0, 9.0, -18.0, 13.0, 11.0, -1.0, 4.0, 6.0, 6.0, 10.0, 9.0, 13.0, -17.0, -4.0, 12.0, -5.0, 12.0, 12.0, -17.0, 8.0, 12.0, -5.0, 9.0, 10.0, 1.0, 10.0, -4.0, 13.0, -4.0, -9.0, 8.0, 3.0, 13.0, 7.0, -8.0, 6.0, 10.0, 14.0, -12.0, 4.0, 9.0, 12.0, 10.0, 13.0, 321.0, -2.0, 12.0, -8.0, 13.0, 6.0, 11.0, 5.0, -7.0, -15.0, 6.0, 11.0, 13.0, 13.0, 11.0, -1.0, -8.0, 3.0, 10.0, -9.0, 11.0, 6.0, -16.0, 13.0, 12.0, 11.0, -8.0, 1.0, 11.0, 9.0, 8.0, -7.0, 5.0, -6.0, 12.0, -4.0, 13.0, 5.0, -9.0, 7.0, 12.0, 14.0, -13.0, 10.0, 4.0, 13.0, 9.0, 10.0, -17.0, 4.0, 8.0, -10.0, 13.0, 11.0, -8.0, 7.0, 5.0, -2.0, 4.0, 11.0, 2.0, 13.0, 4.0, 5.0, -7.0, -12.0, 11.0, 4.0, 12.0, 5.0, -15.0, 13.0, 12.0, 11.0, -12.0, 5.0, 11.0, 9.0, 8.0, 6.0, -8.0, -11.0, 11.0, 3.0, 12.0, 7.0, 11.0, 4.0, -7.0, -8.0, 5.0, 11.0, 7.0, -1.0, -3.0, 12.0, 7.0, -17.0, 12.0, 8.0, 12.0, 13.0, -16.0, 7.0, 11.0, 9.0, -8.0, 3.0, 11.0, 13.0, 9.0, -8.0, 1.0, 1.0, -1.0, 3.0, 12.0, 13.0, -13.0, 8.0, 7.0, -8.0, 6.0, 9.0, 8.0, -2.0, 10.0, 8.0, -1.0, -2.0, -2.0, 6.0, 13.0, 5.0, 6.0, 12.0, -8.0, -12.0, 10.0, 6.0, 11.0, 11.0, 7.0, -8.0, 5.0, -4.0, 12.0, -6.0, 13.0, 3.0, 9.0, 9.0, -6.0, -14.0, 10.0, 8.0, 11.0, -2.0, 3.0, 7.0, 7.0, -7.0, 13.0, -4.0, 13.0, 8.0, -10.0, 6.0, 11.0, -8.0, 5.0, 10.0, 8.0, 13.0, 9.0, -4.0, -3.0, -14.0, 12.0, 4.0, 13.0, 11.0, -17.0, 10.0, 11.0, 13.0, 6.0, -15.0, 11.0, 0.0, 10.0, 13.0, -8.0, -6.0, 12.0, -4.0, 13.0, 6.0, -13.0, 12.0, 10.0, -7.0, 6.0, 11.0, 5.0, 13.0, 8.0, -11.0, 5.0, -2.0, -2.0, 7.0, 12.0, -14.0, 4.0, 13.0, 12.0, -6.0, 9.0, 12.0, 0.0, 9.0, 4.0, -1.0, 3.0, 320.0, 11.0, 11.0, 12.0, -7.0, 5.0, 7.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22021718215894356, "mean_inference_ms": 1.1752934240861794, "mean_action_processing_ms": 0.07193042210735304, "mean_env_wait_ms": 0.17910023829210628, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 405000, "agent_timesteps_total": 404919, "timers": {"sample_time_ms": 349.511, "sample_throughput": 15450.175, "learn_time_ms": 7081.278, "learn_throughput": 762.574, "update_time_ms": 11.878}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 1131.5469970703125, "policy_loss": -0.03291064500808716, "vf_loss": 1131.5767822265625, "vf_explained_var": 0.04513063654303551, "kl": 0.00696781137958169, "entropy": 0.4958381652832031, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 405000, "num_agent_steps_sampled": 404919, "num_steps_trained": 405000, "num_agent_steps_trained": 404919}, "done": false, "episodes_total": 7938, "training_iteration": 75, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-50-42", "timestamp": 1626861042, "time_this_iter_s": 7.604216814041138, "time_total_s": 545.1533682346344, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 545.1533682346344, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 21.218181818181815, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.425925925925927, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.106481481481482}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-16.0, 11.0, 11.0, 9.0, 10.0, -9.0, 6.0, 8.0, 11.0, 12.0, 10.0, -18.0, 6.0, 14.0, -17.0, 12.0, -15.0, 11.0, 9.0, 10.0, 11.0, 5.0, 3.0, -4.0, 4.0, -2.0, 5.0, 8.0, 1.0, 14.0, 1.0, -1.0, -19.0, 12.0, 13.0, 9.0, 12.0, -7.0, -1.0, 11.0, 14.0, 10.0, 11.0, -20.0, 8.0, 14.0, -15.0, 8.0, -7.0, 2.0, 10.0, 10.0, 10.0, 5.0, 3.0, -3.0, 14.0, 10.0, 11.0, -20.0, -2.0, 14.0, -4.0, 7.0, -2.0, -1.0, 11.0, 7.0, 7.0, 10.0, 4.0, -6.0, 14.0, 11.0, 9.0, -19.0, 11.0, -4.0, -4.0, 12.0, -7.0, 10.0, 10.0, 2.0, 10.0, 7.0, -15.0, 13.0, 3.0, -2.0, 6.0, 8.0, 10.0, 13.0, -5.0, -3.0, -14.0, 10.0, 13.0, 6.0, -13.0, 11.0, 6.0, 11.0, 14.0, 3.0, -5.0, 3.0, 7.0, 14.0, -9.0, 3.0, -20.0, 11.0, 13.0, 11.0, 3.0, 13.0, 0.0, -1.0, -2.0, 13.0, -9.0, 13.0, 8.0, 14.0, -3.0, -4.0, 316.0, 14.0, 13.0, 11.0, 10.0, -16.0, 8.0, 13.0, 14.0, 11.0, -5.0, -5.0, 4.0, 14.0, 1.0, -4.0, -17.0, 11.0, 13.0, 8.0, 12.0, -7.0, 4.0, 6.0, 13.0, -5.0, 10.0, -3.0, 9.0, 13.0, -16.0, 9.0, -14.0, 13.0, 11.0, 5.0, -4.0, 3.0, 4.0, 12.0, 12.0, -3.0, 8.0, -2.0, 11.0, 14.0, 0.0, -10.0, 317.0, 12.0, 13.0, 12.0, 11.0, 0.0, 7.0, -3.0, 5.0, -7.0, 9.0, 8.0, 5.0, 12.0, -13.0, 11.0, -15.0, 12.0, 11.0, 7.0, 7.0, -7.0, 2.0, 13.0, 10.0, 12.0, -14.0, 7.0, 7.0, 14.0, -16.0, 10.0, -6.0, -1.0, 13.0, 9.0, 7.0, -15.0, 11.0, 12.0, -3.0, 7.0, 3.0, 8.0, 9.0, 14.0, -17.0, 9.0, -16.0, 12.0, 13.0, 6.0, 7.0, -8.0, 6.0, 10.0, 14.0, -3.0, 9.0, -5.0, -5.0, 12.0, 9.0, -1.0, -15.0, 11.0, 13.0, 6.0, 0.0, -3.0, 5.0, 13.0, 13.0, -2.0, 9.0, -5.0, 11.0, 14.0, -19.0, 9.0, -16.0, 10.0, 13.0, 8.0, 11.0, 8.0, -3.0, -1.0, 0.0, 9.0, 10.0, -4.0, 13.0, 14.0, -22.0, 10.0, -10.0, 10.0, 10.0, 5.0, 10.0, -9.0, 1.0, 13.0, -11.0, 8.0, 10.0, 8.0, -11.0, 13.0, 3.0, 10.0, -14.0, 11.0, 10.0, 8.0, 14.0, -19.0, 9.0, 11.0, 9.0, 7.0, 6.0, -7.0, 13.0, 13.0, -3.0, -8.0, 3.0, 11.0, 6.0, -5.0, 13.0, -14.0, 9.0, 7.0, 13.0, 13.0, 8.0, 321.0, 11.0, 9.0, -16.0, 11.0, -9.0, 11.0, 11.0, 2.0, 4.0, -10.0, 11.0, 10.0, 12.0, 0.0, 10.0, -7.0, 8.0, 14.0, -15.0, 8.0, -14.0, 13.0, 3.0, 13.0, 12.0, -12.0, 2.0, 13.0, 14.0, 10.0, 10.0, -19.0, 12.0, -3.0, -6.0, 12.0, -17.0, 7.0, 13.0, 12.0, 9.0, -10.0, 4.0, 12.0, 14.0, 10.0, 9.0, -18.0, 12.0, 14.0, -17.0, 6.0, -10.0, 11.0, 7.0, 7.0, -3.0, 3.0, 5.0, 10.0, 14.0, -2.0, 10.0, -7.0, -9.0, 14.0, 0.0, 10.0, -16.0, 9.0, 13.0, 9.0, 3.0, -6.0, 6.0, 12.0, 3.0, 14.0, -4.0, 2.0, -6.0, 1.0, 10.0, 10.0, -6.0, 11.0, 11.0, -1.0, 10.0, -8.0, 8.0, 5.0, 6.0, 11.0, 7.0, -9.0, 12.0, 13.0, -19.0, 9.0, -20.0, 12.0, 13.0, 10.0, 12.0, -12.0, 5.0, 10.0, 2.0, 9.0, -4.0, 8.0, 9.0, 10.0, -14.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21999544878315513, "mean_inference_ms": 1.175323433740071, "mean_action_processing_ms": 0.0719390325479786, "mean_env_wait_ms": 0.17910262780031425, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 410400, "agent_timesteps_total": 410346, "timers": {"sample_time_ms": 348.983, "sample_throughput": 15473.525, "learn_time_ms": 7097.144, "learn_throughput": 760.869, "update_time_ms": 11.891}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 642.2279052734375, "policy_loss": -0.0364353209733963, "vf_loss": 642.2603149414062, "vf_explained_var": 0.07827802747488022, "kl": 0.008871259167790413, "entropy": 0.5557445883750916, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 410400, "num_agent_steps_sampled": 410346, "num_steps_trained": 410400, "num_agent_steps_trained": 410346}, "done": false, "episodes_total": 8046, "training_iteration": 76, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-50-50", "timestamp": 1626861050, "time_this_iter_s": 7.619117259979248, "time_total_s": 552.7724854946136, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70223c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 552.7724854946136, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 21.01818181818182, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.8, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 10.0, -17.0, 12.0, -1.0, -1.0, 5.0, 12.0, 8.0, 2.0, -6.0, 11.0, 2.0, 8.0, -8.0, 13.0, -5.0, 0.0, 9.0, 11.0, 12.0, 8.0, -14.0, 9.0, 9.0, 14.0, -14.0, 6.0, -1.0, 6.0, 13.0, -3.0, 5.0, 14.0, -10.0, 6.0, 10.0, 13.0, -16.0, 8.0, -19.0, 14.0, 10.0, 10.0, 7.0, 13.0, -15.0, 10.0, 3.0, 8.0, -9.0, 13.0, -4.0, -1.0, 12.0, 8.0, -3.0, 14.0, 1.0, 3.0, 8.0, 9.0, -15.0, 13.0, -16.0, 13.0, 6.0, 12.0, 7.0, 8.0, -9.0, 9.0, 7.0, 6.0, -11.0, 13.0, 11.0, -6.0, -1.0, 11.0, 7.0, 8.0, -4.0, 4.0, 9.0, 11.0, -12.0, 7.0, 11.0, -6.0, -1.0, 11.0, 6.0, -6.0, 4.0, 11.0, 8.0, 13.0, 3.0, -9.0, -2.0, -2.0, 8.0, 11.0, 7.0, 12.0, 6.0, -10.0, 14.0, 7.0, -18.0, 12.0, -7.0, 0.0, 11.0, 11.0, 5.0, 14.0, -2.0, -2.0, 13.0, 6.0, -12.0, 8.0, -9.0, 14.0, 11.0, -1.0, 7.0, 13.0, -14.0, 9.0, 9.0, 9.0, 5.0, -8.0, 321.0, 11.0, 11.0, 12.0, 8.0, 13.0, -16.0, 10.0, 8.0, 8.0, -12.0, 11.0, -1.0, -1.0, 4.0, 13.0, 8.0, 14.0, -14.0, 7.0, 8.0, 9.0, -15.0, 13.0, 11.0, -6.0, -3.0, 13.0, 9.0, 10.0, -5.0, 1.0, 13.0, -2.0, -4.0, 8.0, 2.0, -5.0, 7.0, 11.0, -10.0, 9.0, 6.0, 10.0, 9.0, 6.0, -12.0, 12.0, -7.0, 14.0, 9.0, -1.0, 4.0, 13.0, -15.0, 13.0, 13.0, 9.0, -20.0, 13.0, -19.0, 14.0, 10.0, 10.0, 5.0, -7.0, 6.0, 11.0, 9.0, 13.0, -15.0, 8.0, -7.0, 13.0, 11.0, -2.0, 12.0, 11.0, 5.0, -13.0, 5.0, 9.0, -11.0, 12.0, -17.0, 10.0, 9.0, 13.0, 7.0, 12.0, -11.0, 7.0, 8.0, 11.0, -17.0, 13.0, 317.0, 14.0, 11.0, 13.0, 12.0, 14.0, -5.0, -6.0, 5.0, 8.0, 4.0, -2.0, -5.0, -3.0, 10.0, 13.0, 8.0, -8.0, 6.0, 9.0, -2.0, 11.0, -6.0, 12.0, -15.0, 14.0, 5.0, 11.0, 5.0, 10.0, -11.0, 11.0, 5.0, 14.0, -13.0, 9.0, -7.0, -1.0, 12.0, 11.0, 8.0, 13.0, -8.0, 2.0, 8.0, 9.0, 1.0, -3.0, -4.0, 0.0, 7.0, 12.0, 10.0, 14.0, -17.0, 8.0, 14.0, 8.0, -14.0, 7.0, -8.0, 0.0, 11.0, 12.0, 7.0, 14.0, 4.0, -10.0, 8.0, 14.0, -18.0, 11.0, 4.0, 5.0, 7.0, -1.0, 9.0, 12.0, -15.0, 9.0, 14.0, 8.0, -20.0, 13.0, -5.0, 13.0, -1.0, 8.0, 7.0, 6.0, -9.0, 11.0, 9.0, -10.0, 4.0, 12.0, 14.0, 10.0, 9.0, -18.0, 12.0, 14.0, -17.0, 6.0, -10.0, 11.0, 7.0, 7.0, -3.0, 3.0, 5.0, 10.0, 14.0, -2.0, 10.0, -7.0, -9.0, 14.0, 0.0, 10.0, -16.0, 9.0, 13.0, 9.0, 3.0, -6.0, 6.0, 12.0, 3.0, 14.0, -4.0, 2.0, -6.0, 1.0, 10.0, 10.0, -6.0, 11.0, 11.0, -1.0, 10.0, -8.0, 8.0, 5.0, 6.0, 11.0, 7.0, -9.0, 12.0, 13.0, -19.0, 9.0, -20.0, 12.0, 13.0, 10.0, 12.0, -12.0, 5.0, 10.0, 2.0, 9.0, -4.0, 8.0, 9.0, 10.0, -14.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2198184522647426, "mean_inference_ms": 1.1743562151197546, "mean_action_processing_ms": 0.07192688042407944, "mean_env_wait_ms": 0.17895899328075907, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 415800, "agent_timesteps_total": 415719, "timers": {"sample_time_ms": 348.231, "sample_throughput": 15506.965, "learn_time_ms": 7083.588, "learn_throughput": 762.326, "update_time_ms": 11.761}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 466.877685546875, "policy_loss": -0.03092486783862114, "vf_loss": 466.9047546386719, "vf_explained_var": 0.1054883822798729, "kl": 0.008784045465290546, "entropy": 0.5271503925323486, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 415800, "num_agent_steps_sampled": 415719, "num_steps_trained": 415800, "num_agent_steps_trained": 415719}, "done": false, "episodes_total": 8127, "training_iteration": 77, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-50-57", "timestamp": 1626861057, "time_this_iter_s": 7.42621922492981, "time_total_s": 560.1987047195435, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70223158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 560.1987047195435, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 21.409090909090907, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 3.0, 3.0, -5.0, 10.0, 10.0, -15.0, 10.0, -17.0, 8.0, 13.0, 11.0, -10.0, 6.0, 11.0, 8.0, 13.0, 6.0, 1.0, -5.0, 9.0, 6.0, -6.0, 6.0, -9.0, -1.0, 13.0, 12.0, -7.0, 14.0, -1.0, 9.0, 14.0, -13.0, 9.0, 5.0, 13.0, -1.0, 6.0, -3.0, -19.0, 10.0, 12.0, 12.0, 11.0, 7.0, -1.0, -2.0, 2.0, -4.0, 7.0, 10.0, 7.0, 7.0, -7.0, 8.0, -18.0, 11.0, 11.0, 11.0, 11.0, 8.0, 5.0, -9.0, 13.0, 8.0, -7.0, 1.0, 13.0, 5.0, -3.0, 0.0, 8.0, 8.0, -3.0, 2.0, 12.0, 14.0, -10.0, -1.0, 7.0, 1.0, 8.0, -1.0, 9.0, 5.0, -6.0, 7.0, -7.0, 8.0, 4.0, 10.0, 12.0, 14.0, -11.0, 0.0, 14.0, -12.0, 8.0, 5.0, -3.0, 4.0, 3.0, 11.0, -4.0, 8.0, 4.0, 7.0, 12.0, 13.0, -14.0, 4.0, 8.0, 4.0, 8.0, -5.0, 10.0, 12.0, -5.0, -2.0, 11.0, -16.0, 9.0, 11.0, -5.0, 14.0, 0.0, 6.0, 13.0, 6.0, -16.0, 12.0, 11.0, 5.0, -8.0, 7.0, -8.0, -1.0, 13.0, 11.0, 11.0, 13.0, -13.0, 4.0, 13.0, -14.0, 8.0, 8.0, -4.0, 4.0, 5.0, 10.0, -10.0, 4.0, 11.0, 10.0, 8.0, 8.0, -12.0, 11.0, 7.0, -3.0, 5.0, 6.0, 10.0, 8.0, -5.0, 2.0, -11.0, 4.0, 10.0, 12.0, 7.0, 11.0, -13.0, 10.0, 13.0, -9.0, -2.0, 13.0, 3.0, 4.0, -5.0, 13.0, -2.0, 1.0, 4.0, 12.0, 8.0, 13.0, -7.0, 1.0, 13.0, -18.0, 9.0, 11.0, 8.0, 8.0, 2.0, -3.0, -14.0, 8.0, 11.0, 10.0, 11.0, 13.0, 2.0, -11.0, -1.0, -3.0, 10.0, 9.0, 13.0, 7.0, 6.0, -11.0, -8.0, 0.0, 13.0, 10.0, -6.0, 12.0, 4.0, 5.0, 13.0, -10.0, 9.0, 3.0, 9.0, 3.0, -4.0, 7.0, -14.0, 4.0, 12.0, 13.0, 12.0, 12.0, -16.0, 7.0, 7.0, -12.0, 8.0, 12.0, 7.0, 7.0, 11.0, -10.0, -9.0, 7.0, 6.0, 11.0, -1.0, 13.0, -1.0, 4.0, 14.0, -16.0, 4.0, 13.0, -4.0, 2.0, 7.0, 10.0, 6.0, -16.0, 13.0, 12.0, 7.0, 13.0, 5.0, -10.0, -6.0, 5.0, 8.0, 8.0, 13.0, -11.0, 3.0, 10.0, -12.0, 5.0, 9.0, 13.0, 12.0, -6.0, 2.0, 7.0, 11.0, -11.0, 5.0, 10.0, 10.0, 6.0, 3.0, -4.0, 6.0, -15.0, 11.0, 13.0, 7.0, 8.0, -3.0, 3.0, 10.0, -13.0, 8.0, 10.0, 11.0, 4.0, 5.0, -5.0, -9.0, 4.0, 12.0, 8.0, -1.0, 14.0, 0.0, 2.0, 10.0, -13.0, 8.0, 10.0, 11.0, 7.0, -9.0, 6.0, -11.0, 2.0, 13.0, 11.0, 7.0, 8.0, 10.0, -10.0, 12.0, -1.0, 6.0, -2.0, 7.0, 7.0, 12.0, -11.0, -20.0, 11.0, 13.0, 11.0, 6.0, 14.0, -8.0, 3.0, 13.0, -8.0, 0.0, 10.0, 9.0, -11.0, 11.0, 6.0, -6.0, 11.0, 2.0, 8.0, 11.0, 14.0, 2.0, -12.0, 14.0, -15.0, 9.0, 7.0, 11.0, 13.0, -11.0, 2.0, -13.0, 6.0, 12.0, 10.0, -3.0, 12.0, -3.0, 9.0, 14.0, -7.0, 12.0, -4.0, 11.0, 2.0, -6.0, 8.0, -9.0, 8.0, 12.0, 4.0, 9.0, 12.0, -8.0, 2.0, 14.0, 7.0, -11.0, 5.0, 12.0, 0.0, -3.0, 6.0, -6.0, 1.0, 9.0, 11.0, 5.0, 9.0, 10.0, -9.0, 5.0, 8.0, -7.0, 9.0, 12.0, 4.0, 8.0, -9.0, 5.0, -8.0, 12.0, 6.0, -6.0, 13.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22007617470870736, "mean_inference_ms": 1.175180410543393, "mean_action_processing_ms": 0.07192867793360867, "mean_env_wait_ms": 0.1790771843179886, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 421200, "agent_timesteps_total": 421119, "timers": {"sample_time_ms": 347.988, "sample_throughput": 15517.773, "learn_time_ms": 7076.057, "learn_throughput": 763.137, "update_time_ms": 11.501}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 28.775022506713867, "policy_loss": -0.09366864711046219, "vf_loss": 28.86040496826172, "vf_explained_var": 0.19770190119743347, "kl": 0.018408622592687607, "entropy": 0.5421863794326782, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 421200, "num_agent_steps_sampled": 421119, "num_steps_trained": 421200, "num_agent_steps_trained": 421119}, "done": false, "episodes_total": 8235, "training_iteration": 78, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-51-05", "timestamp": 1626861065, "time_this_iter_s": 7.50987982749939, "time_total_s": 567.7085845470428, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70223840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 567.7085845470428, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 21.689999999999998, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.416666666666668, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 6.104166666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 12.0, 1.0, 11.0, 7.0, 7.0, 5.0, -4.0, 12.0, -20.0, 11.0, 12.0, 13.0, 14.0, -20.0, 8.0, 4.0, 13.0, 0.0, -2.0, 12.0, 9.0, 3.0, -9.0, 9.0, -16.0, 10.0, 12.0, 12.0, 14.0, -16.0, 5.0, 1.0, 13.0, 5.0, -4.0, 12.0, 8.0, 7.0, -12.0, 9.0, 8.0, 11.0, -13.0, 5.0, 14.0, -10.0, 6.0, 1.0, 7.0, 11.0, -4.0, 3.0, 13.0, 10.0, -11.0, 13.0, -18.0, 10.0, 10.0, 5.0, 13.0, -11.0, 8.0, -14.0, 13.0, 7.0, 9.0, 12.0, 2.0, 6.0, -5.0, -1.0, 7.0, 11.0, -2.0, 13.0, 14.0, 314.0, 12.0, -15.0, 13.0, 4.0, 13.0, 13.0, 9.0, -1.0, -6.0, 14.0, -20.0, 11.0, 10.0, 11.0, 14.0, -19.0, 9.0, 5.0, 11.0, 4.0, -5.0, 11.0, 9.0, 6.0, -11.0, -12.0, 9.0, 7.0, 11.0, 14.0, -5.0, -1.0, 7.0, 2.0, 11.0, 6.0, -4.0, 7.0, 3.0, 10.0, -5.0, 11.0, 0.0, 10.0, -6.0, 12.0, -2.0, -4.0, 9.0, 12.0, 13.0, 2.0, -12.0, 11.0, 7.0, 6.0, -9.0, 3.0, 11.0, 10.0, -9.0, 1.0, 14.0, -12.0, 12.0, -1.0, 8.0, -3.0, 11.0, 9.0, 3.0, 10.0, -7.0, 7.0, 12.0, 5.0, -9.0, 12.0, 10.0, -19.0, 12.0, -13.0, 11.0, 6.0, 11.0, 8.0, 6.0, 8.0, -7.0, 6.0, -10.0, 10.0, 9.0, 7.0, 0.0, 8.0, 0.0, -2.0, 9.0, 11.0, -3.0, -15.0, 13.0, 10.0, 7.0, 5.0, 2.0, 11.0, -3.0, 11.0, 14.0, 318.0, 13.0, 8.0, 7.0, 11.0, -11.0, 6.0, 7.0, 6.0, -4.0, 9.0, -1.0, -4.0, 11.0, 13.0, 14.0, -19.0, 7.0, 7.0, 10.0, 2.0, -4.0, 13.0, 6.0, 0.0, -4.0, 14.0, -14.0, 8.0, 7.0, 13.0, 14.0, -11.0, -1.0, 0.0, 14.0, 3.0, -2.0, 3.0, 7.0, 9.0, -4.0, 14.0, -5.0, 11.0, -5.0, 14.0, -3.0, -8.0, 12.0, 5.0, 7.0, 11.0, -8.0, 8.0, 2.0, 11.0, -6.0, 0.0, 0.0, 4.0, 11.0, 12.0, 9.0, -13.0, 7.0, -1.0, 8.0, 13.0, -5.0, -4.0, 3.0, 11.0, 5.0, 5.0, 12.0, -6.0, 4.0, 1.0, 13.0, -11.0, 12.0, 0.0, 8.0, 9.0, -2.0, 11.0, 6.0, 6.0, -8.0, -1.0, 14.0, -8.0, 10.0, 11.0, 14.0, -18.0, 8.0, -18.0, 13.0, 11.0, 9.0, 12.0, 6.0, 10.0, -13.0, 8.0, -13.0, 12.0, 8.0, 3.0, 14.0, -14.0, 12.0, 4.0, 13.0, 1.0, -3.0, 11.0, 7.0, 10.0, -13.0, 9.0, -2.0, -3.0, 11.0, 12.0, 10.0, -15.0, 8.0, 3.0, 11.0, 7.0, -6.0, 13.0, 9.0, 5.0, -12.0, -7.0, 3.0, 11.0, 8.0, -3.0, 14.0, -3.0, 7.0, 1.0, 8.0, 12.0, -6.0, 5.0, 5.0, 10.0, -5.0, 11.0, -3.0, -2.0, 9.0, 11.0, 14.0, -15.0, 5.0, 2.0, 13.0, 4.0, -4.0, -2.0, 6.0, 0.0, 11.0, -3.0, -2.0, 11.0, 9.0, 10.0, 13.0, 7.0, -15.0, 0.0, 11.0, 8.0, -4.0, 12.0, 7.0, 4.0, -8.0, 4.0, -5.0, 8.0, 8.0, 14.0, 14.0, -19.0, 6.0, -14.0, 10.0, 7.0, 12.0, 3.0, 5.0, 9.0, -2.0, 14.0, 317.0, 11.0, 11.0, 13.0, 14.0, -14.0, 2.0, -14.0, 8.0, 11.0, 10.0, 13.0, 14.0, 4.0, -16.0, 14.0, -3.0, -5.0, 9.0, 8.0, 0.0, 7.0, 0.0, -10.0, 12.0, 1.0, 12.0, -5.0, 5.0, 5.0, 10.0, 2.0, 7.0, 10.0, -4.0, 11.0, 14.0, 8.0, -18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2201793999264392, "mean_inference_ms": 1.175024423887451, "mean_action_processing_ms": 0.07191377128623588, "mean_env_wait_ms": 0.1790926495777374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 426600, "agent_timesteps_total": 426519, "timers": {"sample_time_ms": 347.164, "sample_throughput": 15554.595, "learn_time_ms": 7070.712, "learn_throughput": 763.714, "update_time_ms": 11.533}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 650.316162109375, "policy_loss": -0.022077791392803192, "vf_loss": 650.3350830078125, "vf_explained_var": 0.06931672245264053, "kl": 0.0070799230597913265, "entropy": 0.5099924206733704, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 426600, "num_agent_steps_sampled": 426519, "num_steps_trained": 426600, "num_agent_steps_trained": 426519}, "done": false, "episodes_total": 8343, "training_iteration": 79, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-51-12", "timestamp": 1626861072, "time_this_iter_s": 7.532831907272339, "time_total_s": 575.2414164543152, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 575.2414164543152, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 21.19090909090909, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 28.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.157407407407407, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7893518518518516}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 11.0, -6.0, 13.0, -1.0, -1.0, 12.0, 5.0, 13.0, 10.0, -12.0, 4.0, 12.0, 7.0, -10.0, 6.0, 5.0, 2.0, 13.0, -5.0, 9.0, 5.0, -3.0, 4.0, 14.0, 10.0, -6.0, -3.0, -1.0, -9.0, 12.0, 13.0, 5.0, 13.0, -2.0, -1.0, 1.0, 11.0, 12.0, -9.0, 11.0, 13.0, -1.0, 5.0, 6.0, 10.0, -14.0, 13.0, 7.0, 4.0, -5.0, 9.0, -1.0, 13.0, 13.0, -10.0, -2.0, 13.0, 0.0, 4.0, 1.0, 10.0, -4.0, 8.0, 6.0, -1.0, 13.0, -3.0, -4.0, -1.0, 12.0, 8.0, -2.0, 11.0, 1.0, 5.0, 5.0, -4.0, 2.0, 12.0, 5.0, 8.0, 8.0, -6.0, 0.0, 12.0, 8.0, -5.0, 14.0, 11.0, -9.0, -1.0, 8.0, -1.0, 1.0, 7.0, 1.0, 7.0, 13.0, -6.0, 5.0, 14.0, 12.0, -16.0, -2.0, 12.0, -3.0, 8.0, 9.0, 11.0, -17.0, 12.0, 0.0, 4.0, 13.0, -2.0, 8.0, 7.0, 12.0, -12.0, 12.0, 10.0, 0.0, -6.0, 5.0, 12.0, -10.0, 8.0, 0.0, 6.0, 12.0, -3.0, 8.0, 7.0, 12.0, -12.0, -1.0, 9.0, 7.0, 0.0, 6.0, -1.0, 3.0, 7.0, 5.0, -1.0, -2.0, 13.0, 8.0, 5.0, 12.0, -10.0, 14.0, 9.0, -7.0, -1.0, 7.0, 13.0, -18.0, 13.0, 2.0, 4.0, -4.0, 13.0, 9.0, -5.0, 6.0, 5.0, -1.0, 11.0, 9.0, -4.0, -6.0, 3.0, 5.0, 13.0, 1.0, 11.0, 7.0, -4.0, 8.0, 14.0, 7.0, -14.0, -1.0, 9.0, 6.0, 1.0, -12.0, 12.0, 3.0, 12.0, -1.0, 7.0, -3.0, 12.0, -9.0, -1.0, 12.0, 13.0, 10.0, 7.0, -7.0, 5.0, 5.0, 11.0, 12.0, -13.0, -7.0, 10.0, 13.0, -1.0, 5.0, -2.0, 12.0, 0.0, 14.0, 12.0, 0.0, -10.0, 8.0, -5.0, -1.0, 13.0, 4.0, 4.0, 13.0, -6.0, 11.0, 13.0, 10.0, -19.0, 0.0, 10.0, 1.0, 5.0, 2.0, 11.0, -1.0, 3.0, 2.0, 13.0, -13.0, 13.0, 1.0, -2.0, 10.0, 6.0, -2.0, 9.0, 7.0, 1.0, 5.0, 13.0, -3.0, 0.0, 1.0, 0.0, 1.0, 13.0, 12.0, -5.0, 1.0, 7.0, 12.0, 11.0, -5.0, -3.0, -8.0, 13.0, -3.0, 13.0, 8.0, 1.0, -7.0, 13.0, 7.0, 11.0, 8.0, -11.0, 13.0, 12.0, -6.0, -4.0, -9.0, 9.0, 3.0, 12.0, 1.0, 8.0, 13.0, -7.0, 10.0, 13.0, 8.0, -16.0, -2.0, 11.0, 8.0, -2.0, 8.0, 12.0, 3.0, -8.0, -2.0, 8.0, -4.0, 13.0, 2.0, 10.0, 12.0, -9.0, 13.0, 8.0, -11.0, 5.0, 3.0, 8.0, -9.0, 13.0, 8.0, 2.0, 8.0, -3.0, 1.0, -9.0, 13.0, 10.0, 0.0, 11.0, 9.0, -5.0, 0.0, 8.0, -6.0, 13.0, 2.0, 10.0, 6.0, -3.0, 3.0, 12.0, -12.0, 12.0, 14.0, 7.0, -7.0, 1.0, 10.0, 12.0, -14.0, 7.0, 3.0, 1.0, 13.0, -2.0, -7.0, -1.0, 12.0, 11.0, 11.0, 12.0, -14.0, 6.0, 4.0, -10.0, 8.0, 13.0, 8.0, 10.0, -16.0, 13.0, 10.0, 0.0, 12.0, -7.0, -4.0, 12.0, 8.0, -1.0, 3.0, -6.0, 5.0, 13.0, 4.0, 8.0, 6.0, -3.0, 11.0, -3.0, 8.0, -1.0, 13.0, 6.0, -12.0, 8.0, -6.0, 10.0, -1.0, 12.0, -2.0, 8.0, -4.0, 13.0, 10.0, -11.0, 5.0, 11.0, 13.0, 8.0, -9.0, 3.0, 0.0, -4.0, 7.0, 12.0, -4.0, 11.0, -5.0, 13.0, 11.0, 11.0, -3.0, -4.0, 13.0, 13.0, 2.0, -12.0, 4.0, 10.0, -12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22019381704440535, "mean_inference_ms": 1.1748626443305545, "mean_action_processing_ms": 0.07189619211624793, "mean_env_wait_ms": 0.17908372837462194, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 432000, "agent_timesteps_total": 431919, "timers": {"sample_time_ms": 346.923, "sample_throughput": 15565.428, "learn_time_ms": 7068.779, "learn_throughput": 763.923, "update_time_ms": 11.482}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 26.31178092956543, "policy_loss": -0.08939829468727112, "vf_loss": 26.392799377441406, "vf_explained_var": 0.1974339336156845, "kl": 0.018618304282426834, "entropy": 0.5470947623252869, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 432000, "num_agent_steps_sampled": 431919, "num_steps_trained": 432000, "num_agent_steps_trained": 431919}, "done": false, "episodes_total": 8451, "training_iteration": 80, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-51-20", "timestamp": 1626861080, "time_this_iter_s": 7.787488698959351, "time_total_s": 583.0289051532745, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 583.0289051532745, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 20.936363636363637, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 8.0, 7.0, -9.0, 3.0, 14.0, -15.0, 13.0, 9.0, 6.0, 12.0, -12.0, 4.0, 0.0, 5.0, 6.0, 9.0, 9.0, 3.0, -6.0, -5.0, 9.0, 12.0, -1.0, 4.0, 13.0, -3.0, 1.0, 4.0, -2.0, 1.0, 12.0, 8.0, 13.0, 7.0, -13.0, -4.0, 4.0, 3.0, 12.0, 10.0, -6.0, 9.0, 2.0, 6.0, -1.0, 3.0, 7.0, 6.0, 7.0, 7.0, -5.0, 3.0, 14.0, -15.0, 13.0, 4.0, 11.0, -7.0, 7.0, -8.0, 0.0, 13.0, 10.0, 6.0, 5.0, 10.0, -6.0, -4.0, 4.0, 3.0, 12.0, 8.0, 14.0, -1.0, -6.0, -1.0, 0.0, 8.0, 8.0, 8.0, 6.0, 9.0, -8.0, 12.0, 9.0, -16.0, 10.0, 2.0, 11.0, -4.0, 6.0, 10.0, -1.0, 1.0, 5.0, 13.0, 5.0, 4.0, -7.0, -11.0, 14.0, 13.0, -1.0, -11.0, 13.0, 11.0, 2.0, -14.0, 13.0, 8.0, 8.0, 11.0, 5.0, -13.0, 12.0, -2.0, 14.0, 12.0, -9.0, 6.0, -1.0, 10.0, 0.0, 3.0, -1.0, 9.0, 4.0, -4.0, 0.0, 10.0, 9.0, -4.0, 9.0, -2.0, 12.0, -6.0, 12.0, 11.0, -2.0, 4.0, -3.0, 5.0, 9.0, 7.0, 2.0, -5.0, 11.0, -2.0, 14.0, -10.0, 13.0, 5.0, 13.0, -1.0, -2.0, 2.0, -2.0, 4.0, 11.0, 7.0, 0.0, 11.0, -3.0, 1.0, 14.0, 12.0, -12.0, 9.0, 13.0, 10.0, -17.0, 1.0, 0.0, 4.0, 10.0, 6.0, 2.0, 10.0, -3.0, -11.0, 9.0, 6.0, 11.0, 4.0, 13.0, -9.0, 7.0, 3.0, -1.0, 2.0, 11.0, 13.0, -6.0, -4.0, 12.0, 9.0, 9.0, -16.0, 13.0, 1.0, 12.0, -5.0, 7.0, 5.0, -4.0, 2.0, 12.0, 13.0, 8.0, 5.0, -11.0, 9.0, 14.0, -21.0, 13.0, 6.0, 13.0, -5.0, 1.0, 0.0, 0.0, 8.0, 7.0, 7.0, 12.0, -11.0, 7.0, -16.0, 9.0, 9.0, 13.0, 11.0, -2.0, 10.0, -4.0, 2.0, -1.0, 3.0, 11.0, 8.0, 9.0, 0.0, -2.0, -10.0, 14.0, 13.0, -2.0, 7.0, 12.0, -2.0, -2.0, 5.0, -1.0, 7.0, 4.0, 6.0, 2.0, 9.0, -2.0, 9.0, 14.0, -21.0, 13.0, -7.0, 13.0, 6.0, 3.0, 4.0, -1.0, 1.0, 11.0, 11.0, -6.0, -3.0, 13.0, -5.0, 10.0, 11.0, -1.0, -14.0, 12.0, 11.0, 6.0, 1.0, -1.0, 3.0, 12.0, 13.0, -10.0, 7.0, 5.0, 12.0, 9.0, -17.0, 11.0, 8.0, 11.0, -3.0, -1.0, 5.0, -10.0, 13.0, 7.0, 12.0, 7.0, 7.0, -11.0, -6.0, 14.0, -6.0, 13.0, 3.0, 11.0, -1.0, 2.0, -5.0, 0.0, 12.0, 8.0, 13.0, -13.0, 6.0, 9.0, 12.0, 4.0, -11.0, 10.0, -14.0, 11.0, 9.0, 9.0, -1.0, -2.0, 10.0, 8.0, 11.0, -6.0, -3.0, 13.0, -2.0, 9.0, -3.0, 11.0, 7.0, 12.0, -3.0, -1.0, -6.0, -1.0, 12.0, 10.0, 11.0, 4.0, -7.0, 7.0, 3.0, 14.0, -14.0, 12.0, 2.0, 10.0, -4.0, 7.0, -2.0, 0.0, 8.0, 9.0, 11.0, -11.0, 8.0, 7.0, -6.0, 5.0, 3.0, 13.0, -1.0, 10.0, -1.0, 7.0, 4.0, -2.0, 1.0, 12.0, 4.0, 1.0, -2.0, 12.0, 12.0, 8.0, -18.0, 13.0, 5.0, 5.0, -4.0, 9.0, -3.0, -1.0, 8.0, 11.0, 12.0, 9.0, -4.0, -2.0, -3.0, 9.0, -4.0, 13.0, 1.0, 13.0, -5.0, 6.0, -11.0, 7.0, 8.0, 11.0, 5.0, 8.0, 11.0, -9.0, 7.0, 8.0, 9.0, -9.0, 7.0, 12.0, -1.0, -3.0, 6.0, 0.0, 2.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22019887728844878, "mean_inference_ms": 1.1748208343330957, "mean_action_processing_ms": 0.07190438569544952, "mean_env_wait_ms": 0.17907962763709573, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 437400, "agent_timesteps_total": 437319, "timers": {"sample_time_ms": 347.072, "sample_throughput": 15558.747, "learn_time_ms": 7070.428, "learn_throughput": 763.744, "update_time_ms": 11.342}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 22.81594467163086, "policy_loss": -0.08075356483459473, "vf_loss": 22.888965606689453, "vf_explained_var": 0.2686344087123871, "kl": 0.01718026213347912, "entropy": 0.5000989437103271, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 437400, "num_agent_steps_sampled": 437319, "num_steps_trained": 437400, "num_agent_steps_trained": 437319}, "done": false, "episodes_total": 8559, "training_iteration": 81, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-51-28", "timestamp": 1626861088, "time_this_iter_s": 7.559355974197388, "time_total_s": 590.5882611274719, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 590.5882611274719, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 23.13636363636364, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.037037037037036, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.759259259259259}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 11.0, 1.0, -3.0, 6.0, 13.0, 5.0, -9.0, 14.0, -12.0, 9.0, 4.0, 7.0, -1.0, -2.0, 11.0, -12.0, 7.0, 11.0, 9.0, 4.0, -2.0, 1.0, 12.0, 14.0, -2.0, -7.0, 10.0, 3.0, -10.0, 11.0, 11.0, 10.0, 11.0, -11.0, 5.0, 9.0, 14.0, 6.0, -14.0, 8.0, 11.0, -12.0, 8.0, 5.0, 11.0, 3.0, -4.0, 11.0, 9.0, -11.0, 6.0, 8.0, 2.0, 7.0, -2.0, 14.0, -7.0, -1.0, 9.0, 3.0, -11.0, 12.0, 11.0, 10.0, 4.0, -10.0, 11.0, 11.0, 7.0, -15.0, 12.0, 8.0, 9.0, -9.0, 7.0, -7.0, 1.0, 11.0, 10.0, -7.0, 11.0, -1.0, 12.0, -1.0, 4.0, 11.0, 1.0, 12.0, -10.0, 1.0, 12.0, 13.0, 5.0, -11.0, 8.0, 11.0, 13.0, -10.0, 1.0, -7.0, 13.0, 1.0, 8.0, 14.0, -16.0, 5.0, 12.0, -13.0, 2.0, 13.0, 13.0, 12.0, 7.0, -6.0, 2.0, -3.0, 12.0, 2.0, 4.0, 7.0, -7.0, 7.0, 8.0, 1.0, 6.0, 10.0, -2.0, 11.0, 7.0, -8.0, 5.0, -4.0, 7.0, 4.0, 8.0, 14.0, 0.0, -10.0, 11.0, 12.0, 4.0, -12.0, 11.0, 11.0, 10.0, -13.0, 7.0, -4.0, 9.0, 6.0, 4.0, 13.0, -14.0, 8.0, 8.0, -7.0, 3.0, 12.0, 7.0, 11.0, 3.0, -12.0, 13.0, 7.0, 8.0, -8.0, 8.0, 6.0, 0.0, 2.0, 7.0, 5.0, -13.0, 10.0, 13.0, 13.0, 7.0, -9.0, 4.0, -2.0, 5.0, 11.0, 1.0, 14.0, 3.0, 9.0, -11.0, 11.0, 4.0, 12.0, -12.0, 13.0, 1.0, -9.0, 10.0, -11.0, 13.0, 12.0, 1.0, 13.0, -9.0, -1.0, 12.0, 4.0, 1.0, -2.0, 12.0, 3.0, 10.0, -3.0, 5.0, 11.0, -8.0, 5.0, 7.0, 4.0, -1.0, 10.0, 2.0, 8.0, 2.0, -6.0, 11.0, 3.0, 12.0, -10.0, 10.0, 9.0, 13.0, 5.0, -12.0, 5.0, 3.0, 8.0, -1.0, 8.0, -12.0, 10.0, 10.0, 12.0, 11.0, -20.0, 12.0, -5.0, 4.0, 3.0, 13.0, 14.0, 7.0, 4.0, -10.0, 8.0, 7.0, 10.0, -10.0, 12.0, 5.0, -13.0, 11.0, -4.0, 12.0, 7.0, 0.0, 12.0, 2.0, -7.0, 8.0, 5.0, 3.0, 9.0, -2.0, 13.0, 7.0, 6.0, -11.0, -3.0, 13.0, -1.0, 6.0, 7.0, -6.0, 2.0, 12.0, -8.0, 0.0, 11.0, 12.0, 11.0, 8.0, -8.0, 4.0, -8.0, 11.0, 11.0, 1.0, 8.0, -9.0, 10.0, 6.0, 6.0, 7.0, -2.0, 5.0, 13.0, 10.0, -13.0, 5.0, 11.0, 12.0, -14.0, 6.0, 2.0, -9.0, 11.0, 11.0, 8.0, 3.0, 10.0, -6.0, 12.0, 12.0, -15.0, 6.0, -10.0, 12.0, 7.0, 6.0, 13.0, 7.0, 6.0, -11.0, 6.0, -8.0, 7.0, 10.0, 9.0, 12.0, -1.0, -5.0, -1.0, 13.0, 11.0, -8.0, 13.0, 3.0, -6.0, 5.0, 4.0, 9.0, 10.0, -8.0, 11.0, 12.0, -19.0, 11.0, 3.0, 13.0, -14.0, 13.0, 12.0, -9.0, 7.0, 5.0, -11.0, 4.0, 12.0, 11.0, 6.0, 10.0, -9.0, 8.0, -13.0, 13.0, 12.0, 3.0, 0.0, 12.0, 7.0, -4.0, 13.0, -16.0, 12.0, 6.0, -3.0, 12.0, 3.0, 3.0, -6.0, 10.0, 3.0, 8.0, -1.0, 10.0, 7.0, -1.0, 8.0, -7.0, 7.0, 7.0, 8.0, 12.0, 1.0, -6.0, -2.0, 8.0, 6.0, 3.0, 14.0, 3.0, 6.0, -8.0, 9.0, 7.0, -12.0, 12.0, 13.0, 11.0, -9.0, 0.0, -9.0, 11.0, 5.0, 8.0, 13.0, 4.0, -8.0, 6.0, 5.0, -11.0, 10.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22023898625328237, "mean_inference_ms": 1.1750122473053808, "mean_action_processing_ms": 0.07190185262357973, "mean_env_wait_ms": 0.17909983612049452, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 442800, "agent_timesteps_total": 442719, "timers": {"sample_time_ms": 348.192, "sample_throughput": 15508.663, "learn_time_ms": 7055.685, "learn_throughput": 765.34, "update_time_ms": 11.463}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 22.755876541137695, "policy_loss": -0.08644893765449524, "vf_loss": 22.83516502380371, "vf_explained_var": 0.23485329747200012, "kl": 0.015912137925624847, "entropy": 0.49528396129608154, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 442800, "num_agent_steps_sampled": 442719, "num_steps_trained": 442800, "num_agent_steps_trained": 442719}, "done": false, "episodes_total": 8667, "training_iteration": 82, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-51-35", "timestamp": 1626861095, "time_this_iter_s": 7.410950422286987, "time_total_s": 597.9992115497589, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 597.9992115497589, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 22.00909090909091, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 37.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 323.0}, "policy_reward_mean": {"learned": 9.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -7.0, 4.0, 4.0, 4.0, -7.0, 8.0, 10.0, 11.0, 11.0, 1.0, -8.0, 7.0, 13.0, -6.0, 1.0, 14.0, -16.0, 5.0, 12.0, -1.0, 11.0, 6.0, -1.0, 11.0, -8.0, 11.0, 1.0, 13.0, 13.0, 314.0, 13.0, 10.0, -17.0, 12.0, 10.0, 12.0, 2.0, -6.0, 7.0, 4.0, 12.0, 11.0, -12.0, 11.0, 0.0, -6.0, 10.0, 11.0, -14.0, 6.0, 12.0, -8.0, 8.0, 11.0, 4.0, 7.0, 12.0, 10.0, -14.0, -10.0, 9.0, 5.0, 11.0, 10.0, -10.0, 12.0, 3.0, 6.0, 8.0, -1.0, 2.0, 10.0, 13.0, 1.0, -9.0, 12.0, 11.0, -10.0, 2.0, 6.0, 6.0, 10.0, -7.0, 9.0, 2.0, -7.0, 11.0, 11.0, 3.0, 7.0, -6.0, 13.0, 11.0, 318.0, 12.0, 10.0, -11.0, 11.0, 5.0, -6.0, 8.0, 11.0, 2.0, 1.0, -3.0, 11.0, 6.0, 13.0, 12.0, 319.0, 11.0, 5.0, -6.0, 8.0, 8.0, 6.0, 0.0, 12.0, -3.0, -13.0, 13.0, 11.0, 4.0, -1.0, 13.0, -10.0, 13.0, 12.0, -12.0, 7.0, 8.0, -13.0, 9.0, 12.0, 7.0, -3.0, 7.0, 5.0, 6.0, 13.0, 12.0, -18.0, 8.0, 11.0, -13.0, 6.0, 11.0, 3.0, 13.0, -4.0, 3.0, 14.0, -6.0, 5.0, 2.0, -2.0, 6.0, 11.0, 0.0, 13.0, -12.0, 5.0, 9.0, 13.0, 8.0, -2.0, -4.0, 10.0, 13.0, -10.0, 2.0, 13.0, 12.0, 317.0, 13.0, 3.0, 11.0, -7.0, 8.0, 4.0, 1.0, -3.0, 13.0, 12.0, 12.0, 7.0, -16.0, 13.0, -10.0, 11.0, 1.0, 10.0, -1.0, 3.0, 3.0, -6.0, 7.0, 7.0, 7.0, 12.0, 13.0, -16.0, 6.0, -1.0, 13.0, -10.0, 13.0, 5.0, -4.0, 7.0, 7.0, 2.0, 5.0, -2.0, 10.0, 12.0, 12.0, 2.0, -11.0, 13.0, 12.0, 12.0, 316.0, 12.0, -16.0, 11.0, 8.0, -7.0, 0.0, 11.0, 11.0, 12.0, -2.0, 5.0, 0.0, -6.0, 10.0, 11.0, 0.0, 8.0, -15.0, 11.0, 11.0, 6.0, 6.0, 12.0, -9.0, 12.0, 11.0, 5.0, -13.0, 9.0, 11.0, -7.0, 2.0, 8.0, 6.0, -10.0, 11.0, 7.0, 8.0, -2.0, 2.0, 11.0, 11.0, 5.0, -12.0, -11.0, 11.0, 10.0, 5.0, 12.0, -8.0, 9.0, 2.0, 6.0, 12.0, -2.0, -1.0, 12.0, 12.0, 2.0, -11.0, 13.0, 10.0, -15.0, 7.0, 7.0, -1.0, -3.0, 12.0, 2.0, 12.0, -2.0, 3.0, 13.0, 10.0, 6.0, -14.0, -3.0, 7.0, 5.0, 6.0, 12.0, -10.0, 1.0, 12.0, -5.0, 7.0, 6.0, 7.0, 13.0, 9.0, 2.0, -9.0, 11.0, 8.0, -10.0, 6.0, 14.0, -1.0, 1.0, 1.0, 11.0, 11.0, -7.0, 0.0, 11.0, 14.0, 3.0, -13.0, -4.0, 12.0, -6.0, 13.0, 8.0, -15.0, 10.0, 12.0, -1.0, 7.0, 7.0, 2.0, 12.0, 12.0, 4.0, -13.0, 10.0, 5.0, -7.0, 7.0, 13.0, 323.0, 10.0, 10.0, 9.0, -14.0, 9.0, 11.0, 13.0, 7.0, 2.0, -7.0, 13.0, 3.0, -10.0, 9.0, 9.0, -2.0, -3.0, 11.0, 8.0, 4.0, -8.0, 11.0, 11.0, 11.0, 6.0, -13.0, -1.0, 14.0, -11.0, 13.0, 5.0, -2.0, 1.0, 11.0, -6.0, 3.0, 11.0, 7.0, 8.0, -4.0, 3.0, 8.0, 13.0, 13.0, 316.0, 13.0, 14.0, -15.0, 7.0, 9.0, 11.0, 9.0, -9.0, 4.0, 13.0, 3.0, 11.0, -12.0, 13.0, 10.0, -16.0, 8.0, 14.0, -5.0, 9.0, -3.0, 9.0, 10.0, 5.0, -9.0, 11.0, 4.0, 12.0, -12.0, 11.0, -6.0, 12.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22025374741615292, "mean_inference_ms": 1.174940583874131, "mean_action_processing_ms": 0.07189945345823842, "mean_env_wait_ms": 0.17910558640744506, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 448200, "agent_timesteps_total": 448119, "timers": {"sample_time_ms": 348.571, "sample_throughput": 15491.839, "learn_time_ms": 7057.038, "learn_throughput": 765.194, "update_time_ms": 11.386}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 1349.7945556640625, "policy_loss": -0.028545789420604706, "vf_loss": 1349.820556640625, "vf_explained_var": 0.06522135436534882, "kl": 0.005999759305268526, "entropy": 0.4927893877029419, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 448200, "num_agent_steps_sampled": 448119, "num_steps_trained": 448200, "num_agent_steps_trained": 448119}, "done": false, "episodes_total": 8775, "training_iteration": 83, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-51-43", "timestamp": 1626861103, "time_this_iter_s": 7.607586622238159, "time_total_s": 605.6067981719971, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 605.6067981719971, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 21.200000000000003, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 14.0, 9.0, -9.0, 12.0, 7.0, 3.0, -7.0, 3.0, 12.0, -9.0, 9.0, 2.0, -8.0, 10.0, 11.0, 11.0, 10.0, -9.0, 3.0, 14.0, 8.0, 3.0, -10.0, 13.0, 7.0, -7.0, 2.0, 9.0, 12.0, 4.0, -10.0, -12.0, 7.0, 11.0, 9.0, 13.0, -3.0, 4.0, 1.0, 14.0, 7.0, -7.0, 1.0, 8.0, 10.0, 5.0, -8.0, 4.0, -8.0, 10.0, 9.0, 12.0, -1.0, 10.0, -6.0, 12.0, -2.0, -3.0, 8.0, 8.0, 12.0, 4.0, -9.0, 14.0, 1.0, -5.0, 5.0, 14.0, 6.0, 9.0, -14.0, 4.0, 9.0, -10.0, 12.0, 4.0, 1.0, 12.0, -2.0, 6.0, 9.0, 3.0, -3.0, 12.0, 11.0, 10.0, -18.0, 13.0, -3.0, 0.0, 5.0, 0.0, 12.0, 5.0, -2.0, 7.0, 11.0, 5.0, -8.0, 14.0, 10.0, 8.0, -17.0, 14.0, 11.0, -21.0, 11.0, 9.0, 11.0, 11.0, -16.0, 8.0, 11.0, 5.0, -9.0, 12.0, -4.0, 5.0, 2.0, 2.0, -1.0, 12.0, 2.0, -5.0, -1.0, 9.0, 12.0, 1.0, 13.0, 10.0, -9.0, 11.0, -8.0, 10.0, 2.0, 14.0, 11.0, -13.0, 3.0, 6.0, 10.0, 5.0, -6.0, 8.0, -8.0, 11.0, 4.0, 12.0, 3.0, -3.0, 3.0, 9.0, 9.0, -13.0, 10.0, 5.0, -2.0, 6.0, 6.0, 6.0, 6.0, -8.0, 11.0, 14.0, -3.0, 8.0, -4.0, 14.0, -7.0, 0.0, 8.0, 4.0, 13.0, 3.0, -5.0, -1.0, -5.0, 10.0, 11.0, 11.0, -4.0, 0.0, 8.0, 9.0, 9.0, -9.0, 6.0, -3.0, 10.0, 11.0, -3.0, -12.0, 13.0, 10.0, 4.0, 13.0, -1.0, 3.0, 0.0, 8.0, 13.0, -18.0, 12.0, 8.0, 11.0, 2.0, -6.0, 5.0, 11.0, 3.0, -4.0, 12.0, -1.0, -1.0, 5.0, 5.0, -2.0, 0.0, 12.0, 1.0, -2.0, 5.0, 11.0, 4.0, 13.0, -11.0, 9.0, 12.0, -2.0, 5.0, 0.0, -2.0, 13.0, 12.0, -8.0, 6.0, -8.0, 10.0, 7.0, 11.0, 8.0, 9.0, -13.0, 13.0, -3.0, 4.0, 1.0, 12.0, -9.0, 9.0, 3.0, -9.0, 12.0, 7.0, 5.0, 13.0, 7.0, 4.0, -9.0, 10.0, -8.0, 11.0, 2.0, 11.0, 14.0, 8.0, -18.0, 8.0, 11.0, 12.0, -16.0, 10.0, 8.0, -7.0, 4.0, 13.0, 5.0, 6.0, -9.0, 8.0, 11.0, -10.0, 6.0, 6.0, 11.0, 5.0, -7.0, 9.0, -7.0, 9.0, 4.0, 14.0, 11.0, 10.0, 320.0, 10.0, -2.0, 1.0, 6.0, 8.0, 10.0, 5.0, -8.0, 12.0, 1.0, 5.0, -3.0, 9.0, -7.0, 5.0, 8.0, 13.0, 13.0, 1.0, -12.0, 8.0, -6.0, 9.0, 4.0, 12.0, -1.0, -7.0, 11.0, 12.0, -2.0, 7.0, -2.0, 9.0, 9.0, -10.0, 7.0, 8.0, 12.0, 10.0, -15.0, -7.0, 7.0, 5.0, 10.0, 12.0, -3.0, 9.0, -3.0, 14.0, 13.0, 3.0, -15.0, -2.0, 11.0, 8.0, -2.0, 12.0, 4.0, -8.0, 7.0, 12.0, 10.0, 11.0, -18.0, 10.0, 13.0, -19.0, 11.0, -5.0, 11.0, 10.0, -1.0, 2.0, 8.0, 11.0, -6.0, 13.0, -13.0, 3.0, 12.0, 13.0, 9.0, -8.0, 1.0, 8.0, 13.0, 8.0, -14.0, 3.0, 8.0, -6.0, 10.0, 14.0, -1.0, 9.0, -7.0, 6.0, -3.0, 4.0, 8.0, 7.0, 9.0, 4.0, -5.0, 0.0, -5.0, 12.0, 8.0, 13.0, 5.0, -9.0, 6.0, 11.0, 11.0, 11.0, -18.0, 6.0, -3.0, 7.0, 5.0, 0.0, 11.0, -6.0, 10.0, 14.0, 10.0, 3.0, -12.0, 9.0, 12.0, -13.0, 7.0, 8.0, -1.0, 12.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22026736456472035, "mean_inference_ms": 1.1747146451814627, "mean_action_processing_ms": 0.07189351484892417, "mean_env_wait_ms": 0.1791152320627044, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 453600, "agent_timesteps_total": 453519, "timers": {"sample_time_ms": 347.95, "sample_throughput": 15519.457, "learn_time_ms": 7084.198, "learn_throughput": 762.26, "update_time_ms": 11.434}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 215.70359802246094, "policy_loss": -0.032151009887456894, "vf_loss": 215.7313995361328, "vf_explained_var": 0.20674674212932587, "kl": 0.009637963026762009, "entropy": 0.5158950686454773, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 453600, "num_agent_steps_sampled": 453519, "num_steps_trained": 453600, "num_agent_steps_trained": 453519}, "done": false, "episodes_total": 8883, "training_iteration": 84, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-51-51", "timestamp": 1626861111, "time_this_iter_s": 7.617825746536255, "time_total_s": 613.2246239185333, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cf28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 613.2246239185333, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 21.645454545454548, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 10.0, -6.0, 3.0, 14.0, -10.0, 3.0, 8.0, 11.0, 10.0, -19.0, 13.0, 9.0, 8.0, 0.0, -2.0, 8.0, 8.0, -8.0, 7.0, -10.0, 8.0, 10.0, 7.0, 12.0, -15.0, 5.0, 13.0, 7.0, 4.0, 6.0, -2.0, 13.0, 6.0, -10.0, 6.0, 12.0, -7.0, 5.0, 5.0, 12.0, 4.0, -13.0, 12.0, 7.0, 4.0, -7.0, 11.0, 8.0, 9.0, -9.0, 7.0, 3.0, -2.0, 3.0, 11.0, 12.0, -6.0, -3.0, 12.0, 9.0, 13.0, 0.0, -7.0, 8.0, 9.0, -6.0, 4.0, -3.0, 7.0, -2.0, 13.0, 11.0, 6.0, 6.0, -8.0, 4.0, 13.0, 1.0, -3.0, -9.0, 11.0, 7.0, 6.0, 2.0, -9.0, 9.0, 13.0, 11.0, -13.0, 12.0, 5.0, 7.0, 3.0, 6.0, -1.0, 11.0, 5.0, -5.0, 4.0, 5.0, 1.0, 11.0, -2.0, 8.0, 7.0, -7.0, 7.0, 3.0, 7.0, 7.0, -2.0, -1.0, 3.0, 6.0, 7.0, 10.0, 7.0, 0.0, -2.0, 13.0, 7.0, 4.0, -9.0, 1.0, 13.0, 2.0, -1.0, 13.0, -7.0, 8.0, 1.0, -8.0, 10.0, 2.0, 11.0, -1.0, 6.0, -2.0, 12.0, 9.0, 6.0, 2.0, -2.0, 14.0, 5.0, -15.0, 11.0, -2.0, 7.0, 12.0, -2.0, 12.0, 8.0, -13.0, 8.0, 8.0, 13.0, 1.0, -7.0, 13.0, 3.0, -12.0, 11.0, -10.0, 12.0, 7.0, 6.0, -6.0, 7.0, 1.0, 13.0, 9.0, 13.0, -5.0, -2.0, 6.0, 1.0, -3.0, 11.0, 12.0, 0.0, -7.0, 10.0, -5.0, 11.0, -4.0, 13.0, 4.0, 5.0, 7.0, -1.0, 13.0, 9.0, -12.0, 5.0, -5.0, 10.0, 3.0, 7.0, 13.0, 11.0, 320.0, 11.0, 4.0, 8.0, -4.0, 7.0, 13.0, 6.0, -5.0, 1.0, -6.0, 0.0, 10.0, 11.0, -2.0, 1.0, 11.0, 5.0, 7.0, 5.0, 5.0, -2.0, -6.0, 6.0, 9.0, 6.0, 13.0, -10.0, 4.0, 8.0, -2.0, 1.0, 9.0, 7.0, 5.0, 5.0, 7.0, -2.0, 8.0, 11.0, -5.0, 1.0, 10.0, 4.0, 6.0, -5.0, -3.0, 4.0, 6.0, 8.0, 8.0, 12.0, 2.0, -7.0, 13.0, 6.0, -8.0, 4.0, 11.0, 11.0, 2.0, -9.0, 13.0, -3.0, 10.0, -5.0, 4.0, 8.0, 5.0, -2.0, 7.0, 6.0, -10.0, 12.0, 6.0, 9.0, 4.0, -4.0, -2.0, 4.0, 4.0, 9.0, 9.0, 13.0, 1.0, -8.0, 14.0, 3.0, -14.0, 12.0, 2.0, -5.0, 6.0, 12.0, 9.0, -17.0, 10.0, 13.0, 2.0, 8.0, -7.0, 12.0, 9.0, 4.0, -4.0, 6.0, 7.0, -6.0, 5.0, 9.0, -7.0, 5.0, 10.0, 7.0, 8.0, 2.0, 6.0, -1.0, 12.0, 4.0, -13.0, 12.0, 4.0, 5.0, 11.0, -5.0, 10.0, 5.0, -13.0, 13.0, 3.0, 8.0, 6.0, -2.0, -8.0, 11.0, 5.0, 7.0, 10.0, 12.0, -1.0, -6.0, 8.0, 6.0, 5.0, -4.0, 4.0, 11.0, 2.0, -2.0, 14.0, 11.0, 317.0, 12.0, 6.0, 11.0, 2.0, -4.0, 12.0, -13.0, 3.0, 13.0, 8.0, 13.0, 3.0, -9.0, 7.0, 11.0, 2.0, -5.0, 5.0, 0.0, -1.0, 11.0, -12.0, 11.0, 11.0, 5.0, 9.0, 8.0, 0.0, -2.0, 10.0, 5.0, -7.0, 7.0, 5.0, 4.0, 10.0, -4.0, -2.0, 0.0, 4.0, 13.0, 4.0, 13.0, 1.0, -3.0, 11.0, 3.0, -11.0, 12.0, 5.0, 6.0, 11.0, -7.0, 13.0, -14.0, 9.0, 7.0, 5.0, 5.0, -6.0, 11.0, 6.0, 1.0, 9.0, -1.0, 2.0, 3.0, -2.0, 12.0, 12.0, 12.0, -17.0, 8.0, 9.0, 12.0, 0.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22027690710614203, "mean_inference_ms": 1.174905299844323, "mean_action_processing_ms": 0.07188611673107455, "mean_env_wait_ms": 0.17913151100863292, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 459000, "agent_timesteps_total": 458919, "timers": {"sample_time_ms": 349.956, "sample_throughput": 15430.52, "learn_time_ms": 7086.335, "learn_throughput": 762.03, "update_time_ms": 11.477}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 351.0795593261719, "policy_loss": -0.024300144985318184, "vf_loss": 351.10028076171875, "vf_explained_var": 0.09774276614189148, "kl": 0.007948425598442554, "entropy": 0.47394460439682007, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 459000, "num_agent_steps_sampled": 458919, "num_steps_trained": 459000, "num_agent_steps_trained": 458919}, "done": false, "episodes_total": 8991, "training_iteration": 85, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-51-58", "timestamp": 1626861118, "time_this_iter_s": 7.650905609130859, "time_total_s": 620.8755295276642, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70216c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 620.8755295276642, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 21.63636363636364, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 354.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 13.0, 12.0, -14.0, 5.0, -1.0, 2.0, 9.0, 12.0, 13.0, 316.0, 13.0, 6.0, 8.0, 11.0, -9.0, 9.0, 8.0, 11.0, -13.0, 10.0, -4.0, 4.0, 5.0, 0.0, 11.0, 10.0, -6.0, 6.0, 9.0, -4.0, 4.0, 7.0, 7.0, -11.0, 12.0, 11.0, -5.0, 9.0, 0.0, -16.0, 9.0, 11.0, 11.0, -10.0, 6.0, 7.0, 12.0, 13.0, -3.0, 10.0, -5.0, 8.0, -7.0, 13.0, 1.0, -6.0, 13.0, 11.0, -3.0, 8.0, 14.0, 11.0, -17.0, 11.0, -5.0, 11.0, -2.0, 13.0, -5.0, -2.0, 9.0, 2.0, 10.0, 13.0, -10.0, -16.0, 13.0, 7.0, 12.0, 12.0, -5.0, -3.0, 11.0, 11.0, -7.0, 5.0, 6.0, 8.0, 9.0, 4.0, -6.0, 2.0, 12.0, -10.0, 11.0, 12.0, -14.0, 12.0, 5.0, 0.0, -1.0, 10.0, 6.0, 11.0, 9.0, 8.0, -13.0, -4.0, 14.0, 11.0, -6.0, 3.0, 11.0, 10.0, -9.0, 12.0, -2.0, 13.0, -8.0, 1.0, 10.0, 11.0, -7.0, 5.0, 6.0, 6.0, -1.0, 12.0, 9.0, 8.0, -14.0, 8.0, -1.0, -5.0, 13.0, -5.0, 10.0, 3.0, 7.0, 8.0, 9.0, 10.0, -11.0, 12.0, 4.0, 12.0, -13.0, -9.0, 9.0, 6.0, 9.0, 13.0, 12.0, 11.0, -21.0, 12.0, 7.0, 11.0, -15.0, -7.0, 6.0, 5.0, 11.0, 8.0, -6.0, 3.0, 10.0, 7.0, 13.0, 7.0, -12.0, -6.0, 13.0, 11.0, -2.0, 9.0, 5.0, 12.0, -11.0, 8.0, -4.0, 2.0, 9.0, -4.0, 10.0, 10.0, -1.0, 13.0, 4.0, -5.0, 3.0, 10.0, -10.0, 6.0, 9.0, 9.0, -1.0, 0.0, 7.0, -11.0, 12.0, 5.0, 9.0, 13.0, 4.0, -11.0, 9.0, 7.0, 13.0, 11.0, -16.0, -5.0, 11.0, 9.0, 0.0, 7.0, -8.0, 5.0, 11.0, -7.0, 7.0, 11.0, 4.0, 7.0, -11.0, 6.0, 13.0, 14.0, 8.0, 13.0, -20.0, -3.0, 11.0, 4.0, 3.0, 4.0, 8.0, 11.0, -7.0, 2.0, -1.0, 9.0, 5.0, 5.0, 13.0, 3.0, -6.0, 8.0, 13.0, 8.0, -14.0, 13.0, 6.0, 3.0, -6.0, 13.0, 9.0, 11.0, -18.0, -1.0, 8.0, 5.0, 3.0, 12.0, 11.0, 12.0, -20.0, -17.0, 8.0, 12.0, 12.0, 13.0, 12.0, 11.0, -21.0, -5.0, 13.0, 9.0, -2.0, 7.0, 12.0, 12.0, -16.0, 5.0, 8.0, -3.0, 6.0, 7.0, 5.0, 10.0, -7.0, -7.0, 13.0, 4.0, 5.0, 7.0, 12.0, 3.0, -7.0, 3.0, 8.0, -5.0, 9.0, 9.0, 9.0, 3.0, -6.0, -4.0, 6.0, 0.0, 13.0, 12.0, -7.0, 3.0, 7.0, 5.0, 9.0, 11.0, -9.0, 11.0, 4.0, 10.0, -10.0, 6.0, -1.0, -3.0, 13.0, 6.0, 9.0, 12.0, -12.0, -4.0, 11.0, -3.0, 11.0, 13.0, 12.0, -12.0, 2.0, 11.0, -1.0, 13.0, -8.0, 3.0, -1.0, 3.0, 10.0, -13.0, 8.0, 11.0, 9.0, 8.0, -2.0, 6.0, 3.0, 9.0, -1.0, -2.0, 9.0, 0.0, -5.0, 10.0, 10.0, 5.0, -5.0, 6.0, 10.0, 12.0, 11.0, -13.0, 5.0, 9.0, -5.0, 3.0, 8.0, -8.0, 12.0, 12.0, -1.0, 2.0, 5.0, 11.0, -3.0, 8.0, -6.0, 9.0, 4.0, 13.0, -7.0, 9.0, 0.0, 7.0, 12.0, 10.0, -14.0, 0.0, 11.0, -2.0, 6.0, 13.0, -17.0, 8.0, 11.0, 11.0, 13.0, 9.0, -18.0, 7.0, 4.0, 10.0, -6.0, 6.0, 8.0, -7.0, 9.0, 6.0, 9.0, 12.0, -12.0, 8.0, -5.0, -1.0, 13.0, 1.0, 13.0, -5.0, 6.0, -5.0, 12.0, -2.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22028987670889505, "mean_inference_ms": 1.1749237664595846, "mean_action_processing_ms": 0.0718871552467061, "mean_env_wait_ms": 0.1791091639693508, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 464400, "agent_timesteps_total": 464319, "timers": {"sample_time_ms": 350.777, "sample_throughput": 15394.412, "learn_time_ms": 7082.357, "learn_throughput": 762.458, "update_time_ms": 11.679}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 239.77651977539062, "policy_loss": -0.03736867010593414, "vf_loss": 239.80911254882812, "vf_explained_var": 0.1030077263712883, "kl": 0.010667056776583195, "entropy": 0.5591278076171875, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 464400, "num_agent_steps_sampled": 464319, "num_steps_trained": 464400, "num_agent_steps_trained": 464319}, "done": false, "episodes_total": 9099, "training_iteration": 86, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-52-06", "timestamp": 1626861126, "time_this_iter_s": 7.599623441696167, "time_total_s": 628.4751529693604, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7027b158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 628.4751529693604, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 21.009999999999998, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 12.0, -2.0, 4.0, 10.0, -1.0, -6.0, 12.0, -15.0, 12.0, 7.0, 11.0, 13.0, -17.0, 6.0, 13.0, 6.0, 0.0, 11.0, -2.0, -4.0, 8.0, 2.0, 9.0, -4.0, 12.0, -5.0, 12.0, 12.0, -12.0, 2.0, 13.0, 2.0, 8.0, 6.0, -1.0, 4.0, -2.0, 2.0, 11.0, -12.0, 10.0, 5.0, 12.0, -1.0, 3.0, 6.0, 7.0, -12.0, 10.0, 11.0, 6.0, 8.0, -9.0, 6.0, 10.0, 6.0, 9.0, -6.0, 6.0, -3.0, 8.0, 3.0, 7.0, 3.0, 12.0, 6.0, -6.0, 6.0, -2.0, -1.0, 12.0, -13.0, 11.0, 5.0, 12.0, -4.0, 1.0, 8.0, 10.0, -6.0, 13.0, 11.0, -3.0, -8.0, 10.0, 2.0, 11.0, -14.0, 10.0, 8.0, 11.0, 14.0, -19.0, 12.0, 8.0, 7.0, 10.0, 3.0, -5.0, 10.0, -8.0, 0.0, 13.0, 1.0, 0.0, 2.0, 12.0, 13.0, -10.0, 0.0, 12.0, -14.0, 7.0, 11.0, 11.0, 7.0, -2.0, 6.0, 4.0, 0.0, -4.0, 7.0, 12.0, -2.0, 2.0, 2.0, 13.0, -14.0, 11.0, 11.0, 7.0, 10.0, 13.0, 321.0, 12.0, -10.0, 11.0, 5.0, 9.0, 11.0, -7.0, 0.0, 11.0, -9.0, 8.0, 4.0, 12.0, -3.0, 8.0, 1.0, 9.0, -14.0, 11.0, 10.0, 8.0, 13.0, -17.0, 6.0, 13.0, 5.0, -4.0, 5.0, 9.0, -10.0, 13.0, 0.0, 12.0, -12.0, 9.0, 6.0, 12.0, 14.0, -9.0, 2.0, 8.0, 0.0, 10.0, -3.0, 8.0, -10.0, 13.0, 4.0, 8.0, -13.0, 13.0, 8.0, 7.0, 11.0, -7.0, 2.0, 9.0, 7.0, 12.0, -16.0, 12.0, -10.0, 13.0, 0.0, 12.0, -3.0, 14.0, -8.0, 12.0, 13.0, -9.0, -2.0, 13.0, 6.0, 8.0, -3.0, 4.0, -5.0, 8.0, 4.0, 8.0, -5.0, 13.0, 1.0, 6.0, -1.0, -2.0, 7.0, 11.0, 1.0, 12.0, -5.0, 7.0, -3.0, 6.0, 1.0, 11.0, 2.0, 9.0, -8.0, 12.0, 14.0, -7.0, 1.0, 7.0, 4.0, 10.0, -5.0, 6.0, -8.0, 9.0, 2.0, 12.0, -15.0, 10.0, 9.0, 11.0, 12.0, -14.0, 4.0, 13.0, 4.0, -8.0, 7.0, 12.0, -4.0, 8.0, 11.0, 0.0, 0.0, 13.0, -9.0, 11.0, -2.0, -2.0, 6.0, 13.0, 8.0, 2.0, 7.0, -2.0, -7.0, 8.0, 3.0, 11.0, 4.0, 13.0, -8.0, 6.0, -2.0, 1.0, 3.0, 13.0, -21.0, 14.0, 13.0, 9.0, -9.0, 11.0, 3.0, 10.0, -11.0, 11.0, 3.0, 12.0, 13.0, -19.0, 13.0, 8.0, 0.0, -1.0, 11.0, 5.0, -4.0, 13.0, -6.0, 12.0, -13.0, 8.0, 8.0, 12.0, 14.0, 316.0, 12.0, 12.0, -15.0, 12.0, 10.0, 8.0, 11.0, 13.0, -1.0, -8.0, 1.0, 6.0, -4.0, 12.0, 13.0, -15.0, 4.0, 13.0, 2.0, 10.0, 9.0, -6.0, 2.0, -2.0, 3.0, 12.0, -11.0, 11.0, 7.0, 8.0, -1.0, 7.0, 0.0, 9.0, -2.0, 11.0, -7.0, 13.0, -4.0, 9.0, 4.0, 6.0, 5.0, 11.0, -9.0, 8.0, 12.0, -17.0, 8.0, 12.0, -10.0, 13.0, 4.0, 8.0, -2.0, 7.0, 1.0, 9.0, -2.0, 12.0, -7.0, 12.0, -1.0, 3.0, 1.0, 12.0, -7.0, 12.0, 5.0, 5.0, -3.0, 8.0, 4.0, 6.0, -2.0, 10.0, -5.0, 12.0, -1.0, -5.0, 13.0, 8.0, 3.0, 13.0, 6.0, -7.0, -10.0, 13.0, 1.0, 11.0, 9.0, 6.0, -11.0, 11.0, 0.0, 2.0, 7.0, 6.0, -6.0, 0.0, 11.0, 10.0, 7.0, -6.0, 5.0, 9.0, 0.0, 11.0, -7.0, 11.0, 11.0, -11.0, 5.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2203072137675552, "mean_inference_ms": 1.174733917293196, "mean_action_processing_ms": 0.07188134607031052, "mean_env_wait_ms": 0.1791109595023835, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 469800, "agent_timesteps_total": 469719, "timers": {"sample_time_ms": 350.838, "sample_throughput": 15391.74, "learn_time_ms": 7100.345, "learn_throughput": 760.526, "update_time_ms": 11.94}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 484.354248046875, "policy_loss": -0.038212042301893234, "vf_loss": 484.3887634277344, "vf_explained_var": 0.14926956593990326, "kl": 0.008201810531318188, "entropy": 0.49643513560295105, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 469800, "num_agent_steps_sampled": 469719, "num_steps_trained": 469800, "num_agent_steps_trained": 469719}, "done": false, "episodes_total": 9207, "training_iteration": 87, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-52-14", "timestamp": 1626861134, "time_this_iter_s": 7.614586353302002, "time_total_s": 636.0897393226624, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 636.0897393226624, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 21.127272727272725, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, -3.0, 13.0, 7.0, -4.0, 13.0, -1.0, 7.0, 7.0, -3.0, 13.0, -2.0, 0.0, -8.0, 12.0, 11.0, -9.0, -2.0, 13.0, 13.0, -7.0, 14.0, -1.0, 9.0, -10.0, 8.0, 12.0, 5.0, -11.0, 11.0, 4.0, 11.0, 9.0, -15.0, 13.0, 8.0, -3.0, 13.0, 3.0, 2.0, 7.0, 9.0, 12.0, -13.0, -7.0, 5.0, 9.0, 8.0, 7.0, 3.0, -6.0, 11.0, -4.0, 14.0, 2.0, 3.0, 5.0, 7.0, -8.0, 11.0, -5.0, -2.0, 12.0, 10.0, -14.0, 6.0, 10.0, 13.0, -13.0, 12.0, 4.0, 12.0, 3.0, -3.0, 11.0, 4.0, -5.0, -3.0, 11.0, 12.0, 5.0, 4.0, 8.0, -2.0, 10.0, 12.0, -8.0, 1.0, -6.0, 4.0, 13.0, 4.0, -16.0, 6.0, 12.0, 13.0, -3.0, 3.0, 13.0, 2.0, -5.0, 14.0, -3.0, 9.0, 8.0, -15.0, 11.0, 11.0, 7.0, -3.0, 6.0, 5.0, 6.0, -1.0, -3.0, 13.0, -7.0, 14.0, 1.0, 7.0, 4.0, -5.0, 12.0, 4.0, 2.0, -6.0, 8.0, 11.0, 4.0, -12.0, 10.0, 13.0, -11.0, 13.0, 5.0, 8.0, -15.0, 6.0, 13.0, 11.0, 2.0, -8.0, 11.0, 10.0, 10.0, 5.0, 6.0, -6.0, -4.0, 14.0, 3.0, 2.0, -4.0, -5.0, 13.0, 11.0, 2.0, -4.0, 7.0, 10.0, 9.0, -16.0, 9.0, 13.0, 11.0, 9.0, -8.0, 3.0, 7.0, -2.0, 11.0, -1.0, -13.0, 12.0, 7.0, 9.0, 6.0, -13.0, 13.0, 9.0, -5.0, 14.0, 2.0, 4.0, -12.0, 8.0, 13.0, 6.0, 8.0, 12.0, -15.0, 10.0, 4.0, -7.0, 8.0, 10.0, 9.0, 14.0, -10.0, 2.0, 5.0, 9.0, 12.0, -11.0, 3.0, -8.0, 9.0, 11.0, 10.0, 8.0, 11.0, -14.0, 13.0, 14.0, 0.0, -12.0, 11.0, 2.0, 10.0, -8.0, 8.0, -7.0, 9.0, 5.0, 5.0, 2.0, 13.0, -5.0, 9.0, 14.0, -10.0, 2.0, 8.0, -14.0, 10.0, 11.0, 1.0, -4.0, 5.0, 13.0, -1.0, 5.0, -2.0, 13.0, 12.0, 14.0, 6.0, -17.0, 6.0, -13.0, 10.0, 12.0, -10.0, 10.0, 5.0, 10.0, 6.0, -11.0, 13.0, 7.0, -5.0, 14.0, 3.0, 3.0, 12.0, 13.0, 9.0, -19.0, 3.0, 10.0, -4.0, 6.0, 7.0, -10.0, 11.0, 7.0, -6.0, 13.0, 0.0, 8.0, 6.0, 8.0, 13.0, -12.0, -7.0, -1.0, 11.0, 12.0, 10.0, 6.0, -5.0, 4.0, 10.0, -6.0, 6.0, 5.0, 0.0, -5.0, 9.0, 11.0, -7.0, 8.0, 3.0, 11.0, -3.0, -3.0, 12.0, 9.0, -12.0, 14.0, 6.0, 7.0, 6.0, -5.0, 9.0, 5.0, 4.0, -1.0, 2.0, 10.0, 10.0, -8.0, 8.0, 5.0, -1.0, 14.0, 11.0, -9.0, 2.0, 5.0, 12.0, -4.0, 5.0, 12.0, -8.0, 6.0, -12.0, 2.0, 13.0, 12.0, -8.0, 12.0, 8.0, 3.0, -7.0, 7.0, 10.0, 5.0, 0.0, -2.0, 6.0, 11.0, 0.0, 7.0, 13.0, -5.0, -9.0, 14.0, 1.0, 9.0, 6.0, -5.0, 7.0, 7.0, 3.0, -9.0, 13.0, 8.0, 9.0, -5.0, 13.0, -2.0, 11.0, 11.0, -8.0, 1.0, 5.0, -13.0, 12.0, 11.0, -6.0, -1.0, 12.0, 10.0, 6.0, 6.0, 11.0, -8.0, 12.0, 13.0, -2.0, -8.0, 4.0, -6.0, 9.0, 8.0, 0.0, -2.0, 7.0, 10.0, 6.0, -7.0, 3.0, 13.0, -5.0, 14.0, 6.0, 0.0, 12.0, 8.0, 4.0, -9.0, -4.0, -1.0, 9.0, 11.0, 5.0, 6.0, 9.0, -5.0, -10.0, 12.0, 6.0, 7.0, -6.0, 9.0, 11.0, 1.0, -11.0, 10.0, 4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2202384614529958, "mean_inference_ms": 1.1749191892554012, "mean_action_processing_ms": 0.07189891290220872, "mean_env_wait_ms": 0.17914242405270497, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 475200, "agent_timesteps_total": 475119, "timers": {"sample_time_ms": 351.661, "sample_throughput": 15355.694, "learn_time_ms": 7111.046, "learn_throughput": 759.382, "update_time_ms": 12.1}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 32.75707244873047, "policy_loss": -0.08408009260892868, "vf_loss": 32.83270263671875, "vf_explained_var": 0.20134073495864868, "kl": 0.018784530460834503, "entropy": 0.48285773396492004, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 475200, "num_agent_steps_sampled": 475119, "num_steps_trained": 475200, "num_agent_steps_trained": 475119}, "done": false, "episodes_total": 9315, "training_iteration": 88, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-52-21", "timestamp": 1626861141, "time_this_iter_s": 7.6316750049591064, "time_total_s": 643.7214143276215, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70216048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 643.7214143276215, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 21.05454545454546, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 33.861111111111114, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 8.465277777777779}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 0.0, 3.0, 4.0, -19.0, 10.0, 12.0, 12.0, 12.0, 9.0, -9.0, 3.0, -1.0, -2.0, 6.0, 12.0, -17.0, 8.0, 11.0, 13.0, 318.0, 11.0, 11.0, 12.0, 11.0, 14.0, -17.0, 7.0, 12.0, -2.0, 3.0, 2.0, 12.0, 13.0, -18.0, 8.0, 2.0, 6.0, -4.0, 11.0, 10.0, 13.0, -11.0, 3.0, 2.0, 11.0, -8.0, 10.0, -1.0, 13.0, -5.0, 8.0, -10.0, 2.0, 12.0, 11.0, 12.0, 13.0, -3.0, -7.0, -3.0, -2.0, 8.0, 12.0, 12.0, 8.0, -7.0, 2.0, 3.0, -4.0, 5.0, 11.0, 12.0, 1.0, -4.0, 6.0, 2.0, 11.0, -10.0, 12.0, 4.0, 5.0, -5.0, 11.0, 7.0, -10.0, 10.0, 8.0, 9.0, 9.0, -9.0, 6.0, 12.0, 8.0, -12.0, 7.0, 4.0, 9.0, 10.0, -8.0, 1.0, -6.0, 9.0, 11.0, 12.0, 14.0, -15.0, 4.0, 6.0, -3.0, 9.0, 3.0, 8.0, -12.0, 10.0, 9.0, 7.0, -8.0, 7.0, 9.0, 5.0, 14.0, -6.0, 2.0, 0.0, -2.0, 7.0, 10.0, 13.0, 12.0, 5.0, -15.0, 6.0, -8.0, 6.0, 11.0, 11.0, 13.0, -8.0, -1.0, 6.0, -7.0, 6.0, 10.0, 2.0, -11.0, 11.0, 13.0, 5.0, -8.0, 8.0, 10.0, 12.0, 6.0, 11.0, -14.0, -4.0, -2.0, 10.0, 11.0, 12.0, 13.0, -1.0, -9.0, 319.0, 12.0, 11.0, 13.0, 7.0, 13.0, -4.0, -1.0, 1.0, -2.0, 4.0, 12.0, 8.0, 12.0, 8.0, -13.0, 0.0, -5.0, 7.0, 13.0, 6.0, 13.0, -6.0, 2.0, 7.0, -2.0, 8.0, 2.0, 6.0, 13.0, -11.0, 7.0, 2.0, -11.0, 12.0, 12.0, 4.0, 14.0, 8.0, -11.0, 7.0, -2.0, 5.0, 5.0, 5.0, 14.0, -2.0, -2.0, 5.0, 7.0, 12.0, -9.0, -4.0, 13.0, 9.0, -3.0, 2.0, -3.0, 11.0, 5.0, 12.0, 13.0, 318.0, 13.0, 7.0, -8.0, 6.0, 10.0, 9.0, 10.0, 1.0, -5.0, -5.0, -2.0, 11.0, 11.0, 12.0, 13.0, 5.0, -15.0, -13.0, 6.0, 10.0, 12.0, -3.0, 12.0, 1.0, 5.0, 4.0, -7.0, 5.0, 13.0, 12.0, 13.0, 316.0, 13.0, -12.0, 4.0, 12.0, 11.0, 10.0, 7.0, -6.0, 4.0, 7.0, -2.0, 5.0, 5.0, 7.0, 13.0, -14.0, 9.0, 320.0, 12.0, 11.0, 12.0, 10.0, 13.0, -7.0, -1.0, 1.0, -2.0, 4.0, 12.0, 7.0, -3.0, 6.0, 5.0, -10.0, 8.0, 4.0, 13.0, 12.0, 10.0, -8.0, 1.0, 7.0, -7.0, 3.0, 12.0, 2.0, 13.0, -12.0, 12.0, 6.0, -6.0, 9.0, 6.0, 11.0, 13.0, -11.0, 2.0, 5.0, 11.0, -14.0, 13.0, 3.0, 10.0, 7.0, -5.0, -10.0, 10.0, 10.0, 5.0, 11.0, 13.0, -4.0, -5.0, -8.0, -1.0, 11.0, 13.0, 3.0, -1.0, 7.0, 6.0, -11.0, 11.0, 4.0, 11.0, 8.0, 12.0, -6.0, 1.0, -2.0, -5.0, 10.0, 12.0, 2.0, -10.0, 11.0, 12.0, -16.0, 12.0, 8.0, 11.0, 9.0, 14.0, -9.0, 1.0, 1.0, -2.0, 4.0, 12.0, 12.0, 13.0, 318.0, 12.0, -17.0, 11.0, 10.0, 11.0, 8.0, 11.0, -10.0, 6.0, -8.0, -2.0, 12.0, 13.0, 8.0, 13.0, 4.0, -10.0, 0.0, -8.0, 11.0, 12.0, 8.0, 9.0, -13.0, 11.0, -1.0, 10.0, -7.0, 13.0, 12.0, 12.0, -7.0, -2.0, -17.0, 10.0, 10.0, 12.0, 8.0, 14.0, -18.0, 11.0, 3.0, -3.0, 4.0, 11.0, 10.0, 14.0, -17.0, 8.0, -13.0, 5.0, 12.0, 11.0, 13.0, 6.0, -11.0, 7.0, -7.0, 11.0, -1.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2200696208156284, "mean_inference_ms": 1.1749643812858626, "mean_action_processing_ms": 0.07189608842623899, "mean_env_wait_ms": 0.17914337100485847, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 480600, "agent_timesteps_total": 480573, "timers": {"sample_time_ms": 351.458, "sample_throughput": 15364.576, "learn_time_ms": 7120.662, "learn_throughput": 758.356, "update_time_ms": 12.111}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 1245.8787841796875, "policy_loss": -0.028250671923160553, "vf_loss": 1245.9036865234375, "vf_explained_var": 0.05786091089248657, "kl": 0.0072616892866790295, "entropy": 0.484146386384964, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 480600, "num_agent_steps_sampled": 480573, "num_steps_trained": 480600, "num_agent_steps_trained": 480573}, "done": false, "episodes_total": 9423, "training_iteration": 89, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-52-29", "timestamp": 1626861149, "time_this_iter_s": 7.632198095321655, "time_total_s": 651.3536124229431, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70216bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 651.3536124229431, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 20.890909090909094, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.4, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, -1.0, 9.0, 2.0, -15.0, 12.0, 9.0, 9.0, 8.0, 12.0, -7.0, 2.0, 7.0, 7.0, 8.0, -7.0, -13.0, 10.0, 12.0, 6.0, 13.0, 7.0, -7.0, 2.0, 11.0, -5.0, 0.0, 9.0, 13.0, -2.0, -9.0, 13.0, 13.0, 8.0, 8.0, -14.0, 5.0, 13.0, -15.0, 12.0, 12.0, -5.0, -1.0, 9.0, 13.0, 1.0, -4.0, 5.0, 11.0, -8.0, 1.0, 11.0, 1.0, -4.0, 10.0, 8.0, 13.0, 4.0, -6.0, 4.0, 6.0, 3.0, -5.0, 11.0, 3.0, -8.0, 7.0, 13.0, 8.0, 10.0, -12.0, 9.0, 14.0, 0.0, -11.0, 12.0, -1.0, 7.0, -3.0, 12.0, 13.0, -1.0, 11.0, -8.0, 5.0, 10.0, 5.0, -5.0, 4.0, 9.0, -5.0, 7.0, 10.0, 5.0, -4.0, 4.0, 7.0, -7.0, 8.0, 7.0, -3.0, 8.0, -3.0, 13.0, 8.0, -4.0, 8.0, 3.0, 14.0, -12.0, 3.0, 10.0, -1.0, 7.0, -4.0, 13.0, 8.0, -5.0, 8.0, 4.0, 3.0, 5.0, -5.0, 12.0, 5.0, 2.0, -3.0, 11.0, 13.0, 2.0, 10.0, -10.0, 3.0, -8.0, 10.0, 10.0, 7.0, 11.0, -6.0, 3.0, 13.0, -8.0, 9.0, 1.0, 14.0, -4.0, 7.0, -2.0, 9.0, -5.0, 6.0, 5.0, 9.0, 4.0, 8.0, -6.0, 8.0, -10.0, 5.0, 12.0, -7.0, 11.0, -2.0, 13.0, 13.0, 7.0, -5.0, 0.0, 9.0, 6.0, 2.0, -2.0, 9.0, -12.0, 9.0, 9.0, 12.0, 0.0, -4.0, 7.0, 1.0, -3.0, 5.0, 12.0, 2.0, -3.0, 7.0, 9.0, 13.0, 8.0, 8.0, -14.0, 9.0, 6.0, -11.0, 11.0, 10.0, -8.0, 4.0, 9.0, 13.0, 3.0, 7.0, -8.0, 7.0, 11.0, -9.0, 6.0, -9.0, 6.0, 9.0, 9.0, 13.0, -1.0, -4.0, 7.0, 14.0, -12.0, 10.0, 3.0, -10.0, 6.0, 6.0, 13.0, 13.0, 7.0, -5.0, 0.0, 3.0, 5.0, 9.0, -2.0, -1.0, 5.0, -2.0, 13.0, 13.0, 6.0, -4.0, 0.0, 9.0, 8.0, -10.0, 8.0, 4.0, -10.0, 8.0, 13.0, 8.0, 8.0, 8.0, -9.0, 6.0, -11.0, 10.0, 10.0, -3.0, 4.0, 10.0, 4.0, 13.0, 6.0, -5.0, 1.0, 6.0, 1.0, -4.0, 12.0, 2.0, 9.0, -2.0, 6.0, 13.0, -7.0, 11.0, -2.0, 13.0, -1.0, -8.0, 11.0, -1.0, 6.0, -3.0, 13.0, 13.0, 7.0, 9.0, -14.0, 6.0, -1.0, 8.0, 2.0, -1.0, 11.0, -8.0, 13.0, 9.0, -10.0, 10.0, 6.0, 14.0, -16.0, 9.0, 8.0, -1.0, -7.0, 10.0, 13.0, 5.0, 4.0, 9.0, -3.0, 4.0, 8.0, -7.0, 10.0, 4.0, 8.0, -4.0, 7.0, 13.0, 4.0, -3.0, 1.0, -16.0, 12.0, 8.0, 11.0, 9.0, 14.0, -9.0, 1.0, 1.0, -2.0, 4.0, 12.0, 12.0, 13.0, 318.0, 12.0, -17.0, 11.0, 10.0, 11.0, 8.0, 11.0, -10.0, 6.0, -8.0, -2.0, 12.0, 13.0, 8.0, 13.0, 4.0, -10.0, 0.0, -8.0, 11.0, 12.0, 8.0, 9.0, -13.0, 11.0, -1.0, 10.0, -7.0, 13.0, 12.0, 12.0, -7.0, -2.0, -17.0, 10.0, 10.0, 12.0, 8.0, 14.0, -18.0, 11.0, 3.0, -3.0, 4.0, 11.0, 10.0, 14.0, -17.0, 8.0, -13.0, 5.0, 12.0, 11.0, 13.0, 6.0, -11.0, 7.0, -7.0, 11.0, -1.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21992351327741383, "mean_inference_ms": 1.1739265786171222, "mean_action_processing_ms": 0.07188816515202195, "mean_env_wait_ms": 0.17901020250654953, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 486000, "agent_timesteps_total": 485919, "timers": {"sample_time_ms": 351.291, "sample_throughput": 15371.868, "learn_time_ms": 7077.79, "learn_throughput": 762.95, "update_time_ms": 12.242}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 27.979610443115234, "policy_loss": -0.09182851761579514, "vf_loss": 28.062271118164062, "vf_explained_var": 0.19612248241901398, "kl": 0.020377032458782196, "entropy": 0.5041276216506958, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 486000, "num_agent_steps_sampled": 485919, "num_steps_trained": 486000, "num_agent_steps_trained": 485919}, "done": false, "episodes_total": 9504, "training_iteration": 90, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-52-36", "timestamp": 1626861156, "time_this_iter_s": 7.155906915664673, "time_total_s": 658.5095193386078, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702161e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 658.5095193386078, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 22.400000000000002, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 13.0, 5.0, -11.0, 11.0, 7.0, -8.0, 5.0, 12.0, -5.0, 1.0, 7.0, 12.0, 14.0, -1.0, -10.0, 5.0, 11.0, 4.0, -5.0, 9.0, 11.0, -7.0, 2.0, -8.0, 12.0, 3.0, 8.0, 5.0, 9.0, 11.0, -10.0, -9.0, 13.0, 4.0, 7.0, 3.0, 14.0, -6.0, 4.0, 11.0, -4.0, 10.0, -2.0, 2.0, 11.0, -4.0, 6.0, 7.0, -6.0, 2.0, 12.0, 11.0, 12.0, -10.0, 2.0, -1.0, 12.0, 7.0, -3.0, 4.0, 13.0, 2.0, -4.0, -14.0, 13.0, 11.0, 5.0, 9.0, 14.0, 3.0, -11.0, 3.0, -3.0, 9.0, 6.0, -10.0, 13.0, 7.0, 5.0, -14.0, 11.0, 7.0, 11.0, 7.0, 14.0, -11.0, 5.0, 13.0, -9.0, 9.0, 2.0, 4.0, 13.0, 11.0, -13.0, -6.0, 12.0, 2.0, 7.0, 10.0, 14.0, -12.0, 3.0, 11.0, -11.0, 2.0, 13.0, 7.0, 11.0, 11.0, -14.0, 10.0, 12.0, -9.0, 2.0, 4.0, 10.0, 12.0, -11.0, 11.0, -6.0, 7.0, 3.0, 7.0, 14.0, 5.0, -11.0, -12.0, 9.0, 6.0, 12.0, 11.0, 13.0, -16.0, 7.0, 6.0, -12.0, 8.0, 13.0, 10.0, 13.0, -8.0, 0.0, 7.0, 9.0, -10.0, 9.0, 7.0, 14.0, -9.0, 3.0, 11.0, -13.0, 4.0, 13.0, 0.0, 12.0, 11.0, -8.0, 13.0, 9.0, -13.0, 6.0, 10.0, 13.0, -14.0, 6.0, -1.0, 6.0, 3.0, 7.0, 5.0, 13.0, -6.0, 3.0, 12.0, 12.0, -11.0, 2.0, 11.0, 11.0, -9.0, 2.0, 12.0, -3.0, 8.0, -2.0, 6.0, 13.0, 6.0, -10.0, 5.0, 13.0, 2.0, -5.0, 13.0, 14.0, -10.0, -2.0, -3.0, 9.0, 6.0, 3.0, 7.0, 14.0, -15.0, 9.0, -12.0, 14.0, 3.0, 10.0, 7.0, 0.0, 6.0, 2.0, 12.0, -8.0, 12.0, -1.0, 12.0, 9.0, -1.0, -5.0, -11.0, 13.0, 6.0, 7.0, 8.0, 13.0, -10.0, 4.0, 7.0, -4.0, 4.0, 8.0, 8.0, 14.0, 10.0, -17.0, 5.0, 13.0, -13.0, 10.0, 10.0, 12.0, 5.0, -12.0, 12.0, 9.0, -9.0, 3.0, 7.0, -3.0, 7.0, 4.0, 13.0, 11.0, -14.0, 5.0, 3.0, -3.0, 10.0, 5.0, -1.0, 4.0, 12.0, 0.0, 9.0, 13.0, -13.0, 6.0, -9.0, 14.0, 5.0, 5.0, 6.0, 13.0, -7.0, 3.0, 12.0, 11.0, -16.0, 8.0, 5.0, 14.0, 4.0, -8.0, -9.0, 13.0, 3.0, 8.0, 4.0, 11.0, -2.0, 2.0, 3.0, -2.0, 11.0, 3.0, 6.0, 13.0, -3.0, -1.0, 3.0, 13.0, -13.0, 12.0, 5.0, 14.0, -10.0, 6.0, 10.0, -5.0, 2.0, 8.0, 9.0, 11.0, 7.0, -12.0, -14.0, 14.0, 4.0, 11.0, 10.0, 12.0, -10.0, 3.0, 6.0, -2.0, 3.0, 8.0, 3.0, 13.0, -3.0, 2.0, -19.0, 14.0, 9.0, 11.0, 6.0, 14.0, -15.0, 10.0, -7.0, 11.0, 4.0, 7.0, 12.0, 11.0, 3.0, -11.0, 6.0, 13.0, -5.0, 1.0, 8.0, 10.0, -11.0, 8.0, -6.0, 12.0, 2.0, 7.0, 8.0, 10.0, 9.0, -12.0, 13.0, -5.0, 2.0, 5.0, 4.0, 11.0, -8.0, 8.0, -3.0, 10.0, -1.0, 9.0, 8.0, 12.0, 8.0, -13.0, -5.0, 12.0, -4.0, 12.0, 3.0, -4.0, 11.0, 5.0, 9.0, -2.0, 9.0, -1.0, 11.0, 10.0, 5.0, -11.0, -3.0, 13.0, 1.0, 4.0, 9.0, 12.0, -10.0, 4.0, 10.0, -5.0, 11.0, -1.0, -14.0, 13.0, 11.0, 5.0, 11.0, -6.0, 7.0, 3.0, 5.0, 10.0, -7.0, 7.0, 12.0, -14.0, 9.0, 8.0, 9.0, 12.0, 11.0, -17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22015548704595342, "mean_inference_ms": 1.1748065726323862, "mean_action_processing_ms": 0.07189330520783424, "mean_env_wait_ms": 0.17912779509194385, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 491400, "agent_timesteps_total": 491319, "timers": {"sample_time_ms": 351.618, "sample_throughput": 15357.591, "learn_time_ms": 7082.713, "learn_throughput": 762.42, "update_time_ms": 12.34}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 22.90276336669922, "policy_loss": -0.07010605186223984, "vf_loss": 22.96310043334961, "vf_explained_var": 0.25982797145843506, "kl": 0.014471558853983879, "entropy": 0.48220446705818176, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 491400, "num_agent_steps_sampled": 491319, "num_steps_trained": 491400, "num_agent_steps_trained": 491319}, "done": false, "episodes_total": 9612, "training_iteration": 91, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-52-44", "timestamp": 1626861164, "time_this_iter_s": 7.613988161087036, "time_total_s": 666.1235074996948, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cbf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 666.1235074996948, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 21.181818181818183, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 368.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.555555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 6.138888888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 368.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 12.0, -3.0, 6.0, 9.0, -2.0, 2.0, 6.0, -11.0, 13.0, 1.0, 12.0, 0.0, -4.0, 9.0, 10.0, 7.0, 13.0, -4.0, -1.0, -7.0, 11.0, 4.0, 7.0, -5.0, 9.0, 8.0, 3.0, 13.0, -20.0, 10.0, 12.0, -4.0, 14.0, -4.0, 9.0, 0.0, 12.0, 2.0, 1.0, -9.0, 13.0, -2.0, 13.0, 13.0, -17.0, 10.0, 9.0, 13.0, 6.0, 10.0, -14.0, -14.0, 11.0, 10.0, 8.0, -15.0, 6.0, 11.0, 13.0, 0.0, -3.0, 11.0, 7.0, 6.0, 6.0, 10.0, -7.0, -4.0, 6.0, 4.0, 9.0, -21.0, 14.0, 11.0, 11.0, 13.0, 332.0, 11.0, 12.0, 9.0, 8.0, -8.0, 6.0, -7.0, 10.0, 0.0, 12.0, -20.0, 10.0, 12.0, 13.0, 14.0, -20.0, 10.0, 11.0, 9.0, 13.0, -4.0, -3.0, -3.0, 11.0, 5.0, 2.0, 4.0, 8.0, -4.0, 7.0, 0.0, -6.0, 9.0, 12.0, 9.0, 13.0, -3.0, -4.0, 0.0, 8.0, -5.0, 12.0, -17.0, 8.0, 11.0, 13.0, 13.0, -13.0, 11.0, 4.0, 7.0, 14.0, 6.0, -12.0, -3.0, 9.0, 1.0, 8.0, 3.0, -9.0, 9.0, 12.0, -3.0, -3.0, 9.0, 12.0, 8.0, -5.0, 1.0, 11.0, 13.0, -2.0, 3.0, 1.0, -11.0, 14.0, -1.0, 13.0, -1.0, -4.0, 9.0, 11.0, 5.0, 10.0, -3.0, 3.0, -8.0, 11.0, 4.0, 8.0, -11.0, 5.0, 8.0, 13.0, 13.0, -5.0, 12.0, -5.0, 13.0, 13.0, -9.0, -2.0, -1.0, 6.0, 3.0, 7.0, 316.0, 13.0, 12.0, 13.0, 0.0, -9.0, 12.0, 12.0, 9.0, 13.0, 9.0, -16.0, -7.0, 11.0, 3.0, 8.0, -9.0, 14.0, 6.0, 4.0, 13.0, -15.0, 11.0, 6.0, -9.0, 14.0, 8.0, 2.0, -5.0, 7.0, 5.0, 8.0, -6.0, 14.0, -5.0, 12.0, 13.0, -18.0, 9.0, 11.0, 13.0, 13.0, -14.0, 3.0, -7.0, 12.0, 5.0, 5.0, -9.0, 8.0, 4.0, 12.0, 0.0, -2.0, 6.0, 11.0, 10.0, 13.0, -4.0, -4.0, -6.0, 3.0, 10.0, 8.0, 6.0, 9.0, -13.0, 13.0, 0.0, 8.0, 9.0, -2.0, -11.0, 12.0, 10.0, 4.0, 2.0, -2.0, 9.0, 6.0, 9.0, 14.0, -16.0, 8.0, 13.0, -19.0, 10.0, 11.0, 13.0, 10.0, 9.0, -17.0, -8.0, 10.0, 3.0, 10.0, -14.0, 9.0, 11.0, 9.0, 9.0, -19.0, 13.0, 12.0, -7.0, 12.0, -1.0, 11.0, -5.0, 10.0, 4.0, 6.0, -16.0, 13.0, 5.0, 13.0, 14.0, -17.0, 11.0, 7.0, 7.0, 9.0, -4.0, 3.0, -10.0, 12.0, 0.0, 13.0, -7.0, 1.0, 10.0, 11.0, 9.0, 2.0, -4.0, 8.0, 14.0, 13.0, 0.0, -12.0, 8.0, 11.0, -1.0, -3.0, -15.0, 13.0, 9.0, 8.0, 14.0, 319.0, 11.0, 11.0, 5.0, 14.0, 0.0, -4.0, -3.0, 13.0, 0.0, 5.0, -17.0, 10.0, 10.0, 12.0, -4.0, -5.0, 12.0, 12.0, -7.0, 13.0, 6.0, 3.0, 0.0, 0.0, 4.0, 11.0, -17.0, 13.0, 6.0, 13.0, 13.0, -21.0, 11.0, 12.0, -11.0, 10.0, 10.0, 6.0, -9.0, 8.0, 9.0, 7.0, -14.0, 10.0, 7.0, 12.0, 13.0, -1.0, -4.0, 7.0, 14.0, 13.0, -10.0, -2.0, -6.0, 7.0, 6.0, 8.0, -18.0, 14.0, 11.0, 8.0, 13.0, -2.0, -8.0, 12.0, -6.0, 14.0, 3.0, 4.0, -8.0, 11.0, 5.0, 7.0, -16.0, 9.0, 9.0, 13.0, 14.0, -9.0, -1.0, 11.0, 4.0, 14.0, 9.0, -12.0, -4.0, 11.0, 1.0, 7.0, 3.0, 13.0, -12.0, 11.0, 14.0, -19.0, 9.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22021553387093207, "mean_inference_ms": 1.1746291596445406, "mean_action_processing_ms": 0.07188503211088874, "mean_env_wait_ms": 0.17913867080884696, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 496800, "agent_timesteps_total": 496719, "timers": {"sample_time_ms": 351.036, "sample_throughput": 15383.037, "learn_time_ms": 7100.924, "learn_throughput": 760.464, "update_time_ms": 12.375}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 721.7416381835938, "policy_loss": -0.030312152579426765, "vf_loss": 721.7685546875, "vf_explained_var": 0.11421787738800049, "kl": 0.005019737407565117, "entropy": 0.47636014223098755, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 496800, "num_agent_steps_sampled": 496719, "num_steps_trained": 496800, "num_agent_steps_trained": 496719}, "done": false, "episodes_total": 9720, "training_iteration": 92, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-52-51", "timestamp": 1626861171, "time_this_iter_s": 7.58295464515686, "time_total_s": 673.7064621448517, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 673.7064621448517, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 21.19090909090909, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.40740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 6.101851851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -8.0, 6.0, 8.0, -9.0, 11.0, 3.0, 10.0, 9.0, 11.0, -10.0, 5.0, 0.0, -3.0, 10.0, 8.0, -6.0, -2.0, 11.0, 12.0, 1.0, -2.0, 7.0, 9.0, -20.0, 13.0, 10.0, 12.0, 6.0, 9.0, -4.0, 4.0, 9.0, -7.0, 7.0, 6.0, -6.0, -3.0, 11.0, 13.0, 6.0, 10.0, 1.0, -2.0, 11.0, 10.0, -4.0, -2.0, 7.0, 1.0, 10.0, -3.0, 1.0, -3.0, 5.0, 12.0, 13.0, 9.0, -6.0, -1.0, 3.0, 0.0, 4.0, 8.0, 6.0, 6.0, 6.0, -3.0, -5.0, -5.0, 12.0, 13.0, -12.0, 13.0, 11.0, 3.0, 6.0, -6.0, 10.0, 5.0, -8.0, 1.0, 9.0, 13.0, 5.0, -3.0, 5.0, 8.0, -3.0, 11.0, 11.0, -4.0, 7.0, -3.0, -1.0, 12.0, 13.0, -1.0, 12.0, -9.0, 4.0, -10.0, 10.0, 11.0, 316.0, 14.0, 12.0, 12.0, 4.0, 9.0, -5.0, 7.0, 8.0, 0.0, 12.0, -5.0, 4.0, -4.0, 5.0, 10.0, -6.0, 6.0, 8.0, 7.0, -3.0, 13.0, -7.0, 12.0, 8.0, 1.0, 12.0, -6.0, -14.0, 13.0, 6.0, 10.0, -18.0, 10.0, 11.0, 12.0, -1.0, 13.0, -10.0, 13.0, 11.0, 0.0, 11.0, -7.0, 1.0, -5.0, 10.0, 9.0, 1.0, 12.0, 9.0, -7.0, 8.0, 8.0, -5.0, 4.0, 9.0, 4.0, 12.0, -10.0, -10.0, 12.0, 3.0, 10.0, -18.0, 12.0, 12.0, 9.0, 9.0, 11.0, -9.0, 4.0, 8.0, 7.0, 6.0, -6.0, -10.0, 12.0, 7.0, 6.0, 11.0, 8.0, 8.0, -12.0, 11.0, 6.0, -9.0, 7.0, 6.0, 11.0, 5.0, -7.0, -4.0, -2.0, 10.0, 11.0, 2.0, 6.0, 10.0, -3.0, 6.0, -3.0, -1.0, 13.0, 6.0, 3.0, -6.0, 12.0, 3.0, -7.0, 11.0, 8.0, -4.0, 9.0, 12.0, -2.0, 3.0, 9.0, -9.0, 12.0, -5.0, 6.0, 3.0, 11.0, -7.0, -2.0, 12.0, 12.0, 6.0, 10.0, 5.0, -6.0, 4.0, 11.0, -7.0, 7.0, 8.0, 5.0, 6.0, -4.0, -17.0, 10.0, 9.0, 13.0, 4.0, 12.0, 11.0, -12.0, 9.0, -6.0, 0.0, 12.0, 9.0, -15.0, 9.0, 12.0, -3.0, -4.0, 9.0, 13.0, -3.0, 11.0, 0.0, 7.0, 1.0, 12.0, -5.0, 7.0, 14.0, -12.0, 10.0, 3.0, 7.0, -6.0, 5.0, 9.0, -1.0, 11.0, 7.0, -2.0, 7.0, -3.0, -1.0, 12.0, 5.0, 11.0, 10.0, -11.0, 318.0, 12.0, 11.0, 13.0, -13.0, 11.0, 5.0, 12.0, 6.0, 6.0, -4.0, 7.0, 4.0, 7.0, 11.0, -7.0, -2.0, -2.0, 7.0, 12.0, -15.0, 14.0, 5.0, 11.0, 5.0, -4.0, 2.0, 12.0, 7.0, 6.0, 3.0, -1.0, -10.0, 5.0, 7.0, 13.0, -17.0, 11.0, 12.0, 9.0, 3.0, 13.0, -8.0, 7.0, 9.0, 2.0, 10.0, -6.0, -15.0, 10.0, 8.0, 12.0, -6.0, 8.0, 7.0, 6.0, 3.0, -5.0, 10.0, 7.0, 7.0, 11.0, 0.0, -3.0, -11.0, 12.0, 2.0, 12.0, 4.0, 12.0, 10.0, -11.0, 7.0, 11.0, -14.0, 11.0, 7.0, -2.0, 12.0, -2.0, -8.0, 9.0, 1.0, 13.0, 9.0, 7.0, 10.0, -11.0, 6.0, -2.0, -1.0, 12.0, 6.0, 1.0, 12.0, -4.0, -18.0, 9.0, 11.0, 13.0, 316.0, 12.0, 12.0, 13.0, 4.0, 8.0, -4.0, 7.0, 7.0, 6.0, 5.0, -3.0, -13.0, 10.0, 12.0, 6.0, -8.0, 13.0, 11.0, -1.0, 8.0, -2.0, 4.0, 5.0, -5.0, 6.0, 7.0, 7.0, -6.0, -3.0, 11.0, 13.0, -7.0, 8.0, 8.0, 6.0, 6.0, -7.0, 9.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2202414343494361, "mean_inference_ms": 1.1746400865148985, "mean_action_processing_ms": 0.07188330200298126, "mean_env_wait_ms": 0.17913358841051907, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 502200, "agent_timesteps_total": 502119, "timers": {"sample_time_ms": 350.956, "sample_throughput": 15386.543, "learn_time_ms": 7098.012, "learn_throughput": 760.776, "update_time_ms": 12.242}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 4.999999873689376e-05, "total_loss": 650.3515625, "policy_loss": -0.01938760094344616, "vf_loss": 650.367919921875, "vf_explained_var": 0.07324033230543137, "kl": 0.0044959476217627525, "entropy": 0.4694845974445343, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 502200, "num_agent_steps_sampled": 502119, "num_steps_trained": 502200, "num_agent_steps_trained": 502119}, "done": false, "episodes_total": 9828, "training_iteration": 93, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-52-59", "timestamp": 1626861179, "time_this_iter_s": 7.578525543212891, "time_total_s": 681.2849876880646, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 681.2849876880646, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 21.19090909090909, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.305555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.326388888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -13.0, 10.0, 10.0, 12.0, 5.0, -6.0, 4.0, 8.0, -3.0, -3.0, 13.0, -7.0, 6.0, 8.0, 8.0, 3.0, -1.0, 6.0, 7.0, 12.0, 7.0, -6.0, 2.0, 9.0, -6.0, 11.0, 1.0, 9.0, 13.0, -18.0, 11.0, 2.0, -3.0, 7.0, 9.0, -11.0, 10.0, 9.0, 7.0, 5.0, -2.0, -1.0, 13.0, 4.0, 10.0, -8.0, 9.0, 13.0, -18.0, 11.0, 9.0, -2.0, 11.0, 3.0, 3.0, 8.0, 9.0, 11.0, -13.0, 8.0, 6.0, -5.0, 7.0, 5.0, -7.0, 5.0, 12.0, 8.0, 8.0, 4.0, -5.0, 9.0, 12.0, -18.0, 12.0, 8.0, 14.0, 8.0, -15.0, 8.0, 0.0, -1.0, 8.0, 13.0, 7.0, -3.0, -2.0, 12.0, 13.0, -11.0, 1.0, 10.0, 12.0, 2.0, -9.0, 6.0, -5.0, 11.0, 3.0, -4.0, 7.0, 10.0, 2.0, 10.0, 11.0, -18.0, 12.0, 3.0, 14.0, 5.0, -7.0, 8.0, -9.0, 11.0, 5.0, -1.0, 5.0, 10.0, 1.0, 12.0, 13.0, 9.0, -19.0, 8.0, 9.0, -11.0, 9.0, -1.0, 8.0, -4.0, 12.0, -2.0, 8.0, 8.0, 1.0, 13.0, 11.0, -6.0, -3.0, 8.0, 14.0, -14.0, 7.0, 3.0, 13.0, 2.0, -3.0, 10.0, -9.0, 9.0, 5.0, 3.0, 12.0, -8.0, 8.0, 3.0, 14.0, -10.0, 8.0, 4.0, -2.0, 9.0, 4.0, -3.0, 12.0, 9.0, -3.0, 4.0, 9.0, -11.0, 13.0, 14.0, 9.0, -18.0, 10.0, 3.0, 13.0, -6.0, 5.0, 13.0, 8.0, -13.0, 7.0, 12.0, 11.0, -12.0, 4.0, 4.0, 10.0, 8.0, -7.0, 6.0, -2.0, 11.0, 0.0, 11.0, 7.0, -11.0, 8.0, 1.0, 6.0, -4.0, 12.0, 9.0, 14.0, -7.0, -1.0, 3.0, 12.0, -11.0, 11.0, 5.0, 12.0, -7.0, 5.0, 11.0, 13.0, 318.0, 12.0, 4.0, 8.0, -6.0, 9.0, 9.0, 11.0, 11.0, -16.0, 10.0, -6.0, 2.0, 9.0, 4.0, 12.0, -11.0, 10.0, 11.0, 4.0, 8.0, -8.0, 6.0, -1.0, 2.0, 8.0, -7.0, 12.0, 10.0, 0.0, 6.0, 11.0, -14.0, 12.0, 3.0, 10.0, -9.0, 11.0, 6.0, -3.0, 11.0, 1.0, -3.0, 11.0, 4.0, 3.0, 1.0, 13.0, -12.0, 13.0, 7.0, 14.0, -11.0, 5.0, 1.0, -7.0, 12.0, 9.0, -5.0, 12.0, 5.0, 3.0, 7.0, -2.0, -3.0, 13.0, 7.0, 4.0, -6.0, 10.0, 13.0, -17.0, 8.0, 11.0, 10.0, 7.0, -10.0, 8.0, 5.0, -4.0, 2.0, 12.0, -15.0, 13.0, 9.0, 8.0, 3.0, 11.0, -9.0, 10.0, -9.0, 7.0, 9.0, 8.0, 12.0, -4.0, -1.0, 8.0, 5.0, 13.0, -14.0, 11.0, 13.0, -16.0, 9.0, 9.0, -2.0, 12.0, 8.0, -3.0, 8.0, 13.0, 12.0, -18.0, 9.0, 12.0, 5.0, -11.0, 9.0, -3.0, 9.0, 0.0, -3.0, 2.0, 10.0, 6.0, 8.0, 13.0, 12.0, -18.0, 7.0, 9.0, -9.0, 8.0, 4.0, 13.0, 11.0, -13.0, 14.0, 12.0, -6.0, -5.0, 12.0, 12.0, 10.0, -19.0, 10.0, 9.0, -6.0, 2.0, 8.0, -3.0, 3.0, 7.0, 321.0, 11.0, 11.0, 12.0, 6.0, 9.0, -13.0, 13.0, 11.0, 2.0, -7.0, 9.0, 3.0, -1.0, 3.0, 10.0, 13.0, 9.0, 9.0, -16.0, 7.0, 11.0, -16.0, 13.0, 14.0, 7.0, 0.0, -6.0, 8.0, -8.0, 10.0, 5.0, -4.0, 7.0, 8.0, 4.0, 7.0, -3.0, 1.0, 10.0, 4.0, 12.0, -6.0, 5.0, 4.0, 7.0, 11.0, -7.0, 6.0, -7.0, 11.0, 5.0, 8.0, 14.0, -19.0, 12.0, 4.0, 14.0, -11.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22025791213429227, "mean_inference_ms": 1.1748303687486503, "mean_action_processing_ms": 0.07187575282382887, "mean_env_wait_ms": 0.17913251383558165, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 507600, "agent_timesteps_total": 507519, "timers": {"sample_time_ms": 351.909, "sample_throughput": 15344.863, "learn_time_ms": 7097.225, "learn_throughput": 760.861, "update_time_ms": 12.122}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.3375000059604645, "cur_lr": 4.999999873689376e-05, "total_loss": 423.0892028808594, "policy_loss": -0.025451289489865303, "vf_loss": 423.11114501953125, "vf_explained_var": 0.1219375878572464, "kl": 0.010343190282583237, "entropy": 0.49723517894744873, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 507600, "num_agent_steps_sampled": 507519, "num_steps_trained": 507600, "num_agent_steps_trained": 507519}, "done": false, "episodes_total": 9936, "training_iteration": 94, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-53-07", "timestamp": 1626861187, "time_this_iter_s": 7.6147003173828125, "time_total_s": 688.8996880054474, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70212c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 688.8996880054474, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 21.281818181818178, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.00925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.752314814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 12.0, 8.0, -1.0, 6.0, -2.0, 0.0, 11.0, 12.0, 8.0, 11.0, -16.0, 14.0, -3.0, 11.0, -7.0, 5.0, -4.0, 12.0, 2.0, 14.0, 11.0, -16.0, 6.0, 14.0, 9.0, -4.0, -4.0, 13.0, 5.0, -13.0, 10.0, 4.0, -1.0, 11.0, 1.0, 7.0, 7.0, 8.0, -7.0, -8.0, 13.0, 5.0, 5.0, 13.0, 3.0, 7.0, -8.0, 9.0, 11.0, 11.0, -16.0, 10.0, 11.0, -4.0, -2.0, 14.0, 3.0, 3.0, -5.0, 14.0, 9.0, -1.0, -7.0, -13.0, 10.0, 12.0, 6.0, 14.0, 6.0, -9.0, 4.0, 6.0, 10.0, -14.0, 13.0, 14.0, 6.0, -11.0, 6.0, -10.0, 12.0, 11.0, 2.0, 4.0, 11.0, 11.0, -11.0, 10.0, 10.0, -11.0, 6.0, 13.0, 2.0, -4.0, 4.0, -7.0, 13.0, 13.0, -4.0, 9.0, 11.0, -2.0, -3.0, 3.0, 13.0, -1.0, 0.0, 14.0, 8.0, -4.0, -3.0, 5.0, -7.0, 13.0, 4.0, 4.0, 6.0, 11.0, -6.0, 13.0, 4.0, -9.0, 7.0, 14.0, 3.0, 5.0, -7.0, 4.0, 12.0, 8.0, -9.0, 0.0, 8.0, 5.0, 2.0, -2.0, 4.0, 2.0, 11.0, 11.0, 0.0, 5.0, -1.0, -7.0, 8.0, 11.0, 3.0, 4.0, -1.0, 5.0, 7.0, -1.0, 11.0, -1.0, 6.0, 14.0, 12.0, -6.0, -5.0, 5.0, 13.0, -16.0, 13.0, -6.0, 6.0, 6.0, 9.0, 13.0, 4.0, -5.0, 3.0, 14.0, 8.0, -5.0, -2.0, 4.0, -6.0, 12.0, 5.0, 12.0, 11.0, -2.0, -6.0, 12.0, 5.0, 11.0, -13.0, 11.0, 8.0, 8.0, -12.0, -8.0, 12.0, 7.0, 4.0, 14.0, -10.0, 3.0, 8.0, 11.0, 7.0, -2.0, -1.0, 14.0, 4.0, -3.0, 0.0, -14.0, 13.0, 13.0, 3.0, 6.0, -1.0, 8.0, 2.0, 4.0, 4.0, 10.0, -3.0, 12.0, 4.0, -1.0, 0.0, 10.0, -2.0, 11.0, -4.0, -5.0, 12.0, 2.0, 6.0, 8.0, 6.0, 9.0, -8.0, 12.0, -8.0, -2.0, 13.0, -7.0, 13.0, 10.0, -1.0, -4.0, 5.0, 3.0, 11.0, 13.0, 6.0, -12.0, 8.0, 14.0, 4.0, -5.0, 2.0, -9.0, 14.0, -2.0, 12.0, 5.0, 9.0, 9.0, -8.0, 10.0, 8.0, -2.0, -1.0, 12.0, -6.0, 6.0, 4.0, -6.0, 11.0, 10.0, 0.0, -2.0, 13.0, 8.0, -4.0, -2.0, 8.0, 12.0, -3.0, 14.0, 4.0, 3.0, -6.0, -14.0, 12.0, 11.0, 6.0, 8.0, 5.0, -6.0, 8.0, 12.0, 7.0, -7.0, 3.0, 13.0, 3.0, -2.0, 1.0, 8.0, 11.0, 12.0, -16.0, 10.0, -1.0, 1.0, 5.0, 12.0, 1.0, -2.0, 4.0, 13.0, 11.0, -7.0, -2.0, 2.0, 0.0, 13.0, 0.0, 10.0, 14.0, -2.0, -7.0, 12.0, 8.0, 11.0, -16.0, 14.0, -7.0, 5.0, 3.0, 7.0, -2.0, 13.0, -3.0, -2.0, 10.0, 0.0, 7.0, 13.0, 5.0, -12.0, 9.0, 14.0, 11.0, -7.0, -3.0, -6.0, 12.0, 11.0, -2.0, -5.0, 8.0, 7.0, 5.0, 12.0, 11.0, 7.0, -15.0, 14.0, -3.0, 12.0, -8.0, -9.0, 12.0, 12.0, 0.0, -1.0, -5.0, 10.0, 11.0, -1.0, -3.0, 8.0, 11.0, 14.0, -2.0, -7.0, 10.0, 0.0, -4.0, 12.0, 7.0, 9.0, -7.0, 6.0, 7.0, 12.0, 9.0, 6.0, -12.0, 12.0, 8.0, -1.0, -4.0, 1.0, 13.0, 12.0, -11.0, -12.0, 13.0, 4.0, 10.0, -1.0, 5.0, 11.0, 0.0, 14.0, 4.0, 9.0, -12.0, 8.0, 11.0, 12.0, -16.0, 7.0, 9.0, 9.0, -10.0, 1.0, 11.0, 11.0, -8.0, 14.0, 5.0, -8.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22024777422395073, "mean_inference_ms": 1.174722799826072, "mean_action_processing_ms": 0.071877420136677, "mean_env_wait_ms": 0.17913540139071613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 513000, "agent_timesteps_total": 512919, "timers": {"sample_time_ms": 350.353, "sample_throughput": 15413.04, "learn_time_ms": 7091.073, "learn_throughput": 761.521, "update_time_ms": 12.236}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.3375000059604645, "cur_lr": 4.999999873689376e-05, "total_loss": 19.22472381591797, "policy_loss": -0.09620290249586105, "vf_loss": 19.31324005126953, "vf_explained_var": 0.18709377944469452, "kl": 0.022770266979932785, "entropy": 0.5078356266021729, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 513000, "num_agent_steps_sampled": 512919, "num_steps_trained": 513000, "num_agent_steps_trained": 512919}, "done": false, "episodes_total": 10044, "training_iteration": 95, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-53-14", "timestamp": 1626861194, "time_this_iter_s": 7.5735838413238525, "time_total_s": 696.4732718467712, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70212e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 696.4732718467712, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 21.063636363636363, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.064814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7662037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 10.0, 10.0, -13.0, 14.0, 9.0, -4.0, -4.0, -11.0, 12.0, 3.0, 11.0, 12.0, -3.0, -5.0, 11.0, -6.0, 4.0, 4.0, 13.0, 14.0, 2.0, -5.0, 4.0, -6.0, 2.0, 8.0, 11.0, 11.0, 2.0, 3.0, -1.0, 9.0, 9.0, 8.0, -11.0, 13.0, 7.0, -9.0, 5.0, -1.0, 10.0, -7.0, 13.0, 12.0, 10.0, 4.0, -11.0, -9.0, 7.0, 13.0, 4.0, 13.0, 8.0, -6.0, 0.0, -8.0, 9.0, 13.0, 1.0, 10.0, 1.0, -7.0, 11.0, 8.0, 12.0, -11.0, 6.0, 8.0, 7.0, -10.0, 10.0, -6.0, 5.0, 7.0, 9.0, 10.0, 4.0, -8.0, 9.0, 3.0, 2.0, -3.0, 13.0, 7.0, -1.0, -3.0, 12.0, -4.0, 11.0, 6.0, 2.0, 10.0, 5.0, 6.0, -6.0, -10.0, 7.0, 9.0, 9.0, 14.0, -7.0, -5.0, 13.0, 9.0, 6.0, -13.0, 13.0, 9.0, 3.0, 10.0, -7.0, -1.0, 3.0, 13.0, 0.0, 12.0, -4.0, -3.0, 10.0, -1.0, 6.0, -1.0, 11.0, -2.0, 8.0, 3.0, 6.0, -8.0, 3.0, 13.0, 7.0, 14.0, 12.0, -10.0, 0.0, 11.0, 7.0, -15.0, 12.0, 9.0, 8.0, 7.0, -9.0, -10.0, 5.0, 13.0, 7.0, 12.0, 8.0, -11.0, 6.0, -2.0, 6.0, -1.0, 12.0, 11.0, -2.0, -3.0, 9.0, 5.0, 3.0, 13.0, -6.0, 9.0, 5.0, -8.0, 9.0, -12.0, 8.0, 11.0, 8.0, 13.0, 1.0, 7.0, -6.0, -10.0, 11.0, 1.0, 13.0, -3.0, 11.0, -6.0, 13.0, 0.0, 11.0, -5.0, 9.0, 10.0, 2.0, 6.0, -3.0, -5.0, 6.0, 6.0, 8.0, 12.0, 6.0, 10.0, -12.0, 0.0, 9.0, -5.0, 11.0, 11.0, 14.0, -1.0, -9.0, -7.0, 6.0, 13.0, 3.0, 12.0, 9.0, -10.0, 5.0, 13.0, -10.0, 6.0, 6.0, 11.0, 4.0, 8.0, -8.0, 6.0, 3.0, -7.0, 13.0, 12.0, 1.0, -9.0, 11.0, -9.0, 12.0, 13.0, -1.0, 12.0, 6.0, 8.0, -11.0, 7.0, 10.0, -8.0, 6.0, 14.0, -4.0, -3.0, 8.0, 0.0, 12.0, -6.0, 9.0, 12.0, -12.0, 10.0, 5.0, 9.0, 6.0, -9.0, 9.0, -5.0, 4.0, 12.0, 4.0, -7.0, 6.0, 4.0, 12.0, 12.0, -4.0, 10.0, -3.0, -13.0, 5.0, 10.0, 13.0, 13.0, 10.0, -10.0, 2.0, 9.0, -11.0, 9.0, 8.0, 11.0, 11.0, 1.0, -8.0, -9.0, 7.0, 8.0, 9.0, 12.0, 5.0, -9.0, 7.0, -9.0, 12.0, 6.0, 6.0, 11.0, -1.0, -3.0, 8.0, -7.0, 10.0, 6.0, 6.0, 14.0, 13.0, -9.0, -2.0, 12.0, -14.0, 7.0, 10.0, 11.0, 2.0, 6.0, -4.0, -13.0, 10.0, 13.0, 5.0, 14.0, 8.0, -3.0, -3.0, -1.0, 8.0, 0.0, 8.0, 10.0, 7.0, 8.0, -10.0, 4.0, -1.0, 13.0, -1.0, -2.0, 10.0, 7.0, 0.0, -4.0, 9.0, 2.0, 8.0, 5.0, 11.0, 7.0, -8.0, 8.0, 7.0, -13.0, 13.0, -1.0, 6.0, 0.0, 10.0, 8.0, -14.0, 11.0, 10.0, 12.0, 5.0, 4.0, -6.0, 13.0, 8.0, 10.0, -16.0, 1.0, 10.0, -3.0, 7.0, -10.0, 9.0, 8.0, 8.0, 11.0, 6.0, 4.0, -6.0, -13.0, 4.0, 11.0, 13.0, 12.0, 13.0, -15.0, 5.0, 8.0, 9.0, -9.0, 7.0, 10.0, 5.0, 6.0, -6.0, -6.0, 5.0, 5.0, 11.0, 6.0, 6.0, -9.0, 12.0, -6.0, 5.0, 5.0, 11.0, 6.0, 13.0, 9.0, -13.0, 8.0, 7.0, -3.0, 3.0, 11.0, 2.0, -7.0, 10.0, 3.0, 11.0, -11.0, 12.0, 7.0, 4.0, 8.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2202365938532147, "mean_inference_ms": 1.1744347282400116, "mean_action_processing_ms": 0.07186577113779131, "mean_env_wait_ms": 0.17912142998701366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 518400, "agent_timesteps_total": 518319, "timers": {"sample_time_ms": 350.01, "sample_throughput": 15428.145, "learn_time_ms": 7093.534, "learn_throughput": 761.257, "update_time_ms": 12.064}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 21.38096809387207, "policy_loss": -0.08445701003074646, "vf_loss": 21.45689582824707, "vf_explained_var": 0.23185929656028748, "kl": 0.016848089173436165, "entropy": 0.5064418315887451, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 518400, "num_agent_steps_sampled": 518319, "num_steps_trained": 518400, "num_agent_steps_trained": 518319}, "done": false, "episodes_total": 10152, "training_iteration": 96, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-53-22", "timestamp": 1626861202, "time_this_iter_s": 7.612852096557617, "time_total_s": 704.0861239433289, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70212ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 704.0861239433289, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 20.94545454545454, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 369.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.694444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 335.0}, "policy_reward_mean": {"learned": 6.923611111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 369.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -5.0, 9.0, 1.0, 4.0, -3.0, 10.0, 4.0, 12.0, -14.0, 8.0, 9.0, 2.0, 11.0, -7.0, 9.0, 11.0, -7.0, -1.0, 12.0, 14.0, 11.0, -20.0, 10.0, 2.0, -8.0, 8.0, 13.0, 12.0, 318.0, 11.0, 11.0, 10.0, -1.0, 4.0, 2.0, 13.0, 4.0, 11.0, -13.0, 11.0, 6.0, -15.0, 13.0, 11.0, -3.0, -5.0, 12.0, 12.0, -9.0, -1.0, 13.0, 9.0, 9.0, -10.0, 7.0, 8.0, -5.0, -1.0, 13.0, 9.0, 10.0, -14.0, 10.0, 7.0, -1.0, -4.0, 13.0, 14.0, 10.0, 12.0, -21.0, -19.0, 9.0, 12.0, 13.0, 10.0, 0.0, -7.0, 12.0, 13.0, -8.0, -3.0, 13.0, 13.0, 8.0, -2.0, -4.0, 8.0, -10.0, 4.0, 13.0, 12.0, 2.0, -7.0, 8.0, 12.0, -3.0, -2.0, 8.0, 12.0, 11.0, -10.0, 2.0, -14.0, 8.0, 8.0, 13.0, 7.0, -14.0, 10.0, 12.0, 11.0, -1.0, 2.0, 3.0, 8.0, 12.0, -7.0, 2.0, -1.0, -5.0, 8.0, 13.0, 7.0, -2.0, -3.0, 13.0, 6.0, -1.0, 9.0, 1.0, 8.0, 10.0, -10.0, 7.0, 9.0, -11.0, 4.0, 13.0, 6.0, 6.0, -4.0, 7.0, 0.0, -3.0, 5.0, 13.0, 5.0, 11.0, -4.0, 3.0, 8.0, -5.0, -1.0, 13.0, 5.0, -1.0, -1.0, 12.0, 11.0, -3.0, -6.0, 13.0, 7.0, -5.0, 11.0, 2.0, 11.0, -8.0, -1.0, 13.0, 10.0, -5.0, -3.0, 13.0, -2.0, 10.0, 12.0, -5.0, 7.0, 13.0, 5.0, -10.0, 13.0, -7.0, -1.0, 10.0, 11.0, 3.0, -8.0, 9.0, 7.0, 4.0, 13.0, -9.0, 7.0, 0.0, -3.0, 11.0, -20.0, 11.0, 11.0, 13.0, 7.0, -3.0, -2.0, 13.0, 11.0, -2.0, 2.0, 4.0, 13.0, 10.0, -14.0, 6.0, 6.0, -8.0, 4.0, 13.0, 7.0, -7.0, 2.0, 13.0, -9.0, 11.0, 0.0, 13.0, 12.0, 10.0, -18.0, 11.0, -8.0, -2.0, 12.0, 13.0, 12.0, 2.0, -11.0, 12.0, 12.0, 10.0, -10.0, 3.0, 4.0, 13.0, -14.0, 12.0, 10.0, -8.0, 4.0, 9.0, 6.0, -13.0, 10.0, 12.0, 12.0, -4.0, -1.0, 8.0, 12.0, 11.0, -5.0, -3.0, 11.0, -5.0, -2.0, 11.0, 5.0, 2.0, -4.0, 12.0, 13.0, -4.0, 7.0, -1.0, 14.0, 12.0, 11.0, 317.0, 11.0, -6.0, -2.0, 12.0, 7.0, 0.0, -2.0, 10.0, 6.0, -3.0, 8.0, 4.0, 14.0, 10.0, 9.0, -18.0, 319.0, 12.0, 12.0, 13.0, 4.0, 3.0, -3.0, 11.0, 12.0, -3.0, -4.0, 10.0, 4.0, 9.0, 11.0, -9.0, 7.0, -4.0, 2.0, 10.0, 12.0, 2.0, -8.0, 9.0, 12.0, -4.0, 8.0, -1.0, 2.0, 9.0, -3.0, 7.0, 10.0, -5.0, 0.0, 10.0, 13.0, -6.0, -5.0, 13.0, 11.0, -5.0, 8.0, 1.0, 1.0, 12.0, 5.0, -3.0, 12.0, -11.0, 1.0, 13.0, 7.0, -15.0, 11.0, 12.0, -2.0, 9.0, 6.0, 2.0, 4.0, 8.0, 5.0, -2.0, 13.0, 9.0, -12.0, 5.0, 5.0, -12.0, 10.0, 12.0, 11.0, -3.0, -5.0, 12.0, 14.0, 9.0, 10.0, -18.0, 12.0, -6.0, -4.0, 13.0, 10.0, 0.0, -7.0, 12.0, 12.0, 9.0, 335.0, 13.0, 7.0, 3.0, 10.0, -5.0, 2.0, -3.0, 4.0, 12.0, 10.0, 7.0, -14.0, 12.0, 10.0, -7.0, 12.0, 0.0, 9.0, 10.0, -13.0, 9.0, -2.0, -4.0, 8.0, 13.0, 5.0, 1.0, -4.0, 13.0, 6.0, -2.0, 0.0, 11.0, 9.0, 13.0, -13.0, 6.0, -2.0, -7.0, 12.0, 12.0, 11.0, -2.0, -5.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22024198333583694, "mean_inference_ms": 1.174186557713359, "mean_action_processing_ms": 0.07186909316273712, "mean_env_wait_ms": 0.17911070737349793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 523800, "agent_timesteps_total": 523719, "timers": {"sample_time_ms": 349.747, "sample_throughput": 15439.719, "learn_time_ms": 7092.818, "learn_throughput": 761.334, "update_time_ms": 11.713}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 775.0974731445312, "policy_loss": -0.022787436842918396, "vf_loss": 775.1172485351562, "vf_explained_var": 0.09578201174736023, "kl": 0.0057693785056471825, "entropy": 0.5108795762062073, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 523800, "num_agent_steps_sampled": 523719, "num_steps_trained": 523800, "num_agent_steps_trained": 523719}, "done": false, "episodes_total": 10260, "training_iteration": 97, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-53-29", "timestamp": 1626861209, "time_this_iter_s": 7.6016223430633545, "time_total_s": 711.6877462863922, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 711.6877462863922, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 21.599999999999998, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 0.0, 7.0, 3.0, -2.0, 9.0, 8.0, 0.0, 6.0, -12.0, 13.0, 8.0, 5.0, -5.0, 8.0, 7.0, 9.0, -3.0, 4.0, 5.0, -4.0, 3.0, 10.0, 6.0, 4.0, 5.0, 12.0, -6.0, 7.0, 12.0, -2.0, -2.0, 10.0, 10.0, 10.0, -15.0, -7.0, 7.0, 9.0, 6.0, 4.0, -15.0, 13.0, 13.0, 6.0, 4.0, -6.0, 11.0, 0.0, -3.0, 12.0, 6.0, -3.0, 5.0, 11.0, 2.0, -10.0, 3.0, 9.0, 13.0, 9.0, -14.0, 11.0, 9.0, 10.0, -4.0, 0.0, 9.0, -1.0, 10.0, 7.0, -1.0, 6.0, -16.0, 12.0, 13.0, 11.0, -7.0, 7.0, 4.0, 11.0, 0.0, 10.0, -6.0, -5.0, 11.0, -3.0, 12.0, 6.0, -16.0, 13.0, 12.0, 9.0, -5.0, 2.0, 9.0, 0.0, -3.0, 7.0, 11.0, 6.0, 6.0, 8.0, -5.0, -7.0, -3.0, 13.0, 12.0, 8.0, 3.0, 12.0, -8.0, 3.0, -9.0, 9.0, 12.0, -1.0, 5.0, 12.0, -1.0, 3.0, 5.0, 8.0, -1.0, 11.0, -18.0, 13.0, 9.0, 7.0, -2.0, 0.0, 10.0, -1.0, 1.0, 10.0, 5.0, 1.0, -8.0, 13.0, 9.0, 8.0, -9.0, 8.0, 8.0, 2.0, -1.0, 13.0, 1.0, -2.0, 9.0, 10.0, -2.0, 4.0, -14.0, 12.0, 13.0, 8.0, 8.0, 2.0, -3.0, 10.0, -5.0, 4.0, 6.0, -7.0, 9.0, 8.0, 5.0, 6.0, 2.0, 10.0, -3.0, 11.0, -9.0, 2.0, 11.0, 3.0, 9.0, 5.0, -2.0, -1.0, 10.0, 7.0, -1.0, 10.0, -16.0, 9.0, 12.0, 9.0, 4.0, 6.0, -4.0, 7.0, -3.0, 8.0, 3.0, -3.0, 9.0, 11.0, -2.0, -10.0, 2.0, 13.0, 10.0, 1.0, 0.0, 4.0, 10.0, 7.0, -1.0, 11.0, -2.0, -1.0, 12.0, 2.0, 2.0, 2.0, -4.0, 9.0, 8.0, 8.0, -1.0, 12.0, -4.0, 6.0, -1.0, 6.0, 4.0, -7.0, 8.0, 10.0, 4.0, -3.0, -3.0, 8.0, 13.0, 7.0, -5.0, 6.0, 7.0, 11.0, 10.0, 2.0, -8.0, -1.0, 10.0, 4.0, 2.0, 9.0, -13.0, 8.0, 11.0, 7.0, -9.0, 8.0, 9.0, 3.0, -1.0, 11.0, 2.0, -1.0, 14.0, 7.0, -5.0, -10.0, 2.0, 11.0, 12.0, 12.0, -14.0, 8.0, 9.0, 1.0, -6.0, 8.0, 12.0, -4.0, -2.0, 10.0, 11.0, 5.0, 6.0, 8.0, -4.0, 3.0, -8.0, 10.0, 10.0, 7.0, 11.0, 1.0, -4.0, -4.0, 7.0, 4.0, 8.0, 7.0, -9.0, 13.0, 4.0, 11.0, -11.0, 9.0, 6.0, 13.0, 10.0, 0.0, -8.0, -1.0, 7.0, 9.0, 0.0, -9.0, -1.0, 12.0, 13.0, 12.0, 6.0, 3.0, -6.0, -1.0, -3.0, 8.0, 11.0, -3.0, 14.0, 11.0, -7.0, -12.0, 5.0, 9.0, 13.0, 8.0, -9.0, 7.0, 9.0, 8.0, -5.0, -1.0, 13.0, -1.0, 13.0, 7.0, -4.0, 6.0, -13.0, 9.0, 13.0, 9.0, 10.0, -14.0, 10.0, 3.0, 13.0, 2.0, -3.0, -1.0, 7.0, 9.0, 0.0, 3.0, -11.0, 13.0, 10.0, 11.0, 0.0, 5.0, -1.0, -1.0, -6.0, 12.0, 10.0, -1.0, 6.0, 7.0, 3.0, 2.0, -13.0, 13.0, 13.0, 11.0, -1.0, 5.0, 0.0, 6.0, -4.0, 5.0, 8.0, -6.0, 8.0, 10.0, 3.0, 2.0, -12.0, 12.0, 13.0, 12.0, -12.0, 5.0, 10.0, 6.0, 13.0, 11.0, -15.0, 10.0, 3.0, 7.0, -5.0, 1.0, -10.0, 11.0, 13.0, 8.0, -6.0, 3.0, 10.0, 5.0, -6.0, 6.0, 10.0, -1.0, -2.0, 11.0, 7.0, 1.0, -12.0, 13.0, 13.0, 8.0, 9.0, 3.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22025622560038235, "mean_inference_ms": 1.174098185595769, "mean_action_processing_ms": 0.07186884382953401, "mean_env_wait_ms": 0.1791150201849964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 529200, "agent_timesteps_total": 529119, "timers": {"sample_time_ms": 348.801, "sample_throughput": 15481.623, "learn_time_ms": 7010.225, "learn_throughput": 770.303, "update_time_ms": 11.346}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 16.670940399169922, "policy_loss": -0.08240249007940292, "vf_loss": 16.74498176574707, "vf_explained_var": 0.293575257062912, "kl": 0.016518114134669304, "entropy": 0.46780675649642944, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 529200, "num_agent_steps_sampled": 529119, "num_steps_trained": 529200, "num_agent_steps_trained": 529119}, "done": false, "episodes_total": 10368, "training_iteration": 98, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-53-36", "timestamp": 1626861216, "time_this_iter_s": 6.7966461181640625, "time_total_s": 718.4843924045563, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 718.4843924045563, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 24.166666666666664, "ram_util_percent": 14.21111111111111}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 37.00925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 9.252314814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 10.0, 1.0, 8.0, 14.0, -9.0, 3.0, 7.0, -5.0, 11.0, -4.0, 13.0, -14.0, 4.0, 13.0, 12.0, -3.0, 1.0, 4.0, 13.0, 13.0, -2.0, -2.0, 6.0, 6.0, 13.0, -17.0, 13.0, -2.0, -1.0, 13.0, 5.0, 10.0, -8.0, 5.0, 8.0, 8.0, 4.0, -2.0, 5.0, 3.0, 13.0, -10.0, 9.0, 1.0, -12.0, 13.0, 13.0, 2.0, -5.0, 5.0, 13.0, 10.0, 4.0, -2.0, 3.0, 13.0, 11.0, -15.0, 6.0, -16.0, 11.0, 8.0, 12.0, 5.0, 10.0, -10.0, 10.0, 12.0, 1.0, -10.0, 12.0, 11.0, 13.0, 318.0, 13.0, 0.0, -3.0, 8.0, 10.0, -7.0, 10.0, 5.0, 7.0, 10.0, 0.0, -3.0, 8.0, 12.0, 13.0, 316.0, 13.0, 3.0, -6.0, 13.0, 5.0, -4.0, 10.0, 6.0, 3.0, 13.0, -6.0, -4.0, 12.0, -3.0, 13.0, -8.0, 13.0, 9.0, -12.0, 13.0, 5.0, 7.0, 3.0, 11.0, -6.0, 13.0, -3.0, -2.0, 7.0, 10.0, 13.0, -21.0, 13.0, -17.0, 7.0, 13.0, 12.0, 9.0, 6.0, -3.0, 3.0, 10.0, -12.0, 9.0, 8.0, 11.0, 13.0, 318.0, 13.0, -9.0, 7.0, 6.0, 11.0, -8.0, 10.0, 4.0, 9.0, 11.0, -11.0, 11.0, 4.0, 11.0, 9.0, -15.0, 10.0, -4.0, 11.0, -4.0, 12.0, 10.0, -7.0, 4.0, 8.0, 9.0, 3.0, -1.0, 4.0, 11.0, 13.0, -22.0, 13.0, -1.0, -6.0, 9.0, 13.0, 11.0, 3.0, -12.0, 13.0, -5.0, -1.0, 12.0, 9.0, 8.0, 10.0, -16.0, 13.0, -13.0, 6.0, 11.0, 11.0, 14.0, -14.0, 8.0, 7.0, 12.0, -13.0, 8.0, 8.0, -4.0, 13.0, -7.0, 13.0, 10.0, -19.0, 11.0, 13.0, 11.0, -9.0, 0.0, 13.0, 13.0, -8.0, 3.0, 7.0, 12.0, 13.0, -18.0, 8.0, 3.0, -8.0, 8.0, 12.0, 13.0, -9.0, 5.0, 6.0, 13.0, 4.0, -6.0, 4.0, 6.0, 13.0, -17.0, 13.0, -1.0, 9.0, 11.0, -4.0, 11.0, 4.0, -8.0, 8.0, 11.0, -12.0, 11.0, 5.0, 12.0, 13.0, 316.0, 13.0, 0.0, 11.0, -8.0, 12.0, 12.0, -8.0, 12.0, -1.0, 11.0, -2.0, -2.0, 8.0, 9.0, 14.0, 12.0, -20.0, -15.0, 10.0, 11.0, 9.0, -1.0, 4.0, 11.0, 1.0, 13.0, 1.0, -2.0, 3.0, 11.0, 13.0, -22.0, 13.0, 4.0, 8.0, -10.0, 13.0, -3.0, 11.0, 2.0, 5.0, 12.0, -1.0, -3.0, 7.0, 11.0, 12.0, -19.0, 11.0, 1.0, -8.0, 13.0, 9.0, 11.0, 11.0, -15.0, 8.0, 13.0, -3.0, -3.0, 8.0, 5.0, 13.0, -16.0, 13.0, -14.0, 4.0, 13.0, 12.0, 12.0, -9.0, 7.0, 5.0, 13.0, 1.0, -1.0, 2.0, 8.0, 13.0, -19.0, 13.0, 5.0, -12.0, 13.0, 9.0, 10.0, 6.0, -14.0, 13.0, 13.0, -2.0, -3.0, 7.0, 14.0, 9.0, 9.0, -17.0, 6.0, 3.0, 13.0, -7.0, 14.0, 6.0, -13.0, 8.0, 12.0, -2.0, -2.0, 7.0, 12.0, 13.0, 316.0, 13.0, -14.0, 11.0, 13.0, 5.0, 12.0, 2.0, -8.0, 9.0, 13.0, 0.0, -9.0, 11.0, -3.0, 13.0, -8.0, 13.0, -13.0, 9.0, 13.0, 6.0, 11.0, 4.0, -7.0, 7.0, 13.0, -12.0, 5.0, 9.0, 10.0, 13.0, 319.0, 13.0, 8.0, -9.0, 13.0, 3.0, 12.0, 10.0, -10.0, 3.0, 7.0, 2.0, -4.0, 10.0, 3.0, 13.0, -14.0, 13.0, 8.0, -16.0, 10.0, 13.0, 11.0, 6.0, -10.0, 8.0, 10.0, -4.0, -2.0, 11.0, 12.0, 13.0, 317.0, 13.0, -12.0, 6.0, 9.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22022644821010667, "mean_inference_ms": 1.1739274134369948, "mean_action_processing_ms": 0.07184980751455454, "mean_env_wait_ms": 0.17909262826947017, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 534600, "agent_timesteps_total": 534519, "timers": {"sample_time_ms": 348.935, "sample_throughput": 15475.668, "learn_time_ms": 6970.479, "learn_throughput": 774.696, "update_time_ms": 11.309}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 1464.4613037109375, "policy_loss": -0.03333091363310814, "vf_loss": 1464.49169921875, "vf_explained_var": 0.06863965094089508, "kl": 0.0061130039393901825, "entropy": 0.47485703229904175, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 534600, "num_agent_steps_sampled": 534519, "num_steps_trained": 534600, "num_agent_steps_trained": 534519}, "done": false, "episodes_total": 10476, "training_iteration": 99, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-53-44", "timestamp": 1626861224, "time_this_iter_s": 7.2451794147491455, "time_total_s": 725.7295718193054, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 725.7295718193054, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 25.181818181818183, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.444444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 6.111111111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, -9.0, 8.0, 11.0, -5.0, 12.0, 8.0, 0.0, 1.0, -2.0, 3.0, 13.0, 8.0, 9.0, -7.0, 5.0, 1.0, -9.0, 13.0, 10.0, 13.0, 8.0, -12.0, 6.0, 14.0, -1.0, -4.0, 6.0, -1.0, 14.0, -10.0, 12.0, -11.0, 12.0, 6.0, 8.0, -5.0, 13.0, 6.0, 1.0, 8.0, -1.0, -5.0, 13.0, -3.0, 14.0, -2.0, 6.0, -1.0, 8.0, 4.0, 4.0, 14.0, 12.0, 1.0, -12.0, 9.0, -4.0, -2.0, 12.0, 2.0, 14.0, -8.0, 7.0, -14.0, 6.0, 11.0, 12.0, 14.0, 8.0, -1.0, -6.0, 13.0, 13.0, 11.0, 318.0, 4.0, 13.0, -10.0, 8.0, 11.0, 5.0, -8.0, 7.0, 14.0, 13.0, -11.0, -1.0, 13.0, -1.0, -9.0, 12.0, 3.0, 14.0, -10.0, 8.0, -10.0, 11.0, 4.0, 10.0, 14.0, 12.0, 2.0, -13.0, 9.0, -1.0, -4.0, 11.0, 3.0, 11.0, -12.0, 13.0, -4.0, -6.0, 12.0, 13.0, 9.0, 12.0, 8.0, -14.0, 13.0, 13.0, 12.0, 316.0, 4.0, 12.0, -8.0, 7.0, -18.0, 12.0, 12.0, 9.0, 14.0, 12.0, 2.0, -13.0, 11.0, 13.0, -21.0, 12.0, -3.0, 14.0, -4.0, 8.0, -5.0, 7.0, 6.0, 7.0, 8.0, 9.0, 7.0, -9.0, 14.0, -1.0, -10.0, 12.0, 3.0, 14.0, -13.0, 11.0, 14.0, 10.0, -12.0, 3.0, -2.0, 4.0, 12.0, 1.0, 9.0, -1.0, 12.0, -5.0, 10.0, 11.0, -19.0, 13.0, 13.0, 11.0, -13.0, 4.0, -13.0, 11.0, 11.0, 6.0, 2.0, -1.0, 2.0, 12.0, 3.0, 14.0, -13.0, 11.0, 11.0, -2.0, -4.0, 10.0, 10.0, 11.0, 7.0, -13.0, 13.0, -1.0, -9.0, 12.0, 2.0, 14.0, -3.0, 2.0, -19.0, 8.0, 13.0, 13.0, 13.0, 12.0, 8.0, -18.0, 12.0, -6.0, -4.0, 13.0, -2.0, 14.0, -8.0, 11.0, 7.0, 11.0, 11.0, -14.0, 13.0, 7.0, 7.0, -12.0, 13.0, -6.0, 9.0, -1.0, -1.0, 14.0, -3.0, 5.0, -12.0, 6.0, 10.0, 11.0, 9.0, 12.0, 8.0, -14.0, 9.0, -6.0, 0.0, 12.0, 4.0, 12.0, -14.0, 13.0, -11.0, 10.0, 9.0, 7.0, 13.0, 11.0, 5.0, -14.0, 14.0, -1.0, -8.0, 10.0, -10.0, 14.0, 0.0, 11.0, -6.0, 12.0, -3.0, 12.0, 8.0, 6.0, 9.0, -8.0, 13.0, -2.0, -7.0, 11.0, 5.0, 14.0, -10.0, 6.0, 11.0, 4.0, 5.0, -5.0, -5.0, 11.0, 8.0, 1.0, 13.0, -2.0, -6.0, 10.0, -18.0, 14.0, 7.0, 12.0, -5.0, 7.0, 6.0, 7.0, 3.0, 13.0, 9.0, -10.0, 14.0, -1.0, -9.0, 11.0, 4.0, 9.0, -10.0, 12.0, 1.0, 6.0, 9.0, -1.0, 9.0, -8.0, 9.0, 5.0, 8.0, -1.0, 3.0, 5.0, 1.0, 14.0, -8.0, 8.0, 12.0, 5.0, -5.0, 3.0, 5.0, -1.0, 6.0, 5.0, 14.0, -6.0, -2.0, 9.0, 3.0, 13.0, -8.0, 7.0, -13.0, 4.0, 13.0, 11.0, -9.0, 8.0, 6.0, 10.0, 13.0, -1.0, -9.0, 12.0, 1.0, 14.0, 11.0, -11.0, -14.0, 11.0, 6.0, 12.0, -6.0, 11.0, 5.0, 5.0, 5.0, -1.0, 0.0, 11.0, 1.0, 13.0, -8.0, 9.0, -11.0, 11.0, 9.0, 6.0, -11.0, 11.0, 10.0, 5.0, 8.0, -1.0, -2.0, 10.0, 3.0, 11.0, -7.0, 8.0, 7.0, -10.0, 8.0, 10.0, 13.0, 9.0, 1.0, -8.0, 14.0, 13.0, 319.0, 10.0, 9.0, 8.0, -15.0, 13.0, 8.0, -6.0, 7.0, 6.0, 14.0, 6.0, 10.0, -15.0, 3.0, -1.0, 13.0, 0.0, -1.0, 10.0, -6.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2202092740865739, "mean_inference_ms": 1.1739981139877957, "mean_action_processing_ms": 0.07184273184804824, "mean_env_wait_ms": 0.17909334119082915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 540000, "agent_timesteps_total": 539919, "timers": {"sample_time_ms": 350.408, "sample_throughput": 15410.614, "learn_time_ms": 6971.891, "learn_throughput": 774.539, "update_time_ms": 11.198}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 647.14697265625, "policy_loss": -0.020468175411224365, "vf_loss": 647.163818359375, "vf_explained_var": 0.12891815602779388, "kl": 0.007141387555748224, "entropy": 0.4592607617378235, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 540000, "num_agent_steps_sampled": 539919, "num_steps_trained": 540000, "num_agent_steps_trained": 539919}, "done": false, "episodes_total": 10584, "training_iteration": 100, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-53-51", "timestamp": 1626861231, "time_this_iter_s": 7.1821653842926025, "time_total_s": 732.911737203598, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021cc80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 732.911737203598, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 23.04, "ram_util_percent": 14.270000000000001}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.314814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 13.0, 3.0, -14.0, -18.0, 11.0, 11.0, 11.0, 11.0, 7.0, -15.0, 12.0, 13.0, 2.0, 2.0, -2.0, 14.0, -5.0, 5.0, 1.0, 1.0, 11.0, 10.0, -7.0, 14.0, 10.0, 317.0, 13.0, 7.0, 7.0, 11.0, -10.0, -12.0, 12.0, 10.0, 5.0, 7.0, 13.0, 9.0, -14.0, 10.0, -4.0, -3.0, 12.0, 14.0, 5.0, -2.0, -2.0, 12.0, -7.0, 0.0, 10.0, 14.0, 9.0, 8.0, -16.0, 7.0, -7.0, 3.0, 12.0, 9.0, 4.0, -9.0, 11.0, 13.0, -7.0, 2.0, 7.0, 3.0, 13.0, 9.0, -10.0, 6.0, -2.0, -1.0, 12.0, 13.0, 12.0, -2.0, -8.0, 13.0, 2.0, 12.0, -12.0, 7.0, -1.0, 7.0, 2.0, 319.0, 11.0, 11.0, 11.0, 4.0, 6.0, -7.0, 12.0, 14.0, -18.0, 7.0, 12.0, 13.0, 7.0, 12.0, -17.0, 6.0, -4.0, 2.0, 11.0, 13.0, 5.0, -9.0, 6.0, 6.0, -9.0, 12.0, 6.0, 13.0, 12.0, 5.0, -15.0, 6.0, 8.0, -9.0, 10.0, 13.0, 7.0, -4.0, -1.0, 12.0, -11.0, 6.0, 8.0, 2.0, 4.0, 12.0, -3.0, 6.0, -10.0, 7.0, 12.0, 13.0, 9.0, 7.0, -14.0, 7.0, -11.0, 12.0, 7.0, 3.0, -9.0, 9.0, 12.0, 9.0, -3.0, 0.0, 9.0, 5.0, 11.0, 2.0, -3.0, 13.0, -5.0, 3.0, 4.0, 9.0, 13.0, 13.0, -20.0, 2.0, -2.0, 2.0, 13.0, 9.0, 4.0, 4.0, -2.0, 14.0, -9.0, 2.0, 8.0, -14.0, 11.0, 6.0, 12.0, 9.0, 8.0, -15.0, 13.0, 12.0, 5.0, -8.0, 6.0, 13.0, -7.0, 1.0, 8.0, 9.0, 7.0, 13.0, -14.0, 3.0, -3.0, 2.0, 13.0, 13.0, 11.0, -7.0, -2.0, 11.0, 3.0, -5.0, 6.0, 8.0, -5.0, 12.0, 0.0, 0.0, -2.0, 6.0, 11.0, 13.0, 4.0, -13.0, 11.0, -14.0, 6.0, 13.0, 10.0, 8.0, 13.0, 9.0, -15.0, 9.0, -3.0, -4.0, 13.0, 3.0, 13.0, 1.0, -2.0, -10.0, 8.0, 4.0, 13.0, 2.0, 6.0, -5.0, 12.0, 7.0, -1.0, -4.0, 13.0, 8.0, 3.0, -2.0, 6.0, 8.0, -6.0, 1.0, 12.0, 3.0, 11.0, -7.0, 8.0, 5.0, -9.0, 6.0, 13.0, 14.0, 5.0, -1.0, -3.0, 8.0, -15.0, 13.0, 9.0, -17.0, 13.0, 9.0, 10.0, 4.0, -2.0, 0.0, 13.0, 13.0, 1.0, -2.0, 3.0, 13.0, 7.0, 8.0, -13.0, 4.0, 10.0, -3.0, 4.0, 6.0, -2.0, -2.0, 13.0, 13.0, 11.0, 11.0, -20.0, 11.0, 12.0, 5.0, -13.0, 14.0, 8.0, 8.0, -15.0, 4.0, -6.0, 4.0, 13.0, 13.0, 8.0, -2.0, -4.0, 3.0, 9.0, 13.0, -10.0, 5.0, 9.0, 9.0, -8.0, 11.0, 5.0, -12.0, 11.0, 8.0, 6.0, 3.0, -2.0, 3.0, -10.0, 12.0, 10.0, 8.0, 13.0, -4.0, -2.0, 8.0, -9.0, 3.0, 13.0, 13.0, 3.0, -7.0, 6.0, 8.0, -4.0, 4.0, 7.0, 14.0, 13.0, -1.0, -11.0, 2.0, -4.0, 5.0, 12.0, 13.0, 8.0, -16.0, 10.0, 13.0, -11.0, 8.0, 5.0, 9.0, 12.0, -19.0, 13.0, 5.0, -8.0, 8.0, 10.0, 14.0, 11.0, -3.0, -7.0, 14.0, -14.0, 7.0, 8.0, 8.0, 13.0, 5.0, -11.0, 8.0, 9.0, -15.0, 13.0, 13.0, 7.0, -4.0, -1.0, 3.0, -8.0, 9.0, 11.0, -2.0, -1.0, 8.0, 10.0, 10.0, -10.0, 2.0, 13.0, 9.0, 4.0, 4.0, -2.0, 13.0, 10.0, 6.0, -14.0, 4.0, 4.0, 12.0, -5.0, 12.0, -10.0, 2.0, 11.0, 12.0, 7.0, 12.0, -16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22009738199173973, "mean_inference_ms": 1.17404008786496, "mean_action_processing_ms": 0.07184428870863178, "mean_env_wait_ms": 0.17907592169256853, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 545400, "agent_timesteps_total": 545320, "timers": {"sample_time_ms": 350.172, "sample_throughput": 15421.01, "learn_time_ms": 6971.718, "learn_throughput": 774.558, "update_time_ms": 11.182}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 440.8496398925781, "policy_loss": -0.028510503470897675, "vf_loss": 440.8742370605469, "vf_explained_var": 0.12055190652608871, "kl": 0.007794956211000681, "entropy": 0.48312488198280334, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 545400, "num_agent_steps_sampled": 545320, "num_steps_trained": 545400, "num_agent_steps_trained": 545320}, "done": false, "episodes_total": 10692, "training_iteration": 101, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-53-58", "timestamp": 1626861238, "time_this_iter_s": 7.602018117904663, "time_total_s": 740.5137553215027, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021cd90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 740.5137553215027, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 21.181818181818183, "ram_util_percent": 14.300000000000004}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 330.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 10.0, -12.0, 5.0, -1.0, -3.0, 11.0, 8.0, -1.0, 10.0, 2.0, 4.0, 0.0, 12.0, -8.0, 11.0, 7.0, 7.0, -11.0, 12.0, 12.0, 9.0, 3.0, -9.0, 6.0, -5.0, 4.0, 10.0, 5.0, -7.0, 8.0, 9.0, 9.0, -6.0, 8.0, 4.0, 9.0, 13.0, 9.0, -16.0, 12.0, -10.0, 1.0, 12.0, 12.0, -14.0, 5.0, 12.0, -5.0, 6.0, 9.0, 5.0, -10.0, 6.0, 11.0, 8.0, 12.0, 4.0, -10.0, 9.0, -1.0, 6.0, -2.0, 12.0, 11.0, 3.0, 5.0, -4.0, 14.0, 9.0, 8.0, -16.0, -2.0, 8.0, 3.0, 6.0, 8.0, 1.0, -6.0, 12.0, 5.0, 9.0, -5.0, 6.0, 13.0, 13.0, 7.0, -18.0, -3.0, 4.0, 6.0, 8.0, 7.0, -1.0, -3.0, 12.0, 9.0, 3.0, -4.0, 7.0, 13.0, -2.0, 10.0, -6.0, -1.0, 5.0, 5.0, 6.0, 7.0, 0.0, 9.0, -1.0, -9.0, 7.0, 11.0, 6.0, 14.0, 8.0, 12.0, -19.0, -7.0, -1.0, 12.0, 11.0, 11.0, 6.0, -13.0, 11.0, 8.0, 11.0, -10.0, 6.0, 13.0, 7.0, 13.0, -18.0, -1.0, 10.0, 4.0, 2.0, 7.0, -12.0, 8.0, 12.0, 13.0, 8.0, -15.0, 9.0, 4.0, 5.0, 8.0, -2.0, 0.0, 2.0, 7.0, 6.0, -8.0, 13.0, -1.0, 11.0, -2.0, 5.0, -1.0, 13.0, 9.0, -3.0, 11.0, -2.0, 11.0, -8.0, 6.0, 6.0, -3.0, 0.0, 8.0, 10.0, 12.0, 12.0, -11.0, 2.0, -5.0, 5.0, 11.0, 4.0, -2.0, -1.0, 8.0, 10.0, 7.0, -1.0, -2.0, 11.0, 11.0, 6.0, -8.0, 6.0, 11.0, 9.0, 8.0, -13.0, 11.0, -4.0, 1.0, 7.0, -12.0, 4.0, 11.0, 12.0, -4.0, 4.0, 9.0, 6.0, -5.0, 10.0, 7.0, 3.0, 13.0, -17.0, 6.0, 13.0, -18.0, 11.0, 10.0, 12.0, 13.0, 12.0, -5.0, -5.0, 6.0, -7.0, 10.0, 6.0, -2.0, 5.0, 9.0, 3.0, 1.0, 9.0, -5.0, 10.0, 5.0, 10.0, -6.0, 6.0, -4.0, 12.0, 9.0, -2.0, -8.0, 8.0, 7.0, 8.0, 2.0, -5.0, 6.0, 12.0, -3.0, 2.0, 11.0, 5.0, 13.0, -3.0, 13.0, -8.0, -1.0, 5.0, 4.0, 7.0, 6.0, 1.0, -3.0, 11.0, 4.0, 7.0, -8.0, 12.0, -2.0, 2.0, 8.0, 7.0, 0.0, -9.0, 11.0, 13.0, -6.0, 7.0, 2.0, 12.0, -9.0, 8.0, 8.0, 8.0, -1.0, -2.0, 9.0, 9.0, -1.0, 5.0, 4.0, 7.0, -11.0, 6.0, 8.0, 12.0, -2.0, 1.0, 8.0, 8.0, 12.0, 1.0, 11.0, -9.0, -4.0, 2.0, 10.0, 7.0, 8.0, 1.0, -6.0, 12.0, 12.0, 8.0, 2.0, -7.0, -3.0, 2.0, 11.0, 5.0, -10.0, 1.0, 11.0, 13.0, 12.0, 1.0, -9.0, 11.0, 11.0, 9.0, -7.0, 2.0, -5.0, -1.0, 13.0, 8.0, 12.0, 330.0, 13.0, 12.0, 2.0, 8.0, -6.0, 11.0, 6.0, 3.0, -5.0, 11.0, 11.0, 5.0, 7.0, -8.0, -5.0, 4.0, 6.0, 10.0, 5.0, -11.0, 11.0, 10.0, 12.0, -5.0, -5.0, 13.0, 11.0, -6.0, 7.0, 3.0, -2.0, 10.0, 5.0, 2.0, 10.0, -5.0, -2.0, 12.0, -1.0, 7.0, 9.0, 0.0, -1.0, 6.0, 12.0, -2.0, -2.0, 10.0, 5.0, 2.0, 5.0, 4.0, -4.0, 10.0, 0.0, 4.0, 6.0, 5.0, 11.0, -2.0, 12.0, -6.0, -4.0, 3.0, 5.0, 11.0, 1.0, -7.0, 9.0, 12.0, 9.0, 4.0, -6.0, 8.0, 8.0, 13.0, 9.0, -15.0, -2.0, -1.0, 8.0, 10.0, 5.0, 7.0, -9.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21989454318271337, "mean_inference_ms": 1.1735449769144775, "mean_action_processing_ms": 0.07181669590152777, "mean_env_wait_ms": 0.17903209394629938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 550800, "agent_timesteps_total": 550800, "timers": {"sample_time_ms": 348.488, "sample_throughput": 15495.506, "learn_time_ms": 6875.434, "learn_throughput": 785.405, "update_time_ms": 11.022}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 239.01605224609375, "policy_loss": -0.03194683417677879, "vf_loss": 239.04319763183594, "vf_explained_var": 0.13642708957195282, "kl": 0.009514125064015388, "entropy": 0.4929623305797577, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 550800, "num_agent_steps_sampled": 550800, "num_steps_trained": 550800, "num_agent_steps_trained": 550800}, "done": false, "episodes_total": 10800, "training_iteration": 102, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-54-05", "timestamp": 1626861245, "time_this_iter_s": 6.602916955947876, "time_total_s": 747.1166722774506, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021cae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 747.1166722774506, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 24.644444444444446, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 12.0, -6.0, 2.0, 4.0, 9.0, -10.0, 12.0, -17.0, 13.0, 8.0, 11.0, 8.0, 12.0, -7.0, 2.0, -2.0, 9.0, 9.0, -1.0, -16.0, 11.0, 9.0, 11.0, 7.0, 9.0, -2.0, 1.0, 0.0, 11.0, -8.0, 12.0, 2.0, 7.0, -2.0, 8.0, 6.0, 10.0, -2.0, 1.0, 9.0, 12.0, -10.0, 4.0, -13.0, 7.0, 13.0, 8.0, 0.0, 10.0, -7.0, 12.0, 3.0, 8.0, -8.0, 12.0, -6.0, 7.0, 12.0, 2.0, 11.0, 12.0, -5.0, -3.0, -1.0, -3.0, 7.0, 12.0, -15.0, 12.0, 11.0, 7.0, 1.0, -6.0, 10.0, 10.0, 5.0, -4.0, 11.0, 3.0, -6.0, 5.0, 8.0, 8.0, 5.0, 10.0, 3.0, -3.0, 4.0, 9.0, 4.0, -2.0, 11.0, 7.0, -5.0, 2.0, 8.0, 9.0, 2.0, -4.0, 2.0, 7.0, -6.0, 12.0, 8.0, 10.0, -3.0, 0.0, 9.0, -4.0, -1.0, 11.0, -12.0, 6.0, 10.0, 11.0, -9.0, 8.0, 8.0, 8.0, 5.0, -2.0, 11.0, 1.0, 1.0, 10.0, 5.0, -1.0, -4.0, 6.0, 12.0, 1.0, 7.0, -1.0, 11.0, -2.0, -13.0, 11.0, 5.0, 12.0, 5.0, 12.0, -4.0, 2.0, 7.0, 10.0, -3.0, 1.0, 13.0, 4.0, -1.0, -1.0, 0.0, -9.0, 12.0, 12.0, 7.0, -4.0, 10.0, 2.0, 5.0, 7.0, -8.0, 11.0, -7.0, 8.0, 13.0, 1.0, 13.0, -2.0, 7.0, -3.0, 9.0, 7.0, -12.0, 11.0, -16.0, 11.0, 9.0, 11.0, 7.0, -2.0, 1.0, 9.0, 13.0, 12.0, -9.0, -1.0, 1.0, -4.0, 12.0, 6.0, 5.0, -1.0, 10.0, 1.0, 7.0, 8.0, -2.0, 2.0, -4.0, 9.0, 10.0, 0.0, 2.0, -4.0, 10.0, 7.0, 5.0, 9.0, -11.0, 12.0, -5.0, 3.0, 11.0, 6.0, 6.0, 13.0, -5.0, 1.0, 4.0, 9.0, -4.0, 6.0, -7.0, 7.0, 11.0, 4.0, -3.0, -3.0, 10.0, 11.0, 2.0, 10.0, 5.0, -2.0, 13.0, 5.0, 6.0, -9.0, 6.0, 0.0, 8.0, 1.0, 6.0, 4.0, -7.0, 12.0, -12.0, 6.0, 8.0, 13.0, 8.0, -2.0, 10.0, -1.0, 5.0, 10.0, -11.0, 11.0, -17.0, 13.0, 7.0, 12.0, 8.0, 13.0, -4.0, -2.0, 6.0, 3.0, 9.0, -3.0, -5.0, 12.0, 13.0, -5.0, 7.0, -8.0, 10.0, 6.0, 4.0, 8.0, 5.0, -2.0, -5.0, 1.0, 7.0, 12.0, 12.0, 4.0, -4.0, 3.0, 2.0, 11.0, -10.0, 12.0, 5.0, 7.0, 11.0, -8.0, 6.0, -1.0, 10.0, 0.0, 2.0, 4.0, 11.0, -2.0, -3.0, 7.0, 4.0, 7.0, 9.0, -3.0, -2.0, 11.0, 13.0, 2.0, 2.0, -2.0, -6.0, 7.0, 7.0, 7.0, 11.0, 5.0, 7.0, -8.0, -5.0, 4.0, 6.0, 10.0, 5.0, -11.0, 11.0, 10.0, 12.0, -5.0, -5.0, 13.0, 11.0, -6.0, 7.0, 3.0, -2.0, 10.0, 5.0, 2.0, 10.0, -5.0, -2.0, 12.0, -1.0, 7.0, 9.0, 0.0, -1.0, 6.0, 12.0, -2.0, -2.0, 10.0, 5.0, 2.0, 5.0, 4.0, -4.0, 10.0, 0.0, 4.0, 6.0, 5.0, 11.0, -2.0, 12.0, -6.0, -4.0, 3.0, 5.0, 11.0, 1.0, -7.0, 9.0, 12.0, 9.0, 4.0, -6.0, 8.0, 8.0, 13.0, 9.0, -15.0, -2.0, -1.0, 8.0, 10.0, 5.0, 7.0, -9.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21964551390778678, "mean_inference_ms": 1.171974897602152, "mean_action_processing_ms": 0.07177377089467743, "mean_env_wait_ms": 0.1788474368306609, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 556200, "agent_timesteps_total": 556119, "timers": {"sample_time_ms": 346.93, "sample_throughput": 15565.105, "learn_time_ms": 6766.364, "learn_throughput": 798.065, "update_time_ms": 11.05}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 23.452266693115234, "policy_loss": -0.09087046980857849, "vf_loss": 23.533771514892578, "vf_explained_var": 0.25414806604385376, "kl": 0.018496086820960045, "entropy": 0.48531201481819153, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 556200, "num_agent_steps_sampled": 556119, "num_steps_trained": 556200, "num_agent_steps_trained": 556119}, "done": false, "episodes_total": 10881, "training_iteration": 103, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-54-12", "timestamp": 1626861252, "time_this_iter_s": 6.470517635345459, "time_total_s": 753.587189912796, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cd90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 753.587189912796, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 23.86, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [2.0, -3.0, 3.0, 13.0, 5.0, 13.0, 10.0, -13.0, 14.0, 13.0, 3.0, -15.0, 7.0, 2.0, 9.0, -3.0, -7.0, 8.0, 11.0, 3.0, 11.0, 14.0, -17.0, 7.0, 5.0, -7.0, 6.0, 11.0, 5.0, -8.0, 13.0, 5.0, 7.0, 6.0, -11.0, 13.0, 1.0, 14.0, 2.0, -2.0, -6.0, 5.0, 9.0, 7.0, 1.0, 6.0, 9.0, -1.0, -3.0, 7.0, -2.0, 13.0, 3.0, 11.0, 10.0, -9.0, 13.0, 10.0, -15.0, 7.0, -10.0, 7.0, 7.0, 11.0, 3.0, -2.0, 2.0, 12.0, 10.0, 14.0, 9.0, -18.0, 9.0, -6.0, 0.0, 12.0, 8.0, -14.0, 8.0, 13.0, -11.0, 9.0, 5.0, 12.0, 2.0, -7.0, 8.0, 12.0, 14.0, -17.0, 11.0, 7.0, 8.0, 7.0, 10.0, -10.0, -1.0, 6.0, -2.0, 12.0, 12.0, 14.0, -3.0, -8.0, 9.0, 0.0, 1.0, 5.0, 11.0, -2.0, -1.0, 7.0, 7.0, 12.0, -17.0, 13.0, 1.0, 13.0, -6.0, 7.0, 8.0, 9.0, -9.0, 7.0, 5.0, 8.0, 6.0, -4.0, 8.0, 10.0, -14.0, 11.0, 6.0, 14.0, -8.0, 3.0, 13.0, 4.0, -7.0, 5.0, -4.0, -6.0, 12.0, 13.0, 11.0, -14.0, 5.0, 13.0, 11.0, 14.0, -8.0, -2.0, 14.0, -14.0, 9.0, 6.0, 1.0, -9.0, 11.0, 12.0, -2.0, 2.0, 2.0, 13.0, 6.0, 14.0, -3.0, -2.0, 13.0, -9.0, 6.0, 5.0, 9.0, 8.0, 4.0, -6.0, 5.0, 9.0, -11.0, 12.0, 10.0, 9.0, 11.0, -15.0, 11.0, -2.0, 12.0, -6.0, 2.0, -3.0, 3.0, 13.0, 7.0, 13.0, 5.0, -10.0, 8.0, 9.0, -14.0, 12.0, 8.0, 9.0, 5.0, -7.0, -6.0, 1.0, 10.0, 10.0, 1.0, 13.0, -12.0, 13.0, 10.0, 14.0, -4.0, -5.0, 9.0, -10.0, 5.0, 11.0, 4.0, -6.0, 5.0, 12.0, 5.0, 9.0, -11.0, 12.0, 7.0, 14.0, 6.0, -12.0, 13.0, -4.0, 1.0, 5.0, -3.0, 12.0, -1.0, 7.0, -10.0, 12.0, 12.0, 1.0, 11.0, 14.0, 11.0, 320.0, 10.0, 8.0, -8.0, 5.0, 2.0, 11.0, 3.0, -1.0, -15.0, 8.0, 12.0, 10.0, 10.0, 14.0, 9.0, -18.0, 10.0, 7.0, -11.0, 9.0, 3.0, 10.0, 3.0, -1.0, -4.0, 13.0, 12.0, -6.0, 6.0, 14.0, -3.0, -2.0, 14.0, 8.0, -12.0, 5.0, 1.0, -5.0, 9.0, 10.0, 11.0, 0.0, -9.0, 13.0, 3.0, 14.0, -15.0, 13.0, 6.0, -6.0, 6.0, 9.0, 7.0, -2.0, -2.0, 12.0, 12.0, 3.0, -13.0, 13.0, 11.0, 5.0, -13.0, 12.0, 14.0, -3.0, -2.0, 6.0, 7.0, 3.0, 6.0, -1.0, -7.0, 12.0, -3.0, 13.0, 10.0, 13.0, -15.0, 7.0, 10.0, 12.0, -15.0, 8.0, -1.0, 11.0, 6.0, -1.0, 4.0, -7.0, 5.0, 13.0, -9.0, 6.0, 6.0, 12.0, 10.0, 3.0, -5.0, 7.0, -3.0, 0.0, 10.0, 8.0, 12.0, 4.0, -14.0, 13.0, 11.0, 14.0, 8.0, -18.0, 10.0, 3.0, 7.0, -5.0, 3.0, 6.0, -6.0, 12.0, -6.0, 12.0, -4.0, 13.0, 1.0, 14.0, -12.0, 12.0, 8.0, 14.0, -14.0, 7.0, -13.0, 11.0, 10.0, 7.0, 2.0, -5.0, 5.0, 13.0, 10.0, 10.0, -3.0, -2.0, 14.0, -3.0, 3.0, 1.0, 5.0, -2.0, 4.0, 8.0, -14.0, 12.0, 4.0, 13.0, 11.0, 14.0, 6.0, -16.0, 13.0, 5.0, -9.0, 6.0, 1.0, 9.0, 6.0, -1.0, 11.0, 4.0, -13.0, 13.0, -3.0, 14.0, 9.0, -5.0, 9.0, 12.0, 3.0, -9.0, 6.0, -10.0, 11.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.219795725525423, "mean_inference_ms": 1.172824047367451, "mean_action_processing_ms": 0.0717637494875065, "mean_env_wait_ms": 0.17895223380243533, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 561600, "agent_timesteps_total": 561519, "timers": {"sample_time_ms": 346.308, "sample_throughput": 15593.069, "learn_time_ms": 6665.462, "learn_throughput": 810.146, "update_time_ms": 11.025}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 226.0076141357422, "policy_loss": -0.026339832693338394, "vf_loss": 226.0299530029297, "vf_explained_var": 0.2128124237060547, "kl": 0.007918776012957096, "entropy": 0.48764291405677795, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 561600, "num_agent_steps_sampled": 561519, "num_steps_trained": 561600, "num_agent_steps_trained": 561519}, "done": false, "episodes_total": 10989, "training_iteration": 104, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-54-18", "timestamp": 1626861258, "time_this_iter_s": 6.606964111328125, "time_total_s": 760.1941540241241, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 760.1941540241241, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 24.244444444444444, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.64814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 7.662037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, -1.0, 12.0, 0.0, 11.0, 13.0, -2.0, -7.0, -9.0, 8.0, 13.0, 3.0, 13.0, -8.0, 5.0, 5.0, 13.0, 11.0, 318.0, 10.0, 6.0, 13.0, -14.0, 10.0, 1.0, -2.0, 13.0, 3.0, 8.0, -8.0, 5.0, 10.0, 8.0, 11.0, -15.0, 11.0, 12.0, 11.0, -2.0, -6.0, 8.0, -4.0, 5.0, 6.0, 14.0, 0.0, -3.0, 4.0, -2.0, 8.0, -2.0, 11.0, 4.0, 7.0, 12.0, -8.0, -17.0, 9.0, 12.0, 11.0, 14.0, -3.0, 4.0, 0.0, 8.0, 13.0, -14.0, 8.0, 8.0, 8.0, -3.0, 2.0, 1.0, -6.0, 13.0, 7.0, 13.0, -14.0, 7.0, 9.0, 4.0, 0.0, 2.0, 9.0, 10.0, 1.0, 5.0, -1.0, 5.0, 10.0, 12.0, -12.0, 12.0, -17.0, 7.0, 13.0, 13.0, 8.0, -15.0, 9.0, 8.0, 10.0, 6.0, -9.0, -13.0, 12.0, 13.0, 3.0, 11.0, -15.0, 12.0, 7.0, 9.0, 13.0, -17.0, 10.0, 8.0, 7.0, 9.0, -9.0, 318.0, 12.0, 13.0, 10.0, 13.0, -7.0, 10.0, -1.0, 12.0, 11.0, 10.0, -18.0, 7.0, 3.0, 12.0, -7.0, -17.0, 11.0, 12.0, 9.0, 12.0, -19.0, 10.0, 12.0, 13.0, 3.0, 7.0, -8.0, 7.0, 10.0, -4.0, 2.0, 2.0, -1.0, 12.0, 2.0, 11.0, -16.0, 7.0, 13.0, 4.0, -3.0, 2.0, 12.0, 9.0, 8.0, 9.0, -11.0, 6.0, 8.0, 12.0, -11.0, -2.0, -5.0, 11.0, 11.0, 10.0, -3.0, 8.0, 0.0, 4.0, 12.0, 7.0, -8.0, 6.0, 12.0, 2.0, -5.0, -2.0, 3.0, 6.0, 8.0, 11.0, 13.0, -17.0, 8.0, 7.0, 7.0, 4.0, -3.0, 7.0, -5.0, 3.0, 10.0, 6.0, -15.0, 12.0, 12.0, 11.0, -11.0, 10.0, 5.0, 9.0, 9.0, 4.0, -7.0, -5.0, 8.0, 2.0, 10.0, 11.0, -15.0, 11.0, 8.0, 14.0, 12.0, 318.0, 8.0, 10.0, 9.0, 7.0, -11.0, 10.0, 13.0, -4.0, -4.0, 14.0, 6.0, -11.0, 6.0, 14.0, 11.0, -19.0, 9.0, 2.0, 7.0, 13.0, -7.0, -11.0, 12.0, 13.0, 1.0, 12.0, 318.0, 13.0, 11.0, 12.0, 3.0, -6.0, 6.0, 12.0, 13.0, -1.0, -9.0, -16.0, 12.0, 12.0, 7.0, 13.0, -18.0, 12.0, 8.0, 7.0, 13.0, 10.0, -15.0, 7.0, 13.0, 2.0, -7.0, 4.0, 11.0, 8.0, -8.0, -3.0, 4.0, 9.0, 5.0, 12.0, 5.0, -10.0, 8.0, 4.0, 13.0, -5.0, 3.0, 9.0, 8.0, 2.0, -4.0, 12.0, -12.0, 7.0, 8.0, 6.0, 10.0, 12.0, -13.0, 6.0, 8.0, 5.0, -4.0, 4.0, 8.0, 13.0, -10.0, 14.0, -7.0, 0.0, 8.0, 12.0, 12.0, -18.0, 9.0, 12.0, 8.0, -17.0, 12.0, -5.0, 7.0, 3.0, 10.0, 14.0, -10.0, 2.0, 9.0, 5.0, 13.0, 11.0, -14.0, 8.0, 10.0, -1.0, -2.0, 7.0, -9.0, 12.0, 5.0, 13.0, -14.0, 8.0, 8.0, 9.0, 1.0, -6.0, 11.0, 13.0, 12.0, -1.0, -9.0, -9.0, 7.0, 6.0, 11.0, 13.0, 5.0, 5.0, -8.0, 13.0, 6.0, -10.0, 6.0, 5.0, 5.0, -7.0, 12.0, -7.0, 12.0, 7.0, 3.0, 11.0, -19.0, 10.0, 13.0, 13.0, 13.0, 5.0, -16.0, 6.0, 2.0, -4.0, 11.0, 318.0, 13.0, 13.0, 10.0, 13.0, -11.0, 4.0, 9.0, 5.0, 8.0, -2.0, 4.0, 5.0, 11.0, 5.0, -6.0, -3.0, -1.0, 11.0, 8.0, 7.0, -14.0, 10.0, 12.0, 11.0, -17.0, 10.0, 11.0, 5.0, 7.0, -4.0, 7.0, 7.0, 12.0, 12.0, -16.0, -2.0, 10.0, 5.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21984932447769512, "mean_inference_ms": 1.1728368472693222, "mean_action_processing_ms": 0.07175478735189864, "mean_env_wait_ms": 0.17895112486057696, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 567000, "agent_timesteps_total": 566919, "timers": {"sample_time_ms": 347.273, "sample_throughput": 15549.713, "learn_time_ms": 6576.338, "learn_throughput": 821.126, "update_time_ms": 10.956}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 767.1644287109375, "policy_loss": -0.020145945250988007, "vf_loss": 767.1810302734375, "vf_explained_var": 0.10691887885332108, "kl": 0.007108827121555805, "entropy": 0.48876553773880005, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 567000, "num_agent_steps_sampled": 566919, "num_steps_trained": 567000, "num_agent_steps_trained": 566919}, "done": false, "episodes_total": 11097, "training_iteration": 105, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-54-25", "timestamp": 1626861265, "time_this_iter_s": 6.6980133056640625, "time_total_s": 766.8921673297882, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029ce18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 766.8921673297882, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 24.05, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, -6.0, 11.0, 6.0, 8.0, 13.0, -15.0, 9.0, 9.0, 8.0, -3.0, 1.0, 12.0, 5.0, -15.0, 13.0, 6.0, -16.0, 13.0, 12.0, 12.0, 8.0, 11.0, -16.0, -8.0, 12.0, 10.0, 1.0, 11.0, 10.0, -12.0, 6.0, 7.0, -9.0, 10.0, 7.0, 3.0, 2.0, 12.0, -2.0, 8.0, 1.0, 12.0, -6.0, -4.0, 7.0, 5.0, 7.0, 2.0, 12.0, -4.0, 5.0, 13.0, 5.0, -14.0, 11.0, 11.0, -6.0, 3.0, 7.0, 0.0, 7.0, -3.0, 11.0, 6.0, -8.0, 6.0, 11.0, 3.0, 11.0, 12.0, -11.0, 10.0, -11.0, 12.0, 4.0, 13.0, 2.0, 5.0, -5.0, -13.0, 12.0, 12.0, 4.0, 3.0, 13.0, 12.0, -13.0, 8.0, 6.0, 3.0, -2.0, 11.0, 7.0, -8.0, 5.0, 6.0, -3.0, 0.0, 12.0, 5.0, 9.0, -11.0, 12.0, 9.0, 4.0, 8.0, -6.0, 5.0, 9.0, -6.0, 7.0, 12.0, -13.0, 7.0, 9.0, 7.0, 14.0, 11.0, -17.0, 5.0, -8.0, 9.0, 9.0, 12.0, 8.0, -16.0, 11.0, 7.0, -7.0, 6.0, 9.0, 3.0, 5.0, -2.0, 9.0, -10.0, 6.0, 10.0, 9.0, 3.0, 2.0, -2.0, 12.0, 5.0, 13.0, -13.0, 10.0, 2.0, -8.0, 11.0, 10.0, 8.0, -11.0, 8.0, 10.0, 13.0, 3.0, 3.0, -4.0, 2.0, -5.0, 12.0, 6.0, -1.0, 9.0, 9.0, -2.0, 7.0, -11.0, 6.0, 13.0, -1.0, -3.0, 8.0, 11.0, -9.0, 6.0, 9.0, 9.0, 9.0, 11.0, -16.0, 11.0, 0.0, 12.0, 10.0, -7.0, 13.0, -3.0, -2.0, 7.0, 8.0, -4.0, 12.0, -1.0, -14.0, 12.0, 10.0, 7.0, 13.0, -15.0, 6.0, 11.0, 9.0, 9.0, -7.0, 4.0, 5.0, -4.0, 11.0, 3.0, 13.0, 4.0, 11.0, -13.0, -6.0, 11.0, 3.0, 7.0, 11.0, 6.0, 2.0, -4.0, 3.0, 0.0, 2.0, 10.0, 1.0, -6.0, 11.0, 9.0, 5.0, -9.0, 8.0, 11.0, -8.0, 10.0, 1.0, 12.0, 9.0, -3.0, -1.0, 10.0, -1.0, 9.0, -5.0, 12.0, 8.0, -13.0, 7.0, 13.0, -2.0, 3.0, 7.0, 7.0, -2.0, 6.0, 7.0, 4.0, 7.0, 8.0, 10.0, -10.0, 13.0, -20.0, 12.0, 10.0, 14.0, 4.0, -15.0, 12.0, 6.0, -2.0, 6.0, 5.0, 4.0, 13.0, 11.0, -13.0, 7.0, 11.0, 9.0, -12.0, 10.0, 5.0, 8.0, -8.0, 6.0, -3.0, 0.0, 12.0, 2.0, 9.0, 9.0, -5.0, 6.0, -9.0, 11.0, 7.0, 14.0, 5.0, -10.0, 6.0, -3.0, 9.0, 0.0, 9.0, -19.0, 11.0, 11.0, 12.0, 9.0, -5.0, 4.0, 7.0, 10.0, -9.0, 7.0, 7.0, 10.0, -12.0, 11.0, 6.0, 7.0, -11.0, 8.0, 11.0, -2.0, 8.0, 10.0, -1.0, 13.0, 2.0, -9.0, 9.0, 12.0, -12.0, 12.0, 3.0, 3.0, -10.0, 11.0, 11.0, 4.0, 7.0, 11.0, -7.0, 14.0, -10.0, 0.0, 11.0, 8.0, -15.0, 11.0, 11.0, 12.0, 13.0, 6.0, -16.0, -8.0, 3.0, 7.0, 13.0, -14.0, 6.0, 11.0, 12.0, 2.0, 12.0, -3.0, 4.0, 4.0, -7.0, 9.0, 9.0, 6.0, -12.0, 8.0, 13.0, -2.0, 10.0, 0.0, 7.0, 9.0, 6.0, 9.0, -9.0, 7.0, 4.0, 12.0, -8.0, 13.0, -3.0, 11.0, -6.0, 10.0, 11.0, 5.0, -11.0, 5.0, -3.0, 10.0, 3.0, -12.0, 12.0, 5.0, 10.0, 13.0, -19.0, 9.0, 12.0, 13.0, 2.0, -6.0, 6.0, 13.0, -18.0, 13.0, 7.0, 13.0, 6.0, -15.0, 11.0, 4.0, 3.0, 12.0, -4.0, 13.0, 4.0, 2.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2198607219369126, "mean_inference_ms": 1.1725713866548604, "mean_action_processing_ms": 0.07174055808488392, "mean_env_wait_ms": 0.1789628847639714, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 572400, "agent_timesteps_total": 572319, "timers": {"sample_time_ms": 347.661, "sample_throughput": 15532.388, "learn_time_ms": 6476.945, "learn_throughput": 833.726, "update_time_ms": 10.876}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 30.461978912353516, "policy_loss": -0.07767804712057114, "vf_loss": 30.530641555786133, "vf_explained_var": 0.21846725046634674, "kl": 0.017804570496082306, "entropy": 0.45167458057403564, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 572400, "num_agent_steps_sampled": 572319, "num_steps_trained": 572400, "num_agent_steps_trained": 572319}, "done": false, "episodes_total": 11205, "training_iteration": 106, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-54-32", "timestamp": 1626861272, "time_this_iter_s": 6.639143228530884, "time_total_s": 773.5313105583191, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70209c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 773.5313105583191, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 24.555555555555557, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.62037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 323.0}, "policy_reward_mean": {"learned": 6.905092592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, 13.0, 5.0, -6.0, 1.0, 12.0, -10.0, 12.0, -14.0, 13.0, 12.0, 4.0, 13.0, -5.0, 11.0, -4.0, -14.0, 14.0, 10.0, 5.0, 1.0, 9.0, -8.0, 13.0, 6.0, -1.0, 1.0, 9.0, 12.0, -10.0, 8.0, 5.0, 5.0, 13.0, 0.0, -3.0, 13.0, 9.0, -8.0, 1.0, -4.0, 6.0, 4.0, 9.0, 11.0, -16.0, 10.0, 10.0, 1.0, 13.0, -9.0, 10.0, 11.0, 8.0, 4.0, -8.0, 7.0, -3.0, 12.0, -1.0, 12.0, 3.0, 9.0, -9.0, 2.0, 14.0, -8.0, 7.0, 0.0, 10.0, -7.0, 12.0, 10.0, -12.0, 10.0, 7.0, 13.0, 4.0, 3.0, -5.0, 11.0, 13.0, -8.0, -1.0, 12.0, 8.0, -14.0, 9.0, 3.0, 9.0, 9.0, -6.0, 14.0, 0.0, 11.0, -10.0, -1.0, 13.0, -9.0, 12.0, 1.0, 7.0, -5.0, 12.0, -8.0, 13.0, -2.0, 12.0, 13.0, 1.0, 7.0, -6.0, 3.0, 13.0, -6.0, 5.0, -10.0, 10.0, 4.0, 11.0, -5.0, 8.0, -1.0, 13.0, 12.0, 320.0, 10.0, 12.0, -8.0, 13.0, 8.0, 2.0, 1.0, 12.0, -10.0, 12.0, -10.0, 9.0, 11.0, 5.0, 12.0, 1.0, 3.0, -1.0, -1.0, 13.0, -4.0, 7.0, -13.0, 11.0, 5.0, 12.0, -6.0, 11.0, 7.0, 3.0, 12.0, -5.0, -3.0, 11.0, -14.0, 12.0, 5.0, 12.0, 8.0, 5.0, -6.0, 8.0, -4.0, 8.0, 2.0, 9.0, 13.0, 6.0, 5.0, -9.0, 1.0, 13.0, 9.0, -8.0, 12.0, 14.0, -17.0, 6.0, -17.0, 14.0, 9.0, 9.0, 12.0, 0.0, 11.0, -8.0, -8.0, 11.0, 4.0, 8.0, 4.0, 7.0, -8.0, 12.0, 6.0, 9.0, 9.0, -9.0, 12.0, 320.0, 11.0, 13.0, 9.0, 14.0, -9.0, 1.0, 11.0, 9.0, -14.0, 9.0, 10.0, -2.0, 5.0, 2.0, 10.0, -4.0, 12.0, -3.0, -10.0, 13.0, 10.0, 2.0, 7.0, 9.0, -9.0, 8.0, 4.0, -9.0, 8.0, 12.0, 11.0, 1.0, 11.0, -8.0, -7.0, 13.0, 8.0, 1.0, 320.0, 14.0, 10.0, 12.0, -8.0, 12.0, 2.0, 9.0, 11.0, -5.0, 10.0, -1.0, -5.0, 4.0, 5.0, 11.0, 0.0, 8.0, -5.0, 12.0, -9.0, 6.0, 5.0, 13.0, 12.0, 4.0, 6.0, -7.0, 6.0, 13.0, -8.0, 4.0, -2.0, 8.0, 0.0, 9.0, 8.0, -3.0, 6.0, 4.0, 13.0, -13.0, 9.0, 6.0, -9.0, 14.0, -1.0, 11.0, 5.0, 9.0, -10.0, 11.0, 0.0, 12.0, 8.0, -5.0, 12.0, -5.0, -2.0, 10.0, 7.0, 7.0, 9.0, -8.0, 1.0, 8.0, -6.0, 12.0, -12.0, 12.0, 6.0, 9.0, 12.0, 9.0, 3.0, -9.0, 1.0, 13.0, -2.0, 3.0, 9.0, 9.0, -15.0, 12.0, 4.0, 14.0, 8.0, -11.0, 11.0, -11.0, 10.0, 5.0, 2.0, 14.0, 10.0, -11.0, 9.0, 8.0, -14.0, 12.0, -8.0, 10.0, 9.0, 4.0, -1.0, -5.0, 9.0, 12.0, -7.0, 7.0, 13.0, 2.0, -2.0, 2.0, 8.0, 7.0, -11.0, 11.0, 2.0, 13.0, 12.0, 5.0, -1.0, -1.0, 3.0, 13.0, 3.0, -4.0, -9.0, 9.0, 3.0, 12.0, -4.0, 11.0, 4.0, 4.0, 12.0, 323.0, 10.0, 12.0, 2.0, 13.0, -9.0, 9.0, 4.0, -8.0, 8.0, 11.0, 5.0, 11.0, 10.0, -11.0, 9.0, 6.0, -10.0, 10.0, 2.0, 14.0, 8.0, -9.0, 3.0, 14.0, -10.0, 8.0, 8.0, -2.0, 11.0, -2.0, 13.0, -1.0, 9.0, -6.0, 2.0, 14.0, -4.0, 3.0, 5.0, 6.0, -8.0, 12.0, -8.0, 10.0, 4.0, 9.0, 13.0, -15.0, 10.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2198565852462223, "mean_inference_ms": 1.1725696253654048, "mean_action_processing_ms": 0.07173407089693172, "mean_env_wait_ms": 0.17898066109001134, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 577800, "agent_timesteps_total": 577719, "timers": {"sample_time_ms": 348.408, "sample_throughput": 15499.056, "learn_time_ms": 6376.195, "learn_throughput": 846.9, "update_time_ms": 10.908}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 869.3644409179688, "policy_loss": -0.024710923433303833, "vf_loss": 869.3854370117188, "vf_explained_var": 0.09552779048681259, "kl": 0.007009149994701147, "entropy": 0.511544942855835, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 577800, "num_agent_steps_sampled": 577719, "num_steps_trained": 577800, "num_agent_steps_trained": 577719}, "done": false, "episodes_total": 11313, "training_iteration": 107, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-54-38", "timestamp": 1626861278, "time_this_iter_s": 6.608262777328491, "time_total_s": 780.1395733356476, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70209e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 780.1395733356476, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 24.849999999999998, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-17.0, 9.0, 11.0, 12.0, 9.0, 10.0, 5.0, -9.0, 14.0, 2.0, 1.0, -2.0, 7.0, 3.0, -7.0, 12.0, -7.0, 5.0, 9.0, 8.0, 12.0, 6.0, -11.0, 8.0, 5.0, -9.0, 8.0, 11.0, -3.0, 0.0, 6.0, 12.0, -13.0, 7.0, 9.0, 12.0, 9.0, 13.0, 10.0, -17.0, 10.0, -10.0, 4.0, 11.0, 4.0, -8.0, 9.0, 10.0, -10.0, 5.0, 13.0, 7.0, 13.0, 7.0, 11.0, -16.0, 10.0, 0.0, 6.0, -1.0, 5.0, 10.0, 3.0, -3.0, 0.0, 9.0, -6.0, 12.0, 7.0, 13.0, -14.0, 9.0, 10.0, 12.0, -16.0, 9.0, 8.0, -6.0, 6.0, 7.0, -14.0, 6.0, 11.0, 12.0, 11.0, 12.0, 9.0, -17.0, 14.0, -6.0, 1.0, 6.0, 13.0, -2.0, 12.0, -8.0, 0.0, -5.0, 12.0, 8.0, 10.0, 5.0, 8.0, -8.0, 14.0, 3.0, 4.0, -6.0, 5.0, 1.0, 11.0, -2.0, -2.0, 7.0, 13.0, -3.0, 11.0, 7.0, -10.0, 7.0, 14.0, 2.0, -13.0, 12.0, 8.0, 11.0, 7.0, -11.0, -12.0, 9.0, 12.0, 6.0, 7.0, 6.0, 7.0, -5.0, 13.0, 7.0, -16.0, 11.0, 5.0, -1.0, 0.0, 11.0, -17.0, 12.0, 8.0, 12.0, 8.0, 12.0, 10.0, -15.0, 10.0, -17.0, 11.0, 11.0, 7.0, 4.0, 12.0, -8.0, -8.0, 3.0, 13.0, 7.0, 8.0, 13.0, 0.0, -6.0, 14.0, 3.0, -13.0, 11.0, 10.0, 4.0, -2.0, 3.0, -2.0, 6.0, 8.0, 3.0, 8.0, 12.0, 8.0, -13.0, 12.0, 6.0, -14.0, 11.0, 12.0, 6.0, -2.0, -1.0, -10.0, 9.0, 12.0, 4.0, 6.0, 10.0, 7.0, -8.0, 14.0, 0.0, -9.0, 10.0, 9.0, 4.0, 10.0, -8.0, 9.0, 5.0, 13.0, -12.0, 13.0, 12.0, 9.0, -19.0, 14.0, 0.0, -5.0, 6.0, -2.0, 6.0, 8.0, 3.0, 2.0, -7.0, 7.0, 13.0, 13.0, 7.0, -14.0, 9.0, 10.0, -9.0, 2.0, 12.0, 13.0, 1.0, 7.0, -6.0, -8.0, 5.0, 7.0, 11.0, 9.0, 9.0, 4.0, -7.0, 14.0, 0.0, -11.0, 12.0, 8.0, 3.0, 5.0, -1.0, -15.0, 7.0, 11.0, 12.0, 13.0, 6.0, 10.0, -14.0, 14.0, 4.0, -13.0, 10.0, 7.0, -9.0, 11.0, 6.0, -12.0, 5.0, 10.0, 12.0, 13.0, 11.0, 7.0, -16.0, 11.0, 8.0, -15.0, 11.0, 10.0, 4.0, 9.0, -8.0, 12.0, -11.0, 9.0, 5.0, 9.0, -6.0, 8.0, 4.0, 10.0, 7.0, -12.0, 10.0, 12.0, -2.0, 8.0, -3.0, -11.0, 10.0, 12.0, 4.0, 3.0, 13.0, 10.0, -11.0, 14.0, -4.0, 7.0, -2.0, 8.0, -9.0, 7.0, 9.0, 2.0, 7.0, -6.0, 12.0, 0.0, -3.0, 11.0, 7.0, 14.0, 1.0, -10.0, 10.0, 7.0, -9.0, 5.0, 12.0, -13.0, 11.0, 13.0, 4.0, 8.0, -3.0, 7.0, 3.0, 10.0, -8.0, 1.0, 12.0, 0.0, 5.0, 12.0, -2.0, 13.0, -6.0, 6.0, 2.0, 8.0, 2.0, -7.0, 12.0, 14.0, -15.0, 8.0, 8.0, 13.0, -5.0, 3.0, 4.0, 3.0, 10.0, 12.0, -10.0, 9.0, 9.0, 5.0, -8.0, 14.0, -20.0, 10.0, 11.0, 12.0, -9.0, 10.0, 2.0, -18.0, 10.0, 12.0, 11.0, 12.0, 5.0, 12.0, -14.0, 10.0, 7.0, -11.0, 9.0, 14.0, -8.0, 4.0, 5.0, -2.0, 3.0, 5.0, 9.0, 6.0, 10.0, 8.0, -9.0, 13.0, -1.0, -7.0, 10.0, 13.0, 5.0, -7.0, 4.0, -12.0, 9.0, 12.0, 6.0, 6.0, 12.0, 12.0, -15.0, 14.0, -4.0, 6.0, -1.0, 8.0, 4.0, -2.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2198279755577285, "mean_inference_ms": 1.1722384184493606, "mean_action_processing_ms": 0.07171330086513386, "mean_env_wait_ms": 0.17896051776424748, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 583200, "agent_timesteps_total": 583119, "timers": {"sample_time_ms": 347.59, "sample_throughput": 15535.556, "learn_time_ms": 6355.814, "learn_throughput": 849.616, "update_time_ms": 11.088}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 26.790050506591797, "policy_loss": -0.08980537950992584, "vf_loss": 26.869861602783203, "vf_explained_var": 0.2996087074279785, "kl": 0.019735395908355713, "entropy": 0.4667430818080902, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 583200, "num_agent_steps_sampled": 583119, "num_steps_trained": 583200, "num_agent_steps_trained": 583119}, "done": false, "episodes_total": 11421, "training_iteration": 108, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-54-45", "timestamp": 1626861285, "time_this_iter_s": 6.591664791107178, "time_total_s": 786.7312381267548, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70209ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 786.7312381267548, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 24.43333333333333, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12962962962963, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.532407407407407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -13.0, 9.0, 7.0, 11.0, -1.0, 1.0, 4.0, 5.0, 5.0, 7.0, -2.0, 2.0, 7.0, -7.0, 13.0, 12.0, -13.0, 4.0, 12.0, 5.0, -2.0, 6.0, 6.0, 11.0, -20.0, 12.0, 12.0, 8.0, 0.0, 8.0, -1.0, 11.0, -10.0, 2.0, 12.0, -8.0, 8.0, 7.0, 8.0, 2.0, 10.0, 6.0, -3.0, 2.0, 10.0, 5.0, -2.0, -2.0, 5.0, -1.0, 13.0, -5.0, 1.0, 12.0, 7.0, 9.0, -1.0, 8.0, -1.0, 6.0, -7.0, 11.0, 5.0, -4.0, 7.0, 12.0, 0.0, 6.0, -3.0, -1.0, 13.0, 9.0, -13.0, 7.0, 12.0, -1.0, -1.0, 8.0, 9.0, 10.0, -2.0, 7.0, 0.0, 8.0, -12.0, 6.0, 13.0, 6.0, 7.0, 6.0, -4.0, 3.0, 11.0, 12.0, -11.0, 10.0, -7.0, 6.0, 6.0, -9.0, 7.0, 4.0, 13.0, 12.0, 317.0, 13.0, 11.0, -13.0, 13.0, 12.0, 3.0, 12.0, -17.0, 11.0, 9.0, 3.0, -6.0, 9.0, 9.0, 10.0, 0.0, 7.0, -2.0, 3.0, -12.0, 12.0, 12.0, -3.0, 10.0, -4.0, 12.0, 12.0, 9.0, -12.0, 6.0, 10.0, -1.0, 7.0, -1.0, -9.0, 1.0, 11.0, 12.0, 10.0, -14.0, 11.0, 8.0, 7.0, -9.0, 5.0, 12.0, 12.0, 2.0, 6.0, -5.0, -14.0, 7.0, 12.0, 10.0, -4.0, 7.0, 12.0, 0.0, 4.0, -6.0, 6.0, 11.0, -7.0, 5.0, 6.0, 11.0, 7.0, 3.0, 11.0, -6.0, 11.0, -13.0, 5.0, 12.0, 8.0, -5.0, 8.0, 4.0, 10.0, 1.0, 7.0, -3.0, -8.0, 1.0, 11.0, 11.0, 11.0, -6.0, 12.0, -2.0, 9.0, -1.0, 7.0, 0.0, 8.0, -18.0, 12.0, 13.0, 4.0, 10.0, -10.0, 11.0, 4.0, -7.0, 7.0, 11.0, 9.0, -12.0, 6.0, 12.0, 7.0, 8.0, 3.0, -3.0, -7.0, 12.0, 7.0, 3.0, 12.0, -2.0, 6.0, -1.0, -8.0, -2.0, 12.0, 13.0, 8.0, -3.0, 12.0, -2.0, -2.0, 7.0, -2.0, 12.0, -5.0, 5.0, 7.0, 8.0, -2.0, 7.0, -3.0, 13.0, 9.0, 3.0, 10.0, -7.0, 0.0, -1.0, 4.0, 12.0, 10.0, -1.0, 9.0, -3.0, 2.0, -9.0, 10.0, 12.0, 8.0, -11.0, 6.0, 12.0, -13.0, 12.0, 11.0, 5.0, 13.0, -3.0, -4.0, 9.0, -5.0, 5.0, 3.0, 12.0, 11.0, -1.0, 7.0, -2.0, 5.0, 6.0, -9.0, 13.0, -4.0, 11.0, 4.0, 4.0, 9.0, -13.0, 6.0, 13.0, 11.0, 14.0, -1.0, -9.0, 5.0, 9.0, -4.0, 5.0, 13.0, -10.0, 6.0, 6.0, -3.0, -2.0, 7.0, 13.0, 8.0, 8.0, 2.0, -3.0, -16.0, 11.0, 9.0, 11.0, 11.0, -8.0, 0.0, 12.0, -7.0, 10.0, 5.0, 7.0, 10.0, -14.0, 7.0, 12.0, 5.0, -1.0, 10.0, 1.0, 12.0, -9.0, -1.0, 13.0, 11.0, -11.0, 8.0, 7.0, 10.0, -17.0, 10.0, 12.0, -2.0, 13.0, -4.0, 8.0, 10.0, -12.0, 5.0, 12.0, 4.0, -2.0, 9.0, 4.0, 11.0, -15.0, 7.0, 12.0, 7.0, 11.0, 7.0, -10.0, -4.0, 6.0, 2.0, 11.0, 7.0, -10.0, 6.0, 12.0, -8.0, 4.0, 8.0, 11.0, -11.0, 12.0, 11.0, 3.0, 9.0, -8.0, 6.0, 8.0, 7.0, -9.0, 6.0, 11.0, 9.0, -12.0, 8.0, 10.0, 6.0, -1.0, 11.0, -1.0, 12.0, -16.0, 11.0, 8.0, 6.0, -10.0, 6.0, 13.0, 8.0, 2.0, 7.0, -2.0, -7.0, -1.0, 12.0, 11.0, 13.0, -14.0, 11.0, 5.0, 9.0, -3.0, -1.0, 10.0, 6.0, -9.0, 7.0, 11.0, -12.0, 13.0, 11.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21980348189476195, "mean_inference_ms": 1.1718643059226084, "mean_action_processing_ms": 0.07169023094523769, "mean_env_wait_ms": 0.17894843050334952, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 588600, "agent_timesteps_total": 588519, "timers": {"sample_time_ms": 346.591, "sample_throughput": 15580.314, "learn_time_ms": 6384.149, "learn_throughput": 845.845, "update_time_ms": 11.164}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 224.6028289794922, "policy_loss": -0.024315334856510162, "vf_loss": 224.6234130859375, "vf_explained_var": 0.17579777538776398, "kl": 0.007403012830764055, "entropy": 0.4656836986541748, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 588600, "num_agent_steps_sampled": 588519, "num_steps_trained": 588600, "num_agent_steps_trained": 588519}, "done": false, "episodes_total": 11529, "training_iteration": 109, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-54-53", "timestamp": 1626861293, "time_this_iter_s": 7.511301517486572, "time_total_s": 794.2425396442413, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cbf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 794.2425396442413, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 21.054545454545455, "ram_util_percent": 14.209090909090907}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 6.0, 6.0, 12.0, 8.0, 6.0, -1.0, 2.0, 10.0, -2.0, -4.0, 11.0, 2.0, 9.0, 8.0, -4.0, 9.0, 6.0, -6.0, 6.0, 13.0, -14.0, 12.0, 4.0, 11.0, 12.0, -4.0, -4.0, -14.0, 11.0, 7.0, 11.0, 9.0, 9.0, -16.0, 13.0, 8.0, 7.0, 11.0, -11.0, -3.0, 13.0, -7.0, 12.0, -13.0, 9.0, 9.0, 10.0, 14.0, 4.0, -16.0, 13.0, 9.0, 1.0, 11.0, -6.0, 5.0, 11.0, -11.0, 10.0, 9.0, 9.0, 10.0, -13.0, 6.0, 11.0, -9.0, 7.0, 1.0, 11.0, 12.0, -9.0, 10.0, -1.0, -6.0, 12.0, 8.0, 10.0, 11.0, -14.0, -2.0, 6.0, -1.0, 12.0, 8.0, -14.0, 11.0, 10.0, 6.0, -1.0, 12.0, -2.0, -18.0, 12.0, 11.0, 10.0, -9.0, 11.0, 6.0, 7.0, 9.0, -12.0, 9.0, 9.0, 8.0, -2.0, 12.0, -3.0, 4.0, 10.0, 9.0, -8.0, 12.0, 10.0, -10.0, 3.0, -5.0, 13.0, 12.0, -5.0, 6.0, -1.0, 11.0, -1.0, 3.0, 11.0, 12.0, -11.0, 10.0, 3.0, 12.0, -10.0, 13.0, -20.0, 11.0, 11.0, -2.0, 12.0, -7.0, 12.0, 10.0, 7.0, 7.0, -9.0, -1.0, 10.0, -1.0, 7.0, 4.0, -1.0, 4.0, 8.0, -6.0, 4.0, 10.0, 7.0, 1.0, -3.0, 11.0, 6.0, 14.0, -7.0, -1.0, 9.0, 9.0, -16.0, 11.0, 11.0, 5.0, -2.0, 12.0, 0.0, 9.0, 12.0, 8.0, -14.0, 14.0, 10.0, -17.0, 8.0, 12.0, 5.0, 9.0, -11.0, 6.0, 14.0, 5.0, -10.0, 9.0, -6.0, 7.0, 5.0, 14.0, 6.0, -6.0, 1.0, 9.0, 0.0, 10.0, -4.0, 6.0, 12.0, -10.0, 7.0, -2.0, -4.0, 10.0, 11.0, 1.0, -6.0, 9.0, 11.0, 12.0, 5.0, 11.0, -13.0, 6.0, -2.0, 12.0, -1.0, 9.0, 7.0, 4.0, -5.0, 6.0, 9.0, -10.0, 10.0, 12.0, 5.0, 7.0, -9.0, 6.0, -2.0, 4.0, 7.0, -1.0, 11.0, 12.0, -7.0, 14.0, 3.0, -5.0, 3.0, 9.0, -3.0, 11.0, -2.0, 11.0, -1.0, 3.0, 2.0, 9.0, 10.0, 2.0, -6.0, 14.0, 5.0, -8.0, 4.0, 5.0, 4.0, 10.0, -4.0, 7.0, -8.0, 6.0, 10.0, 9.0, -7.0, 7.0, 6.0, 9.0, 11.0, -15.0, 10.0, 12.0, 3.0, -3.0, 3.0, 10.0, -10.0, 3.0, 12.0, 5.0, 9.0, 3.0, -2.0, 14.0, -11.0, 5.0, 7.0, 12.0, 5.0, -3.0, 1.0, 5.0, 12.0, 1.0, -3.0, 8.0, -2.0, 4.0, 5.0, 12.0, 3.0, -7.0, 7.0, 7.0, 2.0, 11.0, -5.0, 6.0, -11.0, 9.0, 11.0, 10.0, 11.0, 7.0, -13.0, -5.0, 12.0, -4.0, 12.0, 13.0, -2.0, 11.0, -7.0, 11.0, -7.0, 11.0, 0.0, -8.0, 10.0, 5.0, 8.0, 5.0, 8.0, 6.0, -4.0, 8.0, -14.0, 11.0, 10.0, 10.0, 0.0, -8.0, 13.0, -15.0, 10.0, 11.0, 9.0, -9.0, 10.0, 12.0, 2.0, 9.0, 0.0, 11.0, -5.0, -7.0, 8.0, 11.0, 3.0, 14.0, 12.0, 2.0, -13.0, 14.0, 9.0, -11.0, 3.0, 5.0, 12.0, 9.0, -11.0, 11.0, -4.0, 0.0, 8.0, 8.0, 3.0, 10.0, -6.0, -1.0, 7.0, 2.0, 7.0, 13.0, -3.0, 9.0, -4.0, 11.0, 11.0, -12.0, 5.0, 3.0, 9.0, 5.0, -2.0, -9.0, 12.0, 8.0, 4.0, 8.0, 0.0, 10.0, -3.0, 10.0, 13.0, 10.0, 321.0, 3.0, 9.0, 7.0, -4.0, 10.0, 7.0, -10.0, 8.0, 4.0, 10.0, 8.0, -7.0, 7.0, -2.0, 12.0, -2.0, -18.0, 11.0, 12.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21982070096782383, "mean_inference_ms": 1.1717491482453049, "mean_action_processing_ms": 0.07169373346761719, "mean_env_wait_ms": 0.17895382307921562, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 594000, "agent_timesteps_total": 593919, "timers": {"sample_time_ms": 344.586, "sample_throughput": 15670.994, "learn_time_ms": 6428.443, "learn_throughput": 840.017, "update_time_ms": 11.443}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 214.18511962890625, "policy_loss": -0.030579810962080956, "vf_loss": 214.21107482910156, "vf_explained_var": 0.17589791119098663, "kl": 0.00908378604799509, "entropy": 0.4586790204048157, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 594000, "num_agent_steps_sampled": 593919, "num_steps_trained": 594000, "num_agent_steps_trained": 593919}, "done": false, "episodes_total": 11637, "training_iteration": 110, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-00", "timestamp": 1626861300, "time_this_iter_s": 7.614349603652954, "time_total_s": 801.8568892478943, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 801.8568892478943, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 21.372727272727275, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 49.657407407407405, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 12.414351851851851}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 3.0, 4.0, 13.0, 8.0, 0.0, -6.0, 13.0, 11.0, 6.0, -14.0, 12.0, -2.0, 6.0, 10.0, 1.0, -3.0, 8.0, -3.0, 13.0, 13.0, -2.0, -8.0, 12.0, -9.0, 9.0, 2.0, 13.0, -6.0, -4.0, 12.0, 13.0, 10.0, -13.0, 5.0, 13.0, 14.0, 5.0, -3.0, -1.0, 12.0, -2.0, -1.0, 6.0, 10.0, -14.0, 11.0, 8.0, 12.0, -9.0, -1.0, 13.0, 13.0, 5.0, 2.0, -5.0, -4.0, 5.0, 12.0, 2.0, 12.0, -10.0, 11.0, 2.0, -16.0, 11.0, 7.0, 13.0, 12.0, 5.0, -10.0, 8.0, 11.0, 7.0, -12.0, 9.0, 9.0, -13.0, 10.0, 9.0, -1.0, -1.0, 4.0, 13.0, 11.0, 10.0, -2.0, -4.0, -5.0, 1.0, 9.0, 10.0, -1.0, 6.0, 11.0, -1.0, -1.0, -1.0, 4.0, 13.0, 12.0, -5.0, -2.0, 10.0, -5.0, 6.0, 10.0, 4.0, 12.0, -16.0, 10.0, 9.0, -8.0, 11.0, -1.0, 13.0, 7.0, 5.0, -7.0, 10.0, -1.0, 11.0, -1.0, 6.0, 12.0, 319.0, 13.0, 12.0, 13.0, 316.0, 12.0, 13.0, 12.0, 10.0, -3.0, -4.0, -4.0, 11.0, 5.0, 3.0, 12.0, -17.0, 11.0, 9.0, 10.0, 13.0, -19.0, 11.0, 12.0, 4.0, 3.0, -4.0, 7.0, 13.0, -1.0, -4.0, 13.0, 317.0, 13.0, 12.0, 0.0, 1.0, 1.0, 13.0, 11.0, 5.0, 2.0, -3.0, 13.0, 6.0, -9.0, 5.0, 12.0, 318.0, 12.0, 13.0, -13.0, 6.0, 10.0, 12.0, 14.0, -17.0, 7.0, 11.0, 12.0, 6.0, -16.0, 13.0, 11.0, -7.0, 10.0, 1.0, -9.0, 7.0, 4.0, 13.0, 0.0, -1.0, 7.0, 9.0, -2.0, 5.0, 6.0, 6.0, 13.0, 318.0, 12.0, 13.0, -5.0, 9.0, 9.0, 2.0, 11.0, 5.0, 2.0, -3.0, 13.0, 6.0, 8.0, -12.0, 8.0, -8.0, 9.0, 6.0, -7.0, 6.0, 4.0, 12.0, 14.0, 8.0, -15.0, 8.0, 9.0, 9.0, -16.0, 13.0, 10.0, 319.0, 13.0, 13.0, 11.0, 6.0, -14.0, 12.0, 12.0, -6.0, 10.0, -1.0, 11.0, 8.0, -11.0, 7.0, 13.0, 319.0, 13.0, 11.0, 11.0, -7.0, -2.0, 13.0, 14.0, -10.0, 7.0, 4.0, 11.0, -2.0, -7.0, 13.0, 11.0, -17.0, 12.0, 9.0, -8.0, 13.0, 12.0, -2.0, 13.0, -4.0, 7.0, -1.0, 12.0, 11.0, -13.0, 5.0, 12.0, 317.0, 13.0, 12.0, 4.0, 9.0, -11.0, 13.0, 12.0, 0.0, 7.0, -4.0, 12.0, 5.0, 6.0, -8.0, 12.0, 320.0, 12.0, 12.0, 6.0, 11.0, -14.0, 12.0, 14.0, -8.0, 1.0, 8.0, 10.0, 6.0, -12.0, 11.0, 11.0, -18.0, 13.0, 9.0, 13.0, -13.0, 4.0, 11.0, 7.0, 5.0, -6.0, 9.0, 10.0, -9.0, 6.0, 8.0, 8.0, -11.0, 12.0, 6.0, -3.0, 3.0, 3.0, 12.0, 13.0, 0.0, -9.0, 11.0, 11.0, -6.0, 4.0, 6.0, 13.0, 318.0, 13.0, 12.0, -3.0, 4.0, 2.0, 12.0, 13.0, 0.0, -7.0, 9.0, 11.0, 11.0, 0.0, -7.0, -15.0, 10.0, 11.0, 9.0, -3.0, 7.0, -2.0, 13.0, 14.0, 5.0, -13.0, 9.0, 11.0, 3.0, 5.0, -4.0, 12.0, -11.0, 8.0, 6.0, 8.0, 3.0, -9.0, 13.0, 14.0, -18.0, 8.0, 11.0, -4.0, 13.0, -2.0, 8.0, 11.0, -17.0, 12.0, 9.0, 13.0, 4.0, -15.0, 13.0, 12.0, 1.0, -11.0, 13.0, 12.0, -15.0, 10.0, 8.0, 12.0, 318.0, 13.0, 12.0, -6.0, 8.0, 12.0, 1.0, 14.0, -6.0, -1.0, 8.0, 12.0, -3.0, -5.0, 11.0, 12.0, 3.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.219817676455763, "mean_inference_ms": 1.1717851279605525, "mean_action_processing_ms": 0.07169534007931168, "mean_env_wait_ms": 0.17895566607675775, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 599400, "agent_timesteps_total": 599319, "timers": {"sample_time_ms": 344.735, "sample_throughput": 15664.226, "learn_time_ms": 6423.817, "learn_throughput": 840.622, "update_time_ms": 11.463}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 2242.753173828125, "policy_loss": -0.03204985707998276, "vf_loss": 2242.781005859375, "vf_explained_var": 0.025638394057750702, "kl": 0.00835777260363102, "entropy": 0.4822814464569092, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 599400, "num_agent_steps_sampled": 599319, "num_steps_trained": 599400, "num_agent_steps_trained": 599319}, "done": false, "episodes_total": 11745, "training_iteration": 111, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-08", "timestamp": 1626861308, "time_this_iter_s": 7.570409774780273, "time_total_s": 809.4272990226746, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cd90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 809.4272990226746, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 21.136363636363637, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 12.0, 2.0, 5.0, 13.0, 6.0, 8.0, -12.0, 6.0, 14.0, 10.0, -15.0, -3.0, 5.0, 7.0, 6.0, 14.0, 3.0, 1.0, -3.0, 7.0, 14.0, 12.0, -18.0, 5.0, 14.0, 6.0, -10.0, -6.0, 6.0, 4.0, 11.0, -6.0, 12.0, 7.0, 2.0, 8.0, 12.0, -15.0, 10.0, -9.0, 14.0, 6.0, 4.0, -5.0, 14.0, -4.0, 10.0, 9.0, -1.0, 2.0, 5.0, 6.0, 10.0, -8.0, 7.0, 13.0, 13.0, -6.0, -5.0, 10.0, -11.0, 12.0, 4.0, 13.0, -6.0, -3.0, 11.0, 6.0, 11.0, 9.0, -11.0, 12.0, 13.0, 1.0, -11.0, -4.0, 7.0, 8.0, 4.0, -8.0, 12.0, 6.0, 5.0, 8.0, -7.0, 11.0, 3.0, 13.0, 13.0, -11.0, 0.0, -8.0, 13.0, -2.0, 12.0, -6.0, 14.0, 6.0, 1.0, 8.0, 11.0, -7.0, 3.0, 8.0, 14.0, -14.0, 7.0, -9.0, 7.0, 7.0, 10.0, 13.0, 6.0, 3.0, -7.0, -7.0, 12.0, 9.0, 1.0, 12.0, 9.0, 5.0, -11.0, -1.0, 2.0, 6.0, 8.0, -9.0, 12.0, 8.0, 4.0, 12.0, 9.0, 11.0, -17.0, 13.0, 13.0, 317.0, 11.0, 10.0, -1.0, 3.0, 3.0, -5.0, 12.0, 3.0, 5.0, 11.0, 12.0, -10.0, 2.0, 12.0, 8.0, 3.0, -8.0, 6.0, -10.0, 11.0, 8.0, 13.0, -14.0, 6.0, 10.0, 14.0, 12.0, -16.0, 5.0, 14.0, 9.0, 3.0, -11.0, 12.0, -16.0, 12.0, 7.0, -10.0, 12.0, 6.0, 7.0, -8.0, 11.0, 8.0, 4.0, 9.0, 13.0, 4.0, -11.0, -10.0, 5.0, 10.0, 10.0, -3.0, 2.0, 6.0, 10.0, 10.0, 7.0, -9.0, 7.0, 11.0, 14.0, -11.0, 1.0, -3.0, 8.0, 8.0, 2.0, 13.0, 13.0, 5.0, -16.0, 0.0, 12.0, 5.0, -2.0, 14.0, 10.0, 7.0, -16.0, -15.0, 9.0, 9.0, 12.0, -7.0, 14.0, 7.0, 1.0, -8.0, 12.0, 12.0, -1.0, 7.0, 6.0, 10.0, -8.0, 13.0, -13.0, 10.0, 5.0, 6.0, 8.0, 4.0, -3.0, 10.0, 11.0, -7.0, 1.0, 11.0, 14.0, -19.0, 9.0, -2.0, 8.0, 3.0, 6.0, 14.0, 8.0, -9.0, 2.0, -10.0, 13.0, 5.0, 7.0, 10.0, 9.0, -7.0, 3.0, 11.0, -6.0, 7.0, 3.0, -1.0, 7.0, 5.0, 4.0, 0.0, 10.0, 7.0, -2.0, -1.0, 13.0, -6.0, 9.0, -1.0, 1.0, 12.0, 3.0, -8.0, 12.0, 11.0, 0.0, 13.0, 11.0, 1.0, -10.0, -6.0, 14.0, 8.0, -1.0, 4.0, -3.0, 5.0, 9.0, -5.0, 12.0, 1.0, 7.0, 10.0, 8.0, -11.0, 8.0, 14.0, 10.0, 7.0, -16.0, -3.0, 1.0, 12.0, 5.0, -4.0, 1.0, 6.0, 12.0, 0.0, 12.0, 8.0, -5.0, 6.0, 10.0, 3.0, -4.0, -2.0, 12.0, -2.0, 7.0, 7.0, 5.0, 9.0, -6.0, 9.0, -8.0, 12.0, 2.0, 11.0, 13.0, 4.0, -13.0, 11.0, -16.0, 10.0, 10.0, 11.0, -6.0, 3.0, 7.0, 9.0, -4.0, 11.0, -1.0, 14.0, 13.0, -10.0, -2.0, -5.0, 3.0, 7.0, 10.0, 14.0, -1.0, 4.0, -2.0, -1.0, 9.0, 7.0, 0.0, 14.0, 14.0, -8.0, -5.0, 9.0, -10.0, 8.0, 8.0, 11.0, 12.0, 5.0, -13.0, 0.0, 6.0, 6.0, 3.0, 13.0, 2.0, 12.0, -12.0, 12.0, -15.0, 7.0, 11.0, 12.0, 12.0, 8.0, -17.0, 6.0, 12.0, 5.0, -8.0, 13.0, 5.0, 3.0, -6.0, 14.0, 6.0, -18.0, 13.0, 13.0, 9.0, 0.0, -7.0, 13.0, 10.0, 10.0, -18.0, 11.0, 14.0, -12.0, 2.0, 12.0, -6.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21985719640978954, "mean_inference_ms": 1.1718847979039209, "mean_action_processing_ms": 0.07169689829314156, "mean_env_wait_ms": 0.17897229782248875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 604800, "agent_timesteps_total": 604719, "timers": {"sample_time_ms": 346.599, "sample_throughput": 15579.973, "learn_time_ms": 6520.204, "learn_throughput": 828.195, "update_time_ms": 11.454}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 224.92967224121094, "policy_loss": -0.03341986611485481, "vf_loss": 224.95823669433594, "vf_explained_var": 0.18675988912582397, "kl": 0.009477931074798107, "entropy": 0.49673426151275635, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 604800, "num_agent_steps_sampled": 604719, "num_steps_trained": 604800, "num_agent_steps_trained": 604719}, "done": false, "episodes_total": 11853, "training_iteration": 112, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-16", "timestamp": 1626861316, "time_this_iter_s": 7.588616609573364, "time_total_s": 817.0159156322479, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022cc80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 817.0159156322479, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 21.454545454545453, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 11.0, 10.0, -13.0, 5.0, 7.0, 10.0, -7.0, -7.0, 9.0, 8.0, 5.0, 9.0, 11.0, 4.0, -9.0, 8.0, 14.0, 2.0, -9.0, 8.0, 12.0, 8.0, -13.0, 12.0, 13.0, -8.0, -2.0, 11.0, 12.0, -11.0, 3.0, 13.0, 14.0, 4.0, -16.0, 3.0, 11.0, -4.0, 5.0, -3.0, 14.0, 1.0, 3.0, 11.0, 12.0, -16.0, 8.0, 14.0, 13.0, -3.0, -9.0, 12.0, 6.0, -8.0, 5.0, 12.0, 13.0, -4.0, -6.0, 9.0, 13.0, -13.0, 6.0, 13.0, 10.0, 4.0, -12.0, 3.0, 9.0, -9.0, 12.0, -11.0, 8.0, 12.0, 6.0, 13.0, 11.0, 7.0, -16.0, 14.0, 7.0, -4.0, -2.0, -15.0, 13.0, 6.0, 11.0, 12.0, 13.0, -7.0, -3.0, 4.0, 7.0, 11.0, -7.0, 12.0, 12.0, -2.0, -7.0, -18.0, 13.0, 8.0, 12.0, 11.0, 10.0, 5.0, -11.0, -4.0, 13.0, 2.0, 4.0, 9.0, 12.0, 5.0, -11.0, 10.0, 11.0, -6.0, 0.0, -3.0, 8.0, 4.0, 6.0, 12.0, 13.0, -2.0, -8.0, -13.0, 10.0, 11.0, 7.0, 0.0, 13.0, -6.0, 8.0, 8.0, 12.0, 9.0, -14.0, -3.0, 12.0, 5.0, 1.0, 13.0, 14.0, 6.0, -18.0, -12.0, 10.0, 5.0, 12.0, 5.0, 13.0, 9.0, -12.0, 10.0, 12.0, 4.0, -11.0, 6.0, 10.0, 1.0, -2.0, 7.0, 8.0, 6.0, -6.0, -10.0, 13.0, 10.0, 2.0, 9.0, 12.0, -10.0, 4.0, 13.0, 11.0, -10.0, 1.0, 5.0, 13.0, 5.0, -8.0, 10.0, 9.0, 7.0, -11.0, 9.0, 13.0, -13.0, 6.0, 14.0, 8.0, 4.0, -11.0, 5.0, 14.0, -11.0, 7.0, 10.0, 11.0, 8.0, -14.0, 11.0, 12.0, -6.0, -2.0, 14.0, 12.0, -3.0, -8.0, 8.0, 13.0, 7.0, -13.0, 11.0, 13.0, 9.0, -18.0, 8.0, 3.0, -6.0, 10.0, 9.0, 3.0, 10.0, -7.0, 10.0, 8.0, -14.0, 11.0, 10.0, 13.0, -9.0, 1.0, 11.0, 5.0, -5.0, 4.0, 12.0, 12.0, 3.0, -12.0, -1.0, 8.0, 5.0, 3.0, 8.0, 13.0, 7.0, -13.0, 10.0, 8.0, 1.0, -4.0, 6.0, 12.0, -15.0, 12.0, -6.0, 13.0, 9.0, -1.0, -3.0, 8.0, 7.0, 3.0, 12.0, 13.0, -11.0, 1.0, 13.0, 9.0, -8.0, 1.0, 3.0, 13.0, 2.0, -3.0, 7.0, 14.0, 11.0, -17.0, 9.0, 12.0, 2.0, -8.0, 12.0, 14.0, -18.0, 7.0, 4.0, 12.0, -13.0, 12.0, 10.0, 13.0, -9.0, 1.0, 12.0, 10.0, -11.0, 4.0, 11.0, 13.0, 10.0, -19.0, 6.0, 12.0, -6.0, 3.0, 6.0, 8.0, 8.0, -7.0, 11.0, 12.0, -2.0, -6.0, 10.0, 7.0, -10.0, 8.0, 9.0, 12.0, 5.0, -11.0, 7.0, 10.0, 7.0, -9.0, 11.0, 10.0, -8.0, 2.0, 14.0, 14.0, 3.0, -16.0, 11.0, 12.0, 4.0, -12.0, 5.0, 13.0, 12.0, -15.0, 12.0, 9.0, 3.0, -9.0, 13.0, 12.0, -1.0, -9.0, 6.0, 7.0, 6.0, -4.0, 10.0, 13.0, 4.0, -12.0, 11.0, 11.0, -1.0, -6.0, 13.0, 12.0, 5.0, -15.0, -3.0, 13.0, 6.0, -1.0, 5.0, 11.0, 6.0, -7.0, 11.0, 7.0, -8.0, 5.0, 11.0, 14.0, 1.0, -11.0, 7.0, 12.0, -7.0, 3.0, 12.0, 13.0, 6.0, -16.0, 8.0, 13.0, 8.0, -14.0, 12.0, 14.0, -1.0, -10.0, 4.0, 12.0, 7.0, -8.0, 7.0, 14.0, 7.0, -13.0, 11.0, 12.0, -13.0, 5.0, 13.0, 13.0, 1.0, -12.0, 10.0, 11.0, -11.0, 5.0, -6.0, 10.0, 9.0, 2.0, 12.0, 7.0, 4.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21985388020215413, "mean_inference_ms": 1.1719327420966918, "mean_action_processing_ms": 0.07169733143958165, "mean_env_wait_ms": 0.17897169191246998, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 610200, "agent_timesteps_total": 610119, "timers": {"sample_time_ms": 347.979, "sample_throughput": 15518.165, "learn_time_ms": 6597.01, "learn_throughput": 818.553, "update_time_ms": 11.7}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 23.019386291503906, "policy_loss": -0.07788673043251038, "vf_loss": 23.088171005249023, "vf_explained_var": 0.3602234423160553, "kl": 0.017976606264710426, "entropy": 0.46013176441192627, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 610200, "num_agent_steps_sampled": 610119, "num_steps_trained": 610200, "num_agent_steps_trained": 610119}, "done": false, "episodes_total": 11961, "training_iteration": 113, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-23", "timestamp": 1626861323, "time_this_iter_s": 7.250262975692749, "time_total_s": 824.2661786079407, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022cd90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 824.2661786079407, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 21.939999999999998, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -7.0, 1.0, 13.0, -5.0, 0.0, 7.0, 13.0, 12.0, 8.0, -17.0, 12.0, 13.0, 14.0, 316.0, 11.0, -8.0, 4.0, 10.0, 9.0, 9.0, 3.0, -10.0, 13.0, 6.0, -3.0, 1.0, 11.0, -7.0, 12.0, -2.0, 12.0, 11.0, -6.0, 7.0, 3.0, 11.0, 1.0, -10.0, 13.0, -7.0, 13.0, -2.0, 11.0, 13.0, 11.0, -4.0, -5.0, -15.0, 8.0, 10.0, 12.0, 11.0, 9.0, 13.0, -18.0, -8.0, 7.0, 3.0, 13.0, -7.0, 14.0, -3.0, 11.0, -6.0, 10.0, 0.0, 11.0, -4.0, -3.0, 9.0, 13.0, -16.0, 13.0, 6.0, 12.0, 9.0, 11.0, -3.0, -2.0, 8.0, -7.0, 1.0, 13.0, -4.0, 5.0, 13.0, 1.0, -18.0, 13.0, 7.0, 13.0, -14.0, 12.0, 9.0, 8.0, -5.0, 1.0, 6.0, 13.0, -4.0, -1.0, 10.0, 10.0, 12.0, -9.0, 0.0, 12.0, 4.0, 13.0, 2.0, -4.0, 10.0, 9.0, -1.0, -3.0, -7.0, 0.0, 9.0, 13.0, -22.0, 13.0, 11.0, 13.0, 8.0, 11.0, -12.0, 8.0, -8.0, 9.0, 1.0, 13.0, 10.0, 9.0, -15.0, 11.0, -17.0, 13.0, 7.0, 12.0, -5.0, 11.0, -2.0, 11.0, -9.0, 9.0, 2.0, 13.0, 7.0, 0.0, -5.0, 13.0, -9.0, 12.0, 13.0, -1.0, 13.0, 10.0, -20.0, 12.0, -1.0, 2.0, 1.0, 13.0, 5.0, 0.0, -3.0, 13.0, -18.0, 12.0, 9.0, 12.0, -17.0, 14.0, 7.0, 11.0, 11.0, 9.0, -17.0, 12.0, 11.0, -3.0, 12.0, -5.0, -13.0, 8.0, 7.0, 13.0, 12.0, -8.0, 9.0, 2.0, 11.0, 7.0, 4.0, -7.0, 5.0, 9.0, -8.0, 9.0, -14.0, 13.0, 5.0, 11.0, 2.0, 13.0, 4.0, -4.0, 10.0, 11.0, -19.0, 13.0, 10.0, 9.0, 13.0, -17.0, 10.0, 2.0, 4.0, -1.0, -6.0, 14.0, 11.0, -4.0, -16.0, 6.0, 12.0, 13.0, -7.0, 3.0, 7.0, 12.0, -5.0, 5.0, 3.0, 12.0, 9.0, 11.0, -3.0, -2.0, 2.0, -7.0, 8.0, 12.0, 6.0, -13.0, 11.0, 11.0, -2.0, 2.0, 7.0, 8.0, 9.0, 8.0, 6.0, -8.0, -3.0, 8.0, 2.0, 8.0, -7.0, 0.0, 9.0, 13.0, -6.0, 5.0, 5.0, 11.0, 6.0, 14.0, -17.0, 12.0, 13.0, 8.0, 3.0, -9.0, -4.0, 0.0, 9.0, 10.0, 12.0, 8.0, -16.0, 11.0, -3.0, 14.0, -6.0, 10.0, 6.0, -9.0, 5.0, 13.0, -5.0, 1.0, 6.0, 13.0, 10.0, 5.0, -7.0, 7.0, 12.0, 8.0, -1.0, -4.0, 12.0, -1.0, 0.0, 4.0, -6.0, -2.0, 10.0, 13.0, 13.0, 8.0, 8.0, -14.0, -1.0, 13.0, -3.0, 6.0, -8.0, 14.0, 3.0, 6.0, -6.0, 6.0, 4.0, 11.0, -12.0, 8.0, 6.0, 13.0, 7.0, 10.0, 5.0, -7.0, 6.0, -9.0, 10.0, 8.0, 9.0, 9.0, 13.0, -16.0, -13.0, 13.0, 4.0, 11.0, 9.0, 12.0, -8.0, 2.0, -3.0, 10.0, 0.0, 8.0, -10.0, 4.0, 10.0, 11.0, -5.0, 5.0, 7.0, 8.0, -1.0, 12.0, -3.0, 7.0, -5.0, 6.0, 2.0, 12.0, -5.0, 9.0, -2.0, 13.0, 5.0, 8.0, -10.0, 12.0, -6.0, 12.0, 11.0, -2.0, -6.0, 5.0, 11.0, 5.0, 6.0, 9.0, -5.0, 5.0, 10.0, 5.0, -10.0, 10.0, 5.0, 14.0, 0.0, -4.0, 5.0, -7.0, 8.0, 9.0, 8.0, 7.0, 2.0, -2.0, 7.0, 5.0, -9.0, 12.0, 5.0, 13.0, -12.0, 9.0, -3.0, 9.0, 3.0, 6.0, -10.0, 5.0, 7.0, 13.0, -8.0, 4.0, 8.0, 11.0, 13.0, 10.0, -19.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21978909846868763, "mean_inference_ms": 1.1720669373603911, "mean_action_processing_ms": 0.07171425501527223, "mean_env_wait_ms": 0.17899601911072785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 615600, "agent_timesteps_total": 615546, "timers": {"sample_time_ms": 348.539, "sample_throughput": 15493.256, "learn_time_ms": 6621.022, "learn_throughput": 815.584, "update_time_ms": 11.636}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 248.27259826660156, "policy_loss": -0.04073113948106766, "vf_loss": 248.30836486816406, "vf_explained_var": 0.16552866995334625, "kl": 0.009852075017988682, "entropy": 0.49295127391815186, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 615600, "num_agent_steps_sampled": 615546, "num_steps_trained": 615600, "num_agent_steps_trained": 615546}, "done": false, "episodes_total": 12069, "training_iteration": 114, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-30", "timestamp": 1626861330, "time_this_iter_s": 6.848368167877197, "time_total_s": 831.1145467758179, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022cae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 831.1145467758179, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 23.06, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -2.0, -9.0, 12.0, 11.0, 14.0, -7.0, -3.0, 4.0, 8.0, -6.0, 9.0, 13.0, 9.0, -3.0, -4.0, 12.0, 14.0, -7.0, -4.0, 14.0, 4.0, 7.0, -10.0, 12.0, -9.0, 12.0, 0.0, 6.0, 6.0, -5.0, 8.0, 4.0, 8.0, 10.0, -7.0, 12.0, 7.0, -8.0, 4.0, 7.0, 13.0, -13.0, 8.0, 2.0, 12.0, 7.0, -6.0, 9.0, 5.0, -7.0, 8.0, 1.0, 6.0, -2.0, 10.0, 10.0, 5.0, 5.0, -5.0, 2.0, 4.0, -4.0, 13.0, -1.0, 14.0, 7.0, -5.0, -1.0, 13.0, 6.0, -3.0, 8.0, 10.0, -16.0, 13.0, 0.0, 13.0, 7.0, -5.0, 10.0, 8.0, 2.0, -5.0, 13.0, 0.0, -3.0, 5.0, 5.0, 5.0, 11.0, -6.0, 14.0, 1.0, -7.0, 7.0, 5.0, 0.0, -2.0, 12.0, 11.0, 1.0, 6.0, -3.0, -11.0, 5.0, 12.0, 9.0, 5.0, 7.0, -9.0, 12.0, 13.0, 13.0, -19.0, 8.0, 5.0, 13.0, 2.0, -5.0, 9.0, 8.0, -13.0, 11.0, 3.0, 14.0, -11.0, 9.0, -5.0, 9.0, 1.0, 10.0, 9.0, 4.0, -10.0, 12.0, 8.0, 13.0, -5.0, -1.0, 11.0, 6.0, -10.0, 8.0, 8.0, 2.0, -3.0, 8.0, -5.0, 14.0, 11.0, -5.0, 13.0, 3.0, 11.0, -12.0, 6.0, -5.0, 11.0, 3.0, 1.0, 14.0, 7.0, -7.0, 14.0, 12.0, -6.0, -5.0, 8.0, 5.0, -10.0, 12.0, 12.0, 14.0, -7.0, -4.0, 13.0, 13.0, -5.0, -6.0, 9.0, 2.0, 11.0, -7.0, -1.0, 12.0, 9.0, -5.0, 13.0, 1.0, 6.0, -5.0, 13.0, 4.0, -2.0, 0.0, 6.0, 14.0, 2.0, -7.0, 5.0, 9.0, 8.0, -7.0, 14.0, 10.0, 4.0, -13.0, 9.0, 13.0, -17.0, 10.0, -4.0, 3.0, 7.0, 9.0, 9.0, 2.0, -8.0, 12.0, 8.0, 10.0, 3.0, -6.0, 12.0, 7.0, 1.0, -5.0, 5.0, -3.0, 0.0, 13.0, 6.0, 14.0, 0.0, -5.0, 9.0, 7.0, 4.0, -5.0, 3.0, 11.0, -10.0, 11.0, 10.0, 4.0, 7.0, -6.0, 14.0, -10.0, 6.0, 5.0, 7.0, -8.0, 4.0, 12.0, -1.0, 14.0, -7.0, 9.0, 12.0, 13.0, -1.0, -9.0, 5.0, -9.0, 6.0, 13.0, 4.0, 8.0, 7.0, -4.0, 9.0, 8.0, 0.0, -2.0, 8.0, 3.0, -8.0, 12.0, 13.0, 14.0, -7.0, -5.0, 12.0, 10.0, -12.0, 5.0, 8.0, 9.0, -3.0, 1.0, 13.0, 8.0, -16.0, 10.0, 10.0, 5.0, 6.0, -6.0, 10.0, 5.0, -12.0, 12.0, 8.0, 11.0, -1.0, -3.0, 14.0, -1.0, 12.0, -10.0, 6.0, -12.0, 11.0, 10.0, -5.0, 14.0, 11.0, -5.0, 4.0, 13.0, 1.0, -3.0, -10.0, 4.0, 10.0, 11.0, -5.0, 5.0, 7.0, 8.0, -1.0, 12.0, -3.0, 7.0, -5.0, 6.0, 2.0, 12.0, -5.0, 9.0, -2.0, 13.0, 5.0, 8.0, -10.0, 12.0, -6.0, 12.0, 11.0, -2.0, -6.0, 5.0, 11.0, 5.0, 6.0, 9.0, -5.0, 5.0, 10.0, 5.0, -10.0, 10.0, 5.0, 14.0, 0.0, -4.0, 5.0, -7.0, 8.0, 9.0, 8.0, 7.0, 2.0, -2.0, 7.0, 5.0, -9.0, 12.0, 5.0, 13.0, -12.0, 9.0, -3.0, 9.0, 3.0, 6.0, -10.0, 5.0, 7.0, 13.0, -8.0, 4.0, 8.0, 11.0, 13.0, 10.0, -19.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2196264636165979, "mean_inference_ms": 1.1709411553478468, "mean_action_processing_ms": 0.07171459692375044, "mean_env_wait_ms": 0.17885860669025047, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 621000, "agent_timesteps_total": 620919, "timers": {"sample_time_ms": 347.339, "sample_throughput": 15546.787, "learn_time_ms": 6619.73, "learn_throughput": 815.743, "update_time_ms": 11.548}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 25.992570877075195, "policy_loss": -0.08267129212617874, "vf_loss": 26.06658935546875, "vf_explained_var": 0.2647058367729187, "kl": 0.01710466481745243, "entropy": 0.4531099200248718, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 621000, "num_agent_steps_sampled": 620919, "num_steps_trained": 621000, "num_agent_steps_trained": 620919}, "done": false, "episodes_total": 12150, "training_iteration": 115, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-36", "timestamp": 1626861336, "time_this_iter_s": 6.652665853500366, "time_total_s": 837.7672126293182, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 837.7672126293182, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 23.244444444444444, "ram_util_percent": 14.233333333333333}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.52777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 6.131944444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 356.0, 16.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -12.0, 13.0, 6.0, 0.0, -2.0, 8.0, 9.0, 0.0, 11.0, -5.0, 10.0, 7.0, -4.0, 11.0, 1.0, 5.0, -16.0, 13.0, 13.0, 11.0, -17.0, 11.0, 10.0, 8.0, -5.0, 12.0, 0.0, 12.0, 7.0, -10.0, 6.0, 6.0, -10.0, 12.0, 7.0, -14.0, 10.0, 8.0, 11.0, 13.0, 7.0, 12.0, -17.0, 0.0, -4.0, 12.0, 7.0, 6.0, -13.0, 10.0, 12.0, -1.0, -1.0, 10.0, 7.0, 0.0, 11.0, -8.0, 12.0, 7.0, 7.0, -6.0, 7.0, -16.0, 13.0, 13.0, 5.0, 5.0, -5.0, 7.0, 8.0, -5.0, 13.0, 2.0, 6.0, 3.0, -11.0, 12.0, 11.0, 8.0, -7.0, 12.0, 2.0, -7.0, 7.0, 4.0, 11.0, -9.0, 10.0, 2.0, 13.0, 2.0, -3.0, 5.0, 11.0, -5.0, 5.0, 7.0, 8.0, 3.0, -8.0, 12.0, 8.0, 12.0, 7.0, 11.0, -15.0, 0.0, -2.0, 10.0, 7.0, 7.0, -7.0, 8.0, 7.0, -12.0, 8.0, 8.0, 11.0, -12.0, 9.0, 5.0, 13.0, 2.0, 5.0, -5.0, 13.0, 8.0, 13.0, -9.0, 3.0, 8.0, -16.0, 11.0, 12.0, 14.0, 10.0, -5.0, -3.0, 2.0, -6.0, 6.0, 13.0, 8.0, -13.0, 13.0, 7.0, 3.0, 10.0, -10.0, 12.0, 12.0, 10.0, -4.0, -2.0, 1.0, -10.0, 11.0, 13.0, 7.0, -13.0, 13.0, 8.0, 0.0, -4.0, 8.0, 11.0, -5.0, 13.0, -5.0, 13.0, -2.0, -6.0, 10.0, 13.0, 11.0, -19.0, 13.0, 10.0, 3.0, -6.0, 11.0, 7.0, 12.0, 11.0, 9.0, -17.0, 8.0, 12.0, -5.0, 0.0, 10.0, -21.0, 13.0, 13.0, 5.0, -12.0, 11.0, 11.0, 14.0, 8.0, -5.0, -1.0, 3.0, 12.0, -11.0, 11.0, 8.0, -15.0, 13.0, 9.0, -7.0, -1.0, 11.0, 12.0, 11.0, 11.0, 8.0, -15.0, 3.0, -7.0, 8.0, 11.0, 7.0, -16.0, 12.0, 12.0, 0.0, -1.0, 5.0, 11.0, 8.0, 12.0, 9.0, -14.0, -3.0, -2.0, 12.0, 8.0, 12.0, 316.0, 13.0, 13.0, 6.0, -7.0, 11.0, 5.0, -4.0, 10.0, 11.0, -2.0, 2.0, 4.0, -4.0, 13.0, -7.0, 3.0, 9.0, 10.0, 3.0, -11.0, 11.0, 12.0, 13.0, 9.0, -18.0, 11.0, 6.0, 11.0, -8.0, 6.0, 9.0, -14.0, 7.0, 13.0, -8.0, 4.0, 11.0, 8.0, -4.0, 12.0, -6.0, 13.0, 3.0, 7.0, 12.0, -7.0, -7.0, 9.0, 10.0, 3.0, -2.0, -3.0, 9.0, 11.0, -4.0, 11.0, -1.0, 9.0, 2.0, -9.0, 12.0, 10.0, -6.0, 3.0, 12.0, 6.0, 8.0, -9.0, 5.0, 11.0, 13.0, 10.0, -19.0, 11.0, 2.0, -3.0, 6.0, 10.0, -6.0, 1.0, 13.0, 7.0, 8.0, -9.0, 6.0, 10.0, 13.0, 9.0, -19.0, 12.0, -1.0, -6.0, 11.0, 11.0, -16.0, 14.0, 10.0, 7.0, 11.0, -17.0, 11.0, 10.0, 14.0, 10.0, -17.0, 8.0, 3.0, 12.0, -8.0, 8.0, -9.0, 13.0, 10.0, 1.0, 6.0, -5.0, 11.0, 3.0, 12.0, 12.0, 317.0, 12.0, 2.0, -6.0, 6.0, 13.0, 8.0, -9.0, 13.0, 3.0, 5.0, 5.0, 12.0, -7.0, 13.0, 13.0, -19.0, 9.0, 8.0, -2.0, 0.0, 9.0, -10.0, 11.0, 13.0, 1.0, -12.0, 9.0, 6.0, 12.0, -1.0, 7.0, 0.0, 10.0, 5.0, -8.0, 9.0, 9.0, 11.0, -7.0, 12.0, -1.0, 6.0, -7.0, 9.0, 7.0, -11.0, 12.0, 2.0, 13.0, 4.0, 10.0, -7.0, 8.0, -2.0, -8.0, 13.0, 12.0, 12.0, 320.0, 11.0, 13.0, -5.0, 14.0, -6.0, 13.0, 4.0, 7.0, -9.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21988244621033598, "mean_inference_ms": 1.172048159101757, "mean_action_processing_ms": 0.0717128053161882, "mean_env_wait_ms": 0.17900322800669494, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 626400, "agent_timesteps_total": 626319, "timers": {"sample_time_ms": 347.087, "sample_throughput": 15558.079, "learn_time_ms": 6639.744, "learn_throughput": 813.284, "update_time_ms": 11.575}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 460.2259216308594, "policy_loss": -0.024451376870274544, "vf_loss": 460.24658203125, "vf_explained_var": 0.1489834040403366, "kl": 0.007389464881271124, "entropy": 0.48113033175468445, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 626400, "num_agent_steps_sampled": 626319, "num_steps_trained": 626400, "num_agent_steps_trained": 626319}, "done": false, "episodes_total": 12258, "training_iteration": 116, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-43", "timestamp": 1626861343, "time_this_iter_s": 6.82283878326416, "time_total_s": 844.5900514125824, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 844.5900514125824, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 21.44, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 7.0, 11.0, -8.0, 13.0, 2.0, 8.0, -8.0, -12.0, 14.0, 7.0, 6.0, -8.0, 5.0, 12.0, 6.0, 8.0, 8.0, 11.0, -12.0, 11.0, 7.0, 8.0, -11.0, -3.0, 14.0, 0.0, 4.0, 8.0, 7.0, -8.0, 8.0, 12.0, 6.0, 9.0, -12.0, 5.0, 4.0, -7.0, 13.0, -2.0, 12.0, 7.0, -2.0, -4.0, 9.0, 3.0, 7.0, 3.0, -4.0, 10.0, 6.0, 6.0, 7.0, 11.0, -9.0, -9.0, 12.0, 8.0, 4.0, 11.0, 12.0, 6.0, -14.0, -17.0, 8.0, 12.0, 12.0, -5.0, 11.0, 1.0, 8.0, -11.0, 13.0, 9.0, 4.0, 1.0, 14.0, 3.0, -3.0, 4.0, 10.0, 9.0, -8.0, 8.0, 6.0, 10.0, -9.0, -12.0, 14.0, 9.0, 4.0, 12.0, -6.0, 1.0, 8.0, 2.0, 0.0, 6.0, 7.0, -6.0, 11.0, 4.0, 6.0, -9.0, 12.0, 9.0, 3.0, -10.0, 10.0, 9.0, 6.0, 14.0, 8.0, 5.0, -12.0, -3.0, 7.0, 8.0, 3.0, -5.0, 13.0, 0.0, 7.0, -1.0, -2.0, 5.0, 13.0, 7.0, 6.0, 11.0, -9.0, 12.0, 0.0, -8.0, 11.0, -6.0, 14.0, 2.0, 5.0, 4.0, 10.0, 5.0, -4.0, 10.0, 10.0, 10.0, -15.0, 3.0, 9.0, 13.0, -10.0, 11.0, 14.0, 7.0, -17.0, 8.0, 10.0, -6.0, 3.0, 7.0, 6.0, 10.0, -8.0, -6.0, 3.0, 13.0, 5.0, -13.0, 13.0, 9.0, 6.0, 5.0, 13.0, 4.0, -7.0, 8.0, -5.0, 5.0, 7.0, 4.0, 7.0, 12.0, -8.0, -9.0, 9.0, 10.0, 5.0, -4.0, 11.0, 4.0, 4.0, 2.0, 11.0, 10.0, -8.0, 10.0, 7.0, 13.0, -15.0, -8.0, 8.0, 8.0, 7.0, 8.0, 10.0, 8.0, -11.0, -4.0, -2.0, 10.0, 11.0, -2.0, 14.0, 12.0, -9.0, 11.0, 7.0, -11.0, 8.0, -15.0, 8.0, 11.0, 11.0, 10.0, 11.0, 5.0, -11.0, -4.0, 8.0, 3.0, 8.0, -10.0, 11.0, 11.0, 3.0, 10.0, 12.0, -2.0, -5.0, 1.0, 12.0, 8.0, -6.0, 9.0, 6.0, 9.0, -9.0, 10.0, 13.0, -14.0, 6.0, -1.0, 13.0, 7.0, -4.0, 7.0, 10.0, 12.0, -14.0, 4.0, 13.0, 13.0, -15.0, -13.0, 13.0, 5.0, 10.0, -6.0, 8.0, 2.0, 11.0, 1.0, 12.0, 10.0, -8.0, 13.0, 5.0, 13.0, -16.0, -7.0, 8.0, 9.0, 5.0, -15.0, 14.0, 5.0, 11.0, 13.0, 5.0, 8.0, -11.0, 8.0, 13.0, -2.0, -4.0, -7.0, 14.0, 4.0, 4.0, 4.0, 12.0, 6.0, -7.0, 3.0, 11.0, 3.0, -2.0, -8.0, 8.0, 9.0, 6.0, -10.0, 6.0, 10.0, 9.0, 5.0, 11.0, 8.0, -9.0, 6.0, -3.0, 6.0, 6.0, -3.0, 8.0, 1.0, 9.0, 3.0, 13.0, 10.0, -11.0, 13.0, -8.0, 3.0, 7.0, 5.0, 1.0, 12.0, -3.0, 12.0, 7.0, 7.0, -11.0, 2.0, 13.0, 8.0, -8.0, -15.0, 13.0, 12.0, 5.0, 11.0, 5.0, 11.0, -12.0, 9.0, 4.0, 8.0, -6.0, -13.0, 13.0, 10.0, 5.0, 3.0, 12.0, 10.0, -10.0, 1.0, 0.0, 8.0, 6.0, -11.0, 14.0, 9.0, 3.0, 2.0, 14.0, -8.0, 7.0, 8.0, 13.0, 0.0, -6.0, 3.0, 11.0, -4.0, 5.0, -5.0, 8.0, 8.0, 4.0, 0.0, 14.0, 4.0, -3.0, 4.0, 10.0, 5.0, -4.0, 6.0, 3.0, -2.0, 8.0, -2.0, 2.0, 12.0, 3.0, -5.0, 7.0, 8.0, 5.0, 11.0, 8.0, -3.0, -1.0, 6.0, 10.0, 8.0, -9.0, 8.0, 13.0, 5.0, -11.0, -9.0, 14.0, 5.0, 5.0, 9.0, 7.0, -13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.220018611571105, "mean_inference_ms": 1.1721459809087884, "mean_action_processing_ms": 0.0717254262241705, "mean_env_wait_ms": 0.17903686352948703, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 631800, "agent_timesteps_total": 631719, "timers": {"sample_time_ms": 348.028, "sample_throughput": 15515.971, "learn_time_ms": 6663.946, "learn_throughput": 810.331, "update_time_ms": 11.696}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 26.370891571044922, "policy_loss": -0.0855531394481659, "vf_loss": 26.447263717651367, "vf_explained_var": 0.290651798248291, "kl": 0.018141092732548714, "entropy": 0.48414647579193115, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 631800, "num_agent_steps_sampled": 631719, "num_steps_trained": 631800, "num_agent_steps_trained": 631719}, "done": false, "episodes_total": 12366, "training_iteration": 117, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-50", "timestamp": 1626861350, "time_this_iter_s": 6.849014520645142, "time_total_s": 851.4390659332275, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 851.4390659332275, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 21.700000000000003, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.703703703703702, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 7.675925925925926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 14.0, -19.0, 10.0, 5.0, -6.0, 5.0, 11.0, 7.0, -4.0, 12.0, 0.0, 4.0, 8.0, 12.0, -9.0, 10.0, 13.0, -21.0, 13.0, -7.0, 11.0, 0.0, 11.0, 7.0, -6.0, 9.0, 5.0, 5.0, 9.0, -10.0, 11.0, 11.0, 14.0, 317.0, 13.0, -2.0, 8.0, -3.0, 12.0, -1.0, 7.0, 11.0, -2.0, 5.0, 8.0, 8.0, -6.0, 12.0, 13.0, -7.0, -3.0, -5.0, -4.0, 12.0, 12.0, -7.0, 7.0, 9.0, 6.0, 11.0, 9.0, -1.0, -4.0, 11.0, -1.0, -5.0, 10.0, -9.0, 10.0, 2.0, 12.0, 8.0, -3.0, 11.0, -1.0, 12.0, -2.0, 8.0, -3.0, 13.0, 11.0, -7.0, -2.0, 2.0, -5.0, 6.0, 12.0, 9.0, 8.0, 6.0, -8.0, 8.0, -10.0, 6.0, 11.0, 9.0, 13.0, -20.0, 13.0, 6.0, -4.0, 2.0, 11.0, 4.0, -13.0, 13.0, 11.0, 7.0, 8.0, -8.0, 8.0, 13.0, 10.0, -6.0, -2.0, -2.0, 12.0, -6.0, 11.0, 9.0, -9.0, 12.0, 3.0, 1.0, 9.0, 10.0, -5.0, 13.0, 13.0, -8.0, -3.0, -1.0, 12.0, 7.0, -3.0, -15.0, 10.0, 13.0, 7.0, 12.0, 7.0, 3.0, -7.0, 9.0, 14.0, -11.0, 3.0, -1.0, 5.0, -1.0, 12.0, 12.0, -8.0, 10.0, 1.0, 11.0, 3.0, 3.0, -2.0, 12.0, 14.0, -9.0, -2.0, 7.0, -11.0, 7.0, 12.0, 3.0, -7.0, 11.0, 8.0, 12.0, 3.0, 2.0, -2.0, 11.0, 13.0, -22.0, 13.0, 8.0, 9.0, -13.0, 11.0, 13.0, 11.0, -9.0, 0.0, 5.0, 14.0, 0.0, -4.0, 13.0, 14.0, -10.0, -2.0, 7.0, -10.0, 5.0, 13.0, 14.0, 10.0, -3.0, -6.0, 11.0, 3.0, 5.0, -4.0, 7.0, -4.0, 4.0, 8.0, -13.0, 4.0, 12.0, 12.0, 6.0, 13.0, -6.0, 2.0, 3.0, 3.0, -3.0, 12.0, 11.0, 13.0, -18.0, 9.0, -8.0, 11.0, 5.0, 7.0, -6.0, 12.0, 9.0, 0.0, 9.0, 4.0, 7.0, -5.0, 11.0, 0.0, -7.0, 11.0, -13.0, 4.0, 11.0, 13.0, 5.0, -11.0, 11.0, 10.0, 10.0, 1.0, -3.0, 7.0, 14.0, 13.0, 9.0, -21.0, -2.0, 3.0, 1.0, 13.0, 6.0, -10.0, 10.0, 9.0, -5.0, 14.0, 10.0, -4.0, 13.0, 13.0, -7.0, -4.0, -6.0, -2.0, 11.0, 12.0, 11.0, 6.0, 7.0, -9.0, 7.0, 3.0, 9.0, -4.0, 8.0, 14.0, -20.0, 13.0, 5.0, -5.0, 4.0, 11.0, 9.0, 8.0, 8.0, -10.0, 13.0, 316.0, 12.0, 11.0, 12.0, 12.0, 318.0, 13.0, -4.0, 11.0, -3.0, 11.0, 11.0, -6.0, 13.0, -3.0, 5.0, 4.0, 10.0, -4.0, 9.0, 14.0, -20.0, 12.0, 3.0, -3.0, 2.0, 13.0, 12.0, 3.0, 7.0, -7.0, -4.0, 14.0, -4.0, 9.0, 9.0, 13.0, -19.0, 12.0, 9.0, -14.0, 7.0, 13.0, -4.0, 8.0, 10.0, 1.0, 12.0, 8.0, 2.0, -7.0, 11.0, 13.0, -8.0, -1.0, -5.0, -5.0, 12.0, 13.0, 5.0, -6.0, 12.0, 4.0, 7.0, 5.0, 6.0, -3.0, 13.0, 13.0, 315.0, 13.0, 6.0, 5.0, -8.0, 12.0, 10.0, -6.0, 10.0, 1.0, 13.0, 3.0, -10.0, 9.0, 12.0, 13.0, 317.0, 13.0, -13.0, 10.0, 6.0, 12.0, 10.0, -7.0, 11.0, 1.0, 8.0, -10.0, 8.0, 9.0, 12.0, -1.0, -5.0, 9.0, 3.0, -4.0, 7.0, 9.0, 4.0, -3.0, 11.0, 3.0, 12.0, 6.0, -13.0, 10.0, 11.0, 14.0, -4.0, -6.0, -3.0, -2.0, 8.0, 12.0, 2.0, 11.0, -2.0, 4.0, 6.0, 5.0, -6.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22010039006004162, "mean_inference_ms": 1.1723666129463577, "mean_action_processing_ms": 0.07172776522107359, "mean_env_wait_ms": 0.1790688368385334, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 637200, "agent_timesteps_total": 637119, "timers": {"sample_time_ms": 349.889, "sample_throughput": 15433.481, "learn_time_ms": 6691.756, "learn_throughput": 806.963, "update_time_ms": 11.69}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 459.2284851074219, "policy_loss": -0.020181680098176003, "vf_loss": 459.2455139160156, "vf_explained_var": 0.1562788486480713, "kl": 0.006101102102547884, "entropy": 0.466220498085022, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 637200, "num_agent_steps_sampled": 637119, "num_steps_trained": 637200, "num_agent_steps_trained": 637119}, "done": false, "episodes_total": 12474, "training_iteration": 118, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-55-57", "timestamp": 1626861357, "time_this_iter_s": 6.878281831741333, "time_total_s": 858.3173477649689, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f6c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 858.3173477649689, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 21.8, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 13.0, -2.0, 6.0, 8.0, 9.0, 3.0, -5.0, 4.0, 7.0, 8.0, -4.0, 9.0, 12.0, 1.0, -7.0, 6.0, 9.0, 9.0, -9.0, 11.0, 7.0, -2.0, -1.0, 5.0, 6.0, -2.0, 6.0, 8.0, 7.0, 8.0, -8.0, -21.0, 12.0, 11.0, 13.0, 9.0, 6.0, 3.0, -3.0, -11.0, 8.0, 12.0, 6.0, 5.0, 9.0, 7.0, -6.0, -7.0, 12.0, 13.0, -3.0, 14.0, 5.0, -1.0, -3.0, -7.0, 11.0, 3.0, 8.0, -10.0, 8.0, 5.0, 12.0, 0.0, 12.0, 12.0, -9.0, 13.0, 6.0, 2.0, -6.0, 9.0, 14.0, -10.0, 2.0, 8.0, 8.0, 5.0, -6.0, 3.0, 11.0, 11.0, -10.0, 14.0, 9.0, -7.0, -1.0, 4.0, 14.0, -1.0, -2.0, 9.0, 11.0, 1.0, -6.0, -14.0, 14.0, 11.0, 4.0, 14.0, 9.0, 6.0, -14.0, -12.0, 12.0, 11.0, 4.0, 10.0, -2.0, 1.0, 6.0, 5.0, 12.0, 11.0, -13.0, 8.0, 10.0, -12.0, 9.0, -5.0, 9.0, 9.0, 2.0, -4.0, 10.0, 12.0, -3.0, -1.0, 11.0, 11.0, -6.0, 14.0, -1.0, 4.0, -2.0, 7.0, 9.0, -2.0, 1.0, 4.0, -3.0, 5.0, 9.0, -7.0, 13.0, -3.0, 12.0, 13.0, 4.0, 0.0, -2.0, -10.0, 8.0, 10.0, 7.0, 11.0, -1.0, -8.0, 13.0, -20.0, 9.0, 13.0, 13.0, 7.0, 12.0, 1.0, -5.0, 6.0, 9.0, 12.0, -12.0, -4.0, 10.0, -2.0, 11.0, -17.0, 13.0, 11.0, 8.0, 6.0, -7.0, 5.0, 11.0, -11.0, 7.0, 8.0, 11.0, 6.0, 8.0, 7.0, -6.0, -19.0, 14.0, 11.0, 9.0, 8.0, 11.0, -3.0, -1.0, 4.0, 9.0, 8.0, -6.0, -2.0, 10.0, -1.0, 8.0, -8.0, 14.0, 13.0, -4.0, 9.0, 4.0, 7.0, -5.0, -10.0, 11.0, 7.0, 7.0, 6.0, -5.0, 12.0, 2.0, -8.0, 13.0, 11.0, -1.0, 14.0, 10.0, 10.0, -19.0, 12.0, 1.0, -5.0, 7.0, -4.0, 12.0, 0.0, 7.0, -4.0, 13.0, -2.0, 8.0, 6.0, 5.0, 11.0, -7.0, -8.0, 13.0, 8.0, 2.0, 10.0, -2.0, -5.0, 12.0, -8.0, 14.0, -3.0, 12.0, 10.0, 6.0, 6.0, -7.0, 7.0, 8.0, 7.0, -7.0, 9.0, -2.0, 1.0, 7.0, 1.0, 12.0, -4.0, 6.0, 14.0, 4.0, -1.0, -2.0, 3.0, 3.0, -3.0, 12.0, 13.0, 11.0, 318.0, 12.0, 6.0, -6.0, 7.0, 8.0, 12.0, 6.0, 0.0, -3.0, 2.0, 14.0, 2.0, -3.0, 8.0, 6.0, 7.0, -6.0, -19.0, 13.0, 10.0, 11.0, 10.0, 6.0, 4.0, -5.0, 3.0, 14.0, 12.0, -14.0, -6.0, 11.0, 4.0, 6.0, 1.0, 13.0, 11.0, -10.0, 8.0, -11.0, 6.0, 12.0, 7.0, 5.0, 12.0, -9.0, 8.0, 9.0, -1.0, -1.0, -15.0, 14.0, 13.0, 3.0, 13.0, -5.0, 2.0, 5.0, 9.0, 8.0, 11.0, -13.0, 10.0, 11.0, -14.0, 8.0, -10.0, 9.0, 10.0, 6.0, 14.0, 1.0, 5.0, -5.0, -9.0, 8.0, 9.0, 7.0, 7.0, 8.0, 2.0, -2.0, -4.0, 13.0, 11.0, -5.0, 14.0, 3.0, 2.0, -4.0, -10.0, 5.0, 12.0, 8.0, 6.0, -2.0, 5.0, 6.0, -7.0, 12.0, 13.0, -3.0, 5.0, 12.0, 0.0, -2.0, -3.0, 11.0, 12.0, -5.0, 13.0, -4.0, -6.0, 12.0, 2.0, 13.0, 10.0, -10.0, 14.0, 6.0, 3.0, -8.0, -7.0, 9.0, 8.0, 5.0, -8.0, 11.0, 11.0, 1.0, -18.0, 13.0, 13.0, 7.0, 8.0, 7.0, 6.0, -6.0, -6.0, 8.0, 5.0, 8.0, 12.0, 10.0, -5.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22018546032288264, "mean_inference_ms": 1.1727320419021436, "mean_action_processing_ms": 0.07174600593066803, "mean_env_wait_ms": 0.1791066652398498, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 642600, "agent_timesteps_total": 642519, "timers": {"sample_time_ms": 352.751, "sample_throughput": 15308.24, "learn_time_ms": 6627.06, "learn_throughput": 814.841, "update_time_ms": 11.648}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 213.50831604003906, "policy_loss": -0.026408014819025993, "vf_loss": 213.53065490722656, "vf_explained_var": 0.21301251649856567, "kl": 0.008020338602364063, "entropy": 0.44934943318367004, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 642600, "num_agent_steps_sampled": 642519, "num_steps_trained": 642600, "num_agent_steps_trained": 642519}, "done": false, "episodes_total": 12582, "training_iteration": 119, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-56-04", "timestamp": 1626861364, "time_this_iter_s": 6.89334511756897, "time_total_s": 865.2106928825378, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f6e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 865.2106928825378, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 21.7, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 43.24074074074074, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 10.810185185185185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 13.0, -19.0, 10.0, 10.0, -5.0, 2.0, 8.0, -9.0, 12.0, 10.0, 2.0, 13.0, 14.0, 314.0, 13.0, -5.0, 11.0, 0.0, 9.0, -5.0, 14.0, 3.0, 3.0, -2.0, -7.0, 12.0, 12.0, 11.0, 13.0, -8.0, -1.0, 8.0, -7.0, 2.0, 12.0, 8.0, -5.0, 8.0, 4.0, 4.0, -13.0, 13.0, 11.0, 13.0, 9.0, -6.0, -1.0, 11.0, 13.0, -18.0, 9.0, -2.0, 12.0, -1.0, 6.0, 10.0, -7.0, 6.0, 6.0, 11.0, 14.0, -9.0, -1.0, 13.0, 14.0, 318.0, 10.0, 11.0, 0.0, 2.0, 2.0, 2.0, -10.0, 12.0, 11.0, 11.0, 14.0, -9.0, -1.0, -8.0, 13.0, 1.0, 9.0, 12.0, -5.0, 8.0, 0.0, 2.0, 13.0, -6.0, 6.0, 13.0, 14.0, 313.0, 13.0, 11.0, 8.0, -14.0, 10.0, 9.0, -3.0, 7.0, 2.0, -2.0, 9.0, 13.0, -5.0, 11.0, 13.0, -8.0, -1.0, 7.0, 9.0, -11.0, 10.0, 8.0, 14.0, -3.0, -4.0, 7.0, 10.0, 9.0, -11.0, 12.0, 14.0, -10.0, -1.0, -10.0, 8.0, 5.0, 12.0, 11.0, 9.0, -9.0, 4.0, -16.0, 7.0, 13.0, 11.0, 11.0, 14.0, -9.0, -1.0, 1.0, -5.0, 6.0, 13.0, -6.0, 6.0, 3.0, 12.0, 3.0, -1.0, 6.0, 7.0, 13.0, 14.0, -11.0, -1.0, 13.0, 8.0, -16.0, 10.0, 9.0, -3.0, 1.0, 8.0, -2.0, -2.0, 12.0, 7.0, 11.0, 14.0, -9.0, -1.0, 13.0, 13.0, -20.0, 9.0, 11.0, 13.0, -15.0, 6.0, 9.0, -15.0, 10.0, 11.0, 12.0, 14.0, -10.0, -1.0, 13.0, 14.0, 318.0, 9.0, 11.0, 9.0, -6.0, 1.0, -3.0, -6.0, 13.0, 11.0, 11.0, 14.0, -9.0, -1.0, -2.0, 12.0, -7.0, 12.0, -5.0, 14.0, -5.0, 11.0, 2.0, -6.0, 9.0, 10.0, 5.0, 13.0, -2.0, -1.0, 14.0, 5.0, -13.0, 9.0, 11.0, -11.0, 12.0, 3.0, -6.0, 13.0, -3.0, 11.0, 9.0, 14.0, -21.0, 13.0, 13.0, 14.0, -6.0, -6.0, 10.0, 9.0, -7.0, 3.0, -2.0, -2.0, 6.0, 13.0, 13.0, 14.0, 315.0, 13.0, 11.0, 7.0, -14.0, 11.0, 7.0, 10.0, -8.0, 6.0, -1.0, -4.0, 10.0, 10.0, 13.0, 14.0, 313.0, 13.0, 13.0, 14.0, -20.0, 8.0, 5.0, 10.0, -6.0, 6.0, 4.0, 11.0, 11.0, -11.0, 11.0, 14.0, -9.0, -1.0, 12.0, 11.0, -19.0, 11.0, -3.0, 14.0, -8.0, 12.0, 14.0, 317.0, 11.0, 12.0, 2.0, 10.0, -10.0, 13.0, 9.0, 7.0, -13.0, 12.0, 13.0, -5.0, 8.0, -1.0, -2.0, -8.0, 13.0, 12.0, 6.0, 6.0, 7.0, -4.0, 12.0, 8.0, -15.0, 10.0, 12.0, -6.0, 3.0, 6.0, 12.0, 10.0, 12.0, -19.0, 13.0, 14.0, -11.0, -1.0, 5.0, 9.0, -10.0, 11.0, 8.0, 8.0, -2.0, 1.0, 6.0, -4.0, 11.0, 2.0, 5.0, 14.0, -3.0, -1.0, 13.0, 14.0, -19.0, 7.0, 10.0, -10.0, 4.0, 11.0, 11.0, -12.0, 6.0, 10.0, 13.0, 14.0, 314.0, 13.0, 13.0, 12.0, -20.0, 10.0, -4.0, 7.0, 8.0, 4.0, 6.0, 12.0, -9.0, 6.0, 9.0, 14.0, -7.0, -1.0, 13.0, 13.0, 315.0, 12.0, 8.0, 4.0, -2.0, 5.0, -19.0, 10.0, 13.0, 11.0, 11.0, 14.0, -9.0, -1.0, 4.0, 11.0, -8.0, 8.0, 8.0, -6.0, 8.0, 5.0, 0.0, -2.0, 6.0, 11.0, 12.0, 11.0, -3.0, -5.0, -2.0, 6.0, 8.0, 3.0, 7.0, 0.0, 7.0, 1.0, 4.0, -8.0, 12.0, 7.0, 12.0, 13.0, -9.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22019815606607948, "mean_inference_ms": 1.172810708164653, "mean_action_processing_ms": 0.07175008513858817, "mean_env_wait_ms": 0.1791338584930077, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 648000, "agent_timesteps_total": 647919, "timers": {"sample_time_ms": 354.051, "sample_throughput": 15252.041, "learn_time_ms": 6583.493, "learn_throughput": 820.233, "update_time_ms": 11.413}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 1552.8590087890625, "policy_loss": -0.026064695790410042, "vf_loss": 1552.8812255859375, "vf_explained_var": 0.03304152190685272, "kl": 0.007649847771972418, "entropy": 0.4580642282962799, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 648000, "num_agent_steps_sampled": 647919, "num_steps_trained": 648000, "num_agent_steps_trained": 647919}, "done": false, "episodes_total": 12690, "training_iteration": 120, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-56-11", "timestamp": 1626861371, "time_this_iter_s": 7.191779613494873, "time_total_s": 872.4024724960327, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f6ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 872.4024724960327, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 21.39, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.546296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 6.136574074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 9.0, 5.0, -7.0, 5.0, 2.0, -5.0, 13.0, 7.0, -12.0, 10.0, 10.0, -7.0, 7.0, 8.0, 7.0, 12.0, -1.0, 12.0, -8.0, 9.0, -15.0, 12.0, 9.0, 1.0, 5.0, 11.0, -2.0, -8.0, 6.0, 7.0, 10.0, 5.0, 9.0, -12.0, 13.0, 7.0, 7.0, -8.0, 9.0, 6.0, 10.0, 2.0, -3.0, -5.0, 7.0, 3.0, 10.0, 12.0, 8.0, -10.0, 5.0, 8.0, 6.0, -8.0, 9.0, 11.0, -6.0, 4.0, 6.0, 13.0, -5.0, 7.0, 0.0, 11.0, 8.0, 11.0, -15.0, 7.0, -3.0, -2.0, 13.0, 7.0, -7.0, 9.0, 6.0, 4.0, 0.0, 12.0, -1.0, 10.0, 9.0, -3.0, -1.0, 12.0, -5.0, 10.0, -2.0, 7.0, -13.0, 13.0, 8.0, 8.0, 6.0, 8.0, -7.0, 9.0, 8.0, 1.0, -3.0, 7.0, -12.0, 12.0, 8.0, 7.0, -2.0, 5.0, 5.0, -6.0, 7.0, 6.0, 8.0, 12.0, -6.0, 12.0, -3.0, 13.0, -14.0, 9.0, 7.0, -7.0, -1.0, 10.0, 13.0, 13.0, 332.0, 11.0, 11.0, 11.0, 13.0, 4.0, -13.0, 2.0, -9.0, 12.0, 10.0, 12.0, 318.0, 12.0, 12.0, 13.0, 11.0, 11.0, -20.0, -1.0, 10.0, -3.0, 9.0, 7.0, -11.0, 10.0, 9.0, 8.0, -9.0, 7.0, 9.0, -1.0, 7.0, 6.0, 3.0, 13.0, -6.0, 11.0, -3.0, 6.0, 6.0, 4.0, -1.0, 8.0, -3.0, 4.0, 6.0, 13.0, -15.0, 7.0, 10.0, 9.0, -5.0, 2.0, 9.0, 13.0, 318.0, 12.0, 12.0, 2.0, -8.0, 10.0, 11.0, 11.0, -17.0, 11.0, 10.0, 10.0, -1.0, -5.0, 11.0, 11.0, -5.0, -2.0, 11.0, 12.0, -17.0, 12.0, 8.0, 10.0, -1.0, 11.0, -5.0, 10.0, 0.0, 12.0, -7.0, 13.0, 3.0, 9.0, -10.0, -7.0, 1.0, 10.0, 11.0, -3.0, -3.0, 11.0, 10.0, 12.0, 8.0, -14.0, 9.0, 7.0, -3.0, -2.0, 13.0, 10.0, -11.0, 10.0, 6.0, -1.0, 3.0, 5.0, 8.0, 11.0, 8.0, -11.0, 7.0, 3.0, 4.0, 9.0, -1.0, 11.0, -11.0, 9.0, 6.0, -2.0, 12.0, -6.0, 11.0, 8.0, -5.0, 4.0, 8.0, 9.0, -6.0, -1.0, 13.0, 7.0, -13.0, 10.0, 11.0, -3.0, 4.0, 6.0, 8.0, -6.0, 8.0, 2.0, 11.0, 9.0, -6.0, -1.0, 13.0, 7.0, 11.0, -14.0, 11.0, -1.0, 9.0, 11.0, -4.0, 5.0, 9.0, 11.0, -10.0, 6.0, 0.0, 10.0, -1.0, 2.0, -4.0, 11.0, 6.0, -3.0, 3.0, 7.0, 8.0, 6.0, 8.0, 11.0, -10.0, 10.0, -1.0, 8.0, -2.0, 7.0, -9.0, 10.0, 7.0, 12.0, 7.0, 11.0, -15.0, 9.0, -6.0, 3.0, 9.0, 10.0, -3.0, 10.0, -2.0, 1.0, -2.0, 5.0, 11.0, 4.0, 8.0, 7.0, -4.0, 6.0, 8.0, -10.0, 11.0, 5.0, 4.0, -4.0, 10.0, -2.0, -6.0, 12.0, 11.0, 12.0, -2.0, 7.0, -2.0, 11.0, -2.0, 8.0, -2.0, 13.0, -18.0, 7.0, 13.0, 13.0, -21.0, 12.0, 11.0, -3.0, 1.0, 7.0, 10.0, 13.0, -8.0, 11.0, -1.0, 12.0, -7.0, 12.0, -2.0, 2.0, -8.0, 11.0, 10.0, 13.0, 11.0, 6.0, -15.0, 10.0, -6.0, 2.0, 9.0, 2.0, 5.0, -5.0, 13.0, 10.0, 8.0, -11.0, 8.0, -2.0, 8.0, 11.0, -2.0, -11.0, 13.0, 5.0, 8.0, 9.0, -18.0, 12.0, 12.0, 12.0, -13.0, 8.0, 8.0, -10.0, 8.0, 12.0, 5.0, 11.0, 8.0, 10.0, -14.0, 9.0, -1.0, 9.0, -2.0, 12.0, -12.0, 11.0, 4.0, -6.0, 3.0, 9.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22024432824115311, "mean_inference_ms": 1.1730339610879676, "mean_action_processing_ms": 0.07176294293170025, "mean_env_wait_ms": 0.17917426025624983, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 653400, "agent_timesteps_total": 653319, "timers": {"sample_time_ms": 354.654, "sample_throughput": 15226.12, "learn_time_ms": 6536.371, "learn_throughput": 826.146, "update_time_ms": 11.343}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 663.6458129882812, "policy_loss": -0.022232765331864357, "vf_loss": 663.6640014648438, "vf_explained_var": 0.07430345565080643, "kl": 0.007867838256061077, "entropy": 0.4550175666809082, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 653400, "num_agent_steps_sampled": 653319, "num_steps_trained": 653400, "num_agent_steps_trained": 653319}, "done": false, "episodes_total": 12798, "training_iteration": 121, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-56-18", "timestamp": 1626861378, "time_this_iter_s": 7.0949413776397705, "time_total_s": 879.4974138736725, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cc80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 879.4974138736725, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 21.64, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.26851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 314.0}, "policy_reward_mean": {"learned": 5.31712962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 14.0, -1.0, -6.0, 12.0, 5.0, -15.0, 13.0, 14.0, 14.0, 0.0, -13.0, -6.0, 13.0, 10.0, -2.0, 10.0, 12.0, -13.0, 6.0, 12.0, 9.0, -18.0, 12.0, 8.0, 12.0, -13.0, 8.0, 9.0, -8.0, 13.0, 1.0, 8.0, 14.0, -19.0, 12.0, 12.0, 8.0, -17.0, 12.0, -5.0, -3.0, 10.0, 13.0, 9.0, -1.0, -1.0, 8.0, -9.0, 9.0, 9.0, 6.0, 14.0, 6.0, -16.0, 11.0, -6.0, 7.0, 2.0, 12.0, -3.0, 9.0, 13.0, -4.0, -13.0, 13.0, 7.0, 8.0, 14.0, 5.0, -16.0, 12.0, 8.0, 11.0, -16.0, 12.0, 10.0, -2.0, 13.0, -6.0, 7.0, 14.0, -2.0, -4.0, 8.0, 7.0, -12.0, 12.0, -7.0, 9.0, 9.0, 4.0, 11.0, 7.0, 12.0, -15.0, 12.0, -7.0, 5.0, 5.0, 13.0, 5.0, -15.0, 12.0, -6.0, 6.0, 2.0, 13.0, 4.0, 7.0, 7.0, -3.0, 0.0, 10.0, -7.0, 12.0, 13.0, 7.0, -17.0, 12.0, 14.0, 14.0, -4.0, -9.0, -5.0, 7.0, 7.0, 6.0, 7.0, 12.0, -12.0, 8.0, 13.0, 5.0, -1.0, -2.0, 10.0, -8.0, 2.0, 11.0, 8.0, -9.0, 3.0, 13.0, 9.0, 2.0, -7.0, 11.0, 13.0, 7.0, 11.0, -16.0, 14.0, 14.0, 314.0, 11.0, 12.0, -8.0, 0.0, 11.0, 6.0, 12.0, -12.0, 9.0, 12.0, 5.0, -15.0, 13.0, -4.0, 12.0, -2.0, 9.0, 12.0, -2.0, -1.0, 6.0, -8.0, 6.0, 10.0, 7.0, 12.0, 7.0, -17.0, 13.0, 10.0, 13.0, -21.0, 13.0, 13.0, -2.0, 0.0, 4.0, 10.0, 7.0, 7.0, -9.0, 14.0, 6.0, -2.0, -3.0, -3.0, 8.0, -3.0, 13.0, 13.0, -2.0, 1.0, 3.0, 11.0, -11.0, 4.0, 11.0, 13.0, 6.0, -15.0, 11.0, 9.0, 10.0, -17.0, 13.0, 14.0, -9.0, 3.0, 7.0, 8.0, -4.0, 1.0, 10.0, 11.0, 5.0, -14.0, 13.0, 6.0, 11.0, -10.0, 8.0, -5.0, 10.0, 9.0, 1.0, 13.0, 12.0, -6.0, -4.0, 13.0, 4.0, -15.0, 13.0, 10.0, 12.0, -20.0, 13.0, 12.0, -8.0, 4.0, 7.0, 3.0, 9.0, -8.0, 11.0, 13.0, 1.0, -11.0, 12.0, 10.0, 9.0, -17.0, 13.0, 11.0, -2.0, 2.0, 4.0, 9.0, 12.0, -6.0, 0.0, 13.0, 5.0, 0.0, -3.0, 0.0, 10.0, -8.0, 13.0, 8.0, 7.0, 8.0, -8.0, -12.0, 8.0, 12.0, 7.0, 8.0, 11.0, -16.0, 12.0, 14.0, 14.0, -20.0, 7.0, 11.0, -2.0, 3.0, 3.0, -7.0, 14.0, -2.0, 10.0, 12.0, 5.0, -15.0, 13.0, 14.0, 14.0, -15.0, 2.0, 10.0, -1.0, 7.0, -1.0, 13.0, -7.0, 2.0, 7.0, 13.0, 4.0, -15.0, 13.0, 13.0, 7.0, -13.0, 8.0, -4.0, 7.0, 13.0, -1.0, -6.0, 13.0, 6.0, 2.0, 14.0, 6.0, -17.0, 12.0, 14.0, 14.0, 313.0, 13.0, -3.0, 13.0, 12.0, -7.0, 4.0, 7.0, -2.0, 6.0, 13.0, 4.0, -15.0, 13.0, 10.0, 13.0, -20.0, 12.0, 7.0, 8.0, 12.0, -12.0, 4.0, 5.0, -2.0, 8.0, 13.0, 6.0, -17.0, 13.0, 14.0, 14.0, -16.0, 3.0, 10.0, -2.0, 5.0, 2.0, 11.0, 14.0, -20.0, 10.0, 13.0, 7.0, -1.0, -4.0, -10.0, 6.0, 6.0, 13.0, 12.0, -7.0, 13.0, -3.0, -2.0, 12.0, 8.0, -3.0, 13.0, 7.0, -2.0, -3.0, -5.0, 5.0, 3.0, 12.0, 10.0, -6.0, 13.0, -2.0, 12.0, 7.0, -13.0, 9.0, 13.0, 4.0, -15.0, 13.0, 13.0, 14.0, -2.0, -10.0, 10.0, -1.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22028213456519907, "mean_inference_ms": 1.173127421614758, "mean_action_processing_ms": 0.07176010242450677, "mean_env_wait_ms": 0.17917551016217945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 658800, "agent_timesteps_total": 658719, "timers": {"sample_time_ms": 355.465, "sample_throughput": 15191.355, "learn_time_ms": 6500.616, "learn_throughput": 830.691, "update_time_ms": 11.464}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 438.89239501953125, "policy_loss": -0.027444351464509964, "vf_loss": 438.9159240722656, "vf_explained_var": 0.13121862709522247, "kl": 0.007794239558279514, "entropy": 0.4695011079311371, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 658800, "num_agent_steps_sampled": 658719, "num_steps_trained": 658800, "num_agent_steps_trained": 658719}, "done": false, "episodes_total": 12906, "training_iteration": 122, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-56-26", "timestamp": 1626861386, "time_this_iter_s": 7.24540114402771, "time_total_s": 886.7428150177002, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 886.7428150177002, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 21.69090909090909, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 1.0, 6.0, -4.0, -10.0, 13.0, 6.0, 6.0, 3.0, -7.0, 8.0, 11.0, 14.0, 7.0, 3.0, -9.0, 12.0, -19.0, 11.0, 11.0, -9.0, 12.0, 6.0, 6.0, 11.0, 2.0, -3.0, 5.0, 8.0, 13.0, -6.0, 0.0, 12.0, -3.0, -7.0, 13.0, -12.0, 14.0, 7.0, 6.0, 7.0, -12.0, 8.0, 12.0, 4.0, 13.0, -4.0, 2.0, 12.0, 0.0, 6.0, -3.0, -12.0, 14.0, 6.0, 7.0, 10.0, 2.0, -5.0, 8.0, 0.0, 9.0, 3.0, 3.0, 11.0, 6.0, 2.0, -4.0, 0.0, 0.0, 8.0, 7.0, 6.0, -7.0, 8.0, 8.0, 8.0, 9.0, -7.0, 5.0, 11.0, -1.0, 8.0, -3.0, 4.0, 0.0, 5.0, 6.0, 11.0, 3.0, -5.0, 6.0, 14.0, 12.0, 317.0, 12.0, 6.0, 3.0, 8.0, -2.0, -10.0, 14.0, 6.0, 5.0, 0.0, 1.0, 6.0, 8.0, 7.0, -5.0, 6.0, 7.0, 12.0, -3.0, 12.0, -6.0, -15.0, 14.0, 10.0, 6.0, 13.0, -11.0, 7.0, 6.0, 8.0, 13.0, 9.0, -15.0, 10.0, -1.0, 11.0, -5.0, -3.0, 14.0, 7.0, -3.0, 13.0, 5.0, 9.0, -12.0, 4.0, 11.0, -12.0, 12.0, 14.0, -17.0, 8.0, 10.0, 11.0, 8.0, -11.0, 7.0, 11.0, -16.0, 8.0, 12.0, 7.0, 12.0, -16.0, 12.0, 8.0, 8.0, 0.0, -1.0, 6.0, 14.0, -9.0, 4.0, 2.0, -10.0, 13.0, 10.0, 9.0, 3.0, 5.0, -2.0, 12.0, -1.0, 7.0, -3.0, -16.0, 14.0, 11.0, 6.0, -8.0, 12.0, 5.0, 6.0, 14.0, 12.0, -10.0, -1.0, 13.0, -5.0, 12.0, -5.0, -10.0, 14.0, 7.0, 4.0, 7.0, -6.0, 5.0, 9.0, 13.0, 6.0, -9.0, 5.0, 11.0, -15.0, 6.0, 13.0, -2.0, 14.0, 11.0, -8.0, 12.0, -12.0, 8.0, 7.0, 13.0, -4.0, 3.0, 3.0, 10.0, -20.0, 13.0, 12.0, -6.0, 8.0, 5.0, 8.0, -12.0, 10.0, 8.0, 9.0, -10.0, 9.0, 9.0, 7.0, 14.0, -7.0, 11.0, -3.0, -8.0, 10.0, 7.0, 6.0, 8.0, -7.0, 8.0, 6.0, 8.0, 10.0, 9.0, -12.0, 13.0, -5.0, 10.0, -3.0, -14.0, 14.0, 10.0, 5.0, 6.0, -11.0, 11.0, 9.0, 9.0, 10.0, -16.0, 12.0, 14.0, -2.0, 6.0, -3.0, -2.0, -1.0, 12.0, 6.0, -9.0, 0.0, 11.0, 13.0, 13.0, 12.0, -19.0, 9.0, 12.0, 3.0, -13.0, 13.0, -12.0, 14.0, 7.0, 6.0, 14.0, -1.0, 9.0, -7.0, 8.0, 11.0, -11.0, 7.0, 11.0, -12.0, 3.0, 13.0, -12.0, 14.0, 7.0, 6.0, 9.0, 10.0, 5.0, -9.0, 9.0, 12.0, 4.0, -10.0, 11.0, 4.0, -11.0, 11.0, -1.0, 10.0, 1.0, 5.0, 12.0, -7.0, 4.0, 6.0, 7.0, 9.0, 11.0, -12.0, 12.0, -4.0, 10.0, -3.0, -6.0, 11.0, 4.0, 6.0, 13.0, -14.0, 9.0, 7.0, 14.0, 10.0, 5.0, -14.0, 4.0, 5.0, 11.0, -5.0, -5.0, 11.0, 1.0, 8.0, 10.0, -7.0, 7.0, 5.0, -4.0, 8.0, 9.0, 2.0, 8.0, -1.0, 11.0, -3.0, -15.0, 12.0, 11.0, 7.0, -1.0, 7.0, 3.0, 6.0, 7.0, 11.0, -11.0, 8.0, 13.0, 1.0, -12.0, 13.0, -16.0, 14.0, 11.0, 6.0, 14.0, -8.0, 4.0, 5.0, 10.0, 6.0, 4.0, -5.0, 13.0, 3.0, -14.0, 13.0, -13.0, 12.0, 8.0, 8.0, -5.0, 6.0, 7.0, 7.0, 14.0, 13.0, -18.0, 6.0, 3.0, 5.0, 9.0, -2.0, -13.0, 14.0, 8.0, 6.0, 8.0, 9.0, -9.0, 7.0, 13.0, 13.0, 2.0, -13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22029914900350908, "mean_inference_ms": 1.173282366070726, "mean_action_processing_ms": 0.07176289969190376, "mean_env_wait_ms": 0.17918237117711755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 664200, "agent_timesteps_total": 664119, "timers": {"sample_time_ms": 356.061, "sample_throughput": 15165.921, "learn_time_ms": 6480.8, "learn_throughput": 833.23, "update_time_ms": 11.307}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 236.75086975097656, "policy_loss": -0.033199429512023926, "vf_loss": 236.77902221679688, "vf_explained_var": 0.20036552846431732, "kl": 0.009881467558443546, "entropy": 0.4368067979812622, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 664200, "num_agent_steps_sampled": 664119, "num_steps_trained": 664200, "num_agent_steps_trained": 664119}, "done": false, "episodes_total": 13014, "training_iteration": 123, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-56-33", "timestamp": 1626861393, "time_this_iter_s": 7.066072225570679, "time_total_s": 893.8088872432709, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029ce18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 893.8088872432709, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 21.270000000000003, "ram_util_percent": 14.209999999999999}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.314814814814813, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 5.328703703703703}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 8.0, -14.0, 9.0, 12.0, 12.0, 6.0, -15.0, 12.0, -5.0, 10.0, -2.0, 11.0, -6.0, 4.0, 6.0, -13.0, 9.0, 8.0, 11.0, 12.0, 10.0, 8.0, -15.0, 11.0, 3.0, -6.0, 7.0, 8.0, -4.0, 6.0, 5.0, 3.0, 11.0, 8.0, -7.0, -4.0, 13.0, 4.0, 2.0, 13.0, 7.0, 2.0, -7.0, -5.0, 5.0, 10.0, 5.0, -4.0, 7.0, 8.0, 4.0, 5.0, 10.0, 8.0, -8.0, 6.0, 8.0, 6.0, -5.0, 8.0, -7.0, 6.0, 8.0, 6.0, 8.0, -7.0, 8.0, 4.0, -6.0, 11.0, 6.0, 6.0, -14.0, 10.0, 13.0, 12.0, -9.0, 6.0, 6.0, -7.0, 8.0, 7.0, 7.0, -11.0, 11.0, 9.0, 6.0, 8.0, -6.0, 2.0, 11.0, 3.0, -1.0, 8.0, 5.0, 3.0, 9.0, 9.0, -6.0, 5.0, 7.0, 12.0, -9.0, 6.0, -5.0, 9.0, 5.0, 6.0, 11.0, -8.0, 6.0, 2.0, 8.0, -8.0, 13.0, 8.0, 8.0, 5.0, -6.0, 8.0, 9.0, -6.0, 4.0, 14.0, -19.0, 10.0, 10.0, 4.0, 8.0, -6.0, 9.0, 0.0, 13.0, 4.0, -2.0, 8.0, 4.0, -3.0, 6.0, 8.0, -8.0, 4.0, 11.0, 12.0, 13.0, 319.0, 12.0, 10.0, 10.0, 10.0, -15.0, 3.0, 8.0, 10.0, -6.0, 7.0, -3.0, 5.0, 6.0, 8.0, 9.0, -13.0, 11.0, -5.0, 12.0, 5.0, 3.0, 11.0, 3.0, -3.0, 4.0, 4.0, -3.0, 9.0, 5.0, 12.0, 11.0, 320.0, 13.0, -15.0, 11.0, 12.0, 7.0, 11.0, 8.0, -5.0, 1.0, 4.0, 9.0, -10.0, 12.0, -18.0, 11.0, 9.0, 13.0, 3.0, -1.0, 12.0, 1.0, 2.0, 7.0, -4.0, 10.0, -6.0, 8.0, 6.0, 7.0, 8.0, 10.0, -15.0, 12.0, 9.0, -5.0, 5.0, 6.0, 7.0, -1.0, -1.0, 10.0, 9.0, -9.0, 6.0, 9.0, -15.0, 11.0, 8.0, 11.0, 8.0, -5.0, 8.0, 4.0, 8.0, -7.0, 6.0, 8.0, 13.0, 11.0, -13.0, 4.0, -8.0, 5.0, 6.0, 12.0, -18.0, 13.0, 11.0, 9.0, 9.0, 9.0, -5.0, 2.0, 11.0, 11.0, -3.0, -4.0, -1.0, 11.0, -3.0, 8.0, 8.0, 3.0, 7.0, -3.0, 7.0, -5.0, 2.0, 11.0, 7.0, 6.0, 6.0, -4.0, 5.0, 12.0, 8.0, -10.0, -5.0, 14.0, 5.0, 1.0, 10.0, -10.0, 8.0, 7.0, 7.0, -1.0, 8.0, 1.0, 4.0, 7.0, -9.0, 13.0, 9.0, -2.0, 11.0, -3.0, 12.0, -1.0, 11.0, -7.0, 7.0, -1.0, 3.0, 6.0, 8.0, 1.0, -5.0, 11.0, 0.0, 8.0, 12.0, -5.0, 4.0, 4.0, 11.0, -4.0, 12.0, 0.0, -2.0, 5.0, 7.0, 9.0, -8.0, 7.0, 13.0, -3.0, -2.0, 7.0, 11.0, -4.0, 10.0, -2.0, 13.0, -3.0, -3.0, 8.0, 2.0, 11.0, -7.0, 9.0, 9.0, 8.0, 8.0, -10.0, 11.0, 1.0, 5.0, -2.0, 12.0, -8.0, 5.0, 6.0, 8.0, 8.0, -8.0, 7.0, 9.0, -4.0, 6.0, 4.0, 6.0, -2.0, 0.0, 11.0, 0.0, -2.0, 11.0, 6.0, 8.0, 10.0, -15.0, 12.0, -14.0, 12.0, 12.0, 5.0, 5.0, 12.0, 2.0, -4.0, 7.0, -13.0, 9.0, 12.0, 6.0, 8.0, -10.0, 11.0, -15.0, 11.0, 11.0, 8.0, 10.0, 8.0, -10.0, 7.0, -12.0, 10.0, 10.0, 7.0, 3.0, 9.0, -5.0, 8.0, 2.0, 12.0, 12.0, -11.0, 2.0, -7.0, 11.0, 9.0, -17.0, 12.0, 12.0, 8.0, 6.0, 8.0, -3.0, 4.0, 8.0, 12.0, -11.0, 6.0, 5.0, 9.0, 4.0, -3.0, 12.0, 12.0, -12.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22035403090052536, "mean_inference_ms": 1.1735135612518954, "mean_action_processing_ms": 0.07177457117335904, "mean_env_wait_ms": 0.17922817204059435, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 669600, "agent_timesteps_total": 669519, "timers": {"sample_time_ms": 357.211, "sample_throughput": 15117.111, "learn_time_ms": 6510.063, "learn_throughput": 829.485, "update_time_ms": 11.561}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 331.743408203125, "policy_loss": -0.025910519063472748, "vf_loss": 331.76531982421875, "vf_explained_var": 0.12109897285699844, "kl": 0.007875404320657253, "entropy": 0.48069852590560913, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 669600, "num_agent_steps_sampled": 669519, "num_steps_trained": 669600, "num_agent_steps_trained": 669519}, "done": false, "episodes_total": 13122, "training_iteration": 124, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-56-40", "timestamp": 1626861400, "time_this_iter_s": 7.1519997119903564, "time_total_s": 900.9608869552612, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70214c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 900.9608869552612, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 22.049999999999997, "ram_util_percent": 14.209999999999999}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.546296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.886574074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -8.0, 9.0, 4.0, 9.0, 12.0, -13.0, 7.0, 4.0, 13.0, 7.0, -9.0, 3.0, 12.0, -8.0, 8.0, -12.0, 14.0, 10.0, 3.0, 4.0, 9.0, -2.0, 4.0, -14.0, 12.0, 7.0, 10.0, 8.0, 10.0, -11.0, 8.0, 7.0, -7.0, 9.0, 6.0, -8.0, 10.0, 0.0, 13.0, -15.0, 13.0, 5.0, 12.0, -12.0, 12.0, 10.0, 5.0, 2.0, 14.0, 11.0, -12.0, 2.0, 13.0, 4.0, -4.0, 12.0, -2.0, 7.0, -2.0, 5.0, 12.0, -10.0, 8.0, 11.0, -8.0, 5.0, 7.0, 10.0, 12.0, 2.0, -9.0, 12.0, 12.0, 8.0, -17.0, 9.0, 11.0, 1.0, -6.0, 9.0, -6.0, 12.0, 0.0, 11.0, 13.0, -2.0, -7.0, 8.0, 13.0, 6.0, -12.0, 4.0, 12.0, -8.0, 7.0, -2.0, 11.0, 9.0, -3.0, 9.0, 11.0, -4.0, -1.0, -19.0, 11.0, 11.0, 12.0, 6.0, 8.0, -7.0, 8.0, 3.0, -2.0, 13.0, 1.0, -17.0, 11.0, 8.0, 13.0, -6.0, 11.0, 12.0, -2.0, 5.0, 12.0, -3.0, 1.0, 9.0, 11.0, 5.0, -10.0, 0.0, -6.0, 10.0, 11.0, 13.0, 12.0, 13.0, 315.0, 0.0, 12.0, 10.0, -7.0, 10.0, -6.0, 12.0, -1.0, -10.0, 10.0, 9.0, 6.0, -6.0, 13.0, 13.0, -5.0, -1.0, -7.0, 10.0, 13.0, 9.0, 13.0, 13.0, -20.0, 1.0, 6.0, -5.0, 13.0, 12.0, 13.0, 2.0, -12.0, 4.0, 12.0, -9.0, 8.0, 11.0, 6.0, 12.0, -14.0, -8.0, 10.0, 4.0, 9.0, 7.0, 10.0, 12.0, -14.0, 2.0, 11.0, 5.0, -3.0, 10.0, -7.0, 10.0, 2.0, 12.0, 11.0, 321.0, 11.0, 9.0, 7.0, 4.0, -5.0, -13.0, 12.0, 8.0, 8.0, 10.0, 5.0, 12.0, -12.0, 4.0, -3.0, 5.0, 9.0, 9.0, 11.0, 13.0, -18.0, 4.0, 12.0, -6.0, 5.0, 11.0, 7.0, 11.0, -14.0, -2.0, 8.0, -4.0, 13.0, 8.0, 10.0, 13.0, -16.0, 3.0, 10.0, 7.0, -5.0, 5.0, 14.0, 10.0, -14.0, 11.0, 12.0, -17.0, 9.0, 6.0, 13.0, 6.0, -10.0, 8.0, 11.0, -7.0, 3.0, 12.0, 4.0, 12.0, -13.0, 13.0, 7.0, -13.0, 8.0, 12.0, 7.0, 7.0, -11.0, 8.0, 11.0, -5.0, 1.0, 6.0, -6.0, 13.0, 2.0, -5.0, 11.0, -3.0, 12.0, 3.0, -6.0, 7.0, 11.0, -3.0, 12.0, -7.0, 13.0, 8.0, -3.0, 7.0, 3.0, 9.0, 10.0, 8.0, -12.0, -15.0, 12.0, 6.0, 12.0, 9.0, 11.0, -8.0, 3.0, 7.0, -6.0, 11.0, 3.0, -12.0, 12.0, 6.0, 9.0, -20.0, 13.0, 12.0, 10.0, 6.0, 12.0, -5.0, 2.0, 10.0, -3.0, 7.0, 1.0, -6.0, 13.0, -5.0, 13.0, 12.0, 13.0, 12.0, 316.0, -3.0, 11.0, 8.0, -1.0, 317.0, 14.0, 12.0, 11.0, 9.0, 12.0, -8.0, 2.0, 12.0, 10.0, 6.0, -13.0, 7.0, 12.0, 7.0, -11.0, 11.0, -6.0, 9.0, 1.0, -15.0, 13.0, 9.0, 8.0, 13.0, 10.0, 11.0, -19.0, 10.0, 12.0, -4.0, -3.0, -8.0, 7.0, 13.0, 3.0, 9.0, 12.0, 9.0, -15.0, 13.0, 7.0, 9.0, -14.0, 7.0, 10.0, -7.0, 5.0, 1.0, 11.0, 13.0, -10.0, -8.0, 7.0, 10.0, 6.0, -15.0, 8.0, 11.0, 11.0, 4.0, 11.0, 3.0, -3.0, 5.0, 13.0, 11.0, -14.0, 8.0, 10.0, -9.0, 6.0, 12.0, -5.0, 11.0, -3.0, 13.0, 5.0, 4.0, -7.0, 8.0, 8.0, 12.0, -13.0, 1.0, 10.0, -9.0, 13.0, 9.0, 9.0, 13.0, -16.0, 7.0, 12.0, 5.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22037579228337217, "mean_inference_ms": 1.1737185551764762, "mean_action_processing_ms": 0.07178329779085495, "mean_env_wait_ms": 0.17924585592712, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 675000, "agent_timesteps_total": 674919, "timers": {"sample_time_ms": 358.038, "sample_throughput": 15082.207, "learn_time_ms": 6552.109, "learn_throughput": 824.162, "update_time_ms": 11.596}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 788.3357543945312, "policy_loss": -0.02294693887233734, "vf_loss": 788.3550415039062, "vf_explained_var": 0.09270428121089935, "kl": 0.0070291683077812195, "entropy": 0.47421765327453613, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 675000, "num_agent_steps_sampled": 674919, "num_steps_trained": 675000, "num_agent_steps_trained": 674919}, "done": false, "episodes_total": 13230, "training_iteration": 125, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-56-47", "timestamp": 1626861407, "time_this_iter_s": 7.0864503383636475, "time_total_s": 908.0473372936249, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70214e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 908.0473372936249, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 21.56, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, -4.0, 12.0, 12.0, -9.0, 10.0, 4.0, 10.0, 12.0, -5.0, -3.0, 11.0, 5.0, -4.0, 3.0, 11.0, -2.0, 6.0, 12.0, -1.0, -7.0, 12.0, 5.0, 5.0, 9.0, -8.0, 5.0, 9.0, -13.0, 10.0, 11.0, 7.0, 12.0, -4.0, -6.0, 13.0, 2.0, 13.0, -12.0, 12.0, 10.0, -6.0, 10.0, 1.0, -15.0, 11.0, 12.0, 7.0, -8.0, 1.0, 11.0, 11.0, -1.0, 12.0, 5.0, -1.0, 6.0, 2.0, -5.0, 12.0, -1.0, -1.0, 7.0, 10.0, 12.0, -16.0, 7.0, 12.0, -6.0, 13.0, -3.0, 11.0, 10.0, -2.0, -4.0, 11.0, 9.0, -10.0, 5.0, 11.0, 11.0, -2.0, -6.0, 12.0, 10.0, 11.0, -10.0, 4.0, 10.0, 8.0, -9.0, 6.0, 10.0, 4.0, -12.0, 13.0, -4.0, 5.0, 4.0, 10.0, -3.0, 9.0, 3.0, 6.0, -2.0, 8.0, 5.0, 4.0, 5.0, -5.0, 11.0, 4.0, -2.0, 1.0, 8.0, 8.0, -6.0, 14.0, 4.0, 3.0, 10.0, 7.0, -4.0, 2.0, 3.0, -4.0, 8.0, 8.0, -6.0, 9.0, 5.0, 7.0, -11.0, 6.0, 8.0, 12.0, 9.0, 4.0, -10.0, 12.0, 2.0, -10.0, 10.0, 13.0, -7.0, 4.0, 10.0, 8.0, 11.0, 12.0, -9.0, 1.0, 6.0, 6.0, -4.0, 7.0, 5.0, -6.0, 3.0, 13.0, -1.0, -6.0, 12.0, 10.0, -4.0, 13.0, -5.0, 11.0, 8.0, 3.0, -7.0, 11.0, -15.0, 12.0, 12.0, 6.0, -2.0, -5.0, 11.0, 11.0, -4.0, 12.0, -4.0, 11.0, 10.0, 4.0, -4.0, 5.0, -1.0, -3.0, 7.0, 12.0, -6.0, 8.0, 10.0, 3.0, 7.0, 11.0, -11.0, 8.0, 11.0, 2.0, -1.0, 3.0, -4.0, -4.0, 10.0, 13.0, -3.0, 1.0, 11.0, 6.0, -6.0, 12.0, -4.0, 13.0, 10.0, 8.0, -3.0, 0.0, -20.0, 12.0, 11.0, 12.0, -3.0, -3.0, 12.0, 9.0, -5.0, 6.0, 3.0, 11.0, -6.0, 1.0, 8.0, 12.0, 6.0, -9.0, 5.0, 13.0, -4.0, 2.0, 5.0, 12.0, 6.0, 11.0, -10.0, 8.0, -7.0, 3.0, 7.0, 12.0, -2.0, -3.0, 11.0, 9.0, -2.0, 1.0, 5.0, 11.0, 4.0, 11.0, -11.0, 11.0, 5.0, 4.0, -4.0, 10.0, -4.0, -2.0, 10.0, 11.0, -2.0, -1.0, 10.0, 8.0, -6.0, 11.0, 5.0, 5.0, 9.0, 9.0, 12.0, -15.0, -2.0, 8.0, -4.0, 13.0, -2.0, -2.0, 12.0, 7.0, 1.0, 11.0, -4.0, 7.0, 10.0, 2.0, 11.0, -8.0, 1.0, -6.0, 11.0, 9.0, -1.0, 5.0, 4.0, 7.0, -8.0, 13.0, -1.0, 11.0, -5.0, 2.0, 6.0, 12.0, 1.0, -4.0, 5.0, 13.0, -5.0, -3.0, 12.0, 11.0, 12.0, -9.0, 10.0, 2.0, 12.0, 4.0, 2.0, -3.0, -17.0, 8.0, 11.0, 13.0, -3.0, -2.0, 11.0, 9.0, -1.0, 3.0, 10.0, 3.0, 10.0, 4.0, -2.0, 3.0, -1.0, -3.0, 8.0, 11.0, 6.0, -7.0, 6.0, 10.0, 12.0, 11.0, -2.0, -6.0, -6.0, 3.0, 11.0, 7.0, 4.0, 9.0, -3.0, 5.0, 10.0, -18.0, 11.0, 12.0, -10.0, 11.0, 4.0, 10.0, 8.0, 3.0, -4.0, 8.0, 12.0, -2.0, -4.0, 9.0, -4.0, -3.0, 11.0, 11.0, 9.0, 12.0, -2.0, -4.0, 12.0, 6.0, -11.0, 8.0, 6.0, -9.0, 5.0, 13.0, -3.0, 10.0, 2.0, 6.0, 12.0, 8.0, 6.0, -11.0, 11.0, -1.0, -3.0, 8.0, -2.0, 7.0, 12.0, -2.0, 5.0, 5.0, 12.0, -7.0, -5.0, 12.0, 5.0, 3.0, -3.0, 3.0, 11.0, 4.0, 1.0, -5.0, 7.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2203686349072836, "mean_inference_ms": 1.173882946348446, "mean_action_processing_ms": 0.07178815208134458, "mean_env_wait_ms": 0.17926687941478536, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 680400, "agent_timesteps_total": 680319, "timers": {"sample_time_ms": 358.533, "sample_throughput": 15061.395, "learn_time_ms": 6597.685, "learn_throughput": 818.469, "update_time_ms": 11.652}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 24.17848014831543, "policy_loss": -0.08237846195697784, "vf_loss": 24.251047134399414, "vf_explained_var": 0.253421425819397, "kl": 0.019386811181902885, "entropy": 0.45670193433761597, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 680400, "num_agent_steps_sampled": 680319, "num_steps_trained": 680400, "num_agent_steps_trained": 680319}, "done": false, "episodes_total": 13338, "training_iteration": 126, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-56-54", "timestamp": 1626861414, "time_this_iter_s": 7.298424959182739, "time_total_s": 915.3457622528076, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70214ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 915.3457622528076, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 22.063636363636363, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 366.0, "episode_reward_min": 15.0, "episode_reward_mean": 33.99074074074074, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 8.497685185185185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 7.0, 11.0, -11.0, -8.0, 14.0, -3.0, 12.0, -3.0, 5.0, 5.0, 8.0, 11.0, 11.0, 0.0, -7.0, 7.0, -2.0, 4.0, 6.0, -11.0, 13.0, 1.0, 12.0, -9.0, 1.0, 10.0, 13.0, 10.0, 12.0, -15.0, 8.0, 14.0, 12.0, 6.0, -17.0, 1.0, 13.0, -11.0, 12.0, -4.0, 12.0, 5.0, 2.0, 8.0, 11.0, -17.0, 13.0, 12.0, 7.0, -1.0, -3.0, -3.0, 14.0, -7.0, 11.0, 10.0, 4.0, -12.0, 13.0, 5.0, 11.0, -10.0, 9.0, 11.0, 7.0, 8.0, -11.0, 319.0, 14.0, 10.0, 11.0, 10.0, -2.0, 3.0, 4.0, -9.0, 10.0, 6.0, 8.0, 7.0, 14.0, 2.0, -8.0, -16.0, 14.0, 6.0, 11.0, -2.0, 3.0, 5.0, 9.0, 7.0, 11.0, -1.0, -2.0, 9.0, 3.0, -10.0, 13.0, -11.0, 14.0, 0.0, 12.0, -9.0, 8.0, 8.0, 8.0, 9.0, 5.0, -4.0, 5.0, 11.0, 8.0, 6.0, -10.0, -13.0, 10.0, 6.0, 12.0, -4.0, 6.0, 4.0, 9.0, 13.0, 3.0, -14.0, 13.0, 11.0, 1.0, -9.0, 12.0, 9.0, 14.0, -19.0, 11.0, -3.0, 7.0, 7.0, 4.0, 13.0, 9.0, -14.0, 7.0, 11.0, 9.0, 6.0, -11.0, -8.0, 14.0, -3.0, 12.0, 12.0, -4.0, 3.0, 4.0, 6.0, 14.0, -17.0, 12.0, 9.0, 6.0, 12.0, -12.0, -7.0, 14.0, -3.0, 11.0, 14.0, 9.0, 331.0, 12.0, 8.0, 10.0, 2.0, -5.0, 6.0, 9.0, -6.0, 6.0, 0.0, 14.0, 8.0, -7.0, -8.0, 7.0, 10.0, 6.0, 6.0, 10.0, -14.0, 13.0, 4.0, 12.0, 12.0, -13.0, -17.0, 12.0, 8.0, 12.0, -5.0, 12.0, 8.0, 0.0, 4.0, 12.0, 10.0, -11.0, -2.0, 12.0, -6.0, 11.0, -4.0, 14.0, -6.0, 11.0, -8.0, 11.0, 4.0, 8.0, 10.0, 7.0, -10.0, 8.0, 6.0, 9.0, -13.0, 13.0, -12.0, 11.0, 5.0, 11.0, 9.0, -11.0, 9.0, 8.0, 8.0, -2.0, 1.0, 8.0, 12.0, -8.0, 7.0, 4.0, 4.0, 14.0, -15.0, 12.0, -10.0, 7.0, 13.0, 5.0, 8.0, 14.0, -15.0, 8.0, 10.0, 2.0, 6.0, -3.0, -15.0, 10.0, 8.0, 12.0, 7.0, 6.0, 4.0, -2.0, 12.0, 0.0, 9.0, -6.0, 12.0, 3.0, 5.0, -5.0, -11.0, 5.0, 9.0, 12.0, -6.0, 13.0, 3.0, 5.0, 3.0, 10.0, -5.0, 7.0, 11.0, 5.0, 6.0, -7.0, 321.0, 13.0, 9.0, 11.0, -1.0, 8.0, 3.0, 5.0, 7.0, 13.0, -11.0, 6.0, 13.0, 9.0, 5.0, -12.0, 319.0, 14.0, 9.0, 12.0, -2.0, 3.0, 5.0, 9.0, 12.0, 9.0, 0.0, -6.0, 7.0, 5.0, 9.0, -6.0, -18.0, 14.0, 10.0, 9.0, -6.0, 12.0, 4.0, 5.0, 9.0, 13.0, -14.0, 7.0, 13.0, 10.0, 7.0, -15.0, -17.0, 14.0, 6.0, 12.0, -7.0, 13.0, 3.0, 6.0, 0.0, 11.0, 5.0, -1.0, 13.0, -2.0, 12.0, -8.0, -13.0, 13.0, 3.0, 12.0, -3.0, 3.0, 3.0, 12.0, 1.0, -5.0, 6.0, 13.0, 0.0, 11.0, -8.0, 12.0, -12.0, 14.0, 1.0, 12.0, -7.0, 12.0, 11.0, -1.0, 6.0, -9.0, 11.0, 7.0, 8.0, -7.0, 3.0, 11.0, -2.0, 9.0, -4.0, 12.0, -3.0, 0.0, 8.0, 10.0, -10.0, 1.0, 11.0, 13.0, 7.0, 8.0, -12.0, 12.0, 323.0, 14.0, 8.0, 12.0, 13.0, 2.0, 10.0, -10.0, 6.0, -10.0, 11.0, 8.0, 13.0, 7.0, -15.0, 10.0, 324.0, 12.0, 9.0, 11.0, -6.0, 12.0, -2.0, 11.0, 1.0, -3.0, 4.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.220230608759163, "mean_inference_ms": 1.1738380676909583, "mean_action_processing_ms": 0.0717858722106971, "mean_env_wait_ms": 0.17924630354632975, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 685800, "agent_timesteps_total": 685746, "timers": {"sample_time_ms": 356.872, "sample_throughput": 15131.476, "learn_time_ms": 6627.171, "learn_throughput": 814.827, "update_time_ms": 11.48}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 1268.8177490234375, "policy_loss": -0.021459391340613365, "vf_loss": 1268.83642578125, "vf_explained_var": 0.06827504932880402, "kl": 0.005794833414256573, "entropy": 0.4397108256816864, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 685800, "num_agent_steps_sampled": 685746, "num_steps_trained": 685800, "num_agent_steps_trained": 685746}, "done": false, "episodes_total": 13446, "training_iteration": 127, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-02", "timestamp": 1626861422, "time_this_iter_s": 7.11868691444397, "time_total_s": 922.4644491672516, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cbf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 922.4644491672516, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 21.14, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 25.22, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 324.0}, "policy_reward_mean": {"learned": 6.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -8.0, 5.0, 10.0, 2.0, 12.0, -3.0, 4.0, 12.0, -6.0, 5.0, 4.0, -1.0, -2.0, 8.0, 10.0, 0.0, 13.0, -6.0, 8.0, -8.0, 7.0, 8.0, 8.0, 11.0, 3.0, -10.0, 11.0, 5.0, 3.0, -4.0, 11.0, 11.0, 5.0, -2.0, 1.0, 10.0, -2.0, 4.0, 3.0, 4.0, 11.0, 5.0, -5.0, 6.0, -2.0, 6.0, 5.0, 8.0, 13.0, -16.0, 10.0, 6.0, 5.0, -2.0, 6.0, -12.0, 12.0, 12.0, 3.0, 0.0, 1.0, 3.0, 11.0, 2.0, 13.0, 4.0, -4.0, 10.0, -9.0, 11.0, 3.0, 9.0, 10.0, -16.0, 12.0, 8.0, 1.0, -3.0, 9.0, -13.0, 9.0, 6.0, 13.0, 0.0, -3.0, 9.0, 9.0, -5.0, 13.0, 10.0, -3.0, 6.0, 13.0, -9.0, 5.0, 13.0, -13.0, 5.0, 10.0, 6.0, 12.0, 0.0, -3.0, 3.0, -7.0, 13.0, 6.0, 13.0, -13.0, 4.0, 11.0, -2.0, 8.0, 10.0, -1.0, 0.0, 13.0, -5.0, 7.0, 13.0, 8.0, -15.0, 9.0, 5.0, 10.0, -9.0, 9.0, 3.0, 5.0, -5.0, 12.0, 12.0, -10.0, 1.0, 12.0, 4.0, 10.0, 9.0, -8.0, -3.0, 2.0, 5.0, 11.0, 10.0, 8.0, -10.0, 7.0, 3.0, 13.0, 6.0, -7.0, -8.0, 13.0, 10.0, 0.0, 1.0, 0.0, 4.0, 10.0, 4.0, 7.0, 10.0, -6.0, 12.0, -9.0, 6.0, 6.0, -11.0, 14.0, 5.0, 7.0, 2.0, 11.0, 12.0, -10.0, -4.0, 0.0, 6.0, 13.0, -9.0, 13.0, 0.0, 11.0, 3.0, 11.0, 4.0, -3.0, 10.0, -8.0, 7.0, 6.0, 13.0, -11.0, 3.0, 10.0, 6.0, 10.0, 8.0, -9.0, -11.0, 14.0, 12.0, 0.0, 11.0, -5.0, 0.0, 9.0, 5.0, 10.0, 6.0, -6.0, 3.0, 12.0, -4.0, 4.0, 13.0, 13.0, 318.0, 10.0, 1.0, 12.0, -7.0, 9.0, 7.0, -2.0, 6.0, 4.0, 12.0, -13.0, 5.0, 11.0, 13.0, 9.0, -12.0, 5.0, -8.0, 13.0, 8.0, 2.0, 0.0, 12.0, -9.0, 12.0, 8.0, 3.0, 7.0, -3.0, 6.0, 0.0, 8.0, 1.0, 13.0, -8.0, 1.0, 9.0, 0.0, 12.0, 6.0, -3.0, -5.0, 0.0, 8.0, 12.0, 12.0, -11.0, 4.0, 10.0, 3.0, 12.0, 4.0, -4.0, -3.0, 2.0, 5.0, 11.0, 13.0, 3.0, -12.0, 11.0, 9.0, 11.0, 2.0, -7.0, -5.0, 5.0, 7.0, 8.0, -13.0, 14.0, 3.0, 11.0, 8.0, 12.0, 5.0, -10.0, 10.0, 13.0, -3.0, -5.0, -6.0, 11.0, -1.0, 11.0, 9.0, 10.0, -10.0, 6.0, -8.0, 14.0, 4.0, 5.0, 13.0, 9.0, -17.0, 10.0, 9.0, 11.0, -17.0, 12.0, -18.0, 13.0, 8.0, 12.0, -13.0, 13.0, 3.0, 12.0, -3.0, 3.0, 3.0, 12.0, 1.0, -5.0, 6.0, 13.0, 0.0, 11.0, -8.0, 12.0, -12.0, 14.0, 1.0, 12.0, -7.0, 12.0, 11.0, -1.0, 6.0, -9.0, 11.0, 7.0, 8.0, -7.0, 3.0, 11.0, -2.0, 9.0, -4.0, 12.0, -3.0, 0.0, 8.0, 10.0, -10.0, 1.0, 11.0, 13.0, 7.0, 8.0, -12.0, 12.0, 323.0, 14.0, 8.0, 12.0, 13.0, 2.0, 10.0, -10.0, 6.0, -10.0, 11.0, 8.0, 13.0, 7.0, -15.0, 10.0, 324.0, 12.0, 9.0, 11.0, -6.0, 12.0, -2.0, 11.0, 1.0, -3.0, 4.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22008483675616486, "mean_inference_ms": 1.1727355660725065, "mean_action_processing_ms": 0.07178883836124665, "mean_env_wait_ms": 0.17912960238128453, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 691200, "agent_timesteps_total": 691119, "timers": {"sample_time_ms": 356.564, "sample_throughput": 15144.552, "learn_time_ms": 6646.968, "learn_throughput": 812.4, "update_time_ms": 11.541}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 237.16592407226562, "policy_loss": -0.027652200311422348, "vf_loss": 237.1888427734375, "vf_explained_var": 0.17408983409404755, "kl": 0.009279152378439903, "entropy": 0.472079873085022, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 691200, "num_agent_steps_sampled": 691119, "num_steps_trained": 691200, "num_agent_steps_trained": 691119}, "done": false, "episodes_total": 13527, "training_iteration": 128, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-09", "timestamp": 1626861429, "time_this_iter_s": 7.0767810344696045, "time_total_s": 929.5412302017212, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 929.5412302017212, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 21.380000000000003, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 13.0, 12.0, -16.0, 13.0, 4.0, 7.0, -9.0, 8.0, 11.0, 12.0, -16.0, 1.0, -3.0, 13.0, 4.0, 6.0, 6.0, 11.0, -8.0, 12.0, -1.0, -2.0, 6.0, 11.0, 3.0, 9.0, -8.0, 8.0, 10.0, 3.0, -6.0, 10.0, 12.0, 8.0, -15.0, 10.0, -5.0, 5.0, 5.0, 9.0, -4.0, 13.0, -3.0, 11.0, -12.0, 7.0, 9.0, 11.0, 4.0, 10.0, -10.0, 11.0, 7.0, 3.0, -6.0, 12.0, 7.0, 7.0, -11.0, 2.0, -1.0, 13.0, 1.0, -6.0, 13.0, 13.0, -5.0, 12.0, -3.0, -7.0, 13.0, -12.0, 5.0, 12.0, 10.0, -10.0, 12.0, 4.0, 9.0, 3.0, 11.0, 11.0, -10.0, 6.0, 8.0, 2.0, -1.0, 13.0, 10.0, 9.0, -17.0, 4.0, 11.0, -9.0, 9.0, 3.0, 9.0, 9.0, -6.0, 7.0, -6.0, 5.0, 9.0, 13.0, 5.0, 5.0, -8.0, 9.0, -5.0, 3.0, 8.0, 9.0, 10.0, 7.0, -11.0, 10.0, 4.0, -10.0, 11.0, 7.0, -5.0, 11.0, 2.0, 7.0, -1.0, 5.0, 4.0, 10.0, 12.0, 8.0, -15.0, 5.0, 8.0, -11.0, 13.0, 12.0, -3.0, 12.0, -6.0, 1.0, 10.0, 13.0, -9.0, -8.0, 11.0, 6.0, 6.0, 5.0, -3.0, 0.0, 13.0, 12.0, 4.0, 13.0, -14.0, 2.0, -3.0, 12.0, 4.0, 6.0, 10.0, -10.0, 9.0, 8.0, -2.0, 8.0, 1.0, 4.0, 2.0, 10.0, -1.0, 4.0, -1.0, 7.0, 5.0, 8.0, 0.0, 11.0, -4.0, 9.0, 3.0, -2.0, 5.0, 9.0, -2.0, 13.0, -5.0, 11.0, -1.0, -2.0, 7.0, 5.0, 12.0, 6.0, -8.0, 9.0, 3.0, 5.0, -2.0, 9.0, 5.0, 13.0, -12.0, 3.0, -4.0, 8.0, 8.0, 9.0, 4.0, 11.0, -9.0, 3.0, 7.0, -2.0, 7.0, -1.0, 7.0, 12.0, -3.0, -1.0, -1.0, 4.0, 13.0, 7.0, 7.0, 12.0, -11.0, 10.0, -11.0, 5.0, 11.0, 8.0, -4.0, 9.0, 2.0, 4.0, 0.0, 12.0, -1.0, 8.0, 3.0, 12.0, -8.0, 11.0, 1.0, 12.0, -9.0, 13.0, 9.0, 13.0, -20.0, 4.0, 3.0, 10.0, -2.0, 5.0, 12.0, 9.0, -11.0, 12.0, 1.0, 8.0, -6.0, 11.0, -8.0, 11.0, 1.0, 4.0, -4.0, 2.0, 13.0, -9.0, 7.0, 13.0, 4.0, 12.0, -11.0, 10.0, 4.0, 11.0, 6.0, 13.0, -15.0, -3.0, -2.0, 7.0, 13.0, 4.0, 10.0, 9.0, -8.0, 8.0, -6.0, 4.0, 9.0, 10.0, 7.0, 8.0, -10.0, 5.0, -3.0, 7.0, 6.0, 3.0, 11.0, 6.0, -5.0, 11.0, 10.0, 4.0, -10.0, -2.0, 10.0, 6.0, 1.0, 9.0, -13.0, 11.0, 8.0, 4.0, 8.0, 11.0, -8.0, 10.0, 9.0, 1.0, -5.0, 12.0, 4.0, 12.0, -13.0, 10.0, -10.0, 3.0, 12.0, 8.0, 6.0, 6.0, -5.0, 12.0, -10.0, 8.0, 5.0, 10.0, -6.0, 8.0, 3.0, 7.0, 12.0, 13.0, -17.0, 8.0, 13.0, -10.0, 4.0, 12.0, 10.0, 5.0, -12.0, 11.0, -4.0, 5.0, 3.0, -9.0, 1.0, 11.0, 12.0, 1.0, 12.0, 12.0, -10.0, 10.0, 6.0, -10.0, 9.0, 12.0, 5.0, 10.0, -12.0, 3.0, -3.0, 7.0, 8.0, 8.0, 7.0, 11.0, -11.0, 7.0, -3.0, 1.0, 10.0, 9.0, -8.0, 10.0, 4.0, 2.0, 0.0, 13.0, 0.0, 12.0, 7.0, 8.0, -12.0, 14.0, 2.0, -11.0, 10.0, 12.0, -9.0, 12.0, 0.0, 2.0, -1.0, 11.0, 3.0, -2.0, 13.0, 12.0, -8.0, 14.0, 4.0, 0.0, -3.0, -8.0, 12.0, 12.0, -1.0, 4.0, -13.0, 11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22032705176019285, "mean_inference_ms": 1.174029430376169, "mean_action_processing_ms": 0.07178688829913621, "mean_env_wait_ms": 0.17926045831539136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 696600, "agent_timesteps_total": 696519, "timers": {"sample_time_ms": 355.564, "sample_throughput": 15187.134, "learn_time_ms": 6664.922, "learn_throughput": 810.212, "update_time_ms": 11.738}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 22.90089225769043, "policy_loss": -0.08281800150871277, "vf_loss": 22.97422981262207, "vf_explained_var": 0.28468334674835205, "kl": 0.018729068338871002, "entropy": 0.46478718519210815, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 696600, "num_agent_steps_sampled": 696519, "num_steps_trained": 696600, "num_agent_steps_trained": 696519}, "done": false, "episodes_total": 13635, "training_iteration": 129, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-16", "timestamp": 1626861436, "time_this_iter_s": 7.07050895690918, "time_total_s": 936.6117391586304, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cd90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 936.6117391586304, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 21.71, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -9.0, 4.0, 10.0, -7.0, 11.0, 6.0, 5.0, 8.0, 13.0, -13.0, 7.0, 5.0, -9.0, 12.0, 7.0, 8.0, -14.0, 12.0, 9.0, -15.0, 9.0, 12.0, 9.0, 10.0, 8.0, 8.0, -11.0, 4.0, -6.0, 8.0, 9.0, 13.0, 10.0, 8.0, -16.0, -4.0, -2.0, 9.0, 12.0, 8.0, 12.0, -12.0, 7.0, 3.0, -7.0, 8.0, 11.0, 8.0, 12.0, 3.0, -8.0, 5.0, 10.0, 1.0, -1.0, -2.0, 6.0, 4.0, 7.0, 0.0, -9.0, 13.0, 11.0, 13.0, 13.0, -12.0, 1.0, -17.0, 8.0, 12.0, 12.0, 14.0, 1.0, -12.0, 12.0, 9.0, -15.0, 10.0, 11.0, 13.0, 10.0, -16.0, 8.0, -14.0, 9.0, 12.0, 8.0, 8.0, 12.0, 11.0, -16.0, 4.0, -8.0, 8.0, 11.0, 3.0, 13.0, 12.0, -13.0, 3.0, -3.0, 10.0, 5.0, -8.0, 2.0, 8.0, 13.0, 8.0, -13.0, 13.0, 7.0, 8.0, 9.0, 7.0, -9.0, -4.0, -5.0, 12.0, 12.0, 8.0, 7.0, -12.0, 12.0, 14.0, 8.0, 10.0, -17.0, 11.0, 7.0, 12.0, -15.0, -3.0, 9.0, 10.0, -1.0, 4.0, 11.0, -4.0, 4.0, 13.0, -10.0, 6.0, 6.0, 11.0, 13.0, -1.0, -8.0, 4.0, -4.0, 4.0, 11.0, 9.0, 12.0, -4.0, -2.0, 8.0, -11.0, 13.0, 5.0, 8.0, 12.0, 5.0, -10.0, 13.0, -9.0, 2.0, 9.0, 6.0, 13.0, 7.0, -11.0, -7.0, 10.0, 8.0, 4.0, 2.0, 10.0, -10.0, 13.0, 8.0, 10.0, -2.0, -1.0, -8.0, 8.0, 4.0, 11.0, 3.0, -6.0, 13.0, 5.0, 11.0, 10.0, -1.0, -5.0, 3.0, 6.0, 12.0, -6.0, 10.0, 4.0, 3.0, -2.0, 10.0, -14.0, 13.0, 6.0, 8.0, 9.0, -7.0, 5.0, 13.0, -5.0, 4.0, 3.0, 9.0, 8.0, 2.0, -4.0, 14.0, 3.0, 13.0, -15.0, 12.0, 12.0, 4.0, -13.0, -11.0, 9.0, 9.0, 8.0, 3.0, 13.0, 9.0, -10.0, 8.0, -8.0, 8.0, 7.0, 3.0, 9.0, 7.0, -4.0, -9.0, 8.0, 7.0, 9.0, 9.0, 7.0, -13.0, 12.0, 14.0, -5.0, 6.0, 0.0, 12.0, 7.0, 8.0, -12.0, 5.0, -5.0, 6.0, 9.0, 6.0, 8.0, 8.0, -7.0, 6.0, -12.0, 13.0, 8.0, 11.0, 0.0, 8.0, -4.0, -11.0, 11.0, 7.0, 8.0, 0.0, 1.0, 4.0, 10.0, 3.0, -10.0, 11.0, 11.0, -1.0, 13.0, -4.0, 7.0, -1.0, -4.0, 10.0, 10.0, 5.0, 11.0, 10.0, -11.0, 8.0, -9.0, 11.0, 5.0, 9.0, -2.0, 8.0, 0.0, -17.0, 9.0, 10.0, 13.0, 7.0, 6.0, -10.0, 12.0, 6.0, -13.0, 12.0, 10.0, 13.0, 9.0, 7.0, -14.0, -9.0, 10.0, 11.0, 3.0, 14.0, -1.0, -9.0, 11.0, 4.0, 6.0, 10.0, -5.0, 12.0, 10.0, -12.0, 5.0, 14.0, -4.0, 3.0, 2.0, 6.0, 8.0, -9.0, 10.0, 6.0, -11.0, 11.0, 9.0, 8.0, 12.0, -2.0, -3.0, -15.0, 9.0, 9.0, 12.0, 13.0, 9.0, -9.0, 2.0, -2.0, -8.0, 13.0, 12.0, 10.0, 7.0, -12.0, 10.0, 10.0, 8.0, -8.0, 5.0, 3.0, 12.0, 2.0, -2.0, 13.0, -9.0, 8.0, 3.0, 11.0, 13.0, 3.0, -12.0, -2.0, 8.0, 12.0, -3.0, 14.0, 8.0, -13.0, 6.0, 2.0, 6.0, 13.0, -6.0, 8.0, 6.0, -6.0, 7.0, -7.0, 12.0, 8.0, 2.0, 8.0, 3.0, -8.0, 12.0, 8.0, 4.0, 8.0, -5.0, 9.0, 12.0, 8.0, -14.0, 1.0, 11.0, 10.0, -7.0, -5.0, 4.0, 9.0, 7.0, 3.0, -12.0, 12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22041063068662675, "mean_inference_ms": 1.1740054626862817, "mean_action_processing_ms": 0.07179287380957522, "mean_env_wait_ms": 0.17927609707956668, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 702000, "agent_timesteps_total": 701919, "timers": {"sample_time_ms": 354.794, "sample_throughput": 15220.111, "learn_time_ms": 6666.818, "learn_throughput": 809.982, "update_time_ms": 11.676}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 22.185531616210938, "policy_loss": -0.08237527310848236, "vf_loss": 22.2587833404541, "vf_explained_var": 0.35794878005981445, "kl": 0.018017617985606194, "entropy": 0.4436740577220917, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 702000, "num_agent_steps_sampled": 701919, "num_steps_trained": 702000, "num_agent_steps_trained": 701919}, "done": false, "episodes_total": 13743, "training_iteration": 130, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-23", "timestamp": 1626861443, "time_this_iter_s": 7.195445537567139, "time_total_s": 943.8071846961975, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f8c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 943.8071846961975, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 21.93, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.38888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 329.0}, "policy_reward_mean": {"learned": 7.847222222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 356.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 10.0, 11.0, -15.0, 13.0, -12.0, 6.0, 8.0, 4.0, -6.0, 7.0, 10.0, 9.0, 4.0, 2.0, 13.0, 9.0, -13.0, 11.0, 8.0, 14.0, 11.0, 10.0, -20.0, 8.0, 6.0, 3.0, -2.0, 0.0, -8.0, 13.0, 10.0, 13.0, 4.0, 9.0, -11.0, 14.0, -5.0, 12.0, -6.0, 7.0, -9.0, 6.0, 11.0, 8.0, -4.0, -2.0, 13.0, 13.0, 0.0, 9.0, -7.0, 11.0, 12.0, -18.0, 10.0, 13.0, 8.0, 0.0, -6.0, 9.0, 6.0, -12.0, 12.0, -10.0, 12.0, 12.0, 1.0, 13.0, -2.0, 5.0, -1.0, 7.0, -5.0, 9.0, 4.0, 14.0, -9.0, -3.0, 13.0, 8.0, 12.0, 10.0, -15.0, 11.0, -2.0, 2.0, 4.0, 7.0, 7.0, 9.0, -8.0, 9.0, 8.0, -15.0, 13.0, 8.0, 10.0, -9.0, 6.0, 10.0, -1.0, 5.0, 1.0, 4.0, 10.0, -9.0, 10.0, 14.0, -16.0, 4.0, 13.0, 14.0, -9.0, 11.0, -1.0, 8.0, -4.0, 1.0, 10.0, 13.0, -7.0, -2.0, 11.0, 14.0, -11.0, 0.0, 13.0, 13.0, -15.0, 6.0, 11.0, 12.0, -5.0, 12.0, -4.0, 3.0, -3.0, 7.0, 8.0, 14.0, -15.0, 3.0, 13.0, 12.0, 3.0, 11.0, -11.0, 13.0, -2.0, -1.0, 5.0, 13.0, -4.0, 0.0, 6.0, 3.0, 6.0, -7.0, 13.0, 13.0, 5.0, 11.0, -14.0, 7.0, -3.0, 3.0, 8.0, 8.0, 3.0, -7.0, 11.0, 9.0, 3.0, 3.0, 13.0, 12.0, 12.0, 11.0, 321.0, 11.0, -8.0, 6.0, 6.0, 11.0, 7.0, -2.0, -1.0, 6.0, 0.0, 9.0, 13.0, 11.0, 7.0, 12.0, -15.0, 12.0, -7.0, 11.0, -1.0, 13.0, 10.0, -13.0, 5.0, 10.0, 13.0, -21.0, 13.0, 7.0, 12.0, -10.0, 6.0, 13.0, -3.0, 7.0, -2.0, -10.0, 11.0, 5.0, 9.0, 14.0, 11.0, 329.0, 13.0, 13.0, 5.0, -16.0, 13.0, 7.0, -13.0, 12.0, 9.0, 13.0, -3.0, -6.0, 11.0, 14.0, 8.0, -20.0, 13.0, 13.0, 0.0, 11.0, -9.0, 14.0, -8.0, 12.0, -3.0, 8.0, 12.0, 1.0, -6.0, 14.0, 6.0, -18.0, 13.0, 5.0, -7.0, 11.0, 6.0, 12.0, 13.0, 12.0, 319.0, 11.0, 11.0, 0.0, -7.0, 9.0, 5.0, -10.0, 12.0, 8.0, 10.0, 11.0, -14.0, 13.0, -2.0, 10.0, -6.0, 12.0, -10.0, 2.0, 11.0, 5.0, -8.0, 6.0, 13.0, -1.0, -6.0, 11.0, 11.0, 5.0, 7.0, -3.0, 6.0, 12.0, -7.0, 2.0, 8.0, 12.0, 1.0, -10.0, 12.0, 14.0, -2.0, 10.0, -7.0, 13.0, -5.0, 10.0, -3.0, 7.0, -8.0, 4.0, 12.0, 14.0, 9.0, -21.0, 13.0, 9.0, 10.0, 7.0, -11.0, 14.0, 13.0, -17.0, 5.0, 2.0, -10.0, 12.0, 11.0, 13.0, -7.0, -4.0, 13.0, 13.0, 11.0, 12.0, 319.0, 13.0, 12.0, 319.0, 11.0, 13.0, 6.0, -2.0, -2.0, 14.0, -7.0, -5.0, 13.0, 11.0, -13.0, 11.0, 6.0, 6.0, -2.0, -1.0, 12.0, 7.0, -9.0, 6.0, 11.0, 14.0, 2.0, -12.0, 12.0, 14.0, 11.0, 10.0, -20.0, 8.0, -3.0, 2.0, 8.0, 13.0, -4.0, -1.0, 7.0, 2.0, -9.0, 9.0, 13.0, 10.0, -6.0, 11.0, 0.0, 6.0, -1.0, 0.0, 10.0, 10.0, 7.0, 12.0, -14.0, 14.0, 1.0, -11.0, 11.0, 10.0, 10.0, 2.0, -7.0, 12.0, 13.0, -4.0, -6.0, 5.0, 10.0, -11.0, 11.0, 6.0, 12.0, -3.0, 13.0, 11.0, 12.0, 5.0, -13.0, 8.0, -11.0, 12.0, 6.0, -12.0, 11.0, 7.0, 9.0, 14.0, -11.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.220459094263099, "mean_inference_ms": 1.1740600244299477, "mean_action_processing_ms": 0.07179708047168319, "mean_env_wait_ms": 0.17929424786800666, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 707400, "agent_timesteps_total": 707319, "timers": {"sample_time_ms": 354.799, "sample_throughput": 15219.869, "learn_time_ms": 6667.914, "learn_throughput": 809.848, "update_time_ms": 11.604}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 748.3824462890625, "policy_loss": -0.020186150446534157, "vf_loss": 748.3997192382812, "vf_explained_var": 0.09339199215173721, "kl": 0.005707516800612211, "entropy": 0.4262976050376892, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 707400, "num_agent_steps_sampled": 707319, "num_steps_trained": 707400, "num_agent_steps_trained": 707319}, "done": false, "episodes_total": 13851, "training_iteration": 131, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-30", "timestamp": 1626861450, "time_this_iter_s": 7.105806112289429, "time_total_s": 950.9129908084869, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f8d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 950.9129908084869, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 21.945454545454545, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.416666666666668, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.104166666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-8.0, 13.0, 9.0, 1.0, 10.0, 10.0, 3.0, -8.0, 4.0, 14.0, -8.0, 5.0, 13.0, 12.0, -8.0, -2.0, 5.0, -5.0, 10.0, 5.0, 12.0, 8.0, -1.0, -4.0, 4.0, 14.0, -11.0, 8.0, 12.0, 8.0, -11.0, 6.0, 2.0, 0.0, 12.0, 1.0, 11.0, -4.0, -4.0, 12.0, -13.0, 14.0, 6.0, 8.0, 14.0, 7.0, -12.0, 6.0, 6.0, -5.0, 12.0, 2.0, 8.0, 14.0, -13.0, 6.0, 13.0, 14.0, 315.0, 12.0, 13.0, 8.0, -8.0, 2.0, 7.0, 7.0, 4.0, -3.0, 11.0, 14.0, -3.0, -7.0, 13.0, 14.0, -7.0, -5.0, 14.0, 7.0, -11.0, 5.0, -7.0, 6.0, 10.0, 6.0, 7.0, 7.0, 5.0, -4.0, 6.0, 14.0, -18.0, 13.0, 13.0, 12.0, -7.0, -3.0, 11.0, -8.0, 6.0, 6.0, 11.0, -10.0, 5.0, 9.0, 1.0, 13.0, 10.0, -9.0, 14.0, 7.0, -16.0, 10.0, 6.0, 4.0, 9.0, -4.0, 11.0, 5.0, -14.0, 13.0, 11.0, 10.0, 7.0, -13.0, 6.0, 5.0, -2.0, 6.0, 12.0, -8.0, 6.0, 5.0, 12.0, 11.0, -4.0, -4.0, -13.0, 8.0, 8.0, 12.0, 14.0, 6.0, -2.0, -3.0, 11.0, 321.0, 12.0, 10.0, 12.0, 10.0, -6.0, -1.0, -3.0, 13.0, 10.0, -5.0, 14.0, 6.0, -10.0, 5.0, 3.0, -5.0, 12.0, 5.0, 12.0, 9.0, 3.0, -9.0, -6.0, 14.0, 2.0, 5.0, -4.0, 6.0, 3.0, 10.0, 5.0, -6.0, 12.0, 4.0, 13.0, 3.0, 4.0, -5.0, -14.0, 14.0, 6.0, 9.0, 13.0, 8.0, -7.0, 1.0, 4.0, 0.0, 6.0, 5.0, 12.0, 11.0, -6.0, -2.0, 4.0, 14.0, -7.0, 4.0, 14.0, 10.0, -8.0, -1.0, 11.0, 321.0, 10.0, 12.0, 10.0, 7.0, -13.0, 11.0, 4.0, 14.0, -11.0, 8.0, 9.0, 4.0, -8.0, 10.0, 6.0, -7.0, 7.0, 9.0, 6.0, -1.0, 2.0, 8.0, 4.0, 14.0, 2.0, -5.0, -11.0, 6.0, 11.0, 9.0, 7.0, 0.0, 2.0, 6.0, 10.0, -9.0, 12.0, 2.0, -12.0, 14.0, 5.0, 8.0, 14.0, 6.0, -3.0, -2.0, 1.0, -7.0, 11.0, 10.0, 12.0, -5.0, 11.0, -3.0, 5.0, 13.0, -11.0, 8.0, 10.0, 8.0, -9.0, 6.0, 3.0, 0.0, 6.0, 6.0, 12.0, 8.0, -2.0, -3.0, -9.0, 8.0, 10.0, 6.0, -1.0, 6.0, 4.0, 6.0, 10.0, 6.0, -8.0, 7.0, 11.0, -1.0, -1.0, 6.0, 4.0, 14.0, -11.0, 8.0, 14.0, 6.0, -16.0, 11.0, 6.0, -8.0, 11.0, 6.0, 10.0, 11.0, 5.0, -11.0, 4.0, 14.0, -9.0, 6.0, 14.0, 8.0, -8.0, 1.0, -1.0, 11.0, -5.0, 10.0, 12.0, 10.0, -16.0, 9.0, 10.0, 9.0, -6.0, 2.0, -13.0, 12.0, 6.0, 10.0, 11.0, -11.0, 7.0, 8.0, 13.0, 11.0, -1.0, -8.0, 13.0, 12.0, -17.0, 7.0, -1.0, 8.0, 2.0, 6.0, 3.0, -1.0, 4.0, 9.0, 12.0, 7.0, 0.0, -4.0, 4.0, 14.0, -9.0, 6.0, 14.0, 8.0, -3.0, -4.0, 8.0, -12.0, 12.0, 7.0, 12.0, -1.0, -1.0, 5.0, -9.0, 14.0, 8.0, 2.0, 9.0, 8.0, -12.0, 10.0, 4.0, -7.0, 8.0, 10.0, 12.0, 8.0, -4.0, -1.0, -12.0, 8.0, 6.0, 13.0, 9.0, 7.0, -11.0, 10.0, -1.0, 11.0, 2.0, 3.0, 13.0, 9.0, -18.0, 11.0, 4.0, 14.0, -11.0, 8.0, 9.0, 7.0, -12.0, 11.0, 2.0, -5.0, 11.0, 7.0, 12.0, 4.0, 10.0, -11.0, 4.0, 14.0, -12.0, 9.0, 13.0, 8.0, -8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22049158549470887, "mean_inference_ms": 1.1741830106624933, "mean_action_processing_ms": 0.07179542236746397, "mean_env_wait_ms": 0.17929207825500604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 712800, "agent_timesteps_total": 712719, "timers": {"sample_time_ms": 354.11, "sample_throughput": 15249.48, "learn_time_ms": 6651.207, "learn_throughput": 811.883, "update_time_ms": 11.418}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 427.5666198730469, "policy_loss": -0.037639982998371124, "vf_loss": 427.5992126464844, "vf_explained_var": 0.21292400360107422, "kl": 0.010160407051444054, "entropy": 0.41995275020599365, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 712800, "num_agent_steps_sampled": 712719, "num_steps_trained": 712800, "num_agent_steps_trained": 712719}, "done": false, "episodes_total": 13959, "training_iteration": 132, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-37", "timestamp": 1626861457, "time_this_iter_s": 7.055374622344971, "time_total_s": 957.9683654308319, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f8ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 957.9683654308319, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 21.46, "ram_util_percent": 14.229999999999999}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 6.0, -2.0, 1.0, -10.0, 8.0, 8.0, 9.0, -2.0, 13.0, -9.0, 13.0, 5.0, 12.0, 5.0, -7.0, 9.0, -1.0, 10.0, -3.0, 12.0, -9.0, 1.0, 11.0, -11.0, 13.0, 2.0, 11.0, -3.0, 12.0, 12.0, -6.0, 6.0, 7.0, 7.0, -5.0, 9.0, -9.0, 10.0, 5.0, 1.0, 11.0, -4.0, 7.0, 11.0, 10.0, 7.0, -13.0, 10.0, 6.0, -6.0, 5.0, 9.0, -7.0, 3.0, 10.0, -11.0, 13.0, 10.0, 3.0, 12.0, 10.0, 7.0, -14.0, 11.0, 5.0, -14.0, 13.0, 9.0, -9.0, 11.0, 4.0, 0.0, 12.0, 6.0, -3.0, 13.0, 12.0, -1.0, -9.0, 6.0, -1.0, -3.0, 13.0, 11.0, -2.0, 2.0, 4.0, 13.0, 11.0, -5.0, -4.0, 12.0, 13.0, 1.0, -11.0, 12.0, 12.0, -17.0, 8.0, 11.0, -14.0, 10.0, 8.0, 5.0, 14.0, -7.0, 3.0, -7.0, 11.0, 3.0, 8.0, 11.0, -3.0, 9.0, -2.0, -8.0, 11.0, 1.0, 11.0, 4.0, 11.0, 5.0, -5.0, -3.0, 13.0, 4.0, 1.0, 9.0, 6.0, 3.0, -3.0, 8.0, -12.0, 8.0, 11.0, 2.0, 10.0, 4.0, -1.0, 13.0, 12.0, -13.0, 3.0, 10.0, 9.0, -17.0, 13.0, 11.0, -9.0, 4.0, 9.0, 6.0, 11.0, 1.0, -3.0, 4.0, 13.0, 6.0, -8.0, 10.0, 4.0, -10.0, 11.0, 6.0, -4.0, 2.0, 11.0, -12.0, 12.0, 12.0, 3.0, 3.0, 13.0, 9.0, -10.0, 11.0, 11.0, -18.0, 11.0, -6.0, 9.0, 3.0, 9.0, 5.0, 11.0, 2.0, -3.0, -3.0, 12.0, 2.0, 4.0, 12.0, 1.0, 5.0, -3.0, 13.0, -5.0, -2.0, 9.0, -10.0, 12.0, 12.0, 1.0, 6.0, 14.0, -13.0, 8.0, 13.0, 0.0, -1.0, 3.0, 8.0, -8.0, 3.0, 12.0, -8.0, 12.0, 10.0, 1.0, 10.0, 9.0, -6.0, 2.0, 12.0, -5.0, -1.0, 9.0, 3.0, 10.0, -10.0, 12.0, 1.0, 12.0, -10.0, 12.0, 6.0, 12.0, 0.0, -3.0, 11.0, 3.0, 2.0, -1.0, 5.0, -1.0, 3.0, 8.0, 0.0, 14.0, -6.0, 7.0, 7.0, 12.0, 0.0, -4.0, 11.0, 0.0, 8.0, -4.0, 5.0, -4.0, 2.0, 12.0, -13.0, 12.0, 4.0, 12.0, 5.0, 12.0, -12.0, 10.0, 11.0, 6.0, -7.0, 5.0, 10.0, -3.0, 4.0, 4.0, 8.0, 13.0, -18.0, 12.0, 10.0, 13.0, 3.0, -11.0, 12.0, 7.0, -14.0, 10.0, 9.0, -9.0, 10.0, 5.0, 4.0, 12.0, -13.0, 12.0, 7.0, 11.0, -7.0, 4.0, 4.0, 6.0, -6.0, 11.0, 10.0, -13.0, 10.0, 8.0, -13.0, 10.0, 12.0, 6.0, 10.0, 8.0, 0.0, -3.0, 10.0, 4.0, -11.0, 12.0, 7.0, 9.0, 9.0, -10.0, 9.0, 12.0, -18.0, 12.0, -10.0, 12.0, 8.0, 5.0, 9.0, 13.0, 8.0, -15.0, -2.0, 7.0, 6.0, 4.0, 8.0, 11.0, -15.0, 11.0, 8.0, 13.0, -9.0, 3.0, 13.0, 0.0, -2.0, 4.0, -9.0, 12.0, 4.0, 8.0, 5.0, 12.0, 3.0, -5.0, 11.0, 11.0, -4.0, -3.0, 2.0, 11.0, -11.0, 13.0, 8.0, -2.0, 1.0, 8.0, 1.0, 14.0, -4.0, 4.0, 10.0, 12.0, -16.0, 9.0, 8.0, 6.0, -12.0, 13.0, 5.0, -4.0, 11.0, 3.0, 6.0, 11.0, 0.0, -2.0, 8.0, 13.0, 6.0, -12.0, 10.0, -5.0, -2.0, 12.0, 2.0, 8.0, 13.0, -8.0, 8.0, 13.0, -2.0, -4.0, 6.0, 10.0, 4.0, -5.0, 12.0, -2.0, -7.0, 12.0, 7.0, 11.0, -14.0, 11.0, -6.0, 14.0, 8.0, -1.0, 7.0, 11.0, 3.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2205199476113476, "mean_inference_ms": 1.1741573174981075, "mean_action_processing_ms": 0.07179740052761191, "mean_env_wait_ms": 0.17931135696966832, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 718200, "agent_timesteps_total": 718119, "timers": {"sample_time_ms": 353.902, "sample_throughput": 15258.471, "learn_time_ms": 6646.677, "learn_throughput": 812.436, "update_time_ms": 11.665}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 23.405773162841797, "policy_loss": -0.07269473373889923, "vf_loss": 23.469318389892578, "vf_explained_var": 0.29613277316093445, "kl": 0.018071582540869713, "entropy": 0.43969860672950745, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 718200, "num_agent_steps_sampled": 718119, "num_steps_trained": 718200, "num_agent_steps_trained": 718119}, "done": false, "episodes_total": 14067, "training_iteration": 133, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-44", "timestamp": 1626861464, "time_this_iter_s": 7.010196924209595, "time_total_s": 964.9785623550415, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 964.9785623550415, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 22.43, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 9.0, 12.0, 4.0, 10.0, -5.0, 2.0, 8.0, -2.0, 5.0, 7.0, 5.0, 9.0, 3.0, 8.0, -5.0, -4.0, -4.0, 10.0, 13.0, -7.0, 13.0, 8.0, 1.0, 3.0, 7.0, -7.0, 12.0, 8.0, -15.0, 11.0, 11.0, 4.0, -2.0, 12.0, 1.0, -6.0, -2.0, 13.0, 10.0, 6.0, 11.0, -10.0, 8.0, 3.0, -8.0, 10.0, 10.0, 2.0, -5.0, 13.0, 5.0, 11.0, -2.0, -4.0, 10.0, 6.0, 9.0, 6.0, -6.0, 14.0, -18.0, 7.0, 12.0, 1.0, -10.0, 11.0, 13.0, -4.0, -1.0, 12.0, 8.0, -7.0, 4.0, 12.0, 6.0, 14.0, -5.0, 9.0, -3.0, -1.0, 6.0, 13.0, -3.0, -17.0, 14.0, 5.0, 13.0, 0.0, 13.0, -10.0, 12.0, 13.0, -14.0, 10.0, 6.0, 6.0, -7.0, 12.0, 4.0, -13.0, 13.0, 4.0, 11.0, 6.0, 5.0, -3.0, 7.0, 3.0, 3.0, -1.0, 10.0, 2.0, 10.0, 12.0, -9.0, -5.0, 5.0, 6.0, 9.0, -2.0, 14.0, -5.0, 8.0, 4.0, -8.0, 11.0, 8.0, 6.0, -10.0, 6.0, 13.0, 6.0, -8.0, 5.0, 12.0, 2.0, 11.0, -6.0, 8.0, 14.0, -18.0, 13.0, 6.0, 6.0, -11.0, 7.0, 13.0, 10.0, -16.0, 11.0, 10.0, -3.0, 6.0, 5.0, 7.0, 4.0, 2.0, 10.0, -1.0, 4.0, -5.0, 13.0, 3.0, -13.0, 14.0, 9.0, 5.0, -9.0, 4.0, 8.0, 12.0, 14.0, -18.0, 11.0, 8.0, 12.0, -15.0, 5.0, 13.0, -1.0, 2.0, 8.0, 6.0, -14.0, 10.0, 12.0, 7.0, 2.0, -9.0, 9.0, 13.0, 1.0, -1.0, 2.0, 13.0, 7.0, -6.0, 13.0, 1.0, 6.0, 9.0, -12.0, 12.0, 10.0, -2.0, -5.0, 12.0, 12.0, -15.0, 5.0, 13.0, -9.0, 9.0, 3.0, 12.0, -19.0, 14.0, 12.0, 8.0, 5.0, -13.0, 13.0, 10.0, 4.0, -13.0, 12.0, 12.0, -6.0, 3.0, 13.0, 5.0, 5.0, 6.0, -4.0, 8.0, 11.0, 2.0, 13.0, -11.0, 4.0, 3.0, 9.0, -1.0, -5.0, 8.0, 8.0, 4.0, 6.0, 12.0, -5.0, 2.0, 6.0, 2.0, 11.0, -4.0, 1.0, -4.0, 12.0, 6.0, 6.0, 3.0, 11.0, -5.0, 5.0, 7.0, -5.0, 8.0, 9.0, -14.0, 9.0, 11.0, -2.0, -3.0, 13.0, 7.0, -3.0, 2.0, 8.0, 8.0, 5.0, 10.0, -12.0, 12.0, 13.0, -19.0, 10.0, 11.0, 11.0, 2.0, -8.0, 10.0, -13.0, 13.0, 11.0, 4.0, 4.0, 4.0, -5.0, 12.0, 9.0, 0.0, 8.0, -2.0, -2.0, -7.0, 11.0, 13.0, -12.0, 8.0, 7.0, 12.0, -15.0, 13.0, 9.0, 8.0, 4.0, 4.0, 13.0, -6.0, 5.0, -9.0, 13.0, 6.0, -9.0, 8.0, 12.0, 4.0, 9.0, 10.0, -11.0, 7.0, 2.0, -10.0, 12.0, 11.0, 6.0, 5.0, -5.0, 9.0, -1.0, 3.0, 6.0, 7.0, 10.0, 12.0, -15.0, 8.0, 9.0, -6.0, 11.0, 1.0, 4.0, 10.0, 12.0, -11.0, -5.0, 9.0, 7.0, 4.0, -14.0, 11.0, 10.0, 8.0, 14.0, -12.0, 6.0, 7.0, 5.0, -8.0, 8.0, 10.0, 10.0, -14.0, 8.0, 11.0, 7.0, 5.0, -6.0, 9.0, 9.0, -6.0, 7.0, 5.0, 0.0, -3.0, 13.0, 5.0, -4.0, 9.0, 8.0, 2.0, 1.0, 11.0, -3.0, 6.0, 5.0, 5.0, 8.0, -3.0, 4.0, -8.0, 13.0, 6.0, -9.0, 8.0, 13.0, 3.0, 3.0, 9.0, -5.0, 8.0, 13.0, -5.0, 13.0, -6.0, 5.0, 5.0, 10.0, -5.0, 10.0, -9.0, 10.0, 4.0, 4.0, 11.0, -12.0, 12.0, 4.0, -10.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2205027648590842, "mean_inference_ms": 1.1740674948508707, "mean_action_processing_ms": 0.07178567421396986, "mean_env_wait_ms": 0.1793032112245623, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 723600, "agent_timesteps_total": 723519, "timers": {"sample_time_ms": 353.216, "sample_throughput": 15288.084, "learn_time_ms": 6642.217, "learn_throughput": 812.982, "update_time_ms": 11.724}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 21.6354923248291, "policy_loss": -0.08503744006156921, "vf_loss": 21.71108627319336, "vf_explained_var": 0.3372783362865448, "kl": 0.01865137740969658, "entropy": 0.4547748565673828, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 723600, "num_agent_steps_sampled": 723519, "num_steps_trained": 723600, "num_agent_steps_trained": 723519}, "done": false, "episodes_total": 14175, "training_iteration": 134, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-52", "timestamp": 1626861472, "time_this_iter_s": 7.11102294921875, "time_total_s": 972.0895853042603, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 972.0895853042603, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 22.490000000000002, "ram_util_percent": 14.219999999999999}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, -3.0, 8.0, 9.0, 10.0, -12.0, 12.0, 5.0, 5.0, 10.0, -6.0, 6.0, 8.0, -6.0, 10.0, 3.0, 13.0, -1.0, -6.0, 9.0, -9.0, 9.0, 4.0, 11.0, 0.0, 6.0, -3.0, 12.0, -2.0, 3.0, 1.0, 13.0, 2.0, 13.0, -10.0, 10.0, 9.0, 3.0, -3.0, 6.0, -1.0, 12.0, -7.0, 11.0, 10.0, -13.0, 12.0, 6.0, -17.0, 13.0, 12.0, 7.0, 11.0, 9.0, -16.0, 11.0, 4.0, 7.0, -8.0, 12.0, 5.0, -10.0, 11.0, 9.0, -17.0, 14.0, 12.0, 6.0, 12.0, 6.0, 1.0, -4.0, 12.0, 4.0, -13.0, 12.0, 9.0, -4.0, 0.0, 10.0, 0.0, 11.0, 8.0, -4.0, 12.0, 2.0, 4.0, -3.0, 8.0, -11.0, 8.0, 10.0, 6.0, -13.0, 10.0, 12.0, 3.0, 5.0, -4.0, 11.0, 12.0, -1.0, -3.0, 7.0, 1.0, 6.0, -2.0, 10.0, 8.0, -11.0, 7.0, 11.0, 11.0, -15.0, 12.0, 7.0, 6.0, 9.0, -9.0, 9.0, 4.0, 3.0, -2.0, 10.0, -7.0, 9.0, 4.0, 9.0, -4.0, 13.0, -4.0, 10.0, -2.0, 12.0, -6.0, 11.0, 3.0, 8.0, 7.0, -3.0, 8.0, -10.0, 7.0, 10.0, 8.0, 4.0, 7.0, -4.0, 10.0, -9.0, 3.0, 11.0, 9.0, -9.0, 3.0, 12.0, 12.0, -6.0, 1.0, 8.0, 0.0, -2.0, 12.0, 5.0, 13.0, 4.0, -11.0, 9.0, 11.0, -2.0, -6.0, 12.0, 4.0, -13.0, 13.0, 11.0, 1.0, 9.0, -6.0, 11.0, 14.0, -10.0, 1.0, 10.0, 8.0, -10.0, 13.0, 4.0, 6.0, 0.0, -2.0, 11.0, 5.0, 7.0, -2.0, 5.0, 11.0, 6.0, 9.0, -11.0, 9.0, 8.0, -12.0, 10.0, -1.0, 7.0, 11.0, -2.0, 4.0, 12.0, -3.0, 2.0, 0.0, 8.0, -2.0, 9.0, 4.0, 14.0, -8.0, 5.0, 12.0, -11.0, 8.0, 6.0, 9.0, -17.0, 12.0, 11.0, 11.0, -13.0, 7.0, 10.0, 14.0, 11.0, -12.0, 2.0, 13.0, -8.0, 3.0, 7.0, 11.0, -1.0, -2.0, 7.0, 8.0, 4.0, -3.0, 6.0, 10.0, -14.0, 12.0, 7.0, 4.0, -14.0, 12.0, 13.0, 12.0, -7.0, -2.0, 12.0, 12.0, -8.0, 2.0, 9.0, 10.0, 6.0, -7.0, 6.0, 13.0, -8.0, 4.0, 6.0, 4.0, 11.0, -2.0, 2.0, 13.0, 2.0, -11.0, 11.0, 11.0, 1.0, -9.0, 12.0, 13.0, -2.0, 10.0, -6.0, 9.0, 9.0, -12.0, 9.0, 12.0, 3.0, -12.0, 12.0, 12.0, -7.0, 1.0, 9.0, -8.0, 11.0, 11.0, 1.0, -5.0, -3.0, 12.0, 11.0, 14.0, 9.0, -16.0, 8.0, 5.0, 13.0, -10.0, 7.0, 13.0, 1.0, 5.0, -4.0, 12.0, -2.0, -6.0, 11.0, 13.0, -5.0, 1.0, 6.0, 12.0, -5.0, -3.0, 11.0, 8.0, -2.0, -4.0, 13.0, 9.0, 11.0, -6.0, 1.0, 12.0, -7.0, 7.0, 3.0, 8.0, 3.0, 5.0, -1.0, 9.0, -12.0, 6.0, 12.0, 7.0, -1.0, 0.0, 9.0, 11.0, 5.0, -11.0, 10.0, 6.0, -1.0, -1.0, 11.0, 5.0, -8.0, 8.0, 10.0, -3.0, 12.0, -6.0, 12.0, 13.0, 3.0, -9.0, 8.0, 7.0, 13.0, -9.0, 4.0, 3.0, -10.0, 11.0, 11.0, -2.0, 14.0, -2.0, 5.0, 11.0, 3.0, -10.0, 11.0, 9.0, -3.0, -2.0, 11.0, 12.0, -6.0, -2.0, 11.0, 9.0, -10.0, 7.0, 9.0, 13.0, 6.0, -17.0, 13.0, 4.0, 6.0, -2.0, 7.0, 9.0, -12.0, 7.0, 11.0, 7.0, -16.0, 12.0, 12.0, 10.0, 2.0, 11.0, -8.0, 6.0, 9.0, 6.0, -6.0, 8.0, -6.0, 7.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2205338384483937, "mean_inference_ms": 1.1741775821564462, "mean_action_processing_ms": 0.07180113681011112, "mean_env_wait_ms": 0.1793231925939605, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 729000, "agent_timesteps_total": 728919, "timers": {"sample_time_ms": 352.995, "sample_throughput": 15297.658, "learn_time_ms": 6641.999, "learn_throughput": 813.008, "update_time_ms": 11.782}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 22.263824462890625, "policy_loss": -0.07616987824440002, "vf_loss": 22.331829071044922, "vf_explained_var": 0.3115335702896118, "kl": 0.016130657866597176, "entropy": 0.44215530157089233, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 729000, "num_agent_steps_sampled": 728919, "num_steps_trained": 729000, "num_agent_steps_trained": 728919}, "done": false, "episodes_total": 14283, "training_iteration": 135, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-57-59", "timestamp": 1626861479, "time_this_iter_s": 7.091089487075806, "time_total_s": 979.1806747913361, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 979.1806747913361, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 21.919999999999998, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -19.0, 13.0, 11.0, 7.0, 11.0, 11.0, -14.0, -6.0, 5.0, 12.0, 4.0, 8.0, -3.0, 7.0, 3.0, -5.0, 1.0, 13.0, 6.0, 1.0, 3.0, -1.0, 12.0, -8.0, 8.0, 2.0, 13.0, 6.0, -10.0, 12.0, 7.0, 12.0, -16.0, 12.0, 7.0, -16.0, 9.0, 12.0, 10.0, 3.0, 8.0, 5.0, -1.0, -9.0, 3.0, 13.0, 8.0, 10.0, 2.0, -9.0, 12.0, 1.0, 9.0, 6.0, -1.0, 7.0, -11.0, 7.0, 12.0, 6.0, -8.0, 5.0, 12.0, 13.0, 0.0, -7.0, 9.0, 3.0, 9.0, 13.0, -10.0, -7.0, 10.0, 7.0, 5.0, -7.0, -3.0, 13.0, 12.0, -4.0, 7.0, 2.0, 10.0, 10.0, 9.0, -1.0, -3.0, -10.0, 12.0, 11.0, 2.0, 2.0, -6.0, 7.0, 12.0, 8.0, -16.0, 12.0, 11.0, -10.0, 6.0, 8.0, 11.0, -11.0, 2.0, 11.0, 13.0, -9.0, 10.0, 6.0, 8.0, 3.0, -2.0, 7.0, 7.0, 9.0, 5.0, 3.0, -2.0, -8.0, 2.0, 8.0, 13.0, 5.0, 7.0, -6.0, 9.0, 12.0, 3.0, 2.0, -2.0, -11.0, 9.0, 10.0, 7.0, -16.0, 12.0, 6.0, 13.0, -7.0, 0.0, 12.0, 10.0, 13.0, 5.0, -6.0, 3.0, -4.0, 10.0, 12.0, -3.0, -18.0, 8.0, 12.0, 13.0, 4.0, 6.0, -1.0, 6.0, 11.0, -2.0, -1.0, 7.0, -2.0, 10.0, 12.0, -5.0, -9.0, 7.0, 12.0, 5.0, 6.0, -7.0, 3.0, 13.0, 8.0, 3.0, 9.0, -5.0, 1.0, 12.0, -1.0, 3.0, -6.0, 6.0, 2.0, 13.0, -4.0, 1.0, 12.0, 6.0, 9.0, -3.0, -1.0, 10.0, -16.0, 8.0, 12.0, 11.0, -1.0, 1.0, 7.0, 8.0, -11.0, 7.0, 7.0, 12.0, 4.0, 11.0, 3.0, -3.0, 3.0, -11.0, 11.0, 12.0, -13.0, 9.0, 7.0, 12.0, 5.0, -10.0, 12.0, 8.0, 7.0, -8.0, 5.0, 11.0, -3.0, 14.0, 6.0, -2.0, -9.0, -1.0, 12.0, 13.0, -6.0, 7.0, 2.0, 12.0, 8.0, 2.0, -1.0, 6.0, -6.0, 1.0, 10.0, 10.0, 11.0, -6.0, -1.0, 11.0, -9.0, 5.0, 7.0, 12.0, 1.0, 6.0, -2.0, 10.0, -6.0, 8.0, 12.0, 1.0, -15.0, 10.0, 7.0, 13.0, 10.0, 2.0, -9.0, 12.0, -18.0, 10.0, 13.0, 10.0, 3.0, -9.0, 10.0, 11.0, -5.0, 10.0, 3.0, 7.0, 10.0, -14.0, 6.0, 13.0, -2.0, 11.0, -5.0, 11.0, 3.0, 6.0, 7.0, -1.0, -8.0, 10.0, 0.0, 13.0, 7.0, 3.0, -2.0, 7.0, 2.0, 3.0, -1.0, 11.0, -5.0, 3.0, 11.0, 6.0, -17.0, 12.0, 12.0, 8.0, -8.0, 3.0, 8.0, 12.0, 11.0, 6.0, 12.0, -14.0, -3.0, 8.0, -3.0, 13.0, -3.0, -3.0, 11.0, 10.0, -10.0, 5.0, 8.0, 12.0, 5.0, 8.0, -9.0, 11.0, 7.0, 14.0, 4.0, -10.0, -14.0, 13.0, 11.0, 5.0, 4.0, -8.0, 12.0, 7.0, 8.0, 7.0, -13.0, 13.0, -2.0, 8.0, 12.0, -3.0, -8.0, 4.0, 6.0, 13.0, 5.0, -8.0, 5.0, 13.0, 11.0, -20.0, 12.0, 12.0, -2.0, 8.0, -1.0, 10.0, -7.0, -1.0, 11.0, 12.0, 3.0, -7.0, 7.0, 12.0, 8.0, 4.0, -2.0, 5.0, -6.0, 7.0, 4.0, 10.0, 318.0, 11.0, 12.0, 13.0, -4.0, 2.0, 10.0, 7.0, 8.0, -2.0, -2.0, 11.0, -4.0, 10.0, 13.0, -4.0, 11.0, -15.0, 6.0, 13.0, 6.0, -6.0, 3.0, 12.0, 10.0, -3.0, -3.0, 11.0, -10.0, 1.0, 12.0, 12.0, -10.0, 7.0, 5.0, 13.0, -4.0, -1.0, 13.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22054018884049978, "mean_inference_ms": 1.1743059024927374, "mean_action_processing_ms": 0.0718015493218191, "mean_env_wait_ms": 0.17932692965690603, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 734400, "agent_timesteps_total": 734319, "timers": {"sample_time_ms": 352.894, "sample_throughput": 15302.067, "learn_time_ms": 6633.838, "learn_throughput": 814.008, "update_time_ms": 12.109}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 230.59243774414062, "policy_loss": -0.025963397696614265, "vf_loss": 230.61480712890625, "vf_explained_var": 0.25072652101516724, "kl": 0.007122635375708342, "entropy": 0.45427659153938293, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 734400, "num_agent_steps_sampled": 734319, "num_steps_trained": 734400, "num_agent_steps_trained": 734319}, "done": false, "episodes_total": 14391, "training_iteration": 136, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-58-06", "timestamp": 1626861486, "time_this_iter_s": 7.206234693527222, "time_total_s": 986.3869094848633, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70214c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 986.3869094848633, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 21.530000000000005, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, -7.0, 9.0, 7.0, 14.0, -7.0, -1.0, 9.0, 8.0, -4.0, 3.0, 8.0, -4.0, -4.0, 10.0, 13.0, 10.0, 0.0, 9.0, -4.0, 14.0, 11.0, -1.0, -9.0, 13.0, 0.0, 8.0, -6.0, 7.0, 11.0, 3.0, -6.0, 8.0, 14.0, -4.0, -3.0, 14.0, -8.0, -2.0, 11.0, 12.0, 0.0, -2.0, 5.0, 2.0, 9.0, 7.0, -3.0, 2.0, 14.0, 10.0, -11.0, 14.0, -4.0, 3.0, 2.0, 13.0, 0.0, 8.0, -6.0, -2.0, 0.0, 5.0, 12.0, 12.0, 13.0, 6.0, -16.0, 4.0, -1.0, 1.0, 11.0, 7.0, -9.0, 4.0, 13.0, 1.0, 12.0, 5.0, -3.0, 5.0, 14.0, -7.0, 3.0, 13.0, -3.0, -4.0, 9.0, 10.0, -1.0, 12.0, -6.0, 3.0, -4.0, 8.0, 8.0, 7.0, 0.0, 7.0, 1.0, 8.0, -8.0, 4.0, 11.0, 13.0, -1.0, 10.0, -7.0, 6.0, 12.0, -12.0, 9.0, 7.0, 13.0, -4.0, -1.0, 14.0, -3.0, -5.0, 9.0, 13.0, 0.0, 9.0, -7.0, -1.0, -3.0, 6.0, 13.0, 9.0, -6.0, 6.0, 6.0, 2.0, -1.0, 4.0, 10.0, 13.0, 14.0, -4.0, -8.0, 7.0, 11.0, -7.0, 4.0, 8.0, 10.0, -13.0, 10.0, 14.0, 11.0, 2.0, -12.0, 13.0, 5.0, -8.0, 5.0, 5.0, -3.0, 1.0, 12.0, 1.0, 0.0, 9.0, 5.0, 9.0, -5.0, 0.0, 11.0, 12.0, -2.0, 5.0, 0.0, -1.0, -1.0, 5.0, 12.0, 2.0, -4.0, 10.0, 7.0, 5.0, 14.0, 2.0, -6.0, 12.0, 14.0, -4.0, -7.0, 4.0, -10.0, 9.0, 12.0, 10.0, -1.0, 11.0, -5.0, 1.0, -1.0, 7.0, 8.0, 11.0, -2.0, 3.0, 3.0, 12.0, 10.0, -9.0, 2.0, 3.0, 0.0, 10.0, 2.0, 9.0, 4.0, 6.0, -4.0, 13.0, 14.0, -19.0, 7.0, 1.0, 11.0, 6.0, -3.0, 4.0, 0.0, 6.0, 5.0, 9.0, -2.0, 6.0, 2.0, 11.0, 14.0, -6.0, -4.0, 10.0, 10.0, 8.0, -13.0, 4.0, 14.0, -8.0, 5.0, 9.0, 9.0, 0.0, -3.0, 11.0, 0.0, -1.0, 5.0, -2.0, 8.0, -3.0, 12.0, 6.0, 14.0, -10.0, 5.0, 9.0, -4.0, 8.0, 2.0, 11.0, -2.0, 0.0, 6.0, 0.0, 11.0, -7.0, 11.0, 4.0, 12.0, 7.0, -8.0, 13.0, -7.0, 11.0, -2.0, 12.0, 0.0, 10.0, -7.0, 10.0, -7.0, 2.0, 10.0, 12.0, -6.0, 10.0, -1.0, 1.0, 0.0, 4.0, 10.0, 2.0, 6.0, -6.0, 13.0, -14.0, 6.0, 10.0, 13.0, 2.0, 0.0, 11.0, 2.0, 14.0, -6.0, -3.0, 10.0, 7.0, 10.0, -10.0, 8.0, 7.0, 5.0, -2.0, 5.0, -1.0, -1.0, 6.0, 11.0, 4.0, -3.0, 4.0, 10.0, 12.0, -1.0, 10.0, -6.0, 3.0, -6.0, 10.0, 8.0, -14.0, 10.0, 7.0, 12.0, 0.0, 13.0, 7.0, -5.0, 11.0, 14.0, -4.0, -6.0, 7.0, 12.0, -6.0, 2.0, 6.0, -4.0, 3.0, 10.0, 14.0, 4.0, 0.0, -3.0, 9.0, 14.0, -3.0, -5.0, 6.0, 11.0, 0.0, -2.0, 11.0, 14.0, 9.0, -19.0, 14.0, -6.0, 3.0, 4.0, 12.0, -6.0, 6.0, 3.0, 12.0, -3.0, 5.0, 1.0, 11.0, 13.0, 11.0, 320.0, 4.0, 0.0, 0.0, 11.0, 10.0, 14.0, -4.0, -5.0, 0.0, 11.0, 11.0, -7.0, 12.0, -3.0, 11.0, -5.0, 13.0, -5.0, 6.0, 1.0, 11.0, 12.0, -4.0, -4.0, -14.0, 13.0, 6.0, 10.0, 3.0, 12.0, -7.0, 7.0, 9.0, -3.0, 7.0, 2.0, 10.0, 0.0, 11.0, -6.0, -18.0, 12.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22057855613135366, "mean_inference_ms": 1.174335869661194, "mean_action_processing_ms": 0.07180935367212636, "mean_env_wait_ms": 0.17935217540186113, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 739800, "agent_timesteps_total": 739719, "timers": {"sample_time_ms": 353.268, "sample_throughput": 15285.864, "learn_time_ms": 6632.129, "learn_throughput": 814.218, "update_time_ms": 12.302}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 174.83462524414062, "policy_loss": -0.02700931765139103, "vf_loss": 174.85708618164062, "vf_explained_var": 0.18562756478786469, "kl": 0.009023323655128479, "entropy": 0.45252951979637146, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 739800, "num_agent_steps_sampled": 739719, "num_steps_trained": 739800, "num_agent_steps_trained": 739719}, "done": false, "episodes_total": 14499, "training_iteration": 137, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-58-13", "timestamp": 1626861493, "time_this_iter_s": 7.105465888977051, "time_total_s": 993.4923753738403, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70214d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 993.4923753738403, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 22.20909090909091, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.34259259259259, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.335648148148148}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 13.0, -7.0, 10.0, -8.0, 11.0, 6.0, 6.0, 10.0, 8.0, 7.0, -10.0, 12.0, 12.0, 7.0, -16.0, 3.0, 0.0, 6.0, 6.0, -9.0, 11.0, 5.0, 8.0, 6.0, 0.0, 11.0, -2.0, 6.0, -2.0, 11.0, 0.0, 1.0, 11.0, 10.0, -7.0, 8.0, -6.0, 2.0, 11.0, 13.0, 6.0, 7.0, -11.0, 5.0, -1.0, 11.0, 0.0, -6.0, 9.0, 10.0, 2.0, -1.0, 11.0, -7.0, 12.0, 11.0, 9.0, 3.0, -8.0, 11.0, -1.0, 9.0, -4.0, -9.0, 13.0, 6.0, 5.0, 4.0, 14.0, -13.0, 10.0, 6.0, 3.0, 8.0, -2.0, 13.0, -2.0, 10.0, -6.0, -9.0, 12.0, 9.0, 3.0, -6.0, 8.0, 1.0, 12.0, 13.0, 3.0, -6.0, 6.0, 11.0, 12.0, 10.0, -18.0, -19.0, 12.0, 10.0, 12.0, 7.0, 8.0, -13.0, 13.0, 10.0, 6.0, -7.0, 7.0, 12.0, -2.0, -6.0, 11.0, -15.0, 13.0, 6.0, 11.0, 11.0, 6.0, -12.0, 10.0, 11.0, 7.0, 7.0, -10.0, 12.0, -1.0, 10.0, -6.0, 2.0, 13.0, -7.0, 7.0, -7.0, 9.0, 2.0, 11.0, 9.0, 6.0, 3.0, -3.0, 9.0, -2.0, 11.0, -3.0, -14.0, 12.0, 5.0, 12.0, 4.0, 14.0, 5.0, -8.0, 10.0, 8.0, 12.0, -15.0, 11.0, -1.0, 2.0, 3.0, -11.0, 12.0, 5.0, 9.0, -11.0, 9.0, 6.0, 11.0, 3.0, 5.0, 12.0, -5.0, 10.0, -1.0, 11.0, -5.0, -1.0, 11.0, 11.0, -6.0, 7.0, -10.0, 5.0, 13.0, 10.0, 6.0, 1.0, -2.0, 12.0, -1.0, 10.0, -6.0, 1.0, 0.0, 2.0, 12.0, 3.0, 14.0, -9.0, 7.0, 8.0, -13.0, 11.0, 10.0, 12.0, -2.0, 11.0, -6.0, -14.0, 13.0, 8.0, 8.0, -8.0, 14.0, 5.0, 4.0, 13.0, 4.0, -8.0, 7.0, 12.0, 11.0, 11.0, 321.0, -9.0, 9.0, 13.0, 2.0, 8.0, 14.0, 7.0, -14.0, 10.0, 5.0, 5.0, -5.0, 12.0, -7.0, 12.0, -2.0, -12.0, 4.0, 10.0, 13.0, -6.0, 5.0, 4.0, 12.0, 14.0, 6.0, 6.0, -10.0, 6.0, 11.0, 12.0, -14.0, 1.0, 8.0, -5.0, 11.0, 6.0, -7.0, 10.0, 6.0, 11.0, 9.0, 4.0, -9.0, 12.0, -2.0, 11.0, -6.0, -15.0, 8.0, 11.0, 11.0, 4.0, 11.0, 12.0, -12.0, 4.0, 2.0, 13.0, -4.0, 10.0, -1.0, 10.0, -4.0, 2.0, 13.0, 8.0, -8.0, -10.0, 14.0, 12.0, -1.0, 11.0, 8.0, 6.0, -10.0, 11.0, -3.0, 9.0, -2.0, -10.0, 13.0, 5.0, 7.0, -8.0, 9.0, 9.0, 5.0, 11.0, 9.0, -1.0, -4.0, 9.0, -2.0, 7.0, 1.0, -11.0, 8.0, 6.0, 12.0, -11.0, 14.0, 6.0, 6.0, 11.0, 8.0, 5.0, -9.0, 6.0, -2.0, 12.0, -1.0, -16.0, 13.0, 6.0, 12.0, -3.0, 4.0, 12.0, 2.0, -4.0, 10.0, -2.0, 11.0, 7.0, -2.0, 10.0, 0.0, -2.0, 0.0, 11.0, 6.0, 8.0, 9.0, 10.0, -12.0, -1.0, 5.0, 13.0, -2.0, 11.0, -7.0, 10.0, 1.0, 1.0, 14.0, -9.0, 9.0, -10.0, 14.0, 5.0, 6.0, 4.0, 5.0, 10.0, -4.0, 11.0, 11.0, 12.0, 321.0, -13.0, 11.0, 10.0, 7.0, -7.0, 14.0, 9.0, -1.0, 12.0, 7.0, -6.0, 2.0, 5.0, -1.0, 6.0, 5.0, 5.0, 11.0, -9.0, 8.0, 7.0, 9.0, 12.0, -13.0, 4.0, 6.0, 8.0, -3.0, 12.0, -1.0, 10.0, -6.0, 1.0, 8.0, -2.0, 8.0, -6.0, 13.0, 1.0, 7.0, -4.0, 6.0, 3.0, 10.0, 8.0, -7.0, 12.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22058467506082813, "mean_inference_ms": 1.1745126433920514, "mean_action_processing_ms": 0.07181288778262727, "mean_env_wait_ms": 0.17933346132454578, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 745200, "agent_timesteps_total": 745119, "timers": {"sample_time_ms": 353.214, "sample_throughput": 15288.201, "learn_time_ms": 6639.242, "learn_throughput": 813.346, "update_time_ms": 12.355}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 411.7215576171875, "policy_loss": -0.021993115544319153, "vf_loss": 411.7401123046875, "vf_explained_var": 0.20653897523880005, "kl": 0.006880537606775761, "entropy": 0.4259008467197418, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 745200, "num_agent_steps_sampled": 745119, "num_steps_trained": 745200, "num_agent_steps_trained": 745119}, "done": false, "episodes_total": 14607, "training_iteration": 138, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-58-20", "timestamp": 1626861500, "time_this_iter_s": 7.154477119445801, "time_total_s": 1000.6468524932861, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70214ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1000.6468524932861, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 20.77, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-14.0, 9.0, 10.0, 10.0, 4.0, 5.0, 10.0, -4.0, 8.0, 14.0, -15.0, 8.0, 0.0, 14.0, 0.0, 1.0, 7.0, 8.0, -3.0, 3.0, 7.0, -5.0, 7.0, 6.0, -6.0, 11.0, 10.0, 0.0, 13.0, 14.0, -2.0, -10.0, 0.0, 11.0, -8.0, 12.0, 13.0, -13.0, 8.0, 7.0, -8.0, 14.0, 5.0, 4.0, 13.0, 10.0, -16.0, 8.0, -10.0, 13.0, 5.0, 7.0, 13.0, -18.0, 8.0, 12.0, 12.0, 14.0, 8.0, -19.0, 13.0, 7.0, 6.0, -11.0, 0.0, 9.0, -6.0, 12.0, 7.0, -6.0, 10.0, 4.0, -15.0, 14.0, 7.0, 9.0, 0.0, 10.0, 13.0, -8.0, 0.0, 13.0, -7.0, 9.0, 13.0, 6.0, -14.0, 10.0, 10.0, 14.0, -19.0, 10.0, 14.0, 12.0, -19.0, 8.0, -18.0, 13.0, 9.0, 11.0, 13.0, 11.0, -19.0, 10.0, -7.0, 8.0, 6.0, 8.0, -7.0, 13.0, 7.0, 2.0, -13.0, 12.0, 11.0, 5.0, 13.0, -16.0, 7.0, 11.0, 6.0, 10.0, 0.0, -1.0, -5.0, 12.0, 0.0, 8.0, 13.0, 12.0, -6.0, -4.0, 13.0, -14.0, 4.0, 12.0, -9.0, 3.0, 11.0, 10.0, -4.0, 14.0, 1.0, 4.0, -14.0, 12.0, 11.0, 6.0, 5.0, -11.0, 11.0, 10.0, -12.0, 11.0, 8.0, 8.0, 10.0, 12.0, -16.0, 9.0, 0.0, 11.0, -9.0, 13.0, -2.0, 11.0, 2.0, 4.0, 7.0, 14.0, -14.0, 8.0, 11.0, 13.0, -18.0, 9.0, 8.0, 13.0, -14.0, 8.0, 8.0, -5.0, 2.0, 10.0, -3.0, 14.0, 4.0, 0.0, 12.0, 10.0, -6.0, -1.0, -1.0, 11.0, 13.0, -8.0, 8.0, -16.0, 11.0, 12.0, -9.0, 9.0, 2.0, 13.0, -1.0, 9.0, 4.0, 3.0, -7.0, 13.0, 1.0, 8.0, 12.0, -10.0, 6.0, 7.0, -9.0, 14.0, 0.0, 10.0, 14.0, 10.0, -18.0, 9.0, 0.0, 12.0, -7.0, 10.0, 13.0, 10.0, -19.0, 11.0, -7.0, 6.0, 9.0, 7.0, 8.0, 12.0, 4.0, -9.0, -5.0, 12.0, -2.0, 10.0, 8.0, 5.0, -2.0, 4.0, 10.0, 14.0, -8.0, -1.0, 10.0, 13.0, 3.0, -11.0, 0.0, 12.0, -6.0, 9.0, 12.0, -14.0, 11.0, 6.0, -2.0, 3.0, 6.0, 8.0, 14.0, 12.0, -18.0, 7.0, -11.0, 11.0, 3.0, 12.0, 13.0, 11.0, 3.0, -12.0, 9.0, 13.0, -16.0, 9.0, -4.0, 9.0, 6.0, 4.0, 2.0, 11.0, -1.0, 3.0, 13.0, 6.0, -14.0, 10.0, -2.0, 13.0, -1.0, 5.0, 14.0, 13.0, -13.0, 1.0, -13.0, 12.0, 12.0, 4.0, 13.0, -14.0, 9.0, 7.0, 13.0, 14.0, -3.0, -9.0, 12.0, 13.0, -21.0, 11.0, -11.0, 8.0, 12.0, 6.0, -4.0, -3.0, 10.0, 12.0, -10.0, 14.0, 5.0, 6.0, 7.0, 11.0, 6.0, -9.0, -1.0, 12.0, -5.0, 9.0, 9.0, -7.0, 6.0, 7.0, -9.0, 14.0, 6.0, 4.0, 12.0, 9.0, 1.0, -7.0, -14.0, 13.0, 10.0, 6.0, 13.0, 12.0, -20.0, 10.0, -4.0, 5.0, 7.0, 7.0, 0.0, 12.0, 0.0, 3.0, 0.0, 13.0, -8.0, 10.0, 6.0, -3.0, 7.0, 5.0, -11.0, 11.0, 7.0, 8.0, 14.0, 8.0, -15.0, 8.0, -6.0, 5.0, 4.0, 12.0, -2.0, 1.0, 5.0, 11.0, -3.0, 14.0, -7.0, 11.0, 0.0, 12.0, -5.0, 8.0, -4.0, 12.0, -5.0, 12.0, -8.0, 9.0, 10.0, 4.0, -1.0, 11.0, 7.0, -2.0, 0.0, 12.0, 6.0, -3.0, -6.0, 7.0, 12.0, 2.0, 14.0, -10.0, -1.0, 12.0, -8.0, 5.0, 12.0, 6.0, 13.0, 11.0, 318.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2205477473654901, "mean_inference_ms": 1.1746271533674688, "mean_action_processing_ms": 0.07181977567650662, "mean_env_wait_ms": 0.1793466266347655, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 750600, "agent_timesteps_total": 750519, "timers": {"sample_time_ms": 353.297, "sample_throughput": 15284.571, "learn_time_ms": 6645.104, "learn_throughput": 812.628, "update_time_ms": 11.993}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 243.6305389404297, "policy_loss": -0.02973991446197033, "vf_loss": 243.6553192138672, "vf_explained_var": 0.22202859818935394, "kl": 0.009804617613554, "entropy": 0.45154690742492676, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 750600, "num_agent_steps_sampled": 750519, "num_steps_trained": 750600, "num_agent_steps_trained": 750519}, "done": false, "episodes_total": 14715, "training_iteration": 139, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-58-27", "timestamp": 1626861507, "time_this_iter_s": 7.116116523742676, "time_total_s": 1007.7629690170288, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cc80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1007.7629690170288, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 21.520000000000003, "ram_util_percent": 14.2}, "trial_id": "cf107_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.00925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.752314814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -13.0, 6.0, 13.0, 7.0, -7.0, 5.0, 10.0, -17.0, 11.0, 13.0, 8.0, 5.0, -3.0, 5.0, 8.0, 12.0, -7.0, 4.0, 6.0, 9.0, -10.0, 12.0, 4.0, -11.0, 5.0, 13.0, 8.0, -6.0, 12.0, 2.0, 7.0, 14.0, -14.0, 2.0, 13.0, 10.0, -2.0, 12.0, -5.0, -14.0, 6.0, 13.0, 10.0, -8.0, 12.0, 8.0, 3.0, 12.0, -17.0, 7.0, 13.0, 7.0, -1.0, 5.0, 4.0, -9.0, 9.0, 6.0, 9.0, -9.0, 11.0, 5.0, 8.0, 11.0, 6.0, -1.0, -1.0, 11.0, -6.0, 2.0, 8.0, -16.0, 10.0, 8.0, 13.0, -14.0, 8.0, 13.0, 8.0, 7.0, -13.0, 8.0, 13.0, -7.0, 2.0, 7.0, 13.0, -1.0, 7.0, 13.0, -4.0, -2.0, -7.0, 12.0, 12.0, 8.0, -14.0, 13.0, 8.0, -14.0, 11.0, 6.0, 12.0, -4.0, 7.0, 4.0, 8.0, 9.0, 5.0, 12.0, -11.0, 13.0, 7.0, -11.0, 6.0, 7.0, -2.0, 12.0, -2.0, 3.0, -3.0, 8.0, 7.0, 7.0, -9.0, 10.0, 7.0, 3.0, -6.0, 13.0, 5.0, 2.0, -7.0, 12.0, 8.0, -11.0, 3.0, 13.0, 10.0, -5.0, 10.0, 2.0, 8.0, 14.0, -7.0, 0.0, 8.0, 10.0, -5.0, 9.0, 1.0, -8.0, 0.0, 12.0, 11.0, -9.0, 3.0, 13.0, 8.0, 5.0, -7.0, 11.0, 6.0, 4.0, -5.0, 7.0, 9.0, -9.0, 5.0, 13.0, 6.0, 11.0, 8.0, -9.0, 5.0, 14.0, -11.0, -1.0, 13.0, -1.0, -2.0, 12.0, 6.0, -4.0, 3.0, 10.0, 6.0, -20.0, 13.0, 9.0, 13.0, 14.0, -1.0, -9.0, 11.0, -12.0, 14.0, 7.0, 6.0, -8.0, 6.0, 4.0, 13.0, -7.0, 5.0, 5.0, 12.0, -5.0, 9.0, 6.0, 5.0, -1.0, -1.0, 6.0, 11.0, -12.0, 5.0, 13.0, 9.0, -15.0, 12.0, 11.0, 7.0, 8.0, 9.0, -9.0, 7.0, 1.0, 12.0, -8.0, 10.0, -14.0, 5.0, 13.0, 11.0, -8.0, 0.0, 12.0, 11.0, 7.0, -8.0, 8.0, 8.0, -8.0, 2.0, 12.0, 9.0, 9.0, 13.0, 8.0, -15.0, 7.0, -6.0, 12.0, 2.0, 12.0, -8.0, -2.0, 13.0, 8.0, -13.0, 12.0, 8.0, 5.0, 14.0, 12.0, -16.0, -8.0, 8.0, 8.0, 7.0, 9.0, -14.0, 7.0, 13.0, -8.0, 8.0, 11.0, 4.0, 5.0, 6.0, 13.0, -9.0, 1.0, 11.0, 12.0, -9.0, 6.0, -8.0, 11.0, 6.0, -7.0, -1.0, 12.0, 12.0, -16.0, 10.0, 8.0, 13.0, -5.0, 12.0, 6.0, 2.0, 2.0, -5.0, 5.0, 13.0, 12.0, -5.0, 1.0, 7.0, -2.0, 7.0, 13.0, -3.0, -14.0, 8.0, 8.0, 13.0, -3.0, 3.0, 8.0, 7.0, 4.0, -1.0, 1.0, 11.0, 3.0, 8.0, 13.0, -9.0, -16.0, 8.0, 10.0, 13.0, 12.0, -9.0, 4.0, 8.0, 6.0, 10.0, 10.0, -11.0, -14.0, 5.0, 12.0, 12.0, -4.0, 14.0, -3.0, 8.0, 9.0, -4.0, 5.0, 5.0, -12.0, 11.0, 12.0, 4.0, -10.0, 11.0, 13.0, 1.0, -9.0, 8.0, 8.0, 8.0, 8.0, -8.0, 3.0, 12.0, 12.0, -10.0, 0.0, 13.0, -11.0, 2.0, 13.0, 11.0, 8.0, -4.0, 8.0, 3.0, 9.0, -8.0, 1.0, 13.0, -12.0, 12.0, 12.0, 3.0, -13.0, 9.0, 12.0, 7.0, 11.0, 5.0, 2.0, -3.0, 13.0, -10.0, 11.0, 1.0, 7.0, 6.0, 10.0, -8.0, 9.0, 5.0, 8.0, -7.0, -16.0, 13.0, 5.0, 13.0, 13.0, 2.0, 1.0, -1.0, -4.0, 12.0, 1.0, 6.0, -15.0, 6.0, 11.0, 13.0, 9.0, 10.0, 7.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2204364359724209, "mean_inference_ms": 1.1747242798659725, "mean_action_processing_ms": 0.07182061186166365, "mean_env_wait_ms": 0.1793721219810117, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 756000, "agent_timesteps_total": 755973, "timers": {"sample_time_ms": 353.983, "sample_throughput": 15254.978, "learn_time_ms": 6631.403, "learn_throughput": 814.307, "update_time_ms": 12.01}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 29.019323348999023, "policy_loss": -0.08575286716222763, "vf_loss": 29.09545135498047, "vf_explained_var": 0.3069922626018524, "kl": 0.019015200436115265, "entropy": 0.4503103196620941, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 756000, "num_agent_steps_sampled": 755973, "num_steps_trained": 756000, "num_agent_steps_trained": 755973}, "done": false, "episodes_total": 14823, "training_iteration": 140, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-58-34", "timestamp": 1626861514, "time_this_iter_s": 7.055823802947998, "time_total_s": 1014.8187928199768, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1014.8187928199768, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 22.67, "ram_util_percent": 14.219999999999999}, "trial_id": "cf107_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.01, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, -4.0, 10.0, 10.0, 12.0, 6.0, 10.0, -13.0, -5.0, 12.0, -3.0, 11.0, 8.0, -12.0, 11.0, 8.0, 11.0, 5.0, -14.0, 13.0, 10.0, -3.0, -5.0, 13.0, 7.0, 9.0, -3.0, 2.0, 8.0, -3.0, 3.0, 7.0, 11.0, -3.0, -1.0, 8.0, -3.0, -5.0, 10.0, 13.0, 14.0, -22.0, 10.0, 13.0, 9.0, -1.0, -6.0, 13.0, 7.0, 6.0, 9.0, -7.0, 10.0, 5.0, 4.0, -4.0, 13.0, -5.0, -3.0, 10.0, 9.0, -11.0, 5.0, 12.0, 14.0, -11.0, 11.0, 1.0, 7.0, -3.0, -2.0, 13.0, -2.0, 11.0, -5.0, 11.0, 10.0, 8.0, -4.0, 1.0, 8.0, 7.0, -10.0, 10.0, 13.0, -16.0, 12.0, 6.0, -7.0, 8.0, 7.0, 7.0, 13.0, 1.0, -3.0, 4.0, 5.0, -5.0, 8.0, 7.0, 13.0, -1.0, -10.0, 13.0, 8.0, 4.0, -4.0, 7.0, 5.0, -7.0, 5.0, 12.0, 10.0, 14.0, -22.0, 13.0, 11.0, 2.0, -1.0, 3.0, 3.0, -6.0, 5.0, 13.0, 12.0, 5.0, -7.0, 5.0, 0.0, 7.0, -1.0, 9.0, 0.0, 13.0, -8.0, 10.0, 11.0, 9.0, 4.0, -9.0, 11.0, -12.0, 8.0, 8.0, 4.0, -4.0, 6.0, 9.0, 13.0, -13.0, 9.0, 6.0, 5.0, -1.0, -2.0, 13.0, 1.0, 10.0, -4.0, 8.0, 12.0, 14.0, 8.0, -19.0, 12.0, 3.0, -7.0, 7.0, 7.0, -12.0, 9.0, 11.0, 14.0, 5.0, 12.0, -16.0, 12.0, -1.0, -1.0, 5.0, 7.0, -6.0, 4.0, 10.0, 12.0, 4.0, 9.0, -10.0, 14.0, 1.0, -5.0, 5.0, 2.0, -5.0, 11.0, 7.0, 14.0, -4.0, 12.0, -7.0, 4.0, 5.0, -5.0, 11.0, 2.0, 3.0, -2.0, 12.0, 7.0, 3.0, -7.0, 12.0, 8.0, -3.0, -3.0, 13.0, 3.0, -2.0, 6.0, 8.0, -12.0, 4.0, 10.0, 13.0, 8.0, -13.0, 12.0, 8.0, 4.0, -7.0, 9.0, 9.0, 12.0, 9.0, 6.0, -12.0, 13.0, -7.0, 10.0, -1.0, 4.0, -5.0, 8.0, 8.0, 11.0, 4.0, -8.0, 8.0, 10.0, -2.0, -1.0, 8.0, -4.0, -2.0, 12.0, 10.0, 2.0, -8.0, 8.0, 13.0, 13.0, 2.0, -5.0, 5.0, 5.0, -8.0, 10.0, 8.0, 9.0, 2.0, -9.0, 13.0, 4.0, 7.0, -7.0, 11.0, 3.0, -3.0, 12.0, 3.0, 8.0, -9.0, 7.0, 9.0, -7.0, 10.0, -1.0, 13.0, 6.0, -1.0, 3.0, 7.0, 14.0, -2.0, -8.0, 11.0, 8.0, 3.0, -9.0, 13.0, 5.0, 9.0, -6.0, 7.0, 12.0, 8.0, -18.0, 13.0, 12.0, -2.0, -3.0, 8.0, 8.0, -3.0, 7.0, 3.0, 4.0, -2.0, 7.0, 6.0, 13.0, -16.0, 8.0, 10.0, -12.0, 11.0, 12.0, 4.0, -10.0, 11.0, 13.0, 1.0, -9.0, 8.0, 8.0, 8.0, 8.0, -8.0, 3.0, 12.0, 12.0, -10.0, 0.0, 13.0, -11.0, 2.0, 13.0, 11.0, 8.0, -4.0, 8.0, 3.0, 9.0, -8.0, 1.0, 13.0, -12.0, 12.0, 12.0, 3.0, -13.0, 9.0, 12.0, 7.0, 11.0, 5.0, 2.0, -3.0, 13.0, -10.0, 11.0, 1.0, 7.0, 6.0, 10.0, -8.0, 9.0, 5.0, 8.0, -7.0, -16.0, 13.0, 5.0, 13.0, 13.0, 2.0, 1.0, -1.0, -4.0, 12.0, 1.0, 6.0, -15.0, 6.0, 11.0, 13.0, 9.0, 10.0, 7.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2202819426580595, "mean_inference_ms": 1.1734479883264402, "mean_action_processing_ms": 0.07181739587931849, "mean_env_wait_ms": 0.17925633789634748, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 761400, "agent_timesteps_total": 761319, "timers": {"sample_time_ms": 352.714, "sample_throughput": 15309.851, "learn_time_ms": 6620.555, "learn_throughput": 815.642, "update_time_ms": 12.144}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 27.973575592041016, "policy_loss": -0.08275119215250015, "vf_loss": 28.047847747802734, "vf_explained_var": 0.2366165816783905, "kl": 0.016746439039707184, "entropy": 0.4914800524711609, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 761400, "num_agent_steps_sampled": 761319, "num_steps_trained": 761400, "num_agent_steps_trained": 761319}, "done": false, "episodes_total": 14904, "training_iteration": 141, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-58-42", "timestamp": 1626861522, "time_this_iter_s": 6.986872911453247, "time_total_s": 1021.80566573143, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029ce18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1021.80566573143, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 21.509999999999998, "ram_util_percent": 14.209999999999999}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 40.157407407407405, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 10.039351851851851}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 4.0, 4.0, 8.0, 9.0, 11.0, -9.0, 4.0, 5.0, -12.0, 10.0, 12.0, 9.0, -14.0, 7.0, 13.0, 14.0, -9.0, 3.0, 7.0, 13.0, -6.0, 4.0, 4.0, 10.0, 14.0, 11.0, 320.0, 10.0, 7.0, -14.0, 12.0, -2.0, 9.0, 3.0, 5.0, 10.0, -19.0, 12.0, 12.0, -3.0, 5.0, 13.0, 0.0, 11.0, -3.0, -2.0, 9.0, -3.0, 6.0, 6.0, 6.0, 10.0, -16.0, 12.0, 9.0, -3.0, 8.0, 12.0, -2.0, 12.0, 3.0, -9.0, 9.0, 12.0, -8.0, 6.0, 5.0, 10.0, -19.0, 11.0, 13.0, 11.0, 9.0, 9.0, -14.0, 11.0, 8.0, -4.0, 0.0, 14.0, 12.0, -9.0, -2.0, 14.0, -15.0, 8.0, 8.0, 11.0, -11.0, 10.0, 5.0, 13.0, 2.0, -12.0, 12.0, 14.0, -9.0, 5.0, 5.0, 14.0, -5.0, 3.0, 3.0, 6.0, -8.0, 10.0, 7.0, 11.0, 321.0, 10.0, 13.0, 14.0, -10.0, 6.0, 5.0, 12.0, -1.0, 7.0, -3.0, 9.0, -6.0, 11.0, 1.0, 12.0, 7.0, -16.0, 12.0, 13.0, 3.0, -9.0, 8.0, 14.0, -18.0, 8.0, 11.0, -6.0, 3.0, 12.0, 6.0, 8.0, -2.0, 12.0, -3.0, 13.0, 319.0, 9.0, 13.0, 14.0, -20.0, 12.0, 9.0, -2.0, 4.0, 11.0, 2.0, -3.0, -2.0, 9.0, 11.0, 14.0, 321.0, 9.0, 11.0, 14.0, 10.0, -4.0, -5.0, 10.0, 12.0, 13.0, -20.0, 5.0, 2.0, -5.0, 13.0, 14.0, 7.0, 8.0, -14.0, 13.0, 317.0, 12.0, 13.0, -3.0, 10.0, 13.0, -5.0, 5.0, 3.0, -5.0, 12.0, 14.0, 5.0, 9.0, -13.0, 14.0, -3.0, -6.0, 10.0, 9.0, 10.0, 12.0, -16.0, 0.0, 12.0, -9.0, 12.0, 10.0, -4.0, 0.0, 9.0, 13.0, 5.0, 8.0, -11.0, 9.0, -11.0, 13.0, 4.0, -4.0, 7.0, 0.0, 12.0, 14.0, 12.0, -8.0, -3.0, 8.0, 10.0, 6.0, -9.0, 7.0, -9.0, 10.0, 7.0, 12.0, 1.0, -10.0, 12.0, 0.0, 9.0, 0.0, 6.0, 9.0, 1.0, 12.0, -7.0, 8.0, -7.0, 10.0, 4.0, 9.0, -2.0, -3.0, 11.0, 14.0, 7.0, -9.0, 3.0, 13.0, 321.0, 10.0, 12.0, 10.0, 6.0, 10.0, -11.0, 10.0, -3.0, -4.0, 12.0, 11.0, -12.0, 9.0, 7.0, 6.0, -15.0, 11.0, 13.0, -7.0, 2.0, 8.0, 12.0, 9.0, -14.0, 8.0, 12.0, 11.0, 4.0, -5.0, 5.0, 5.0, 10.0, 7.0, -7.0, -3.0, 14.0, 13.0, -9.0, 10.0, 5.0, 12.0, -12.0, 14.0, -14.0, 8.0, 7.0, 14.0, -8.0, -4.0, 13.0, 7.0, -12.0, 10.0, 10.0, 12.0, -12.0, 4.0, 11.0, -2.0, -5.0, 9.0, 13.0, 13.0, 12.0, -2.0, -8.0, 7.0, -9.0, 12.0, 5.0, -2.0, -3.0, 7.0, 13.0, -3.0, 2.0, 9.0, 7.0, 14.0, 9.0, -5.0, -3.0, -3.0, 13.0, 11.0, -6.0, 11.0, 7.0, -14.0, 11.0, 0.0, -4.0, 9.0, 10.0, 14.0, 315.0, 12.0, 13.0, 8.0, -14.0, 9.0, 12.0, 12.0, 7.0, -16.0, 12.0, -6.0, 12.0, 3.0, 6.0, 14.0, 4.0, -6.0, 3.0, 9.0, -10.0, 12.0, 4.0, 10.0, -2.0, -6.0, 13.0, 14.0, 13.0, 2.0, -14.0, 6.0, 3.0, -6.0, 12.0, 10.0, -7.0, 12.0, 0.0, -4.0, 7.0, 0.0, 12.0, 13.0, 1.0, -9.0, 10.0, 14.0, -12.0, 9.0, 4.0, -11.0, 1.0, 12.0, 13.0, 10.0, 7.0, -12.0, 10.0, -1.0, 2.0, 4.0, 10.0, 10.0, -5.0, 4.0, 6.0, -3.0, 12.0, 12.0, -6.0, 12.0, 12.0, 11.0, 318.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2204596933424666, "mean_inference_ms": 1.1743859926485194, "mean_action_processing_ms": 0.07181296122666626, "mean_env_wait_ms": 0.17938470814399365, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 766800, "agent_timesteps_total": 766719, "timers": {"sample_time_ms": 352.381, "sample_throughput": 15324.315, "learn_time_ms": 6635.163, "learn_throughput": 813.846, "update_time_ms": 12.417}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 1324.1295166015625, "policy_loss": -0.020766137167811394, "vf_loss": 1324.146728515625, "vf_explained_var": 0.07354371249675751, "kl": 0.0070922174490988255, "entropy": 0.4208389222621918, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 766800, "num_agent_steps_sampled": 766719, "num_steps_trained": 766800, "num_agent_steps_trained": 766719}, "done": false, "episodes_total": 15012, "training_iteration": 142, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-58-49", "timestamp": 1626861529, "time_this_iter_s": 7.216453552246094, "time_total_s": 1029.0221192836761, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70208c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1029.0221192836761, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 21.66, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 33.879629629629626, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 8.469907407407407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -14.0, 11.0, 5.0, -15.0, 9.0, 10.0, 11.0, -1.0, -6.0, 10.0, 12.0, -13.0, 5.0, 11.0, 12.0, 13.0, 321.0, 11.0, 10.0, -17.0, 12.0, 12.0, 8.0, 5.0, 9.0, -8.0, 9.0, 4.0, -4.0, 6.0, 9.0, 13.0, 12.0, -17.0, 7.0, 321.0, 13.0, 10.0, 12.0, -14.0, 8.0, 9.0, 12.0, 12.0, 12.0, 0.0, -9.0, 12.0, -9.0, 8.0, 4.0, -4.0, 11.0, 11.0, -3.0, 11.0, 7.0, -16.0, 13.0, -3.0, 3.0, 7.0, 8.0, 0.0, 8.0, -1.0, 8.0, 2.0, 12.0, 11.0, -10.0, 7.0, -13.0, 9.0, 12.0, -2.0, 5.0, 7.0, 5.0, 8.0, -11.0, 12.0, 6.0, -13.0, 7.0, 10.0, 11.0, -11.0, 3.0, 11.0, 12.0, -3.0, 5.0, 3.0, 10.0, 7.0, -10.0, 11.0, 7.0, -4.0, 10.0, -3.0, 12.0, 7.0, 7.0, -9.0, 10.0, -3.0, 8.0, 0.0, 10.0, 13.0, 320.0, 11.0, 10.0, -16.0, 13.0, 10.0, 8.0, 5.0, -7.0, 10.0, 7.0, -5.0, 8.0, 2.0, 10.0, -8.0, 13.0, 1.0, 9.0, -9.0, 9.0, 2.0, 13.0, 5.0, -6.0, 4.0, 12.0, 319.0, 13.0, 12.0, 11.0, 12.0, -6.0, 5.0, 4.0, -18.0, 13.0, 10.0, 10.0, 8.0, -17.0, 12.0, 12.0, 14.0, -8.0, 2.0, 7.0, 11.0, 0.0, -3.0, 7.0, -15.0, 7.0, 10.0, 13.0, 7.0, 9.0, -14.0, 13.0, -17.0, 8.0, 11.0, 13.0, 11.0, -6.0, 10.0, 0.0, -15.0, 10.0, 7.0, 13.0, -8.0, 14.0, -3.0, 12.0, -7.0, 10.0, 7.0, 5.0, -14.0, 8.0, 11.0, 10.0, 3.0, 12.0, 6.0, -6.0, 8.0, 9.0, -14.0, 12.0, -10.0, 6.0, 6.0, 13.0, 13.0, -6.0, 6.0, 2.0, 4.0, 12.0, 9.0, -10.0, -8.0, 10.0, 1.0, 12.0, -15.0, 7.0, 12.0, 11.0, 8.0, -9.0, 7.0, 9.0, -9.0, 7.0, 4.0, 13.0, -3.0, -1.0, 7.0, 12.0, -1.0, 4.0, 3.0, 9.0, 14.0, -8.0, 12.0, -3.0, 4.0, 12.0, -8.0, 7.0, -8.0, 1.0, 10.0, 12.0, -12.0, 13.0, 8.0, 6.0, 11.0, 8.0, -15.0, 11.0, -18.0, 12.0, 10.0, 11.0, 7.0, 9.0, -14.0, 13.0, 13.0, 10.0, 5.0, -13.0, 8.0, 0.0, 6.0, 1.0, -16.0, 13.0, 11.0, 7.0, -10.0, 8.0, 5.0, 12.0, 3.0, 7.0, 12.0, -7.0, 2.0, -8.0, 11.0, 10.0, -18.0, 10.0, 12.0, 11.0, -19.0, 10.0, 12.0, 12.0, -7.0, 7.0, 6.0, 9.0, 12.0, -13.0, 3.0, 13.0, -13.0, 11.0, 6.0, 11.0, 6.0, 3.0, -6.0, 12.0, 0.0, -4.0, 12.0, 7.0, 7.0, -10.0, 10.0, 8.0, -14.0, 11.0, 7.0, 11.0, 10.0, -17.0, 10.0, 12.0, -5.0, 8.0, 6.0, 6.0, 12.0, -6.0, 6.0, 3.0, 3.0, 11.0, -11.0, 12.0, 8.0, -5.0, 0.0, 12.0, -7.0, 6.0, 10.0, 6.0, 14.0, -12.0, 11.0, 2.0, 6.0, 13.0, 7.0, -11.0, 5.0, -2.0, 0.0, 12.0, 8.0, 0.0, -5.0, 12.0, 7.0, -3.0, 5.0, 6.0, -14.0, 13.0, 8.0, 8.0, 8.0, -16.0, 11.0, 12.0, -3.0, 2.0, 7.0, 9.0, 10.0, -14.0, 11.0, 8.0, -12.0, 11.0, 9.0, 7.0, -6.0, 6.0, 3.0, 12.0, 8.0, 6.0, 11.0, -10.0, 13.0, -4.0, 4.0, 2.0, 321.0, 12.0, 11.0, 11.0, 6.0, -6.0, 3.0, 12.0, -1.0, -3.0, 9.0, 10.0, 7.0, -11.0, 12.0, 7.0, 319.0, 13.0, 11.0, 11.0, 0.0, -5.0, 8.0, 12.0, -10.0, 7.0, 12.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2205182903759038, "mean_inference_ms": 1.174520357574365, "mean_action_processing_ms": 0.07181427025733636, "mean_env_wait_ms": 0.17940028304673047, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 772200, "agent_timesteps_total": 772119, "timers": {"sample_time_ms": 352.443, "sample_throughput": 15321.643, "learn_time_ms": 6643.675, "learn_throughput": 812.803, "update_time_ms": 12.245}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 933.2348022460938, "policy_loss": -0.019657397642731667, "vf_loss": 933.2513427734375, "vf_explained_var": 0.0841071680188179, "kl": 0.0061432914808392525, "entropy": 0.45831790566444397, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 772200, "num_agent_steps_sampled": 772119, "num_steps_trained": 772200, "num_agent_steps_trained": 772119}, "done": false, "episodes_total": 15120, "training_iteration": 143, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-58-56", "timestamp": 1626861536, "time_this_iter_s": 7.111374855041504, "time_total_s": 1036.1334941387177, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70208d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1036.1334941387177, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 21.12727272727273, "ram_util_percent": 14.300000000000004}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -6.0, -5.0, 13.0, 4.0, 9.0, 13.0, -11.0, 13.0, 5.0, 8.0, -11.0, 5.0, -4.0, 5.0, 9.0, 5.0, 13.0, -16.0, 13.0, -8.0, 13.0, -1.0, 11.0, 9.0, 10.0, 6.0, -10.0, 12.0, 13.0, 5.0, -15.0, 1.0, -1.0, 2.0, 13.0, 10.0, -8.0, 1.0, 12.0, 14.0, 5.0, -10.0, 6.0, 12.0, 14.0, -10.0, -1.0, 3.0, 9.0, -7.0, 10.0, 9.0, 3.0, 5.0, -2.0, 9.0, 13.0, -3.0, -4.0, 319.0, 13.0, 9.0, 13.0, 7.0, 2.0, -6.0, 12.0, 10.0, -6.0, -1.0, 12.0, 10.0, 7.0, -5.0, 3.0, 9.0, 11.0, 6.0, -11.0, 7.0, 12.0, 4.0, -8.0, -8.0, 8.0, 2.0, 13.0, 13.0, 13.0, -15.0, 4.0, 6.0, 10.0, -6.0, 5.0, -2.0, 12.0, -6.0, 11.0, -8.0, 7.0, 3.0, 13.0, 9.0, 11.0, -10.0, 5.0, 3.0, 13.0, 10.0, -11.0, 8.0, -13.0, 7.0, 13.0, 6.0, -3.0, 0.0, 12.0, 11.0, 11.0, 9.0, -16.0, 11.0, -5.0, 5.0, 4.0, -9.0, 12.0, 4.0, 8.0, 8.0, 13.0, 11.0, -17.0, 8.0, -7.0, 10.0, 4.0, 7.0, 0.0, 4.0, 4.0, 4.0, -2.0, 3.0, 10.0, -7.0, 8.0, 3.0, 11.0, 10.0, -8.0, 7.0, 6.0, 11.0, 13.0, -8.0, -1.0, 8.0, 12.0, -17.0, 12.0, -6.0, 12.0, 7.0, 2.0, 13.0, 12.0, 2.0, -12.0, 5.0, 13.0, 8.0, -11.0, 0.0, 13.0, -6.0, 8.0, 7.0, 9.0, -14.0, 13.0, 11.0, 10.0, -8.0, 2.0, 12.0, 10.0, 0.0, -7.0, 7.0, -4.0, 3.0, 9.0, -9.0, 8.0, 3.0, 13.0, 13.0, 6.0, 8.0, -12.0, 9.0, 11.0, 9.0, -14.0, 13.0, 13.0, 317.0, 12.0, 11.0, 10.0, 9.0, -15.0, 14.0, -15.0, 4.0, 12.0, 4.0, -4.0, 10.0, 5.0, 6.0, -2.0, 1.0, 10.0, 8.0, 13.0, -3.0, -3.0, 13.0, 12.0, 6.0, -16.0, 11.0, 12.0, -13.0, 5.0, 4.0, -5.0, 8.0, 8.0, 5.0, -5.0, 4.0, 11.0, 13.0, 4.0, 8.0, -10.0, -16.0, 10.0, 8.0, 13.0, 9.0, 12.0, -13.0, 7.0, -4.0, 11.0, -4.0, 12.0, 14.0, 8.0, -11.0, 4.0, 9.0, -2.0, 6.0, 2.0, 14.0, 3.0, -15.0, 13.0, 4.0, 13.0, 9.0, -11.0, 13.0, 8.0, 5.0, -11.0, 13.0, -2.0, 0.0, 4.0, -15.0, 13.0, 7.0, 10.0, 11.0, 8.0, -2.0, -2.0, 9.0, 12.0, 5.0, -11.0, 12.0, 13.0, -11.0, 1.0, 8.0, -1.0, -1.0, 9.0, -4.0, 6.0, 1.0, 12.0, 8.0, 11.0, -11.0, 7.0, 12.0, -4.0, -3.0, 10.0, 2.0, 7.0, -6.0, 12.0, 2.0, 10.0, 5.0, -2.0, 14.0, 10.0, 10.0, -19.0, 8.0, 11.0, -17.0, 13.0, 3.0, 13.0, -9.0, 8.0, -11.0, 10.0, 5.0, 11.0, -6.0, 11.0, 10.0, 0.0, 11.0, -1.0, 8.0, -3.0, 1.0, -1.0, 4.0, 11.0, 3.0, -2.0, 1.0, 13.0, 13.0, 9.0, -12.0, 5.0, 8.0, 13.0, -1.0, -5.0, -11.0, 13.0, 0.0, 13.0, 9.0, 6.0, 2.0, -2.0, 12.0, 9.0, -5.0, -1.0, 4.0, -2.0, 9.0, 4.0, 8.0, 0.0, -5.0, 12.0, 8.0, 3.0, -8.0, 12.0, 13.0, -9.0, 6.0, 5.0, 4.0, -11.0, 10.0, 12.0, 10.0, 11.0, -10.0, 4.0, -14.0, 11.0, 5.0, 13.0, 12.0, 11.0, 7.0, -15.0, 12.0, -6.0, 0.0, 9.0, 4.0, -3.0, 4.0, 10.0, 5.0, 13.0, -2.0, -1.0, 13.0, 10.0, 3.0, -11.0, -11.0, 9.0, 9.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22055319987527258, "mean_inference_ms": 1.1746908303389736, "mean_action_processing_ms": 0.07182235807005606, "mean_env_wait_ms": 0.17942262807860687, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 777600, "agent_timesteps_total": 777519, "timers": {"sample_time_ms": 352.561, "sample_throughput": 15316.479, "learn_time_ms": 6637.918, "learn_throughput": 813.508, "update_time_ms": 11.907}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 284.3117980957031, "policy_loss": -0.02605932205915451, "vf_loss": 284.3334655761719, "vf_explained_var": 0.11023165285587311, "kl": 0.008554070256650448, "entropy": 0.43702253699302673, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 777600, "num_agent_steps_sampled": 777519, "num_steps_trained": 777600, "num_agent_steps_trained": 777519}, "done": false, "episodes_total": 15228, "training_iteration": 144, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-03", "timestamp": 1626861543, "time_this_iter_s": 7.037003993988037, "time_total_s": 1043.1704981327057, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70208ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1043.1704981327057, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 22.28, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 11.0, 11.0, 321.0, 11.0, 13.0, -20.0, 11.0, 13.0, 5.0, 2.0, -5.0, 13.0, -1.0, 2.0, 1.0, 4.0, 3.0, 9.0, -1.0, -7.0, 9.0, 13.0, 0.0, 13.0, 3.0, 4.0, -5.0, 12.0, -6.0, -1.0, 10.0, 7.0, 1.0, 11.0, -4.0, -5.0, 13.0, 1.0, 6.0, 12.0, 10.0, -18.0, 11.0, 13.0, -2.0, 1.0, 3.0, 0.0, 5.0, 11.0, -1.0, 5.0, 5.0, -3.0, 8.0, 11.0, 13.0, 11.0, -20.0, 14.0, -6.0, 1.0, 6.0, 6.0, -5.0, 3.0, 11.0, 6.0, 5.0, 7.0, -3.0, 13.0, 1.0, 3.0, -2.0, 13.0, -4.0, 2.0, 4.0, 10.0, 0.0, -6.0, 11.0, 9.0, 13.0, -16.0, 9.0, 12.0, 13.0, -11.0, 1.0, 14.0, -3.0, -2.0, 6.0, 9.0, -7.0, 0.0, 13.0, 10.0, 6.0, 4.0, -5.0, 12.0, 3.0, 3.0, -3.0, 12.0, 13.0, -11.0, 1.0, 7.0, 13.0, -7.0, 2.0, 10.0, 13.0, -3.0, -5.0, 8.0, 5.0, -2.0, 4.0, 8.0, 13.0, -11.0, 5.0, -12.0, 12.0, 11.0, 4.0, 11.0, 8.0, -13.0, 9.0, 12.0, 10.0, -15.0, 8.0, 12.0, -6.0, -2.0, 11.0, 13.0, -3.0, 4.0, 1.0, 8.0, 12.0, 13.0, -18.0, 12.0, 1.0, 10.0, -8.0, 11.0, -1.0, 5.0, 0.0, 5.0, 10.0, 5.0, -5.0, -4.0, 13.0, 13.0, -7.0, 1.0, 6.0, 12.0, -4.0, 7.0, -3.0, 4.0, 7.0, 5.0, -9.0, 6.0, 13.0, 9.0, 13.0, -11.0, 4.0, 12.0, 4.0, -11.0, 10.0, 14.0, -7.0, 11.0, -3.0, 7.0, -5.0, 10.0, 3.0, 11.0, 9.0, -14.0, 9.0, 13.0, 13.0, -22.0, 11.0, 12.0, 0.0, 1.0, 2.0, 7.0, 6.0, -4.0, 6.0, 7.0, 12.0, -15.0, 11.0, 12.0, 5.0, 0.0, -2.0, 12.0, -8.0, -2.0, 13.0, 4.0, 5.0, -7.0, 13.0, 6.0, 13.0, 9.0, -13.0, 6.0, 10.0, 0.0, -1.0, 10.0, -6.0, 9.0, 2.0, 6.0, 12.0, -9.0, 6.0, 4.0, 9.0, -9.0, 11.0, 7.0, -3.0, 12.0, -1.0, 9.0, -2.0, 1.0, 7.0, -10.0, 13.0, 4.0, 8.0, 5.0, 12.0, -14.0, 12.0, 13.0, 11.0, 6.0, -15.0, 12.0, 0.0, 3.0, 0.0, 11.0, -4.0, 7.0, 1.0, -3.0, 13.0, -1.0, 6.0, 13.0, 4.0, -8.0, 6.0, 13.0, 0.0, -1.0, 3.0, 5.0, -1.0, 6.0, 5.0, 7.0, 9.0, 3.0, -4.0, 10.0, 13.0, 318.0, 13.0, 13.0, -3.0, 0.0, 5.0, 7.0, 10.0, 7.0, -9.0, 11.0, 8.0, -14.0, 10.0, 12.0, -3.0, -2.0, 8.0, 13.0, 8.0, -5.0, -1.0, 7.0, -12.0, 7.0, 13.0, 4.0, 12.0, -13.0, 12.0, 4.0, 4.0, -5.0, 12.0, 10.0, -2.0, 8.0, -1.0, -2.0, 6.0, 6.0, 5.0, 3.0, 12.0, -10.0, 10.0, 12.0, 13.0, -9.0, -1.0, 10.0, -2.0, 1.0, 6.0, 6.0, -1.0, 2.0, 8.0, 5.0, 7.0, -6.0, 9.0, 10.0, 13.0, 11.0, -19.0, 14.0, -4.0, 8.0, -3.0, 3.0, 6.0, 7.0, -1.0, 10.0, 8.0, -6.0, 3.0, 12.0, 13.0, 9.0, -19.0, 12.0, -1.0, -2.0, 6.0, -1.0, 13.0, -8.0, 11.0, 9.0, 13.0, -15.0, 8.0, 10.0, 2.0, -8.0, 11.0, 13.0, -1.0, 4.0, -1.0, 4.0, 5.0, -3.0, 9.0, 6.0, 13.0, -15.0, 11.0, 12.0, 9.0, 3.0, -9.0, 12.0, -2.0, 6.0, -1.0, 7.0, 11.0, 9.0, -12.0, 9.0, 13.0, -3.0, -4.0, 13.0, 3.0, -12.0, 11.0, 12.0, 0.0, -3.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22060669705575428, "mean_inference_ms": 1.174846879685639, "mean_action_processing_ms": 0.0718375344451914, "mean_env_wait_ms": 0.17943460874660275, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 783000, "agent_timesteps_total": 782919, "timers": {"sample_time_ms": 353.197, "sample_throughput": 15288.934, "learn_time_ms": 6609.342, "learn_throughput": 817.025, "update_time_ms": 11.901}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 307.726318359375, "policy_loss": -0.020763887092471123, "vf_loss": 307.7430419921875, "vf_explained_var": 0.20449206233024597, "kl": 0.007944694720208645, "entropy": 0.41163381934165955, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 783000, "num_agent_steps_sampled": 782919, "num_steps_trained": 783000, "num_agent_steps_trained": 782919}, "done": false, "episodes_total": 15336, "training_iteration": 145, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-10", "timestamp": 1626861550, "time_this_iter_s": 6.807578086853027, "time_total_s": 1049.9780762195587, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cbf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1049.9780762195587, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 22.31111111111111, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 13.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-11.0, 12.0, 2.0, 12.0, -4.0, 12.0, 13.0, -6.0, 7.0, 2.0, 11.0, -5.0, -5.0, 10.0, 11.0, -1.0, -15.0, 13.0, 5.0, 12.0, -5.0, 7.0, 0.0, 13.0, -8.0, 13.0, 6.0, 4.0, -3.0, 12.0, 4.0, 2.0, 12.0, -8.0, 13.0, -2.0, 1.0, 11.0, 6.0, -3.0, -9.0, 8.0, 12.0, 4.0, -3.0, 3.0, 7.0, 8.0, 7.0, -9.0, 6.0, 11.0, 4.0, 4.0, 13.0, -6.0, -14.0, 10.0, 7.0, 12.0, -6.0, 11.0, 11.0, -1.0, 9.0, -8.0, 8.0, 6.0, -12.0, 3.0, 13.0, 11.0, -10.0, 7.0, 7.0, 11.0, -5.0, 9.0, 12.0, -1.0, -13.0, 6.0, 11.0, 11.0, 12.0, 7.0, 4.0, -8.0, 8.0, -13.0, 8.0, 12.0, -5.0, 10.0, 12.0, -2.0, -11.0, 8.0, 11.0, 7.0, 12.0, -11.0, 2.0, 12.0, -13.0, 9.0, 11.0, 8.0, -9.0, 13.0, 8.0, 3.0, -4.0, 3.0, 11.0, 5.0, 1.0, 7.0, 8.0, -1.0, -3.0, 2.0, 10.0, 6.0, -3.0, 11.0, 6.0, 1.0, 9.0, -5.0, 1.0, 10.0, -6.0, 7.0, 3.0, 11.0, -10.0, 8.0, 9.0, 8.0, -5.0, 11.0, 12.0, -3.0, 4.0, -7.0, 13.0, 5.0, -14.0, 9.0, 13.0, 7.0, 9.0, 3.0, -8.0, 11.0, -2.0, 5.0, 9.0, 3.0, 3.0, -6.0, 5.0, 13.0, -15.0, 11.0, 13.0, 6.0, -7.0, 5.0, 7.0, 10.0, -10.0, 0.0, 12.0, 13.0, 10.0, -11.0, 4.0, 12.0, -2.0, 10.0, 12.0, -5.0, -12.0, 11.0, 12.0, 4.0, -9.0, 12.0, 5.0, 7.0, -10.0, 9.0, 4.0, 12.0, 5.0, 9.0, 8.0, -7.0, -7.0, 3.0, 11.0, 8.0, -5.0, 6.0, 11.0, 3.0, 0.0, 7.0, -5.0, 13.0, -16.0, 11.0, 13.0, 7.0, -8.0, 0.0, 10.0, 13.0, -12.0, 12.0, 11.0, 4.0, -5.0, 8.0, 10.0, 2.0, 6.0, 11.0, 5.0, -7.0, -2.0, 11.0, 11.0, -5.0, -1.0, 11.0, -1.0, 6.0, 1.0, 13.0, 11.0, -10.0, -7.0, 6.0, 7.0, 9.0, 11.0, -10.0, 11.0, 3.0, -9.0, 11.0, 7.0, 6.0, -3.0, 2.0, 4.0, 12.0, -1.0, -1.0, 5.0, 12.0, 3.0, -7.0, 11.0, 8.0, -6.0, 9.0, 10.0, 2.0, 0.0, 7.0, 12.0, -4.0, -16.0, 10.0, 12.0, 9.0, -8.0, 5.0, 12.0, 6.0, -4.0, 8.0, 12.0, -1.0, -2.0, 1.0, 11.0, 5.0, 2.0, 12.0, 6.0, -5.0, 5.0, 6.0, 7.0, -3.0, -4.0, 4.0, 12.0, 3.0, 8.0, 11.0, 7.0, -11.0, -11.0, 9.0, 5.0, 12.0, -10.0, 10.0, 11.0, 4.0, -1.0, 2.0, 12.0, 2.0, 11.0, 6.0, -2.0, 0.0, 7.0, 8.0, 7.0, -7.0, -4.0, 9.0, 3.0, 7.0, -4.0, 10.0, 13.0, -4.0, 12.0, -9.0, 0.0, 12.0, -9.0, 4.0, 13.0, 7.0, -10.0, 11.0, 11.0, 3.0, -3.0, 10.0, 9.0, -1.0, -2.0, 12.0, -7.0, 12.0, 7.0, 0.0, 13.0, -5.0, -8.0, 4.0, 12.0, 7.0, -2.0, 11.0, 7.0, -1.0, -4.0, 7.0, 12.0, 0.0, -13.0, 9.0, 8.0, 11.0, -4.0, 9.0, 6.0, 4.0, -3.0, 2.0, 12.0, 4.0, 9.0, -11.0, 6.0, 11.0, 6.0, 10.0, 7.0, -8.0, -13.0, 8.0, 12.0, 8.0, -10.0, 11.0, 10.0, 4.0, -8.0, 11.0, 0.0, 12.0, 0.0, 4.0, 13.0, -2.0, -6.0, 9.0, 7.0, 5.0, -10.0, 11.0, 12.0, 2.0, -3.0, 4.0, 10.0, 4.0, -1.0, 10.0, 7.0, -1.0, -10.0, 10.0, 12.0, 3.0, -5.0, 5.0, 12.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2206436956122806, "mean_inference_ms": 1.1750654625361057, "mean_action_processing_ms": 0.07185225436091647, "mean_env_wait_ms": 0.17946520118000248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 788400, "agent_timesteps_total": 788319, "timers": {"sample_time_ms": 355.124, "sample_throughput": 15205.949, "learn_time_ms": 6576.278, "learn_throughput": 821.133, "update_time_ms": 11.537}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.5062500238418579, "cur_lr": 4.999999873689376e-05, "total_loss": 20.39769172668457, "policy_loss": -0.08456023782491684, "vf_loss": 20.47132682800293, "vf_explained_var": 0.33770132064819336, "kl": 0.021583538502454758, "entropy": 0.4215434789657593, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 788400, "num_agent_steps_sampled": 788319, "num_steps_trained": 788400, "num_agent_steps_trained": 788319}, "done": false, "episodes_total": 15444, "training_iteration": 146, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-17", "timestamp": 1626861557, "time_this_iter_s": 6.895223379135132, "time_total_s": 1056.8732995986938, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1056.8732995986938, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 21.66, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12962962962963, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 315.0}, "policy_reward_mean": {"learned": 4.532407407407407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [2.0, 4.0, 11.0, -2.0, 2.0, 11.0, -5.0, 7.0, 14.0, -3.0, -7.0, 11.0, 2.0, 12.0, 7.0, -6.0, -3.0, 2.0, 6.0, 10.0, 13.0, 1.0, -10.0, 11.0, 9.0, 6.0, -13.0, 13.0, -6.0, 4.0, 6.0, 11.0, 6.0, 9.0, -11.0, 11.0, 11.0, 1.0, -10.0, 13.0, 10.0, -4.0, -2.0, 11.0, 13.0, -4.0, 7.0, -1.0, 7.0, 5.0, -7.0, 10.0, 4.0, -8.0, 12.0, 7.0, 13.0, 4.0, -15.0, 13.0, 9.0, 3.0, 11.0, -8.0, 4.0, -9.0, 9.0, 11.0, 13.0, -9.0, 0.0, 11.0, 14.0, 5.0, -17.0, 13.0, 13.0, 8.0, -11.0, 5.0, 9.0, 5.0, -6.0, 7.0, 10.0, -10.0, 12.0, 3.0, 14.0, 8.0, -20.0, 13.0, 13.0, 2.0, -12.0, 12.0, 8.0, 6.0, 5.0, -4.0, 12.0, -16.0, 6.0, 13.0, 14.0, -6.0, -6.0, 13.0, 14.0, 11.0, -2.0, -8.0, -4.0, 11.0, 2.0, 6.0, 6.0, 5.0, -3.0, 7.0, 14.0, 4.0, -15.0, 12.0, 13.0, -11.0, 1.0, 12.0, 9.0, -2.0, 10.0, -2.0, 3.0, 10.0, -7.0, 9.0, 14.0, 2.0, -12.0, 11.0, 13.0, 1.0, 2.0, -1.0, 13.0, 0.0, 10.0, -8.0, 2.0, -6.0, 9.0, 10.0, 0.0, -5.0, 7.0, 13.0, 13.0, 11.0, -14.0, 5.0, -2.0, 1.0, 5.0, 11.0, 11.0, 3.0, 5.0, -4.0, -6.0, 7.0, 1.0, 13.0, 13.0, 9.0, 0.0, -7.0, 8.0, 1.0, 9.0, -3.0, 7.0, 9.0, -2.0, 1.0, 13.0, -1.0, -10.0, 13.0, -2.0, 11.0, -1.0, 7.0, 10.0, 6.0, -3.0, 2.0, 6.0, 8.0, -11.0, 12.0, 13.0, 0.0, -11.0, 13.0, 12.0, 13.0, -14.0, 4.0, 6.0, 10.0, -7.0, 6.0, 11.0, -15.0, 8.0, 11.0, 14.0, 11.0, 315.0, 13.0, 13.0, 10.0, -15.0, 7.0, 6.0, -6.0, 10.0, 5.0, 11.0, 0.0, -8.0, 12.0, 13.0, 2.0, -13.0, 13.0, 14.0, 10.0, -16.0, 7.0, 8.0, 0.0, 11.0, -4.0, 12.0, 1.0, -11.0, 13.0, -5.0, 8.0, 0.0, 12.0, -3.0, 11.0, 0.0, 7.0, -7.0, 4.0, 11.0, 7.0, 9.0, 5.0, -7.0, 8.0, 14.0, -1.0, -11.0, 13.0, -1.0, 4.0, 11.0, 1.0, -13.0, 11.0, 10.0, 7.0, 9.0, 2.0, -8.0, 12.0, -2.0, -4.0, 9.0, 12.0, 9.0, 5.0, -11.0, 12.0, 0.0, 14.0, -8.0, 9.0, 8.0, -7.0, 9.0, 5.0, 11.0, 11.0, -19.0, 12.0, 8.0, 12.0, -17.0, 12.0, 4.0, 13.0, 10.0, -12.0, 11.0, -2.0, -7.0, 13.0, 14.0, -1.0, -11.0, 13.0, -8.0, 10.0, 4.0, 9.0, -6.0, 3.0, 11.0, 7.0, 4.0, 10.0, -4.0, 5.0, 14.0, -1.0, -11.0, 13.0, 9.0, 11.0, -2.0, -3.0, 5.0, 12.0, -9.0, 7.0, 13.0, -4.0, -7.0, 13.0, 13.0, -1.0, 10.0, -7.0, 13.0, -7.0, 1.0, 8.0, 3.0, 12.0, -4.0, 4.0, 10.0, -1.0, -7.0, 13.0, 12.0, -4.0, -2.0, 9.0, 10.0, 12.0, -8.0, 1.0, 7.0, 1.0, 10.0, -3.0, 1.0, 12.0, -9.0, 11.0, 11.0, 1.0, -10.0, 13.0, 12.0, 9.0, 12.0, -18.0, 6.0, 9.0, -6.0, 6.0, 8.0, -14.0, 8.0, 13.0, 13.0, 6.0, -10.0, 6.0, 12.0, 5.0, -7.0, 5.0, 1.0, 12.0, -3.0, 5.0, 12.0, -1.0, -9.0, 13.0, 10.0, 5.0, -13.0, 13.0, 10.0, 10.0, -12.0, 7.0, 7.0, -14.0, 11.0, 11.0, 3.0, 12.0, -9.0, 9.0, 0.0, 8.0, -5.0, 12.0, 12.0, 10.0, -19.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22069491020294627, "mean_inference_ms": 1.1752274120962396, "mean_action_processing_ms": 0.07185400442575775, "mean_env_wait_ms": 0.17948382029276116, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 793800, "agent_timesteps_total": 793719, "timers": {"sample_time_ms": 355.853, "sample_throughput": 15174.793, "learn_time_ms": 6549.231, "learn_throughput": 824.524, "update_time_ms": 11.502}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.7593749761581421, "cur_lr": 4.999999873689376e-05, "total_loss": 216.97763061523438, "policy_loss": -0.028316320851445198, "vf_loss": 217.0016632080078, "vf_explained_var": 0.2729131877422333, "kl": 0.005705990828573704, "entropy": 0.43282097578048706, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 793800, "num_agent_steps_sampled": 793719, "num_steps_trained": 793800, "num_agent_steps_trained": 793719}, "done": false, "episodes_total": 15552, "training_iteration": 147, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-24", "timestamp": 1626861564, "time_this_iter_s": 6.854461908340454, "time_total_s": 1063.7277615070343, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cd90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1063.7277615070343, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 21.759999999999998, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 13.0, 11.0, -18.0, 13.0, 11.0, 5.0, -14.0, 12.0, -16.0, 12.0, 7.0, -5.0, 13.0, 11.0, -4.0, 9.0, -9.0, 8.0, 7.0, 12.0, 13.0, -16.0, 6.0, 10.0, 10.0, 9.0, -14.0, 11.0, -18.0, 11.0, 11.0, 8.0, 5.0, 7.0, -5.0, -2.0, 9.0, 2.0, 6.0, 8.0, 10.0, -8.0, 5.0, 10.0, 6.0, 11.0, -12.0, 11.0, 11.0, 1.0, -8.0, 9.0, 10.0, -8.0, 4.0, 12.0, 6.0, -8.0, 5.0, 6.0, 7.0, 11.0, -9.0, 7.0, -10.0, 6.0, 12.0, 3.0, 12.0, -1.0, 1.0, 13.0, 8.0, -10.0, 4.0, -5.0, 0.0, 11.0, 9.0, 7.0, 13.0, 3.0, -8.0, 11.0, 11.0, -3.0, -4.0, 12.0, -9.0, 11.0, 1.0, -2.0, 5.0, 1.0, 11.0, -7.0, 5.0, 6.0, 11.0, 11.0, 8.0, -16.0, 12.0, 14.0, -13.0, 8.0, 6.0, -1.0, 7.0, 4.0, 5.0, 10.0, 6.0, 1.0, -2.0, 7.0, 11.0, -15.0, 12.0, 9.0, -13.0, 12.0, 7.0, 14.0, -14.0, 2.0, 13.0, 13.0, 3.0, -11.0, 10.0, 12.0, 11.0, -15.0, 7.0, 13.0, 8.0, -1.0, -5.0, -1.0, 6.0, 6.0, 4.0, 13.0, 1.0, 3.0, -2.0, 7.0, 11.0, -8.0, 5.0, 14.0, -13.0, 12.0, 2.0, -5.0, 9.0, 7.0, 4.0, 12.0, 10.0, -19.0, 12.0, 13.0, 11.0, -10.0, 1.0, 14.0, -17.0, 6.0, 12.0, -1.0, -1.0, 8.0, 9.0, 7.0, 9.0, -13.0, 12.0, 7.0, 9.0, -2.0, 1.0, 12.0, -12.0, 7.0, 8.0, -3.0, 10.0, 1.0, 7.0, 13.0, 3.0, -13.0, 12.0, 7.0, 11.0, -13.0, 10.0, 12.0, -4.0, 13.0, -6.0, 11.0, 5.0, -10.0, 9.0, -6.0, 5.0, 6.0, 10.0, 12.0, 6.0, -15.0, 12.0, 11.0, 5.0, -5.0, 4.0, -3.0, 11.0, 11.0, -4.0, 12.0, -12.0, 8.0, 7.0, 12.0, 6.0, -6.0, 3.0, -2.0, 4.0, 12.0, 1.0, 8.0, 13.0, 11.0, -17.0, 11.0, -5.0, -3.0, 12.0, 12.0, 10.0, -8.0, 1.0, 12.0, -11.0, 8.0, 6.0, -11.0, 8.0, 11.0, 7.0, 11.0, 9.0, 8.0, -13.0, 11.0, 6.0, -3.0, 1.0, 5.0, -7.0, 7.0, 10.0, -6.0, 5.0, 11.0, 5.0, 12.0, -3.0, -6.0, 12.0, 6.0, 9.0, 4.0, -4.0, 13.0, -14.0, 12.0, 4.0, 9.0, 13.0, 11.0, -18.0, 10.0, 2.0, 11.0, -8.0, 12.0, 6.0, -11.0, 8.0, 8.0, -9.0, 11.0, 5.0, 10.0, 5.0, -11.0, 11.0, -10.0, 3.0, 10.0, 12.0, 12.0, 4.0, 10.0, -11.0, 13.0, 0.0, -4.0, 6.0, -1.0, 9.0, 5.0, 2.0, 11.0, -1.0, -7.0, 12.0, 10.0, -10.0, 5.0, 10.0, 14.0, 319.0, 10.0, 12.0, 12.0, -11.0, 8.0, 6.0, -5.0, 8.0, 2.0, 10.0, 11.0, 8.0, -6.0, 2.0, 12.0, -4.0, -4.0, 11.0, -7.0, 12.0, 3.0, 7.0, -10.0, 9.0, 9.0, 7.0, 12.0, 10.0, -4.0, -3.0, 13.0, -10.0, 1.0, 11.0, 7.0, 7.0, 8.0, -7.0, 7.0, 8.0, 3.0, -3.0, 12.0, 12.0, -10.0, 1.0, 5.0, -9.0, 12.0, 7.0, 11.0, 9.0, 1.0, -6.0, 7.0, -1.0, 1.0, 8.0, 9.0, 8.0, -13.0, 11.0, 13.0, 5.0, -5.0, 2.0, -8.0, 9.0, 7.0, 7.0, 5.0, 4.0, -4.0, 10.0, 7.0, 13.0, -3.0, -2.0, 13.0, -2.0, 5.0, -1.0, 12.0, 7.0, -9.0, 5.0, 11.0, 7.0, 3.0, -6.0, 7.0, 5.0, -8.0, 11.0, 9.0, -4.0, 6.0, 4.0, 12.0, -6.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22073678438018, "mean_inference_ms": 1.1753873912884207, "mean_action_processing_ms": 0.07186616935673802, "mean_env_wait_ms": 0.17950113894126896, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 799200, "agent_timesteps_total": 799119, "timers": {"sample_time_ms": 356.258, "sample_throughput": 15157.543, "learn_time_ms": 6518.188, "learn_throughput": 828.451, "update_time_ms": 11.388}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.7593749761581421, "cur_lr": 4.999999873689376e-05, "total_loss": 239.94187927246094, "policy_loss": -0.022824816405773163, "vf_loss": 239.95913696289062, "vf_explained_var": 0.2202003002166748, "kl": 0.0073699383065104485, "entropy": 0.46090924739837646, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 799200, "num_agent_steps_sampled": 799119, "num_steps_trained": 799200, "num_agent_steps_trained": 799119}, "done": false, "episodes_total": 15660, "training_iteration": 148, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-31", "timestamp": 1626861571, "time_this_iter_s": 6.8376922607421875, "time_total_s": 1070.5654537677765, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70212c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1070.5654537677765, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 21.830000000000002, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -1.0, 6.0, -2.0, 13.0, -9.0, -1.0, 12.0, 11.0, -11.0, 12.0, 3.0, 12.0, 6.0, -12.0, 9.0, -7.0, 8.0, 4.0, 10.0, 14.0, -18.0, 13.0, 6.0, 13.0, -6.0, 11.0, -3.0, 9.0, 11.0, -18.0, 13.0, 7.0, 13.0, -3.0, -2.0, 6.0, -12.0, 8.0, 13.0, 11.0, -13.0, 9.0, 8.0, 7.0, 13.0, -14.0, 9.0, 10.0, -2.0, 10.0, -3.0, 4.0, -5.0, 3.0, 13.0, 11.0, -15.0, 11.0, 8.0, 10.0, 8.0, -16.0, 13.0, 10.0, 13.0, -6.0, -2.0, 7.0, -5.0, 1.0, 12.0, 7.0, -15.0, 12.0, 11.0, -2.0, 13.0, 1.0, 3.0, -3.0, 12.0, 8.0, -2.0, 8.0, -12.0, 8.0, 11.0, -14.0, 9.0, 10.0, 10.0, 14.0, 0.0, -12.0, 13.0, -3.0, 7.0, 3.0, 8.0, 7.0, -13.0, 10.0, 11.0, 13.0, -12.0, 2.0, 12.0, 9.0, 11.0, -18.0, 13.0, -12.0, 12.0, 11.0, 4.0, 8.0, -13.0, 9.0, 11.0, -7.0, 10.0, 13.0, -1.0, -7.0, 13.0, -4.0, 13.0, 12.0, 13.0, 1.0, -11.0, 6.0, -10.0, 6.0, 13.0, 11.0, -14.0, 10.0, 8.0, -8.0, 8.0, 2.0, 13.0, -9.0, 7.0, 7.0, 10.0, 2.0, -9.0, 9.0, 13.0, 12.0, -15.0, 11.0, 7.0, 8.0, 4.0, -10.0, 13.0, -6.0, 7.0, 9.0, 5.0, 2.0, 4.0, -4.0, 13.0, 12.0, -14.0, 5.0, 12.0, -10.0, 13.0, -1.0, 13.0, -3.0, -7.0, 12.0, 13.0, 8.0, -12.0, 13.0, 6.0, 11.0, -10.0, 7.0, 7.0, 11.0, 6.0, -15.0, 13.0, 9.0, -13.0, 12.0, 7.0, 3.0, 8.0, -9.0, 13.0, 12.0, -15.0, 11.0, 7.0, 13.0, 12.0, 317.0, 13.0, 9.0, -3.0, 11.0, -2.0, 5.0, -15.0, 12.0, 13.0, 11.0, -11.0, 12.0, 3.0, 5.0, 9.0, -8.0, 9.0, -5.0, 12.0, 4.0, 4.0, 8.0, -17.0, 13.0, 11.0, 12.0, -15.0, 12.0, 6.0, 6.0, -6.0, 6.0, 9.0, 9.0, 14.0, -2.0, -6.0, 8.0, -18.0, 12.0, 13.0, 12.0, -18.0, 8.0, 13.0, 12.0, -1.0, -9.0, 13.0, 2.0, 8.0, 6.0, -1.0, 6.0, -11.0, 7.0, 13.0, 11.0, 1.0, 11.0, -8.0, -6.0, 8.0, 4.0, 9.0, 12.0, -6.0, 11.0, -2.0, 8.0, -10.0, 6.0, 11.0, 12.0, -13.0, 12.0, 4.0, 8.0, 13.0, -15.0, 9.0, 9.0, -3.0, 10.0, -1.0, 8.0, -17.0, 13.0, 11.0, 7.0, -10.0, 13.0, 5.0, 13.0, 6.0, -17.0, 13.0, -2.0, -6.0, 11.0, 12.0, 5.0, -9.0, 10.0, 9.0, 12.0, -12.0, 7.0, 8.0, 8.0, 8.0, -14.0, 13.0, 7.0, -2.0, 11.0, -1.0, 8.0, -14.0, 11.0, 10.0, 12.0, -13.0, 10.0, 6.0, 10.0, 9.0, -17.0, 13.0, -4.0, -4.0, 11.0, 12.0, 6.0, -16.0, 13.0, 12.0, 12.0, 0.0, 11.0, -8.0, 8.0, 7.0, -9.0, 9.0, -5.0, -1.0, 10.0, 11.0, 13.0, 315.0, 13.0, 13.0, 11.0, -12.0, 3.0, 13.0, 9.0, 11.0, -18.0, 13.0, 0.0, -8.0, 11.0, 12.0, 11.0, -10.0, 1.0, 13.0, 5.0, -14.0, 11.0, 13.0, -2.0, -3.0, 7.0, 13.0, -2.0, -1.0, 6.0, 12.0, 5.0, 4.0, -5.0, 11.0, 12.0, -13.0, 11.0, 5.0, 12.0, 6.0, -16.0, 13.0, -9.0, 8.0, 4.0, 12.0, 13.0, 0.0, -1.0, 3.0, -4.0, 1.0, 11.0, 7.0, 5.0, 14.0, -16.0, 12.0, -6.0, 9.0, 0.0, 12.0, 9.0, 2.0, -9.0, 13.0, 12.0, -7.0, 10.0, 0.0, 5.0, 14.0, -17.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22075412359120422, "mean_inference_ms": 1.1755488476380718, "mean_action_processing_ms": 0.07187477203989977, "mean_env_wait_ms": 0.1795170227087723, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 804600, "agent_timesteps_total": 804519, "timers": {"sample_time_ms": 356.259, "sample_throughput": 15157.496, "learn_time_ms": 6486.396, "learn_throughput": 832.512, "update_time_ms": 11.446}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.7593749761581421, "cur_lr": 4.999999873689376e-05, "total_loss": 428.5166320800781, "policy_loss": -0.019415700808167458, "vf_loss": 428.5323486328125, "vf_explained_var": 0.237333282828331, "kl": 0.004869712982326746, "entropy": 0.4173367917537689, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 804600, "num_agent_steps_sampled": 804519, "num_steps_trained": 804600, "num_agent_steps_trained": 804519}, "done": false, "episodes_total": 15768, "training_iteration": 149, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-37", "timestamp": 1626861577, "time_this_iter_s": 6.805583715438843, "time_total_s": 1077.3710374832153, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70212d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1077.3710374832153, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 22.59, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 13.0, -4.0, 2.0, 0.0, 3.0, 0.0, 12.0, -14.0, 12.0, 7.0, 10.0, -2.0, 10.0, -3.0, 10.0, 6.0, 14.0, 11.0, -16.0, 13.0, -18.0, 10.0, 10.0, 0.0, 13.0, 12.0, -10.0, -12.0, 13.0, 8.0, 6.0, -4.0, 7.0, 10.0, 2.0, 12.0, -1.0, -3.0, 7.0, -17.0, 13.0, 9.0, 10.0, 3.0, 13.0, -10.0, 9.0, 12.0, -5.0, -3.0, 11.0, 9.0, -6.0, 2.0, 10.0, 6.0, 14.0, -14.0, 9.0, -1.0, 11.0, 8.0, -3.0, -10.0, 14.0, 12.0, -1.0, 12.0, -17.0, 9.0, 11.0, 3.0, 8.0, 9.0, -5.0, -20.0, 11.0, 12.0, 12.0, 2.0, 10.0, -7.0, 10.0, 14.0, -16.0, 8.0, 9.0, 6.0, 14.0, 0.0, -5.0, 7.0, 13.0, -9.0, 4.0, 5.0, 13.0, -5.0, 2.0, 11.0, -5.0, 0.0, 9.0, -14.0, 6.0, 11.0, 12.0, -2.0, 13.0, 11.0, -7.0, 3.0, 13.0, -5.0, 4.0, 13.0, -13.0, 9.0, 6.0, 3.0, 12.0, -10.0, 10.0, -15.0, 11.0, 11.0, 8.0, -4.0, 8.0, 10.0, 1.0, -3.0, 2.0, 4.0, 12.0, 6.0, 11.0, -9.0, 7.0, -12.0, 9.0, 8.0, 10.0, -4.0, 13.0, 11.0, -5.0, 7.0, -8.0, 7.0, 9.0, 5.0, 11.0, 10.0, -11.0, -18.0, 11.0, 11.0, 11.0, 10.0, 9.0, 11.0, -15.0, 13.0, -6.0, -3.0, 11.0, -6.0, 11.0, 9.0, 1.0, -1.0, 13.0, 6.0, -3.0, 12.0, 14.0, -6.0, -5.0, 9.0, -13.0, 9.0, 10.0, -10.0, 7.0, 9.0, 9.0, -6.0, 4.0, 9.0, 8.0, 2.0, 13.0, -5.0, 5.0, 6.0, -8.0, 7.0, 10.0, 7.0, 12.0, -11.0, 7.0, -16.0, 13.0, 7.0, 11.0, 6.0, 12.0, -2.0, -1.0, 9.0, -7.0, 3.0, 10.0, 4.0, 14.0, -10.0, 7.0, -12.0, 10.0, 12.0, 5.0, 9.0, 14.0, -4.0, -4.0, 5.0, -6.0, 10.0, 6.0, 4.0, 14.0, -5.0, 2.0, -15.0, 13.0, 5.0, 12.0, 6.0, 14.0, -7.0, 2.0, -1.0, -5.0, 9.0, 12.0, 2.0, 6.0, -4.0, 11.0, -5.0, 13.0, -2.0, 9.0, 2.0, 12.0, -3.0, 4.0, 9.0, -6.0, 3.0, 9.0, 5.0, 9.0, -9.0, 10.0, -14.0, 6.0, 11.0, 12.0, 3.0, 10.0, -5.0, 7.0, 7.0, -5.0, 5.0, 8.0, 4.0, 12.0, 6.0, -7.0, -16.0, 8.0, 12.0, 11.0, 7.0, 9.0, -8.0, 7.0, 9.0, -11.0, 7.0, 10.0, 3.0, 7.0, -3.0, 8.0, 7.0, 10.0, -5.0, 3.0, 11.0, 13.0, -4.0, -5.0, 4.0, -7.0, 10.0, 8.0, 4.0, 14.0, -13.0, 10.0, -16.0, 11.0, 12.0, 8.0, 8.0, 14.0, 10.0, -17.0, -12.0, 10.0, 10.0, 7.0, 3.0, 14.0, 10.0, -12.0, 319.0, 13.0, 11.0, 12.0, 2.0, 11.0, -2.0, 4.0, 8.0, -6.0, 4.0, 9.0, 4.0, 14.0, -11.0, 8.0, 0.0, 10.0, -5.0, 10.0, 11.0, 9.0, -3.0, -2.0, 2.0, -8.0, 11.0, 10.0, 5.0, 8.0, 11.0, -9.0, -10.0, 5.0, 8.0, 12.0, 4.0, 14.0, -4.0, 1.0, -2.0, 1.0, 6.0, 10.0, 7.0, 6.0, -9.0, 11.0, 0.0, 13.0, 0.0, 2.0, 6.0, 14.0, 11.0, -16.0, -1.0, 0.0, 6.0, 10.0, 6.0, 12.0, -13.0, 10.0, -18.0, 10.0, 12.0, 11.0, 7.0, 14.0, 8.0, -14.0, 12.0, -6.0, -2.0, 11.0, 13.0, -2.0, 8.0, -4.0, -5.0, -4.0, 12.0, 12.0, -6.0, 13.0, 9.0, -1.0, 12.0, -12.0, 6.0, 9.0, 7.0, 11.0, -4.0, 1.0, -2.0, 8.0, 11.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22076790770530824, "mean_inference_ms": 1.1755874334091008, "mean_action_processing_ms": 0.0718811411131583, "mean_env_wait_ms": 0.1795137881479759, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 810000, "agent_timesteps_total": 809919, "timers": {"sample_time_ms": 356.768, "sample_throughput": 15135.89, "learn_time_ms": 6464.395, "learn_throughput": 835.345, "update_time_ms": 11.441}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.37968748807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 241.2601776123047, "policy_loss": -0.027718883007764816, "vf_loss": 241.28379821777344, "vf_explained_var": 0.20138834416866302, "kl": 0.010710316710174084, "entropy": 0.44302430748939514, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 810000, "num_agent_steps_sampled": 809919, "num_steps_trained": 810000, "num_agent_steps_trained": 809919}, "done": false, "episodes_total": 15876, "training_iteration": 150, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-44", "timestamp": 1626861584, "time_this_iter_s": 6.8461081981658936, "time_total_s": 1084.2171456813812, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70212ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1084.2171456813812, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 22.04, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.444444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 323.0}, "policy_reward_mean": {"learned": 6.111111111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 3.0, 3.0, 10.0, -3.0, 6.0, 0.0, 12.0, 13.0, 7.0, 1.0, -6.0, -6.0, 7.0, 9.0, 5.0, 13.0, -18.0, 9.0, 11.0, -2.0, 9.0, -4.0, 12.0, 13.0, 11.0, -10.0, 1.0, 2.0, 11.0, 12.0, -10.0, -9.0, 7.0, 12.0, 5.0, -2.0, 8.0, -3.0, 12.0, 9.0, 9.0, 7.0, -10.0, -3.0, 8.0, 6.0, 4.0, 11.0, 323.0, 12.0, 10.0, 0.0, 4.0, 1.0, 10.0, 10.0, 9.0, -8.0, 4.0, -10.0, 5.0, 9.0, 11.0, 7.0, -4.0, 3.0, 9.0, -2.0, 7.0, -1.0, 11.0, 1.0, 12.0, -3.0, 5.0, -9.0, 7.0, 10.0, 7.0, -7.0, 2.0, 9.0, 11.0, -11.0, 9.0, 9.0, 8.0, 11.0, 13.0, -8.0, -1.0, 6.0, 9.0, 9.0, -9.0, 11.0, -8.0, 7.0, 5.0, 12.0, 9.0, -18.0, 12.0, 13.0, 7.0, 0.0, -5.0, -8.0, 11.0, 5.0, 7.0, 12.0, -18.0, 11.0, 10.0, -5.0, 9.0, 3.0, 8.0, 5.0, 9.0, -10.0, 11.0, -7.0, 12.0, 7.0, 3.0, 12.0, -9.0, 7.0, 5.0, -11.0, 14.0, 2.0, 10.0, 8.0, 8.0, 7.0, -8.0, -6.0, 8.0, 4.0, 9.0, 7.0, -8.0, 11.0, 5.0, 6.0, 9.0, -9.0, 9.0, 10.0, 11.0, 6.0, -12.0, -7.0, 7.0, 8.0, 7.0, -7.0, 3.0, 9.0, 10.0, 0.0, 14.0, 3.0, -2.0, 11.0, 5.0, -8.0, 7.0, -10.0, 8.0, 4.0, 13.0, 14.0, -14.0, 7.0, 8.0, 9.0, 14.0, -3.0, -5.0, 12.0, 9.0, 0.0, -6.0, 12.0, 7.0, -9.0, 5.0, 9.0, -5.0, 11.0, 0.0, -1.0, 4.0, 1.0, 11.0, 13.0, 5.0, -3.0, 0.0, -11.0, 9.0, 9.0, 8.0, 13.0, -18.0, 9.0, 11.0, -1.0, 4.0, 2.0, 10.0, 13.0, 9.0, 7.0, -14.0, 9.0, 11.0, 3.0, -8.0, -5.0, 4.0, 8.0, 8.0, 12.0, 9.0, -16.0, 10.0, 10.0, 11.0, 5.0, -11.0, 8.0, -2.0, 1.0, 8.0, 6.0, -10.0, 12.0, 7.0, -11.0, 14.0, 0.0, 12.0, 12.0, 6.0, 1.0, -4.0, -14.0, 12.0, 11.0, 6.0, 9.0, 10.0, 8.0, -12.0, -1.0, 14.0, -9.0, 11.0, 12.0, 6.0, -8.0, 5.0, 11.0, 7.0, -10.0, 7.0, 11.0, 320.0, 12.0, 12.0, 13.0, 9.0, -4.0, -3.0, 11.0, 5.0, -7.0, 6.0, -8.0, 12.0, 5.0, 6.0, 9.0, -6.0, 8.0, 4.0, -5.0, 5.0, 9.0, 6.0, 14.0, -1.0, -5.0, 7.0, -8.0, 7.0, 10.0, 6.0, 10.0, 6.0, -9.0, 8.0, -2.0, 9.0, 1.0, 7.0, 4.0, 9.0, 11.0, -9.0, -4.0, 7.0, 9.0, 3.0, 12.0, -16.0, 8.0, 11.0, -4.0, 6.0, 3.0, 10.0, 13.0, 6.0, -1.0, -3.0, 9.0, 5.0, 8.0, -7.0, 11.0, -19.0, 12.0, 11.0, 5.0, 6.0, -5.0, 9.0, 13.0, -2.0, 0.0, 4.0, -12.0, 11.0, 10.0, 6.0, 13.0, -18.0, 8.0, 12.0, -2.0, -1.0, 8.0, 10.0, 6.0, 9.0, 8.0, -8.0, 10.0, 3.0, 11.0, -9.0, 12.0, 319.0, 11.0, 12.0, -1.0, 9.0, -5.0, 12.0, 12.0, 2.0, 5.0, -4.0, -1.0, 11.0, -3.0, 8.0, 5.0, -11.0, 10.0, 11.0, -3.0, 9.0, 2.0, 7.0, 12.0, 10.0, 4.0, -11.0, -5.0, 7.0, 6.0, 7.0, 11.0, -17.0, 11.0, 10.0, -1.0, 10.0, -1.0, 7.0, 4.0, 7.0, -8.0, 12.0, -8.0, 7.0, 9.0, 7.0, 13.0, -8.0, 2.0, 8.0, -15.0, 14.0, 5.0, 11.0, 7.0, 11.0, 6.0, -9.0, -3.0, 9.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22078825194364218, "mean_inference_ms": 1.1757806455327193, "mean_action_processing_ms": 0.0718848066462804, "mean_env_wait_ms": 0.17953337292250945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 815400, "agent_timesteps_total": 815319, "timers": {"sample_time_ms": 358.562, "sample_throughput": 15060.176, "learn_time_ms": 6447.301, "learn_throughput": 837.56, "update_time_ms": 11.35}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.37968748807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 559.61962890625, "policy_loss": -0.02153865620493889, "vf_loss": 559.6381225585938, "vf_explained_var": 0.16777867078781128, "kl": 0.008138700388371944, "entropy": 0.4193353056907654, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 815400, "num_agent_steps_sampled": 815319, "num_steps_trained": 815400, "num_agent_steps_trained": 815319}, "done": false, "episodes_total": 15984, "training_iteration": 151, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-51", "timestamp": 1626861591, "time_this_iter_s": 6.829848289489746, "time_total_s": 1091.046993970871, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c9d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1091.046993970871, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 21.955555555555556, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 12.0, -4.0, -5.0, 11.0, -9.0, 2.0, 11.0, 8.0, 7.0, -10.0, 10.0, 10.0, -11.0, 6.0, 10.0, 12.0, 10.0, 2.0, -9.0, 9.0, 11.0, -7.0, 2.0, 12.0, 11.0, -20.0, 12.0, 9.0, 7.0, -11.0, 10.0, 11.0, -2.0, 12.0, -6.0, 11.0, 12.0, -11.0, 3.0, 4.0, 9.0, -5.0, 7.0, 7.0, -14.0, 11.0, 11.0, 9.0, 10.0, -13.0, 9.0, 10.0, -7.0, 8.0, 4.0, -1.0, 12.0, -8.0, 12.0, 7.0, 0.0, -3.0, 11.0, 8.0, 2.0, -8.0, 13.0, -3.0, 6.0, -1.0, 13.0, 7.0, 5.0, 12.0, -9.0, 9.0, -7.0, 11.0, 2.0, 10.0, -13.0, 12.0, 6.0, -5.0, 6.0, 11.0, 3.0, 11.0, -8.0, 2.0, 10.0, 10.0, 4.0, 2.0, -1.0, 6.0, 5.0, 7.0, -3.0, 11.0, -4.0, 1.0, 7.0, 7.0, 14.0, -13.0, 7.0, 9.0, -6.0, 8.0, 4.0, 12.0, -2.0, -2.0, 7.0, 8.0, -3.0, 4.0, 6.0, 4.0, 11.0, -10.0, 10.0, 8.0, -4.0, -2.0, 13.0, 13.0, 13.0, 6.0, -17.0, -7.0, 12.0, 7.0, 3.0, 8.0, 7.0, -11.0, 11.0, 14.0, 7.0, -2.0, -4.0, 13.0, -7.0, 4.0, 5.0, 12.0, 4.0, -10.0, 9.0, 7.0, 3.0, -6.0, 11.0, 14.0, 6.0, -8.0, 3.0, 13.0, -13.0, 7.0, 8.0, -1.0, 8.0, 1.0, 7.0, 12.0, 10.0, -19.0, 12.0, 10.0, -8.0, 6.0, 7.0, -13.0, 14.0, 9.0, 5.0, -4.0, 6.0, 1.0, 12.0, -5.0, 2.0, 7.0, 11.0, 13.0, 8.0, 1.0, -7.0, 9.0, 10.0, 11.0, -15.0, 12.0, -3.0, -7.0, 13.0, 10.0, 4.0, -12.0, 13.0, 4.0, -11.0, 10.0, 12.0, 10.0, 0.0, 2.0, 3.0, -2.0, 4.0, 6.0, 7.0, 13.0, 7.0, 7.0, -12.0, 9.0, -15.0, 8.0, 13.0, 10.0, -7.0, 1.0, 11.0, 5.0, -11.0, 8.0, 13.0, 9.0, 6.0, -11.0, 11.0, 9.0, 5.0, -7.0, 8.0, 9.0, 7.0, 1.0, -2.0, 11.0, 11.0, -15.0, 8.0, 12.0, 7.0, -16.0, 12.0, 12.0, 6.0, -9.0, 6.0, 11.0, -6.0, 3.0, 7.0, -5.0, 11.0, 2.0, 7.0, 9.0, 11.0, -17.0, 12.0, 12.0, 7.0, 0.0, -4.0, 6.0, -7.0, 8.0, 8.0, 14.0, 11.0, -7.0, -3.0, -10.0, 11.0, 2.0, 12.0, 14.0, -15.0, 6.0, 10.0, 9.0, -4.0, 9.0, 1.0, 11.0, -7.0, 1.0, 10.0, 7.0, 10.0, -15.0, 13.0, 6.0, 4.0, 6.0, -1.0, 10.0, -10.0, 5.0, 10.0, 11.0, 11.0, -19.0, 12.0, 8.0, 4.0, -9.0, 12.0, 10.0, 8.0, -12.0, 9.0, 7.0, -3.0, 8.0, 3.0, 13.0, 10.0, -5.0, -3.0, 6.0, 9.0, -13.0, 13.0, 12.0, -9.0, 7.0, 5.0, 10.0, -9.0, 1.0, 13.0, 13.0, 12.0, 318.0, 11.0, 7.0, 8.0, -11.0, 11.0, 8.0, 4.0, -4.0, 7.0, 9.0, 6.0, 12.0, -12.0, 13.0, -4.0, 1.0, 5.0, -1.0, 10.0, -6.0, 12.0, 11.0, -1.0, 6.0, -1.0, 5.0, 14.0, -10.0, 6.0, 0.0, 5.0, 5.0, 5.0, 11.0, 4.0, 3.0, -3.0, 9.0, 7.0, 4.0, -5.0, 9.0, 0.0, 9.0, -3.0, 9.0, 9.0, -14.0, 11.0, 6.0, 6.0, -6.0, 9.0, 14.0, -7.0, 4.0, 4.0, 10.0, -3.0, 7.0, 1.0, 0.0, 7.0, 5.0, 3.0, 11.0, 6.0, -14.0, 12.0, 10.0, -6.0, 5.0, 6.0, 3.0, -4.0, 3.0, 13.0, 9.0, 5.0, -11.0, 12.0, 8.0, 10.0, -10.0, 7.0, 10.0, -14.0, 7.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2207427179151845, "mean_inference_ms": 1.1757907010431021, "mean_action_processing_ms": 0.07188689786596945, "mean_env_wait_ms": 0.1795421699131212, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 820800, "agent_timesteps_total": 820746, "timers": {"sample_time_ms": 358.243, "sample_throughput": 15073.585, "learn_time_ms": 6410.775, "learn_throughput": 842.332, "update_time_ms": 11.295}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.37968748807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 219.96343994140625, "policy_loss": -0.03440108895301819, "vf_loss": 219.99298095703125, "vf_explained_var": 0.2543345093727112, "kl": 0.01274807658046484, "entropy": 0.469204306602478, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 820800, "num_agent_steps_sampled": 820746, "num_steps_trained": 820800, "num_agent_steps_trained": 820746}, "done": false, "episodes_total": 16092, "training_iteration": 152, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_11-59-58", "timestamp": 1626861598, "time_this_iter_s": 6.839174270629883, "time_total_s": 1097.8861682415009, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1097.8861682415009, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 21.999999999999996, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.555555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 6.888888888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -18.0, 13.0, 9.0, -14.0, 9.0, 8.0, 12.0, 11.0, 11.0, -15.0, 8.0, -10.0, 4.0, 10.0, 11.0, 4.0, 3.0, -2.0, 10.0, 6.0, -7.0, 5.0, 11.0, 6.0, 7.0, -7.0, 9.0, -6.0, 3.0, 8.0, 10.0, 11.0, -13.0, 6.0, 11.0, 11.0, -13.0, 5.0, 12.0, 13.0, 7.0, -18.0, 13.0, 9.0, 4.0, -6.0, 8.0, 13.0, -5.0, 11.0, -4.0, -10.0, 9.0, 4.0, 12.0, 8.0, 6.0, -12.0, 13.0, 12.0, 3.0, -7.0, 7.0, 13.0, -12.0, 4.0, 10.0, -8.0, 9.0, 2.0, 12.0, 9.0, 3.0, -5.0, 8.0, -7.0, 7.0, 7.0, 8.0, 11.0, 318.0, 12.0, 13.0, 13.0, 14.0, -20.0, 8.0, 12.0, 10.0, -20.0, 13.0, -8.0, 7.0, 6.0, 10.0, 12.0, -14.0, 12.0, 5.0, 13.0, 14.0, 317.0, 10.0, 12.0, 6.0, -16.0, 13.0, -3.0, 3.0, 5.0, 10.0, 12.0, -18.0, 10.0, 11.0, 5.0, -3.0, 2.0, 11.0, 12.0, -2.0, -3.0, 8.0, 14.0, 4.0, -4.0, 1.0, 11.0, -14.0, 7.0, 11.0, -15.0, 7.0, 11.0, 12.0, 6.0, -9.0, 10.0, 8.0, 11.0, -2.0, -7.0, 13.0, 6.0, 12.0, -8.0, 5.0, -14.0, 9.0, 9.0, 11.0, 9.0, -9.0, 10.0, 5.0, -2.0, 4.0, 5.0, 8.0, 12.0, 0.0, -8.0, 11.0, 0.0, 9.0, -7.0, 13.0, 6.0, -2.0, -2.0, 13.0, 11.0, 2.0, -9.0, 11.0, 11.0, 317.0, 13.0, 12.0, -9.0, 4.0, 8.0, 12.0, 4.0, -4.0, 2.0, 13.0, 9.0, 1.0, -7.0, 12.0, 6.0, 2.0, -1.0, 8.0, 7.0, 6.0, -10.0, 12.0, 9.0, -10.0, 7.0, 9.0, 12.0, 3.0, 6.0, -6.0, 11.0, -17.0, 11.0, 10.0, 13.0, 1.0, 4.0, -3.0, 12.0, -5.0, -5.0, 13.0, 14.0, 2.0, -6.0, 5.0, 8.0, -18.0, 13.0, 12.0, 4.0, -8.0, 7.0, 12.0, 14.0, -5.0, -7.0, 13.0, -1.0, 12.0, -5.0, 9.0, 13.0, 1.0, -7.0, 8.0, 13.0, 14.0, 318.0, 10.0, 9.0, -11.0, 4.0, 13.0, -13.0, 9.0, 6.0, 13.0, 12.0, -17.0, 13.0, 7.0, -11.0, 5.0, 9.0, 12.0, 13.0, -9.0, 0.0, 11.0, 8.0, 0.0, -5.0, 12.0, 3.0, 3.0, -1.0, 10.0, -15.0, 8.0, 10.0, 12.0, 9.0, 12.0, -4.0, -2.0, -10.0, 4.0, 8.0, 13.0, 0.0, 12.0, -5.0, 8.0, 10.0, 9.0, -15.0, 11.0, 10.0, -12.0, 10.0, 7.0, 7.0, -1.0, -4.0, 13.0, 12.0, -5.0, -2.0, 10.0, -13.0, 5.0, 11.0, 12.0, 12.0, -6.0, -4.0, 13.0, 11.0, 0.0, -6.0, 10.0, 12.0, -4.0, -2.0, 9.0, -6.0, 5.0, 5.0, 11.0, 12.0, -3.0, -1.0, 7.0, 5.0, 1.0, -3.0, 12.0, 13.0, -4.0, 10.0, -4.0, -13.0, 9.0, 9.0, 10.0, 10.0, -16.0, 12.0, 9.0, 5.0, 2.0, -4.0, 12.0, 7.0, -15.0, 13.0, 10.0, -11.0, 7.0, 9.0, 10.0, 10.0, 11.0, -17.0, 11.0, -5.0, 1.0, 10.0, 9.0, 11.0, -18.0, 12.0, 10.0, 5.0, -10.0, 8.0, 12.0, 12.0, 3.0, -6.0, 6.0, 12.0, 1.0, -6.0, 8.0, 13.0, -5.0, 9.0, -2.0, 13.0, 6.0, -16.0, 12.0, 6.0, 11.0, -14.0, 12.0, -1.0, 8.0, 4.0, 4.0, 12.0, 7.0, -13.0, 9.0, -13.0, 9.0, 8.0, 11.0, 8.0, 5.0, 10.0, -8.0, -4.0, 8.0, 8.0, 3.0, 11.0, -19.0, 13.0, 10.0, -2.0, 4.0, 2.0, 11.0, 13.0, -11.0, 5.0, 8.0, -1.0, 3.0, 8.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22066523523166565, "mean_inference_ms": 1.1758071463494564, "mean_action_processing_ms": 0.07188758703599969, "mean_env_wait_ms": 0.1795456505652608, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 826200, "agent_timesteps_total": 826200, "timers": {"sample_time_ms": 358.466, "sample_throughput": 15064.177, "learn_time_ms": 6388.231, "learn_throughput": 845.304, "update_time_ms": 11.182}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.37968748807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 823.504150390625, "policy_loss": -0.029065730050206184, "vf_loss": 823.5297241210938, "vf_explained_var": 0.12181961536407471, "kl": 0.009365985170006752, "entropy": 0.47979074716567993, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 826200, "num_agent_steps_sampled": 826200, "num_steps_trained": 826200, "num_agent_steps_trained": 826200}, "done": false, "episodes_total": 16200, "training_iteration": 153, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-00-05", "timestamp": 1626861605, "time_this_iter_s": 6.880378246307373, "time_total_s": 1104.7665464878082, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c8c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1104.7665464878082, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 22.080000000000002, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.38, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 4.0, 10.0, 11.0, 12.0, 10.0, 7.0, -14.0, -8.0, 11.0, 5.0, 7.0, -4.0, 5.0, 6.0, 8.0, 11.0, -13.0, 9.0, 8.0, 8.0, 10.0, -14.0, 11.0, -7.0, 4.0, 8.0, 10.0, 5.0, 14.0, 7.0, -11.0, 8.0, 9.0, -14.0, 12.0, -6.0, 10.0, 2.0, 9.0, -2.0, 0.0, 10.0, 7.0, -12.0, 12.0, 4.0, 11.0, 8.0, -3.0, -2.0, 12.0, 13.0, -9.0, 6.0, 5.0, 10.0, 6.0, 5.0, -6.0, 10.0, -15.0, 9.0, 11.0, 10.0, 2.0, 11.0, -8.0, 5.0, 6.0, -9.0, 13.0, -11.0, 13.0, 5.0, 8.0, 13.0, -13.0, 9.0, 6.0, 14.0, 5.0, -11.0, 7.0, -6.0, 3.0, 7.0, 11.0, -4.0, 12.0, 9.0, -2.0, 12.0, 12.0, 316.0, 13.0, -6.0, 6.0, 5.0, 10.0, 10.0, 7.0, 10.0, -12.0, 7.0, 10.0, -10.0, 8.0, -5.0, 5.0, 7.0, 8.0, -3.0, 14.0, 6.0, -2.0, 14.0, 7.0, -18.0, 12.0, 12.0, -9.0, 10.0, 2.0, 14.0, -13.0, 8.0, 6.0, -12.0, 9.0, 9.0, 9.0, -4.0, 5.0, 3.0, 11.0, 10.0, -10.0, 10.0, 5.0, -11.0, 10.0, 3.0, 13.0, -10.0, 14.0, 1.0, 10.0, 13.0, -9.0, 7.0, 4.0, 4.0, 10.0, -6.0, 7.0, -2.0, 5.0, 8.0, 4.0, -2.0, 13.0, 9.0, -5.0, 8.0, 8.0, -8.0, 7.0, -7.0, 5.0, 5.0, 12.0, 11.0, 13.0, 9.0, -18.0, -13.0, 9.0, 11.0, 8.0, -4.0, 11.0, 0.0, 8.0, 8.0, 12.0, 8.0, -13.0, -11.0, 10.0, 7.0, 9.0, -4.0, 12.0, -2.0, 9.0, -11.0, 13.0, 8.0, 5.0, 7.0, 9.0, -13.0, 12.0, -6.0, 9.0, 9.0, 3.0, -10.0, 12.0, 12.0, 1.0, 6.0, 11.0, 3.0, -5.0, -12.0, 9.0, 8.0, 10.0, 8.0, 13.0, 8.0, -14.0, 8.0, 9.0, 3.0, -5.0, -4.0, 5.0, 5.0, 9.0, 7.0, 12.0, 11.0, -15.0, -8.0, 12.0, -2.0, 13.0, 12.0, -6.0, 0.0, 9.0, -12.0, 14.0, 9.0, 4.0, 4.0, 12.0, -14.0, 13.0, 8.0, -9.0, 10.0, 6.0, 7.0, 4.0, 11.0, -7.0, 10.0, 8.0, -15.0, 12.0, -6.0, 4.0, 7.0, 10.0, 6.0, 13.0, 6.0, -10.0, -9.0, 11.0, 5.0, 8.0, -1.0, 5.0, 4.0, 7.0, -5.0, 13.0, 7.0, 0.0, 11.0, 8.0, -13.0, 9.0, -5.0, 4.0, 10.0, 6.0, 10.0, 7.0, 8.0, -10.0, 8.0, 8.0, -13.0, 12.0, 13.0, 5.0, 10.0, -13.0, 13.0, 7.0, 9.0, -14.0, 9.0, 5.0, -11.0, 12.0, 9.0, 5.0, 10.0, -9.0, 0.0, 10.0, 7.0, -2.0, 8.0, 13.0, -5.0, -1.0, -11.0, 7.0, 9.0, 10.0, 10.0, 11.0, -17.0, 11.0, -5.0, 1.0, 10.0, 9.0, 11.0, -18.0, 12.0, 10.0, 5.0, -10.0, 8.0, 12.0, 12.0, 3.0, -6.0, 6.0, 12.0, 1.0, -6.0, 8.0, 13.0, -5.0, 9.0, -2.0, 13.0, 6.0, -16.0, 12.0, 6.0, 11.0, -14.0, 12.0, -1.0, 8.0, 4.0, 4.0, 12.0, 7.0, -13.0, 9.0, -13.0, 9.0, 8.0, 11.0, 8.0, 5.0, 10.0, -8.0, -4.0, 8.0, 8.0, 3.0, 11.0, -19.0, 13.0, 10.0, -2.0, 4.0, 2.0, 11.0, 13.0, -11.0, 5.0, 8.0, -1.0, 3.0, 8.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.220527556808114, "mean_inference_ms": 1.1747771467884633, "mean_action_processing_ms": 0.0718971201434622, "mean_env_wait_ms": 0.1794518261054659, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 831600, "agent_timesteps_total": 831519, "timers": {"sample_time_ms": 358.313, "sample_throughput": 15070.628, "learn_time_ms": 6355.96, "learn_throughput": 849.596, "update_time_ms": 11.205}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.37968748807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 227.58938598632812, "policy_loss": -0.03320169448852539, "vf_loss": 227.6181182861328, "vf_explained_var": 0.20767056941986084, "kl": 0.011708737351000309, "entropy": 0.4758893847465515, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 831600, "num_agent_steps_sampled": 831519, "num_steps_trained": 831600, "num_agent_steps_trained": 831519}, "done": false, "episodes_total": 16281, "training_iteration": 154, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-00-12", "timestamp": 1626861612, "time_this_iter_s": 6.71318507194519, "time_total_s": 1111.4797315597534, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022dc80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1111.4797315597534, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 21.96, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -2.0, 5.0, 4.0, 11.0, 2.0, 9.0, -7.0, 7.0, 5.0, 7.0, -4.0, 7.0, 6.0, 4.0, -2.0, 9.0, 3.0, -9.0, 12.0, 11.0, 10.0, 7.0, -13.0, 13.0, 10.0, -20.0, 12.0, 7.0, -5.0, 7.0, 6.0, 0.0, -2.0, 10.0, 7.0, 5.0, 1.0, 12.0, -3.0, 13.0, 3.0, -13.0, 12.0, 8.0, 12.0, -12.0, 7.0, 4.0, -1.0, 6.0, 6.0, 5.0, 7.0, 10.0, -7.0, 8.0, -5.0, 0.0, 12.0, 5.0, -5.0, 10.0, 5.0, 4.0, 0.0, 11.0, 0.0, 8.0, 7.0, -3.0, 3.0, 13.0, -9.0, 3.0, 8.0, 8.0, -13.0, 13.0, 7.0, 13.0, 9.0, -11.0, 4.0, 10.0, 13.0, -3.0, -5.0, 0.0, 14.0, 11.0, -10.0, 9.0, -5.0, 4.0, 7.0, 2.0, -1.0, 3.0, 11.0, 8.0, 4.0, -4.0, 7.0, 13.0, -10.0, 0.0, 12.0, 6.0, -10.0, 7.0, 12.0, 11.0, -1.0, 10.0, -5.0, 10.0, 7.0, -12.0, 10.0, 4.0, -11.0, 13.0, 9.0, 12.0, -17.0, 11.0, 9.0, 7.0, 6.0, 12.0, -10.0, 6.0, 9.0, 10.0, -10.0, 7.0, 14.0, 6.0, -12.0, 13.0, -15.0, 11.0, 6.0, -10.0, 7.0, 12.0, 6.0, 9.0, 13.0, 7.0, -14.0, 5.0, 13.0, 13.0, -16.0, 6.0, -5.0, 9.0, 5.0, 3.0, 0.0, 10.0, 2.0, 10.0, 8.0, -8.0, 5.0, 13.0, 3.0, -13.0, 12.0, 9.0, 8.0, -6.0, 4.0, -2.0, -5.0, 9.0, 13.0, 12.0, 11.0, 3.0, -11.0, 14.0, -6.0, 5.0, 2.0, 6.0, 7.0, -1.0, 3.0, 3.0, -5.0, 8.0, 9.0, 12.0, 11.0, 5.0, -13.0, 5.0, -7.0, 6.0, 11.0, 13.0, -7.0, 11.0, -2.0, 10.0, -7.0, 0.0, 12.0, 11.0, 7.0, 6.0, -9.0, 2.0, -1.0, 6.0, 8.0, 6.0, 10.0, -7.0, 6.0, 5.0, 11.0, -13.0, 12.0, 13.0, 6.0, -1.0, -3.0, 13.0, 3.0, -10.0, 9.0, 9.0, -4.0, -1.0, 11.0, 3.0, 13.0, -6.0, 5.0, 12.0, 3.0, -3.0, 3.0, -13.0, 9.0, 12.0, 7.0, 9.0, 8.0, -3.0, 1.0, 3.0, -2.0, 9.0, 5.0, 11.0, 4.0, 8.0, -8.0, 13.0, 7.0, -14.0, 9.0, 6.0, 6.0, -3.0, 6.0, 13.0, 7.0, -4.0, -1.0, 13.0, 14.0, -12.0, 0.0, -9.0, 7.0, 6.0, 11.0, 6.0, 4.0, 7.0, -2.0, 5.0, -8.0, 6.0, 12.0, 13.0, 7.0, 12.0, -17.0, 9.0, -4.0, 9.0, 1.0, 5.0, -2.0, -1.0, 13.0, 13.0, 13.0, -13.0, 2.0, 5.0, 6.0, 6.0, -2.0, 8.0, 5.0, 6.0, -4.0, 5.0, 9.0, -1.0, 2.0, -14.0, 13.0, 3.0, 13.0, 9.0, 8.0, 8.0, -10.0, 10.0, 12.0, -4.0, -3.0, 8.0, 13.0, 10.0, -16.0, 2.0, 13.0, 6.0, -6.0, 5.0, 13.0, -8.0, 5.0, 8.0, -8.0, 7.0, 8.0, 8.0, 5.0, 9.0, -7.0, 5.0, 13.0, -9.0, 6.0, 11.0, 6.0, 5.0, -7.0, -2.0, 11.0, 10.0, -4.0, 9.0, -15.0, 9.0, 12.0, 4.0, 11.0, 10.0, -10.0, 11.0, 9.0, 4.0, -9.0, 13.0, 8.0, 3.0, -9.0, 9.0, 1.0, 7.0, -2.0, 3.0, 0.0, 11.0, 1.0, 8.0, 2.0, -7.0, 12.0, 0.0, 12.0, 10.0, -7.0, 8.0, 2.0, 7.0, -2.0, 12.0, -3.0, 0.0, 6.0, 7.0, 7.0, -3.0, 4.0, 8.0, 11.0, 8.0, -12.0, 6.0, -10.0, 13.0, 6.0, -10.0, 12.0, 7.0, 6.0, 13.0, 8.0, -16.0, 10.0, 9.0, 10.0, 0.0, -4.0, 13.0, -4.0, 8.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22070313616799775, "mean_inference_ms": 1.1758821343313786, "mean_action_processing_ms": 0.07189742436099254, "mean_env_wait_ms": 0.17956583555455052, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 837000, "agent_timesteps_total": 836919, "timers": {"sample_time_ms": 357.259, "sample_throughput": 15115.089, "learn_time_ms": 6357.262, "learn_throughput": 849.422, "update_time_ms": 11.134}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.37968748807907104, "cur_lr": 4.999999873689376e-05, "total_loss": 27.255271911621094, "policy_loss": -0.07756780833005905, "vf_loss": 27.324010848999023, "vf_explained_var": 0.20925657451152802, "kl": 0.023248257115483284, "entropy": 0.4392636716365814, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 837000, "num_agent_steps_sampled": 836919, "num_steps_trained": 837000, "num_agent_steps_trained": 836919}, "done": false, "episodes_total": 16389, "training_iteration": 155, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-00-19", "timestamp": 1626861619, "time_this_iter_s": 6.8058788776397705, "time_total_s": 1118.2856104373932, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022dd90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1118.2856104373932, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 22.500000000000004, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12962962962963, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.532407407407407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [2.0, -4.0, 5.0, 12.0, 4.0, 12.0, -9.0, 8.0, 14.0, -1.0, 3.0, -1.0, 7.0, 12.0, -5.0, 1.0, 5.0, 11.0, 12.0, -13.0, -1.0, -9.0, 12.0, 13.0, 6.0, -8.0, 6.0, 11.0, 7.0, 13.0, -16.0, 11.0, 3.0, -6.0, 12.0, 6.0, 8.0, 9.0, -13.0, 11.0, 13.0, 9.0, 4.0, -11.0, 12.0, 8.0, 5.0, -10.0, 1.0, 8.0, -2.0, 8.0, -9.0, 2.0, 10.0, 12.0, 6.0, -7.0, 4.0, 12.0, 14.0, -3.0, 12.0, -8.0, 7.0, -8.0, 12.0, 4.0, 1.0, 13.0, -11.0, 12.0, 7.0, 11.0, -14.0, 11.0, 13.0, 13.0, 9.0, -20.0, -6.0, 11.0, -2.0, 12.0, 7.0, 4.0, -2.0, 6.0, 3.0, 12.0, 6.0, -6.0, 13.0, 13.0, -15.0, 4.0, -3.0, 11.0, 11.0, -4.0, 5.0, -5.0, 3.0, 12.0, 5.0, 11.0, -14.0, 13.0, 13.0, -18.0, 10.0, 10.0, 6.0, -7.0, 11.0, 5.0, 4.0, 4.0, -4.0, 11.0, 5.0, 13.0, -14.0, 11.0, 9.0, -5.0, 5.0, 6.0, 4.0, 7.0, -8.0, 12.0, -1.0, 9.0, -6.0, 13.0, 11.0, 7.0, 4.0, -7.0, 9.0, 12.0, -5.0, -1.0, -15.0, 10.0, 11.0, 9.0, 4.0, 10.0, -11.0, 12.0, 6.0, 10.0, 8.0, -9.0, 14.0, 9.0, 6.0, -14.0, 6.0, 11.0, 11.0, -13.0, 9.0, 0.0, -1.0, 7.0, 10.0, 13.0, -19.0, 11.0, 5.0, 12.0, -13.0, 11.0, -1.0, -7.0, 11.0, 12.0, 5.0, 8.0, -11.0, 13.0, 9.0, 7.0, 1.0, -2.0, 12.0, 13.0, -13.0, 3.0, -12.0, 10.0, 12.0, 5.0, 11.0, 11.0, -11.0, 4.0, 8.0, 11.0, -3.0, -1.0, 3.0, 13.0, -3.0, 2.0, 7.0, 6.0, -1.0, 3.0, 7.0, 9.0, -11.0, 10.0, 4.0, 7.0, 6.0, -2.0, 9.0, 8.0, -11.0, 9.0, 6.0, -6.0, 12.0, 3.0, -8.0, 1.0, 13.0, 9.0, 6.0, 5.0, 7.0, -3.0, 2.0, 13.0, 4.0, -4.0, 1.0, 9.0, -3.0, 8.0, 7.0, 9.0, -8.0, 7.0, 7.0, -5.0, 2.0, 11.0, 14.0, 8.0, -2.0, -5.0, 6.0, -7.0, 11.0, 5.0, 13.0, 2.0, -8.0, 8.0, 13.0, 6.0, -11.0, 7.0, 12.0, 8.0, -10.0, 5.0, 3.0, 11.0, -2.0, 3.0, 10.0, 7.0, -14.0, 12.0, 6.0, 5.0, -8.0, 12.0, 6.0, 13.0, 2.0, -6.0, -3.0, -1.0, 11.0, 8.0, 7.0, 10.0, -15.0, 13.0, 4.0, 9.0, 4.0, -2.0, 7.0, 12.0, -9.0, 5.0, 6.0, -7.0, 9.0, 7.0, 14.0, -13.0, 7.0, 7.0, 6.0, 12.0, 7.0, -10.0, 14.0, 317.0, 11.0, 11.0, 4.0, 11.0, 11.0, -11.0, 8.0, 11.0, -9.0, 5.0, 0.0, 12.0, 6.0, -3.0, 13.0, 13.0, 7.0, -18.0, 5.0, 5.0, 7.0, -2.0, 3.0, 11.0, -11.0, 12.0, 4.0, 5.0, 8.0, -2.0, 14.0, 12.0, 4.0, -15.0, 0.0, 12.0, 6.0, -3.0, 6.0, 9.0, -10.0, 10.0, 10.0, 9.0, -1.0, -3.0, 14.0, -11.0, 11.0, 1.0, 6.0, 8.0, 12.0, -11.0, 12.0, 8.0, -17.0, 12.0, 7.0, 9.0, 3.0, -4.0, 7.0, 9.0, -11.0, 10.0, -16.0, 13.0, 11.0, 7.0, 3.0, 12.0, -12.0, 12.0, 12.0, 3.0, -6.0, 6.0, 7.0, 2.0, -5.0, 11.0, 7.0, -5.0, 11.0, 2.0, -9.0, 9.0, 3.0, 12.0, 12.0, 9.0, -3.0, -3.0, 9.0, -3.0, 11.0, -2.0, 8.0, -14.0, 10.0, 11.0, 9.0, 5.0, 4.0, -3.0, 6.0, 11.0, -9.0, 7.0, 7.0, 13.0, -12.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2207529458695031, "mean_inference_ms": 1.1759943339166519, "mean_action_processing_ms": 0.07191109474488896, "mean_env_wait_ms": 0.17957544076654505, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 842400, "agent_timesteps_total": 842319, "timers": {"sample_time_ms": 355.016, "sample_throughput": 15210.58, "learn_time_ms": 6356.91, "learn_throughput": 849.469, "update_time_ms": 11.066}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 230.83416748046875, "policy_loss": -0.027943510562181473, "vf_loss": 230.85760498046875, "vf_explained_var": 0.20727784931659698, "kl": 0.007896725088357925, "entropy": 0.44696244597435, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 842400, "num_agent_steps_sampled": 842319, "num_steps_trained": 842400, "num_agent_steps_trained": 842319}, "done": false, "episodes_total": 16497, "training_iteration": 156, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-00-26", "timestamp": 1626861626, "time_this_iter_s": 6.870159387588501, "time_total_s": 1125.1557698249817, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7022dae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1125.1557698249817, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 22.07, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 5.0, -16.0, 13.0, 10.0, 8.0, -8.0, 5.0, 8.0, 11.0, -2.0, -2.0, 9.0, -9.0, 9.0, 6.0, 2.0, 8.0, -3.0, 8.0, -11.0, 2.0, 13.0, 11.0, 14.0, 6.0, -15.0, 10.0, -3.0, -1.0, 12.0, 7.0, 7.0, -15.0, 10.0, 13.0, -9.0, 4.0, 11.0, 9.0, -2.0, 8.0, -4.0, 13.0, 10.0, -12.0, 11.0, 6.0, -6.0, 3.0, 7.0, 11.0, -6.0, 3.0, 7.0, 11.0, 13.0, 7.0, -2.0, -3.0, -4.0, 1.0, 11.0, 7.0, -5.0, 7.0, 6.0, 7.0, 1.0, 5.0, -1.0, 10.0, 1.0, 7.0, -1.0, 8.0, -10.0, 0.0, 13.0, 12.0, 10.0, 2.0, -3.0, 6.0, 7.0, 7.0, -6.0, 7.0, 0.0, 12.0, -9.0, 12.0, 8.0, -8.0, 4.0, 11.0, 12.0, 4.0, -11.0, 10.0, 5.0, 4.0, -2.0, 8.0, 11.0, 11.0, 13.0, -20.0, -10.0, 5.0, 13.0, 7.0, 13.0, 0.0, -11.0, 13.0, -16.0, 9.0, 13.0, 9.0, 8.0, 11.0, -2.0, -2.0, 1.0, -2.0, 11.0, 5.0, -6.0, 7.0, 6.0, 8.0, -8.0, 2.0, 10.0, 11.0, 6.0, -3.0, 13.0, -1.0, 5.0, -9.0, 12.0, 7.0, 7.0, -2.0, -3.0, 13.0, -9.0, 4.0, 11.0, 9.0, 7.0, 3.0, 12.0, -7.0, -12.0, 5.0, 11.0, 11.0, -7.0, 2.0, 7.0, 13.0, 6.0, 4.0, 10.0, -5.0, 7.0, 1.0, -2.0, 9.0, -14.0, 7.0, 10.0, 12.0, -2.0, 1.0, 12.0, 4.0, 3.0, 3.0, -2.0, 11.0, 10.0, -10.0, 4.0, 11.0, 10.0, -12.0, 7.0, 10.0, 12.0, 7.0, -11.0, 7.0, -10.0, 5.0, 13.0, 7.0, 10.0, 5.0, -1.0, 1.0, 12.0, -15.0, 11.0, 7.0, -2.0, 3.0, 1.0, 13.0, -6.0, 0.0, 13.0, 8.0, 4.0, 9.0, -6.0, 8.0, 11.0, -21.0, 13.0, 12.0, 11.0, 6.0, -3.0, 1.0, 12.0, 4.0, 8.0, -9.0, 5.0, 11.0, -2.0, 1.0, -12.0, 10.0, 10.0, 7.0, -7.0, 3.0, 7.0, 12.0, -1.0, -2.0, 8.0, 10.0, 1.0, 6.0, 10.0, -2.0, 12.0, -17.0, 8.0, 12.0, 11.0, 3.0, -3.0, 4.0, 5.0, 5.0, 10.0, -5.0, 12.0, 8.0, 12.0, -17.0, 11.0, -16.0, 13.0, 7.0, 6.0, 12.0, -10.0, 7.0, -9.0, 1.0, 12.0, 11.0, 11.0, 7.0, -6.0, 3.0, -10.0, 5.0, 11.0, 9.0, 10.0, 6.0, -2.0, 1.0, -1.0, 14.0, 8.0, -6.0, 11.0, 11.0, -15.0, 8.0, -11.0, 12.0, 6.0, 8.0, 9.0, 1.0, -8.0, 13.0, 10.0, 1.0, 8.0, -4.0, 6.0, 12.0, 4.0, -7.0, -8.0, 4.0, 12.0, 7.0, 12.0, 3.0, -13.0, 13.0, -8.0, 5.0, 10.0, 8.0, 6.0, 4.0, -7.0, 12.0, 13.0, -3.0, 0.0, 5.0, 7.0, 12.0, 5.0, -9.0, -4.0, -3.0, 13.0, 9.0, 5.0, 7.0, 12.0, -9.0, 13.0, -13.0, 3.0, 12.0, 3.0, 11.0, -2.0, 3.0, 7.0, 8.0, -4.0, 4.0, 4.0, -9.0, 13.0, 7.0, -9.0, 4.0, 13.0, 7.0, 8.0, 3.0, -6.0, 10.0, 6.0, 2.0, 11.0, -4.0, 7.0, 10.0, -1.0, -1.0, -2.0, 2.0, 8.0, 7.0, 10.0, 0.0, -3.0, 8.0, 1.0, 5.0, 13.0, -4.0, 12.0, -5.0, 0.0, 8.0, -8.0, 3.0, 13.0, 7.0, 4.0, 7.0, 10.0, -6.0, -15.0, 8.0, 12.0, 10.0, 10.0, 12.0, -5.0, -2.0, 1.0, -7.0, 11.0, 10.0, 11.0, 6.0, -9.0, 7.0, 9.0, 9.0, 6.0, -9.0, 10.0, 12.0, -1.0, -6.0, 10.0, -11.0, 6.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22078894913287736, "mean_inference_ms": 1.1760023555298458, "mean_action_processing_ms": 0.07191336953142112, "mean_env_wait_ms": 0.17958498773923678, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 847800, "agent_timesteps_total": 847719, "timers": {"sample_time_ms": 354.75, "sample_throughput": 15221.986, "learn_time_ms": 6357.084, "learn_throughput": 849.446, "update_time_ms": 10.908}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 22.86176872253418, "policy_loss": -0.0762171745300293, "vf_loss": 22.928102493286133, "vf_explained_var": 0.28473538160324097, "kl": 0.01735171489417553, "entropy": 0.4386872947216034, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 847800, "num_agent_steps_sampled": 847719, "num_steps_trained": 847800, "num_agent_steps_trained": 847719}, "done": false, "episodes_total": 16605, "training_iteration": 157, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-00-32", "timestamp": 1626861632, "time_this_iter_s": 6.857573509216309, "time_total_s": 1132.013343334198, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cc80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1132.013343334198, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 21.910000000000004, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 10.0, -7.0, 4.0, 2.0, 11.0, 3.0, -1.0, 12.0, -4.0, 4.0, 3.0, 9.0, -13.0, 9.0, 10.0, 13.0, 11.0, -1.0, -8.0, 2.0, 12.0, -3.0, 4.0, 13.0, 0.0, 3.0, -1.0, 10.0, 2.0, 11.0, -8.0, 8.0, 8.0, 4.0, -5.0, 0.0, 12.0, 5.0, -2.0, 7.0, -5.0, 3.0, 10.0, 14.0, -15.0, 11.0, 5.0, 8.0, 11.0, -14.0, 10.0, 2.0, 7.0, -4.0, 10.0, 5.0, -2.0, 6.0, 6.0, -8.0, 13.0, 10.0, 0.0, 3.0, 10.0, -1.0, 3.0, 1.0, 10.0, 11.0, -7.0, -13.0, 13.0, 3.0, 12.0, 13.0, -17.0, 12.0, 7.0, 13.0, 4.0, -9.0, 7.0, 0.0, 12.0, -10.0, 13.0, 12.0, -4.0, -1.0, 8.0, 8.0, -2.0, 12.0, -3.0, 13.0, 10.0, 6.0, -14.0, -2.0, -3.0, 9.0, 11.0, 2.0, -2.0, 11.0, 4.0, 11.0, 11.0, 12.0, -19.0, 7.0, 8.0, -5.0, 5.0, 0.0, -1.0, 10.0, 6.0, 6.0, 9.0, 10.0, -10.0, 12.0, 6.0, 12.0, -15.0, 3.0, -3.0, 5.0, 10.0, 1.0, -1.0, 9.0, 6.0, 7.0, -1.0, -1.0, 10.0, 12.0, -7.0, -2.0, 12.0, 9.0, 11.0, -3.0, -2.0, 1.0, 13.0, -2.0, 3.0, 11.0, -1.0, 2.0, 3.0, 11.0, -2.0, 11.0, -5.0, 8.0, -4.0, 13.0, -2.0, 3.0, 8.0, -3.0, 7.0, 11.0, -13.0, 7.0, 10.0, 10.0, -3.0, 12.0, -4.0, 9.0, -5.0, 6.0, 5.0, -4.0, 12.0, -4.0, 11.0, 11.0, -3.0, 5.0, 2.0, -2.0, 11.0, 10.0, -4.0, 9.0, -3.0, -3.0, 12.0, 1.0, 10.0, -4.0, 8.0, 7.0, 13.0, 10.0, -15.0, 8.0, -10.0, 12.0, 5.0, 7.0, 11.0, -12.0, 9.0, -1.0, 11.0, -4.0, 9.0, 8.0, -6.0, 6.0, 7.0, 7.0, -9.0, 12.0, 5.0, 13.0, 9.0, -6.0, -1.0, 0.0, 10.0, -5.0, 10.0, 10.0, -1.0, 4.0, 2.0, 14.0, -20.0, 12.0, 9.0, 12.0, -3.0, 1.0, 5.0, 7.0, 11.0, -14.0, 11.0, 10.0, -2.0, 9.0, -2.0, -9.0, 6.0, 5.0, 13.0, 8.0, 10.0, -13.0, 10.0, -4.0, 11.0, -5.0, 13.0, 6.0, -7.0, 12.0, 4.0, 10.0, -6.0, 11.0, 0.0, 8.0, 8.0, -4.0, 3.0, 2.0, 12.0, -9.0, 10.0, 4.0, -2.0, 12.0, 1.0, 10.0, -2.0, 11.0, -4.0, 13.0, -5.0, 13.0, -6.0, 0.0, 9.0, -3.0, 9.0, 13.0, -3.0, 1.0, 4.0, 9.0, -6.0, 12.0, 0.0, 2.0, 9.0, -6.0, 10.0, -16.0, 11.0, 10.0, 10.0, 5.0, -4.0, 4.0, 10.0, 10.0, -10.0, 12.0, 3.0, 12.0, -2.0, 1.0, 4.0, 4.0, 6.0, -7.0, 12.0, 10.0, -8.0, 2.0, 11.0, 6.0, -2.0, 12.0, -1.0, 13.0, 8.0, 13.0, -19.0, -6.0, 10.0, 13.0, -2.0, 7.0, -10.0, 11.0, 7.0, 13.0, -10.0, 12.0, 0.0, 6.0, 11.0, -7.0, 5.0, -13.0, 7.0, 12.0, 9.0, 2.0, -6.0, 8.0, 11.0, 10.0, 2.0, 12.0, -9.0, 8.0, 9.0, -3.0, 1.0, 3.0, 5.0, -4.0, 11.0, 3.0, -1.0, 5.0, 8.0, 14.0, -19.0, 8.0, 12.0, 13.0, 12.0, 8.0, -18.0, -1.0, 11.0, -4.0, 9.0, 9.0, -9.0, 11.0, 4.0, 10.0, 7.0, 11.0, -13.0, 11.0, 12.0, -13.0, 5.0, 1.0, 0.0, 3.0, 11.0, 8.0, 7.0, 6.0, -6.0, 10.0, -1.0, 9.0, -3.0, 12.0, 9.0, 13.0, -19.0, 2.0, 10.0, -2.0, 5.0, 8.0, 4.0, 12.0, -9.0, 12.0, -10.0, 11.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22084380455788719, "mean_inference_ms": 1.176299435051044, "mean_action_processing_ms": 0.07193144839754283, "mean_env_wait_ms": 0.17959934248241982, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 853200, "agent_timesteps_total": 853119, "timers": {"sample_time_ms": 355.81, "sample_throughput": 15176.64, "learn_time_ms": 6352.876, "learn_throughput": 850.009, "update_time_ms": 10.98}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 18.23293113708496, "policy_loss": -0.07514069974422455, "vf_loss": 18.298686981201172, "vf_explained_var": 0.38967838883399963, "kl": 0.016481267288327217, "entropy": 0.4454818665981293, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 853200, "num_agent_steps_sampled": 853119, "num_steps_trained": 853200, "num_agent_steps_trained": 853119}, "done": false, "episodes_total": 16713, "training_iteration": 158, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-00-39", "timestamp": 1626861639, "time_this_iter_s": 6.810614109039307, "time_total_s": 1138.8239574432373, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1138.8239574432373, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 22.33, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.694444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 7.673611111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 4.0, -9.0, 7.0, 13.0, -4.0, -4.0, 10.0, 11.0, 10.0, -1.0, -5.0, 10.0, -3.0, 7.0, 1.0, -6.0, 5.0, 10.0, 6.0, 4.0, 12.0, 11.0, -12.0, -10.0, 7.0, 12.0, 6.0, 10.0, -6.0, 12.0, -1.0, 13.0, 5.0, -3.0, 0.0, 8.0, -12.0, 8.0, 11.0, -9.0, 11.0, 13.0, 0.0, 12.0, -11.0, 12.0, 2.0, -5.0, 5.0, 10.0, 5.0, 7.0, -10.0, 6.0, 12.0, 2.0, 2.0, -1.0, 12.0, 13.0, 0.0, 3.0, -1.0, 13.0, 11.0, -15.0, 6.0, 11.0, -16.0, 8.0, 12.0, 7.0, 4.0, -2.0, 6.0, 12.0, 14.0, -3.0, -8.0, 0.0, 5.0, 6.0, 4.0, 6.0, -7.0, 6.0, 10.0, -5.0, 2.0, 13.0, 5.0, 12.0, -3.0, 11.0, -5.0, 7.0, 5.0, -1.0, 4.0, 5.0, 7.0, -8.0, 11.0, 7.0, 11.0, 13.0, -16.0, 12.0, 13.0, 6.0, -16.0, 8.0, 4.0, 12.0, -9.0, 14.0, -14.0, 4.0, 11.0, 7.0, 7.0, 11.0, -10.0, 9.0, 14.0, 7.0, -15.0, 13.0, 7.0, -3.0, -2.0, 6.0, 3.0, -6.0, 12.0, 12.0, 12.0, -1.0, -8.0, 12.0, 14.0, -22.0, 11.0, 13.0, -4.0, 7.0, -1.0, 12.0, 1.0, -8.0, 10.0, -6.0, 1.0, 13.0, 7.0, 12.0, 13.0, 2.0, -12.0, 14.0, -7.0, 8.0, 0.0, 14.0, -6.0, -5.0, 12.0, -1.0, 9.0, 13.0, -6.0, 13.0, -7.0, 12.0, -3.0, 13.0, -10.0, 8.0, 4.0, 14.0, 318.0, 10.0, 12.0, 9.0, 10.0, -1.0, -3.0, 13.0, 316.0, 12.0, 12.0, -8.0, 6.0, 12.0, 5.0, 14.0, -20.0, 11.0, 10.0, 8.0, 11.0, 13.0, -17.0, 12.0, -5.0, 11.0, -3.0, 14.0, 3.0, -3.0, 1.0, 7.0, 4.0, -6.0, 10.0, 5.0, 1.0, 13.0, -4.0, 12.0, 4.0, 12.0, -13.0, -2.0, 6.0, 12.0, -1.0, 12.0, -7.0, -2.0, 12.0, 10.0, 3.0, 13.0, -11.0, 11.0, 0.0, 12.0, -8.0, -12.0, 11.0, 12.0, 4.0, 12.0, -5.0, -4.0, 12.0, -10.0, 6.0, 11.0, 8.0, 9.0, 0.0, -3.0, 9.0, 10.0, 10.0, 7.0, -12.0, 9.0, 8.0, 9.0, -11.0, 13.0, 11.0, -4.0, -5.0, 13.0, -6.0, 12.0, -4.0, 0.0, 6.0, 11.0, -2.0, -10.0, 8.0, 7.0, 10.0, 7.0, 4.0, -1.0, 5.0, 10.0, 7.0, 0.0, -2.0, 13.0, 10.0, 1.0, -9.0, 14.0, -18.0, 7.0, 12.0, 5.0, 2.0, -1.0, 9.0, 10.0, 12.0, 7.0, -14.0, -1.0, 3.0, 8.0, 5.0, 3.0, 7.0, -6.0, 11.0, 7.0, 12.0, 13.0, -17.0, 13.0, -14.0, 8.0, 8.0, -1.0, 10.0, 6.0, 0.0, 12.0, -10.0, 3.0, 10.0, 11.0, 11.0, 13.0, 321.0, 11.0, 2.0, 8.0, -6.0, 13.0, 5.0, -8.0, 5.0, 14.0, 1.0, -11.0, 11.0, 6.0, 7.0, -1.0, 3.0, 9.0, -4.0, 12.0, -2.0, 0.0, 1.0, 10.0, 4.0, 14.0, 316.0, 11.0, 12.0, 14.0, 9.0, -1.0, -7.0, 11.0, 318.0, 12.0, 13.0, 12.0, -4.0, 12.0, -5.0, 5.0, -2.0, 5.0, 7.0, -9.0, 11.0, 13.0, 0.0, 11.0, 8.0, -12.0, 8.0, 0.0, 11.0, 10.0, -6.0, 5.0, -4.0, 7.0, 7.0, -10.0, 2.0, 13.0, 10.0, 11.0, -5.0, 12.0, -3.0, -1.0, 6.0, 12.0, -2.0, 6.0, -12.0, 11.0, 10.0, -5.0, 2.0, 9.0, 9.0, 12.0, 12.0, 0.0, -9.0, 14.0, 4.0, -1.0, -2.0, 14.0, -8.0, -3.0, 12.0, -11.0, 6.0, 13.0, 7.0, 9.0, 13.0, 7.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22086555125685092, "mean_inference_ms": 1.1763914720863453, "mean_action_processing_ms": 0.0719346275581185, "mean_env_wait_ms": 0.17961110006977132, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 858600, "agent_timesteps_total": 858519, "timers": {"sample_time_ms": 356.616, "sample_throughput": 15142.339, "learn_time_ms": 6356.478, "learn_throughput": 849.527, "update_time_ms": 10.941}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 1073.6788330078125, "policy_loss": -0.020255470648407936, "vf_loss": 1073.69580078125, "vf_explained_var": 0.06547525525093079, "kl": 0.0058830673806369305, "entropy": 0.4471709132194519, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 858600, "num_agent_steps_sampled": 858519, "num_steps_trained": 858600, "num_agent_steps_trained": 858519}, "done": false, "episodes_total": 16821, "training_iteration": 159, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-00-46", "timestamp": 1626861646, "time_this_iter_s": 6.849660158157349, "time_total_s": 1145.6736176013947, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029ce18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1145.6736176013947, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 21.69, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.73148148148148, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 7.68287037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-18.0, 14.0, 11.0, 8.0, 14.0, -18.0, 6.0, 13.0, 2.0, 11.0, -11.0, 13.0, -2.0, 13.0, 10.0, -6.0, -14.0, 14.0, 4.0, 11.0, 12.0, 7.0, -11.0, 7.0, 4.0, 14.0, -10.0, 7.0, -5.0, 13.0, 8.0, -1.0, -8.0, 13.0, 11.0, -1.0, 14.0, -13.0, 6.0, 8.0, -13.0, 14.0, 1.0, 13.0, -1.0, 13.0, 8.0, -5.0, -3.0, 0.0, 11.0, 7.0, 13.0, -18.0, 7.0, 13.0, -2.0, 14.0, -10.0, 13.0, -6.0, 13.0, 9.0, -1.0, 322.0, 11.0, 11.0, 13.0, 8.0, 12.0, -18.0, 13.0, -1.0, 14.0, -11.0, 13.0, 10.0, 3.0, 11.0, -9.0, -14.0, 14.0, 10.0, 5.0, 13.0, 317.0, 11.0, 13.0, -2.0, 14.0, -8.0, 11.0, -2.0, 11.0, 11.0, -5.0, -5.0, 14.0, -3.0, 9.0, 11.0, -3.0, -5.0, 12.0, -15.0, 14.0, 8.0, 8.0, -1.0, 13.0, 3.0, 0.0, -1.0, -6.0, 10.0, 12.0, 9.0, 6.0, -5.0, 5.0, 7.0, 10.0, -14.0, 12.0, -2.0, 8.0, 7.0, 2.0, -19.0, 13.0, 11.0, 10.0, 10.0, -11.0, 8.0, 8.0, 11.0, 11.0, -9.0, 2.0, -1.0, 13.0, 5.0, -2.0, -13.0, 14.0, 5.0, 9.0, 14.0, 6.0, -17.0, 12.0, 6.0, 14.0, -9.0, 4.0, 14.0, 7.0, 9.0, -15.0, -1.0, 11.0, -2.0, 7.0, 10.0, 6.0, -14.0, 13.0, 9.0, 14.0, -20.0, 12.0, -1.0, 8.0, 1.0, 7.0, -17.0, 9.0, 11.0, 12.0, 14.0, 7.0, 4.0, -10.0, -18.0, 13.0, 8.0, 12.0, 6.0, 13.0, 6.0, -10.0, 0.0, 12.0, 11.0, -8.0, 13.0, 5.0, -16.0, 13.0, 11.0, 9.0, 3.0, -8.0, -1.0, 9.0, 7.0, 0.0, -11.0, 14.0, 11.0, 1.0, 10.0, -4.0, -3.0, 12.0, 8.0, 10.0, -13.0, 10.0, 12.0, 8.0, -9.0, 4.0, -9.0, 14.0, -2.0, 12.0, 14.0, 317.0, 10.0, 13.0, 8.0, 14.0, -16.0, 9.0, 12.0, 13.0, -6.0, -4.0, -12.0, 14.0, 11.0, 2.0, 13.0, -9.0, -2.0, 13.0, 3.0, 10.0, -7.0, 9.0, -2.0, 10.0, 8.0, -1.0, -11.0, 13.0, 4.0, 9.0, 11.0, -11.0, 7.0, 8.0, 7.0, 13.0, -13.0, 8.0, -3.0, 8.0, 10.0, 0.0, -10.0, 9.0, 11.0, 5.0, 13.0, 8.0, -13.0, 7.0, -8.0, 11.0, 5.0, 7.0, 13.0, 8.0, -3.0, -3.0, -13.0, 12.0, 8.0, 8.0, 14.0, 3.0, -14.0, 12.0, -15.0, 14.0, 3.0, 13.0, -5.0, 12.0, 9.0, -1.0, -15.0, 12.0, 7.0, 11.0, 13.0, 317.0, 11.0, 13.0, -10.0, 14.0, 3.0, 8.0, -2.0, 13.0, 6.0, -2.0, 318.0, 14.0, 11.0, 12.0, 14.0, -5.0, -6.0, 12.0, -16.0, 13.0, 9.0, 9.0, -9.0, 13.0, 7.0, 4.0, 0.0, 14.0, 10.0, -9.0, 14.0, 13.0, -14.0, 2.0, 5.0, 14.0, -13.0, 9.0, 13.0, 8.0, -3.0, -3.0, -9.0, 14.0, 10.0, 0.0, 14.0, -12.0, 5.0, 8.0, 5.0, 10.0, -9.0, 9.0, -2.0, 9.0, 8.0, 0.0, -17.0, 14.0, 12.0, 6.0, 14.0, -15.0, 6.0, 10.0, -11.0, 14.0, -1.0, 13.0, -3.0, 8.0, 9.0, 1.0, -8.0, 12.0, -2.0, 13.0, 12.0, 3.0, -11.0, 11.0, -5.0, 14.0, -6.0, 12.0, -2.0, 12.0, 5.0, 0.0, -21.0, 14.0, 9.0, 13.0, 14.0, -5.0, -7.0, 13.0, 10.0, 10.0, -16.0, 11.0, 12.0, 12.0, -3.0, -6.0, 3.0, -2.0, 4.0, 10.0, 9.0, 12.0, -19.0, 13.0, 4.0, 14.0, -11.0, 8.0, -1.0, 13.0, 11.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22089460810115627, "mean_inference_ms": 1.1764479756156192, "mean_action_processing_ms": 0.07193775125191683, "mean_env_wait_ms": 0.17963918975739343, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 864000, "agent_timesteps_total": 863919, "timers": {"sample_time_ms": 356.252, "sample_throughput": 15157.817, "learn_time_ms": 6359.161, "learn_throughput": 849.169, "update_time_ms": 11.016}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 891.0631103515625, "policy_loss": -0.016421299427747726, "vf_loss": 891.0762939453125, "vf_explained_var": 0.12234203517436981, "kl": 0.00568006094545126, "entropy": 0.43390846252441406, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 864000, "num_agent_steps_sampled": 863919, "num_steps_trained": 864000, "num_agent_steps_trained": 863919}, "done": false, "episodes_total": 16929, "training_iteration": 160, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-00-53", "timestamp": 1626861653, "time_this_iter_s": 6.873233318328857, "time_total_s": 1152.5468509197235, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f8c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1152.5468509197235, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 22.23, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.26851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.31712962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 13.0, -20.0, 11.0, 12.0, 3.0, 5.0, -5.0, 6.0, 0.0, -3.0, 12.0, 7.0, 10.0, -15.0, 13.0, 3.0, 13.0, 6.0, -7.0, 1.0, 13.0, -3.0, 4.0, -6.0, 12.0, -4.0, 13.0, 12.0, -5.0, 5.0, 3.0, 9.0, 14.0, -18.0, 10.0, -3.0, 13.0, 11.0, -6.0, -3.0, 14.0, -8.0, 12.0, 9.0, -7.0, 5.0, 8.0, -15.0, 13.0, 5.0, 12.0, 6.0, 8.0, -4.0, 5.0, 8.0, -7.0, 6.0, 8.0, 12.0, 9.0, 7.0, -13.0, -13.0, 14.0, 6.0, 8.0, -7.0, 7.0, 2.0, 13.0, 2.0, 14.0, 1.0, -2.0, 11.0, 5.0, 7.0, -8.0, -3.0, 12.0, -6.0, 12.0, -14.0, 13.0, 7.0, 9.0, 9.0, 14.0, -6.0, -2.0, -1.0, 4.0, -1.0, 13.0, 0.0, 13.0, -9.0, 11.0, 8.0, 8.0, -7.0, 6.0, -6.0, 14.0, 1.0, 6.0, 11.0, -5.0, 11.0, -2.0, -3.0, 9.0, 0.0, 9.0, -3.0, 7.0, 12.0, -1.0, -6.0, 14.0, 2.0, 5.0, 12.0, 4.0, -4.0, 3.0, 11.0, 13.0, -18.0, 9.0, -3.0, 12.0, -7.0, 13.0, 6.0, -1.0, -3.0, 13.0, 11.0, 9.0, 12.0, -17.0, -16.0, 14.0, 7.0, 10.0, -10.0, 10.0, 3.0, 12.0, 10.0, -2.0, -6.0, 13.0, -4.0, 8.0, 8.0, 3.0, 7.0, 14.0, -16.0, 10.0, 1.0, 12.0, -6.0, 8.0, -2.0, 5.0, 0.0, 12.0, 10.0, 10.0, -2.0, -3.0, 3.0, 12.0, 4.0, -4.0, 11.0, -3.0, 8.0, -1.0, 10.0, -2.0, 1.0, 6.0, 12.0, 3.0, 12.0, -12.0, 5.0, 13.0, -14.0, 11.0, -7.0, 8.0, 4.0, 10.0, 3.0, 14.0, 8.0, -10.0, 11.0, 5.0, -14.0, 13.0, -2.0, 8.0, -2.0, 11.0, -16.0, 12.0, 7.0, 12.0, 9.0, -7.0, 0.0, 13.0, 9.0, 10.0, -12.0, 8.0, 11.0, 12.0, -20.0, 12.0, -1.0, -2.0, 12.0, 6.0, 3.0, 0.0, 1.0, 11.0, 3.0, 11.0, -12.0, 13.0, 10.0, 12.0, -19.0, 12.0, -9.0, 11.0, 12.0, 1.0, -8.0, 14.0, 4.0, 5.0, 6.0, 10.0, -14.0, 13.0, 6.0, 14.0, -16.0, 11.0, -13.0, 3.0, 13.0, 12.0, 10.0, 5.0, 7.0, -7.0, 13.0, -9.0, 12.0, -1.0, -10.0, 13.0, 4.0, 8.0, 10.0, 8.0, -1.0, -2.0, 8.0, 0.0, 1.0, 6.0, 9.0, 3.0, -1.0, 4.0, 5.0, 9.0, 7.0, -6.0, -2.0, 6.0, -1.0, 12.0, 7.0, 13.0, 3.0, -8.0, -3.0, 7.0, 8.0, 3.0, -17.0, 14.0, 6.0, 12.0, -2.0, 8.0, 10.0, -1.0, 1.0, 0.0, 3.0, 11.0, 11.0, 3.0, 12.0, -11.0, 6.0, 14.0, -12.0, 7.0, 12.0, -1.0, 13.0, -9.0, 7.0, -2.0, 3.0, 7.0, 13.0, -11.0, 12.0, 1.0, -4.0, 10.0, 1.0, 8.0, -2.0, 5.0, 10.0, 2.0, 6.0, 0.0, -4.0, 13.0, 9.0, 10.0, -6.0, 2.0, 14.0, 13.0, 315.0, 11.0, 9.0, 6.0, 8.0, -8.0, -5.0, 14.0, -5.0, 11.0, -5.0, 3.0, 9.0, 8.0, 4.0, 8.0, -7.0, 10.0, -4.0, -2.0, 10.0, 11.0, -12.0, 13.0, 6.0, 8.0, -5.0, 4.0, 9.0, 7.0, 0.0, 9.0, -5.0, 11.0, 0.0, 7.0, -3.0, 11.0, -4.0, 14.0, -2.0, 7.0, 4.0, 10.0, -4.0, 5.0, 13.0, 7.0, -4.0, -1.0, -14.0, 5.0, 12.0, 12.0, 9.0, -5.0, 3.0, 8.0, 2.0, 5.0, -5.0, 13.0, 11.0, 14.0, 319.0, 10.0, -18.0, 8.0, 12.0, 13.0, 7.0, -2.0, 5.0, 5.0, 4.0, 8.0, 9.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22093759413866249, "mean_inference_ms": 1.1765760651511756, "mean_action_processing_ms": 0.07195451859735155, "mean_env_wait_ms": 0.1796631198856717, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 869400, "agent_timesteps_total": 869319, "timers": {"sample_time_ms": 356.076, "sample_throughput": 15165.306, "learn_time_ms": 6362.378, "learn_throughput": 848.739, "update_time_ms": 10.963}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 281.9805908203125, "policy_loss": -0.028967414051294327, "vf_loss": 282.0047607421875, "vf_explained_var": 0.13354277610778809, "kl": 0.008308103308081627, "entropy": 0.45485785603523254, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 869400, "num_agent_steps_sampled": 869319, "num_steps_trained": 869400, "num_agent_steps_trained": 869319}, "done": false, "episodes_total": 17037, "training_iteration": 161, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-00", "timestamp": 1626861660, "time_this_iter_s": 6.868661880493164, "time_total_s": 1159.4155128002167, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f8d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1159.4155128002167, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 22.233333333333334, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, 12.0, -3.0, 3.0, 7.0, 7.0, -11.0, 12.0, -17.0, 13.0, 8.0, 11.0, -13.0, 8.0, 12.0, 8.0, 7.0, 0.0, -2.0, 10.0, 9.0, -11.0, 5.0, 12.0, 1.0, 6.0, 9.0, -1.0, -6.0, 9.0, 7.0, 5.0, 13.0, 6.0, -10.0, 6.0, 11.0, -20.0, 11.0, 13.0, 11.0, 3.0, -9.0, 10.0, 5.0, 7.0, 7.0, -4.0, 5.0, 7.0, -3.0, 6.0, -17.0, 8.0, 11.0, 13.0, 11.0, 3.0, 11.0, -10.0, 8.0, 12.0, -6.0, 1.0, 13.0, 6.0, 1.0, -5.0, 9.0, -9.0, 2.0, 13.0, -3.0, -2.0, 11.0, 9.0, -2.0, 6.0, 5.0, 6.0, 7.0, 11.0, -15.0, 12.0, 9.0, -17.0, 12.0, 11.0, -2.0, 8.0, 10.0, -1.0, 0.0, 10.0, 11.0, -6.0, 7.0, 12.0, 1.0, -5.0, 1.0, -10.0, 11.0, 13.0, -12.0, 7.0, 11.0, 9.0, 8.0, 4.0, -4.0, 7.0, 8.0, 11.0, 11.0, -15.0, 9.0, -11.0, 5.0, 12.0, -11.0, 13.0, 4.0, 9.0, 3.0, 8.0, 8.0, -4.0, 12.0, -8.0, -1.0, 12.0, 9.0, -12.0, 9.0, 9.0, -4.0, 12.0, -1.0, 8.0, 3.0, 7.0, -4.0, 9.0, 3.0, 10.0, -8.0, 10.0, 11.0, -20.0, 11.0, 13.0, 2.0, 7.0, -3.0, 9.0, 8.0, 8.0, 8.0, -9.0, 0.0, 0.0, 13.0, 2.0, 5.0, -11.0, 8.0, 13.0, -8.0, 4.0, 6.0, 13.0, 6.0, 12.0, -6.0, 3.0, 8.0, 9.0, -8.0, 6.0, 14.0, -16.0, 5.0, 12.0, -11.0, 8.0, 5.0, 13.0, 4.0, 7.0, -3.0, 7.0, 6.0, 11.0, 6.0, -8.0, 9.0, -15.0, 10.0, 11.0, -8.0, 0.0, 10.0, 13.0, 3.0, 14.0, -3.0, 1.0, 7.0, 11.0, -16.0, 13.0, -1.0, -6.0, 9.0, 13.0, -16.0, 12.0, 11.0, 8.0, 13.0, 3.0, -8.0, 7.0, 10.0, 12.0, -4.0, -3.0, -1.0, -4.0, 12.0, 8.0, -16.0, 8.0, 10.0, 13.0, -1.0, 14.0, -7.0, 9.0, 12.0, 3.0, 1.0, -1.0, -15.0, 7.0, 11.0, 12.0, -12.0, 11.0, 8.0, 8.0, 5.0, 8.0, -3.0, 5.0, 8.0, 14.0, -17.0, 10.0, 4.0, -7.0, 10.0, 8.0, -9.0, 8.0, 8.0, 8.0, -11.0, 8.0, 9.0, 9.0, 11.0, 9.0, -4.0, -1.0, -12.0, 6.0, 9.0, 12.0, -10.0, 3.0, 9.0, 13.0, 0.0, 14.0, -7.0, 8.0, 11.0, 6.0, -3.0, 1.0, 1.0, -7.0, 11.0, 10.0, -15.0, 8.0, 9.0, 13.0, 0.0, -4.0, 10.0, 9.0, 6.0, 8.0, -12.0, 13.0, 1.0, -10.0, 11.0, 13.0, -1.0, 8.0, 9.0, -1.0, 2.0, 13.0, -5.0, 5.0, 10.0, -1.0, -3.0, 9.0, 1.0, -10.0, 11.0, 13.0, -5.0, 0.0, 12.0, 8.0, 7.0, 14.0, -4.0, -2.0, 8.0, 6.0, 9.0, -8.0, 8.0, -5.0, 6.0, 6.0, -15.0, 14.0, 8.0, 8.0, 8.0, 13.0, -13.0, 7.0, 4.0, -6.0, 4.0, 13.0, -1.0, -7.0, 10.0, 13.0, -20.0, 13.0, 9.0, 13.0, 2.0, 13.0, -4.0, 4.0, 8.0, 5.0, 5.0, -3.0, -3.0, 8.0, 1.0, 9.0, 12.0, 0.0, 5.0, -2.0, 1.0, 13.0, -3.0, 4.0, 6.0, 10.0, -12.0, 11.0, 322.0, 9.0, 11.0, 13.0, 8.0, -10.0, 8.0, 9.0, 3.0, 14.0, -4.0, 2.0, 10.0, 12.0, -13.0, 6.0, -11.0, 6.0, 11.0, 9.0, -3.0, 7.0, -1.0, 12.0, 1.0, 7.0, -5.0, 12.0, 4.0, 11.0, -11.0, 11.0, 8.0, -17.0, 11.0, 13.0, 5.0, 8.0, -5.0, 7.0, 11.0, -6.0, 12.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2209522909999535, "mean_inference_ms": 1.1767811921268458, "mean_action_processing_ms": 0.07197034338034168, "mean_env_wait_ms": 0.17967425298957165, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 874800, "agent_timesteps_total": 874719, "timers": {"sample_time_ms": 357.323, "sample_throughput": 15112.383, "learn_time_ms": 6363.704, "learn_throughput": 848.562, "update_time_ms": 10.795}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 231.16233825683594, "policy_loss": -0.030378971248865128, "vf_loss": 231.18765258789062, "vf_explained_var": 0.24513567984104156, "kl": 0.008886796422302723, "entropy": 0.43813851475715637, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 874800, "num_agent_steps_sampled": 874719, "num_steps_trained": 874800, "num_agent_steps_trained": 874719}, "done": false, "episodes_total": 17145, "training_iteration": 162, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-07", "timestamp": 1626861667, "time_this_iter_s": 6.872326612472534, "time_total_s": 1166.2878394126892, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e701f8ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1166.2878394126892, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 22.44, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 9.0, 8.0, -11.0, 11.0, 5.0, -1.0, 0.0, -11.0, 7.0, 9.0, 10.0, 9.0, 14.0, -2.0, -6.0, -6.0, 10.0, 0.0, 11.0, 11.0, 2.0, -5.0, 7.0, -10.0, 10.0, 10.0, 5.0, 12.0, -2.0, 2.0, 3.0, 6.0, 14.0, 7.0, -12.0, 8.0, 11.0, -3.0, -1.0, -7.0, 7.0, 9.0, 6.0, 12.0, -14.0, 5.0, 12.0, 11.0, 9.0, -5.0, 0.0, 13.0, 0.0, -10.0, 12.0, 7.0, -13.0, 10.0, 11.0, 14.0, -7.0, 5.0, 3.0, 12.0, 9.0, 5.0, -11.0, 12.0, 0.0, -9.0, 12.0, -4.0, 1.0, 11.0, 7.0, 0.0, 4.0, 0.0, 11.0, -2.0, 9.0, 3.0, 5.0, -9.0, 9.0, 10.0, 5.0, 7.0, -9.0, 11.0, 6.0, 0.0, 11.0, 5.0, -1.0, 12.0, -10.0, 8.0, 5.0, 7.0, -4.0, 1.0, 11.0, 5.0, -14.0, 12.0, 12.0, 8.0, -2.0, 10.0, -1.0, 11.0, 5.0, 9.0, -10.0, -9.0, 10.0, 2.0, 12.0, -10.0, 6.0, 7.0, 12.0, 12.0, 5.0, 4.0, -6.0, 6.0, 2.0, 9.0, -2.0, 10.0, -12.0, 6.0, 11.0, -9.0, 1.0, 12.0, 11.0, 13.0, -4.0, 4.0, 2.0, -2.0, 9.0, 5.0, 3.0, 13.0, -9.0, -1.0, 12.0, 10.0, -8.0, 11.0, 2.0, 14.0, -17.0, 8.0, 10.0, 12.0, -1.0, 10.0, -6.0, 5.0, 11.0, -5.0, 4.0, -15.0, 9.0, 9.0, 12.0, -8.0, 8.0, 6.0, 9.0, -9.0, 14.0, 11.0, -1.0, -1.0, 3.0, 5.0, 8.0, -8.0, 6.0, 12.0, 5.0, 14.0, 12.0, 1.0, -12.0, 9.0, 9.0, 11.0, -14.0, 12.0, -6.0, 5.0, 4.0, 3.0, -11.0, 13.0, 10.0, 12.0, -14.0, 4.0, 13.0, -6.0, 14.0, 4.0, 3.0, 9.0, -9.0, 10.0, 5.0, -3.0, 3.0, 10.0, 5.0, 13.0, -7.0, 11.0, -2.0, -9.0, 14.0, 11.0, -1.0, 8.0, 10.0, -9.0, 6.0, -1.0, -2.0, 6.0, 12.0, 14.0, -11.0, 6.0, 6.0, 11.0, 9.0, 4.0, -9.0, 13.0, -5.0, -4.0, 11.0, -1.0, -7.0, 12.0, 11.0, 13.0, -16.0, 9.0, 9.0, 13.0, 2.0, 3.0, -3.0, -1.0, -5.0, 13.0, 8.0, -10.0, 5.0, 11.0, 9.0, 14.0, 7.0, 10.0, -16.0, 12.0, 3.0, -10.0, 10.0, 5.0, -3.0, 8.0, 5.0, -4.0, 8.0, 8.0, 3.0, 11.0, 8.0, -9.0, 5.0, -1.0, 9.0, 3.0, 4.0, 8.0, -3.0, 5.0, 5.0, 2.0, -7.0, 10.0, 10.0, 13.0, -7.0, 2.0, 7.0, -4.0, 9.0, 6.0, 4.0, -3.0, 11.0, 0.0, 7.0, -12.0, 12.0, 9.0, 6.0, 14.0, 7.0, -12.0, 6.0, 10.0, 14.0, -7.0, -2.0, -5.0, 5.0, 10.0, 5.0, 3.0, -10.0, 13.0, 9.0, 12.0, -2.0, -1.0, 6.0, 12.0, 4.0, -3.0, 2.0, -13.0, 10.0, 13.0, 5.0, -11.0, 4.0, 10.0, 12.0, 11.0, -7.0, 9.0, 2.0, 11.0, 9.0, 8.0, -13.0, -9.0, 11.0, 8.0, 5.0, 5.0, -15.0, 13.0, 12.0, 14.0, 3.0, 8.0, -10.0, 11.0, -7.0, 4.0, 7.0, -9.0, 11.0, 11.0, 2.0, -4.0, 5.0, 11.0, 3.0, 12.0, -8.0, 7.0, 4.0, -1.0, 2.0, 8.0, 6.0, -1.0, 4.0, 8.0, 4.0, -12.0, 7.0, 12.0, 8.0, 13.0, -4.0, 5.0, 1.0, -7.0, 9.0, 4.0, 9.0, -6.0, 11.0, 6.0, 4.0, -12.0, 10.0, 11.0, 6.0, 13.0, -1.0, 0.0, 3.0, 10.0, 5.0, 8.0, -8.0, 11.0, 3.0, -5.0, 6.0, -17.0, 14.0, 12.0, 6.0, 14.0, -14.0, 9.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2209801688065991, "mean_inference_ms": 1.1770102398780597, "mean_action_processing_ms": 0.07198374563220454, "mean_env_wait_ms": 0.17969561694529915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 880200, "agent_timesteps_total": 880119, "timers": {"sample_time_ms": 358.187, "sample_throughput": 15075.923, "learn_time_ms": 6361.359, "learn_throughput": 848.875, "update_time_ms": 10.892}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 19.957416534423828, "policy_loss": -0.08601313829421997, "vf_loss": 20.03351402282715, "vf_explained_var": 0.30454814434051514, "kl": 0.01740737073123455, "entropy": 0.427953839302063, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 880200, "num_agent_steps_sampled": 880119, "num_steps_trained": 880200, "num_agent_steps_trained": 880119}, "done": false, "episodes_total": 17253, "training_iteration": 163, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-14", "timestamp": 1626861674, "time_this_iter_s": 6.879071474075317, "time_total_s": 1173.1669108867645, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cbf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1173.1669108867645, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 22.34, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 9.0, -12.0, 4.0, -2.0, 9.0, 1.0, 7.0, 10.0, 12.0, 4.0, -11.0, -4.0, 9.0, 6.0, 4.0, 10.0, 5.0, -8.0, 8.0, -3.0, 3.0, 6.0, 9.0, 13.0, 13.0, 2.0, -13.0, 7.0, -8.0, 12.0, 4.0, 10.0, 10.0, 9.0, -14.0, 7.0, 3.0, 12.0, -7.0, 10.0, 12.0, -12.0, 5.0, 11.0, -4.0, 6.0, 2.0, -5.0, 5.0, 2.0, 13.0, 3.0, 5.0, -3.0, 10.0, -6.0, -2.0, 11.0, 12.0, -9.0, 8.0, 5.0, 11.0, 12.0, 5.0, -14.0, 12.0, 6.0, 5.0, -6.0, 10.0, 2.0, 12.0, 4.0, -3.0, -4.0, 9.0, 5.0, 5.0, 9.0, 4.0, -2.0, 4.0, 8.0, -1.0, 12.0, -4.0, 14.0, -7.0, 12.0, -4.0, 3.0, 2.0, -2.0, 12.0, 10.0, -11.0, 3.0, 13.0, -1.0, 3.0, 10.0, 3.0, 13.0, 13.0, 5.0, -16.0, -14.0, 11.0, 12.0, 6.0, 9.0, 10.0, -10.0, 6.0, 13.0, 8.0, 1.0, -7.0, 14.0, 8.0, 9.0, -16.0, 11.0, 13.0, -3.0, -6.0, -2.0, 1.0, 3.0, 13.0, -7.0, 1.0, 12.0, 9.0, 8.0, -2.0, 5.0, 4.0, 12.0, 3.0, 12.0, -12.0, -4.0, 5.0, 7.0, 7.0, 13.0, 11.0, -4.0, -5.0, 7.0, 12.0, 4.0, -8.0, 4.0, -8.0, 10.0, 9.0, -2.0, 11.0, -2.0, 8.0, 8.0, -10.0, 10.0, 7.0, 13.0, 4.0, 3.0, -5.0, 10.0, 9.0, -16.0, 12.0, -7.0, 11.0, 0.0, 11.0, 9.0, -10.0, 5.0, 11.0, 13.0, 8.0, 5.0, -11.0, 7.0, 10.0, 4.0, -6.0, -8.0, 11.0, -1.0, 13.0, -1.0, 7.0, 11.0, -2.0, 10.0, -6.0, 11.0, 0.0, 10.0, 6.0, -10.0, 9.0, 2.0, 14.0, -13.0, 12.0, 14.0, 5.0, -2.0, -2.0, 13.0, 12.0, 5.0, -15.0, -4.0, 9.0, 1.0, 9.0, -3.0, 5.0, 1.0, 12.0, 12.0, -1.0, 7.0, -3.0, 9.0, 12.0, 6.0, -12.0, -1.0, 12.0, 13.0, -9.0, -9.0, 10.0, 7.0, 7.0, 8.0, 1.0, -5.0, 11.0, 8.0, 13.0, 7.0, -13.0, 4.0, 1.0, -2.0, 12.0, 12.0, 9.0, -14.0, 8.0, 14.0, 3.0, 4.0, -6.0, 2.0, 12.0, 8.0, -7.0, 5.0, 2.0, -3.0, 11.0, 2.0, 13.0, 12.0, -12.0, 14.0, 9.0, -11.0, 3.0, 9.0, 12.0, 10.0, -16.0, 5.0, -11.0, 10.0, 11.0, 12.0, 7.0, -12.0, 8.0, -5.0, 7.0, 6.0, 7.0, 11.0, -3.0, 12.0, -5.0, -6.0, 5.0, 11.0, 5.0, 7.0, 12.0, -16.0, 12.0, -4.0, 9.0, 5.0, 5.0, 13.0, 8.0, 6.0, -12.0, 9.0, 3.0, 13.0, -10.0, -3.0, 8.0, 4.0, 6.0, 8.0, -13.0, 10.0, 10.0, 14.0, 12.0, 2.0, -13.0, 4.0, 6.0, -4.0, 9.0, 9.0, 9.0, -10.0, 7.0, 6.0, -1.0, 10.0, 0.0, 3.0, 13.0, 5.0, -6.0, -9.0, 5.0, 10.0, 9.0, 12.0, 12.0, -10.0, 1.0, 13.0, 4.0, -13.0, 11.0, 11.0, 12.0, 6.0, -14.0, 6.0, 3.0, -5.0, 11.0, 8.0, 10.0, -11.0, 8.0, 1.0, -9.0, 12.0, 11.0, 13.0, 12.0, 3.0, -13.0, 8.0, 4.0, -2.0, 5.0, 13.0, -11.0, 0.0, 13.0, -5.0, 2.0, 12.0, 6.0, 3.0, 13.0, 8.0, -9.0, 10.0, -2.0, -4.0, 11.0, 10.0, 5.0, -2.0, 2.0, 12.0, -1.0, -6.0, 10.0, 10.0, 5.0, -4.0, 4.0, 7.0, 9.0, -10.0, 9.0, 12.0, 319.0, 10.0, 13.0, 13.0, -8.0, 8.0, 2.0, 5.0, -2.0, 8.0, 4.0, 9.0, 3.0, 12.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2209950395688406, "mean_inference_ms": 1.1771693279312012, "mean_action_processing_ms": 0.07199634857577628, "mean_env_wait_ms": 0.17973576528004628, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 885600, "agent_timesteps_total": 885519, "timers": {"sample_time_ms": 358.499, "sample_throughput": 15062.795, "learn_time_ms": 6391.91, "learn_throughput": 844.818, "update_time_ms": 10.87}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 188.54307556152344, "policy_loss": -0.025817500427365303, "vf_loss": 188.56454467773438, "vf_explained_var": 0.2531459927558899, "kl": 0.007618001662194729, "entropy": 0.4369909167289734, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 885600, "num_agent_steps_sampled": 885519, "num_steps_trained": 885600, "num_agent_steps_trained": 885519}, "done": false, "episodes_total": 17361, "training_iteration": 164, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-21", "timestamp": 1626861681, "time_this_iter_s": 7.023500919342041, "time_total_s": 1180.1904118061066, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cb70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1180.1904118061066, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 25.890000000000004, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 40.148148148148145, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 10.037037037037036}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 354.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 10.0, -18.0, 11.0, 13.0, -8.0, 3.0, 7.0, 12.0, 317.0, 13.0, 12.0, -7.0, 8.0, 7.0, 7.0, 12.0, 3.0, -11.0, 11.0, 11.0, -7.0, 5.0, 6.0, -2.0, 1.0, 7.0, 9.0, -6.0, 8.0, 9.0, 4.0, 13.0, 10.0, -19.0, 11.0, 13.0, -15.0, 4.0, 13.0, -1.0, -7.0, 13.0, 10.0, 7.0, 12.0, 7.0, -11.0, 13.0, 13.0, 315.0, 13.0, 13.0, -14.0, 7.0, 9.0, 12.0, -4.0, 11.0, -4.0, 10.0, 12.0, 6.0, -13.0, 9.0, 13.0, -5.0, -2.0, 13.0, 6.0, 3.0, -7.0, -4.0, 13.0, -2.0, 8.0, -11.0, 10.0, 9.0, 7.0, 8.0, 4.0, -9.0, 12.0, 12.0, -12.0, 9.0, 6.0, -8.0, 7.0, 12.0, 4.0, 11.0, 12.0, 12.0, 319.0, 10.0, -2.0, -3.0, 10.0, 13.0, -10.0, 3.0, 9.0, -4.0, -6.0, 13.0, 12.0, -4.0, 9.0, 11.0, -1.0, 10.0, 1.0, -6.0, 10.0, 14.0, -7.0, 6.0, 2.0, 5.0, -14.0, 13.0, 11.0, -7.0, 13.0, 12.0, -3.0, -2.0, 7.0, 12.0, -2.0, 14.0, -4.0, 3.0, 2.0, 12.0, -1.0, 13.0, -9.0, -17.0, 13.0, 12.0, 7.0, 13.0, 9.0, -15.0, 8.0, 13.0, -9.0, -1.0, 12.0, -3.0, 7.0, 5.0, 6.0, 9.0, -3.0, 10.0, -1.0, 14.0, 5.0, -15.0, 11.0, 8.0, -9.0, 4.0, 12.0, 13.0, 317.0, 13.0, 11.0, -6.0, 13.0, 12.0, -4.0, 13.0, 14.0, 316.0, 11.0, 13.0, -13.0, 2.0, 13.0, 13.0, 12.0, 320.0, 11.0, 8.0, -4.0, -1.0, 12.0, 11.0, -7.0, -1.0, 12.0, 8.0, -3.0, 2.0, 8.0, 11.0, -18.0, 12.0, 10.0, -5.0, 13.0, 10.0, -3.0, 11.0, 6.0, -11.0, 9.0, 8.0, -4.0, -1.0, 12.0, -6.0, 5.0, 12.0, 4.0, 3.0, -3.0, 8.0, 7.0, 13.0, -1.0, -4.0, 7.0, 13.0, -12.0, 4.0, 10.0, -5.0, 3.0, 13.0, 4.0, -6.0, 13.0, 9.0, -1.0, 13.0, 12.0, -23.0, 13.0, 14.0, -7.0, 4.0, 4.0, -4.0, 13.0, 9.0, -3.0, 10.0, 5.0, 11.0, -11.0, 13.0, 12.0, 316.0, 13.0, 13.0, -9.0, 2.0, 9.0, -11.0, 9.0, 12.0, 5.0, 7.0, 13.0, 11.0, -16.0, 7.0, 12.0, 0.0, -4.0, 13.0, 10.0, 2.0, -10.0, -6.0, 4.0, 12.0, 5.0, 12.0, 13.0, 10.0, -20.0, 9.0, 8.0, 5.0, -7.0, 14.0, -13.0, 4.0, 10.0, -1.0, 5.0, 7.0, 4.0, -8.0, 12.0, 12.0, -1.0, 10.0, 4.0, -12.0, 13.0, 13.0, -9.0, 5.0, 6.0, 12.0, 14.0, 318.0, 12.0, -15.0, 11.0, 7.0, 12.0, 13.0, 10.0, -19.0, 11.0, 10.0, -10.0, 2.0, 13.0, -7.0, 4.0, 13.0, 5.0, 5.0, -4.0, 12.0, 2.0, 12.0, 3.0, -11.0, 11.0, 13.0, -5.0, -1.0, 8.0, -3.0, 1.0, 7.0, 10.0, -6.0, 14.0, 12.0, -5.0, 10.0, 7.0, -11.0, 9.0, 13.0, -13.0, 4.0, 11.0, -5.0, 2.0, 8.0, 10.0, -1.0, 10.0, 11.0, -5.0, 11.0, -8.0, 0.0, 12.0, 9.0, -3.0, -2.0, 11.0, -8.0, 6.0, 10.0, 7.0, 11.0, -4.0, 10.0, -2.0, 10.0, -2.0, -5.0, 12.0, 13.0, -4.0, -1.0, 7.0, -4.0, 2.0, 12.0, 5.0, -12.0, 8.0, 8.0, 11.0, 8.0, 7.0, -10.0, 10.0, -4.0, 2.0, 5.0, 12.0, -1.0, 13.0, -9.0, 12.0, -14.0, 12.0, 10.0, 7.0, 8.0, -3.0, -3.0, 13.0, 13.0, -10.0, 1.0, 11.0, -2.0, 14.0, -7.0, 10.0, 7.0, -3.0, -1.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22096100506532626, "mean_inference_ms": 1.1773483153191733, "mean_action_processing_ms": 0.07201098085372507, "mean_env_wait_ms": 0.17974962905497396, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 891000, "agent_timesteps_total": 890946, "timers": {"sample_time_ms": 359.571, "sample_throughput": 15017.88, "learn_time_ms": 6395.912, "learn_throughput": 844.289, "update_time_ms": 10.791}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 1590.545654296875, "policy_loss": -0.026857495307922363, "vf_loss": 1590.56884765625, "vf_explained_var": 0.08493932336568832, "kl": 0.006413806229829788, "entropy": 0.4444825053215027, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 891000, "num_agent_steps_sampled": 890946, "num_steps_trained": 891000, "num_agent_steps_trained": 890946}, "done": false, "episodes_total": 17469, "training_iteration": 165, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-28", "timestamp": 1626861688, "time_this_iter_s": 6.868372440338135, "time_total_s": 1187.0587842464447, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702d86a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1187.0587842464447, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 21.890000000000004, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -2.0, 11.0, -4.0, 7.0, 0.0, 12.0, -4.0, 4.0, -5.0, 13.0, 3.0, 9.0, -10.0, 4.0, 12.0, -11.0, 11.0, 12.0, 3.0, 9.0, -5.0, 7.0, 4.0, 1.0, -9.0, 12.0, 11.0, 8.0, -3.0, -2.0, 12.0, 12.0, -10.0, 8.0, 5.0, 4.0, 5.0, 12.0, -6.0, 7.0, -2.0, -2.0, 12.0, 11.0, 4.0, 11.0, -11.0, 3.0, -10.0, 12.0, 10.0, 12.0, -6.0, -4.0, 13.0, 2.0, 2.0, 13.0, -2.0, 7.0, -16.0, 12.0, 12.0, 8.0, -1.0, 12.0, -4.0, 11.0, -1.0, 9.0, -4.0, 6.0, -14.0, 10.0, 13.0, 8.0, -4.0, 12.0, -1.0, -4.0, 2.0, 10.0, 7.0, 12.0, -1.0, 10.0, -6.0, -1.0, -1.0, 12.0, 5.0, 8.0, 7.0, 13.0, -13.0, 2.0, -7.0, 8.0, 12.0, -2.0, -2.0, 6.0, 13.0, 10.0, -15.0, 8.0, 12.0, 8.0, 2.0, 12.0, -7.0, -8.0, 11.0, -1.0, 13.0, 12.0, -11.0, 7.0, 7.0, 13.0, -15.0, 4.0, 13.0, 6.0, 0.0, 12.0, -3.0, 2.0, -7.0, 13.0, 7.0, 13.0, -4.0, 10.0, -4.0, 8.0, -2.0, 12.0, -3.0, 11.0, -13.0, 5.0, 12.0, 13.0, -5.0, 12.0, -5.0, 3.0, -2.0, 12.0, 2.0, -9.0, 4.0, 13.0, 7.0, 3.0, 7.0, 10.0, -5.0, 12.0, -1.0, 12.0, -8.0, -2.0, -1.0, 13.0, 5.0, 2.0, -6.0, 10.0, 9.0, 6.0, -1.0, 12.0, -2.0, 10.0, -8.0, 13.0, 0.0, 8.0, -14.0, 12.0, 9.0, 9.0, 12.0, 12.0, -18.0, 5.0, -10.0, 8.0, 12.0, 9.0, -8.0, 3.0, 11.0, 5.0, -2.0, 12.0, 0.0, 12.0, -13.0, 12.0, 4.0, 2.0, 6.0, 12.0, -5.0, 8.0, -3.0, -3.0, 13.0, 9.0, 2.0, -3.0, 7.0, 8.0, 6.0, 7.0, -6.0, 9.0, -3.0, 12.0, -3.0, 11.0, -3.0, 8.0, -1.0, 8.0, 3.0, 11.0, -7.0, 7.0, -1.0, -4.0, 13.0, 9.0, -15.0, 9.0, 12.0, 8.0, 1.0, 10.0, -4.0, 2.0, -2.0, 2.0, 13.0, 11.0, -10.0, 13.0, 1.0, 9.0, -8.0, 7.0, 7.0, 5.0, 8.0, -11.0, 13.0, 11.0, -10.0, 9.0, 5.0, 3.0, -12.0, 12.0, 12.0, 7.0, 0.0, 12.0, -4.0, 5.0, -5.0, 8.0, 7.0, 8.0, -15.0, 12.0, 10.0, -16.0, 11.0, 7.0, 13.0, 13.0, -7.0, 13.0, -4.0, 4.0, -10.0, 8.0, 13.0, 1.0, 8.0, 12.0, -6.0, -9.0, 0.0, 12.0, 12.0, 2.0, 4.0, 12.0, -3.0, -5.0, 12.0, 12.0, -4.0, 11.0, 1.0, -10.0, 13.0, 9.0, -11.0, 6.0, 11.0, -2.0, -2.0, 6.0, 13.0, 12.0, -10.0, 5.0, 8.0, 13.0, -13.0, 4.0, 11.0, -5.0, 2.0, 8.0, 10.0, -1.0, 10.0, 11.0, -5.0, 11.0, -8.0, 0.0, 12.0, 9.0, -3.0, -2.0, 11.0, -8.0, 6.0, 10.0, 7.0, 11.0, -4.0, 10.0, -2.0, 10.0, -2.0, -5.0, 12.0, 13.0, -4.0, -1.0, 7.0, -4.0, 2.0, 12.0, 5.0, -12.0, 8.0, 8.0, 11.0, 8.0, 7.0, -10.0, 10.0, -4.0, 2.0, 5.0, 12.0, -1.0, 13.0, -9.0, 12.0, -14.0, 12.0, 10.0, 7.0, 8.0, -3.0, -3.0, 13.0, 13.0, -10.0, 1.0, 11.0, -2.0, 14.0, -7.0, 10.0, 7.0, -3.0, -1.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22079821096404065, "mean_inference_ms": 1.1764619769310833, "mean_action_processing_ms": 0.07203061320885139, "mean_env_wait_ms": 0.1796523919521144, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 896400, "agent_timesteps_total": 896319, "timers": {"sample_time_ms": 360.089, "sample_throughput": 14996.299, "learn_time_ms": 6380.871, "learn_throughput": 846.28, "update_time_ms": 10.874}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 22.222824096679688, "policy_loss": -0.0804741233587265, "vf_loss": 22.292509078979492, "vf_explained_var": 0.39802032709121704, "kl": 0.01894313283264637, "entropy": 0.413993775844574, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 896400, "num_agent_steps_sampled": 896319, "num_steps_trained": 896400, "num_agent_steps_trained": 896319}, "done": false, "episodes_total": 17550, "training_iteration": 166, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-35", "timestamp": 1626861695, "time_this_iter_s": 6.726307153701782, "time_total_s": 1193.7850914001465, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029c950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1193.7850914001465, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 22.46, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 8.0, 0.0, 12.0, -10.0, 14.0, 0.0, 11.0, -13.0, 14.0, 6.0, 8.0, 4.0, -11.0, 11.0, 11.0, -7.0, 10.0, 5.0, 7.0, 2.0, 13.0, 8.0, -8.0, 8.0, 14.0, 10.0, -17.0, -7.0, 10.0, 0.0, 12.0, -10.0, 14.0, 4.0, 7.0, 8.0, 13.0, 0.0, -6.0, -8.0, 12.0, 4.0, 7.0, 4.0, -6.0, 6.0, 11.0, 6.0, 7.0, -8.0, 10.0, 11.0, 14.0, -8.0, -2.0, 4.0, 14.0, 5.0, -8.0, 8.0, -3.0, 9.0, 1.0, -6.0, 14.0, -4.0, 11.0, 7.0, 12.0, -3.0, -1.0, -7.0, 14.0, 12.0, -4.0, 7.0, -9.0, 7.0, 10.0, -8.0, 14.0, 5.0, 4.0, 4.0, 14.0, 2.0, -5.0, 12.0, 13.0, -11.0, 1.0, 9.0, -5.0, 3.0, 8.0, -2.0, 10.0, 10.0, -3.0, 10.0, 5.0, 6.0, -6.0, 8.0, 13.0, -17.0, 11.0, 8.0, -5.0, 2.0, 10.0, -5.0, 13.0, 0.0, 7.0, 6.0, 11.0, 11.0, -13.0, 5.0, 2.0, -3.0, 11.0, 9.0, -5.0, 8.0, 3.0, 9.0, 14.0, -15.0, 7.0, 2.0, -3.0, 8.0, 8.0, 8.0, 12.0, -17.0, 12.0, 10.0, -4.0, 5.0, 4.0, -9.0, 13.0, -2.0, 13.0, -3.0, 1.0, 6.0, 11.0, 8.0, 14.0, 10.0, -17.0, -7.0, 11.0, 0.0, 11.0, -5.0, 13.0, -2.0, 9.0, -8.0, 14.0, 0.0, 9.0, 7.0, 13.0, -16.0, 11.0, 10.0, -10.0, 3.0, 12.0, -10.0, 13.0, 3.0, 9.0, 7.0, 13.0, 1.0, -6.0, 8.0, 13.0, 6.0, -12.0, 9.0, -5.0, 13.0, -2.0, -9.0, 9.0, 3.0, 12.0, 6.0, 11.0, -3.0, 1.0, 9.0, 13.0, 11.0, -18.0, -4.0, -4.0, 12.0, 11.0, -6.0, 14.0, -3.0, 10.0, 7.0, 13.0, -3.0, -2.0, 1.0, 11.0, 10.0, -7.0, 8.0, -8.0, 3.0, 12.0, -12.0, 12.0, 6.0, 9.0, 5.0, 13.0, -14.0, 11.0, 8.0, 12.0, -16.0, 11.0, 4.0, -2.0, 1.0, 12.0, -7.0, 9.0, 6.0, 7.0, -9.0, 14.0, -1.0, 11.0, -12.0, 10.0, 8.0, 9.0, 11.0, -5.0, 7.0, 2.0, 4.0, 13.0, -13.0, 11.0, 3.0, 14.0, -11.0, 9.0, 3.0, 10.0, 6.0, -4.0, 8.0, -3.0, -1.0, 11.0, -3.0, 12.0, -4.0, 10.0, -12.0, 14.0, 3.0, 10.0, 11.0, -5.0, 1.0, 8.0, 5.0, -3.0, 1.0, 12.0, -8.0, 13.0, -3.0, 13.0, -8.0, 8.0, 11.0, 4.0, 3.0, 13.0, 7.0, -8.0, 9.0, -5.0, -1.0, 12.0, -10.0, 14.0, 1.0, 10.0, 3.0, 14.0, 0.0, -2.0, 11.0, 13.0, 11.0, -20.0, 5.0, -5.0, 12.0, 3.0, 6.0, 13.0, -14.0, 10.0, 4.0, 9.0, 7.0, -5.0, -2.0, 12.0, 0.0, 5.0, 4.0, -7.0, 7.0, 11.0, -6.0, 14.0, -5.0, 12.0, 9.0, 11.0, 6.0, -11.0, 7.0, 14.0, 4.0, -10.0, 9.0, -7.0, 2.0, 11.0, -7.0, 13.0, 7.0, 2.0, 6.0, 14.0, -17.0, 12.0, 3.0, -7.0, 7.0, 12.0, -1.0, -3.0, 12.0, 7.0, -5.0, 14.0, -3.0, 9.0, 12.0, 11.0, 7.0, -15.0, 8.0, 13.0, 12.0, -18.0, 4.0, -2.0, 3.0, 10.0, -9.0, 14.0, 6.0, 4.0, -10.0, 14.0, 0.0, 11.0, 8.0, 12.0, -13.0, 8.0, 13.0, -5.0, -3.0, 10.0, 10.0, 13.0, -18.0, 10.0, -12.0, 14.0, 2.0, 11.0, 13.0, 12.0, 3.0, -13.0, 13.0, -10.0, 0.0, 12.0, 5.0, 13.0, -13.0, 10.0, 12.0, 14.0, 6.0, -17.0, -14.0, 13.0, 9.0, 7.0, 6.0, -2.0, 7.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22106642337770632, "mean_inference_ms": 1.1775068544643095, "mean_action_processing_ms": 0.07202041573761865, "mean_env_wait_ms": 0.17976136151200403, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 901800, "agent_timesteps_total": 901719, "timers": {"sample_time_ms": 360.563, "sample_throughput": 14976.57, "learn_time_ms": 6382.859, "learn_throughput": 846.016, "update_time_ms": 10.944}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 20.913469314575195, "policy_loss": -0.07858550548553467, "vf_loss": 20.98223114013672, "vf_explained_var": 0.4165628254413605, "kl": 0.017252668738365173, "entropy": 0.4332273304462433, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 901800, "num_agent_steps_sampled": 901719, "num_steps_trained": 901800, "num_agent_steps_trained": 901719}, "done": false, "episodes_total": 17658, "training_iteration": 167, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-42", "timestamp": 1626861702, "time_this_iter_s": 6.878811597824097, "time_total_s": 1200.6639029979706, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1200.6639029979706, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 22.68, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.425925925925927, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.106481481481482}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 11.0, 11.0, -2.0, 6.0, 5.0, 10.0, -6.0, 10.0, -13.0, 5.0, 13.0, 11.0, 3.0, -3.0, 4.0, 13.0, 11.0, -4.0, -5.0, -8.0, 11.0, 4.0, 8.0, -9.0, 10.0, 7.0, 7.0, 14.0, -19.0, 9.0, 11.0, 12.0, 11.0, -5.0, -3.0, 10.0, 12.0, 4.0, -11.0, 12.0, -9.0, 5.0, 7.0, 8.0, -2.0, -1.0, 10.0, 13.0, 12.0, -9.0, -1.0, 14.0, 1.0, -4.0, 4.0, 11.0, -12.0, 3.0, 13.0, 0.0, -2.0, 6.0, 11.0, 13.0, 11.0, 9.0, -18.0, 13.0, -4.0, -1.0, 7.0, -9.0, 11.0, 7.0, 6.0, 10.0, -10.0, 12.0, 3.0, -3.0, 14.0, -6.0, 10.0, 11.0, 1.0, -4.0, 7.0, 8.0, -9.0, 13.0, 3.0, 12.0, -8.0, 7.0, 4.0, -1.0, 9.0, -3.0, 10.0, 14.0, 12.0, -14.0, 3.0, -3.0, 4.0, 8.0, 6.0, 11.0, -16.0, 11.0, 9.0, -3.0, 10.0, 5.0, 3.0, 13.0, 6.0, -2.0, -2.0, 5.0, 12.0, -8.0, 6.0, 7.0, 10.0, 8.0, -10.0, -9.0, 13.0, 2.0, 9.0, 9.0, -7.0, 2.0, 11.0, -5.0, 5.0, 2.0, 13.0, 1.0, -7.0, 9.0, 12.0, -3.0, 9.0, 2.0, 7.0, 14.0, 320.0, 8.0, 12.0, 12.0, -3.0, -3.0, 9.0, 6.0, -8.0, 12.0, 5.0, -2.0, 9.0, 2.0, 6.0, 14.0, 321.0, 9.0, 11.0, -8.0, 7.0, 3.0, 13.0, 8.0, -5.0, 3.0, 9.0, -2.0, 13.0, -5.0, 9.0, 4.0, -7.0, 9.0, 9.0, 8.0, -9.0, 13.0, 3.0, 4.0, 5.0, -2.0, 8.0, 5.0, 12.0, -12.0, 10.0, 9.0, -7.0, 8.0, 5.0, 11.0, 11.0, 13.0, 319.0, 10.0, -8.0, 13.0, 0.0, 12.0, 12.0, -3.0, -6.0, 13.0, 1.0, -6.0, 7.0, 9.0, 7.0, -9.0, 8.0, 10.0, -13.0, 9.0, 9.0, 13.0, 9.0, -4.0, -3.0, 13.0, -15.0, 12.0, 5.0, -7.0, 3.0, 11.0, 8.0, 5.0, -9.0, 13.0, 6.0, -2.0, 9.0, -4.0, 12.0, 12.0, -14.0, 7.0, 10.0, 6.0, 10.0, -9.0, 8.0, 9.0, 1.0, -6.0, 11.0, -3.0, 11.0, -2.0, 9.0, 11.0, -3.0, 11.0, -4.0, 9.0, 11.0, 3.0, -8.0, 2.0, -4.0, 12.0, 5.0, 11.0, 12.0, -7.0, -1.0, 10.0, 6.0, 6.0, -7.0, 7.0, -8.0, 8.0, 8.0, 8.0, -2.0, -2.0, 11.0, 11.0, 13.0, -2.0, -7.0, 11.0, -8.0, 9.0, 3.0, -5.0, 12.0, -2.0, 10.0, 5.0, -12.0, 11.0, 11.0, -2.0, 12.0, 8.0, -3.0, 14.0, -15.0, 7.0, 9.0, 6.0, -3.0, 11.0, 1.0, 7.0, 9.0, 12.0, -13.0, 9.0, 14.0, -5.0, -3.0, 12.0, -8.0, 7.0, 4.0, 11.0, 2.0, -11.0, 13.0, 3.0, -3.0, 13.0, 2.0, -5.0, 14.0, -4.0, 10.0, 14.0, -17.0, 8.0, 10.0, -3.0, 0.0, 5.0, 13.0, 5.0, -10.0, 13.0, 7.0, -2.0, 10.0, -3.0, 10.0, 11.0, -10.0, 10.0, 4.0, 12.0, -11.0, 9.0, 5.0, 5.0, -6.0, 11.0, 5.0, 10.0, 6.0, 2.0, -3.0, 13.0, 4.0, -13.0, 11.0, 12.0, 3.0, 12.0, -12.0, 4.0, -3.0, 1.0, 13.0, -1.0, 13.0, -8.0, 11.0, 8.0, -8.0, 8.0, 7.0, 8.0, -8.0, 12.0, 3.0, 12.0, -10.0, 4.0, 9.0, 10.0, 9.0, 1.0, -5.0, 9.0, -9.0, 10.0, 5.0, 11.0, 5.0, -8.0, 7.0, 8.0, -15.0, 10.0, 12.0, 13.0, 9.0, -10.0, 3.0, 8.0, 5.0, 12.0, -10.0, 10.0, -9.0, 6.0, 8.0, 5.0, 6.0, 11.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22113187935753753, "mean_inference_ms": 1.177563159669068, "mean_action_processing_ms": 0.07202762253513534, "mean_env_wait_ms": 0.17977326881291766, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 907200, "agent_timesteps_total": 907119, "timers": {"sample_time_ms": 360.463, "sample_throughput": 14980.729, "learn_time_ms": 6387.178, "learn_throughput": 845.444, "update_time_ms": 10.947}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 716.3700561523438, "policy_loss": -0.02745668590068817, "vf_loss": 716.3944091796875, "vf_explained_var": 0.1397111415863037, "kl": 0.005526951979845762, "entropy": 0.4331778287887573, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 907200, "num_agent_steps_sampled": 907119, "num_steps_trained": 907200, "num_agent_steps_trained": 907119}, "done": false, "episodes_total": 17766, "training_iteration": 168, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-48", "timestamp": 1626861708, "time_this_iter_s": 6.858286619186401, "time_total_s": 1207.522189617157, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1207.522189617157, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 21.93333333333333, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [2.0, 13.0, 6.0, -6.0, 12.0, 14.0, 6.0, -17.0, 9.0, -9.0, 11.0, 4.0, 14.0, -7.0, 9.0, -1.0, -6.0, 13.0, -1.0, 9.0, 13.0, 13.0, -16.0, 5.0, 9.0, 14.0, -18.0, 10.0, 14.0, 14.0, -5.0, -8.0, -7.0, 11.0, 0.0, 11.0, 10.0, 11.0, 6.0, -12.0, 5.0, 6.0, -3.0, 7.0, 12.0, 14.0, -4.0, -7.0, 10.0, -2.0, 3.0, 4.0, 12.0, 13.0, 2.0, -12.0, 14.0, 5.0, -12.0, 8.0, 12.0, 14.0, 9.0, -20.0, 13.0, -3.0, 2.0, 3.0, 12.0, 13.0, -4.0, -6.0, 8.0, 8.0, -10.0, 9.0, 14.0, 5.0, 6.0, -10.0, 10.0, -7.0, 4.0, 8.0, 9.0, 11.0, 4.0, -9.0, 14.0, 3.0, -11.0, 9.0, 10.0, -6.0, 6.0, 5.0, 13.0, -7.0, 8.0, 1.0, 12.0, 14.0, -9.0, -2.0, 7.0, 13.0, -12.0, 7.0, 13.0, 11.0, 10.0, -19.0, 12.0, 7.0, -11.0, 7.0, 8.0, 10.0, -8.0, 5.0, 9.0, 8.0, -7.0, 5.0, 14.0, 7.0, -10.0, 4.0, -2.0, 3.0, 3.0, 11.0, 14.0, 12.0, -11.0, 0.0, 9.0, 8.0, 10.0, -12.0, 13.0, -12.0, 1.0, 13.0, -2.0, 5.0, 5.0, 7.0, 9.0, 12.0, 7.0, -13.0, 9.0, 6.0, -3.0, 3.0, 14.0, 14.0, 3.0, -16.0, -2.0, 8.0, 3.0, 6.0, 12.0, 14.0, 3.0, -14.0, 14.0, 8.0, -16.0, 9.0, 14.0, -16.0, 8.0, 9.0, 9.0, -2.0, 7.0, 1.0, 9.0, 14.0, 9.0, -17.0, 8.0, 4.0, -6.0, 9.0, 12.0, 14.0, 9.0, -20.0, 13.0, -9.0, 1.0, 10.0, 8.0, 13.0, -2.0, -4.0, 7.0, 8.0, -4.0, 4.0, 13.0, 0.0, 10.0, -8.0, 11.0, -4.0, 2.0, 6.0, 11.0, 13.0, -6.0, -3.0, 14.0, 9.0, -16.0, 8.0, 12.0, 13.0, 10.0, -20.0, -2.0, 11.0, -2.0, 8.0, 10.0, 14.0, -10.0, 1.0, 7.0, 8.0, -9.0, 9.0, 10.0, -3.0, 5.0, 3.0, 12.0, 11.0, 3.0, -11.0, 14.0, 13.0, -19.0, 7.0, 7.0, 7.0, -4.0, 5.0, 14.0, 14.0, -8.0, -5.0, -3.0, 7.0, 7.0, 4.0, 6.0, 13.0, -13.0, 9.0, 4.0, 7.0, -4.0, 8.0, 14.0, -5.0, 2.0, 4.0, 5.0, 13.0, 4.0, -7.0, 12.0, 13.0, -13.0, 3.0, 9.0, 6.0, -8.0, 8.0, 14.0, 4.0, -5.0, 2.0, 13.0, -11.0, 8.0, 5.0, 8.0, 12.0, 3.0, -8.0, 11.0, 3.0, -8.0, 9.0, 10.0, 14.0, 10.0, -19.0, -1.0, 12.0, -4.0, 8.0, 13.0, 14.0, 4.0, -16.0, 7.0, 3.0, 11.0, -6.0, 9.0, 9.0, -1.0, -2.0, -14.0, 11.0, 7.0, 11.0, 7.0, 14.0, -9.0, 3.0, 9.0, 5.0, -4.0, 5.0, 12.0, 13.0, 9.0, -19.0, 3.0, -2.0, 9.0, 5.0, 11.0, 13.0, -2.0, -7.0, 9.0, 8.0, -8.0, 6.0, 12.0, 14.0, -3.0, -8.0, -2.0, 7.0, 5.0, 5.0, 9.0, 10.0, -7.0, 3.0, 6.0, 7.0, -7.0, 9.0, 14.0, 4.0, 9.0, -12.0, 13.0, 6.0, 4.0, -8.0, 9.0, 13.0, 6.0, -13.0, 2.0, 8.0, 10.0, -5.0, 9.0, -7.0, 1.0, 12.0, 11.0, -7.0, 5.0, 6.0, 7.0, 10.0, -6.0, 4.0, 6.0, 3.0, 10.0, -4.0, 12.0, 13.0, 12.0, -22.0, 7.0, -5.0, 4.0, 9.0, 9.0, 13.0, -11.0, 4.0, 9.0, 8.0, 11.0, -13.0, 10.0, 1.0, -8.0, 12.0, 5.0, -7.0, 12.0, 5.0, 13.0, 13.0, 0.0, -11.0, 4.0, 9.0, 11.0, -9.0, 9.0, 11.0, -5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2211620354736342, "mean_inference_ms": 1.1775491908063724, "mean_action_processing_ms": 0.07202190833265949, "mean_env_wait_ms": 0.17977165740635448, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 912600, "agent_timesteps_total": 912519, "timers": {"sample_time_ms": 359.435, "sample_throughput": 15023.597, "learn_time_ms": 6390.328, "learn_throughput": 845.027, "update_time_ms": 11.116}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 22.991355895996094, "policy_loss": -0.06894612312316895, "vf_loss": 23.050739288330078, "vf_explained_var": 0.37113747000694275, "kl": 0.016789481043815613, "entropy": 0.42130690813064575, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 912600, "num_agent_steps_sampled": 912519, "num_steps_trained": 912600, "num_agent_steps_trained": 912519}, "done": false, "episodes_total": 17874, "training_iteration": 169, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-01-55", "timestamp": 1626861715, "time_this_iter_s": 6.873607397079468, "time_total_s": 1214.3957970142365, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70228c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1214.3957970142365, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 21.919999999999995, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.27777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.319444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -2.0, 6.0, 4.0, -6.0, 6.0, 5.0, 10.0, -12.0, 6.0, 9.0, 12.0, 10.0, -2.0, -2.0, 9.0, 2.0, 14.0, -12.0, 11.0, -7.0, 3.0, 11.0, 8.0, 4.0, 6.0, -6.0, 11.0, 12.0, 4.0, -6.0, 5.0, 7.0, 12.0, -8.0, 4.0, 11.0, 1.0, -10.0, 13.0, 7.0, -7.0, 2.0, 13.0, 10.0, -15.0, 10.0, 10.0, -7.0, 14.0, 5.0, 3.0, -12.0, 11.0, 11.0, 5.0, -14.0, 12.0, 10.0, 7.0, 7.0, 3.0, -2.0, 7.0, 7.0, 13.0, -9.0, 4.0, 10.0, 7.0, -13.0, 11.0, 5.0, -6.0, 5.0, 11.0, 9.0, 1.0, -3.0, 8.0, -3.0, 9.0, 8.0, 1.0, -5.0, 3.0, 5.0, 12.0, 8.0, -8.0, 2.0, 13.0, 7.0, 1.0, -3.0, 10.0, -13.0, 8.0, 8.0, 12.0, 6.0, 0.0, 10.0, -1.0, -12.0, 12.0, 5.0, 10.0, 9.0, 4.0, -3.0, 5.0, -14.0, 14.0, 7.0, 8.0, 2.0, 3.0, -1.0, 11.0, -4.0, -2.0, 9.0, 12.0, 7.0, 3.0, -5.0, 10.0, -5.0, -5.0, 12.0, 13.0, -8.0, 12.0, 0.0, 11.0, 1.0, -3.0, 5.0, 12.0, -11.0, 6.0, 7.0, 13.0, -13.0, 12.0, 4.0, 12.0, 12.0, -3.0, 8.0, -2.0, 1.0, -4.0, 10.0, 8.0, 7.0, 6.0, -6.0, 8.0, 1.0, 8.0, -7.0, 13.0, 7.0, 7.0, -12.0, 13.0, -11.0, 11.0, 2.0, 13.0, 2.0, 4.0, -3.0, 12.0, 6.0, 8.0, -4.0, 5.0, -4.0, 8.0, 12.0, -1.0, 6.0, 10.0, -13.0, 12.0, 11.0, 4.0, -7.0, 7.0, -2.0, -3.0, 8.0, 12.0, 6.0, 3.0, 13.0, -7.0, -9.0, 7.0, 5.0, 12.0, 6.0, 5.0, -6.0, 10.0, 12.0, -5.0, 5.0, 3.0, 9.0, -3.0, -3.0, 12.0, 6.0, 6.0, -10.0, 13.0, 11.0, -7.0, -2.0, 13.0, -5.0, 13.0, -6.0, 13.0, -1.0, -4.0, 8.0, 12.0, 5.0, -3.0, 1.0, 12.0, 13.0, -6.0, 11.0, -3.0, 4.0, 14.0, -9.0, 6.0, 13.0, 11.0, -7.0, -2.0, 318.0, 11.0, 11.0, 12.0, 6.0, 10.0, -10.0, 9.0, -3.0, 12.0, 0.0, 6.0, 6.0, 12.0, -1.0, -2.0, 6.0, -6.0, 2.0, 13.0, 13.0, -3.0, 8.0, -3.0, 4.0, 13.0, 9.0, -11.0, 4.0, 11.0, 6.0, -6.0, 7.0, 1.0, -6.0, 13.0, 6.0, 8.0, 11.0, -10.0, -15.0, 11.0, 11.0, 8.0, 5.0, -1.0, -1.0, 12.0, 6.0, -2.0, 4.0, 7.0, 12.0, -7.0, -2.0, 12.0, -5.0, 12.0, 1.0, 7.0, -9.0, 0.0, 11.0, 13.0, 6.0, -8.0, 7.0, 10.0, 7.0, 4.0, -6.0, 10.0, -15.0, 14.0, 4.0, 12.0, -14.0, 12.0, 4.0, 13.0, -16.0, 8.0, 11.0, 12.0, 13.0, 5.0, 9.0, -12.0, -17.0, 14.0, 10.0, 8.0, 1.0, 3.0, 12.0, -1.0, -16.0, 10.0, 11.0, 10.0, 13.0, 5.0, -2.0, -1.0, -2.0, -5.0, 10.0, 12.0, -8.0, 6.0, 5.0, 12.0, -5.0, 7.0, 0.0, 13.0, 6.0, 9.0, -10.0, 10.0, 9.0, 14.0, 8.0, -16.0, 10.0, 8.0, 0.0, -3.0, 1.0, 12.0, -11.0, 13.0, 12.0, 321.0, 11.0, 12.0, 1.0, 12.0, -10.0, 12.0, -2.0, 7.0, 12.0, -2.0, -14.0, 11.0, 6.0, 12.0, 12.0, -5.0, 11.0, -3.0, 13.0, 14.0, 8.0, -20.0, 4.0, 7.0, 5.0, -1.0, -13.0, 12.0, 3.0, 13.0, 7.0, -8.0, 4.0, 12.0, -1.0, 14.0, -10.0, 12.0, -2.0, -5.0, 9.0, 13.0, -3.0, 5.0, 0.0, 13.0, 9.0, -10.0, 5.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22119250816644723, "mean_inference_ms": 1.177677004307447, "mean_action_processing_ms": 0.072027218677019, "mean_env_wait_ms": 0.17978864911263454, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 918000, "agent_timesteps_total": 917919, "timers": {"sample_time_ms": 359.999, "sample_throughput": 15000.05, "learn_time_ms": 6388.49, "learn_throughput": 845.27, "update_time_ms": 10.876}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 436.4355163574219, "policy_loss": -0.02236541546881199, "vf_loss": 436.45379638671875, "vf_explained_var": 0.17019174993038177, "kl": 0.0070428987964987755, "entropy": 0.42793434858322144, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 918000, "num_agent_steps_sampled": 917919, "num_steps_trained": 918000, "num_agent_steps_trained": 917919}, "done": false, "episodes_total": 17982, "training_iteration": 170, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-02", "timestamp": 1626861722, "time_this_iter_s": 6.855236291885376, "time_total_s": 1221.2510333061218, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e842150d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1221.2510333061218, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 22.05, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 369.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.77777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 6.194444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 16.0, 15.0, 15.0, 355.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 369.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 368.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 4.0, -14.0, 12.0, -13.0, 14.0, 7.0, 7.0, -11.0, 13.0, 12.0, 2.0, 12.0, -5.0, 13.0, -5.0, 14.0, -8.0, -3.0, 12.0, 320.0, 12.0, 11.0, 12.0, 9.0, 8.0, 8.0, -9.0, 5.0, 6.0, -9.0, 13.0, 13.0, -14.0, 5.0, 11.0, -8.0, -2.0, 12.0, 13.0, 8.0, 8.0, 9.0, -9.0, -3.0, -1.0, 6.0, 13.0, 13.0, -5.0, -6.0, 13.0, -9.0, 6.0, 7.0, 11.0, -13.0, 9.0, 9.0, 10.0, 12.0, -3.0, 11.0, -5.0, 13.0, 12.0, 331.0, 13.0, 11.0, -3.0, 11.0, -4.0, -3.0, 8.0, 7.0, 4.0, 9.0, -12.0, 7.0, 11.0, 6.0, 6.0, -1.0, 4.0, 2.0, -1.0, 3.0, 11.0, 8.0, 8.0, 9.0, -9.0, -2.0, -3.0, 7.0, 13.0, 9.0, 5.0, -6.0, 7.0, -2.0, 5.0, 6.0, 6.0, -10.0, 9.0, 8.0, 8.0, 13.0, -18.0, 10.0, 10.0, -2.0, 12.0, -7.0, 12.0, -9.0, 9.0, 7.0, 8.0, -9.0, 12.0, 3.0, 9.0, 11.0, -2.0, 11.0, -5.0, 14.0, 10.0, -22.0, 13.0, 5.0, -7.0, 4.0, 13.0, 2.0, 9.0, -6.0, 10.0, 5.0, -8.0, 6.0, 12.0, 13.0, -11.0, 0.0, 13.0, -4.0, 1.0, 5.0, 13.0, 10.0, 8.0, 10.0, -13.0, 12.0, 10.0, 12.0, -19.0, 13.0, -15.0, 9.0, 8.0, 9.0, -8.0, 1.0, 13.0, 3.0, 8.0, 11.0, -6.0, 13.0, 0.0, -10.0, 12.0, 13.0, -10.0, -1.0, 13.0, 8.0, -6.0, 12.0, 1.0, 9.0, 10.0, -13.0, 9.0, 9.0, -7.0, 1.0, 12.0, 13.0, -13.0, 2.0, 13.0, -20.0, 13.0, 10.0, 12.0, 6.0, 7.0, 8.0, -6.0, 8.0, -10.0, 4.0, 13.0, 13.0, -12.0, 1.0, 13.0, -4.0, 5.0, 6.0, 8.0, -7.0, 8.0, 11.0, 3.0, 13.0, -9.0, 12.0, -1.0, 13.0, 9.0, -13.0, 6.0, 6.0, -7.0, 4.0, 12.0, -12.0, 9.0, 8.0, 10.0, 7.0, -8.0, 8.0, 8.0, 7.0, 10.0, 5.0, -7.0, -4.0, 7.0, 0.0, 12.0, -10.0, 8.0, 9.0, 8.0, 8.0, -11.0, 6.0, 12.0, 14.0, -12.0, 0.0, 13.0, -12.0, 14.0, 0.0, 13.0, -10.0, 14.0, 3.0, 8.0, 6.0, 8.0, -9.0, 10.0, 12.0, -8.0, -1.0, 12.0, -3.0, 0.0, 5.0, 13.0, -7.0, 8.0, 7.0, 8.0, -3.0, 6.0, 10.0, 2.0, 13.0, 12.0, 331.0, 12.0, -5.0, 7.0, 6.0, 7.0, -8.0, 8.0, 8.0, 8.0, 11.0, 3.0, 11.0, -10.0, 13.0, -3.0, -7.0, 12.0, -18.0, 12.0, 11.0, 10.0, -9.0, 13.0, 3.0, 8.0, 12.0, -11.0, 8.0, 6.0, 13.0, 10.0, -21.0, 13.0, -18.0, 14.0, 12.0, 7.0, -5.0, 13.0, 5.0, 3.0, 10.0, -3.0, 6.0, 2.0, 12.0, 9.0, -15.0, 9.0, -14.0, 9.0, 12.0, 8.0, -8.0, 10.0, 8.0, 5.0, 13.0, 4.0, -9.0, 7.0, 12.0, 9.0, -17.0, 11.0, -18.0, 14.0, 7.0, 12.0, 6.0, 14.0, 7.0, -12.0, 5.0, -8.0, 5.0, 13.0, 13.0, 9.0, -16.0, 9.0, 6.0, -5.0, 1.0, 13.0, -8.0, 11.0, 9.0, 3.0, 13.0, 6.0, 12.0, -16.0, 13.0, -16.0, 9.0, 9.0, 3.0, -2.0, 12.0, 2.0, 4.0, 14.0, 7.0, -10.0, 5.0, 7.0, -9.0, 12.0, 0.0, 12.0, -10.0, 13.0, -6.0, 6.0, 3.0, 12.0, 2.0, 9.0, -6.0, 10.0, 13.0, -2.0, 12.0, -8.0, 13.0, -16.0, 8.0, 10.0, -17.0, 14.0, 9.0, 9.0, -10.0, 8.0, 7.0, 10.0, 13.0, -18.0, 7.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22119773479809196, "mean_inference_ms": 1.177549218113224, "mean_action_processing_ms": 0.07202023650685259, "mean_env_wait_ms": 0.17979279909844373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 923400, "agent_timesteps_total": 923319, "timers": {"sample_time_ms": 359.23, "sample_throughput": 15032.167, "learn_time_ms": 6384.293, "learn_throughput": 845.826, "update_time_ms": 10.898}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 423.4723815917969, "policy_loss": -0.022352498024702072, "vf_loss": 423.4913330078125, "vf_explained_var": 0.15889139473438263, "kl": 0.006131154019385576, "entropy": 0.4494558870792389, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 923400, "num_agent_steps_sampled": 923319, "num_steps_trained": 923400, "num_agent_steps_trained": 923319}, "done": false, "episodes_total": 18090, "training_iteration": 171, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-09", "timestamp": 1626861729, "time_this_iter_s": 6.8148791790008545, "time_total_s": 1228.0659124851227, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7029cf28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1228.0659124851227, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 21.949999999999996, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 12.0, -11.0, 7.0, 8.0, -2.0, 2.0, 7.0, 3.0, 14.0, 8.0, -10.0, -3.0, 7.0, 10.0, 1.0, 6.0, 5.0, -8.0, 12.0, 9.0, 13.0, 0.0, -7.0, 2.0, 12.0, 2.0, -1.0, 6.0, -2.0, 13.0, -2.0, 7.0, 13.0, -11.0, 6.0, 12.0, -7.0, -2.0, 12.0, 7.0, 0.0, 2.0, 6.0, 12.0, -8.0, -2.0, 13.0, 6.0, -1.0, 8.0, 2.0, 14.0, 13.0, -5.0, -7.0, 5.0, 13.0, 4.0, -7.0, 8.0, 7.0, 13.0, -13.0, 11.0, 12.0, -11.0, 3.0, 9.0, 13.0, -17.0, 10.0, 1.0, -1.0, 3.0, 12.0, 4.0, -10.0, 13.0, 8.0, 5.0, 1.0, -3.0, 12.0, 11.0, 13.0, -18.0, 9.0, 3.0, 13.0, 7.0, -8.0, -8.0, 4.0, 13.0, 6.0, -3.0, 11.0, 3.0, 4.0, 10.0, 13.0, -15.0, 7.0, 9.0, 12.0, -2.0, -4.0, 9.0, 6.0, 11.0, -11.0, 9.0, 11.0, -9.0, 4.0, 13.0, 12.0, -3.0, -7.0, 6.0, 7.0, 3.0, -1.0, 4.0, -9.0, 12.0, 8.0, 6.0, 0.0, 11.0, -2.0, 7.0, 13.0, -10.0, 5.0, 2.0, -1.0, 3.0, 11.0, 7.0, -8.0, 13.0, 3.0, 13.0, 12.0, -9.0, -1.0, 13.0, 13.0, 0.0, -11.0, 0.0, 0.0, 5.0, 10.0, -5.0, 6.0, 13.0, 1.0, 3.0, -2.0, 12.0, 2.0, 9.0, 13.0, 2.0, -9.0, -11.0, 14.0, 5.0, 7.0, 1.0, -11.0, 13.0, 12.0, -7.0, 6.0, 8.0, 8.0, 8.0, 11.0, 3.0, -7.0, 6.0, -1.0, 1.0, 9.0, 9.0, 6.0, 12.0, -12.0, -2.0, 9.0, 2.0, 6.0, 8.0, -1.0, 3.0, 5.0, -10.0, 14.0, 1.0, 10.0, 8.0, -11.0, 12.0, 6.0, 5.0, 6.0, -8.0, 12.0, -6.0, 10.0, 5.0, 6.0, 4.0, 14.0, 0.0, -3.0, 7.0, -15.0, 12.0, 11.0, 10.0, 0.0, 2.0, 3.0, 12.0, 11.0, 0.0, -8.0, -4.0, 13.0, -3.0, 9.0, -5.0, 1.0, 12.0, 7.0, 4.0, 14.0, -7.0, 4.0, 13.0, 12.0, -15.0, 5.0, 2.0, 14.0, 7.0, -8.0, 8.0, -2.0, 11.0, -2.0, 13.0, 1.0, -10.0, 11.0, 8.0, 13.0, 9.0, -15.0, 4.0, 13.0, 5.0, -7.0, 7.0, 10.0, 12.0, -14.0, -1.0, 5.0, 5.0, 6.0, 14.0, 12.0, -1.0, -10.0, 2.0, 14.0, 1.0, -2.0, -6.0, 9.0, 10.0, 2.0, 11.0, 9.0, -14.0, 9.0, 5.0, 11.0, -8.0, 7.0, -3.0, 14.0, 0.0, 4.0, 9.0, -14.0, 10.0, 10.0, 13.0, 11.0, -16.0, 7.0, 13.0, -2.0, -6.0, 10.0, 3.0, 11.0, 2.0, -1.0, 7.0, 4.0, -8.0, 12.0, -4.0, 13.0, 1.0, 5.0, -4.0, 9.0, -1.0, 11.0, 5.0, 13.0, 4.0, -7.0, 2.0, 7.0, 13.0, -7.0, -8.0, 14.0, -2.0, 11.0, 13.0, 12.0, -2.0, -8.0, -6.0, 14.0, 7.0, 0.0, 12.0, -12.0, 12.0, 3.0, -7.0, 14.0, 0.0, 8.0, -4.0, 8.0, 2.0, 9.0, 4.0, 12.0, 7.0, -8.0, 8.0, -3.0, 12.0, -2.0, 10.0, 14.0, -7.0, -2.0, 12.0, 11.0, -16.0, 8.0, -14.0, 14.0, 4.0, 11.0, 7.0, 3.0, 13.0, -8.0, 6.0, 2.0, -5.0, 12.0, -1.0, 13.0, -3.0, 6.0, 11.0, 8.0, 0.0, -4.0, -10.0, 5.0, 12.0, 8.0, 13.0, -6.0, -4.0, 12.0, 10.0, 13.0, 2.0, -10.0, 6.0, 12.0, 0.0, -3.0, -7.0, 10.0, 12.0, 0.0, -7.0, 9.0, 6.0, 7.0, 9.0, 12.0, -10.0, 4.0, 11.0, -6.0, 0.0, 10.0, 6.0, 3.0, 13.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22123647080337716, "mean_inference_ms": 1.1777189324676345, "mean_action_processing_ms": 0.07202452146423294, "mean_env_wait_ms": 0.17981725668762058, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 928800, "agent_timesteps_total": 928719, "timers": {"sample_time_ms": 359.291, "sample_throughput": 15029.598, "learn_time_ms": 6400.683, "learn_throughput": 843.66, "update_time_ms": 10.879}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 20.092103958129883, "policy_loss": -0.08716633170843124, "vf_loss": 20.168811798095703, "vf_explained_var": 0.3133830726146698, "kl": 0.018357710912823677, "entropy": 0.44123148918151855, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 928800, "num_agent_steps_sampled": 928719, "num_steps_trained": 928800, "num_agent_steps_trained": 928719}, "done": false, "episodes_total": 18198, "training_iteration": 172, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-16", "timestamp": 1626861736, "time_this_iter_s": 7.029541969299316, "time_total_s": 1235.095454454422, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70228a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1235.095454454422, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 22.000000000000004, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.453703703703702, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 6.113425925925926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 14.0, 2.0, -15.0, 10.0, 10.0, -14.0, 9.0, 8.0, 2.0, -7.0, 12.0, -4.0, 0.0, 12.0, 7.0, 0.0, -6.0, 10.0, 11.0, 9.0, 3.0, 7.0, -4.0, 4.0, 13.0, 6.0, -8.0, 14.0, 8.0, -18.0, 11.0, 6.0, 14.0, -14.0, 9.0, 14.0, 4.0, -16.0, 13.0, 8.0, 6.0, -7.0, 8.0, -12.0, 6.0, 10.0, 11.0, 13.0, 14.0, -16.0, 4.0, 14.0, 6.0, -2.0, -3.0, 2.0, 4.0, 11.0, -2.0, 1.0, 8.0, 11.0, -5.0, 11.0, 11.0, -16.0, 9.0, 6.0, 10.0, -10.0, 9.0, 6.0, 6.0, 4.0, -1.0, 12.0, 14.0, 10.0, 319.0, 0.0, 9.0, 6.0, 0.0, 14.0, 9.0, -20.0, 12.0, 8.0, 13.0, -3.0, -3.0, 11.0, 8.0, -16.0, 12.0, 14.0, 14.0, -9.0, -4.0, 6.0, 6.0, -6.0, 9.0, 9.0, 5.0, -9.0, 10.0, 3.0, -1.0, 3.0, 10.0, -5.0, 14.0, 7.0, -1.0, 13.0, -10.0, 0.0, 12.0, 4.0, 8.0, -9.0, 12.0, 4.0, 8.0, -7.0, 10.0, 12.0, 12.0, 9.0, -18.0, 13.0, 5.0, 6.0, -9.0, 7.0, 10.0, 9.0, -11.0, 11.0, 8.0, 9.0, -13.0, 9.0, 13.0, -10.0, 3.0, 8.0, 10.0, -10.0, 7.0, 0.0, 5.0, -2.0, 12.0, 6.0, -12.0, 10.0, 11.0, 10.0, 13.0, 10.0, -18.0, 4.0, 10.0, -11.0, 12.0, 12.0, -1.0, 5.0, -1.0, 12.0, 0.0, -2.0, 5.0, 14.0, 13.0, -3.0, -9.0, 14.0, 10.0, -22.0, 13.0, 7.0, 5.0, -9.0, 12.0, -8.0, 5.0, 11.0, 7.0, 10.0, 7.0, -8.0, 6.0, 12.0, 9.0, 6.0, -12.0, 11.0, 1.0, 4.0, -1.0, 9.0, 13.0, -17.0, 10.0, 4.0, 14.0, 3.0, -6.0, 14.0, 10.0, 13.0, -22.0, 13.0, 10.0, 320.0, 13.0, 7.0, 5.0, -3.0, 6.0, 13.0, 13.0, -17.0, 6.0, 11.0, 9.0, -18.0, 13.0, 12.0, 9.0, -4.0, -2.0, -17.0, 13.0, 10.0, 9.0, 14.0, 11.0, 5.0, -15.0, 14.0, 10.0, -22.0, 13.0, 2.0, 8.0, 9.0, -4.0, 6.0, 6.0, 12.0, -9.0, -14.0, 11.0, 10.0, 8.0, 4.0, 9.0, -11.0, 13.0, 7.0, -1.0, -3.0, 12.0, 2.0, 8.0, -2.0, 7.0, 13.0, 11.0, -14.0, 5.0, 14.0, -3.0, -4.0, 8.0, 12.0, 3.0, 1.0, -1.0, 8.0, 8.0, 6.0, -7.0, 8.0, -9.0, 5.0, 11.0, 14.0, -9.0, 4.0, 6.0, 12.0, 12.0, 318.0, 13.0, 1.0, 13.0, 4.0, -3.0, 14.0, 14.0, 3.0, -16.0, 8.0, 11.0, 5.0, -9.0, 9.0, 9.0, 6.0, -9.0, 10.0, 10.0, 11.0, -16.0, 13.0, 11.0, 5.0, -14.0, 14.0, 8.0, -15.0, 8.0, 13.0, 5.0, -2.0, -1.0, 5.0, 14.0, 9.0, -13.0, 13.0, 11.0, -14.0, 5.0, 14.0, -3.0, -3.0, 7.0, 12.0, 1.0, 3.0, -1.0, 6.0, 9.0, 10.0, -10.0, 11.0, 12.0, -11.0, 3.0, 9.0, -8.0, 3.0, 11.0, 8.0, 1.0, -7.0, 13.0, 14.0, -13.0, 9.0, 5.0, 1.0, 12.0, -4.0, 6.0, 2.0, -5.0, 6.0, 12.0, 7.0, 0.0, 9.0, -1.0, 3.0, 13.0, 2.0, -3.0, 7.0, 11.0, -12.0, 9.0, 8.0, 10.0, -12.0, 9.0, 12.0, 3.0, 1.0, -1.0, 7.0, 8.0, -10.0, 10.0, 11.0, 9.0, -15.0, 10.0, 14.0, 6.0, -13.0, 8.0, 13.0, 2.0, -13.0, 13.0, 10.0, 14.0, 11.0, -20.0, 13.0, 13.0, 2.0, -13.0, 4.0, -3.0, 13.0, 1.0, 8.0, 2.0, 11.0, -6.0, 7.0, 13.0, -15.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2212767187189495, "mean_inference_ms": 1.1778310041730582, "mean_action_processing_ms": 0.07202873340718642, "mean_env_wait_ms": 0.17983137190228438, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 934200, "agent_timesteps_total": 934119, "timers": {"sample_time_ms": 358.22, "sample_throughput": 15074.545, "learn_time_ms": 6436.797, "learn_throughput": 838.927, "update_time_ms": 10.858}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 613.5375366210938, "policy_loss": -0.020923521369695663, "vf_loss": 613.5551147460938, "vf_explained_var": 0.13652659952640533, "kl": 0.005785452201962471, "entropy": 0.4466594457626343, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 934200, "num_agent_steps_sampled": 934119, "num_steps_trained": 934200, "num_agent_steps_trained": 934119}, "done": false, "episodes_total": 18306, "training_iteration": 173, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-23", "timestamp": 1626861743, "time_this_iter_s": 7.209479808807373, "time_total_s": 1242.3049342632294, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70228730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1242.3049342632294, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 21.359999999999996, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 6.0, 10.0, -6.0, -2.0, -6.0, 12.0, 11.0, 5.0, 11.0, 2.0, -3.0, 0.0, -2.0, 12.0, 5.0, 4.0, 8.0, 5.0, -2.0, 13.0, -10.0, 0.0, 12.0, 5.0, 12.0, 7.0, -9.0, -6.0, -2.0, 10.0, 13.0, 4.0, 8.0, 7.0, -4.0, 13.0, 9.0, -20.0, 13.0, 8.0, 11.0, -11.0, 7.0, -11.0, 12.0, 1.0, 13.0, 6.0, 6.0, 5.0, -2.0, 12.0, -8.0, 1.0, 10.0, 13.0, -1.0, 4.0, -1.0, -2.0, -3.0, 12.0, 8.0, -7.0, 4.0, 11.0, 7.0, 13.0, -6.0, -3.0, 11.0, 10.0, 13.0, 6.0, -14.0, 5.0, -5.0, 13.0, 2.0, 10.0, 7.0, -6.0, 4.0, -1.0, -4.0, 11.0, 9.0, 4.0, 4.0, 11.0, -4.0, -12.0, 13.0, 2.0, 12.0, -9.0, 2.0, 11.0, 11.0, 13.0, 4.0, -8.0, 6.0, 13.0, 6.0, 11.0, -15.0, 3.0, -4.0, 13.0, 3.0, -8.0, 1.0, 13.0, 9.0, 9.0, -7.0, 5.0, 8.0, 11.0, -2.0, 2.0, 4.0, 9.0, -8.0, 3.0, 11.0, 9.0, 7.0, -2.0, 1.0, 13.0, -10.0, 7.0, 5.0, 11.0, -2.0, 11.0, -5.0, -11.0, 13.0, 12.0, 1.0, 8.0, 4.0, 6.0, -3.0, 13.0, -5.0, -2.0, 9.0, 7.0, 13.0, 5.0, -10.0, -6.0, 11.0, 13.0, -3.0, 11.0, 6.0, 3.0, -5.0, 13.0, -9.0, 9.0, 2.0, 13.0, 13.0, -6.0, -5.0, 1.0, -3.0, 6.0, 11.0, 7.0, 3.0, -4.0, 9.0, -4.0, 10.0, -2.0, 11.0, -8.0, 13.0, 11.0, -1.0, -11.0, 12.0, 6.0, 8.0, 5.0, -6.0, 6.0, 10.0, 14.0, -9.0, 1.0, 9.0, 13.0, 0.0, 4.0, -2.0, -1.0, -1.0, 7.0, 10.0, 8.0, -12.0, 6.0, 13.0, 13.0, -9.0, 3.0, 8.0, 9.0, 13.0, 4.0, -11.0, -3.0, 12.0, -5.0, 11.0, 9.0, 3.0, 6.0, -3.0, 11.0, 6.0, -9.0, 7.0, 8.0, 14.0, 6.0, -13.0, 8.0, -1.0, 6.0, 2.0, 11.0, -1.0, 11.0, -6.0, 9.0, -6.0, 4.0, 8.0, 2.0, 10.0, -9.0, 12.0, -1.0, -5.0, 13.0, 8.0, -5.0, 3.0, 9.0, 8.0, -3.0, -5.0, 12.0, 11.0, 13.0, -8.0, 6.0, 4.0, 2.0, -1.0, 7.0, 7.0, -2.0, 2.0, 11.0, 4.0, 12.0, 6.0, 1.0, -4.0, 14.0, 13.0, -1.0, -11.0, 1.0, -3.0, 8.0, 9.0, 10.0, 8.0, 5.0, -8.0, 8.0, -11.0, 7.0, 11.0, 13.0, 13.0, -2.0, -9.0, -3.0, -2.0, 9.0, 11.0, 9.0, 2.0, -5.0, 9.0, 12.0, 4.0, -12.0, 11.0, 13.0, 3.0, 6.0, -7.0, 1.0, -3.0, 7.0, 10.0, -4.0, 5.0, 11.0, 3.0, 13.0, -4.0, 2.0, 4.0, 8.0, 14.0, 5.0, -12.0, -17.0, 11.0, 11.0, 10.0, 9.0, 9.0, 3.0, -6.0, 12.0, -6.0, 3.0, 6.0, 6.0, 1.0, 11.0, -3.0, -14.0, 11.0, 5.0, 13.0, -7.0, 1.0, 10.0, 11.0, 12.0, -10.0, 0.0, 13.0, 13.0, 12.0, 320.0, 10.0, -4.0, -4.0, 12.0, 11.0, 10.0, 8.0, -1.0, -2.0, 12.0, -11.0, 11.0, 3.0, 14.0, 8.0, 3.0, -10.0, 1.0, -2.0, 10.0, 6.0, -6.0, 1.0, 8.0, 12.0, 9.0, 7.0, -10.0, 9.0, 13.0, -3.0, 11.0, -6.0, 3.0, -6.0, 13.0, 5.0, -13.0, 7.0, 13.0, 8.0, 9.0, -11.0, 7.0, 10.0, 14.0, 13.0, -15.0, 3.0, 6.0, -2.0, -1.0, 12.0, 2.0, 4.0, -2.0, 11.0, -1.0, -7.0, 11.0, 12.0, 9.0, -2.0, 6.0, 2.0, -11.0, 13.0, 12.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2213064433373523, "mean_inference_ms": 1.1779375358561657, "mean_action_processing_ms": 0.07203123977896747, "mean_env_wait_ms": 0.1798440483245447, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 939600, "agent_timesteps_total": 939519, "timers": {"sample_time_ms": 357.719, "sample_throughput": 15095.63, "learn_time_ms": 6444.932, "learn_throughput": 837.868, "update_time_ms": 10.957}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 222.7522430419922, "policy_loss": -0.026877369731664658, "vf_loss": 222.77386474609375, "vf_explained_var": 0.2635990381240845, "kl": 0.009221138432621956, "entropy": 0.4263856112957001, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 939600, "num_agent_steps_sampled": 939519, "num_steps_trained": 939600, "num_agent_steps_trained": 939519}, "done": false, "episodes_total": 18414, "training_iteration": 174, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-31", "timestamp": 1626861751, "time_this_iter_s": 7.111158847808838, "time_total_s": 1249.4160931110382, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70228620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1249.4160931110382, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 21.619999999999997, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 2.0, -3.0, 8.0, 12.0, 8.0, -13.0, 8.0, 8.0, 14.0, -11.0, 4.0, 10.0, -3.0, 2.0, 6.0, 13.0, -7.0, -4.0, 13.0, 4.0, 6.0, 7.0, -2.0, 0.0, 11.0, -2.0, 6.0, 5.0, 13.0, -11.0, 8.0, 9.0, 1.0, -7.0, 12.0, 12.0, 9.0, -14.0, 8.0, 5.0, 13.0, 8.0, -11.0, 13.0, -1.0, 2.0, 1.0, 10.0, -2.0, 12.0, -5.0, 12.0, 6.0, 3.0, -6.0, -5.0, 9.0, 11.0, 0.0, -15.0, 14.0, 9.0, 7.0, 2.0, 8.0, -6.0, 11.0, 6.0, 10.0, -3.0, 2.0, 12.0, 8.0, -12.0, 7.0, 4.0, 14.0, -10.0, 7.0, 9.0, -1.0, 12.0, -5.0, -3.0, 8.0, 12.0, -2.0, 3.0, 14.0, 0.0, -2.0, 12.0, 12.0, 2.0, -11.0, 8.0, 5.0, -7.0, 9.0, 11.0, 6.0, 2.0, -4.0, -1.0, 9.0, 11.0, -4.0, 1.0, -1.0, 9.0, 6.0, 6.0, 0.0, -3.0, 12.0, 6.0, 7.0, -4.0, 6.0, 11.0, 14.0, -17.0, 7.0, -2.0, 7.0, 6.0, 4.0, 12.0, -3.0, -4.0, 10.0, 8.0, 7.0, -11.0, 11.0, -6.0, 14.0, 0.0, 7.0, -13.0, 14.0, 8.0, 6.0, 14.0, -4.0, 12.0, -7.0, -1.0, -3.0, 13.0, 6.0, -3.0, 4.0, 8.0, 6.0, -3.0, 8.0, 5.0, 5.0, 4.0, 7.0, -6.0, 10.0, 13.0, 5.0, -12.0, 9.0, -2.0, 14.0, -3.0, 6.0, -6.0, 12.0, 2.0, 7.0, 3.0, 5.0, 12.0, -5.0, 0.0, 10.0, 7.0, -2.0, 0.0, 2.0, 6.0, 7.0, 6.0, 12.0, 4.0, -7.0, 8.0, 0.0, -4.0, 11.0, 1.0, 12.0, -6.0, 8.0, -1.0, 14.0, -5.0, 7.0, 11.0, -14.0, 10.0, 8.0, 8.0, 1.0, -4.0, 10.0, -1.0, 6.0, 0.0, 10.0, -1.0, 2.0, 6.0, 8.0, -5.0, 11.0, 7.0, 2.0, 8.0, 7.0, -13.0, 13.0, 8.0, 2.0, 9.0, -4.0, 9.0, 11.0, -4.0, -1.0, -7.0, 12.0, 2.0, 8.0, 5.0, 4.0, -6.0, 12.0, 8.0, 9.0, 3.0, -5.0, 12.0, 14.0, -18.0, 7.0, -14.0, 14.0, 5.0, 10.0, 12.0, -3.0, -5.0, 11.0, 13.0, 11.0, -14.0, 5.0, 13.0, 14.0, -19.0, 7.0, -9.0, 12.0, 8.0, 4.0, 14.0, -1.0, 11.0, -9.0, 7.0, 13.0, -2.0, -3.0, -3.0, 12.0, 5.0, 1.0, 0.0, 13.0, -6.0, 8.0, 4.0, 7.0, -7.0, 11.0, 4.0, 9.0, -5.0, 7.0, 11.0, 1.0, -8.0, 11.0, 11.0, -4.0, 5.0, 3.0, -1.0, 11.0, -5.0, 10.0, -6.0, 10.0, 10.0, 1.0, -3.0, 10.0, 6.0, 2.0, -12.0, 9.0, 6.0, 12.0, 9.0, 4.0, 8.0, -6.0, 7.0, 5.0, 7.0, -4.0, -5.0, 14.0, -5.0, 11.0, 1.0, 6.0, -4.0, 12.0, 7.0, 5.0, -7.0, 10.0, 7.0, 11.0, -8.0, 5.0, 12.0, -2.0, 11.0, -6.0, -8.0, 10.0, 8.0, 5.0, 5.0, 9.0, -4.0, 5.0, -7.0, 12.0, 13.0, -3.0, 11.0, 9.0, 10.0, -15.0, 5.0, -6.0, 10.0, 6.0, 9.0, 0.0, 10.0, -4.0, 12.0, 13.0, 0.0, -10.0, 11.0, 7.0, -13.0, 10.0, 5.0, 12.0, -13.0, 11.0, 12.0, -1.0, -8.0, 12.0, 12.0, 9.0, -14.0, 8.0, -3.0, 8.0, 4.0, 6.0, 5.0, 13.0, -10.0, 7.0, 8.0, 5.0, 12.0, -10.0, 7.0, 7.0, 5.0, -4.0, -2.0, 13.0, 1.0, 3.0, 11.0, 9.0, -13.0, 8.0, 3.0, 7.0, -4.0, 9.0, 13.0, 3.0, -10.0, 9.0, -2.0, 6.0, 4.0, 7.0, -8.0, 9.0, 9.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22131121179905544, "mean_inference_ms": 1.1779642940224901, "mean_action_processing_ms": 0.07203105133212519, "mean_env_wait_ms": 0.17984489543035911, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 945000, "agent_timesteps_total": 944919, "timers": {"sample_time_ms": 356.867, "sample_throughput": 15131.687, "learn_time_ms": 6461.614, "learn_throughput": 835.704, "update_time_ms": 11.083}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 21.322858810424805, "policy_loss": -0.07652465999126434, "vf_loss": 21.38926887512207, "vf_explained_var": 0.28549253940582275, "kl": 0.01776597648859024, "entropy": 0.4094613194465637, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 945000, "num_agent_steps_sampled": 944919, "num_steps_trained": 945000, "num_agent_steps_trained": 944919}, "done": false, "episodes_total": 18522, "training_iteration": 175, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-38", "timestamp": 1626861758, "time_this_iter_s": 7.017452716827393, "time_total_s": 1256.4335458278656, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1256.4335458278656, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 22.84545454545454, "ram_util_percent": 14.300000000000004}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 6.0, 9.0, -9.0, 14.0, 7.0, -1.0, -5.0, -1.0, 14.0, -8.0, 10.0, 13.0, 2.0, 9.0, -9.0, 7.0, 7.0, 4.0, -3.0, 13.0, 5.0, -6.0, 3.0, 12.0, 11.0, -18.0, 10.0, 8.0, 12.0, -2.0, -3.0, 9.0, 12.0, 10.0, -16.0, 14.0, 1.0, 5.0, -5.0, -10.0, 14.0, 11.0, 0.0, 11.0, 12.0, 6.0, -14.0, 2.0, 12.0, 6.0, -5.0, 2.0, 5.0, 12.0, -4.0, -4.0, 13.0, -3.0, 9.0, 9.0, 3.0, -8.0, 11.0, -10.0, 12.0, 11.0, 2.0, 13.0, -4.0, 8.0, -2.0, -7.0, 11.0, 0.0, 11.0, 10.0, 8.0, 10.0, -13.0, 12.0, 11.0, 9.0, -17.0, 14.0, 0.0, -2.0, 3.0, -8.0, 12.0, 1.0, 10.0, 13.0, 8.0, 1.0, -7.0, 8.0, 12.0, -12.0, 7.0, 12.0, 6.0, 5.0, -8.0, -17.0, 14.0, 11.0, 7.0, 11.0, 2.0, 12.0, -10.0, -1.0, 9.0, 2.0, 5.0, 4.0, 7.0, -8.0, 12.0, 7.0, 0.0, -3.0, 11.0, 10.0, 13.0, -8.0, 0.0, 13.0, -1.0, 10.0, -7.0, 13.0, 3.0, -6.0, 5.0, -12.0, 12.0, 6.0, 9.0, 11.0, 8.0, 8.0, -12.0, 3.0, 13.0, 1.0, -2.0, 8.0, 6.0, 12.0, -11.0, 13.0, 12.0, 0.0, -10.0, 12.0, 13.0, 7.0, -17.0, -7.0, 12.0, 7.0, 3.0, 13.0, 1.0, 10.0, -9.0, 6.0, 14.0, 5.0, -10.0, 7.0, 2.0, 9.0, -3.0, 13.0, 9.0, 5.0, -12.0, 13.0, 1.0, -11.0, 12.0, 5.0, 14.0, 2.0, -6.0, 12.0, 6.0, 9.0, -12.0, 3.0, 10.0, 9.0, -7.0, 9.0, 0.0, -5.0, 11.0, -4.0, 13.0, 4.0, 2.0, 8.0, 13.0, 8.0, -14.0, 4.0, -5.0, 12.0, 4.0, 14.0, 2.0, 6.0, -7.0, -7.0, 11.0, 0.0, 11.0, 11.0, 11.0, -9.0, 2.0, 8.0, 12.0, 2.0, -7.0, 14.0, -13.0, 6.0, 8.0, 0.0, 12.0, -8.0, 11.0, 8.0, 9.0, -7.0, 5.0, 8.0, -2.0, 2.0, 7.0, 12.0, 4.0, -7.0, 6.0, -13.0, 11.0, 6.0, 11.0, 10.0, 4.0, 9.0, -8.0, 5.0, 12.0, 7.0, -9.0, 13.0, 0.0, 7.0, -5.0, -11.0, 13.0, 5.0, 8.0, 6.0, 6.0, -4.0, 7.0, 4.0, 11.0, 6.0, -6.0, 8.0, 2.0, -6.0, 11.0, -7.0, 10.0, 0.0, 12.0, 11.0, 11.0, 11.0, -18.0, 8.0, -7.0, 8.0, 6.0, 14.0, 3.0, 6.0, -8.0, 9.0, 14.0, 2.0, -10.0, 11.0, 12.0, -9.0, 1.0, 8.0, 11.0, 6.0, -10.0, 8.0, 6.0, 12.0, -11.0, -9.0, 12.0, 3.0, 9.0, 11.0, 8.0, 5.0, -9.0, 2.0, 13.0, -9.0, 9.0, 10.0, 2.0, -6.0, 9.0, -12.0, 6.0, 10.0, 11.0, 12.0, 2.0, -10.0, 11.0, 8.0, 10.0, 7.0, -10.0, 10.0, 6.0, 4.0, -5.0, -11.0, 10.0, 4.0, 12.0, 9.0, 14.0, 7.0, -15.0, 13.0, 10.0, -10.0, 2.0, 13.0, -2.0, -9.0, 13.0, -7.0, 13.0, 4.0, 5.0, 11.0, 4.0, -4.0, 4.0, 2.0, -1.0, 2.0, 12.0, 10.0, 4.0, -7.0, 8.0, -12.0, 14.0, 5.0, 8.0, 13.0, -1.0, 8.0, -5.0, 8.0, -3.0, 0.0, 10.0, 13.0, 2.0, 8.0, -8.0, -3.0, 14.0, 2.0, 2.0, 6.0, 6.0, 5.0, -2.0, 4.0, 12.0, 7.0, -8.0, 14.0, 2.0, 11.0, -12.0, -5.0, 14.0, -2.0, 8.0, 9.0, 7.0, 7.0, -8.0, -5.0, 12.0, 12.0, -4.0, 12.0, 9.0, 5.0, -11.0, -14.0, 14.0, 6.0, 9.0, 8.0, 14.0, 7.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22130441412637897, "mean_inference_ms": 1.1779318889584942, "mean_action_processing_ms": 0.07202813949607359, "mean_env_wait_ms": 0.17985026509258845, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 950400, "agent_timesteps_total": 950319, "timers": {"sample_time_ms": 356.536, "sample_throughput": 15145.736, "learn_time_ms": 6500.924, "learn_throughput": 830.651, "update_time_ms": 11.052}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 18.0985107421875, "policy_loss": -0.07706166803836823, "vf_loss": 18.16602897644043, "vf_explained_var": 0.46715572476387024, "kl": 0.016756070777773857, "entropy": 0.4277181327342987, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 950400, "num_agent_steps_sampled": 950319, "num_steps_trained": 950400, "num_agent_steps_trained": 950319}, "done": false, "episodes_total": 18630, "training_iteration": 176, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-45", "timestamp": 1626861765, "time_this_iter_s": 7.113801717758179, "time_total_s": 1263.5473475456238, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1263.5473475456238, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 20.39, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.38888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 6.097222222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 6.0, 2.0, -4.0, 8.0, 13.0, 6.0, -12.0, -8.0, 3.0, 7.0, 13.0, 7.0, -13.0, 9.0, 12.0, 8.0, 3.0, -6.0, 10.0, 12.0, 2.0, 5.0, -4.0, -8.0, 0.0, 10.0, 13.0, 10.0, -18.0, 10.0, 13.0, 9.0, 10.0, -17.0, 13.0, 5.0, 13.0, 9.0, -12.0, 1.0, 11.0, 11.0, -8.0, 11.0, 6.0, 7.0, -9.0, 11.0, 6.0, 2.0, -4.0, 7.0, 11.0, -6.0, 3.0, 12.0, 5.0, 5.0, -7.0, 12.0, 6.0, 7.0, -10.0, 11.0, 13.0, 317.0, 13.0, -10.0, 14.0, 11.0, 0.0, 10.0, 1.0, 11.0, -7.0, 4.0, -13.0, 12.0, 12.0, 10.0, 8.0, -15.0, 12.0, 2.0, 11.0, 5.0, -3.0, -1.0, 4.0, 4.0, 8.0, 12.0, 4.0, 7.0, -8.0, 9.0, 11.0, -4.0, -1.0, 13.0, 5.0, -9.0, 6.0, 7.0, 8.0, 4.0, -4.0, 5.0, 5.0, -4.0, 9.0, 10.0, 6.0, -11.0, 10.0, 11.0, 11.0, -8.0, 1.0, 11.0, 6.0, 5.0, -7.0, -8.0, 3.0, 7.0, 13.0, 11.0, 13.0, 316.0, 13.0, 7.0, 12.0, 11.0, -15.0, 3.0, 3.0, 10.0, -1.0, -3.0, 4.0, 6.0, 8.0, 11.0, 6.0, -1.0, -1.0, 12.0, 12.0, -11.0, 2.0, 10.0, 4.0, 11.0, -10.0, 9.0, 6.0, 9.0, -9.0, 10.0, -1.0, -2.0, 8.0, 8.0, 13.0, -2.0, -4.0, -3.0, 0.0, 10.0, 8.0, 10.0, -10.0, 10.0, 5.0, 11.0, 12.0, -19.0, 11.0, 12.0, 5.0, -8.0, 6.0, -5.0, 1.0, 12.0, 7.0, 4.0, -12.0, 10.0, 13.0, 10.0, 9.0, -13.0, 9.0, -16.0, 8.0, 11.0, 12.0, 6.0, 2.0, 9.0, -2.0, 14.0, 5.0, 8.0, -12.0, 11.0, 10.0, -19.0, 13.0, 12.0, 3.0, -7.0, 7.0, 7.0, 6.0, 11.0, -9.0, 5.0, -13.0, 10.0, 13.0, 9.0, 6.0, -7.0, 7.0, 0.0, 10.0, -1.0, 6.0, -4.0, 1.0, 11.0, 7.0, 12.0, -8.0, 3.0, 8.0, 10.0, 13.0, -6.0, -2.0, 4.0, 6.0, -3.0, 8.0, 2.0, 8.0, 13.0, -8.0, 9.0, -9.0, 7.0, 8.0, 8.0, 12.0, -18.0, 13.0, 8.0, 13.0, 6.0, -12.0, 6.0, 2.0, 11.0, -4.0, 13.0, -11.0, 3.0, 10.0, 12.0, 10.0, -19.0, 12.0, 5.0, 12.0, 12.0, -14.0, -7.0, 0.0, 10.0, 12.0, -9.0, 5.0, 12.0, 7.0, 8.0, 12.0, -4.0, -1.0, 5.0, 10.0, 4.0, -4.0, 7.0, 12.0, 2.0, -6.0, 12.0, 6.0, 9.0, -12.0, 11.0, 12.0, -7.0, -1.0, 2.0, 13.0, -10.0, 10.0, 8.0, 5.0, 6.0, -4.0, 12.0, -18.0, 8.0, 13.0, 10.0, 13.0, -18.0, 10.0, -11.0, 4.0, 12.0, 10.0, -10.0, 0.0, 12.0, 13.0, -10.0, 10.0, 9.0, 6.0, 11.0, 12.0, -19.0, 11.0, -11.0, 7.0, 9.0, 10.0, 7.0, 6.0, -3.0, 5.0, 11.0, -11.0, 12.0, 3.0, 10.0, 13.0, -21.0, 13.0, -1.0, 8.0, 4.0, 4.0, 11.0, 4.0, 11.0, -11.0, -3.0, 0.0, 11.0, 7.0, 7.0, 8.0, 7.0, -7.0, 7.0, 13.0, -14.0, 9.0, -13.0, 6.0, 9.0, 13.0, -11.0, 3.0, 12.0, 11.0, 10.0, 12.0, -18.0, 11.0, 8.0, 1.0, -3.0, 9.0, 11.0, -1.0, 11.0, -6.0, 9.0, -16.0, 12.0, 10.0, 7.0, 9.0, -11.0, 10.0, 8.0, 5.0, 10.0, -8.0, 12.0, -4.0, 9.0, -2.0, 12.0, -14.0, 11.0, 6.0, 11.0, 12.0, 316.0, 13.0, -10.0, 9.0, 9.0, 7.0, 2.0, 6.0, 10.0, -3.0, -8.0, 6.0, 7.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22128378864761564, "mean_inference_ms": 1.1779072019479653, "mean_action_processing_ms": 0.0720287591639655, "mean_env_wait_ms": 0.17984910019557848, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 955800, "agent_timesteps_total": 955719, "timers": {"sample_time_ms": 356.086, "sample_throughput": 15164.86, "learn_time_ms": 6533.477, "learn_throughput": 826.512, "update_time_ms": 11.376}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 573.6671752929688, "policy_loss": -0.018602395430207253, "vf_loss": 573.682373046875, "vf_explained_var": 0.1863805651664734, "kl": 0.006086775567382574, "entropy": 0.4164575934410095, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 955800, "num_agent_steps_sampled": 955719, "num_steps_trained": 955800, "num_agent_steps_trained": 955719}, "done": false, "episodes_total": 18738, "training_iteration": 177, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-52", "timestamp": 1626861772, "time_this_iter_s": 7.219707727432251, "time_total_s": 1270.767055273056, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae679d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1270.767055273056, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 21.889999999999997, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 14.0, -15.0, 10.0, 5.0, -1.0, 9.0, 2.0, -1.0, 8.0, -5.0, 13.0, 11.0, -7.0, 2.0, 9.0, 8.0, -17.0, 13.0, 11.0, -1.0, 11.0, 3.0, 2.0, -10.0, 13.0, -1.0, 13.0, 6.0, -10.0, 8.0, 11.0, 11.0, -3.0, -2.0, 9.0, 14.0, -5.0, -6.0, 12.0, 13.0, 0.0, -11.0, 13.0, 6.0, 5.0, -9.0, 13.0, 5.0, 7.0, -5.0, 8.0, 12.0, -4.0, 11.0, -4.0, -14.0, 13.0, 3.0, 13.0, 12.0, -10.0, 3.0, 10.0, -2.0, 14.0, 6.0, -3.0, -9.0, 11.0, 6.0, 7.0, 13.0, -11.0, 8.0, 5.0, -3.0, 6.0, 8.0, 4.0, -2.0, 13.0, 8.0, -4.0, -1.0, 12.0, 10.0, -6.0, -2.0, 6.0, -1.0, 12.0, 7.0, -3.0, 4.0, 7.0, -8.0, 13.0, 4.0, 6.0, 7.0, 12.0, -14.0, 10.0, -9.0, 3.0, 13.0, 8.0, 10.0, 8.0, 3.0, -6.0, 5.0, 12.0, -10.0, 8.0, 10.0, 12.0, -4.0, -3.0, 12.0, 3.0, 11.0, -11.0, -5.0, 4.0, 6.0, 10.0, 12.0, -6.0, 12.0, -3.0, 13.0, 12.0, -9.0, -1.0, -7.0, 11.0, -2.0, 13.0, -4.0, 7.0, 1.0, 11.0, 10.0, 10.0, -10.0, 5.0, 9.0, 6.0, -12.0, 12.0, -3.0, 4.0, 5.0, 9.0, 7.0, -8.0, 5.0, 11.0, 5.0, 13.0, -11.0, 8.0, 13.0, -5.0, 1.0, 6.0, 12.0, -10.0, 13.0, 0.0, 10.0, 11.0, -19.0, 13.0, 1.0, 8.0, 11.0, -5.0, 4.0, -1.0, 4.0, 8.0, 8.0, 7.0, 11.0, -11.0, 11.0, 5.0, 1.0, -2.0, 7.0, -1.0, -4.0, 13.0, 13.0, -1.0, -5.0, 8.0, 10.0, -9.0, 11.0, 3.0, 11.0, -12.0, 3.0, 13.0, 5.0, 6.0, -3.0, 7.0, 8.0, -4.0, 2.0, 9.0, 14.0, 11.0, -1.0, -9.0, -4.0, 1.0, 6.0, 12.0, 6.0, -5.0, 7.0, 7.0, 0.0, -1.0, 6.0, 10.0, -4.0, 7.0, 9.0, 3.0, -3.0, 5.0, 8.0, 5.0, 9.0, 12.0, 4.0, -10.0, 14.0, 9.0, -11.0, 3.0, -4.0, 11.0, 9.0, -1.0, 12.0, 10.0, 1.0, -8.0, 3.0, 6.0, -5.0, 11.0, 7.0, -1.0, 2.0, 7.0, -3.0, 11.0, 1.0, 6.0, 5.0, -8.0, 6.0, 12.0, 8.0, 2.0, -2.0, 7.0, 9.0, 4.0, 6.0, -4.0, -6.0, 7.0, 5.0, 9.0, -12.0, 4.0, 13.0, 10.0, 7.0, 11.0, 8.0, -11.0, 11.0, -1.0, 5.0, 0.0, 8.0, -8.0, 2.0, 13.0, 11.0, -6.0, -2.0, 12.0, 6.0, 8.0, -5.0, 6.0, 9.0, -8.0, 1.0, 13.0, -2.0, 7.0, 9.0, 1.0, -6.0, 6.0, 3.0, 12.0, 1.0, 7.0, -6.0, 13.0, 10.0, 6.0, -9.0, 8.0, -15.0, 5.0, 13.0, 12.0, -11.0, 4.0, 11.0, 11.0, -13.0, 8.0, 7.0, 13.0, 10.0, 12.0, -6.0, -1.0, -3.0, 5.0, 1.0, 12.0, 11.0, -9.0, 2.0, 11.0, 10.0, -17.0, 11.0, 11.0, 9.0, 9.0, -10.0, 7.0, 5.0, 11.0, 13.0, -14.0, -6.0, 8.0, 1.0, 12.0, 6.0, 14.0, -4.0, -1.0, 0.0, -2.0, 7.0, 10.0, 10.0, 8.0, 12.0, -15.0, 4.0, -12.0, 11.0, 12.0, -3.0, 2.0, 9.0, 7.0, 2.0, 11.0, -4.0, 6.0, -15.0, 12.0, 6.0, 12.0, 6.0, -11.0, 9.0, 11.0, 2.0, 7.0, 10.0, -4.0, 14.0, 5.0, 11.0, -15.0, -2.0, 6.0, 6.0, 5.0, 6.0, -5.0, 7.0, 7.0, -7.0, 5.0, 9.0, 8.0, 6.0, -1.0, 3.0, 7.0, -18.0, 12.0, 13.0, 8.0, 5.0, -8.0, 7.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2212120768260757, "mean_inference_ms": 1.1779680662296426, "mean_action_processing_ms": 0.07203653340327622, "mean_env_wait_ms": 0.1798611213131157, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 961200, "agent_timesteps_total": 961146, "timers": {"sample_time_ms": 355.338, "sample_throughput": 15196.788, "learn_time_ms": 6560.943, "learn_throughput": 823.052, "update_time_ms": 11.515}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 24.68623924255371, "policy_loss": -0.08375643938779831, "vf_loss": 24.760156631469727, "vf_explained_var": 0.26576653122901917, "kl": 0.017276769503951073, "entropy": 0.44135981798171997, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 961200, "num_agent_steps_sampled": 961146, "num_steps_trained": 961200, "num_agent_steps_trained": 961146}, "done": false, "episodes_total": 18846, "training_iteration": 178, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-02-59", "timestamp": 1626861779, "time_this_iter_s": 7.122432470321655, "time_total_s": 1277.8894877433777, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70216c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1277.8894877433777, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 21.51, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.52, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 330.0}, "policy_reward_mean": {"learned": 4.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 1.0, -9.0, 13.0, -12.0, 7.0, 11.0, 9.0, -3.0, 3.0, 12.0, 3.0, 1.0, 12.0, 5.0, -3.0, -12.0, 13.0, 10.0, 4.0, 11.0, -10.0, 12.0, 2.0, 5.0, 6.0, -9.0, 13.0, 4.0, 13.0, -9.0, 7.0, 6.0, -4.0, 7.0, 6.0, 1.0, 5.0, 11.0, -2.0, 0.0, 14.0, -9.0, 10.0, -3.0, 3.0, 8.0, 7.0, 0.0, 12.0, 5.0, -2.0, -19.0, 12.0, 10.0, 12.0, -7.0, 13.0, 12.0, -3.0, 1.0, 6.0, 10.0, -2.0, -12.0, 7.0, 10.0, 10.0, 11.0, -12.0, 8.0, 8.0, 6.0, 6.0, -4.0, 7.0, -15.0, 13.0, 6.0, 11.0, -6.0, 13.0, 3.0, 5.0, 13.0, 7.0, 1.0, -6.0, 0.0, 14.0, -9.0, 10.0, -4.0, -1.0, 8.0, 12.0, 4.0, 2.0, 11.0, -2.0, -7.0, 7.0, 5.0, 10.0, -9.0, 13.0, 7.0, 4.0, 14.0, 330.0, 10.0, 13.0, -15.0, 8.0, 12.0, 10.0, -5.0, 9.0, 4.0, 7.0, 14.0, 6.0, -10.0, 5.0, -10.0, 8.0, 6.0, 11.0, 7.0, -2.0, 12.0, -2.0, -8.0, 12.0, 5.0, 6.0, 0.0, 10.0, -7.0, 12.0, -5.0, 13.0, 12.0, -5.0, 9.0, 5.0, -8.0, 9.0, -1.0, -3.0, 11.0, 8.0, -11.0, 13.0, 3.0, 10.0, 1.0, 11.0, 10.0, -7.0, -12.0, 5.0, 10.0, 12.0, 9.0, 12.0, 12.0, -18.0, 6.0, 12.0, 3.0, -6.0, 3.0, 4.0, -2.0, 10.0, 10.0, -11.0, 8.0, 8.0, -2.0, 7.0, 11.0, -1.0, -8.0, 12.0, 1.0, 10.0, -11.0, 13.0, 12.0, 1.0, -1.0, 1.0, 6.0, 9.0, -13.0, 7.0, 10.0, 11.0, -7.0, 11.0, 7.0, 4.0, 7.0, 4.0, 11.0, -7.0, -6.0, 8.0, 5.0, 8.0, 13.0, -9.0, 4.0, 7.0, 12.0, 2.0, -6.0, 7.0, 2.0, 7.0, -6.0, 12.0, 11.0, -6.0, 4.0, 6.0, 5.0, 6.0, -5.0, 9.0, -8.0, 4.0, 8.0, 11.0, 10.0, 10.0, -11.0, 6.0, -11.0, 10.0, 10.0, 6.0, -7.0, 8.0, 9.0, 5.0, -8.0, 7.0, 12.0, 4.0, -7.0, 3.0, 7.0, 12.0, 7.0, 8.0, -11.0, 11.0, 11.0, -11.0, 8.0, 7.0, -1.0, 5.0, 5.0, 6.0, 0.0, 13.0, -9.0, 11.0, -7.0, 10.0, 9.0, 3.0, -9.0, 10.0, 3.0, 11.0, -7.0, 13.0, 6.0, 3.0, 11.0, 10.0, -11.0, 5.0, -7.0, 5.0, 7.0, 10.0, -11.0, 8.0, 10.0, 8.0, -7.0, 13.0, 12.0, -3.0, 6.0, -1.0, 11.0, -1.0, 8.0, 8.0, -10.0, 9.0, 11.0, -11.0, 12.0, 3.0, 6.0, 4.0, 9.0, -4.0, -9.0, 7.0, 12.0, 5.0, -9.0, 11.0, 12.0, 1.0, 9.0, 9.0, -10.0, 7.0, 5.0, 11.0, 13.0, -14.0, -6.0, 8.0, 1.0, 12.0, 6.0, 14.0, -4.0, -1.0, 0.0, -2.0, 7.0, 10.0, 10.0, 8.0, 12.0, -15.0, 4.0, -12.0, 11.0, 12.0, -3.0, 2.0, 9.0, 7.0, 2.0, 11.0, -4.0, 6.0, -15.0, 12.0, 6.0, 12.0, 6.0, -11.0, 9.0, 11.0, 2.0, 7.0, 10.0, -4.0, 14.0, 5.0, 11.0, -15.0, -2.0, 6.0, 6.0, 5.0, 6.0, -5.0, 7.0, 7.0, -7.0, 5.0, 9.0, 8.0, 6.0, -1.0, 3.0, 7.0, -18.0, 12.0, 13.0, 8.0, 5.0, -8.0, 7.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22105055561834597, "mean_inference_ms": 1.1770411347228682, "mean_action_processing_ms": 0.07205900150641939, "mean_env_wait_ms": 0.1797778224917741, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 966600, "agent_timesteps_total": 966519, "timers": {"sample_time_ms": 355.36, "sample_throughput": 15195.866, "learn_time_ms": 6581.773, "learn_throughput": 820.448, "update_time_ms": 11.365}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 246.88453674316406, "policy_loss": -0.027391698211431503, "vf_loss": 246.90774536132812, "vf_explained_var": 0.24374797940254211, "kl": 0.007304313592612743, "entropy": 0.44241273403167725, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 966600, "num_agent_steps_sampled": 966519, "num_steps_trained": 966600, "num_agent_steps_trained": 966519}, "done": false, "episodes_total": 18927, "training_iteration": 179, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-03-06", "timestamp": 1626861786, "time_this_iter_s": 7.076791763305664, "time_total_s": 1284.9662795066833, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e702166a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1284.9662795066833, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 21.9, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -17.0, 13.0, 8.0, -6.0, 13.0, 6.0, 2.0, 6.0, 9.0, 12.0, -12.0, 11.0, -17.0, 13.0, 8.0, 10.0, -15.0, 7.0, 13.0, 11.0, 13.0, 1.0, -10.0, 6.0, 8.0, 10.0, -9.0, -2.0, -1.0, 13.0, 5.0, 9.0, -12.0, 8.0, 10.0, 2.0, 13.0, 6.0, -6.0, 6.0, 13.0, 9.0, -13.0, 0.0, -2.0, 8.0, 9.0, -10.0, 6.0, 13.0, 6.0, 4.0, 12.0, 6.0, -7.0, 1.0, 5.0, 12.0, -3.0, -2.0, -4.0, 10.0, 11.0, 10.0, 7.0, 12.0, -14.0, 9.0, -9.0, 5.0, 10.0, -2.0, 9.0, 11.0, -3.0, 11.0, 2.0, -7.0, 9.0, 5.0, -12.0, 13.0, 9.0, 11.0, -4.0, 4.0, 4.0, 2.0, 13.0, -2.0, 2.0, 14.0, 6.0, -14.0, 9.0, 8.0, -7.0, 1.0, 13.0, -10.0, 13.0, 5.0, 7.0, 4.0, 4.0, 13.0, -6.0, -1.0, -10.0, 13.0, 13.0, -14.0, 8.0, 13.0, 8.0, 0.0, -4.0, 12.0, 7.0, 6.0, 8.0, 12.0, -11.0, 0.0, 6.0, -3.0, 12.0, 9.0, -4.0, 13.0, -3.0, 11.0, 4.0, -5.0, 5.0, 6.0, 14.0, 13.0, -18.0, 12.0, -3.0, -3.0, 9.0, 2.0, -3.0, 11.0, 5.0, -11.0, 11.0, 4.0, 11.0, 7.0, 8.0, 7.0, -7.0, 13.0, -2.0, -9.0, 13.0, 7.0, -8.0, 13.0, 3.0, 10.0, 14.0, 0.0, -9.0, -9.0, 14.0, 13.0, -3.0, -1.0, -6.0, 13.0, 9.0, 4.0, -4.0, 13.0, 2.0, 6.0, -8.0, 7.0, 10.0, 7.0, 9.0, 10.0, -11.0, -3.0, -2.0, 12.0, 8.0, 13.0, 11.0, 13.0, 319.0, 11.0, -10.0, 11.0, 3.0, 1.0, 14.0, 11.0, -11.0, -2.0, -5.0, 13.0, 9.0, 10.0, -10.0, 12.0, 3.0, 6.0, 10.0, -3.0, 2.0, 2.0, 14.0, 11.0, -12.0, 14.0, -2.0, -10.0, 13.0, 7.0, -12.0, 13.0, 7.0, 12.0, -8.0, 12.0, -1.0, 3.0, 14.0, 7.0, -9.0, -2.0, 2.0, 6.0, 9.0, 14.0, -16.0, 7.0, 10.0, 5.0, -7.0, 9.0, 8.0, 2.0, 9.0, 12.0, -8.0, -2.0, 1.0, 3.0, 13.0, 3.0, -4.0, 3.0, 13.0, 8.0, -1.0, 4.0, 4.0, 7.0, 8.0, 10.0, -10.0, -2.0, -7.0, 11.0, 13.0, 12.0, -2.0, -8.0, 13.0, 7.0, 14.0, -13.0, 7.0, 1.0, 8.0, 13.0, -7.0, 0.0, 7.0, -5.0, 13.0, 9.0, -4.0, 13.0, -3.0, 9.0, 12.0, 5.0, -11.0, 5.0, 8.0, 13.0, -11.0, -2.0, 4.0, 4.0, 9.0, 12.0, -7.0, 6.0, 4.0, 3.0, 0.0, 4.0, 8.0, -6.0, 9.0, 12.0, 0.0, 13.0, 6.0, -17.0, 13.0, -3.0, -7.0, 13.0, 12.0, 4.0, -11.0, 11.0, 11.0, 2.0, 14.0, -3.0, 2.0, -2.0, 6.0, -2.0, 13.0, 5.0, 11.0, 13.0, -14.0, 5.0, -9.0, 8.0, 11.0, 6.0, 8.0, -2.0, 3.0, -2.0, -3.0, 13.0, 7.0, 12.0, -5.0, 11.0, -3.0, -4.0, 10.0, 5.0, 4.0, 5.0, 8.0, 12.0, -10.0, -2.0, 5.0, 3.0, 9.0, 14.0, -8.0, 12.0, -3.0, 4.0, -7.0, 11.0, 7.0, -1.0, 13.0, 12.0, -9.0, 12.0, -1.0, -4.0, 8.0, -1.0, -2.0, 12.0, 6.0, 11.0, -9.0, 2.0, 11.0, 1.0, 13.0, -3.0, 4.0, -3.0, 3.0, 5.0, 10.0, -3.0, 3.0, 8.0, 7.0, -16.0, 13.0, 11.0, 7.0, 7.0, 8.0, -3.0, 3.0, -1.0, 4.0, 3.0, 9.0, 11.0, 5.0, -5.0, 4.0, 6.0, -13.0, 10.0, 12.0, -1.0, 13.0, 12.0, -9.0, -1.0, -1.0, 4.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22125824374497846, "mean_inference_ms": 1.1777827934877347, "mean_action_processing_ms": 0.07203394479440191, "mean_env_wait_ms": 0.17987490432477557, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 972000, "agent_timesteps_total": 971919, "timers": {"sample_time_ms": 352.896, "sample_throughput": 15301.953, "learn_time_ms": 6609.782, "learn_throughput": 816.971, "update_time_ms": 11.734}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 42.130584716796875, "policy_loss": -0.06673155725002289, "vf_loss": 42.18846130371094, "vf_explained_var": 0.3468727469444275, "kl": 0.015541473403573036, "entropy": 0.4521491527557373, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 972000, "num_agent_steps_sampled": 971919, "num_steps_trained": 972000, "num_agent_steps_trained": 971919}, "done": false, "episodes_total": 19035, "training_iteration": 180, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-03-13", "timestamp": 1626861793, "time_this_iter_s": 7.119963645935059, "time_total_s": 1292.0862431526184, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e70216840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1292.0862431526184, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 21.754545454545454, "ram_util_percent": 14.300000000000004}, "trial_id": "cf107_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.555555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 334.0}, "policy_reward_mean": {"learned": 6.138888888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 12.0, -11.0, 3.0, 6.0, 11.0, 10.0, -12.0, -1.0, 8.0, -2.0, 10.0, 12.0, 1.0, -9.0, 11.0, -8.0, 10.0, 7.0, 6.0, 10.0, -8.0, 12.0, 1.0, -1.0, 6.0, 4.0, 6.0, 12.0, -12.0, 9.0, 6.0, 8.0, 8.0, -11.0, 10.0, 9.0, 5.0, -8.0, 9.0, 13.0, 3.0, -11.0, 10.0, 7.0, -9.0, 8.0, 9.0, -11.0, 7.0, 7.0, 12.0, -5.0, 3.0, 4.0, 13.0, -9.0, 4.0, 9.0, 11.0, 6.0, -13.0, 11.0, 11.0, -7.0, 13.0, 0.0, 9.0, 12.0, 7.0, 10.0, -14.0, 12.0, 10.0, -12.0, 5.0, 9.0, -15.0, 10.0, 11.0, 12.0, 3.0, -7.0, 7.0, 4.0, 12.0, -7.0, 6.0, 12.0, 8.0, -7.0, 2.0, 12.0, -12.0, 8.0, 7.0, 13.0, 10.0, -7.0, -1.0, 5.0, 12.0, -9.0, 7.0, -4.0, 13.0, -4.0, 10.0, 13.0, -12.0, 8.0, 6.0, -6.0, 11.0, 0.0, 10.0, 13.0, 3.0, 5.0, -6.0, -4.0, 7.0, 1.0, 11.0, 8.0, -12.0, 11.0, 8.0, -8.0, 5.0, 6.0, 12.0, 9.0, 13.0, 7.0, -14.0, 12.0, 4.0, -10.0, 9.0, 4.0, -11.0, 10.0, 12.0, 11.0, 12.0, -6.0, -2.0, 5.0, 8.0, 3.0, -1.0, -12.0, 9.0, 6.0, 12.0, 9.0, -16.0, 11.0, 11.0, -11.0, 8.0, 7.0, 11.0, 8.0, -8.0, 2.0, 13.0, 6.0, 6.0, -8.0, 11.0, 11.0, -6.0, 12.0, -2.0, -5.0, 11.0, -3.0, 12.0, 4.0, 10.0, 9.0, -8.0, 11.0, 8.0, -13.0, 9.0, 13.0, -12.0, 9.0, 5.0, -10.0, 8.0, 6.0, 11.0, 6.0, 5.0, 10.0, -6.0, -3.0, 11.0, -4.0, 11.0, -13.0, 5.0, 12.0, 11.0, 7.0, 8.0, -12.0, 12.0, 4.0, 11.0, 7.0, -7.0, 10.0, 7.0, -4.0, 2.0, 11.0, -17.0, 11.0, 10.0, -6.0, 10.0, -1.0, 12.0, 13.0, 5.0, 4.0, -7.0, -7.0, 7.0, 4.0, 11.0, 12.0, -16.0, 10.0, 9.0, 9.0, 5.0, -11.0, 12.0, 8.0, 6.0, 11.0, -10.0, 13.0, 8.0, -7.0, 1.0, 9.0, -2.0, -3.0, 11.0, 10.0, 10.0, -17.0, 12.0, 14.0, -2.0, 12.0, -9.0, -20.0, 13.0, 12.0, 10.0, 11.0, 320.0, 13.0, 11.0, -8.0, 13.0, 3.0, 7.0, 1.0, 5.0, 11.0, -2.0, -2.0, 12.0, -5.0, 10.0, 5.0, 4.0, 11.0, -5.0, -2.0, 12.0, -7.0, 12.0, 14.0, 1.0, -7.0, 7.0, 4.0, 5.0, -2.0, 8.0, 12.0, -17.0, 10.0, 10.0, 9.0, 13.0, -19.0, 12.0, 7.0, 2.0, -6.0, 12.0, 13.0, 3.0, -12.0, 11.0, 12.0, 320.0, 12.0, 11.0, 7.0, 7.0, -11.0, 12.0, 8.0, -7.0, 9.0, 5.0, 12.0, 3.0, -9.0, 9.0, 8.0, -14.0, 9.0, 12.0, -10.0, 6.0, 7.0, 12.0, 6.0, -9.0, 5.0, 13.0, 13.0, 2.0, -10.0, 10.0, 11.0, -17.0, 11.0, 10.0, 10.0, 7.0, -12.0, 10.0, 6.0, -10.0, 11.0, 8.0, -16.0, 12.0, 7.0, 12.0, 10.0, -13.0, 8.0, 10.0, 8.0, -6.0, 2.0, 11.0, 6.0, 7.0, -3.0, 5.0, -7.0, 11.0, 2.0, 9.0, 6.0, -13.0, 10.0, 12.0, 7.0, 9.0, -13.0, 12.0, 5.0, -8.0, 11.0, 7.0, 9.0, 7.0, -10.0, 9.0, 6.0, -13.0, 11.0, 11.0, 8.0, 11.0, -13.0, 9.0, 6.0, -6.0, 6.0, 9.0, -7.0, 4.0, 7.0, 11.0, 11.0, 334.0, 11.0, 11.0, 5.0, 13.0, -14.0, 11.0, 12.0, 9.0, 4.0, -10.0, 12.0, 8.0, -14.0, 9.0, 13.0, 0.0, 8.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22130005574988817, "mean_inference_ms": 1.1778383704987394, "mean_action_processing_ms": 0.07203671377406431, "mean_env_wait_ms": 0.17988988150428753, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 977400, "agent_timesteps_total": 977319, "timers": {"sample_time_ms": 353.369, "sample_throughput": 15281.468, "learn_time_ms": 6650.003, "learn_throughput": 812.03, "update_time_ms": 11.701}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 721.2640991210938, "policy_loss": -0.026359474286437035, "vf_loss": 721.2869873046875, "vf_explained_var": 0.11331827938556671, "kl": 0.006016897037625313, "entropy": 0.42386916279792786, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 977400, "num_agent_steps_sampled": 977319, "num_steps_trained": 977400, "num_agent_steps_trained": 977319}, "done": false, "episodes_total": 19143, "training_iteration": 181, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-03-21", "timestamp": 1626861801, "time_this_iter_s": 7.223327875137329, "time_total_s": 1299.3095710277557, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1299.3095710277557, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 20.949999999999996, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.27777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.319444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 5.0, 10.0, -6.0, -8.0, 11.0, 1.0, 11.0, 5.0, 5.0, 13.0, -8.0, 13.0, 3.0, -13.0, 12.0, 8.0, 8.0, -11.0, 10.0, 12.0, 11.0, -20.0, 12.0, 6.0, 12.0, 2.0, -5.0, -6.0, 14.0, -5.0, 12.0, 12.0, 3.0, 5.0, -5.0, 13.0, 11.0, -19.0, 10.0, 11.0, 12.0, -17.0, 9.0, 11.0, 14.0, -22.0, 12.0, 9.0, 9.0, 2.0, -5.0, 13.0, 12.0, -19.0, 9.0, 8.0, 12.0, 4.0, -9.0, -2.0, 14.0, 0.0, 3.0, 1.0, 7.0, 11.0, -4.0, 13.0, 11.0, -7.0, -2.0, 0.0, 11.0, 8.0, -4.0, -3.0, 14.0, -9.0, 13.0, 7.0, 7.0, 8.0, -7.0, 5.0, -2.0, 3.0, 9.0, 4.0, 13.0, 4.0, -6.0, -7.0, 14.0, -4.0, 12.0, 4.0, 10.0, 5.0, -4.0, 12.0, 12.0, -17.0, 8.0, 9.0, -3.0, 0.0, 9.0, -2.0, 14.0, -10.0, 13.0, 2.0, 9.0, 10.0, -6.0, 14.0, 13.0, -15.0, 3.0, 12.0, 12.0, -1.0, -8.0, -2.0, 14.0, -9.0, 12.0, 9.0, 6.0, 12.0, -12.0, 3.0, 12.0, -8.0, 8.0, 8.0, 13.0, -1.0, -5.0, 0.0, 6.0, -2.0, 11.0, 13.0, 2.0, 12.0, -12.0, 12.0, 10.0, -10.0, 3.0, 6.0, 12.0, 5.0, -8.0, 5.0, 14.0, -17.0, 13.0, 2.0, 8.0, -4.0, 9.0, -11.0, 11.0, 2.0, 13.0, 7.0, 12.0, 1.0, -5.0, 11.0, 14.0, -20.0, 10.0, 13.0, 5.0, 5.0, -8.0, 14.0, 13.0, -16.0, 4.0, 7.0, 11.0, 2.0, -5.0, -6.0, 14.0, -6.0, 13.0, 6.0, 8.0, 6.0, -5.0, 14.0, 12.0, -20.0, 9.0, 12.0, -7.0, 8.0, 2.0, -5.0, 13.0, -6.0, 13.0, 13.0, 3.0, 6.0, -7.0, 13.0, -2.0, -1.0, 5.0, 6.0, -5.0, 4.0, 10.0, 12.0, 14.0, -23.0, 12.0, 12.0, 1.0, 10.0, -8.0, 6.0, 11.0, -12.0, 10.0, 9.0, 13.0, -2.0, -5.0, -8.0, 9.0, 1.0, 13.0, 12.0, 6.0, 2.0, -5.0, 13.0, 12.0, -19.0, 9.0, 10.0, 12.0, 4.0, -11.0, 13.0, 14.0, 315.0, 12.0, 8.0, 2.0, -3.0, 8.0, 14.0, 12.0, -17.0, 6.0, 11.0, 11.0, -1.0, -6.0, -5.0, 6.0, 3.0, 11.0, 8.0, 14.0, 8.0, -15.0, 11.0, 11.0, 12.0, -19.0, 12.0, 7.0, 8.0, -12.0, -3.0, 14.0, -9.0, 13.0, 5.0, 14.0, 11.0, -15.0, 14.0, 12.0, -16.0, 5.0, 0.0, 13.0, 13.0, -11.0, -2.0, 14.0, -6.0, 9.0, 6.0, 5.0, 9.0, -5.0, 6.0, 13.0, -1.0, -3.0, 6.0, 8.0, 6.0, -5.0, 12.0, 14.0, -22.0, 11.0, 1.0, 12.0, 12.0, -10.0, 14.0, 13.0, 318.0, 9.0, 12.0, 10.0, 7.0, -14.0, -4.0, 12.0, 0.0, 7.0, 12.0, 4.0, 9.0, -10.0, 6.0, 13.0, -15.0, 11.0, 11.0, 13.0, -3.0, -6.0, -3.0, 12.0, -3.0, 9.0, 5.0, 9.0, -7.0, 8.0, 11.0, 13.0, -19.0, 10.0, 6.0, 11.0, 3.0, -5.0, -3.0, 14.0, -9.0, 13.0, 11.0, 6.0, 6.0, -8.0, -8.0, 12.0, -1.0, 12.0, 3.0, 10.0, 5.0, -3.0, 11.0, 9.0, -18.0, 13.0, 6.0, 14.0, 3.0, -8.0, -2.0, 13.0, -6.0, 10.0, 6.0, 8.0, 6.0, -5.0, 0.0, 9.0, -7.0, 13.0, 8.0, 7.0, 6.0, -6.0, 12.0, 12.0, 0.0, -9.0, 9.0, 13.0, 7.0, -14.0, 0.0, 5.0, -2.0, 12.0, 7.0, 12.0, 3.0, -7.0, 8.0, 13.0, 2.0, -8.0, 12.0, 9.0, 1.0, -7.0, -3.0, 13.0, -8.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22132858843269657, "mean_inference_ms": 1.1779137141292453, "mean_action_processing_ms": 0.07204044546708574, "mean_env_wait_ms": 0.17990432949945342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 982800, "agent_timesteps_total": 982719, "timers": {"sample_time_ms": 353.354, "sample_throughput": 15282.146, "learn_time_ms": 6632.042, "learn_throughput": 814.229, "update_time_ms": 11.851}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 446.5235595703125, "policy_loss": -0.021051764488220215, "vf_loss": 446.5409851074219, "vf_explained_var": 0.20764464139938354, "kl": 0.006517252419143915, "entropy": 0.43634507060050964, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 982800, "num_agent_steps_sampled": 982719, "num_steps_trained": 982800, "num_agent_steps_trained": 982719}, "done": false, "episodes_total": 19251, "training_iteration": 182, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-03-28", "timestamp": 1626861808, "time_this_iter_s": 6.844403266906738, "time_total_s": 1306.1539742946625, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1306.1539742946625, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 21.860000000000003, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 6.0, -8.0, 5.0, 7.0, 13.0, -10.0, 5.0, 14.0, 12.0, -15.0, 4.0, -14.0, 10.0, 7.0, 12.0, 13.0, -11.0, 13.0, 0.0, 3.0, 12.0, -9.0, 9.0, 14.0, 5.0, 12.0, -16.0, -10.0, 9.0, 4.0, 12.0, 12.0, -12.0, 5.0, 10.0, 9.0, 7.0, 12.0, -13.0, 9.0, 10.0, -14.0, 10.0, -9.0, 11.0, 2.0, 11.0, 10.0, 5.0, -5.0, 5.0, -15.0, 11.0, 7.0, 12.0, 10.0, 3.0, -8.0, 10.0, -7.0, 10.0, 5.0, 7.0, 9.0, 5.0, 10.0, -9.0, 13.0, 2.0, 5.0, -5.0, 10.0, 0.0, -6.0, 11.0, -9.0, 10.0, 9.0, 5.0, 13.0, 9.0, 12.0, -19.0, 6.0, -6.0, 4.0, 11.0, 12.0, 0.0, 12.0, -9.0, -9.0, 13.0, 9.0, 2.0, 8.0, 4.0, 8.0, -5.0, 8.0, 5.0, 7.0, -5.0, 11.0, 11.0, -17.0, 10.0, 8.0, 11.0, 4.0, -8.0, 13.0, -4.0, 11.0, -5.0, 12.0, -6.0, 3.0, 6.0, 9.0, -2.0, -5.0, 13.0, 12.0, -4.0, 12.0, -5.0, 7.0, 13.0, 10.0, -15.0, 1.0, 10.0, -8.0, 12.0, 8.0, -10.0, 6.0, 11.0, 13.0, 7.0, 7.0, -12.0, 5.0, -5.0, 10.0, 5.0, -15.0, 12.0, 11.0, 7.0, 4.0, 12.0, 12.0, -13.0, 12.0, 9.0, 2.0, -8.0, 12.0, 2.0, 11.0, -10.0, 11.0, 1.0, -9.0, 12.0, 13.0, 5.0, -2.0, -1.0, -5.0, 9.0, 9.0, 2.0, 11.0, 1.0, 11.0, -8.0, 7.0, 3.0, 12.0, -7.0, 9.0, -14.0, 10.0, 10.0, -10.0, 10.0, 12.0, 3.0, 13.0, -10.0, 9.0, 3.0, 13.0, 5.0, -10.0, 7.0, 6.0, 11.0, 7.0, -9.0, -2.0, 6.0, 8.0, 3.0, 12.0, 6.0, 8.0, -11.0, 8.0, 13.0, -10.0, 4.0, 13.0, 11.0, 318.0, 13.0, 10.0, 10.0, 8.0, -13.0, 8.0, 10.0, 11.0, -14.0, -8.0, 2.0, 11.0, 10.0, 13.0, 9.0, 6.0, -13.0, -8.0, 11.0, 6.0, 6.0, 7.0, 12.0, 6.0, -10.0, 7.0, 5.0, -7.0, 10.0, 9.0, 11.0, -13.0, 8.0, 6.0, 9.0, -12.0, 12.0, 11.0, 12.0, 5.0, -13.0, 13.0, 6.0, 9.0, -13.0, 8.0, 5.0, 11.0, -9.0, -5.0, 11.0, -1.0, 10.0, 12.0, 6.0, 10.0, -13.0, -1.0, 12.0, 0.0, 4.0, 10.0, 0.0, 11.0, -6.0, -9.0, 7.0, 9.0, 8.0, 12.0, 10.0, 5.0, -12.0, 12.0, 5.0, -14.0, 12.0, 13.0, 10.0, -14.0, 6.0, -6.0, 12.0, -2.0, 11.0, 4.0, 12.0, -12.0, 11.0, -12.0, 8.0, 11.0, 8.0, 0.0, 11.0, 4.0, 0.0, 7.0, -2.0, -2.0, 12.0, 12.0, -4.0, 10.0, -3.0, 13.0, 5.0, 9.0, -12.0, -5.0, 1.0, 12.0, 7.0, -9.0, 10.0, 2.0, 12.0, 12.0, 12.0, 10.0, -19.0, 8.0, 7.0, -9.0, 9.0, -6.0, 11.0, 5.0, 5.0, -10.0, 10.0, 8.0, 7.0, 13.0, 5.0, -13.0, 10.0, 6.0, 11.0, -14.0, 12.0, 6.0, -7.0, 11.0, 5.0, -4.0, 9.0, 3.0, 7.0, 9.0, 12.0, -14.0, 8.0, 12.0, 12.0, -15.0, 6.0, 7.0, 11.0, 12.0, -15.0, -9.0, 12.0, 1.0, 11.0, 11.0, -4.0, 10.0, -2.0, -4.0, 13.0, -4.0, 10.0, -9.0, 12.0, 5.0, 7.0, 5.0, 10.0, 8.0, -8.0, 10.0, -9.0, 8.0, 6.0, -13.0, 12.0, 5.0, 11.0, 14.0, -10.0, -1.0, 12.0, 11.0, 5.0, 13.0, -14.0, 3.0, -1.0, 12.0, 1.0, 13.0, 5.0, 11.0, -14.0, 5.0, 8.0, -11.0, 13.0, -5.0, 10.0, -2.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22132898152251457, "mean_inference_ms": 1.1777963435233205, "mean_action_processing_ms": 0.07203470508397598, "mean_env_wait_ms": 0.17988407976401216, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 988200, "agent_timesteps_total": 988119, "timers": {"sample_time_ms": 352.784, "sample_throughput": 15306.831, "learn_time_ms": 6594.686, "learn_throughput": 818.841, "update_time_ms": 11.899}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 305.3607482910156, "policy_loss": -0.0473092645406723, "vf_loss": 305.4026184082031, "vf_explained_var": 0.2389150708913803, "kl": 0.009525502100586891, "entropy": 0.4211511015892029, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 988200, "num_agent_steps_sampled": 988119, "num_steps_trained": 988200, "num_agent_steps_trained": 988119}, "done": false, "episodes_total": 19359, "training_iteration": 183, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-03-34", "timestamp": 1626861814, "time_this_iter_s": 6.845578193664551, "time_total_s": 1312.999552488327, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e9ae67d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1312.999552488327, "timesteps_since_restore": 0, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 23.84, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 368.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.962962962962962, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 7.7407407407407405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 368.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 9.0, -11.0, 13.0, 9.0, -10.0, 5.0, 11.0, 14.0, 11.0, -11.0, 1.0, 8.0, -10.0, 7.0, 10.0, 11.0, -9.0, 9.0, 4.0, 13.0, 13.0, 12.0, 316.0, 14.0, 11.0, 8.0, -18.0, -17.0, 13.0, 10.0, 9.0, 7.0, -9.0, 4.0, 13.0, -5.0, -5.0, 12.0, 13.0, 14.0, -11.0, 7.0, 5.0, -1.0, -1.0, 10.0, 7.0, 7.0, -10.0, 5.0, 13.0, 12.0, -3.0, 11.0, -5.0, 8.0, -14.0, 10.0, 11.0, 322.0, 13.0, 11.0, 9.0, 8.0, -5.0, -1.0, 13.0, 13.0, 3.0, 1.0, -2.0, 14.0, 9.0, -14.0, 6.0, 12.0, -18.0, 11.0, 10.0, 12.0, -8.0, 3.0, 8.0, 7.0, -11.0, 8.0, 11.0, 14.0, 11.0, -9.0, -1.0, -7.0, 8.0, 4.0, 10.0, -7.0, 9.0, 5.0, 8.0, 9.0, 13.0, 9.0, -16.0, 12.0, 9.0, -14.0, 8.0, 12.0, 332.0, 12.0, 11.0, 3.0, -4.0, 3.0, 13.0, -9.0, 8.0, 6.0, 10.0, 14.0, 9.0, -1.0, -7.0, -14.0, 7.0, 12.0, 10.0, 1.0, -3.0, 4.0, 13.0, 13.0, -1.0, 9.0, -6.0, 14.0, 10.0, -20.0, 11.0, 12.0, -16.0, 9.0, 10.0, 3.0, -5.0, 5.0, 12.0, -2.0, 7.0, 12.0, -2.0, 14.0, -3.0, -5.0, 9.0, 13.0, -12.0, 5.0, 9.0, -8.0, 10.0, 0.0, 13.0, 9.0, 13.0, 5.0, -12.0, 14.0, 4.0, -10.0, 7.0, -17.0, 9.0, 12.0, 11.0, 5.0, -8.0, 10.0, 8.0, 12.0, 10.0, 12.0, -19.0, 14.0, 3.0, 7.0, -9.0, 3.0, 4.0, -4.0, 12.0, 11.0, -8.0, 4.0, 8.0, 13.0, -13.0, 8.0, 7.0, 14.0, -14.0, 3.0, 12.0, 3.0, 9.0, 11.0, -8.0, 9.0, -4.0, -3.0, 13.0, -7.0, 12.0, 3.0, 7.0, 14.0, -3.0, 1.0, 3.0, 10.0, -11.0, 6.0, 10.0, 7.0, 9.0, 6.0, -7.0, -1.0, 10.0, 12.0, -6.0, 14.0, 8.0, -19.0, 12.0, -9.0, 5.0, 10.0, 9.0, -7.0, 10.0, 0.0, 12.0, 9.0, 13.0, 0.0, -7.0, 12.0, 9.0, -12.0, 6.0, 12.0, 2.0, -6.0, 7.0, 11.0, -9.0, 7.0, 6.0, -2.0, 12.0, 11.0, -6.0, 14.0, 3.0, -9.0, 7.0, -4.0, 4.0, 9.0, 6.0, 8.0, -6.0, 5.0, 8.0, 9.0, 8.0, 5.0, -7.0, 14.0, 3.0, -14.0, 12.0, 12.0, -15.0, 6.0, 12.0, 12.0, -5.0, 5.0, 3.0, 9.0, 13.0, 5.0, -12.0, 13.0, 8.0, 1.0, -7.0, 6.0, -14.0, 12.0, 11.0, 7.0, 10.0, -14.0, 12.0, 12.0, -3.0, 7.0, -1.0, 8.0, 6.0, -6.0, 7.0, -19.0, 14.0, 10.0, 10.0, 6.0, 12.0, -16.0, 13.0, 3.0, -10.0, 12.0, 10.0, 14.0, 8.0, -8.0, 1.0, 11.0, 4.0, 10.0, -10.0, 8.0, -4.0, 3.0, 8.0, 13.0, 12.0, 11.0, -21.0, 14.0, 12.0, -13.0, 2.0, -14.0, 13.0, 11.0, 5.0, 9.0, 6.0, -10.0, 10.0, 7.0, -10.0, 6.0, 12.0, 14.0, 7.0, -13.0, 7.0, -5.0, -2.0, 11.0, 11.0, 5.0, 12.0, -15.0, 13.0, 13.0, 13.0, 12.0, 330.0, 10.0, 8.0, -10.0, 7.0, 9.0, -12.0, 7.0, 11.0, -1.0, -8.0, 11.0, 13.0, 13.0, -1.0, 4.0, -1.0, 13.0, 11.0, -14.0, 5.0, -4.0, 4.0, 4.0, 11.0, 8.0, 9.0, -15.0, 13.0, 13.0, 14.0, 11.0, 317.0, 14.0, 6.0, -15.0, 10.0, 0.0, 1.0, 4.0, 10.0, 10.0, -8.0, 0.0, 13.0, -1.0, -6.0, 12.0, 10.0, 14.0, 13.0, -19.0, 7.0, 10.0, -18.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22136078526107716, "mean_inference_ms": 1.177946243946162, "mean_action_processing_ms": 0.07203623344590211, "mean_env_wait_ms": 0.17991197825502492, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 993600, "agent_timesteps_total": 993519, "timers": {"sample_time_ms": 353.284, "sample_throughput": 15285.17, "learn_time_ms": 6569.504, "learn_throughput": 821.98, "update_time_ms": 11.891}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 1142.4803466796875, "policy_loss": -0.031431443989276886, "vf_loss": 1142.5081787109375, "vf_explained_var": 0.08114828169345856, "kl": 0.006506502628326416, "entropy": 0.4437468349933624, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 993600, "num_agent_steps_sampled": 993519, "num_steps_trained": 993600, "num_agent_steps_trained": 993519}, "done": false, "episodes_total": 19467, "training_iteration": 184, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-03-41", "timestamp": 1626861821, "time_this_iter_s": 6.85722017288208, "time_total_s": 1319.856772661209, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021ec80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1319.856772661209, "timesteps_since_restore": 0, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 21.22222222222222, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.27777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.319444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -9.0, 3.0, 12.0, 5.0, 11.0, -4.0, 3.0, 1.0, 5.0, -4.0, 13.0, 6.0, 12.0, -3.0, 0.0, 7.0, -7.0, 3.0, 12.0, 14.0, 10.0, 7.0, -16.0, 2.0, 4.0, -4.0, 13.0, 2.0, 8.0, -4.0, 9.0, 13.0, -13.0, 9.0, 6.0, -4.0, 3.0, 5.0, 11.0, -7.0, -2.0, 11.0, 13.0, -1.0, 13.0, 11.0, -8.0, 7.0, -8.0, 3.0, 13.0, -9.0, 13.0, 8.0, 3.0, 4.0, 9.0, -7.0, 9.0, -14.0, 4.0, 12.0, 13.0, 9.0, 3.0, 11.0, -8.0, 4.0, 9.0, -1.0, 3.0, 7.0, 13.0, -15.0, 10.0, 8.0, -9.0, 11.0, 5.0, -1.0, 8.0, -4.0, 12.0, -13.0, 13.0, 3.0, 12.0, 4.0, 2.0, -4.0, 13.0, -18.0, 8.0, 12.0, 13.0, -1.0, 14.0, 3.0, -1.0, 316.0, 13.0, 12.0, 13.0, 7.0, 1.0, -5.0, 12.0, -11.0, 10.0, 7.0, 9.0, -1.0, 7.0, 0.0, 9.0, -10.0, 8.0, 10.0, 7.0, -8.0, 14.0, -3.0, 12.0, -16.0, 12.0, 7.0, 12.0, 12.0, 6.0, -9.0, 6.0, 0.0, 5.0, 8.0, 2.0, 3.0, 14.0, -13.0, 11.0, -14.0, 13.0, 11.0, 5.0, 7.0, 5.0, -8.0, 11.0, -7.0, 11.0, 9.0, 2.0, -16.0, 11.0, 8.0, 12.0, -12.0, 8.0, 6.0, 13.0, -2.0, 2.0, 2.0, 13.0, -12.0, 11.0, 8.0, 8.0, -2.0, 7.0, -3.0, 13.0, -16.0, 7.0, 13.0, 11.0, -3.0, 0.0, 5.0, 13.0, -13.0, 11.0, 10.0, 7.0, -2.0, 13.0, -8.0, 12.0, -11.0, 7.0, 12.0, 7.0, 10.0, 1.0, -9.0, 13.0, -6.0, 8.0, 9.0, 4.0, 2.0, 6.0, -6.0, 13.0, -11.0, 6.0, 7.0, 13.0, 8.0, -8.0, 2.0, 13.0, 316.0, 13.0, 12.0, 13.0, -6.0, 14.0, -6.0, 13.0, 5.0, 10.0, 12.0, -12.0, 6.0, 10.0, -12.0, 11.0, 0.0, 12.0, 0.0, 3.0, 4.0, 8.0, -9.0, 12.0, -14.0, 8.0, 10.0, 11.0, 8.0, 8.0, -9.0, 8.0, -13.0, 11.0, 9.0, 8.0, 12.0, 2.0, -12.0, 13.0, -15.0, 8.0, 9.0, 13.0, 2.0, 11.0, -9.0, 11.0, 4.0, 12.0, -7.0, 6.0, 7.0, -13.0, 8.0, 13.0, -14.0, 13.0, 11.0, 5.0, 12.0, 4.0, -13.0, 12.0, 13.0, 11.0, -10.0, 1.0, -1.0, -5.0, 8.0, 13.0, -12.0, 12.0, 2.0, 13.0, 8.0, 4.0, -7.0, 10.0, -3.0, 9.0, 10.0, -1.0, 6.0, -10.0, 6.0, 13.0, -15.0, 12.0, 11.0, 7.0, 11.0, 2.0, -9.0, 11.0, -13.0, 12.0, 8.0, 8.0, 4.0, 6.0, -7.0, 12.0, 1.0, 13.0, -10.0, 11.0, 7.0, 9.0, -14.0, 13.0, 8.0, 5.0, 8.0, -6.0, -4.0, -5.0, 11.0, 13.0, -11.0, 8.0, 8.0, 10.0, 8.0, -5.0, -1.0, 13.0, -13.0, 11.0, 11.0, 6.0, 3.0, 11.0, -11.0, 12.0, -11.0, 13.0, 2.0, 11.0, 5.0, 9.0, -10.0, 11.0, -8.0, 10.0, 11.0, 2.0, -15.0, 13.0, 8.0, 9.0, -17.0, 8.0, 11.0, 13.0, 11.0, 3.0, -10.0, 11.0, -13.0, 12.0, 4.0, 12.0, -5.0, 14.0, -6.0, 12.0, 4.0, 13.0, -11.0, 9.0, 0.0, 12.0, 9.0, -6.0, 14.0, 10.0, -10.0, 1.0, -6.0, 14.0, -6.0, 13.0, -16.0, 13.0, 7.0, 11.0, 8.0, -8.0, 10.0, 5.0, -13.0, 9.0, 12.0, 7.0, 11.0, 0.0, -9.0, 13.0, -7.0, 13.0, -4.0, 13.0, 12.0, -6.0, 0.0, 9.0, -10.0, 10.0, 11.0, 4.0, -5.0, 13.0, -4.0, 11.0, -14.0, 12.0, 7.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2213761861346693, "mean_inference_ms": 1.1779878340790628, "mean_action_processing_ms": 0.07204468095459508, "mean_env_wait_ms": 0.1799247272515591, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 999000, "agent_timesteps_total": 998919, "timers": {"sample_time_ms": 353.783, "sample_throughput": 15263.613, "learn_time_ms": 6552.28, "learn_throughput": 824.141, "update_time_ms": 11.823}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 444.60455322265625, "policy_loss": -0.027192944660782814, "vf_loss": 444.6275329589844, "vf_explained_var": 0.21356238424777985, "kl": 0.007432839833199978, "entropy": 0.41337358951568604, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 999000, "num_agent_steps_sampled": 998919, "num_steps_trained": 999000, "num_agent_steps_trained": 998919}, "done": false, "episodes_total": 19575, "training_iteration": 185, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-03-48", "timestamp": 1626861828, "time_this_iter_s": 6.855066776275635, "time_total_s": 1326.7118394374847, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021e598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1326.7118394374847, "timesteps_since_restore": 0, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 22.16, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.26851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 5.31712962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 6.0, 13.0, 6.0, 5.0, 5.0, -8.0, 13.0, 10.0, 5.0, -13.0, 13.0, 14.0, -3.0, -1.0, 5.0, 7.0, -6.0, 10.0, 4.0, 1.0, 4.0, -3.0, 13.0, 14.0, -6.0, -2.0, 9.0, 13.0, -7.0, -2.0, 11.0, 10.0, -15.0, 13.0, 7.0, 8.0, 7.0, -13.0, 13.0, 14.0, 6.0, 0.0, -5.0, -3.0, 6.0, 3.0, 9.0, 13.0, -6.0, 2.0, 6.0, 3.0, 12.0, -10.0, 10.0, 13.0, 5.0, -12.0, 9.0, 1.0, 6.0, -2.0, 10.0, 9.0, -8.0, 7.0, 7.0, -9.0, -1.0, 12.0, 13.0, 14.0, 5.0, -13.0, 9.0, -3.0, 0.0, 12.0, 6.0, 13.0, -13.0, 9.0, 6.0, -2.0, -3.0, 7.0, 13.0, 13.0, 3.0, -10.0, 9.0, 5.0, 5.0, -2.0, 7.0, 9.0, -5.0, 5.0, 6.0, -13.0, 7.0, 9.0, 12.0, 14.0, 3.0, 8.0, -10.0, -10.0, 11.0, 8.0, 6.0, 12.0, -5.0, 7.0, 1.0, -14.0, 7.0, 12.0, 10.0, 13.0, 5.0, 4.0, -7.0, -7.0, 10.0, 8.0, 4.0, -7.0, 4.0, 12.0, 6.0, -3.0, -3.0, 9.0, 12.0, 13.0, 13.0, -20.0, 9.0, -2.0, 5.0, 8.0, 4.0, 13.0, 13.0, 5.0, -16.0, 10.0, -10.0, 2.0, 13.0, 12.0, 2.0, -11.0, 12.0, 8.0, 0.0, -2.0, 9.0, -4.0, 4.0, 12.0, 3.0, 11.0, 317.0, 12.0, 13.0, 8.0, 0.0, -5.0, 12.0, 12.0, -3.0, -1.0, 7.0, -2.0, 8.0, 5.0, 4.0, -3.0, 13.0, 7.0, -2.0, 14.0, 2.0, -4.0, 3.0, 11.0, 0.0, -2.0, 6.0, 9.0, -10.0, 9.0, 7.0, 10.0, -2.0, -6.0, 13.0, 7.0, 1.0, -2.0, 9.0, -4.0, -3.0, 13.0, 9.0, -9.0, 5.0, 13.0, 6.0, -10.0, 6.0, 7.0, 12.0, 12.0, 7.0, -14.0, 10.0, -1.0, 5.0, 7.0, 4.0, 13.0, -15.0, 11.0, 6.0, 4.0, -10.0, 8.0, 13.0, 11.0, -4.0, -3.0, 11.0, -2.0, 3.0, 7.0, 7.0, -2.0, 11.0, 13.0, -7.0, 11.0, -15.0, 7.0, 12.0, 14.0, 7.0, 5.0, -11.0, -1.0, -2.0, 12.0, 6.0, 13.0, -4.0, 9.0, -3.0, -7.0, 8.0, 12.0, 2.0, 14.0, 2.0, -12.0, 11.0, -7.0, 3.0, 12.0, 7.0, -9.0, 6.0, 13.0, 5.0, -2.0, 5.0, 1.0, 11.0, 12.0, 10.0, 4.0, -11.0, 3.0, 6.0, -2.0, 8.0, -6.0, 6.0, 10.0, 5.0, 317.0, 12.0, 12.0, 13.0, 12.0, 12.0, -19.0, 10.0, -5.0, -1.0, 12.0, 9.0, 9.0, 10.0, 5.0, -9.0, 4.0, -8.0, 6.0, 13.0, 14.0, 8.0, -9.0, 2.0, 12.0, 0.0, -2.0, 5.0, 7.0, 5.0, 11.0, -8.0, 4.0, 13.0, -14.0, 12.0, 14.0, 1.0, -9.0, 9.0, -2.0, -2.0, 12.0, 7.0, 7.0, -8.0, 10.0, 6.0, -9.0, 0.0, 12.0, 12.0, 12.0, 11.0, -15.0, 7.0, 10.0, -2.0, -1.0, 8.0, 12.0, -5.0, 3.0, 5.0, 4.0, -13.0, 12.0, 12.0, 12.0, 6.0, 1.0, -4.0, -8.0, 10.0, 8.0, 5.0, 13.0, 9.0, 1.0, -8.0, -3.0, 1.0, 7.0, 10.0, 13.0, 6.0, -12.0, 8.0, 12.0, 13.0, -13.0, 3.0, 9.0, -3.0, 4.0, 5.0, -9.0, -1.0, 12.0, 13.0, 14.0, 13.0, -17.0, 5.0, -1.0, 0.0, 12.0, 4.0, 10.0, -14.0, 13.0, 6.0, 5.0, -13.0, 10.0, 13.0, 12.0, 6.0, 0.0, -3.0, 12.0, 4.0, -2.0, 1.0, 5.0, 6.0, 13.0, -9.0, -13.0, 10.0, 13.0, 5.0, 12.0, 5.0, -12.0, 10.0, -1.0, 10.0, -1.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22142378246966374, "mean_inference_ms": 1.1781333618609027, "mean_action_processing_ms": 0.07205068104526043, "mean_env_wait_ms": 0.17995029351086292, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 1004400, "agent_timesteps_total": 1004319, "timers": {"sample_time_ms": 354.145, "sample_throughput": 15247.974, "learn_time_ms": 6524.884, "learn_throughput": 827.601, "update_time_ms": 11.777}, "info": {"learner": {"learned": {"learner_stats": {"cur_kl_coeff": 0.569531261920929, "cur_lr": 4.999999873689376e-05, "total_loss": 430.96356201171875, "policy_loss": -0.018535198643803596, "vf_loss": 430.9783935546875, "vf_explained_var": 0.18000805377960205, "kl": 0.006683102808892727, "entropy": 0.41117796301841736, "entropy_coeff": 0.0, "model": {}}}}, "num_steps_sampled": 1004400, "num_agent_steps_sampled": 1004319, "num_steps_trained": 1004400, "num_agent_steps_trained": 1004319}, "done": true, "episodes_total": 19683, "training_iteration": 186, "experiment_id": "82628806f16d4164b162f186311bb2c4", "date": "2021-07-21_12-03-55", "timestamp": 1626861835, "time_this_iter_s": 6.843027830123901, "time_total_s": 1333.5548672676086, "pid": 15974, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f9e7021e7b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1333.5548672676086, "timesteps_since_restore": 0, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 21.930000000000003, "ram_util_percent": 14.300000000000002}, "trial_id": "cf107_00000"}
