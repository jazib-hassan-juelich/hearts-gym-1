{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.203703703703702, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.550925925925926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 5.0, -11.0, 9.0, -3.0, 1.0, 5.0, 12.0, -16.0, 11.0, 7.0, 13.0, 12.0, 10.0, 8.0, -15.0, 12.0, 12.0, 9.0, -18.0, 13.0, 1.0, 10.0, -9.0, 13.0, 4.0, -8.0, 6.0, -2.0, 13.0, -2.0, 6.0, 12.0, 3.0, -13.0, 13.0, 14.0, -10.0, 4.0, 7.0, -10.0, 10.0, 13.0, 2.0, 13.0, 12.0, 318.0, 11.0, 8.0, -5.0, 5.0, 7.0, 7.0, 3.0, -5.0, 11.0, 11.0, -11.0, 12.0, 3.0, -3.0, 9.0, 8.0, 1.0, 12.0, 9.0, -6.0, 0.0, 2.0, -6.0, 10.0, 9.0, 6.0, -6.0, 9.0, 6.0, -10.0, 12.0, 6.0, 7.0, -2.0, 10.0, 3.0, 4.0, 7.0, -6.0, 9.0, 5.0, -14.0, 9.0, 13.0, 7.0, 9.0, 13.0, -1.0, -6.0, 8.0, -1.0, 8.0, 0.0, 8.0, 14.0, 3.0, -10.0, -12.0, 7.0, 12.0, 8.0, -6.0, 12.0, 6.0, 3.0, 13.0, 3.0, 12.0, -13.0, 9.0, 9.0, -8.0, 6.0, 2.0, 10.0, 12.0, -9.0, -2.0, 13.0, 12.0, -8.0, 9.0, 7.0, 6.0, -7.0, 14.0, 13.0, 6.0, -17.0, -11.0, 11.0, 8.0, 7.0, 9.0, 5.0, 6.0, -5.0, -3.0, 8.0, 7.0, 3.0, 1.0, 10.0, 7.0, -3.0, 5.0, -12.0, 9.0, 13.0, 10.0, 12.0, 5.0, -12.0, 11.0, -13.0, 8.0, 9.0, 8.0, 5.0, 6.0, -3.0, -11.0, 10.0, 8.0, 8.0, 12.0, 12.0, 6.0, -15.0, 12.0, 8.0, -7.0, 2.0, 14.0, -12.0, 1.0, 12.0, 4.0, -8.0, 8.0, 11.0, 10.0, 12.0, 4.0, -11.0, -6.0, 7.0, 12.0, 2.0, 14.0, 14.0, 7.0, -20.0, 6.0, -4.0, 12.0, 1.0, 11.0, 9.0, -6.0, 1.0, 11.0, 6.0, -9.0, 7.0, 5.0, 8.0, 9.0, -6.0, 7.0, -4.0, 8.0, 4.0, 6.0, 14.0, -9.0, 4.0, 12.0, 13.0, 9.0, -19.0, 5.0, -3.0, 4.0, 9.0, -2.0, 11.0, 8.0, -2.0, 10.0, 6.0, -9.0, 8.0, 4.0, -6.0, 8.0, 9.0, 6.0, 9.0, 5.0, -5.0, -9.0, 7.0, 7.0, 10.0, 11.0, -4.0, 6.0, 2.0, -9.0, 9.0, 5.0, 10.0, 8.0, 9.0, 4.0, -6.0, -10.0, 7.0, 12.0, 6.0, 11.0, 14.0, 5.0, -15.0, -4.0, 5.0, 10.0, 4.0, 4.0, 10.0, -6.0, 7.0, 13.0, -12.0, 2.0, 12.0, 7.0, -6.0, 2.0, 12.0, 10.0, 6.0, 6.0, -7.0, -13.0, 14.0, 5.0, 9.0, -11.0, 4.0, 13.0, 9.0, 12.0, 10.0, 6.0, -13.0, -2.0, 5.0, 7.0, 5.0, 5.0, -6.0, 6.0, 10.0, 2.0, 7.0, 13.0, -7.0, 11.0, 10.0, 5.0, -11.0, 8.0, 9.0, 6.0, -8.0, 9.0, 5.0, -5.0, 6.0, 2.0, -5.0, 11.0, 7.0, -2.0, 10.0, 3.0, 4.0, 10.0, 8.0, 8.0, -11.0, 7.0, -9.0, 10.0, 8.0, -6.0, 11.0, 5.0, 5.0, -2.0, 10.0, 4.0, 3.0, -7.0, 8.0, 8.0, 6.0, -11.0, 7.0, 9.0, 10.0, 4.0, -1.0, 6.0, 6.0, 12.0, 10.0, 5.0, -12.0, 12.0, 4.0, 8.0, -9.0, 13.0, 4.0, 4.0, -6.0, -3.0, 1.0, 12.0, 5.0, 13.0, 11.0, 11.0, -20.0, 10.0, 7.0, -5.0, 3.0, 4.0, 4.0, -4.0, 12.0, -10.0, 6.0, 13.0, 6.0, 10.0, 13.0, -12.0, 4.0, 7.0, 7.0, 11.0, -10.0, 14.0, 2.0, 2.0, -3.0, 9.0, -8.0, 8.0, 6.0, -6.0, 7.0, 11.0, 3.0, 8.0, 5.0, -4.0, 6.0, -4.0, 5.0, 4.0, 10.0, -9.0, 10.0, 6.0, 8.0, 12.0, 8.0, -13.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.17885808591489435, "mean_inference_ms": 1.211309045310912, "mean_action_processing_ms": 0.08348027326657952, "mean_env_wait_ms": 0.17021695234372802, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 5508, "agent_timesteps_total": 5508, "timers": {"sample_time_ms": 0.12, "sample_throughput": 45983920.755, "learn_time_ms": 423.791, "learn_throughput": 12996.96, "update_time_ms": 11.356}, "info": {"learner": {"learned": {"policy_loss": 128227418112.0, "vf_loss": 134.98342895507812, "total_loss": 128227418112.0, "vf_explained_var": 2.5928020477294922e-05, "model": {}}}, "num_steps_sampled": 5508, "num_agent_steps_sampled": 5508, "num_steps_trained": 5508, "num_agent_steps_trained": 5508}, "done": false, "episodes_total": 108, "training_iteration": 1, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-23", "timestamp": 1626864443, "time_this_iter_s": 0.8565301895141602, "time_total_s": 0.8565301895141602, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 0.8565301895141602, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 47.2, "ram_util_percent": 13.9}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, -5.0, 12.0, 7.0, 10.0, 12.0, -10.0, 3.0, 12.0, -2.0, 3.0, 2.0, -3.0, 11.0, 4.0, 3.0, 14.0, 6.0, -9.0, 4.0, 10.0, 9.0, 5.0, -9.0, 6.0, 12.0, 7.0, -10.0, 11.0, -4.0, 7.0, 1.0, 6.0, 2.0, -2.0, 9.0, 6.0, -3.0, 4.0, 8.0, 8.0, 10.0, 12.0, -15.0, 8.0, -5.0, 5.0, 7.0, 13.0, 5.0, -6.0, 3.0, 11.0, 5.0, 8.0, -9.0, 5.0, -1.0, 7.0, 4.0, 6.0, -5.0, 6.0, 8.0, 13.0, 7.0, -9.0, 4.0, 7.0, 10.0, 7.0, -9.0, -4.0, 11.0, 12.0, -4.0, 10.0, -6.0, 1.0, 10.0, 13.0, -3.0, 13.0, -8.0, 8.0, 11.0, -9.0, 5.0, 1.0, 9.0, 13.0, -8.0, 10.0, -9.0, 11.0, 3.0, 11.0, 3.0, -8.0, 9.0, 1.0, -1.0, 12.0, 3.0, 9.0, 10.0, -16.0, 12.0, 7.0, -2.0, 2.0, 8.0, 14.0, 1.0, -5.0, 5.0, 2.0, 11.0, 6.0, -4.0, 8.0, 5.0, 10.0, -8.0, 8.0, -4.0, 11.0, 0.0, 12.0, 4.0, -2.0, 1.0, 7.0, -4.0, 9.0, 3.0, 6.0, 13.0, 4.0, -8.0, 1.0, -1.0, 6.0, 9.0, 12.0, 5.0, -10.0, 8.0, 8.0, 12.0, -9.0, 4.0, 0.0, -4.0, 12.0, 7.0, 12.0, -6.0, 7.0, 2.0, 14.0, 2.0, -7.0, 6.0, 4.0, 11.0, 10.0, -10.0, 6.0, 10.0, -10.0, 9.0, 9.0, 10.0, -11.0, 7.0, 12.0, 9.0, 7.0, -13.0, 7.0, 12.0, -10.0, 6.0, 0.0, -3.0, 6.0, 12.0, -10.0, 6.0, 11.0, 8.0, 2.0, 7.0, -4.0, 10.0, 2.0, 10.0, -8.0, 11.0, -9.0, 10.0, 4.0, 10.0, -14.0, 12.0, 9.0, 8.0, 12.0, 10.0, -12.0, 5.0, 7.0, 8.0, -5.0, 5.0, -20.0, 13.0, 9.0, 13.0, -2.0, 10.0, 5.0, 2.0, 13.0, 6.0, -9.0, 5.0, 12.0, 7.0, 5.0, -9.0, 8.0, -13.0, 8.0, 12.0, 6.0, 11.0, 9.0, -11.0, 12.0, 1.0, -7.0, 9.0, 5.0, 14.0, -4.0, 0.0, -3.0, -4.0, 11.0, 11.0, -4.0, 6.0, 6.0, 7.0, 13.0, -1.0, 7.0, -4.0, 6.0, 5.0, -5.0, 9.0, 10.0, -6.0, 6.0, 5.0, 6.0, -5.0, 7.0, 7.0, 13.0, 5.0, 8.0, -11.0, 2.0, 12.0, -8.0, 9.0, -2.0, 13.0, 7.0, -3.0, -10.0, 6.0, 11.0, 8.0, 11.0, 2.0, -8.0, 10.0, 0.0, 13.0, -8.0, 10.0, 9.0, 14.0, 9.0, -17.0, 5.0, -6.0, 8.0, 8.0, 4.0, 6.0, -8.0, 13.0, 12.0, 7.0, -7.0, 3.0, -3.0, 10.0, -3.0, 11.0, -4.0, 14.0, -3.0, 8.0, 14.0, 3.0, -2.0, 0.0, 8.0, 11.0, -11.0, 7.0, 1.0, -2.0, 9.0, 7.0, -5.0, 5.0, 7.0, 8.0, 2.0, 9.0, -8.0, 12.0, 5.0, 11.0, -6.0, 5.0, 8.0, 10.0, 10.0, -13.0, -7.0, 10.0, 12.0, 0.0, 11.0, -9.0, 6.0, 7.0, 7.0, 8.0, -10.0, 10.0, 4.0, -6.0, 7.0, 10.0, 9.0, -1.0, -1.0, 8.0, 8.0, 8.0, -8.0, 7.0, 7.0, 9.0, -9.0, 8.0, -1.0, 14.0, 4.0, -2.0, 11.0, -9.0, 11.0, 2.0, 10.0, 7.0, -12.0, 10.0, 5.0, 9.0, 10.0, -9.0, -12.0, 12.0, 5.0, 10.0, 11.0, -4.0, 6.0, 2.0, 12.0, 4.0, -9.0, 8.0, 7.0, 11.0, 13.0, -16.0, 1.0, 12.0, 11.0, -9.0, 9.0, 12.0, -12.0, 6.0, 12.0, 5.0, 10.0, -12.0, 6.0, 12.0, 4.0, -7.0, 6.0, -7.0, 11.0, 5.0, 11.0, -4.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18163672135185646, "mean_inference_ms": 1.1443340032415674, "mean_action_processing_ms": 0.07716223110401747, "mean_env_wait_ms": 0.17167454686467554, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 11016, "agent_timesteps_total": 11016, "timers": {"sample_time_ms": 0.091, "sample_throughput": 60386460.399, "learn_time_ms": 219.806, "learn_throughput": 25058.493, "update_time_ms": 8.661}, "info": {"learner": {"learned": {"policy_loss": 1.4791498184204102, "vf_loss": 16.09618377685547, "total_loss": 17.575332641601562, "vf_explained_var": 3.886222839355469e-05, "model": {}}}, "num_steps_sampled": 11016, "num_agent_steps_sampled": 11016, "num_steps_trained": 11016, "num_agent_steps_trained": 11016}, "done": false, "episodes_total": 216, "training_iteration": 2, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-24", "timestamp": 1626864444, "time_this_iter_s": 0.3723907470703125, "time_total_s": 1.2289209365844727, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 1.2289209365844727, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 366.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.537037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 326.0}, "policy_reward_mean": {"learned": 6.1342592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 12.0, 11.0, -9.0, -15.0, 12.0, 11.0, 7.0, 5.0, -12.0, 11.0, 11.0, -1.0, -5.0, 8.0, 13.0, 14.0, 6.0, 10.0, -15.0, -2.0, 1.0, 10.0, 6.0, 6.0, -2.0, 8.0, 3.0, 13.0, -3.0, -6.0, 11.0, 13.0, 11.0, 6.0, -15.0, -6.0, 9.0, 6.0, 6.0, 10.0, -8.0, 8.0, 5.0, 8.0, -4.0, 12.0, -1.0, 12.0, 12.0, 1.0, -10.0, -12.0, 9.0, 11.0, 7.0, 8.0, -5.0, 4.0, 8.0, -1.0, -3.0, 11.0, 8.0, 11.0, 12.0, 11.0, -19.0, 5.0, 13.0, -11.0, 8.0, 12.0, -15.0, 11.0, 7.0, 12.0, -16.0, 11.0, 8.0, 7.0, 9.0, 6.0, -7.0, 1.0, 9.0, 7.0, -2.0, 8.0, -12.0, 7.0, 12.0, -6.0, -1.0, 11.0, 11.0, 10.0, 12.0, -18.0, 11.0, -13.0, 12.0, 11.0, 5.0, 11.0, 7.0, -1.0, -2.0, 0.0, -6.0, 12.0, 9.0, 4.0, 10.0, 9.0, -8.0, -11.0, 13.0, 5.0, 8.0, 7.0, -2.0, 8.0, 2.0, 14.0, -8.0, 12.0, -3.0, 13.0, 7.0, 5.0, -10.0, 8.0, 7.0, -7.0, 7.0, 8.0, -8.0, 5.0, 10.0, -7.0, -2.0, 11.0, 13.0, 9.0, -2.0, 7.0, 1.0, 5.0, -11.0, 13.0, 8.0, 11.0, -7.0, 8.0, 3.0, 14.0, 326.0, 13.0, 13.0, 13.0, -3.0, -6.0, 11.0, -4.0, 12.0, 13.0, -6.0, 5.0, -7.0, 12.0, 5.0, 14.0, -23.0, 11.0, 13.0, 10.0, 14.0, 10.0, -19.0, -5.0, 12.0, 12.0, -4.0, 11.0, -7.0, 7.0, 4.0, 13.0, -6.0, 9.0, -1.0, -5.0, 13.0, -1.0, 8.0, -12.0, 8.0, 12.0, 7.0, 8.0, -11.0, 8.0, 10.0, 14.0, 316.0, 12.0, 12.0, 14.0, -4.0, 6.0, -1.0, -13.0, 8.0, 8.0, 12.0, 6.0, -10.0, 8.0, 11.0, -5.0, 0.0, 8.0, 12.0, 13.0, 10.0, 7.0, -15.0, -10.0, 13.0, 10.0, 2.0, 11.0, 3.0, -10.0, 11.0, 14.0, -22.0, 11.0, 12.0, 8.0, 13.0, -17.0, 11.0, 4.0, -11.0, 13.0, 9.0, 12.0, -2.0, 0.0, 5.0, 9.0, -18.0, 12.0, 12.0, 14.0, 5.0, 4.0, -8.0, 7.0, 12.0, -12.0, 8.0, 5.0, 7.0, 13.0, -10.0, 13.0, -18.0, 9.0, 11.0, 9.0, 14.0, 6.0, -14.0, -12.0, 12.0, 8.0, 7.0, 10.0, -8.0, 3.0, 10.0, 9.0, 2.0, -8.0, 12.0, 12.0, 12.0, 10.0, 321.0, -3.0, -7.0, 13.0, 12.0, 11.0, -12.0, 10.0, 6.0, 12.0, -19.0, 11.0, 11.0, 9.0, 8.0, 10.0, -12.0, 12.0, -15.0, 6.0, 12.0, 7.0, -11.0, 8.0, 11.0, -1.0, -7.0, 11.0, 12.0, 9.0, -3.0, 8.0, 1.0, 2.0, -4.0, 10.0, 7.0, 9.0, 1.0, -8.0, 13.0, 8.0, -16.0, 12.0, 11.0, 10.0, -3.0, 3.0, 5.0, 8.0, 6.0, -7.0, 8.0, 3.0, -13.0, 13.0, 12.0, 9.0, -18.0, 11.0, 13.0, 6.0, -1.0, 7.0, 3.0, 7.0, 12.0, -12.0, 8.0, -2.0, 8.0, 8.0, 1.0, 14.0, -19.0, 8.0, 12.0, -2.0, 6.0, 9.0, 2.0, -13.0, 11.0, 10.0, 7.0, 6.0, 11.0, 7.0, -9.0, 12.0, -3.0, -4.0, 10.0, 6.0, 14.0, 5.0, -10.0, 3.0, 12.0, -6.0, 6.0, 13.0, -6.0, 2.0, 6.0, 13.0, -9.0, -2.0, 13.0, 8.0, 8.0, 9.0, -10.0, 7.0, -16.0, 12.0, 12.0, 6.0, -9.0, 9.0, 9.0, 11.0, 1.0, 11.0, -8.0, 10.0, 12.0, -18.0, 11.0, -1.0, 12.0, -8.0, 12.0, 9.0, 7.0, -14.0, 13.0, 13.0, -7.0, -4.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18296323293040906, "mean_inference_ms": 1.1187244359045747, "mean_action_processing_ms": 0.07541166260252402, "mean_env_wait_ms": 0.17292769925701362, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 16524, "agent_timesteps_total": 16524, "timers": {"sample_time_ms": 0.087, "sample_throughput": 63067498.72, "learn_time_ms": 150.876, "learn_throughput": 36506.885, "update_time_ms": 7.84}, "info": {"learner": {"learned": {"policy_loss": 1.47813081741333, "vf_loss": 16.08620262145996, "total_loss": 17.564332962036133, "vf_explained_var": -3.075599670410156e-05, "model": {}}}, "num_steps_sampled": 16524, "num_agent_steps_sampled": 16524, "num_steps_trained": 16524, "num_agent_steps_trained": 16524}, "done": false, "episodes_total": 324, "training_iteration": 3, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-24", "timestamp": 1626864444, "time_this_iter_s": 0.35642504692077637, "time_total_s": 1.585345983505249, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 1.585345983505249, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 54.6, "ram_util_percent": 13.9}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -15.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 9.0, 9.0, -10.0, 1.0, 6.0, -2.0, 10.0, -8.0, 13.0, -1.0, 11.0, 1.0, -6.0, 9.0, 11.0, 12.0, 0.0, -9.0, 12.0, 0.0, 11.0, -2.0, 6.0, -2.0, 9.0, 2.0, 6.0, 0.0, -5.0, 11.0, 9.0, 10.0, 5.0, 4.0, -4.0, 6.0, 9.0, 8.0, -8.0, 2.0, 13.0, 6.0, -6.0, 11.0, 10.0, 5.0, -11.0, 12.0, 7.0, -3.0, -1.0, 0.0, 8.0, -4.0, 11.0, -5.0, 9.0, 9.0, 2.0, -2.0, 12.0, 13.0, -8.0, 8.0, -2.0, 5.0, 4.0, -10.0, 10.0, 7.0, 8.0, -10.0, 13.0, 1.0, 11.0, 0.0, 13.0, 11.0, -9.0, -4.0, 11.0, 11.0, -3.0, 6.0, 10.0, -8.0, 7.0, 13.0, 1.0, 4.0, -3.0, 12.0, 9.0, 3.0, -9.0, 11.0, 10.0, -14.0, 8.0, 5.0, 7.0, 6.0, -3.0, 2.0, 14.0, 2.0, -3.0, 4.0, -7.0, 12.0, 6.0, 1.0, 11.0, 6.0, -3.0, -9.0, 7.0, 12.0, 5.0, 0.0, 13.0, 4.0, -2.0, 6.0, 6.0, 13.0, -10.0, 10.0, 9.0, -8.0, 4.0, -15.0, 12.0, 12.0, 6.0, 0.0, 1.0, 5.0, 9.0, 8.0, -13.0, 9.0, 11.0, 3.0, 9.0, 9.0, -6.0, -2.0, 7.0, 12.0, -2.0, -7.0, 12.0, 6.0, 4.0, -14.0, 10.0, 10.0, 9.0, 5.0, 13.0, -10.0, 7.0, 3.0, 11.0, -3.0, 4.0, -7.0, 9.0, 4.0, 9.0, -7.0, 11.0, -1.0, 12.0, 11.0, 2.0, -9.0, 11.0, 11.0, 9.0, 7.0, -12.0, -12.0, 12.0, 6.0, 9.0, 2.0, 13.0, 4.0, -4.0, 11.0, 2.0, 12.0, -10.0, 7.0, 10.0, -9.0, 7.0, 0.0, 13.0, -4.0, 6.0, 2.0, -10.0, 10.0, 13.0, 9.0, 4.0, -6.0, 8.0, 5.0, 4.0, -5.0, 11.0, 8.0, 13.0, 1.0, -7.0, -3.0, -7.0, 13.0, 12.0, 3.0, 10.0, -8.0, 10.0, 4.0, 9.0, 4.0, -2.0, 7.0, 14.0, -3.0, -3.0, 2.0, 13.0, 10.0, -10.0, 9.0, 11.0, -15.0, 10.0, -14.0, 9.0, 11.0, 9.0, -9.0, 13.0, 11.0, 0.0, 3.0, 10.0, -9.0, 11.0, 5.0, 11.0, -7.0, 6.0, 2.0, 9.0, -5.0, 9.0, 13.0, 4.0, -1.0, -1.0, 7.0, 11.0, -10.0, 7.0, -13.0, 8.0, 8.0, 12.0, -5.0, 11.0, 11.0, -2.0, -6.0, 9.0, 8.0, 4.0, -1.0, 7.0, -4.0, 13.0, 7.0, -11.0, 12.0, 7.0, -9.0, 13.0, 7.0, 4.0, 2.0, 5.0, 10.0, -2.0, -14.0, 10.0, 11.0, 8.0, 10.0, 5.0, 3.0, -3.0, 11.0, 4.0, 12.0, -12.0, -5.0, 14.0, -5.0, 11.0, 5.0, 6.0, -7.0, 11.0, -11.0, 12.0, 7.0, 7.0, 0.0, 11.0, 11.0, -7.0, -5.0, 2.0, 9.0, 9.0, 3.0, 13.0, 7.0, -8.0, 10.0, 12.0, 6.0, -13.0, 1.0, 11.0, -8.0, 11.0, -2.0, 8.0, 0.0, 9.0, -1.0, 13.0, -10.0, 13.0, -6.0, 3.0, 7.0, 11.0, -1.0, 13.0, -7.0, 10.0, -5.0, 3.0, 6.0, 11.0, 4.0, 7.0, -6.0, 10.0, 11.0, 3.0, 6.0, -5.0, -9.0, 12.0, 4.0, 8.0, -12.0, 9.0, 9.0, 9.0, -1.0, 12.0, -7.0, 11.0, 12.0, 7.0, 4.0, -8.0, 3.0, 11.0, 8.0, -7.0, -2.0, 9.0, 4.0, 4.0, 6.0, 11.0, -10.0, 8.0, 12.0, 5.0, 8.0, -10.0, 7.0, 5.0, -4.0, 7.0, 8.0, 7.0, 4.0, -4.0, 9.0, -3.0, 4.0, 5.0, 14.0, 9.0, -9.0, 1.0, -6.0, 11.0, 4.0, 6.0, -5.0, 13.0, 9.0, -2.0, -5.0, 12.0, 12.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18258390716728432, "mean_inference_ms": 1.09980747173269, "mean_action_processing_ms": 0.07435520960168257, "mean_env_wait_ms": 0.1730965791962792, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 22032, "agent_timesteps_total": 22032, "timers": {"sample_time_ms": 0.087, "sample_throughput": 63086821.742, "learn_time_ms": 116.955, "learn_throughput": 47094.972, "update_time_ms": 7.835}, "info": {"learner": {"learned": {"policy_loss": 1.4771023988723755, "vf_loss": 16.076139450073242, "total_loss": 17.553241729736328, "vf_explained_var": -0.00010228157043457031, "model": {}}}, "num_steps_sampled": 22032, "num_agent_steps_sampled": 22032, "num_steps_trained": 22032, "num_agent_steps_trained": 22032}, "done": false, "episodes_total": 432, "training_iteration": 4, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-25", "timestamp": 1626864445, "time_this_iter_s": 0.3591430187225342, "time_total_s": 1.9444890022277832, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 1.9444890022277832, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 80.2, "ram_util_percent": 13.9}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 13.0, 0.0, -5.0, 13.0, -3.0, 12.0, -7.0, 11.0, 5.0, -8.0, 7.0, 1.0, -4.0, 5.0, 13.0, 6.0, 13.0, -16.0, 12.0, 12.0, -7.0, 4.0, 6.0, 12.0, -11.0, 5.0, 9.0, 1.0, -2.0, 5.0, 11.0, 11.0, 8.0, -13.0, 9.0, 8.0, 9.0, 11.0, -13.0, 7.0, -4.0, 11.0, 1.0, 4.0, -4.0, 10.0, 5.0, 7.0, 10.0, -14.0, 12.0, 6.0, 4.0, -8.0, 13.0, -10.0, 7.0, 6.0, 12.0, -1.0, -8.0, 11.0, 13.0, 13.0, 8.0, -18.0, 12.0, 13.0, -8.0, 7.0, 3.0, 12.0, -9.0, 11.0, 1.0, 0.0, -1.0, 4.0, 12.0, 10.0, 13.0, -3.0, -5.0, 11.0, 8.0, 12.0, -16.0, 7.0, -9.0, 5.0, 12.0, -14.0, 13.0, 5.0, 11.0, 12.0, 6.0, 2.0, -5.0, 12.0, 3.0, -3.0, 3.0, 13.0, 7.0, 9.0, -14.0, 1.0, 8.0, 12.0, -6.0, 7.0, 13.0, -16.0, 11.0, -3.0, 2.0, 12.0, 4.0, 10.0, 8.0, 7.0, -10.0, -3.0, 12.0, -6.0, 12.0, -9.0, 13.0, 4.0, 7.0, 9.0, 7.0, 12.0, -13.0, -1.0, 4.0, 1.0, 11.0, 1.0, 13.0, 12.0, -11.0, 12.0, 6.0, -15.0, 12.0, 12.0, 3.0, -8.0, 8.0, 5.0, 8.0, -9.0, 11.0, -2.0, -1.0, 12.0, 6.0, 6.0, 8.0, -9.0, 10.0, -1.0, 10.0, 6.0, 0.0, 9.0, 8.0, 10.0, -12.0, -7.0, 0.0, 12.0, 10.0, 6.0, 11.0, -1.0, -1.0, 13.0, 3.0, 10.0, -11.0, -6.0, 3.0, 7.0, 11.0, -1.0, -2.0, 12.0, 6.0, 11.0, 8.0, 5.0, -9.0, 12.0, 4.0, 12.0, -13.0, 11.0, 5.0, 7.0, -8.0, 3.0, 12.0, -7.0, 7.0, 12.0, 14.0, -8.0, -3.0, 5.0, -6.0, 4.0, 12.0, -4.0, -2.0, 9.0, 12.0, -2.0, -5.0, 12.0, 10.0, 13.0, 8.0, -17.0, 11.0, 8.0, 10.0, 8.0, -11.0, -6.0, 6.0, 9.0, 6.0, 2.0, -1.0, 12.0, 2.0, 8.0, 13.0, -4.0, -2.0, 9.0, 9.0, 8.0, -11.0, -9.0, 7.0, 6.0, 11.0, 0.0, 0.0, 12.0, 3.0, 2.0, 13.0, 2.0, -2.0, -7.0, 5.0, 7.0, 10.0, 7.0, -13.0, 10.0, 11.0, -10.0, 12.0, 2.0, 11.0, 5.0, 13.0, -1.0, -2.0, 8.0, -6.0, 8.0, 5.0, 10.0, -8.0, 1.0, 12.0, -4.0, -1.0, 7.0, 13.0, 5.0, 7.0, 5.0, -2.0, 12.0, -9.0, 4.0, 8.0, 12.0, -5.0, 8.0, 0.0, 0.0, -5.0, 10.0, 10.0, 13.0, 3.0, 4.0, -5.0, 9.0, -7.0, 11.0, 2.0, 3.0, 2.0, 11.0, -1.0, 2.0, -3.0, 3.0, 13.0, 6.0, 6.0, -8.0, 11.0, 12.0, 0.0, -5.0, 8.0, 13.0, -10.0, 6.0, 6.0, 2.0, -1.0, 3.0, 11.0, 7.0, 13.0, -2.0, -3.0, -4.0, 4.0, 10.0, 5.0, 7.0, 13.0, -9.0, 4.0, -10.0, 11.0, 11.0, 3.0, 5.0, 7.0, 5.0, -2.0, 10.0, -12.0, 12.0, 5.0, 5.0, 10.0, 6.0, -6.0, -7.0, 12.0, -2.0, 12.0, 10.0, 8.0, -13.0, 10.0, 6.0, -9.0, 11.0, 7.0, 9.0, 6.0, 1.0, -1.0, 1.0, 12.0, -7.0, 9.0, 7.0, 12.0, -16.0, 12.0, 11.0, 10.0, 5.0, -11.0, 8.0, 1.0, 10.0, -4.0, 4.0, -4.0, 12.0, 3.0, 3.0, 13.0, -13.0, 12.0, 12.0, -7.0, 6.0, 4.0, -7.0, 2.0, 8.0, 12.0, -6.0, 12.0, -4.0, 13.0, 5.0, 8.0, -10.0, 12.0, 9.0, 9.0, 8.0, -11.0, -2.0, 1.0, 4.0, 12.0, 5.0, 10.0, 12.0, -12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18304536896742743, "mean_inference_ms": 1.0966578743146185, "mean_action_processing_ms": 0.07379673837331087, "mean_env_wait_ms": 0.17358706946834312, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 27540, "agent_timesteps_total": 27540, "timers": {"sample_time_ms": 0.085, "sample_throughput": 65063315.036, "learn_time_ms": 96.166, "learn_throughput": 57275.682, "update_time_ms": 7.246}, "info": {"learner": {"learned": {"policy_loss": 1.314216136932373, "vf_loss": 16.172880172729492, "total_loss": 17.487096786499023, "vf_explained_var": -0.00019073486328125, "model": {}}}, "num_steps_sampled": 27540, "num_agent_steps_sampled": 27540, "num_steps_trained": 27540, "num_agent_steps_trained": 27540}, "done": false, "episodes_total": 540, "training_iteration": 5, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-25", "timestamp": 1626864445, "time_this_iter_s": 0.3594818115234375, "time_total_s": 2.3039708137512207, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 2.3039708137512207, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -4.0, 1.0, 11.0, 10.0, 10.0, -10.0, 5.0, 0.0, 11.0, 13.0, -9.0, 11.0, 1.0, -3.0, 6.0, 8.0, -8.0, 4.0, 11.0, 12.0, 11.0, 6.0, -14.0, 13.0, 8.0, 8.0, -14.0, -2.0, 14.0, -7.0, 10.0, 12.0, -11.0, 11.0, 3.0, 12.0, 6.0, -12.0, 9.0, 7.0, 2.0, -6.0, 12.0, 5.0, 12.0, 1.0, -3.0, 8.0, -3.0, 4.0, 6.0, 8.0, 10.0, 10.0, -13.0, 12.0, 2.0, 11.0, -10.0, 13.0, 13.0, -19.0, 8.0, 9.0, 5.0, 10.0, -9.0, -11.0, 7.0, 12.0, 7.0, -8.0, 7.0, 8.0, 8.0, 11.0, 14.0, -2.0, -8.0, 12.0, -16.0, 9.0, 10.0, 13.0, 9.0, -3.0, -4.0, 0.0, 7.0, 12.0, -4.0, 11.0, 14.0, 6.0, -16.0, 9.0, 5.0, 10.0, -9.0, 9.0, 9.0, 9.0, -12.0, 8.0, 8.0, 10.0, -11.0, 12.0, 14.0, -11.0, 0.0, 9.0, -10.0, 9.0, 7.0, 3.0, 8.0, -4.0, 8.0, 6.0, 8.0, 12.0, -11.0, 9.0, 14.0, -15.0, 7.0, 13.0, -9.0, 13.0, -2.0, 10.0, 2.0, 9.0, -6.0, 9.0, -18.0, 13.0, 11.0, 8.0, 14.0, 8.0, -15.0, 14.0, -10.0, 12.0, -1.0, 14.0, 10.0, -6.0, -3.0, 7.0, 7.0, 13.0, -12.0, 11.0, 14.0, 7.0, -17.0, 14.0, 2.0, 12.0, -13.0, 5.0, 11.0, -6.0, 5.0, -11.0, 4.0, 11.0, 11.0, 11.0, 10.0, -5.0, -1.0, 8.0, 5.0, -6.0, 8.0, 11.0, 9.0, 0.0, -5.0, 0.0, 6.0, 12.0, -3.0, 11.0, -3.0, 1.0, 6.0, 8.0, 11.0, -12.0, 8.0, 7.0, 10.0, -6.0, 4.0, 8.0, 6.0, 12.0, -11.0, 12.0, 12.0, 2.0, -11.0, 5.0, -8.0, 10.0, 8.0, 9.0, 12.0, 7.0, -13.0, 2.0, 6.0, 13.0, -6.0, 8.0, 14.0, -14.0, 7.0, 12.0, -10.0, 3.0, 10.0, 12.0, 3.0, -2.0, 2.0, 9.0, 11.0, 12.0, -17.0, 4.0, 14.0, -8.0, 5.0, 12.0, -8.0, 12.0, -1.0, 12.0, 11.0, 6.0, -14.0, -15.0, 13.0, 8.0, 9.0, -8.0, 13.0, 3.0, 7.0, 12.0, -10.0, 11.0, 2.0, 6.0, 10.0, -6.0, 5.0, 10.0, 3.0, 13.0, -11.0, 9.0, 14.0, 6.0, -14.0, 13.0, -2.0, 11.0, -7.0, 11.0, 10.0, 11.0, -17.0, 3.0, 9.0, 11.0, -8.0, 10.0, 10.0, -9.0, 4.0, 13.0, -9.0, 13.0, -2.0, 7.0, 8.0, 11.0, -11.0, 6.0, 2.0, 13.0, -6.0, 14.0, 14.0, -5.0, -8.0, 13.0, -10.0, 9.0, 3.0, 12.0, 9.0, -13.0, 7.0, 2.0, 8.0, 11.0, -6.0, 4.0, 13.0, -2.0, 0.0, 13.0, 7.0, -13.0, 8.0, 11.0, 3.0, 11.0, -10.0, 9.0, 3.0, 13.0, -10.0, 13.0, 12.0, 11.0, -21.0, 14.0, -10.0, 13.0, -2.0, -7.0, 13.0, 9.0, 0.0, 8.0, 6.0, 12.0, -11.0, 12.0, 14.0, 8.0, -19.0, 12.0, -11.0, 13.0, 1.0, 2.0, 8.0, -2.0, 7.0, 5.0, -11.0, 12.0, 9.0, 11.0, 14.0, -8.0, -2.0, 12.0, 7.0, 12.0, -16.0, 7.0, 11.0, 7.0, -10.0, 8.0, 6.0, 4.0, -3.0, 7.0, 14.0, 10.0, -16.0, 13.0, -12.0, 5.0, 9.0, 12.0, 11.0, -11.0, 3.0, -14.0, 9.0, 13.0, 7.0, 11.0, 14.0, -11.0, 1.0, 13.0, -17.0, 9.0, 10.0, 2.0, 9.0, -4.0, 8.0, -9.0, 6.0, 12.0, 6.0, 10.0, 14.0, 11.0, -20.0, 9.0, -7.0, 11.0, 2.0, 13.0, 10.0, -10.0, 2.0, 13.0, 7.0, -15.0, 10.0, 12.0, 8.0, -9.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18327804559662952, "mean_inference_ms": 1.0885492816443527, "mean_action_processing_ms": 0.07324831465925129, "mean_env_wait_ms": 0.1739711213634489, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 33048, "agent_timesteps_total": 33048, "timers": {"sample_time_ms": 0.085, "sample_throughput": 64715869.183, "learn_time_ms": 82.672, "learn_throughput": 66624.382, "update_time_ms": 7.565}, "info": {"learner": {"learned": {"policy_loss": 1.4750431776046753, "vf_loss": 16.056167602539062, "total_loss": 17.53120994567871, "vf_explained_var": -0.0002466440200805664, "model": {}}}, "num_steps_sampled": 33048, "num_agent_steps_sampled": 33048, "num_steps_trained": 33048, "num_agent_steps_trained": 33048}, "done": false, "episodes_total": 648, "training_iteration": 6, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-26", "timestamp": 1626864446, "time_this_iter_s": 0.35996103286743164, "time_total_s": 2.6639318466186523, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 2.6639318466186523, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 78.2, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -16.0, 6.0, 12.0, 9.0, -14.0, 10.0, 10.0, -11.0, 6.0, 10.0, 10.0, -1.0, 4.0, 5.0, 7.0, -4.0, 0.0, 11.0, 8.0, 14.0, -8.0, 2.0, 7.0, 12.0, 14.0, 9.0, -20.0, 0.0, 4.0, 0.0, 11.0, 6.0, -12.0, 11.0, 10.0, 9.0, -14.0, 10.0, 10.0, 12.0, 7.0, -7.0, 3.0, -6.0, 3.0, 7.0, 11.0, 10.0, 13.0, 5.0, -13.0, 14.0, -11.0, 12.0, 0.0, -10.0, 8.0, 7.0, 10.0, 9.0, -1.0, 6.0, 1.0, 11.0, 6.0, -11.0, 9.0, 13.0, -8.0, 4.0, 6.0, 8.0, 11.0, 1.0, -5.0, 13.0, -11.0, 6.0, 7.0, 12.0, -15.0, 12.0, 6.0, 13.0, -19.0, 12.0, 9.0, 9.0, 9.0, -9.0, 6.0, 12.0, -13.0, 11.0, 5.0, -6.0, 5.0, 9.0, 7.0, 12.0, -15.0, 11.0, 7.0, -2.0, 8.0, 11.0, -2.0, -2.0, 3.0, 3.0, 11.0, 6.0, -9.0, 10.0, 8.0, 12.0, -6.0, -1.0, 10.0, 12.0, 8.0, -3.0, -2.0, -1.0, -1.0, 10.0, 7.0, 11.0, -17.0, 8.0, 13.0, 14.0, -12.0, 4.0, 9.0, 13.0, -2.0, 10.0, -6.0, 8.0, -11.0, 10.0, 8.0, 7.0, -1.0, 10.0, -1.0, 11.0, 10.0, -15.0, 9.0, 11.0, 12.0, -14.0, 6.0, 13.0, -18.0, 9.0, 11.0, 12.0, -15.0, 10.0, 8.0, 12.0, -18.0, 11.0, 10.0, 6.0, 6.0, 10.0, -7.0, 13.0, -16.0, 9.0, 9.0, 11.0, -14.0, 6.0, 12.0, 14.0, -17.0, 9.0, 9.0, 7.0, -10.0, 9.0, 9.0, -2.0, 7.0, 1.0, 9.0, 9.0, -14.0, 8.0, 12.0, 12.0, -10.0, 7.0, 6.0, 11.0, 8.0, -1.0, -3.0, -9.0, 6.0, 9.0, 9.0, 5.0, -12.0, 12.0, 10.0, 14.0, -17.0, 6.0, 12.0, 7.0, 14.0, -16.0, 10.0, -4.0, 7.0, 5.0, 7.0, 11.0, -16.0, 12.0, 8.0, 14.0, -14.0, 4.0, 11.0, 12.0, -6.0, -3.0, 12.0, 3.0, -5.0, 10.0, 7.0, 10.0, -6.0, 11.0, 0.0, 12.0, 12.0, -12.0, 4.0, 13.0, 11.0, 2.0, -11.0, -1.0, -3.0, 9.0, 10.0, 10.0, -10.0, 11.0, 4.0, 8.0, -13.0, 8.0, 12.0, 319.0, 13.0, 10.0, 12.0, 13.0, -14.0, 8.0, 8.0, 12.0, -12.0, 4.0, 11.0, 13.0, -18.0, 11.0, 9.0, 3.0, 8.0, 9.0, -5.0, 12.0, -10.0, 5.0, 8.0, 7.0, -8.0, 3.0, 13.0, 1.0, -4.0, 10.0, 8.0, -6.0, 13.0, 10.0, -2.0, -11.0, 9.0, 7.0, 10.0, 9.0, 8.0, -3.0, 1.0, 12.0, -13.0, 5.0, 11.0, 8.0, 6.0, -3.0, 4.0, -1.0, 7.0, 11.0, -2.0, 5.0, -7.0, 11.0, 6.0, 6.0, -13.0, 11.0, 11.0, 5.0, 7.0, 4.0, -1.0, -1.0, 7.0, 5.0, 4.0, 8.0, 2.0, -4.0, 9.0, 13.0, 1.0, -11.0, 12.0, 8.0, 9.0, 3.0, -5.0, 7.0, -12.0, 11.0, 9.0, 4.0, 10.0, 7.0, -6.0, 14.0, -17.0, 9.0, 9.0, -2.0, 14.0, 11.0, -8.0, 7.0, -9.0, 7.0, 10.0, 10.0, -12.0, 8.0, 9.0, 14.0, 2.0, -11.0, 10.0, 6.0, 3.0, 10.0, -4.0, -1.0, -1.0, 6.0, 11.0, 10.0, 4.0, -4.0, 5.0, 14.0, -17.0, 9.0, 9.0, 7.0, -8.0, 4.0, 12.0, 9.0, -9.0, 9.0, 6.0, 13.0, -12.0, 9.0, 5.0, -4.0, 6.0, 7.0, 6.0, 12.0, 5.0, 1.0, -3.0, -4.0, 4.0, 5.0, 10.0, 2.0, -3.0, 11.0, 5.0, 13.0, 319.0, 10.0, 13.0, 9.0, 8.0, 2.0, -4.0, 13.0, -6.0, -3.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18296080973082654, "mean_inference_ms": 1.0844736420817507, "mean_action_processing_ms": 0.0729098140929222, "mean_env_wait_ms": 0.17373683530898804, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 38556, "agent_timesteps_total": 38556, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67674992.839, "learn_time_ms": 72.731, "learn_throughput": 75731.1, "update_time_ms": 7.199}, "info": {"learner": {"learned": {"policy_loss": 288342507520.0, "vf_loss": 349.9911193847656, "total_loss": 288342507520.0, "vf_explained_var": -7.987022399902344e-06, "model": {}}}, "num_steps_sampled": 38556, "num_agent_steps_sampled": 38556, "num_steps_trained": 38556, "num_agent_steps_trained": 38556}, "done": false, "episodes_total": 756, "training_iteration": 7, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-26", "timestamp": 1626864446, "time_this_iter_s": 0.3571741580963135, "time_total_s": 3.021106004714966, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826dea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 3.021106004714966, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [0.0, 4.0, 12.0, -1.0, -14.0, 11.0, 8.0, 10.0, 10.0, 14.0, 9.0, -18.0, 12.0, 8.0, 4.0, -9.0, -18.0, 9.0, 12.0, 12.0, -14.0, 14.0, 9.0, 6.0, 3.0, 9.0, -1.0, 4.0, -4.0, 9.0, -2.0, 12.0, -2.0, 11.0, -6.0, 12.0, 11.0, -17.0, 11.0, 10.0, 14.0, -8.0, 9.0, 0.0, 9.0, 14.0, 4.0, -12.0, -5.0, 9.0, 13.0, -2.0, 0.0, 13.0, -10.0, 12.0, 8.0, 1.0, 13.0, -7.0, -5.0, 5.0, 11.0, 4.0, -12.0, 12.0, 5.0, 10.0, 11.0, 1.0, -9.0, 12.0, 11.0, -1.0, -7.0, 12.0, 0.0, -2.0, 11.0, 6.0, -2.0, 13.0, -8.0, 12.0, 10.0, -18.0, 11.0, 12.0, 8.0, 2.0, -4.0, 9.0, -5.0, 6.0, 7.0, 7.0, 1.0, 6.0, -5.0, 13.0, -14.0, 10.0, 12.0, 7.0, 12.0, -7.0, 13.0, -3.0, 8.0, 12.0, 1.0, -6.0, -3.0, 7.0, -1.0, 12.0, 10.0, -12.0, 5.0, 12.0, 14.0, -4.0, -8.0, 13.0, -2.0, 7.0, -2.0, 12.0, -17.0, 9.0, 12.0, 11.0, 12.0, -5.0, 11.0, -3.0, 8.0, 1.0, -3.0, 9.0, 7.0, 14.0, -15.0, 9.0, 0.0, 4.0, 12.0, -1.0, 10.0, 7.0, 2.0, -4.0, 5.0, -8.0, 9.0, 9.0, -3.0, 12.0, 0.0, 6.0, -5.0, 13.0, 11.0, -4.0, 7.0, -15.0, 12.0, 11.0, 14.0, -2.0, -10.0, 13.0, -7.0, 4.0, 6.0, 12.0, 0.0, 7.0, 12.0, -4.0, -9.0, 8.0, 7.0, 9.0, 7.0, -2.0, 9.0, 1.0, -7.0, 9.0, 2.0, 11.0, -16.0, 8.0, 11.0, 12.0, 12.0, 3.0, 2.0, -2.0, 12.0, -2.0, 13.0, -8.0, 9.0, 12.0, 1.0, -7.0, -3.0, 9.0, -2.0, 11.0, -10.0, 10.0, 4.0, 11.0, 13.0, -2.0, 13.0, -9.0, 11.0, -3.0, 4.0, 3.0, -15.0, 12.0, 6.0, 12.0, -11.0, 13.0, 11.0, 2.0, 13.0, -3.0, -4.0, 9.0, 13.0, -6.0, 3.0, 5.0, 5.0, 0.0, 11.0, -1.0, 8.0, 7.0, -7.0, 7.0, 9.0, 11.0, 9.0, -14.0, -11.0, 9.0, 4.0, 13.0, 1.0, 13.0, -9.0, 10.0, 5.0, 1.0, 12.0, -3.0, 13.0, 13.0, -1.0, -10.0, -8.0, 14.0, -2.0, 11.0, -2.0, 7.0, -2.0, 12.0, -3.0, 11.0, 8.0, -1.0, 12.0, 11.0, 13.0, 319.0, -1.0, 4.0, 0.0, 12.0, 0.0, 7.0, 9.0, -1.0, -6.0, 11.0, 11.0, -1.0, 14.0, 12.0, -10.0, -1.0, 8.0, 13.0, 2.0, -8.0, -8.0, 12.0, -1.0, 12.0, -1.0, 12.0, -7.0, 11.0, 13.0, -2.0, -9.0, 13.0, 11.0, 13.0, -14.0, 5.0, -5.0, 12.0, -2.0, 10.0, -15.0, 12.0, 11.0, 7.0, 14.0, -1.0, -11.0, 13.0, -12.0, 8.0, 10.0, 9.0, -3.0, 8.0, -1.0, 11.0, 7.0, 5.0, -8.0, 11.0, 6.0, 5.0, 6.0, -2.0, -4.0, 4.0, 6.0, 9.0, -17.0, 9.0, 12.0, 11.0, 8.0, 8.0, -13.0, 12.0, 10.0, 3.0, 3.0, -1.0, -1.0, 9.0, 0.0, 7.0, -16.0, 12.0, 9.0, 10.0, 5.0, 6.0, -9.0, 13.0, 5.0, 2.0, -1.0, 9.0, -5.0, 2.0, 8.0, 10.0, 4.0, 14.0, -2.0, -1.0, -2.0, 14.0, -10.0, 13.0, 13.0, 6.0, 13.0, -17.0, -2.0, -1.0, 7.0, 11.0, -17.0, 9.0, 11.0, 12.0, 1.0, -4.0, 11.0, 7.0, 13.0, 8.0, -5.0, -1.0, 6.0, -1.0, 4.0, 6.0, 3.0, 13.0, -8.0, 7.0, -15.0, 13.0, 5.0, 12.0, 12.0, -2.0, 13.0, -8.0, -6.0, 8.0, 6.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18353601838836667, "mean_inference_ms": 1.0822909171030088, "mean_action_processing_ms": 0.0726716494771672, "mean_env_wait_ms": 0.17397546094423882, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 44064, "agent_timesteps_total": 44064, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68495109.552, "learn_time_ms": 65.537, "learn_throughput": 84044.617, "update_time_ms": 7.218}, "info": {"learner": {"learned": {"policy_loss": 124180447232.0, "vf_loss": 133.04319763183594, "total_loss": 124180447232.0, "vf_explained_var": -3.802776336669922e-05, "model": {}}}, "num_steps_sampled": 44064, "num_agent_steps_sampled": 44064, "num_steps_trained": 44064, "num_agent_steps_trained": 44064}, "done": false, "episodes_total": 864, "training_iteration": 8, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-26", "timestamp": 1626864446, "time_this_iter_s": 0.36437082290649414, "time_total_s": 3.38547682762146, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d6a8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 3.38547682762146, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 72.0, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 334.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -17.0, 10.0, 11.0, -13.0, 12.0, 4.0, 12.0, 5.0, 12.0, 1.0, -3.0, 11.0, 11.0, -15.0, 8.0, 5.0, -13.0, 10.0, 13.0, 7.0, 11.0, -3.0, 0.0, 10.0, 5.0, 11.0, -11.0, 12.0, 11.0, -3.0, -5.0, 6.0, -12.0, 9.0, 12.0, 9.0, 6.0, -8.0, 8.0, -2.0, 3.0, 12.0, 2.0, -6.0, 11.0, 7.0, 3.0, 6.0, -8.0, 7.0, 10.0, 1.0, -3.0, 6.0, 11.0, 8.0, 7.0, 12.0, -12.0, -4.0, 13.0, 5.0, 1.0, 13.0, -17.0, 11.0, 8.0, 10.0, 5.0, -9.0, 9.0, 8.0, 6.0, 11.0, -10.0, 12.0, 9.0, 11.0, -17.0, 9.0, 0.0, -4.0, 10.0, -14.0, 11.0, 7.0, 11.0, 8.0, 11.0, 11.0, -15.0, 13.0, 13.0, 0.0, -11.0, -2.0, 8.0, -1.0, 10.0, 7.0, -11.0, 6.0, 13.0, -3.0, 12.0, 10.0, -4.0, 13.0, 5.0, -1.0, -2.0, 9.0, -14.0, 9.0, 11.0, 6.0, 8.0, -8.0, 9.0, -14.0, 12.0, 10.0, 7.0, 9.0, 10.0, 7.0, -11.0, 13.0, -18.0, 9.0, 11.0, 12.0, -9.0, 13.0, -1.0, -3.0, 4.0, 3.0, 11.0, 13.0, 11.0, -17.0, 8.0, 2.0, 6.0, 8.0, -1.0, 7.0, 9.0, -7.0, 6.0, -9.0, 7.0, 9.0, 8.0, 13.0, 10.0, -18.0, 10.0, 8.0, -15.0, 13.0, 9.0, -14.0, 12.0, 11.0, 6.0, -4.0, 8.0, 10.0, 1.0, 8.0, 7.0, 8.0, -8.0, -9.0, 2.0, 11.0, 11.0, 2.0, 6.0, -1.0, 8.0, 10.0, 4.0, 10.0, -9.0, 7.0, 11.0, 9.0, -12.0, 10.0, 3.0, 10.0, -8.0, 7.0, 10.0, -10.0, 8.0, 12.0, 5.0, 12.0, -14.0, 13.0, 11.0, 11.0, -20.0, 11.0, -15.0, 9.0, 10.0, 7.0, 9.0, -8.0, 7.0, 3.0, 13.0, 12.0, -13.0, 13.0, 11.0, 0.0, -9.0, 10.0, -4.0, 13.0, -4.0, 4.0, 10.0, -9.0, 10.0, 8.0, 8.0, 13.0, -14.0, 12.0, 12.0, 5.0, -14.0, 12.0, -6.0, 12.0, -3.0, 3.0, -4.0, 13.0, 3.0, 6.0, 11.0, -11.0, 9.0, 11.0, 0.0, 1.0, 3.0, 12.0, -1.0, 10.0, -6.0, 7.0, 5.0, 11.0, -8.0, 0.0, 13.0, 12.0, -10.0, 11.0, 10.0, 1.0, -7.0, 4.0, 2.0, 11.0, -2.0, 2.0, -3.0, 11.0, 5.0, 7.0, 8.0, 12.0, -12.0, 12.0, -8.0, 3.0, 8.0, -12.0, 7.0, 11.0, 9.0, 334.0, 9.0, 12.0, 12.0, 8.0, 13.0, 6.0, -12.0, 11.0, 11.0, -11.0, 4.0, 2.0, -10.0, 10.0, 13.0, 1.0, 11.0, 7.0, -4.0, -2.0, 8.0, 7.0, 2.0, -1.0, 11.0, 6.0, -1.0, 11.0, 3.0, -9.0, 10.0, -1.0, -4.0, 7.0, 13.0, -6.0, 6.0, 11.0, 4.0, 12.0, -9.0, 4.0, 8.0, 13.0, -2.0, -3.0, 7.0, -14.0, 11.0, 11.0, 7.0, 11.0, 7.0, 7.0, -10.0, 10.0, 12.0, -13.0, 6.0, 4.0, 7.0, 8.0, -4.0, 0.0, 4.0, -1.0, 12.0, -12.0, 7.0, 12.0, 8.0, 13.0, -9.0, 5.0, 6.0, 7.0, 12.0, 9.0, -13.0, 0.0, 4.0, -1.0, 12.0, 2.0, 11.0, 11.0, -9.0, -5.0, 13.0, 4.0, 3.0, 6.0, 4.0, 10.0, -5.0, -12.0, 12.0, 7.0, 8.0, -7.0, 13.0, -1.0, 10.0, 13.0, 12.0, -19.0, 9.0, 12.0, -6.0, -2.0, 11.0, -15.0, 12.0, 7.0, 11.0, -6.0, 12.0, 5.0, 4.0, 9.0, -8.0, 5.0, 9.0, 1.0, 7.0, -3.0, 10.0, 0.0, 11.0, -8.0, 12.0, 12.0, 3.0, 13.0, -13.0, -5.0, 12.0, 6.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18397291167281957, "mean_inference_ms": 1.0808544891126075, "mean_action_processing_ms": 0.07260063246913093, "mean_env_wait_ms": 0.17462755134527294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 49572, "agent_timesteps_total": 49572, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68194198.821, "learn_time_ms": 59.88, "learn_throughput": 91983.452, "update_time_ms": 7.338}, "info": {"learner": {"learned": {"policy_loss": 104021164032.0, "vf_loss": 137.23912048339844, "total_loss": 104021164032.0, "vf_explained_var": -7.37905502319336e-05, "model": {}}}, "num_steps_sampled": 49572, "num_agent_steps_sampled": 49572, "num_steps_trained": 49572, "num_agent_steps_trained": 49572}, "done": false, "episodes_total": 972, "training_iteration": 9, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-27", "timestamp": 1626864447, "time_this_iter_s": 0.36363840103149414, "time_total_s": 3.749115228652954, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 3.749115228652954, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -15.0, 12.0, 4.0, -1.0, 13.0, 9.0, -6.0, 12.0, 8.0, -16.0, 11.0, 2.0, 11.0, -10.0, 12.0, 12.0, -8.0, 2.0, 9.0, -5.0, 13.0, 6.0, 1.0, 9.0, -6.0, -1.0, 13.0, 2.0, 4.0, -3.0, 12.0, -1.0, 5.0, 3.0, 8.0, -11.0, 13.0, 8.0, 5.0, 8.0, -9.0, 5.0, 11.0, -1.0, 7.0, -3.0, 12.0, -1.0, 4.0, 10.0, 2.0, -6.0, 14.0, 0.0, 7.0, 12.0, 10.0, 12.0, -19.0, 0.0, 7.0, -5.0, 13.0, 12.0, -7.0, 7.0, 3.0, -6.0, 13.0, 2.0, 6.0, 12.0, -13.0, 3.0, 13.0, 0.0, 9.0, -6.0, 12.0, 14.0, -9.0, 4.0, 6.0, 8.0, 13.0, -8.0, 2.0, 11.0, -7.0, 12.0, -1.0, 2.0, 5.0, 11.0, -3.0, -4.0, 10.0, 3.0, 6.0, -8.0, 14.0, 0.0, 9.0, 10.0, 8.0, 11.0, -14.0, 6.0, 4.0, -4.0, 9.0, 14.0, 3.0, 2.0, -4.0, -13.0, 13.0, 6.0, 9.0, 13.0, 9.0, 8.0, -15.0, 9.0, 6.0, -4.0, 4.0, 9.0, 4.0, 12.0, -10.0, -10.0, 13.0, 7.0, 5.0, 13.0, 9.0, -17.0, 10.0, 1.0, 6.0, -4.0, 12.0, 13.0, -11.0, 0.0, 13.0, -1.0, 10.0, 8.0, -2.0, 13.0, 5.0, 11.0, -14.0, 3.0, 4.0, 11.0, -3.0, 13.0, -1.0, -9.0, 12.0, -5.0, 13.0, 1.0, 6.0, 12.0, 8.0, -17.0, 12.0, 4.0, 9.0, 5.0, -3.0, 14.0, 6.0, 5.0, -10.0, 13.0, 0.0, -4.0, 6.0, 11.0, -15.0, 6.0, 13.0, -8.0, 7.0, 11.0, 5.0, 14.0, -8.0, 2.0, 7.0, -1.0, 7.0, -1.0, 10.0, 12.0, -12.0, 3.0, 12.0, 1.0, -4.0, 7.0, 11.0, 14.0, -15.0, 10.0, 6.0, -7.0, 13.0, 2.0, 7.0, 12.0, 10.0, -18.0, 11.0, 14.0, 9.0, -7.0, -1.0, 13.0, 3.0, 7.0, -8.0, -9.0, 13.0, 7.0, 4.0, -4.0, 3.0, 3.0, 13.0, 0.0, 6.0, -4.0, 13.0, 11.0, 9.0, -13.0, 8.0, -1.0, 7.0, 1.0, 8.0, 12.0, 1.0, -10.0, 12.0, -12.0, 12.0, 11.0, 4.0, 13.0, 4.0, -9.0, 7.0, -1.0, 13.0, 7.0, -4.0, -1.0, -3.0, 12.0, 7.0, 3.0, 2.0, -2.0, 12.0, -1.0, 5.0, 6.0, 5.0, 13.0, -1.0, 8.0, -5.0, 11.0, -14.0, 7.0, 11.0, 0.0, 11.0, -4.0, 8.0, 0.0, 6.0, 3.0, 6.0, -1.0, 10.0, 6.0, 0.0, 6.0, 11.0, -3.0, 1.0, 1.0, 10.0, -3.0, 7.0, 12.0, 9.0, -13.0, 7.0, -1.0, 11.0, -5.0, 10.0, 9.0, 5.0, -12.0, 13.0, 8.0, 10.0, -3.0, 0.0, 13.0, -7.0, 10.0, -1.0, -8.0, 13.0, 4.0, 6.0, 11.0, -14.0, 7.0, 11.0, 0.0, 11.0, -3.0, 7.0, 12.0, 3.0, 7.0, -7.0, -1.0, 13.0, 8.0, -5.0, 12.0, -8.0, 3.0, 8.0, 1.0, 4.0, -3.0, 13.0, -3.0, -2.0, 13.0, 7.0, -4.0, 13.0, 4.0, 2.0, 10.0, -12.0, 6.0, 11.0, 3.0, 10.0, -9.0, 11.0, 8.0, 5.0, -9.0, 11.0, 13.0, -1.0, 7.0, -4.0, 11.0, -12.0, 3.0, 13.0, 5.0, 5.0, -7.0, 12.0, -7.0, 9.0, 0.0, 13.0, -6.0, 13.0, 1.0, 7.0, 11.0, 4.0, -12.0, 12.0, 0.0, -3.0, 5.0, 13.0, 13.0, -9.0, 6.0, 5.0, -6.0, 13.0, 0.0, 8.0, 14.0, 4.0, -15.0, 12.0, 3.0, -9.0, 9.0, 12.0, -2.0, 6.0, 3.0, 8.0, -10.0, 13.0, 7.0, 5.0, 10.0, -14.0, 6.0, 13.0, 1.0, 6.0, -4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416830413794544, "mean_inference_ms": 1.0808598835778456, "mean_action_processing_ms": 0.07258441146354112, "mean_env_wait_ms": 0.17461362344454992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 55080, "agent_timesteps_total": 55080, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67764747.203, "learn_time_ms": 55.367, "learn_throughput": 99482.167, "update_time_ms": 7.451}, "info": {"learner": {"learned": {"policy_loss": 1.4710572957992554, "vf_loss": 16.019092559814453, "total_loss": 17.490150451660156, "vf_explained_var": -0.0005429983139038086, "model": {}}}, "num_steps_sampled": 55080, "num_agent_steps_sampled": 55080, "num_steps_trained": 55080, "num_agent_steps_trained": 55080}, "done": false, "episodes_total": 1080, "training_iteration": 10, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-27", "timestamp": 1626864447, "time_this_iter_s": 0.3669557571411133, "time_total_s": 4.116070985794067, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 4.116070985794067, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 74.1, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-11.0, 14.0, 7.0, 5.0, -13.0, 3.0, 12.0, 13.0, -9.0, 0.0, 12.0, 12.0, 10.0, 11.0, 8.0, -14.0, 11.0, 7.0, -8.0, 5.0, -6.0, 5.0, 7.0, 9.0, -5.0, 0.0, 12.0, 8.0, 8.0, 11.0, 3.0, -7.0, 12.0, 13.0, 5.0, -15.0, -3.0, -6.0, 12.0, 12.0, 6.0, -15.0, 13.0, 11.0, 13.0, 10.0, 11.0, -19.0, 13.0, 6.0, 5.0, -9.0, -2.0, 1.0, 7.0, 9.0, -5.0, 1.0, 7.0, 12.0, 0.0, 5.0, 9.0, 1.0, 7.0, 6.0, 6.0, -4.0, -7.0, 8.0, 1.0, 13.0, -6.0, -3.0, 12.0, 12.0, -7.0, 9.0, 6.0, 7.0, 11.0, 8.0, 10.0, -14.0, 7.0, -17.0, 12.0, 13.0, 6.0, 5.0, 12.0, -8.0, -6.0, 7.0, 11.0, 3.0, 12.0, 6.0, 3.0, -6.0, 11.0, -6.0, -3.0, 13.0, -7.0, 3.0, 8.0, 11.0, -4.0, 13.0, 8.0, -2.0, 7.0, 9.0, -10.0, 9.0, 6.0, -14.0, 10.0, 13.0, 6.0, 4.0, 7.0, -2.0, 11.0, 7.0, 9.0, -12.0, 12.0, 1.0, 12.0, -10.0, -12.0, 8.0, 12.0, 7.0, 3.0, -13.0, 12.0, 13.0, 5.0, 7.0, 9.0, -6.0, 8.0, 11.0, 9.0, -13.0, -7.0, 4.0, 5.0, 13.0, -8.0, 5.0, 8.0, 10.0, 11.0, 9.0, 9.0, -14.0, 11.0, -9.0, 3.0, 10.0, -8.0, 3.0, 7.0, 13.0, 9.0, -18.0, 12.0, 12.0, -3.0, 7.0, 8.0, 3.0, 12.0, -2.0, 2.0, 3.0, 11.0, -6.0, 3.0, 7.0, 9.0, 0.0, 12.0, -6.0, -7.0, 9.0, 3.0, 10.0, 12.0, 13.0, -14.0, 4.0, 12.0, -5.0, 0.0, 8.0, 1.0, -8.0, 11.0, 11.0, 10.0, 3.0, 10.0, -8.0, 12.0, 8.0, 3.0, -8.0, -11.0, 3.0, 12.0, 11.0, -7.0, 3.0, 12.0, 7.0, 10.0, 8.0, -6.0, 3.0, 6.0, 12.0, -8.0, 5.0, 9.0, 10.0, -9.0, 5.0, -6.0, -5.0, 13.0, 13.0, -1.0, 2.0, 12.0, 2.0, 13.0, -5.0, 5.0, 2.0, -9.0, 5.0, 8.0, 11.0, 8.0, -3.0, 12.0, -2.0, 6.0, 6.0, -4.0, 7.0, 6.0, 8.0, -7.0, 8.0, -3.0, -1.0, 6.0, 13.0, 2.0, -12.0, 12.0, 13.0, 10.0, 5.0, 13.0, -13.0, 13.0, 7.0, 5.0, -10.0, 5.0, 11.0, -7.0, 6.0, -4.0, -4.0, 11.0, 12.0, -6.0, 8.0, 7.0, 6.0, 6.0, 14.0, 6.0, -11.0, 5.0, -2.0, 4.0, 8.0, 6.0, 4.0, -2.0, 7.0, -4.0, 8.0, 9.0, 2.0, 7.0, 11.0, 2.0, -5.0, 8.0, 10.0, -8.0, 5.0, 7.0, -4.0, 13.0, -1.0, 7.0, 11.0, 8.0, -11.0, 7.0, 5.0, 7.0, -4.0, -10.0, 5.0, 7.0, 13.0, -9.0, 3.0, 12.0, 9.0, -4.0, 8.0, 12.0, -1.0, 12.0, 13.0, -12.0, 2.0, -15.0, 6.0, 11.0, 13.0, 10.0, 0.0, -6.0, 11.0, 8.0, 12.0, -8.0, 3.0, 12.0, -6.0, -2.0, 11.0, 7.0, -15.0, 10.0, 13.0, -8.0, 0.0, 11.0, 12.0, -8.0, 11.0, 4.0, 8.0, 13.0, 13.0, 4.0, -15.0, 12.0, -11.0, 1.0, 13.0, -6.0, 9.0, 13.0, -1.0, 8.0, 13.0, 9.0, -15.0, 1.0, 8.0, 11.0, -5.0, 7.0, -9.0, 6.0, 11.0, -10.0, 0.0, 13.0, 12.0, 13.0, 12.0, 11.0, 318.0, 12.0, 9.0, 2.0, -8.0, 7.0, -15.0, 12.0, 11.0, 1.0, 4.0, 11.0, -1.0, -1.0, 7.0, 11.0, -2.0, 7.0, 10.0, -9.0, 7.0, -13.0, 4.0, 12.0, 12.0, 7.0, 1.0, 10.0, -3.0, -2.0, 10.0, 8.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416872947294505, "mean_inference_ms": 1.0798782992754343, "mean_action_processing_ms": 0.07242166414853222, "mean_env_wait_ms": 0.17458879838512545, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 60588, "agent_timesteps_total": 60588, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70813662.563, "learn_time_ms": 14.205, "learn_throughput": 387757.224, "update_time_ms": 6.753}, "info": {"learner": {"learned": {"policy_loss": 1.2260512113571167, "vf_loss": 20.49688720703125, "total_loss": 21.722938537597656, "vf_explained_var": -0.0008221864700317383, "model": {}}}, "num_steps_sampled": 60588, "num_agent_steps_sampled": 60588, "num_steps_trained": 60588, "num_agent_steps_trained": 60588}, "done": false, "episodes_total": 1188, "training_iteration": 11, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-28", "timestamp": 1626864448, "time_this_iter_s": 0.35074901580810547, "time_total_s": 4.466820001602173, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 4.466820001602173, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 82.8, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 6.0, 4.0, 10.0, -1.0, 7.0, 12.0, -3.0, 13.0, 13.0, 2.0, -13.0, 14.0, 9.0, 0.0, -8.0, -3.0, 8.0, 3.0, 7.0, 13.0, -4.0, 8.0, -2.0, 12.0, 13.0, 2.0, -12.0, 11.0, -1.0, 9.0, -4.0, 4.0, 3.0, 12.0, -4.0, 12.0, 8.0, -1.0, -4.0, 12.0, 14.0, -4.0, -7.0, 5.0, 11.0, 7.0, -8.0, -4.0, 3.0, 10.0, 6.0, -2.0, 11.0, -5.0, 11.0, 14.0, 13.0, 8.0, -20.0, 3.0, 13.0, 12.0, -13.0, 4.0, 9.0, -6.0, 8.0, -1.0, 8.0, 2.0, 6.0, 12.0, 13.0, -10.0, 0.0, 14.0, 11.0, -15.0, 5.0, 8.0, 8.0, 2.0, -3.0, 7.0, 2.0, -2.0, 8.0, 13.0, 13.0, 6.0, -17.0, 14.0, -5.0, 2.0, 4.0, 7.0, -2.0, -3.0, 13.0, 6.0, 6.0, -8.0, 11.0, 14.0, 12.0, -4.0, -7.0, 14.0, 7.0, 6.0, -12.0, 6.0, 13.0, 4.0, -8.0, -10.0, 9.0, 11.0, 5.0, 12.0, 13.0, -18.0, 8.0, -6.0, 11.0, 7.0, 3.0, 13.0, 1.0, -10.0, 11.0, 14.0, 7.0, -5.0, -1.0, 9.0, 14.0, -8.0, 0.0, 10.0, 11.0, 7.0, -13.0, 13.0, 12.0, -5.0, -5.0, -3.0, 4.0, 4.0, 10.0, 12.0, 13.0, -13.0, 3.0, 9.0, -5.0, 3.0, 8.0, 6.0, 4.0, -5.0, 10.0, 9.0, -10.0, 12.0, 4.0, 10.0, 13.0, -15.0, 7.0, 8.0, 10.0, -9.0, 6.0, -4.0, 0.0, 6.0, 13.0, -9.0, 4.0, 11.0, 9.0, 12.0, 12.0, -10.0, 1.0, 13.0, -5.0, 8.0, -1.0, -1.0, 13.0, 10.0, -7.0, -14.0, 7.0, 12.0, 10.0, -6.0, 13.0, 10.0, -2.0, 8.0, -9.0, 13.0, 3.0, 8.0, 6.0, -4.0, 5.0, 0.0, 11.0, 7.0, -3.0, 10.0, 13.0, -3.0, -5.0, 12.0, -2.0, 7.0, -2.0, 6.0, 5.0, -3.0, 7.0, -5.0, 8.0, 11.0, 1.0, 14.0, 13.0, 9.0, -21.0, 13.0, 12.0, 6.0, -16.0, -4.0, 2.0, 10.0, 7.0, 9.0, 10.0, 7.0, -11.0, 11.0, 11.0, -13.0, 6.0, 4.0, 10.0, 9.0, -8.0, 12.0, 12.0, -6.0, -3.0, -5.0, 6.0, 1.0, 13.0, -1.0, 13.0, -6.0, 9.0, -7.0, 12.0, 3.0, 7.0, 11.0, -4.0, -4.0, 12.0, 7.0, 3.0, -5.0, 10.0, 8.0, 13.0, -5.0, -1.0, 4.0, -8.0, 11.0, 8.0, 8.0, 1.0, 9.0, -3.0, 13.0, -2.0, 1.0, 3.0, 11.0, 12.0, -15.0, 7.0, 14.0, 10.0, -19.0, 10.0, 12.0, 12.0, -6.0, -3.0, 8.0, 8.0, -5.0, 4.0, 12.0, 11.0, -6.0, -2.0, 9.0, 10.0, 5.0, -9.0, 11.0, 13.0, -5.0, -4.0, -3.0, 6.0, 4.0, 8.0, -2.0, 12.0, 7.0, -2.0, 13.0, -4.0, 6.0, 0.0, 9.0, 11.0, -3.0, -2.0, 13.0, -7.0, 3.0, 6.0, 12.0, 8.0, -12.0, 7.0, 2.0, 9.0, -8.0, 12.0, 12.0, 13.0, -7.0, -3.0, 13.0, 8.0, -5.0, -1.0, 13.0, 13.0, -14.0, 3.0, 4.0, 11.0, 11.0, -11.0, 13.0, 13.0, -3.0, -8.0, 8.0, 7.0, -11.0, 11.0, 12.0, 12.0, -13.0, 4.0, 13.0, 11.0, -13.0, 4.0, 9.0, 1.0, -5.0, 10.0, -6.0, 11.0, 8.0, 2.0, 13.0, 13.0, -18.0, 7.0, 14.0, -3.0, -2.0, 6.0, -7.0, 0.0, 11.0, 11.0, -9.0, 8.0, 9.0, 7.0, 12.0, 8.0, -3.0, -2.0, 1.0, 14.0, 11.0, -11.0, 6.0, 1.0, 12.0, -4.0, 9.0, 1.0, 7.0, -2.0, 9.0, 12.0, -5.0, -1.0, 5.0, 12.0, 7.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1840712870068568, "mean_inference_ms": 1.0777447733975651, "mean_action_processing_ms": 0.07230780503008628, "mean_env_wait_ms": 0.1745787711508606, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 66096, "agent_timesteps_total": 66096, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69882070.377, "learn_time_ms": 13.893, "learn_throughput": 396469.98, "update_time_ms": 6.837}, "info": {"learner": {"learned": {"policy_loss": 1.3153705596923828, "vf_loss": 22.596071243286133, "total_loss": 23.911441802978516, "vf_explained_var": -0.0006374120712280273, "model": {}}}, "num_steps_sampled": 66096, "num_agent_steps_sampled": 66096, "num_steps_trained": 66096, "num_agent_steps_trained": 66096}, "done": false, "episodes_total": 1296, "training_iteration": 12, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-28", "timestamp": 1626864448, "time_this_iter_s": 0.35067319869995117, "time_total_s": 4.817493200302124, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a183469d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 4.817493200302124, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.61111111111111, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 6.902777777777778}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 7.0, -6.0, 7.0, 7.0, 4.0, 11.0, -7.0, 10.0, 5.0, -7.0, 7.0, 6.0, 13.0, 7.0, -11.0, 10.0, 9.0, -7.0, 3.0, 7.0, 9.0, 9.0, -10.0, 10.0, 7.0, 13.0, -15.0, 12.0, -3.0, 12.0, -6.0, -4.0, 6.0, 6.0, 7.0, 13.0, 0.0, 12.0, -10.0, -5.0, 2.0, 6.0, 12.0, 11.0, 9.0, 12.0, -17.0, 9.0, 8.0, 6.0, -8.0, 1.0, 9.0, 12.0, -7.0, 11.0, -15.0, 12.0, 7.0, 8.0, 11.0, -17.0, 13.0, 7.0, 14.0, 4.0, -10.0, 9.0, 8.0, -8.0, 6.0, 12.0, 2.0, -7.0, 8.0, -12.0, 10.0, 5.0, 12.0, 11.0, 10.0, -7.0, 1.0, 10.0, 8.0, 12.0, -15.0, 13.0, -14.0, 3.0, 13.0, 12.0, -17.0, 10.0, 10.0, 8.0, 7.0, -5.0, 5.0, 13.0, 3.0, -3.0, 2.0, 10.0, -1.0, -7.0, 13.0, 9.0, 7.0, -13.0, 12.0, 8.0, 12.0, -7.0, 2.0, 10.0, 1.0, -6.0, 10.0, 9.0, 11.0, -8.0, 3.0, 12.0, -1.0, -8.0, 12.0, 11.0, 4.0, -4.0, 4.0, 5.0, 8.0, -7.0, 9.0, 12.0, 3.0, 12.0, -12.0, 8.0, 13.0, -18.0, 12.0, 11.0, 9.0, -6.0, 1.0, 6.0, 2.0, 12.0, -5.0, 12.0, 6.0, 11.0, -14.0, 11.0, 11.0, 319.0, 13.0, 8.0, 10.0, 4.0, -7.0, 6.0, 3.0, 8.0, -2.0, 8.0, 8.0, 6.0, -7.0, 9.0, 13.0, 320.0, 13.0, 12.0, 8.0, -6.0, 1.0, 12.0, -1.0, -3.0, 7.0, 10.0, 11.0, -8.0, 2.0, -10.0, 1.0, 12.0, 12.0, 10.0, 13.0, -11.0, 3.0, 8.0, 2.0, 11.0, -6.0, 13.0, 3.0, -12.0, 11.0, 10.0, 12.0, 322.0, 13.0, -5.0, 7.0, 5.0, 8.0, 11.0, 0.0, 8.0, -4.0, 12.0, -9.0, 2.0, 10.0, 12.0, 12.0, 320.0, 12.0, 6.0, 9.0, 7.0, -7.0, 7.0, 4.0, -6.0, 10.0, -9.0, 7.0, 5.0, 12.0, 12.0, -9.0, 0.0, 12.0, 10.0, 7.0, -6.0, 4.0, 11.0, 4.0, 5.0, -5.0, 11.0, -14.0, 12.0, 6.0, 10.0, 10.0, -17.0, 12.0, 11.0, 7.0, 5.0, -8.0, 9.0, 0.0, 12.0, -6.0, 11.0, 9.0, -9.0, 4.0, 3.0, 8.0, 11.0, -7.0, -1.0, 8.0, 6.0, 2.0, 9.0, -2.0, -3.0, 11.0, 11.0, 6.0, 11.0, -13.0, 9.0, 6.0, -12.0, 12.0, 12.0, 9.0, -16.0, 10.0, 5.0, 4.0, 10.0, -4.0, 12.0, -12.0, 4.0, 11.0, 8.0, -1.0, 12.0, -4.0, -8.0, 9.0, 12.0, 2.0, 8.0, 4.0, -1.0, 4.0, 12.0, 0.0, 5.0, -2.0, 10.0, 9.0, -17.0, 13.0, 7.0, 6.0, 8.0, -6.0, 12.0, 2.0, -5.0, 6.0, 7.0, 6.0, -9.0, 11.0, -13.0, 2.0, 13.0, 13.0, 12.0, 2.0, -4.0, 5.0, 5.0, 1.0, -3.0, 12.0, 5.0, -1.0, 12.0, -1.0, -12.0, 9.0, 5.0, 13.0, -5.0, 8.0, 12.0, 0.0, 12.0, 3.0, 9.0, -9.0, 5.0, 9.0, 11.0, -10.0, -13.0, 12.0, 10.0, 6.0, 12.0, 8.0, -16.0, 11.0, 13.0, 4.0, -9.0, 7.0, 12.0, 7.0, -9.0, 5.0, 12.0, 10.0, -19.0, 12.0, 12.0, 11.0, 4.0, -12.0, 8.0, 4.0, 11.0, -8.0, 13.0, 2.0, 10.0, -10.0, -10.0, 7.0, 10.0, 8.0, 9.0, 7.0, -12.0, 11.0, 12.0, 0.0, 11.0, -8.0, -4.0, 7.0, 6.0, 6.0, 11.0, 8.0, -16.0, 12.0, 12.0, 7.0, -11.0, 7.0, 4.0, 3.0, -3.0, 11.0, 10.0, 8.0, 12.0, -15.0, 0.0, 10.0, -7.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18402832515762516, "mean_inference_ms": 1.0777681962366445, "mean_action_processing_ms": 0.07220723565058715, "mean_env_wait_ms": 0.1745160326208341, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 71604, "agent_timesteps_total": 71604, "timers": {"sample_time_ms": 0.077, "sample_throughput": 71455351.057, "learn_time_ms": 13.786, "learn_throughput": 399526.605, "update_time_ms": 6.606}, "info": {"learner": {"learned": {"policy_loss": 1.4683946371078491, "vf_loss": 15.994376182556152, "total_loss": 17.462770462036133, "vf_explained_var": -0.0007282495498657227, "model": {}}}, "num_steps_sampled": 71604, "num_agent_steps_sampled": 71604, "num_steps_trained": 71604, "num_agent_steps_trained": 71604}, "done": false, "episodes_total": 1404, "training_iteration": 13, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-28", "timestamp": 1626864448, "time_this_iter_s": 0.35334253311157227, "time_total_s": 5.170835733413696, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a2297e620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 5.170835733413696, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 77.9, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 13.0, -2.0, 9.0, -5.0, -2.0, 13.0, 9.0, 13.0, 6.0, 3.0, -7.0, 7.0, -10.0, 10.0, 8.0, 11.0, 6.0, 5.0, -7.0, 8.0, 6.0, -7.0, 8.0, -5.0, 6.0, 2.0, 12.0, 6.0, -9.0, 11.0, 7.0, 11.0, 14.0, -14.0, 4.0, 8.0, -6.0, 9.0, 4.0, -3.0, 2.0, 4.0, 12.0, 6.0, -10.0, 11.0, 8.0, 11.0, 7.0, 7.0, -10.0, 12.0, -3.0, -2.0, 8.0, 9.0, 0.0, 8.0, -2.0, -6.0, 7.0, 8.0, 6.0, 7.0, 6.0, 12.0, -10.0, 9.0, 11.0, -6.0, 1.0, 13.0, 3.0, 11.0, -12.0, 6.0, -6.0, 2.0, 13.0, 13.0, 7.0, -3.0, -2.0, 13.0, -8.0, 0.0, 10.0, -2.0, 8.0, -2.0, 11.0, -5.0, 8.0, 2.0, 10.0, 12.0, -8.0, 6.0, 5.0, 6.0, -3.0, 4.0, 8.0, -6.0, 6.0, 5.0, 10.0, -9.0, 2.0, 9.0, 13.0, -8.0, 13.0, 4.0, 6.0, 12.0, -3.0, -1.0, 7.0, -3.0, 0.0, 6.0, 12.0, -2.0, -1.0, 6.0, 12.0, 10.0, 13.0, 9.0, -17.0, 5.0, -10.0, 7.0, 13.0, 12.0, 3.0, 6.0, -6.0, -10.0, 7.0, 6.0, 12.0, 7.0, 9.0, -9.0, 8.0, -2.0, 10.0, -6.0, 13.0, 12.0, 12.0, 9.0, -18.0, -10.0, 9.0, 4.0, 12.0, 7.0, -7.0, 10.0, 5.0, -4.0, 12.0, -6.0, 13.0, 0.0, 9.0, 10.0, -4.0, -9.0, 3.0, 8.0, 13.0, 13.0, 8.0, -12.0, 6.0, 3.0, 7.0, -7.0, 12.0, 0.0, -2.0, 5.0, 12.0, 3.0, 8.0, -6.0, 10.0, 1.0, 8.0, 12.0, -6.0, 8.0, -4.0, 9.0, 2.0, -3.0, 5.0, 3.0, 10.0, 9.0, 3.0, -10.0, 13.0, 11.0, 9.0, 4.0, -9.0, 9.0, -4.0, 3.0, 7.0, -2.0, 1.0, 4.0, 12.0, 6.0, -13.0, 11.0, 11.0, 12.0, -6.0, 4.0, 5.0, 3.0, -3.0, 8.0, 7.0, -8.0, 5.0, 10.0, 8.0, 6.0, 4.0, -6.0, 11.0, 10.0, 9.0, -15.0, 11.0, 14.0, -2.0, 6.0, -3.0, 12.0, 4.0, 8.0, -9.0, 10.0, -11.0, 8.0, 8.0, 11.0, 13.0, -13.0, 4.0, 3.0, -2.0, 8.0, 6.0, 13.0, 1.0, 8.0, -7.0, 3.0, -5.0, 4.0, 13.0, 8.0, 8.0, 11.0, -12.0, 2.0, 10.0, 7.0, -4.0, 0.0, 12.0, 3.0, 0.0, -9.0, 9.0, 9.0, 6.0, 7.0, -6.0, 11.0, 3.0, 7.0, 5.0, 8.0, -5.0, 11.0, 7.0, -13.0, 10.0, -1.0, 9.0, -2.0, 9.0, 8.0, 9.0, 7.0, -9.0, 8.0, -2.0, 5.0, 4.0, 13.0, 5.0, -9.0, 6.0, 2.0, 7.0, -5.0, 11.0, 5.0, 9.0, 12.0, -11.0, -2.0, 8.0, -4.0, 13.0, -1.0, 5.0, -1.0, 12.0, 4.0, 10.0, -10.0, 11.0, -14.0, 7.0, 11.0, 11.0, -3.0, -4.0, 10.0, 12.0, 11.0, 7.0, 3.0, -6.0, -9.0, 3.0, 11.0, 10.0, 12.0, 8.0, 10.0, -15.0, 11.0, 11.0, -7.0, 0.0, 14.0, 7.0, -1.0, -5.0, 7.0, 7.0, -7.0, 8.0, 11.0, 8.0, 12.0, -16.0, 12.0, 3.0, 4.0, -4.0, -1.0, 3.0, 6.0, 7.0, 12.0, -11.0, 6.0, 8.0, 8.0, 9.0, -4.0, 2.0, 5.0, -2.0, 8.0, 4.0, -6.0, 8.0, 1.0, 12.0, -9.0, 2.0, 12.0, 10.0, 11.0, -8.0, 7.0, 5.0, 8.0, -3.0, 0.0, 10.0, -6.0, 4.0, 4.0, 13.0, 8.0, 0.0, -4.0, 11.0, 12.0, 8.0, 0.0, -5.0, -1.0, -2.0, 13.0, 5.0, 9.0, 0.0, 9.0, -3.0, 4.0, -5.0, 9.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1837665371821956, "mean_inference_ms": 1.074777574664917, "mean_action_processing_ms": 0.07213281338638218, "mean_env_wait_ms": 0.17433694468511465, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 77112, "agent_timesteps_total": 77112, "timers": {"sample_time_ms": 0.076, "sample_throughput": 72115289.726, "learn_time_ms": 13.934, "learn_throughput": 395284.191, "update_time_ms": 6.671}, "info": {"learner": {"learned": {"policy_loss": 1.3064866065979004, "vf_loss": 16.10434913635254, "total_loss": 17.41083526611328, "vf_explained_var": -0.0008234977722167969, "model": {}}}, "num_steps_sampled": 77112, "num_agent_steps_sampled": 77112, "num_steps_trained": 77112, "num_agent_steps_trained": 77112}, "done": false, "episodes_total": 1512, "training_iteration": 14, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-29", "timestamp": 1626864449, "time_this_iter_s": 0.3531630039215088, "time_total_s": 5.523998737335205, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 5.523998737335205, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 14.0, -16.0, 11.0, -1.0, -5.0, 13.0, 8.0, 10.0, 12.0, -14.0, 7.0, 7.0, 13.0, -10.0, 5.0, -8.0, 8.0, 3.0, 12.0, -6.0, 6.0, 8.0, 7.0, 12.0, -2.0, 2.0, 3.0, 8.0, 6.0, 6.0, -5.0, 2.0, 9.0, -6.0, 10.0, 8.0, -11.0, 6.0, 12.0, -1.0, 6.0, -2.0, 12.0, 10.0, 13.0, 4.0, -12.0, -11.0, 9.0, 9.0, 8.0, 5.0, -8.0, 12.0, 6.0, 13.0, 6.0, -3.0, -1.0, 12.0, -1.0, -6.0, 10.0, -2.0, 2.0, 8.0, 7.0, 2.0, -9.0, 11.0, 11.0, 7.0, 12.0, -10.0, 6.0, 10.0, 4.0, -12.0, 13.0, -9.0, 7.0, 5.0, 12.0, 2.0, -7.0, 12.0, 8.0, 9.0, 12.0, 0.0, -6.0, 8.0, 14.0, -12.0, 5.0, -6.0, 9.0, 4.0, 8.0, 1.0, -4.0, 10.0, 8.0, 11.0, 5.0, 12.0, -13.0, 12.0, 12.0, -8.0, -1.0, -3.0, 9.0, 4.0, 5.0, -16.0, 8.0, 11.0, 12.0, 0.0, 6.0, 2.0, 7.0, 12.0, 3.0, 7.0, -7.0, -11.0, 14.0, 0.0, 12.0, -7.0, 4.0, 10.0, 8.0, 11.0, 11.0, 0.0, -7.0, 9.0, 12.0, -7.0, 1.0, -11.0, 6.0, 9.0, 11.0, -1.0, 7.0, 2.0, 7.0, 11.0, 11.0, -1.0, -6.0, 10.0, 12.0, -9.0, 2.0, -7.0, 9.0, 10.0, 3.0, 3.0, -5.0, 10.0, 7.0, 13.0, -8.0, 2.0, 8.0, 10.0, 1.0, 12.0, -8.0, -12.0, 9.0, 5.0, 13.0, -6.0, 5.0, 8.0, 8.0, -5.0, 12.0, 12.0, -4.0, 10.0, 13.0, 6.0, -14.0, -8.0, 9.0, 5.0, 9.0, -1.0, -10.0, 13.0, 13.0, 10.0, 12.0, -15.0, 8.0, 11.0, 12.0, 3.0, -11.0, -12.0, 9.0, 13.0, 5.0, -4.0, -2.0, 12.0, 9.0, -5.0, 11.0, 1.0, 8.0, 11.0, 11.0, -8.0, 1.0, -8.0, 8.0, 3.0, 12.0, 7.0, -9.0, 4.0, 13.0, -7.0, 13.0, -2.0, 11.0, 10.0, 8.0, -7.0, 4.0, 5.0, 14.0, -15.0, 11.0, -6.0, 6.0, 2.0, 13.0, 13.0, 12.0, 7.0, -17.0, 8.0, 2.0, 11.0, -6.0, -15.0, 9.0, 11.0, 10.0, 0.0, -9.0, 11.0, 13.0, 7.0, 12.0, 9.0, -13.0, 11.0, 9.0, 7.0, -12.0, -10.0, 9.0, 4.0, 12.0, 3.0, -4.0, 8.0, 8.0, 11.0, 5.0, 12.0, -13.0, 9.0, 8.0, 4.0, -6.0, -5.0, 9.0, 2.0, 9.0, 8.0, -11.0, 7.0, 11.0, 13.0, 10.0, -15.0, 7.0, 9.0, 13.0, -11.0, 4.0, -11.0, 10.0, 8.0, 8.0, -4.0, -3.0, 13.0, 9.0, 9.0, 14.0, 5.0, -13.0, 10.0, 13.0, -12.0, 4.0, -11.0, 9.0, 6.0, 11.0, 6.0, -9.0, 7.0, 11.0, 12.0, 3.0, -5.0, 5.0, 8.0, 13.0, -7.0, 1.0, 6.0, 14.0, -16.0, 11.0, -2.0, -2.0, 6.0, 13.0, 12.0, 12.0, -15.0, 6.0, 9.0, -4.0, -2.0, 12.0, 6.0, -7.0, 6.0, 10.0, 1.0, -6.0, 7.0, 13.0, 13.0, 8.0, 7.0, -13.0, 6.0, 12.0, -7.0, 4.0, 9.0, 14.0, 6.0, -14.0, 2.0, -9.0, 9.0, 13.0, 8.0, 12.0, -16.0, 11.0, 12.0, 11.0, -1.0, -7.0, -6.0, 8.0, 5.0, 8.0, -4.0, -3.0, 11.0, 11.0, 10.0, 12.0, -16.0, 9.0, 13.0, -4.0, 8.0, -2.0, -15.0, 14.0, 5.0, 11.0, 1.0, -7.0, 10.0, 11.0, 11.0, 13.0, 2.0, -11.0, 13.0, 13.0, 6.0, -17.0, -13.0, 9.0, 8.0, 11.0, -17.0, 9.0, 12.0, 11.0, 13.0, -8.0, -2.0, 12.0, 7.0, 11.0, -9.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18392370543563635, "mean_inference_ms": 1.07515457559313, "mean_action_processing_ms": 0.07213702635656781, "mean_env_wait_ms": 0.1745451954498175, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 82620, "agent_timesteps_total": 82620, "timers": {"sample_time_ms": 0.077, "sample_throughput": 71171249.897, "learn_time_ms": 14.194, "learn_throughput": 388044.452, "update_time_ms": 6.8}, "info": {"learner": {"learned": {"policy_loss": 1.336443305015564, "vf_loss": 20.440534591674805, "total_loss": 21.7769775390625, "vf_explained_var": -0.0008543729782104492, "model": {}}}, "num_steps_sampled": 82620, "num_agent_steps_sampled": 82620, "num_steps_trained": 82620, "num_agent_steps_trained": 82620}, "done": false, "episodes_total": 1620, "training_iteration": 15, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-29", "timestamp": 1626864449, "time_this_iter_s": 0.36308884620666504, "time_total_s": 5.88708758354187, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 5.88708758354187, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 73.2, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 6.0, -4.0, 8.0, 7.0, -4.0, 10.0, 2.0, -7.0, 10.0, 4.0, 8.0, 7.0, 2.0, -3.0, 9.0, 7.0, -13.0, 10.0, 11.0, 2.0, -5.0, 5.0, 13.0, 9.0, 4.0, -2.0, 4.0, -6.0, 13.0, -4.0, 12.0, -11.0, 4.0, 12.0, 10.0, 14.0, -10.0, 5.0, 6.0, -13.0, 9.0, 12.0, 7.0, 1.0, 11.0, -4.0, 7.0, 5.0, -9.0, 11.0, 8.0, 5.0, -9.0, 7.0, 12.0, -10.0, 11.0, 5.0, 9.0, 4.0, 2.0, -3.0, 12.0, 1.0, -9.0, 11.0, 12.0, 3.0, 6.0, 12.0, -6.0, -1.0, -1.0, 11.0, 6.0, -11.0, 12.0, 5.0, 9.0, -11.0, 4.0, 9.0, 13.0, -16.0, 10.0, 13.0, 8.0, -4.0, 10.0, 4.0, 5.0, -3.0, -1.0, 8.0, 11.0, -17.0, 6.0, 13.0, 13.0, 7.0, -9.0, 10.0, 7.0, 6.0, 5.0, 11.0, -7.0, -12.0, 10.0, 4.0, 13.0, -14.0, 4.0, 12.0, 13.0, 4.0, -8.0, 11.0, 8.0, -11.0, 7.0, 11.0, 8.0, 3.0, 5.0, 12.0, -5.0, -13.0, 12.0, 13.0, 3.0, 1.0, -10.0, 11.0, 13.0, 11.0, 9.0, 6.0, -11.0, 7.0, 2.0, -5.0, 11.0, -9.0, 10.0, 11.0, 3.0, 7.0, -4.0, 6.0, 6.0, 3.0, 13.0, 7.0, -8.0, -7.0, 12.0, 6.0, 4.0, 2.0, 6.0, 13.0, -6.0, 0.0, -9.0, 12.0, 12.0, 9.0, -16.0, 10.0, 12.0, 8.0, 5.0, -9.0, 11.0, -8.0, 0.0, 10.0, 13.0, 0.0, -7.0, 9.0, 13.0, 9.0, 7.0, 8.0, -9.0, 8.0, 4.0, -8.0, 11.0, -6.0, 12.0, 12.0, -3.0, 6.0, 12.0, 10.0, -13.0, -8.0, 9.0, 3.0, 11.0, 3.0, -5.0, 9.0, 8.0, -16.0, 7.0, 11.0, 13.0, -2.0, -5.0, 9.0, 13.0, 10.0, 2.0, -4.0, 7.0, 4.0, 5.0, 12.0, -6.0, -4.0, 1.0, 10.0, 8.0, 6.0, -5.0, 12.0, 2.0, 9.0, 8.0, 10.0, -12.0, 8.0, 2.0, -6.0, 11.0, -18.0, 12.0, 13.0, 8.0, 3.0, 9.0, 9.0, -6.0, -9.0, 11.0, 6.0, 7.0, 7.0, 7.0, -8.0, 9.0, 3.0, 9.0, 11.0, -8.0, -15.0, 11.0, 6.0, 13.0, 2.0, 8.0, 11.0, -6.0, 0.0, 6.0, -2.0, 11.0, -13.0, 4.0, 12.0, 12.0, 8.0, 11.0, -11.0, 7.0, 8.0, -6.0, 6.0, 7.0, 6.0, 6.0, -6.0, 9.0, 0.0, 9.0, -2.0, 8.0, 0.0, -1.0, 3.0, 13.0, 12.0, 7.0, -9.0, 5.0, -7.0, 4.0, 10.0, 8.0, -6.0, 13.0, 10.0, -2.0, 2.0, -11.0, 12.0, 12.0, -2.0, 13.0, 11.0, -7.0, -14.0, 12.0, 8.0, 9.0, 5.0, -15.0, 13.0, 12.0, 7.0, -7.0, 9.0, 6.0, -5.0, 9.0, 9.0, 2.0, -7.0, 5.0, 6.0, 11.0, 4.0, 8.0, 10.0, -7.0, -3.0, 12.0, -2.0, 8.0, 7.0, 5.0, 10.0, -7.0, -1.0, 2.0, 5.0, 9.0, -9.0, 3.0, 11.0, 10.0, 8.0, 11.0, 3.0, -7.0, 1.0, -2.0, 5.0, 11.0, 4.0, 6.0, 10.0, -5.0, 8.0, -5.0, 8.0, 4.0, 3.0, -5.0, 12.0, 5.0, 3.0, -7.0, 11.0, 8.0, 0.0, 7.0, -3.0, 11.0, -7.0, 7.0, 7.0, 8.0, 8.0, 1.0, -7.0, 13.0, 318.0, 13.0, 11.0, 12.0, -16.0, 11.0, 9.0, 11.0, -12.0, 8.0, 9.0, 10.0, -2.0, -5.0, 10.0, 12.0, 6.0, -1.0, -3.0, 13.0, -11.0, 8.0, 7.0, 11.0, -7.0, 4.0, 12.0, 6.0, -1.0, -9.0, 12.0, 13.0, -4.0, 1.0, 11.0, 7.0, -6.0, 2.0, 9.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18391748475620057, "mean_inference_ms": 1.0742207675856166, "mean_action_processing_ms": 0.07205998239673533, "mean_env_wait_ms": 0.17458088283983444, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 88128, "agent_timesteps_total": 88128, "timers": {"sample_time_ms": 0.077, "sample_throughput": 71516213.503, "learn_time_ms": 14.242, "learn_throughput": 386756.239, "update_time_ms": 6.418}, "info": {"learner": {"learned": {"policy_loss": 1.3050036430358887, "vf_loss": 16.091211318969727, "total_loss": 17.396215438842773, "vf_explained_var": -0.0009343624114990234, "model": {}}}, "num_steps_sampled": 88128, "num_agent_steps_sampled": 88128, "num_steps_trained": 88128, "num_agent_steps_trained": 88128}, "done": false, "episodes_total": 1728, "training_iteration": 16, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-30", "timestamp": 1626864450, "time_this_iter_s": 0.36232638359069824, "time_total_s": 6.249413967132568, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 6.249413967132568, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -7.0, -4.0, 13.0, 12.0, -4.0, 11.0, -4.0, 1.0, 10.0, -6.0, 10.0, 8.0, 12.0, -12.0, 7.0, 6.0, 5.0, 8.0, -4.0, 8.0, -12.0, 11.0, 8.0, 0.0, 12.0, 7.0, -4.0, 12.0, 0.0, -9.0, 12.0, 13.0, 6.0, 5.0, -9.0, -5.0, 3.0, 9.0, 8.0, 7.0, 10.0, 4.0, -6.0, 12.0, 1.0, -6.0, 8.0, 13.0, 6.0, -12.0, 8.0, 13.0, -7.0, 13.0, -4.0, 5.0, 11.0, -12.0, 11.0, 13.0, -9.0, 6.0, 5.0, 12.0, 7.0, -13.0, 9.0, 10.0, -18.0, 10.0, 13.0, 6.0, 12.0, 4.0, -7.0, -3.0, 6.0, 6.0, 6.0, 13.0, 5.0, 0.0, -3.0, 12.0, -18.0, 9.0, 12.0, -14.0, 10.0, 10.0, 9.0, 1.0, 11.0, 6.0, -3.0, 13.0, 4.0, 3.0, -5.0, -5.0, 5.0, 7.0, 8.0, 0.0, 14.0, 6.0, -5.0, 9.0, 9.0, -6.0, 3.0, 11.0, -4.0, 12.0, -4.0, 14.0, 3.0, -8.0, 6.0, -9.0, 12.0, 11.0, 1.0, 8.0, 7.0, 12.0, -12.0, 13.0, -5.0, -5.0, 12.0, 12.0, -16.0, 12.0, 7.0, 5.0, -3.0, 8.0, 5.0, 12.0, 6.0, -12.0, 9.0, 9.0, 6.0, 9.0, -9.0, 8.0, 4.0, 9.0, -6.0, 6.0, 14.0, 6.0, -11.0, 11.0, 8.0, -7.0, 3.0, 13.0, 6.0, -5.0, 1.0, 12.0, -17.0, 13.0, 7.0, 0.0, 7.0, 12.0, -4.0, -8.0, 9.0, 7.0, 7.0, 9.0, 9.0, -5.0, 2.0, 13.0, -18.0, 12.0, 8.0, 0.0, 12.0, 5.0, -2.0, 12.0, 12.0, -12.0, 3.0, 12.0, -17.0, 10.0, 10.0, 13.0, -14.0, 8.0, 8.0, 6.0, 11.0, 2.0, -4.0, 12.0, 10.0, -12.0, 5.0, 13.0, 5.0, 0.0, -3.0, 12.0, -20.0, 13.0, 10.0, -7.0, 12.0, 13.0, -3.0, -1.0, 9.0, 5.0, 2.0, 12.0, 9.0, -7.0, 1.0, -6.0, 4.0, 9.0, 8.0, -2.0, 9.0, 13.0, -5.0, 10.0, 9.0, -12.0, 8.0, 13.0, 8.0, -5.0, -1.0, 13.0, -18.0, 12.0, 8.0, 7.0, -4.0, 9.0, 3.0, 13.0, 3.0, -7.0, 6.0, 13.0, 7.0, 9.0, -14.0, -1.0, 3.0, 11.0, 2.0, 5.0, 0.0, 3.0, 7.0, 11.0, 10.0, -11.0, 5.0, 13.0, 5.0, -9.0, 6.0, 4.0, -10.0, 12.0, 9.0, -18.0, 14.0, 10.0, 9.0, 12.0, 8.0, -9.0, 4.0, 13.0, -1.0, -5.0, 8.0, 12.0, -8.0, 6.0, 5.0, 8.0, -4.0, 5.0, 6.0, 11.0, -6.0, 3.0, 7.0, -4.0, 5.0, 13.0, 1.0, 13.0, -19.0, 12.0, 9.0, 1.0, 12.0, -8.0, 10.0, -2.0, 8.0, 2.0, 7.0, 13.0, 7.0, -11.0, 6.0, 13.0, -14.0, 3.0, 13.0, 3.0, 13.0, -11.0, 10.0, 9.0, -3.0, 9.0, 0.0, 10.0, 1.0, 13.0, -9.0, 12.0, -13.0, 8.0, 8.0, 0.0, 8.0, 10.0, -3.0, 13.0, -12.0, 12.0, 2.0, 8.0, 7.0, -11.0, 11.0, 13.0, -15.0, 10.0, 7.0, 8.0, 11.0, -10.0, 6.0, 0.0, 7.0, 1.0, 7.0, 12.0, -5.0, 13.0, -5.0, 5.0, -12.0, 13.0, 9.0, 5.0, 12.0, 7.0, -9.0, 11.0, -6.0, 8.0, 2.0, 12.0, -2.0, -5.0, 10.0, 12.0, -13.0, 7.0, 9.0, -2.0, 9.0, 12.0, -4.0, 14.0, 2.0, 6.0, -7.0, 13.0, 7.0, -6.0, 1.0, -8.0, 4.0, 8.0, 11.0, -17.0, 14.0, 9.0, 9.0, 11.0, 8.0, -2.0, -2.0, 14.0, 1.0, 7.0, -7.0, -1.0, -4.0, 12.0, 8.0, 7.0, 12.0, -17.0, 13.0, 12.0, 7.0, 2.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18375744860419913, "mean_inference_ms": 1.0724943745109918, "mean_action_processing_ms": 0.07190114351166708, "mean_env_wait_ms": 0.17450208940788328, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 93636, "agent_timesteps_total": 93636, "timers": {"sample_time_ms": 0.078, "sample_throughput": 71059689.503, "learn_time_ms": 14.405, "learn_throughput": 382378.936, "update_time_ms": 6.394}, "info": {"learner": {"learned": {"policy_loss": 1.3089159727096558, "vf_loss": 19.5621280670166, "total_loss": 20.871044158935547, "vf_explained_var": -0.0010906457901000977, "model": {}}}, "num_steps_sampled": 93636, "num_agent_steps_sampled": 93636, "num_steps_trained": 93636, "num_agent_steps_trained": 93636}, "done": false, "episodes_total": 1836, "training_iteration": 17, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-30", "timestamp": 1626864450, "time_this_iter_s": 0.3442962169647217, "time_total_s": 6.59371018409729, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a22970ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 6.59371018409729, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 77.3, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 5.0, -13.0, 13.0, -1.0, 10.0, 1.0, 5.0, 4.0, -1.0, 0.0, 12.0, -3.0, 12.0, 0.0, 6.0, 10.0, 11.0, -18.0, 12.0, 11.0, 10.0, 4.0, -10.0, -2.0, 9.0, -4.0, 12.0, 3.0, 12.0, -8.0, 8.0, 13.0, 13.0, -2.0, -9.0, 13.0, -4.0, 7.0, -1.0, 4.0, 13.0, -12.0, 10.0, 3.0, 13.0, -13.0, 12.0, 5.0, 12.0, -2.0, 0.0, 12.0, -4.0, 3.0, 4.0, 6.0, -1.0, -2.0, 12.0, -14.0, 14.0, 7.0, 8.0, 8.0, 13.0, -2.0, -4.0, 14.0, 12.0, -14.0, 3.0, -5.0, 12.0, -1.0, 9.0, 7.0, 14.0, -5.0, -1.0, 5.0, 11.0, -1.0, 0.0, 11.0, -4.0, 0.0, 8.0, -1.0, 12.0, -1.0, 5.0, -10.0, 14.0, 5.0, 6.0, 6.0, 8.0, 8.0, -7.0, 14.0, -2.0, 4.0, -1.0, -9.0, 12.0, 1.0, 11.0, 10.0, 13.0, -7.0, -1.0, 9.0, 11.0, -3.0, -2.0, 0.0, 11.0, 8.0, -4.0, 12.0, -9.0, 0.0, 12.0, 0.0, 14.0, -2.0, 3.0, 12.0, 12.0, -2.0, -7.0, 14.0, -5.0, 9.0, -3.0, -7.0, 12.0, 3.0, 7.0, 1.0, 12.0, -10.0, 12.0, 12.0, 12.0, 13.0, 317.0, -1.0, 11.0, 0.0, 5.0, -6.0, 8.0, 3.0, 10.0, 5.0, 13.0, -15.0, 12.0, 13.0, -3.0, -7.0, 12.0, 14.0, -9.0, 2.0, 8.0, -9.0, 4.0, 7.0, 13.0, 7.0, 14.0, -5.0, -1.0, 14.0, 11.0, -8.0, -2.0, 12.0, -4.0, 3.0, 4.0, -1.0, 11.0, 1.0, 4.0, -12.0, 14.0, 1.0, 12.0, 11.0, 12.0, -6.0, -2.0, 13.0, -4.0, -3.0, 9.0, -10.0, 10.0, 5.0, 10.0, -12.0, 14.0, 5.0, 8.0, 8.0, 7.0, -2.0, 2.0, 11.0, -4.0, 9.0, -1.0, -11.0, 12.0, 4.0, 10.0, 3.0, 14.0, -12.0, 10.0, 9.0, -1.0, -5.0, 12.0, 11.0, -1.0, -2.0, 7.0, -12.0, 10.0, 5.0, 12.0, 4.0, 14.0, -14.0, 11.0, 4.0, 11.0, 13.0, -13.0, 14.0, -8.0, 8.0, 1.0, -1.0, 6.0, 0.0, 10.0, -13.0, 11.0, 7.0, 10.0, 9.0, 11.0, -17.0, 12.0, 12.0, -4.0, 0.0, 7.0, -3.0, 5.0, 3.0, 10.0, 6.0, 14.0, -3.0, -2.0, 14.0, 10.0, -7.0, -2.0, 9.0, -7.0, 8.0, 5.0, -2.0, 9.0, -4.0, 12.0, -7.0, 12.0, -2.0, 12.0, 4.0, 11.0, 13.0, -13.0, 14.0, 8.0, 4.0, -11.0, 8.0, -6.0, 2.0, 11.0, 2.0, 10.0, 11.0, -8.0, 10.0, 11.0, 13.0, -19.0, 11.0, -1.0, 2.0, 3.0, 1.0, -1.0, 3.0, 12.0, -3.0, 14.0, -9.0, 13.0, 10.0, 10.0, -3.0, -2.0, 14.0, -2.0, 0.0, 3.0, -9.0, 13.0, 0.0, 11.0, -11.0, 14.0, 1.0, 11.0, 13.0, 9.0, -20.0, 13.0, 0.0, 12.0, -2.0, 5.0, 11.0, -1.0, -5.0, 10.0, -5.0, 13.0, -5.0, 12.0, 3.0, 0.0, 13.0, -1.0, 13.0, -3.0, 8.0, -3.0, -9.0, 10.0, 4.0, 10.0, -1.0, 8.0, -4.0, 12.0, 3.0, 10.0, -2.0, 4.0, 14.0, 12.0, -13.0, 2.0, 3.0, -3.0, 3.0, 12.0, 7.0, 13.0, 7.0, -12.0, 12.0, 11.0, 13.0, -21.0, 9.0, 9.0, 3.0, -6.0, 6.0, -2.0, -2.0, 13.0, 5.0, 14.0, 4.0, -8.0, 6.0, 10.0, 12.0, -13.0, 12.0, -1.0, 1.0, 3.0, -6.0, 11.0, -2.0, 12.0, -6.0, 10.0, 3.0, 8.0, 1.0, 12.0, -10.0, 12.0, 11.0, 0.0, 1.0, 3.0, -6.0, 10.0, -1.0, 12.0, 1.0, 13.0, -2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18387687501854366, "mean_inference_ms": 1.072753930348858, "mean_action_processing_ms": 0.07191690129391651, "mean_env_wait_ms": 0.1745467367677201, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 99144, "agent_timesteps_total": 99144, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69844143.709, "learn_time_ms": 14.017, "learn_throughput": 392961.838, "update_time_ms": 6.323}, "info": {"learner": {"learned": {"policy_loss": 122032250880.0, "vf_loss": 132.92913818359375, "total_loss": 122032250880.0, "vf_explained_var": -9.191036224365234e-05, "model": {}}}, "num_steps_sampled": 99144, "num_agent_steps_sampled": 99144, "num_steps_trained": 99144, "num_agent_steps_trained": 99144}, "done": false, "episodes_total": 1944, "training_iteration": 18, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-30", "timestamp": 1626864450, "time_this_iter_s": 0.359025239944458, "time_total_s": 6.952735424041748, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1825e268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 6.952735424041748, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 85.3, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.24074074074074, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 4.560185185185185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 7.0, -1.0, -4.0, 9.0, 8.0, 11.0, -13.0, 11.0, 5.0, -5.0, 4.0, 9.0, 13.0, -3.0, -4.0, 12.0, 3.0, -4.0, 4.0, 11.0, 9.0, -16.0, 11.0, 11.0, 7.0, 7.0, -10.0, 5.0, -1.0, -1.0, 12.0, 7.0, -9.0, 6.0, 11.0, -2.0, 9.0, 3.0, 5.0, 5.0, 7.0, 13.0, -10.0, 8.0, -3.0, -1.0, 11.0, 14.0, -10.0, 7.0, 4.0, -4.0, 9.0, -1.0, 11.0, 10.0, -7.0, 7.0, 5.0, 13.0, 12.0, -8.0, -2.0, 12.0, 4.0, 2.0, -2.0, 8.0, 0.0, 4.0, 3.0, 11.0, 1.0, -3.0, 6.0, 13.0, -1.0, 3.0, 0.0, 14.0, 10.0, 7.0, -15.0, 6.0, -1.0, -2.0, 12.0, -7.0, 9.0, 0.0, 13.0, 12.0, 12.0, -17.0, 8.0, 13.0, -8.0, 4.0, 6.0, -5.0, 9.0, 3.0, 8.0, 11.0, 1.0, 12.0, -9.0, 3.0, -1.0, 4.0, 9.0, 14.0, -18.0, 8.0, 12.0, 10.0, 8.0, -15.0, 12.0, 5.0, 10.0, -9.0, 9.0, 6.0, -1.0, 0.0, 10.0, 13.0, -10.0, 9.0, 3.0, 10.0, 8.0, 12.0, -15.0, 12.0, -11.0, 6.0, 8.0, 14.0, -1.0, 8.0, -6.0, 10.0, 2.0, -3.0, 6.0, 11.0, -3.0, 5.0, 2.0, 1.0, -2.0, 4.0, 12.0, 8.0, -2.0, 2.0, 7.0, 14.0, -15.0, 6.0, 11.0, 10.0, -11.0, 11.0, 5.0, 11.0, -8.0, 7.0, 5.0, 13.0, 13.0, 0.0, -11.0, 13.0, -9.0, 1.0, 11.0, 4.0, 14.0, 7.0, -10.0, 13.0, 4.0, 8.0, -10.0, 11.0, 12.0, -4.0, -4.0, 13.0, -15.0, 7.0, 10.0, 11.0, 8.0, -9.0, 5.0, 12.0, -14.0, 13.0, 4.0, 11.0, -5.0, 2.0, 7.0, 13.0, 5.0, -9.0, 6.0, 9.0, 0.0, 2.0, 4.0, 8.0, -7.0, 5.0, 9.0, 12.0, 13.0, 8.0, -18.0, 10.0, 2.0, 8.0, -4.0, 11.0, 14.0, -8.0, -2.0, 12.0, 0.0, 5.0, -2.0, 14.0, -1.0, -8.0, 10.0, 14.0, 2.0, 5.0, -6.0, -4.0, 8.0, 8.0, 3.0, 10.0, -3.0, 6.0, 2.0, 13.0, -4.0, -3.0, 9.0, 14.0, -8.0, 8.0, 1.0, 7.0, 9.0, 4.0, -5.0, 7.0, -9.0, 8.0, 9.0, 12.0, 0.0, 3.0, 0.0, 9.0, -10.0, 7.0, 10.0, 10.0, -5.0, 6.0, 4.0, 322.0, 11.0, 11.0, 12.0, 12.0, -4.0, -4.0, 11.0, 14.0, -14.0, 10.0, 5.0, 10.0, -8.0, 3.0, 10.0, 10.0, -6.0, 6.0, 5.0, 13.0, 12.0, -6.0, -4.0, 14.0, 7.0, -4.0, -2.0, 9.0, 13.0, -15.0, 8.0, 12.0, -3.0, 9.0, -3.0, 11.0, 11.0, 0.0, -7.0, 10.0, 9.0, -2.0, -1.0, 10.0, -8.0, 6.0, 7.0, 7.0, 10.0, 5.0, -7.0, 11.0, -1.0, 2.0, 3.0, 13.0, -12.0, 4.0, 10.0, 12.0, 13.0, 8.0, -18.0, 8.0, 6.0, 4.0, -3.0, 9.0, -1.0, -4.0, 11.0, 14.0, 7.0, 3.0, -9.0, 7.0, -5.0, 6.0, 7.0, -6.0, 10.0, 12.0, -1.0, 8.0, 13.0, 3.0, -9.0, 14.0, -13.0, 6.0, 9.0, 9.0, 12.0, -6.0, 0.0, -13.0, 11.0, 9.0, 8.0, 13.0, 12.0, -7.0, -3.0, 12.0, 3.0, -6.0, 6.0, 11.0, 8.0, 7.0, -11.0, 11.0, -12.0, 8.0, 8.0, 7.0, -1.0, -1.0, 10.0, 10.0, -12.0, 10.0, 7.0, 9.0, 4.0, 7.0, -5.0, 12.0, 6.0, -11.0, 8.0, 10.0, -1.0, 5.0, 1.0, 14.0, -4.0, 9.0, -4.0, 7.0, -6.0, 3.0, 11.0, 13.0, -7.0, 11.0, -2.0, 7.0, 13.0, -4.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1838180733421268, "mean_inference_ms": 1.0716387338628919, "mean_action_processing_ms": 0.0718668904511904, "mean_env_wait_ms": 0.1744789293208448, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 104652, "agent_timesteps_total": 104652, "timers": {"sample_time_ms": 0.08, "sample_throughput": 69270907.208, "learn_time_ms": 13.826, "learn_throughput": 398387.057, "update_time_ms": 6.201}, "info": {"learner": {"learned": {"policy_loss": 1.3333297967910767, "vf_loss": 20.417186737060547, "total_loss": 21.750516891479492, "vf_explained_var": -0.0010592937469482422, "model": {}}}, "num_steps_sampled": 104652, "num_agent_steps_sampled": 104652, "num_steps_trained": 104652, "num_agent_steps_trained": 104652}, "done": false, "episodes_total": 2052, "training_iteration": 19, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-31", "timestamp": 1626864451, "time_this_iter_s": 0.35219597816467285, "time_total_s": 7.304931402206421, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1825eb70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 7.304931402206421, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 4.0, 6.0, 11.0, -7.0, 13.0, 10.0, -1.0, 9.0, 10.0, -1.0, -3.0, 11.0, 14.0, -3.0, -7.0, 3.0, 8.0, -9.0, 13.0, -5.0, 12.0, 3.0, 5.0, 14.0, 7.0, 5.0, -11.0, 13.0, 12.0, -8.0, -2.0, 2.0, 9.0, 11.0, 6.0, 0.0, -3.0, 8.0, 10.0, 7.0, 6.0, -4.0, 6.0, 13.0, 12.0, 8.0, -18.0, -11.0, 10.0, 6.0, 10.0, 6.0, 13.0, 2.0, -6.0, 14.0, -6.0, 4.0, 3.0, 12.0, 13.0, 3.0, -13.0, 10.0, 7.0, -14.0, 12.0, 9.0, 3.0, 12.0, -9.0, 10.0, 10.0, -4.0, -1.0, 14.0, 11.0, -8.0, -2.0, 13.0, -19.0, 8.0, 13.0, -2.0, 0.0, 10.0, 7.0, 14.0, 9.0, 1.0, -9.0, 13.0, 12.0, 7.0, -17.0, -2.0, 11.0, 6.0, 0.0, 0.0, -2.0, 9.0, 8.0, 14.0, 5.0, 6.0, -10.0, 12.0, 12.0, 12.0, 317.0, -4.0, -1.0, 8.0, 12.0, 10.0, 11.0, -17.0, 11.0, 14.0, 8.0, 8.0, -15.0, 11.0, 11.0, -9.0, 2.0, -4.0, 4.0, 6.0, 9.0, 10.0, -3.0, -5.0, 13.0, 11.0, 9.0, 12.0, -17.0, 14.0, 11.0, 0.0, -10.0, -9.0, 11.0, 11.0, 2.0, 0.0, 7.0, 1.0, 7.0, 6.0, 10.0, 3.0, -4.0, 4.0, 12.0, 6.0, -7.0, -13.0, 10.0, 5.0, 13.0, 0.0, 5.0, 12.0, -2.0, 14.0, 1.0, -10.0, 10.0, 12.0, 13.0, -10.0, 0.0, 5.0, 0.0, 11.0, -1.0, 12.0, 13.0, -8.0, -2.0, 11.0, -7.0, 6.0, 5.0, 13.0, 5.0, 4.0, -7.0, 8.0, 11.0, 6.0, -10.0, 14.0, 11.0, 12.0, -22.0, 14.0, 9.0, 4.0, -12.0, 12.0, 13.0, -4.0, -6.0, 7.0, 2.0, 10.0, -4.0, -1.0, 9.0, -4.0, 11.0, 9.0, 12.0, -14.0, 8.0, 13.0, 5.0, -8.0, 5.0, -8.0, 3.0, 9.0, 11.0, 11.0, -6.0, 12.0, -2.0, 11.0, 5.0, -10.0, 9.0, 10.0, 13.0, -7.0, -1.0, -6.0, 8.0, 8.0, 5.0, -7.0, 13.0, 1.0, 8.0, 14.0, 2.0, 11.0, -12.0, 5.0, 10.0, 4.0, -4.0, 8.0, 11.0, -2.0, -2.0, 11.0, 5.0, 0.0, -1.0, 6.0, -4.0, 9.0, 4.0, 13.0, 11.0, -3.0, -6.0, 10.0, -13.0, 11.0, 7.0, 11.0, 9.0, 9.0, -14.0, 11.0, 9.0, -16.0, 11.0, 12.0, 13.0, 0.0, -10.0, 10.0, -10.0, 11.0, 5.0, -7.0, 0.0, 11.0, 11.0, 14.0, -2.0, 10.0, -7.0, 13.0, -7.0, 8.0, 1.0, -13.0, 11.0, 4.0, 13.0, 14.0, 5.0, -9.0, 5.0, 9.0, 6.0, 11.0, -11.0, 13.0, 13.0, -15.0, 4.0, -8.0, 5.0, 7.0, 11.0, -2.0, 13.0, -7.0, 11.0, 10.0, 6.0, 2.0, -3.0, 13.0, 10.0, 7.0, -15.0, 8.0, 11.0, 12.0, -16.0, -5.0, 12.0, -4.0, 12.0, 9.0, 7.0, 9.0, -10.0, 12.0, 11.0, -1.0, -7.0, 0.0, 10.0, 7.0, -2.0, 0.0, 6.0, 13.0, -4.0, 12.0, 4.0, -8.0, 7.0, 13.0, -6.0, 8.0, 0.0, -8.0, 4.0, 7.0, 12.0, -1.0, -5.0, 12.0, 9.0, 14.0, 8.0, -4.0, -3.0, 13.0, 12.0, -6.0, -4.0, 7.0, 10.0, -9.0, 7.0, -2.0, 1.0, 10.0, 6.0, 14.0, 7.0, 8.0, -14.0, 13.0, 12.0, -16.0, 6.0, -11.0, 9.0, 9.0, 8.0, 4.0, 7.0, 10.0, -6.0, 9.0, 10.0, 7.0, -11.0, 12.0, 12.0, -13.0, 4.0, 5.0, -8.0, 9.0, 9.0, 9.0, -1.0, 11.0, -4.0, 10.0, 6.0, 10.0, -11.0, 13.0, 11.0, -1.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18387230860272472, "mean_inference_ms": 1.0708807726166112, "mean_action_processing_ms": 0.07179994323564846, "mean_env_wait_ms": 0.17440846911319424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 110160, "agent_timesteps_total": 110160, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68038471.149, "learn_time_ms": 13.893, "learn_throughput": 396465.217, "update_time_ms": 6.089}, "info": {"learner": {"learned": {"policy_loss": 91718033408.0, "vf_loss": 126.47327423095703, "total_loss": 91718033408.0, "vf_explained_var": -0.0001277923583984375, "model": {}}}, "num_steps_sampled": 110160, "num_agent_steps_sampled": 110160, "num_steps_trained": 110160, "num_agent_steps_trained": 110160}, "done": false, "episodes_total": 2160, "training_iteration": 20, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-31", "timestamp": 1626864451, "time_this_iter_s": 0.369718074798584, "time_total_s": 7.674649477005005, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1825eea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 7.674649477005005, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 73.7, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -5.0, 7.0, 4.0, 7.0, 5.0, -2.0, 5.0, 7.0, 9.0, 12.0, -13.0, -1.0, 1.0, 11.0, 4.0, 13.0, -3.0, 1.0, 4.0, 12.0, 6.0, -6.0, 3.0, 12.0, -2.0, 6.0, -1.0, 11.0, -3.0, -2.0, 9.0, 8.0, -5.0, 3.0, 9.0, 8.0, 9.0, -9.0, 7.0, 12.0, -20.0, 10.0, 13.0, -14.0, 9.0, 13.0, 7.0, 4.0, -5.0, 5.0, 11.0, -6.0, 8.0, 6.0, 7.0, 11.0, -15.0, 11.0, 8.0, -3.0, 5.0, 7.0, 6.0, 4.0, 12.0, 7.0, -8.0, 11.0, -2.0, 1.0, 5.0, -9.0, 11.0, 11.0, 2.0, -4.0, 5.0, 10.0, 4.0, 9.0, -5.0, 6.0, 5.0, -12.0, 12.0, 12.0, 3.0, 10.0, -10.0, 6.0, 9.0, 13.0, 9.0, 3.0, -10.0, 10.0, -5.0, 6.0, 4.0, 10.0, 13.0, -14.0, 6.0, 12.0, 8.0, 4.0, -9.0, -7.0, 9.0, 13.0, 0.0, 13.0, 10.0, 6.0, -14.0, 11.0, -2.0, 2.0, 4.0, 13.0, -9.0, -1.0, 12.0, -3.0, 8.0, 3.0, 7.0, 1.0, -4.0, 11.0, 7.0, 7.0, -6.0, 7.0, 7.0, 12.0, 0.0, -7.0, 10.0, -2.0, 9.0, 5.0, 3.0, 10.0, 9.0, 0.0, -4.0, 12.0, 5.0, 3.0, -5.0, 6.0, 8.0, -1.0, 2.0, 12.0, -9.0, 7.0, 5.0, 4.0, 11.0, 4.0, -4.0, -2.0, 8.0, 9.0, 0.0, 11.0, 7.0, -9.0, 6.0, -8.0, 8.0, 6.0, 9.0, 6.0, 4.0, 10.0, -5.0, 13.0, 8.0, 1.0, -7.0, 7.0, 8.0, -7.0, 7.0, -1.0, 12.0, -1.0, 5.0, 4.0, 10.0, 3.0, -2.0, 7.0, 12.0, 2.0, -6.0, 12.0, 7.0, 9.0, -13.0, 13.0, -8.0, 5.0, 5.0, 2.0, -4.0, 5.0, 12.0, 11.0, 11.0, -15.0, 8.0, 13.0, -13.0, 7.0, 8.0, -2.0, 1.0, 5.0, 11.0, 11.0, -8.0, 6.0, 6.0, 12.0, -11.0, 11.0, 3.0, 13.0, 10.0, 4.0, -12.0, 12.0, 10.0, -15.0, 8.0, 4.0, -3.0, 3.0, 11.0, 12.0, 7.0, -3.0, -1.0, 11.0, 11.0, 8.0, -15.0, 9.0, 4.0, 3.0, -1.0, 5.0, -5.0, 7.0, 8.0, 11.0, 12.0, -5.0, -3.0, 12.0, -4.0, 7.0, 0.0, 12.0, 10.0, -14.0, 7.0, 10.0, -2.0, 2.0, 5.0, 9.0, -2.0, -1.0, 9.0, 12.0, 2.0, -6.0, 7.0, -6.0, 5.0, 6.0, 10.0, -3.0, 10.0, 11.0, -3.0, 12.0, -3.0, -4.0, 10.0, 12.0, -9.0, 8.0, 4.0, 8.0, -6.0, 10.0, 3.0, 2.0, 0.0, 1.0, 12.0, -7.0, 5.0, 7.0, 10.0, 9.0, 2.0, -4.0, 8.0, 10.0, -7.0, 5.0, 7.0, 5.0, -4.0, 4.0, 10.0, 11.0, 8.0, -10.0, 6.0, 7.0, 13.0, -8.0, 3.0, 12.0, 12.0, -12.0, 3.0, 1.0, -1.0, 5.0, 10.0, 13.0, 7.0, 2.0, -7.0, 8.0, 6.0, 9.0, -8.0, -1.0, 5.0, 3.0, 8.0, -5.0, 5.0, 5.0, 10.0, 9.0, -4.0, 10.0, 0.0, 8.0, 11.0, 7.0, -11.0, -3.0, 3.0, 7.0, 8.0, 10.0, 5.0, 2.0, -2.0, 13.0, -2.0, -1.0, 5.0, 5.0, -10.0, 10.0, 10.0, 7.0, -2.0, 5.0, 5.0, 4.0, -3.0, 2.0, 12.0, 9.0, 7.0, 6.0, -7.0, 10.0, 3.0, -4.0, 6.0, -7.0, 5.0, 11.0, 6.0, 14.0, -9.0, -1.0, 11.0, -1.0, 6.0, 0.0, 10.0, 13.0, 318.0, 12.0, 12.0, -12.0, 9.0, 5.0, 13.0, 10.0, -8.0, 6.0, 7.0, 10.0, 12.0, 6.0, -13.0, 13.0, -20.0, 10.0, 12.0, 6.0, -4.0, 9.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18382449360075967, "mean_inference_ms": 1.0697288023549172, "mean_action_processing_ms": 0.0717519740101337, "mean_env_wait_ms": 0.17445434772430954, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 115668, "agent_timesteps_total": 115668, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69614805.541, "learn_time_ms": 13.933, "learn_throughput": 395317.334, "update_time_ms": 6.014}, "info": {"learner": {"learned": {"policy_loss": 259832168448.0, "vf_loss": 242.78646850585938, "total_loss": 259832168448.0, "vf_explained_var": -0.00015437602996826172, "model": {}}}, "num_steps_sampled": 115668, "num_agent_steps_sampled": 115668, "num_steps_trained": 115668, "num_agent_steps_trained": 115668}, "done": false, "episodes_total": 2268, "training_iteration": 21, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-32", "timestamp": 1626864452, "time_this_iter_s": 0.3461296558380127, "time_total_s": 8.020779132843018, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a22970840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 8.020779132843018, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 333.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, -1.0, 0.0, 12.0, 2.0, 13.0, 7.0, -7.0, -7.0, 10.0, 7.0, 5.0, 10.0, 10.0, 7.0, -12.0, 4.0, -2.0, 2.0, 11.0, 333.0, 12.0, 12.0, 10.0, 13.0, 11.0, 4.0, -13.0, 11.0, 12.0, 0.0, -8.0, 4.0, -1.0, 0.0, 12.0, -8.0, 8.0, 2.0, 13.0, -6.0, 13.0, 2.0, 6.0, 12.0, -3.0, -3.0, 9.0, -13.0, 14.0, 5.0, 9.0, -7.0, 7.0, 5.0, 10.0, -6.0, 8.0, 11.0, 2.0, -1.0, 2.0, 4.0, 10.0, -3.0, 13.0, -7.0, 12.0, -17.0, 13.0, 7.0, 12.0, -9.0, 9.0, 11.0, 4.0, 14.0, -1.0, 5.0, -3.0, 5.0, -4.0, 4.0, 10.0, 1.0, 9.0, -3.0, 8.0, -7.0, 13.0, 11.0, -2.0, 10.0, 1.0, 6.0, -2.0, 1.0, 12.0, -9.0, 11.0, 7.0, 9.0, 11.0, -12.0, -10.0, 12.0, 7.0, 6.0, 11.0, 0.0, 7.0, -3.0, 8.0, 10.0, -9.0, 6.0, 2.0, 7.0, 8.0, -2.0, -7.0, 11.0, 5.0, 6.0, 13.0, 7.0, 3.0, -8.0, 2.0, 7.0, 11.0, -5.0, -2.0, 6.0, 5.0, 6.0, 3.0, 12.0, 4.0, -4.0, 2.0, 9.0, 12.0, -8.0, 8.0, 0.0, 5.0, 2.0, 1.0, 14.0, -7.0, 7.0, 2.0, 12.0, 5.0, -4.0, 12.0, 6.0, 7.0, -10.0, 9.0, -7.0, 1.0, 12.0, 4.0, 7.0, 8.0, -4.0, 7.0, 10.0, -12.0, 10.0, 13.0, 12.0, 5.0, -15.0, 5.0, 11.0, -10.0, 9.0, -15.0, 8.0, 11.0, 11.0, 7.0, 11.0, 9.0, -12.0, 14.0, 7.0, 3.0, -9.0, -3.0, 13.0, 6.0, -1.0, 0.0, 8.0, -3.0, 10.0, -7.0, 12.0, 0.0, 10.0, 11.0, 2.0, 11.0, -9.0, 1.0, -1.0, 7.0, 8.0, -5.0, 14.0, -4.0, 10.0, 4.0, 10.0, 9.0, -8.0, 13.0, 12.0, -18.0, 8.0, 4.0, 10.0, 4.0, -3.0, -8.0, 9.0, 7.0, 7.0, 13.0, 12.0, -2.0, -8.0, -1.0, 10.0, 9.0, -3.0, 12.0, 0.0, -5.0, 8.0, 0.0, 10.0, -4.0, 9.0, -15.0, 12.0, 7.0, 11.0, -2.0, 8.0, 0.0, 9.0, 3.0, 12.0, 5.0, -5.0, 0.0, 0.0, 3.0, 12.0, 13.0, 13.0, -15.0, 4.0, 14.0, 11.0, -1.0, -9.0, 9.0, 14.0, 0.0, -8.0, 6.0, 11.0, -3.0, 1.0, 13.0, 12.0, 0.0, -10.0, -2.0, 8.0, 5.0, 4.0, 2.0, 12.0, 2.0, -1.0, -4.0, 14.0, 5.0, 0.0, 4.0, 11.0, 3.0, -3.0, 13.0, 3.0, 8.0, -9.0, 12.0, 14.0, -8.0, -3.0, -3.0, 6.0, 4.0, 8.0, -10.0, 8.0, 12.0, 5.0, 13.0, 11.0, -16.0, 7.0, 7.0, -2.0, 9.0, 1.0, 6.0, 8.0, 9.0, -8.0, 3.0, 12.0, 6.0, -6.0, 10.0, 10.0, -5.0, 0.0, 9.0, -2.0, -4.0, 12.0, 7.0, 10.0, 6.0, -8.0, 9.0, 12.0, 10.0, -16.0, 12.0, 5.0, 8.0, -10.0, 2.0, 11.0, -11.0, 13.0, 2.0, 11.0, 4.0, -2.0, 12.0, 13.0, -14.0, 4.0, 11.0, 5.0, 9.0, -10.0, 12.0, 14.0, -5.0, -6.0, 0.0, 5.0, 9.0, 1.0, 6.0, 11.0, -10.0, 8.0, 6.0, 0.0, 13.0, -4.0, 8.0, -3.0, 4.0, 6.0, 2.0, 11.0, -7.0, 9.0, -9.0, 11.0, 11.0, 2.0, 13.0, 10.0, 5.0, -13.0, 11.0, -1.0, 2.0, 3.0, -2.0, 12.0, -5.0, 10.0, -7.0, 12.0, 6.0, 4.0, 13.0, 7.0, 4.0, -9.0, 4.0, 11.0, 5.0, -5.0, 7.0, 12.0, 8.0, -12.0, -6.0, 13.0, 9.0, -1.0, 13.0, 10.0, 3.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18386127628064466, "mean_inference_ms": 1.0697076913984958, "mean_action_processing_ms": 0.0716996779325027, "mean_env_wait_ms": 0.17440691728620958, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 121176, "agent_timesteps_total": 121176, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68958868.738, "learn_time_ms": 14.2, "learn_throughput": 387877.665, "update_time_ms": 6.187}, "info": {"learner": {"learned": {"policy_loss": 320054951936.0, "vf_loss": 430.072998046875, "total_loss": 320054951936.0, "vf_explained_var": 2.8312206268310547e-05, "model": {}}}, "num_steps_sampled": 121176, "num_agent_steps_sampled": 121176, "num_steps_trained": 121176, "num_agent_steps_trained": 121176}, "done": false, "episodes_total": 2376, "training_iteration": 22, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-32", "timestamp": 1626864452, "time_this_iter_s": 0.36513590812683105, "time_total_s": 8.385915040969849, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1825e400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 8.385915040969849, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 72.9, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 369.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.72222222222222, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 333.0}, "policy_reward_mean": {"learned": 6.930555555555555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 369.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 11.0, 6.0, 7.0, 11.0, -10.0, 1.0, 13.0, 11.0, -16.0, 12.0, 8.0, -7.0, 0.0, 12.0, 10.0, 0.0, 12.0, -2.0, 5.0, 13.0, -5.0, -2.0, 9.0, 10.0, -12.0, 13.0, 4.0, 0.0, 11.0, -2.0, 6.0, -6.0, 12.0, 10.0, -1.0, 5.0, 10.0, -9.0, 9.0, 5.0, -6.0, 12.0, 4.0, -2.0, 11.0, -1.0, 7.0, -12.0, 12.0, 9.0, 6.0, 2.0, 11.0, 7.0, -5.0, 10.0, 319.0, 12.0, 13.0, 8.0, 13.0, 4.0, -10.0, 9.0, 7.0, -6.0, 5.0, 13.0, 3.0, -14.0, 13.0, 7.0, -12.0, 13.0, 7.0, -8.0, 8.0, 10.0, 5.0, -6.0, 13.0, 2.0, 6.0, 3.0, 10.0, -11.0, 13.0, -2.0, -2.0, 11.0, 8.0, -7.0, 4.0, 7.0, 11.0, 3.0, 12.0, -6.0, 6.0, 5.0, 1.0, -4.0, 13.0, 11.0, 333.0, 12.0, 13.0, -1.0, 3.0, 9.0, 4.0, 4.0, 5.0, -5.0, 11.0, 13.0, -20.0, 9.0, 13.0, 11.0, -19.0, 10.0, 13.0, 6.0, 2.0, -1.0, 8.0, -15.0, 14.0, 5.0, 11.0, 8.0, -7.0, 1.0, 13.0, -9.0, 7.0, 9.0, 8.0, -5.0, 3.0, 6.0, 11.0, 8.0, 5.0, 6.0, -4.0, 14.0, 1.0, 5.0, -5.0, 12.0, -21.0, 11.0, 13.0, -2.0, 1.0, 10.0, 6.0, 7.0, 6.0, 9.0, -7.0, 5.0, -7.0, 8.0, 9.0, -16.0, 11.0, 12.0, 8.0, -2.0, -1.0, 12.0, 6.0, -7.0, 11.0, 0.0, 11.0, 14.0, -16.0, 8.0, 9.0, -3.0, 9.0, 5.0, 4.0, 11.0, 3.0, -2.0, 3.0, 9.0, 13.0, -4.0, -3.0, 9.0, 7.0, -6.0, 5.0, 6.0, -9.0, 9.0, 9.0, -8.0, 13.0, 4.0, 6.0, 4.0, 12.0, -4.0, 3.0, 5.0, -9.0, 6.0, 13.0, 3.0, -2.0, 4.0, 10.0, 0.0, 7.0, 7.0, 1.0, -12.0, 14.0, 6.0, 7.0, 14.0, -7.0, -5.0, 13.0, 8.0, -6.0, 9.0, 4.0, 6.0, -2.0, -1.0, 12.0, -11.0, 14.0, 8.0, 4.0, 9.0, -7.0, 0.0, 13.0, -1.0, -5.0, 13.0, 8.0, 6.0, 11.0, 7.0, -9.0, -13.0, 14.0, 8.0, 6.0, 13.0, -6.0, -5.0, 13.0, 11.0, -20.0, 11.0, 13.0, 8.0, 6.0, -11.0, 12.0, -9.0, 14.0, 1.0, 9.0, 13.0, 11.0, 4.0, -13.0, 13.0, -3.0, 2.0, 3.0, -6.0, 11.0, 6.0, 4.0, 14.0, 10.0, -9.0, 0.0, 12.0, -3.0, 10.0, -4.0, 11.0, -20.0, 11.0, 13.0, -7.0, 3.0, 12.0, 7.0, 7.0, 12.0, -8.0, 4.0, 9.0, 2.0, -9.0, 13.0, 11.0, -9.0, 9.0, 4.0, 11.0, 3.0, -3.0, 4.0, -6.0, 14.0, 4.0, 3.0, 14.0, -8.0, 12.0, -3.0, 3.0, -4.0, 12.0, 4.0, 13.0, 6.0, -11.0, 7.0, -17.0, 13.0, 8.0, 11.0, 8.0, 8.0, -10.0, 9.0, 5.0, -11.0, 11.0, 10.0, 8.0, 7.0, 7.0, -7.0, -11.0, 12.0, 6.0, 8.0, 8.0, 10.0, -13.0, 10.0, 2.0, -4.0, 5.0, 12.0, -8.0, 7.0, 11.0, 5.0, 4.0, 14.0, -7.0, 4.0, 11.0, 10.0, 3.0, -9.0, -8.0, 3.0, 12.0, 8.0, -1.0, 1.0, 11.0, 4.0, -9.0, 12.0, 9.0, 3.0, 13.0, 9.0, 4.0, -11.0, 12.0, 317.0, 13.0, 13.0, 7.0, 5.0, -2.0, 5.0, -7.0, 9.0, 6.0, 7.0, 12.0, 320.0, 11.0, 13.0, 11.0, -13.0, 8.0, 9.0, 13.0, 11.0, -6.0, -3.0, -6.0, 6.0, 6.0, 9.0, 9.0, 11.0, -2.0, -3.0, -10.0, 10.0, 11.0, 4.0, 8.0, 12.0, -9.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18384981956577973, "mean_inference_ms": 1.0696233879189487, "mean_action_processing_ms": 0.07166781654541252, "mean_env_wait_ms": 0.17442610371620942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 126684, "agent_timesteps_total": 126684, "timers": {"sample_time_ms": 0.086, "sample_throughput": 64070426.196, "learn_time_ms": 14.874, "learn_throughput": 370300.386, "update_time_ms": 6.599}, "info": {"learner": {"learned": {"policy_loss": 120815157248.0, "vf_loss": 132.8706512451172, "total_loss": 120815157248.0, "vf_explained_var": -0.00011789798736572266, "model": {}}}, "num_steps_sampled": 126684, "num_agent_steps_sampled": 126684, "num_steps_trained": 126684, "num_agent_steps_trained": 126684}, "done": false, "episodes_total": 2484, "training_iteration": 23, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-32", "timestamp": 1626864452, "time_this_iter_s": 0.3741872310638428, "time_total_s": 8.760102272033691, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1825e510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 8.760102272033691, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 77.3, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 8.0, -2.0, 5.0, 14.0, 8.0, 11.0, -18.0, -4.0, 8.0, 1.0, 10.0, -2.0, 11.0, 12.0, -6.0, -16.0, 9.0, 10.0, 12.0, 14.0, 8.0, 7.0, -14.0, -5.0, 8.0, 0.0, 12.0, -16.0, 14.0, 5.0, 12.0, 2.0, 9.0, 11.0, -7.0, 13.0, -8.0, 6.0, 4.0, -3.0, 4.0, 2.0, 12.0, 12.0, -4.0, 12.0, -5.0, -1.0, 12.0, -2.0, 6.0, -1.0, 13.0, 10.0, -7.0, -11.0, 8.0, 5.0, 13.0, -2.0, 11.0, -5.0, 11.0, 4.0, 11.0, -2.0, 2.0, 12.0, 8.0, -10.0, 5.0, -2.0, 2.0, 3.0, 12.0, 11.0, 0.0, 10.0, -6.0, 6.0, 7.0, -6.0, 8.0, 14.0, 11.0, -4.0, -6.0, 0.0, 7.0, -4.0, 12.0, -14.0, 12.0, 6.0, 11.0, 4.0, 8.0, -2.0, 5.0, 12.0, 8.0, -15.0, 10.0, -2.0, 8.0, -2.0, 11.0, 9.0, -10.0, 4.0, 12.0, 1.0, -2.0, 8.0, 8.0, -6.0, 8.0, 9.0, 4.0, -1.0, 9.0, 0.0, 7.0, 7.0, 7.0, -5.0, 6.0, -9.0, 7.0, 10.0, 7.0, -7.0, 7.0, 4.0, 11.0, -2.0, 5.0, 2.0, 10.0, -13.0, 10.0, 8.0, 10.0, 2.0, 12.0, -4.0, 5.0, -3.0, 8.0, 11.0, -1.0, -2.0, 10.0, -4.0, 11.0, -3.0, 12.0, 11.0, -5.0, 7.0, 14.0, -6.0, 0.0, -1.0, 13.0, -1.0, 4.0, 12.0, 8.0, 2.0, -7.0, -7.0, 12.0, 8.0, 2.0, 4.0, 9.0, -10.0, 12.0, 14.0, 2.0, 11.0, -12.0, -2.0, 12.0, -3.0, 8.0, 10.0, -1.0, 10.0, -4.0, -15.0, 11.0, 12.0, 7.0, -11.0, 8.0, 9.0, 9.0, -8.0, 14.0, 2.0, 7.0, 2.0, 9.0, 6.0, -2.0, 7.0, 13.0, 4.0, -9.0, 14.0, 12.0, 6.0, -17.0, -5.0, 1.0, 6.0, 13.0, 4.0, 1.0, -2.0, 12.0, 2.0, 8.0, -2.0, 7.0, 13.0, -6.0, 11.0, -3.0, -3.0, 9.0, -2.0, 11.0, 3.0, 10.0, 10.0, -8.0, 1.0, 11.0, -4.0, 7.0, 14.0, -5.0, 3.0, 3.0, -1.0, -1.0, 4.0, 13.0, -9.0, 1.0, 12.0, 11.0, -19.0, 13.0, 9.0, 12.0, -1.0, 9.0, 12.0, -5.0, -2.0, 6.0, 4.0, 7.0, 12.0, 11.0, -2.0, -6.0, 1.0, 9.0, -3.0, 8.0, 0.0, 1.0, 11.0, 3.0, 11.0, 5.0, 4.0, -5.0, -18.0, 9.0, 12.0, 12.0, -1.0, 12.0, -3.0, 7.0, -3.0, 12.0, 5.0, 1.0, 12.0, 10.0, -1.0, -6.0, -6.0, 1.0, 9.0, 11.0, -2.0, 6.0, 3.0, 8.0, 12.0, 13.0, -14.0, 4.0, 12.0, 8.0, -15.0, 10.0, -3.0, -4.0, 12.0, 10.0, -2.0, 12.0, 11.0, -6.0, 14.0, 12.0, -21.0, 10.0, -5.0, 5.0, 3.0, 12.0, -11.0, 11.0, 4.0, 11.0, 6.0, 5.0, -2.0, 6.0, 0.0, 6.0, -2.0, 11.0, 11.0, 3.0, 4.0, -3.0, 5.0, -2.0, 5.0, 7.0, -1.0, -6.0, 10.0, 12.0, 11.0, 12.0, -13.0, 5.0, -3.0, 10.0, 2.0, 6.0, -1.0, 10.0, -2.0, 8.0, 7.0, -12.0, 12.0, 8.0, 14.0, 7.0, -11.0, 5.0, -2.0, 8.0, -3.0, 12.0, -1.0, 10.0, 11.0, -5.0, -14.0, 11.0, 11.0, 7.0, 14.0, 8.0, -14.0, 7.0, 5.0, 8.0, 5.0, -3.0, 2.0, -2.0, 8.0, 7.0, 7.0, 5.0, -8.0, 11.0, 0.0, 3.0, 6.0, 6.0, 8.0, 6.0, 3.0, -2.0, -11.0, 10.0, 7.0, 9.0, 6.0, 9.0, -3.0, 3.0, 12.0, 0.0, -10.0, 13.0, -2.0, 8.0, -3.0, 12.0, 12.0, -2.0, 11.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18401490672682938, "mean_inference_ms": 1.0699679096906767, "mean_action_processing_ms": 0.07168625413757045, "mean_env_wait_ms": 0.17451922625332794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 132192, "agent_timesteps_total": 132192, "timers": {"sample_time_ms": 0.085, "sample_throughput": 65098072.471, "learn_time_ms": 14.34, "learn_throughput": 384110.76, "update_time_ms": 6.129}, "info": {"learner": {"learned": {"policy_loss": 255523815424.0, "vf_loss": 242.73509216308594, "total_loss": 255523815424.0, "vf_explained_var": -0.00017082691192626953, "model": {}}}, "num_steps_sampled": 132192, "num_agent_steps_sampled": 132192, "num_steps_trained": 132192, "num_agent_steps_trained": 132192}, "done": false, "episodes_total": 2592, "training_iteration": 24, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-33", "timestamp": 1626864453, "time_this_iter_s": 0.35263681411743164, "time_total_s": 9.112739086151123, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 9.112739086151123, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.00925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.752314814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 9.0, -2.0, -1.0, -4.0, 5.0, 12.0, 2.0, -10.0, 13.0, 0.0, 12.0, -12.0, 12.0, 9.0, 6.0, 8.0, 10.0, 9.0, -12.0, 4.0, 11.0, -12.0, 12.0, -10.0, 14.0, -1.0, 12.0, 1.0, 13.0, 11.0, -10.0, -7.0, 11.0, 7.0, 4.0, 1.0, 7.0, -5.0, 12.0, 6.0, 9.0, -13.0, 13.0, 6.0, 13.0, 6.0, -10.0, 14.0, 4.0, 10.0, -13.0, 5.0, 7.0, 4.0, -1.0, -6.0, 12.0, -3.0, 12.0, 12.0, 13.0, -10.0, 0.0, 13.0, 12.0, -9.0, -1.0, 8.0, 6.0, 3.0, -2.0, 7.0, 8.0, 1.0, -1.0, 0.0, 12.0, -9.0, 12.0, 1.0, 9.0, 11.0, -6.0, 6.0, 9.0, 8.0, -8.0, 10.0, 9.0, -12.0, 8.0, -1.0, 13.0, 10.0, -7.0, 13.0, 6.0, -12.0, 8.0, 2.0, -3.0, 3.0, 13.0, 8.0, 11.0, -16.0, 12.0, 5.0, 9.0, -4.0, 5.0, 13.0, 0.0, 9.0, -7.0, 5.0, 11.0, 2.0, -3.0, -5.0, 7.0, 5.0, 8.0, -1.0, 12.0, -3.0, 7.0, 14.0, 5.0, 10.0, -14.0, 6.0, -4.0, 8.0, 5.0, -4.0, 11.0, 0.0, 8.0, -14.0, 14.0, 9.0, 6.0, -6.0, 10.0, 0.0, 11.0, 11.0, -10.0, 8.0, 6.0, 5.0, 7.0, -10.0, 13.0, -14.0, 12.0, 10.0, 7.0, -14.0, 12.0, 10.0, 7.0, 9.0, 7.0, 5.0, -6.0, -11.0, 13.0, 3.0, 10.0, 12.0, 7.0, 5.0, -9.0, 7.0, 6.0, 7.0, -5.0, 8.0, -6.0, 11.0, 2.0, 8.0, 13.0, 8.0, -14.0, 7.0, 8.0, -10.0, 10.0, -2.0, 12.0, 2.0, 4.0, -3.0, 5.0, 1.0, 12.0, 3.0, 12.0, -13.0, 13.0, -1.0, 14.0, -10.0, 12.0, 2.0, 6.0, 8.0, -1.0, 9.0, -7.0, 8.0, 5.0, 5.0, 10.0, -8.0, 8.0, 0.0, 13.0, -3.0, 5.0, 10.0, 11.0, -11.0, 5.0, 2.0, -6.0, 7.0, 12.0, -14.0, 11.0, 5.0, 13.0, 1.0, 13.0, -4.0, 5.0, 13.0, 12.0, -13.0, 3.0, 12.0, -7.0, 10.0, 0.0, 9.0, 6.0, -8.0, 8.0, 3.0, 12.0, -11.0, 11.0, -5.0, 11.0, -1.0, 10.0, 9.0, -8.0, 9.0, 5.0, -12.0, 12.0, 12.0, 3.0, 0.0, 11.0, -5.0, 9.0, 13.0, 5.0, -2.0, -1.0, 12.0, 3.0, 4.0, -4.0, -8.0, 13.0, 5.0, 5.0, 6.0, 13.0, -4.0, 0.0, 13.0, 6.0, -15.0, 11.0, 3.0, 7.0, -6.0, 11.0, 10.0, 11.0, -19.0, 13.0, 4.0, 13.0, -8.0, 6.0, 7.0, 11.0, 0.0, -3.0, 6.0, 8.0, 3.0, -2.0, 10.0, 13.0, -8.0, 0.0, 4.0, 13.0, -6.0, 4.0, 13.0, 8.0, 4.0, -10.0, 5.0, -3.0, 5.0, 8.0, 4.0, 9.0, 3.0, -1.0, -1.0, 14.0, -3.0, 5.0, 14.0, 6.0, 8.0, -13.0, 8.0, 7.0, 7.0, -7.0, -6.0, 12.0, 2.0, 7.0, 0.0, 11.0, -3.0, 7.0, 10.0, 7.0, -8.0, 6.0, 10.0, 11.0, 7.0, -13.0, -3.0, 14.0, -9.0, 13.0, -11.0, 14.0, 7.0, 5.0, 0.0, 11.0, 5.0, -1.0, 13.0, -9.0, 8.0, 3.0, -2.0, 9.0, 1.0, 7.0, 1.0, 13.0, -6.0, 7.0, 7.0, 11.0, -11.0, 8.0, 5.0, 7.0, -9.0, 12.0, -9.0, 13.0, -1.0, 12.0, 1.0, 13.0, -3.0, 4.0, 7.0, 13.0, -7.0, 2.0, 9.0, 13.0, -12.0, 5.0, 2.0, 12.0, -12.0, 13.0, 2.0, 14.0, -8.0, 7.0, 6.0, 11.0, 9.0, -11.0, 9.0, 2.0, -6.0, 10.0, 3.0, 12.0, -13.0, 13.0, 0.0, 13.0, 9.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18411422306052405, "mean_inference_ms": 1.0699260363539709, "mean_action_processing_ms": 0.0716540954478389, "mean_env_wait_ms": 0.17462979533119127, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 137700, "agent_timesteps_total": 137700, "timers": {"sample_time_ms": 0.085, "sample_throughput": 65079381.936, "learn_time_ms": 14.365, "learn_throughput": 383442.625, "update_time_ms": 6.314}, "info": {"learner": {"learned": {"policy_loss": 120252252160.0, "vf_loss": 132.84390258789062, "total_loss": 120252252160.0, "vf_explained_var": -0.00013136863708496094, "model": {}}}, "num_steps_sampled": 137700, "num_agent_steps_sampled": 137700, "num_steps_trained": 137700, "num_agent_steps_trained": 137700}, "done": false, "episodes_total": 2700, "training_iteration": 25, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-33", "timestamp": 1626864453, "time_this_iter_s": 0.36913561820983887, "time_total_s": 9.481874704360962, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 9.481874704360962, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 79.8, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 13.0, 4.0, -7.0, 13.0, 12.0, -1.0, -9.0, 11.0, -15.0, 11.0, 8.0, 11.0, 9.0, -13.0, 8.0, 2.0, 0.0, 4.0, 9.0, 13.0, 5.0, -15.0, 12.0, -6.0, 5.0, 8.0, 8.0, 5.0, 14.0, -16.0, 12.0, -3.0, -3.0, 10.0, 11.0, 13.0, 9.0, -16.0, 9.0, 9.0, -11.0, 10.0, 7.0, 2.0, 9.0, -7.0, 11.0, 2.0, 8.0, 9.0, -4.0, 13.0, 3.0, -4.0, 3.0, 13.0, -13.0, 12.0, 3.0, 11.0, 9.0, 6.0, -11.0, 0.0, 8.0, -5.0, 12.0, 11.0, 5.0, 11.0, -12.0, 9.0, -13.0, 6.0, 13.0, 11.0, 3.0, 12.0, -11.0, -3.0, 11.0, -4.0, 11.0, 11.0, 9.0, 12.0, -17.0, 8.0, -10.0, 6.0, 11.0, 12.0, 4.0, 11.0, -12.0, 0.0, -1.0, 11.0, 5.0, 0.0, 8.0, -4.0, 11.0, 2.0, -4.0, 7.0, 10.0, 3.0, 14.0, -10.0, 8.0, 3.0, 12.0, -10.0, 10.0, 11.0, 10.0, -4.0, -2.0, 9.0, -11.0, 13.0, 4.0, 1.0, 14.0, -7.0, 7.0, -2.0, 0.0, 10.0, 7.0, -1.0, 8.0, 8.0, 0.0, 8.0, 0.0, -6.0, 13.0, 11.0, 8.0, 8.0, -12.0, 7.0, -5.0, 11.0, 2.0, 12.0, 14.0, -18.0, 7.0, 9.0, -13.0, 7.0, 12.0, 12.0, 6.0, -11.0, 8.0, 4.0, 14.0, 7.0, -10.0, 12.0, 12.0, -20.0, 11.0, 9.0, -14.0, 13.0, 7.0, 12.0, 12.0, 6.0, -15.0, 7.0, -1.0, -3.0, 12.0, 13.0, 6.0, 10.0, -14.0, 12.0, -8.0, 6.0, 5.0, -2.0, 9.0, 8.0, 0.0, -5.0, -2.0, 11.0, 11.0, 11.0, 9.0, 2.0, -7.0, 11.0, -8.0, 6.0, 6.0, -9.0, 13.0, 8.0, 3.0, 0.0, 14.0, -7.0, 8.0, 13.0, 9.0, -8.0, 1.0, 7.0, -9.0, 5.0, 12.0, 12.0, 2.0, 13.0, -12.0, 4.0, -1.0, 0.0, 12.0, 12.0, 5.0, 7.0, -9.0, 8.0, -19.0, 13.0, 13.0, 1.0, 8.0, -6.0, 12.0, -1.0, 11.0, 7.0, -2.0, 13.0, -6.0, 12.0, -4.0, 10.0, -8.0, 7.0, 6.0, 12.0, 10.0, -13.0, 6.0, 7.0, 14.0, 8.0, -14.0, 12.0, 7.0, 3.0, -7.0, 10.0, -9.0, 1.0, 13.0, -4.0, 13.0, -1.0, 7.0, 6.0, -3.0, 7.0, 5.0, 12.0, 8.0, -13.0, 8.0, 10.0, -8.0, 6.0, 7.0, -15.0, 14.0, 11.0, 5.0, -6.0, 0.0, 11.0, 10.0, 12.0, 13.0, 1.0, -11.0, 10.0, -14.0, 8.0, 11.0, 1.0, 13.0, -12.0, 13.0, 5.0, -1.0, 5.0, 6.0, 10.0, 13.0, 0.0, -8.0, 8.0, -14.0, 13.0, 8.0, 11.0, 13.0, 3.0, -12.0, 5.0, 13.0, 6.0, -9.0, 13.0, 6.0, 3.0, -7.0, 9.0, -9.0, 7.0, 8.0, 7.0, 10.0, 8.0, -10.0, -4.0, -1.0, 8.0, 12.0, 9.0, 10.0, 10.0, -14.0, 13.0, -6.0, 6.0, 2.0, 3.0, 13.0, 7.0, -8.0, 8.0, -1.0, 1.0, 7.0, 10.0, 11.0, -8.0, 2.0, 9.0, -9.0, 4.0, 11.0, 13.0, 8.0, -13.0, 7.0, -4.0, 0.0, 10.0, 9.0, 13.0, 6.0, 10.0, -14.0, 10.0, -9.0, 6.0, 8.0, -1.0, 10.0, 3.0, 3.0, 0.0, -6.0, 10.0, 11.0, 12.0, 14.0, 9.0, -20.0, -5.0, 7.0, 7.0, 6.0, 9.0, 8.0, 13.0, -15.0, 3.0, 14.0, 6.0, -8.0, 9.0, 3.0, -3.0, 6.0, 6.0, -9.0, 7.0, 11.0, 0.0, 13.0, 12.0, -10.0, 3.0, 14.0, 8.0, -10.0, 13.0, 9.0, 11.0, -18.0, 10.0, -14.0, 7.0, 12.0, 2.0, 5.0, -5.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1840965616418815, "mean_inference_ms": 1.069191645946736, "mean_action_processing_ms": 0.07161693797376338, "mean_env_wait_ms": 0.17458493619596507, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 143208, "agent_timesteps_total": 143208, "timers": {"sample_time_ms": 0.082, "sample_throughput": 66943287.818, "learn_time_ms": 15.181, "learn_throughput": 362833.511, "update_time_ms": 6.952}, "info": {"learner": {"learned": {"policy_loss": 125996646400.0, "vf_loss": 134.7532958984375, "total_loss": 125996646400.0, "vf_explained_var": -0.00028455257415771484, "model": {}}}, "num_steps_sampled": 143208, "num_agent_steps_sampled": 143208, "num_steps_trained": 143208, "num_agent_steps_trained": 143208}, "done": false, "episodes_total": 2808, "training_iteration": 26, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-34", "timestamp": 1626864454, "time_this_iter_s": 0.45507001876831055, "time_total_s": 9.936944723129272, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1a45e400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 9.936944723129272, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.27777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.319444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -9.0, 1.0, 11.0, 1.0, 5.0, -3.0, 12.0, 13.0, 8.0, -6.0, 0.0, -6.0, 7.0, 12.0, 2.0, 9.0, 3.0, 4.0, -1.0, 6.0, 13.0, -5.0, 1.0, 13.0, 2.0, 11.0, -11.0, 4.0, 11.0, -11.0, 11.0, 11.0, 5.0, -12.0, 11.0, -8.0, 10.0, 10.0, 3.0, 12.0, 4.0, -7.0, 6.0, -3.0, 7.0, 2.0, 9.0, 6.0, 8.0, 8.0, -7.0, 4.0, 11.0, -4.0, 4.0, -3.0, 6.0, 4.0, 8.0, 9.0, 9.0, 12.0, -15.0, 10.0, -12.0, 5.0, 12.0, -2.0, 9.0, -4.0, 12.0, 9.0, 3.0, -5.0, 8.0, -8.0, 6.0, 12.0, 5.0, 11.0, 11.0, -14.0, 7.0, -4.0, -1.0, 12.0, 8.0, 14.0, -11.0, 7.0, 5.0, -1.0, 8.0, -1.0, 9.0, 13.0, -18.0, 8.0, 12.0, 5.0, 7.0, -3.0, 6.0, 13.0, 2.0, -12.0, 12.0, -18.0, 13.0, 10.0, 10.0, 9.0, -10.0, 8.0, 8.0, 0.0, 10.0, -6.0, 11.0, -5.0, 3.0, 6.0, 11.0, 13.0, 5.0, 9.0, -12.0, -9.0, 13.0, 4.0, 7.0, -8.0, 10.0, 7.0, 6.0, 9.0, -2.0, -3.0, 11.0, 1.0, 12.0, 12.0, -10.0, 7.0, -14.0, 10.0, 12.0, -11.0, 13.0, 7.0, 6.0, 14.0, 5.0, 3.0, -7.0, -9.0, 7.0, 6.0, 11.0, 2.0, 4.0, 11.0, -2.0, -15.0, 7.0, 12.0, 11.0, 8.0, 4.0, -2.0, 5.0, -8.0, 6.0, 12.0, 5.0, 10.0, -8.0, 1.0, 12.0, 1.0, 12.0, -3.0, 5.0, 14.0, 1.0, 9.0, -9.0, 2.0, 13.0, -11.0, 11.0, 11.0, -17.0, 13.0, 8.0, -1.0, 7.0, -2.0, 11.0, 13.0, 3.0, 9.0, -10.0, 9.0, 3.0, 11.0, -8.0, 4.0, 13.0, 0.0, -2.0, -2.0, 12.0, -4.0, 9.0, 12.0, 0.0, 12.0, -9.0, 14.0, 6.0, -17.0, 12.0, 8.0, -11.0, 7.0, 11.0, -5.0, 13.0, -3.0, 10.0, 13.0, 0.0, -4.0, 6.0, 9.0, 7.0, 9.0, -10.0, 12.0, -16.0, 8.0, 11.0, 4.0, 13.0, -7.0, 5.0, 13.0, 2.0, -5.0, 5.0, 9.0, 10.0, 7.0, -11.0, 13.0, 317.0, 12.0, 12.0, 5.0, 9.0, 9.0, -8.0, 12.0, 3.0, -2.0, 2.0, 1.0, 9.0, 9.0, -4.0, -7.0, -2.0, 12.0, 12.0, 3.0, -10.0, 11.0, 11.0, 12.0, 6.0, 4.0, -7.0, 0.0, 6.0, 10.0, -1.0, 13.0, -17.0, 11.0, 8.0, -1.0, 6.0, 13.0, -3.0, 14.0, -1.0, 11.0, -9.0, -9.0, 12.0, 10.0, 2.0, 7.0, 8.0, -5.0, 5.0, -10.0, 10.0, 8.0, 7.0, 13.0, -1.0, 12.0, -9.0, -5.0, 7.0, 3.0, 10.0, 12.0, -16.0, 11.0, 8.0, 2.0, 10.0, -3.0, 6.0, 10.0, 7.0, 7.0, -9.0, -4.0, 5.0, 3.0, 11.0, 12.0, -14.0, 6.0, 11.0, 2.0, 6.0, -3.0, 10.0, 14.0, 7.0, 7.0, -13.0, -6.0, 7.0, 2.0, 12.0, -7.0, 5.0, 11.0, 6.0, 7.0, 10.0, 13.0, -15.0, 13.0, 4.0, -6.0, 4.0, 9.0, 6.0, 9.0, -9.0, 12.0, 318.0, 11.0, 13.0, -1.0, 10.0, -5.0, 11.0, 12.0, 7.0, 8.0, -12.0, 9.0, 4.0, 10.0, -8.0, 1.0, 9.0, 6.0, -1.0, 4.0, 7.0, -3.0, 7.0, 12.0, 1.0, 11.0, -9.0, -8.0, 9.0, 8.0, 6.0, 10.0, -18.0, 11.0, 12.0, 4.0, -5.0, 10.0, 6.0, 12.0, -1.0, -3.0, 7.0, 9.0, 7.0, 11.0, -12.0, 11.0, -15.0, 13.0, 6.0, -11.0, 9.0, 10.0, 7.0, 14.0, 1.0, -8.0, 8.0, -14.0, 8.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416341743390496, "mean_inference_ms": 1.068791387625215, "mean_action_processing_ms": 0.07160825236898376, "mean_env_wait_ms": 0.17459934981411726, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 148716, "agent_timesteps_total": 148716, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65246902.969, "learn_time_ms": 15.185, "learn_throughput": 362733.814, "update_time_ms": 6.989}, "info": {"learner": {"learned": {"policy_loss": 1.29990553855896, "vf_loss": 19.49665069580078, "total_loss": 20.79655647277832, "vf_explained_var": -0.001755833625793457, "model": {}}}, "num_steps_sampled": 148716, "num_agent_steps_sampled": 148716, "num_steps_trained": 148716, "num_agent_steps_trained": 148716}, "done": false, "episodes_total": 2916, "training_iteration": 27, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-34", "timestamp": 1626864454, "time_this_iter_s": 0.36002564430236816, "time_total_s": 10.29697036743164, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 10.29697036743164, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 61.5, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.416666666666668, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 330.0}, "policy_reward_mean": {"learned": 5.354166666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 9.0, 12.0, -15.0, -16.0, 12.0, 7.0, 12.0, -9.0, 7.0, 12.0, 5.0, 10.0, 9.0, -14.0, 10.0, 11.0, 13.0, -7.0, -2.0, 11.0, 12.0, -3.0, -5.0, 8.0, 8.0, -10.0, 9.0, 5.0, 13.0, -16.0, 13.0, 8.0, 13.0, -3.0, -3.0, 9.0, 13.0, 323.0, 11.0, 12.0, 6.0, -10.0, 7.0, -10.0, 4.0, 10.0, 11.0, 10.0, 13.0, 12.0, -20.0, -14.0, 14.0, 5.0, 10.0, 4.0, 12.0, 4.0, -5.0, 5.0, 13.0, -13.0, 10.0, 1.0, -4.0, 11.0, 7.0, 5.0, 9.0, 6.0, -5.0, -2.0, 8.0, 12.0, -3.0, 10.0, 9.0, -15.0, 11.0, 11.0, 8.0, -2.0, -2.0, -3.0, 14.0, 8.0, -4.0, 12.0, 8.0, -12.0, 7.0, 7.0, 14.0, -16.0, 10.0, 12.0, 10.0, -2.0, -5.0, 9.0, 13.0, -2.0, -5.0, 12.0, 4.0, -9.0, 8.0, -3.0, 14.0, -5.0, 9.0, 9.0, 10.0, -3.0, -1.0, -19.0, 12.0, 13.0, 9.0, 10.0, 13.0, 4.0, -12.0, 12.0, 2.0, -11.0, 12.0, 12.0, 11.0, -3.0, -5.0, 330.0, 14.0, 13.0, 10.0, 13.0, 13.0, -16.0, 5.0, 8.0, 8.0, -8.0, 7.0, 11.0, 7.0, -3.0, 0.0, -15.0, 12.0, 6.0, 12.0, 4.0, 9.0, 3.0, -1.0, -4.0, 3.0, 10.0, 6.0, 4.0, -6.0, 11.0, 6.0, -15.0, 12.0, 7.0, 11.0, 14.0, 11.0, 7.0, -17.0, -4.0, 2.0, 5.0, 12.0, 8.0, 12.0, -3.0, -2.0, 1.0, -6.0, 12.0, 8.0, 11.0, 7.0, 0.0, -3.0, 6.0, 4.0, -4.0, 9.0, 11.0, 6.0, -4.0, 2.0, 1.0, 9.0, 11.0, -6.0, -9.0, 13.0, 1.0, 10.0, 4.0, 14.0, -12.0, 9.0, 13.0, 8.0, 11.0, -17.0, 5.0, 13.0, -7.0, 4.0, -3.0, 12.0, -1.0, 7.0, 4.0, 9.0, -9.0, 11.0, 11.0, 12.0, -3.0, -5.0, 6.0, -8.0, 7.0, 10.0, 11.0, 7.0, 3.0, -6.0, 11.0, 1.0, -9.0, 12.0, 12.0, 9.0, -3.0, -3.0, -9.0, 8.0, 6.0, 10.0, 12.0, 4.0, -3.0, 2.0, 7.0, 0.0, -4.0, 12.0, 12.0, 8.0, -4.0, -1.0, -1.0, 12.0, 6.0, -2.0, 8.0, 8.0, -2.0, 1.0, -2.0, 13.0, -6.0, 10.0, 5.0, 12.0, -1.0, -1.0, 6.0, 10.0, -12.0, 11.0, 9.0, 6.0, -7.0, 7.0, -4.0, 5.0, 3.0, 11.0, 6.0, -2.0, -2.0, 13.0, 5.0, 12.0, -7.0, 5.0, -5.0, 6.0, 10.0, 4.0, 6.0, 13.0, -13.0, 9.0, 10.0, -5.0, 11.0, -1.0, 10.0, 12.0, -19.0, 12.0, 7.0, 7.0, 7.0, -6.0, -5.0, 13.0, 0.0, 7.0, 9.0, -4.0, -3.0, 13.0, -7.0, 11.0, 8.0, 3.0, 5.0, 12.0, -8.0, 6.0, 9.0, -2.0, -3.0, 11.0, 6.0, 12.0, -11.0, 8.0, -10.0, 14.0, 6.0, 5.0, 6.0, 6.0, -8.0, 11.0, 12.0, 7.0, -8.0, 4.0, 12.0, 9.0, -10.0, 4.0, -14.0, 13.0, 6.0, 10.0, 7.0, 4.0, -8.0, 12.0, -4.0, 5.0, 5.0, 9.0, 9.0, 13.0, -2.0, -5.0, 10.0, 14.0, -16.0, 7.0, 5.0, 7.0, 6.0, -3.0, 11.0, 1.0, -9.0, 12.0, 9.0, 7.0, -3.0, 2.0, 4.0, 11.0, 8.0, -8.0, 7.0, 12.0, -13.0, 9.0, 5.0, 13.0, -9.0, 6.0, 12.0, 13.0, 4.0, -14.0, 1.0, -6.0, 8.0, 12.0, 6.0, 7.0, -2.0, 4.0, 6.0, -8.0, 6.0, 11.0, 11.0, 8.0, -5.0, 1.0, -1.0, 12.0, 8.0, -4.0, 13.0, 10.0, -19.0, 11.0, 3.0, 5.0, -4.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18429213949346024, "mean_inference_ms": 1.068865545530902, "mean_action_processing_ms": 0.07163275088130394, "mean_env_wait_ms": 0.1747305314035172, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 154224, "agent_timesteps_total": 154224, "timers": {"sample_time_ms": 0.085, "sample_throughput": 65111231.818, "learn_time_ms": 15.534, "learn_throughput": 354574.98, "update_time_ms": 7.011}, "info": {"learner": {"learned": {"policy_loss": 1.3848786354064941, "vf_loss": 17.68423843383789, "total_loss": 19.069116592407227, "vf_explained_var": -0.0020352602005004883, "model": {}}}, "num_steps_sampled": 154224, "num_agent_steps_sampled": 154224, "num_steps_trained": 154224, "num_agent_steps_trained": 154224}, "done": false, "episodes_total": 3024, "training_iteration": 28, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-35", "timestamp": 1626864455, "time_this_iter_s": 0.37041592597961426, "time_total_s": 10.667386293411255, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 10.667386293411255, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 86.5, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 8.0, 9.0, -10.0, 10.0, 11.0, 2.0, -8.0, 12.0, 10.0, -12.0, 5.0, 5.0, -9.0, 8.0, 11.0, 5.0, 11.0, -4.0, 3.0, -2.0, 10.0, 4.0, 3.0, 7.0, 10.0, -14.0, 12.0, 8.0, 12.0, 6.0, -11.0, 9.0, 12.0, 9.0, -15.0, 9.0, 12.0, 7.0, -13.0, 13.0, 1.0, -9.0, 10.0, 9.0, -2.0, 4.0, 4.0, 2.0, -4.0, 5.0, 12.0, 11.0, 13.0, -4.0, -5.0, 4.0, 10.0, 7.0, -6.0, 2.0, -8.0, 13.0, 8.0, -7.0, 13.0, 8.0, 1.0, 9.0, 13.0, 2.0, -9.0, 9.0, -7.0, 12.0, 1.0, 7.0, 2.0, 9.0, -3.0, 14.0, 10.0, 3.0, -12.0, 10.0, 13.0, -10.0, 2.0, 9.0, 4.0, 7.0, -5.0, 2.0, 5.0, -3.0, 11.0, -8.0, 14.0, 11.0, -2.0, 9.0, 12.0, -8.0, 2.0, 5.0, -12.0, 12.0, 10.0, 4.0, -1.0, 2.0, 10.0, 8.0, 12.0, 9.0, -14.0, 12.0, 9.0, -17.0, 11.0, 6.0, -3.0, 7.0, 5.0, 8.0, 9.0, -11.0, 9.0, 8.0, -5.0, 12.0, 0.0, 8.0, 12.0, -1.0, -4.0, 2.0, 6.0, -3.0, 10.0, 7.0, 14.0, 4.0, -10.0, 8.0, 10.0, 7.0, -10.0, 10.0, 11.0, 2.0, -8.0, 11.0, 5.0, -2.0, 1.0, 7.0, 12.0, -16.0, 12.0, 9.0, 9.0, 4.0, -7.0, 12.0, 12.0, -5.0, -4.0, 10.0, 6.0, 6.0, -7.0, -3.0, 12.0, 1.0, 5.0, 8.0, -8.0, 5.0, 10.0, 8.0, 9.0, 8.0, -10.0, 5.0, -6.0, 6.0, 10.0, 12.0, 11.0, 6.0, -14.0, 4.0, 10.0, 7.0, -6.0, 12.0, 13.0, -5.0, -5.0, 8.0, 11.0, 7.0, -11.0, 8.0, 12.0, -10.0, 5.0, 1.0, 13.0, -8.0, 9.0, 11.0, 12.0, -16.0, 8.0, 4.0, -6.0, 11.0, 6.0, 13.0, 7.0, -10.0, 5.0, 4.0, 12.0, 11.0, -12.0, 9.0, 12.0, 3.0, -9.0, 6.0, -6.0, 13.0, 2.0, 6.0, -2.0, -2.0, 13.0, 10.0, 3.0, 10.0, -8.0, 10.0, 13.0, 2.0, -10.0, 10.0, -18.0, 12.0, 11.0, 7.0, -1.0, 3.0, 6.0, 7.0, 8.0, 11.0, -11.0, 11.0, 11.0, 8.0, -15.0, 6.0, 9.0, 4.0, -4.0, 7.0, -7.0, 11.0, 4.0, 10.0, -6.0, 7.0, 4.0, 10.0, 7.0, 7.0, -9.0, 3.0, -10.0, 10.0, 12.0, -8.0, 7.0, 9.0, 7.0, 5.0, 11.0, 10.0, -11.0, 9.0, 12.0, -10.0, 4.0, 11.0, -4.0, 7.0, 1.0, 7.0, 8.0, 12.0, -12.0, 3.0, 4.0, -3.0, 11.0, -3.0, 12.0, 1.0, 5.0, 6.0, -5.0, 11.0, 3.0, 12.0, 6.0, -12.0, 9.0, 4.0, 12.0, 8.0, -9.0, 12.0, 12.0, -1.0, -8.0, 3.0, -5.0, 7.0, 10.0, 13.0, 4.0, 1.0, -3.0, -3.0, 11.0, -3.0, 10.0, 9.0, 9.0, -11.0, 8.0, 8.0, -8.0, 6.0, 9.0, 9.0, -9.0, 8.0, 7.0, 9.0, 7.0, 9.0, -10.0, 12.0, 12.0, 1.0, -10.0, -1.0, -5.0, 11.0, 10.0, 7.0, 11.0, -12.0, 9.0, 9.0, -8.0, 7.0, 7.0, -3.0, 12.0, 3.0, 3.0, 3.0, -6.0, 11.0, 7.0, 8.0, 12.0, 10.0, -15.0, 4.0, 11.0, -9.0, 9.0, 11.0, 10.0, 1.0, -7.0, 6.0, -3.0, 5.0, 7.0, 3.0, 9.0, -5.0, 8.0, 4.0, 10.0, -6.0, 7.0, 7.0, 12.0, -8.0, 4.0, 7.0, -5.0, 7.0, 6.0, -4.0, 12.0, 12.0, -5.0, 5.0, -3.0, 6.0, 7.0, -5.0, 13.0, 4.0, 3.0, 13.0, -6.0, -4.0, 12.0, 13.0, -9.0, 6.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18432099474492045, "mean_inference_ms": 1.0695250616846712, "mean_action_processing_ms": 0.07162686793646977, "mean_env_wait_ms": 0.17476778035947102, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 159732, "agent_timesteps_total": 159732, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65845156.345, "learn_time_ms": 15.827, "learn_throughput": 348003.188, "update_time_ms": 6.752}, "info": {"learner": {"learned": {"policy_loss": 1.3249284029006958, "vf_loss": 20.351369857788086, "total_loss": 21.676298141479492, "vf_explained_var": -0.0017197132110595703, "model": {}}}, "num_steps_sampled": 159732, "num_agent_steps_sampled": 159732, "num_steps_trained": 159732, "num_agent_steps_trained": 159732}, "done": false, "episodes_total": 3132, "training_iteration": 29, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-35", "timestamp": 1626864455, "time_this_iter_s": 0.36443233489990234, "time_total_s": 11.031818628311157, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 11.031818628311157, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -5.0, 7.0, 6.0, 8.0, -5.0, 7.0, 5.0, -8.0, 8.0, 11.0, 4.0, -8.0, 8.0, 8.0, 7.0, 320.0, 12.0, 11.0, 12.0, 3.0, 12.0, 3.0, -3.0, 9.0, -4.0, -3.0, 13.0, 3.0, 11.0, 6.0, -5.0, -1.0, 11.0, 12.0, -7.0, -8.0, 0.0, 12.0, 11.0, 10.0, -9.0, 5.0, 9.0, 8.0, -14.0, 10.0, 11.0, 8.0, -6.0, 0.0, 13.0, 2.0, 9.0, 11.0, -7.0, -5.0, 8.0, 8.0, 4.0, 3.0, 3.0, 13.0, -4.0, 5.0, 8.0, -9.0, 11.0, 14.0, 1.0, -9.0, 9.0, 11.0, -16.0, 7.0, 13.0, 7.0, 1.0, 13.0, -6.0, 10.0, 6.0, 5.0, -6.0, 12.0, 4.0, -10.0, 9.0, 5.0, 13.0, 8.0, -11.0, 6.0, 1.0, 12.0, -4.0, -16.0, 7.0, 12.0, 12.0, 13.0, -10.0, 10.0, 2.0, -4.0, 3.0, 11.0, 5.0, 6.0, 5.0, 5.0, -1.0, 8.0, -4.0, 4.0, 7.0, 14.0, 1.0, 9.0, -9.0, -1.0, 10.0, -4.0, 10.0, -7.0, 8.0, 9.0, 5.0, 4.0, 7.0, -7.0, 11.0, -7.0, 7.0, 11.0, 4.0, -9.0, 4.0, 7.0, 13.0, -5.0, 4.0, 8.0, 8.0, 11.0, 11.0, 4.0, -11.0, 7.0, 12.0, 10.0, -14.0, 10.0, 8.0, 8.0, -11.0, 7.0, -10.0, 11.0, 7.0, 3.0, 11.0, -6.0, 7.0, 14.0, -14.0, 6.0, 9.0, 11.0, -14.0, 7.0, 11.0, -8.0, 6.0, 9.0, 8.0, 8.0, 9.0, 0.0, -2.0, 9.0, 7.0, -6.0, 5.0, 13.0, -12.0, 7.0, 7.0, 6.0, 6.0, 8.0, -5.0, 4.0, 11.0, 8.0, -8.0, 4.0, 13.0, 5.0, -7.0, 11.0, 13.0, -14.0, 5.0, 8.0, -11.0, 8.0, 10.0, 12.0, 9.0, 1.0, -7.0, -5.0, 7.0, 1.0, 12.0, -10.0, 13.0, 7.0, 5.0, 7.0, -8.0, 8.0, 8.0, 3.0, -3.0, 4.0, 11.0, 14.0, 6.0, -7.0, 2.0, 12.0, 10.0, 9.0, -16.0, 9.0, 8.0, 9.0, -11.0, 12.0, 1.0, -11.0, 13.0, -5.0, 13.0, 2.0, 5.0, 9.0, 3.0, 11.0, -8.0, -9.0, 1.0, 12.0, 11.0, -11.0, 8.0, 8.0, 10.0, 3.0, 12.0, 10.0, -10.0, 10.0, 9.0, -9.0, 5.0, 7.0, -3.0, 4.0, 7.0, 8.0, 9.0, 7.0, -9.0, 10.0, 7.0, -12.0, 10.0, 10.0, -10.0, 7.0, 8.0, 8.0, -13.0, 7.0, 13.0, 3.0, 10.0, 12.0, -10.0, 13.0, 7.0, -8.0, 3.0, 8.0, -5.0, 9.0, 3.0, -6.0, 6.0, 4.0, 11.0, 7.0, 11.0, 3.0, -6.0, -9.0, 10.0, 1.0, 13.0, -8.0, 7.0, 6.0, 10.0, -5.0, 1.0, 9.0, 10.0, 0.0, 9.0, 8.0, -2.0, 8.0, -6.0, 4.0, 9.0, 14.0, -14.0, 10.0, 5.0, 7.0, -12.0, 12.0, 8.0, 4.0, 8.0, -2.0, 5.0, 8.0, 7.0, -11.0, 11.0, 4.0, 13.0, -9.0, 7.0, 12.0, -13.0, 8.0, 8.0, 8.0, 6.0, -6.0, 7.0, 4.0, 13.0, -11.0, 9.0, 6.0, 6.0, 13.0, -10.0, 7.0, 2.0, 12.0, -6.0, 5.0, 11.0, 0.0, -1.0, 9.0, 10.0, -13.0, 9.0, 9.0, 7.0, -9.0, 8.0, 6.0, -8.0, 8.0, 9.0, 8.0, -4.0, 5.0, 6.0, 7.0, 9.0, -11.0, 10.0, 9.0, -6.0, 9.0, 3.0, -13.0, 5.0, 13.0, 10.0, 6.0, 9.0, 4.0, -4.0, -5.0, 12.0, -4.0, 12.0, -2.0, 7.0, 1.0, 9.0, -13.0, 10.0, 5.0, 13.0, 4.0, 11.0, 6.0, -6.0, 13.0, 7.0, -11.0, 6.0, -8.0, 7.0, 7.0, 9.0, 8.0, 5.0, 9.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.184388601485714, "mean_inference_ms": 1.069421102906769, "mean_action_processing_ms": 0.07164325455708043, "mean_env_wait_ms": 0.1747681051886709, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 165240, "agent_timesteps_total": 165240, "timers": {"sample_time_ms": 0.082, "sample_throughput": 67304931.119, "learn_time_ms": 15.651, "learn_throughput": 351931.498, "update_time_ms": 6.601}, "info": {"learner": {"learned": {"policy_loss": 312855855104.0, "vf_loss": 429.839599609375, "total_loss": 312855855104.0, "vf_explained_var": 3.7550926208496094e-05, "model": {}}}, "num_steps_sampled": 165240, "num_agent_steps_sampled": 165240, "num_steps_trained": 165240, "num_agent_steps_trained": 165240}, "done": false, "episodes_total": 3240, "training_iteration": 30, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-35", "timestamp": 1626864455, "time_this_iter_s": 0.3562781810760498, "time_total_s": 11.388096809387207, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a183469d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 11.388096809387207, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 73.8, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 5.0, -9.0, 8.0, 14.0, 7.0, -3.0, -3.0, 8.0, 9.0, 3.0, -5.0, 14.0, 11.0, -18.0, 8.0, 9.0, 5.0, 12.0, -11.0, 14.0, 4.0, -1.0, -2.0, 13.0, 12.0, -15.0, 5.0, 13.0, 14.0, 8.0, -20.0, 7.0, 7.0, -11.0, 12.0, 11.0, 10.0, -3.0, -3.0, 9.0, 6.0, -11.0, 11.0, 11.0, 10.0, -7.0, 1.0, 7.0, 3.0, -4.0, 9.0, 13.0, -10.0, 10.0, 2.0, 8.0, 14.0, -10.0, 3.0, 0.0, -6.0, 11.0, 10.0, 10.0, -5.0, -1.0, 11.0, 10.0, -7.0, 11.0, 1.0, 3.0, 13.0, 3.0, -4.0, 13.0, 11.0, 1.0, -10.0, 6.0, 10.0, 7.0, -8.0, 11.0, 12.0, -7.0, -1.0, -9.0, 13.0, 2.0, 9.0, 12.0, 3.0, 5.0, -5.0, 7.0, -1.0, 11.0, -2.0, 13.0, -11.0, 11.0, 2.0, 13.0, 6.0, 4.0, -8.0, 11.0, -3.0, 12.0, -5.0, 2.0, 13.0, -10.0, 10.0, 13.0, -7.0, 11.0, -2.0, 13.0, 12.0, 6.0, -16.0, -1.0, 2.0, 10.0, 4.0, 6.0, 5.0, -4.0, 8.0, 14.0, -9.0, 12.0, -2.0, 8.0, -10.0, 5.0, 12.0, 0.0, 13.0, 10.0, -8.0, 7.0, 6.0, -4.0, 6.0, 13.0, -10.0, 12.0, 0.0, 3.0, -4.0, 9.0, 7.0, 9.0, 6.0, 6.0, -6.0, 7.0, 7.0, -8.0, 9.0, 14.0, 12.0, -2.0, -9.0, 11.0, 12.0, -7.0, -1.0, 11.0, 10.0, 8.0, -14.0, 3.0, 11.0, -11.0, 12.0, 14.0, 7.0, -6.0, 0.0, -6.0, 12.0, -1.0, 10.0, 10.0, 11.0, -1.0, -5.0, 3.0, 6.0, -3.0, 9.0, 14.0, -8.0, 10.0, -1.0, -9.0, 12.0, 0.0, 12.0, 13.0, 13.0, 9.0, -20.0, 5.0, 9.0, 7.0, -6.0, 11.0, -18.0, 13.0, 9.0, -5.0, 13.0, 5.0, 2.0, -1.0, 12.0, -3.0, 7.0, 4.0, 10.0, -11.0, 12.0, 14.0, -4.0, 9.0, -4.0, 8.0, 13.0, -15.0, 9.0, 10.0, 10.0, 8.0, -13.0, 2.0, 4.0, 11.0, -2.0, 12.0, 12.0, 4.0, -13.0, 9.0, -12.0, 5.0, 13.0, -5.0, 9.0, 4.0, 7.0, 12.0, -8.0, 12.0, -1.0, 12.0, -4.0, 10.0, -3.0, -4.0, 3.0, 6.0, 10.0, 11.0, 12.0, 9.0, -17.0, 9.0, 7.0, 8.0, -9.0, 14.0, -12.0, 10.0, 3.0, 8.0, 9.0, -7.0, 5.0, 13.0, 4.0, 0.0, -2.0, 8.0, 5.0, 8.0, -6.0, 9.0, -5.0, 12.0, -1.0, 2.0, 12.0, -8.0, 9.0, -2.0, 10.0, 7.0, 0.0, 10.0, -4.0, -3.0, 12.0, 12.0, 8.0, -3.0, -2.0, 8.0, -5.0, 5.0, 7.0, 13.0, 11.0, 8.0, -17.0, 11.0, -3.0, -2.0, 9.0, 14.0, -8.0, 8.0, 1.0, 9.0, 11.0, 2.0, -7.0, 11.0, 10.0, 0.0, -6.0, -2.0, 11.0, 7.0, -1.0, 14.0, 10.0, -8.0, -1.0, 5.0, 12.0, 5.0, -7.0, 12.0, 12.0, -16.0, 7.0, 13.0, 0.0, -1.0, 3.0, 12.0, -11.0, 11.0, 3.0, 13.0, 12.0, 1.0, -11.0, 13.0, -7.0, 7.0, 2.0, 13.0, 2.0, 2.0, -2.0, 14.0, 6.0, 7.0, -12.0, 9.0, 0.0, -5.0, 11.0, 14.0, -1.0, 0.0, 2.0, 9.0, 0.0, 12.0, -6.0, 14.0, 9.0, -3.0, -5.0, 10.0, 7.0, -11.0, 9.0, 12.0, 10.0, 8.0, -15.0, 13.0, -6.0, 11.0, -3.0, 14.0, 6.0, -5.0, 0.0, 6.0, 12.0, 6.0, -9.0, 12.0, 3.0, 5.0, -5.0, 13.0, -2.0, -1.0, 5.0, 13.0, 3.0, -3.0, 2.0, 8.0, 12.0, 11.0, -16.0, 12.0, 9.0, -8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18440641538061278, "mean_inference_ms": 1.0688272483735217, "mean_action_processing_ms": 0.07162348345596119, "mean_env_wait_ms": 0.17483062755309411, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 170748, "agent_timesteps_total": 170748, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65775489.198, "learn_time_ms": 15.687, "learn_throughput": 351116.343, "update_time_ms": 6.96}, "info": {"learner": {"learned": {"policy_loss": 238776074240.0, "vf_loss": 236.07054138183594, "total_loss": 238776074240.0, "vf_explained_var": -8.7738037109375e-05, "model": {}}}, "num_steps_sampled": 170748, "num_agent_steps_sampled": 170748, "num_steps_trained": 170748, "num_agent_steps_trained": 170748}, "done": false, "episodes_total": 3348, "training_iteration": 31, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-36", "timestamp": 1626864456, "time_this_iter_s": 0.3550145626068115, "time_total_s": 11.743111371994019, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 11.743111371994019, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.39814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 333.0}, "policy_reward_mean": {"learned": 5.349537037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, 12.0, -8.0, 8.0, 11.0, 4.0, 12.0, -12.0, 3.0, 4.0, 12.0, -4.0, 7.0, -8.0, 10.0, 6.0, 7.0, 12.0, -16.0, 12.0, 11.0, 0.0, -6.0, 10.0, 9.0, -2.0, 11.0, -3.0, -9.0, 11.0, 11.0, 2.0, 10.0, -3.0, 10.0, -2.0, 12.0, 1.0, -3.0, 5.0, 13.0, 319.0, 12.0, 10.0, 4.0, 5.0, -2.0, 8.0, 13.0, -2.0, -7.0, 11.0, 12.0, 5.0, -4.0, 2.0, 9.0, -1.0, -4.0, 11.0, -6.0, 2.0, 11.0, 8.0, -16.0, 12.0, 12.0, 7.0, 12.0, 5.0, -13.0, 11.0, 9.0, 1.0, 6.0, -1.0, -8.0, 4.0, 7.0, 12.0, 12.0, -10.0, 1.0, 12.0, 14.0, -7.0, 6.0, 2.0, 9.0, -14.0, 12.0, 8.0, -3.0, 1.0, 9.0, 8.0, 6.0, -4.0, 6.0, 7.0, 13.0, -5.0, -4.0, 11.0, 7.0, -13.0, 11.0, 10.0, 6.0, 9.0, -7.0, 7.0, 9.0, -7.0, 10.0, 3.0, 12.0, -2.0, 12.0, -7.0, 14.0, 7.0, -13.0, 7.0, 11.0, -16.0, 13.0, 7.0, -3.0, 11.0, 0.0, 7.0, 12.0, -8.0, 3.0, 8.0, 6.0, 1.0, 11.0, -3.0, 5.0, 7.0, -4.0, 7.0, 12.0, -3.0, -1.0, 7.0, -1.0, 2.0, 6.0, 8.0, 7.0, 0.0, 13.0, -5.0, -11.0, 6.0, 13.0, 7.0, 7.0, -8.0, 6.0, 10.0, 14.0, 8.0, 7.0, -14.0, 6.0, 2.0, -4.0, 11.0, -1.0, -3.0, 13.0, 6.0, 8.0, -6.0, 2.0, 11.0, 12.0, 2.0, 11.0, -10.0, 8.0, 1.0, 8.0, -2.0, -4.0, 5.0, 12.0, 2.0, 11.0, -19.0, 11.0, 12.0, 10.0, 12.0, -13.0, 6.0, 9.0, 11.0, 3.0, -8.0, 10.0, -1.0, -1.0, 7.0, 12.0, -12.0, 8.0, 7.0, 12.0, 7.0, 6.0, -10.0, 7.0, -1.0, 12.0, -3.0, 10.0, -7.0, 12.0, 0.0, 8.0, 1.0, -6.0, 12.0, 12.0, -8.0, 5.0, 6.0, 14.0, 0.0, -10.0, 11.0, -4.0, -3.0, 10.0, 12.0, 8.0, -10.0, 7.0, 10.0, 12.0, 1.0, 11.0, -9.0, 8.0, 4.0, 11.0, -8.0, 5.0, 8.0, -4.0, 6.0, -1.0, 6.0, 1.0, 9.0, -1.0, 4.0, 1.0, 11.0, 14.0, -3.0, -5.0, 9.0, 7.0, 4.0, -3.0, 7.0, 8.0, -17.0, 12.0, 12.0, 13.0, -9.0, 12.0, -1.0, 12.0, -14.0, 12.0, 5.0, 6.0, 6.0, -1.0, 4.0, 6.0, -3.0, 1.0, 11.0, 8.0, 11.0, -13.0, 9.0, 13.0, 6.0, -6.0, 2.0, -12.0, 11.0, 11.0, 5.0, -10.0, 7.0, 11.0, 7.0, 14.0, -2.0, 7.0, -4.0, 5.0, 3.0, -2.0, 9.0, -5.0, 1.0, 12.0, 7.0, 5.0, -6.0, 5.0, 11.0, 12.0, 6.0, 10.0, -13.0, 5.0, 4.0, -2.0, 8.0, 13.0, -2.0, -2.0, 6.0, -9.0, 13.0, 6.0, 5.0, 14.0, -9.0, 5.0, 5.0, 9.0, 0.0, 8.0, -2.0, -8.0, 3.0, 13.0, 7.0, -1.0, 1.0, 2.0, 13.0, 9.0, 5.0, 7.0, -6.0, 7.0, 5.0, 5.0, -2.0, -15.0, 6.0, 11.0, 13.0, 5.0, -14.0, 13.0, 11.0, 14.0, -14.0, 6.0, 9.0, 13.0, -6.0, -2.0, 10.0, -5.0, 6.0, 12.0, 2.0, 8.0, -3.0, 3.0, 7.0, 14.0, -2.0, 12.0, -9.0, 8.0, -2.0, -2.0, 11.0, -10.0, 8.0, 5.0, 12.0, -11.0, 3.0, 11.0, 12.0, 11.0, 1.0, -3.0, 6.0, 13.0, 333.0, 10.0, 11.0, -4.0, 3.0, 10.0, 6.0, 6.0, -14.0, 11.0, 12.0, 12.0, 9.0, -3.0, -3.0, 9.0, 5.0, -6.0, 7.0, -8.0, 3.0, 13.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843360828754051, "mean_inference_ms": 1.068664814470849, "mean_action_processing_ms": 0.07157881125495594, "mean_env_wait_ms": 0.17472227155449846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 176256, "agent_timesteps_total": 176256, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66691690.343, "learn_time_ms": 15.449, "learn_throughput": 356530.695, "update_time_ms": 6.569}, "info": {"learner": {"learned": {"policy_loss": 126477230080.0, "vf_loss": 134.6995391845703, "total_loss": 126477230080.0, "vf_explained_var": -0.00036203861236572266, "model": {}}}, "num_steps_sampled": 176256, "num_agent_steps_sampled": 176256, "num_steps_trained": 176256, "num_agent_steps_trained": 176256}, "done": false, "episodes_total": 3456, "training_iteration": 32, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-36", "timestamp": 1626864456, "time_this_iter_s": 0.35814499855041504, "time_total_s": 12.101256370544434, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 12.101256370544434, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 76.3, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.40740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 334.0}, "policy_reward_mean": {"learned": 5.351851851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 9.0, -6.0, 5.0, -13.0, 14.0, 11.0, 3.0, -9.0, 4.0, 11.0, 9.0, -1.0, -5.0, 9.0, 12.0, -4.0, 8.0, 7.0, 4.0, -10.0, 9.0, 13.0, 3.0, -13.0, 9.0, 6.0, 13.0, -1.0, 8.0, -4.0, 12.0, 13.0, -15.0, 5.0, 12.0, -5.0, 8.0, 11.0, 1.0, -11.0, 7.0, 11.0, 8.0, -9.0, 12.0, 3.0, 9.0, 1.0, 9.0, 8.0, -3.0, -8.0, 10.0, 7.0, 6.0, -5.0, 13.0, 7.0, 0.0, -5.0, -4.0, 11.0, 13.0, -5.0, 7.0, 2.0, 11.0, -6.0, 10.0, 4.0, 7.0, 7.0, 9.0, 10.0, -11.0, -16.0, 11.0, 8.0, 12.0, -7.0, 8.0, 2.0, 12.0, -7.0, 8.0, 10.0, 4.0, -11.0, 13.0, 6.0, 7.0, 321.0, 13.0, 11.0, 10.0, -10.0, 9.0, 7.0, 9.0, 7.0, 5.0, -4.0, 7.0, -15.0, 13.0, 5.0, 12.0, 2.0, 5.0, 12.0, -4.0, -8.0, 14.0, 4.0, 5.0, 12.0, -5.0, 10.0, -2.0, -10.0, 8.0, 8.0, 9.0, -14.0, 7.0, 10.0, 12.0, 11.0, -5.0, -4.0, 13.0, 3.0, 14.0, -9.0, 7.0, -7.0, 3.0, 10.0, 9.0, -16.0, 12.0, 11.0, 8.0, -12.0, 13.0, 1.0, 13.0, -13.0, 9.0, 7.0, 12.0, 7.0, 4.0, 10.0, -6.0, -5.0, -1.0, 10.0, 11.0, 10.0, 7.0, -15.0, 13.0, 7.0, 6.0, -4.0, 6.0, -2.0, -4.0, 12.0, 9.0, 5.0, -3.0, 5.0, 8.0, 11.0, 334.0, 10.0, 12.0, 2.0, 9.0, 11.0, -7.0, -7.0, 8.0, 10.0, 4.0, -14.0, 7.0, 9.0, 13.0, 3.0, 9.0, 5.0, -2.0, -5.0, 14.0, -3.0, 9.0, -12.0, 13.0, 11.0, 3.0, 2.0, -9.0, 10.0, 12.0, 8.0, 9.0, 0.0, -2.0, 9.0, 8.0, -9.0, 7.0, -3.0, 14.0, -7.0, 11.0, 1.0, 4.0, -3.0, 13.0, -8.0, 7.0, 3.0, 13.0, -17.0, 9.0, 11.0, 12.0, 7.0, -3.0, 2.0, 9.0, 1.0, 14.0, 3.0, -3.0, 2.0, 9.0, -8.0, 12.0, -20.0, 14.0, 12.0, 9.0, 6.0, 8.0, -5.0, 6.0, 6.0, -7.0, 6.0, 10.0, -1.0, -3.0, 7.0, 12.0, 4.0, 9.0, 10.0, -8.0, -3.0, 8.0, -1.0, 11.0, 2.0, -10.0, 12.0, 11.0, 11.0, -17.0, 9.0, 12.0, 8.0, -14.0, 12.0, 9.0, -11.0, 4.0, 10.0, 12.0, 4.0, -3.0, 6.0, 8.0, 5.0, 13.0, -1.0, -2.0, 10.0, 6.0, -8.0, 7.0, 10.0, -17.0, 11.0, 11.0, -2.0, -2.0, 8.0, 11.0, -2.0, 14.0, 5.0, -2.0, 5.0, 14.0, -5.0, 1.0, -6.0, 9.0, 10.0, 2.0, 4.0, 14.0, 5.0, -8.0, -16.0, 14.0, 5.0, 12.0, 7.0, 5.0, -1.0, 4.0, 8.0, 9.0, 10.0, -12.0, -5.0, -3.0, 10.0, 13.0, -4.0, 9.0, 10.0, 0.0, 0.0, 9.0, -1.0, 7.0, 10.0, -11.0, 5.0, 11.0, -14.0, 5.0, 11.0, 13.0, -11.0, 13.0, 1.0, 12.0, 4.0, 10.0, 13.0, -12.0, -6.0, 8.0, 4.0, 9.0, -6.0, -2.0, 10.0, 13.0, 5.0, 13.0, 0.0, -3.0, 1.0, 13.0, -11.0, 12.0, -13.0, 13.0, 3.0, 12.0, 1.0, 6.0, -5.0, 13.0, 11.0, -16.0, 8.0, 12.0, 1.0, 9.0, 13.0, -8.0, 5.0, 13.0, 11.0, -14.0, 5.0, -10.0, 11.0, 9.0, 11.0, -3.0, 9.0, -2.0, -2.0, 14.0, 10.0, -7.0, -11.0, 14.0, 1.0, 11.0, 1.0, 6.0, -4.0, 12.0, 1.0, 14.0, 1.0, -1.0, 10.0, 3.0, -4.0, 6.0, -5.0, 6.0, 11.0, 3.0, 4.0, 12.0, 6.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18436890977352458, "mean_inference_ms": 1.0687369304498573, "mean_action_processing_ms": 0.07156573311850595, "mean_env_wait_ms": 0.1748022264158204, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 181764, "agent_timesteps_total": 181764, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70255729.617, "learn_time_ms": 16.133, "learn_throughput": 341401.45, "update_time_ms": 6.755}, "info": {"learner": {"learned": {"policy_loss": 31010394112.0, "vf_loss": 124.29402923583984, "total_loss": 31010394112.0, "vf_explained_var": -0.00027751922607421875, "model": {}}}, "num_steps_sampled": 181764, "num_agent_steps_sampled": 181764, "num_steps_trained": 181764, "num_agent_steps_trained": 181764}, "done": false, "episodes_total": 3564, "training_iteration": 33, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-37", "timestamp": 1626864457, "time_this_iter_s": 0.3824317455291748, "time_total_s": 12.483688116073608, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 12.483688116073608, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.62037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.905092592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -5.0, -2.0, 13.0, 1.0, 9.0, 12.0, -7.0, 3.0, 6.0, 8.0, -2.0, -4.0, 10.0, 1.0, 8.0, 8.0, -16.0, 10.0, 13.0, -7.0, 3.0, 9.0, 10.0, 0.0, 13.0, -4.0, 6.0, -8.0, 5.0, 7.0, 11.0, 9.0, -2.0, -4.0, 12.0, -7.0, 5.0, 11.0, 6.0, 7.0, 1.0, -2.0, 9.0, 13.0, 1.0, -2.0, 3.0, -1.0, -3.0, 6.0, 13.0, 320.0, 11.0, 12.0, 13.0, 9.0, 8.0, 1.0, -3.0, -5.0, 5.0, 11.0, 4.0, 6.0, 0.0, -4.0, 13.0, -19.0, 11.0, 10.0, 13.0, -11.0, 13.0, 1.0, 12.0, 5.0, -7.0, 10.0, 7.0, 9.0, 7.0, -14.0, 13.0, -9.0, 9.0, 8.0, 7.0, -16.0, 13.0, 11.0, 7.0, -7.0, 9.0, 2.0, 11.0, 5.0, -14.0, 11.0, 13.0, 5.0, 10.0, -11.0, 11.0, 1.0, 10.0, 7.0, -3.0, -7.0, 4.0, 11.0, 7.0, 8.0, 3.0, -3.0, 7.0, -16.0, 8.0, 13.0, 10.0, 1.0, -6.0, 10.0, 10.0, 14.0, 11.0, 318.0, 13.0, 13.0, -6.0, -3.0, 11.0, 1.0, 7.0, -2.0, 9.0, 7.0, 8.0, 9.0, -9.0, 13.0, 5.0, -1.0, -2.0, 2.0, -7.0, 11.0, 9.0, 3.0, 9.0, -7.0, 10.0, 12.0, 6.0, -2.0, -1.0, 6.0, 8.0, -10.0, 11.0, 4.0, -9.0, 8.0, 12.0, 7.0, 11.0, 8.0, -11.0, -4.0, 12.0, -5.0, 12.0, 0.0, 6.0, -2.0, 11.0, 9.0, -12.0, 5.0, 13.0, -15.0, 10.0, 11.0, 9.0, 1.0, 8.0, 9.0, -3.0, 7.0, 8.0, -2.0, 2.0, 13.0, 6.0, -17.0, 13.0, -8.0, 4.0, 6.0, 13.0, 1.0, 8.0, -3.0, 9.0, 9.0, 1.0, -6.0, 11.0, 4.0, -12.0, 11.0, 12.0, 7.0, 8.0, -4.0, 4.0, 8.0, 6.0, -6.0, 7.0, 3.0, 11.0, 11.0, -10.0, 6.0, -8.0, 9.0, 8.0, -10.0, 6.0, 8.0, 11.0, 9.0, 3.0, -6.0, 9.0, 10.0, 4.0, -2.0, 3.0, 7.0, -11.0, 8.0, 11.0, 2.0, 5.0, -5.0, 13.0, 9.0, 7.0, 3.0, -4.0, -6.0, 9.0, 12.0, 0.0, 6.0, -15.0, 11.0, 13.0, -9.0, 11.0, 4.0, 9.0, 4.0, 13.0, 6.0, -8.0, 10.0, -11.0, 12.0, 4.0, 9.0, 7.0, -14.0, 13.0, -19.0, 10.0, 11.0, 13.0, 8.0, 13.0, -11.0, 5.0, 5.0, 6.0, 9.0, -5.0, 6.0, 4.0, -4.0, 9.0, 4.0, 12.0, -3.0, 2.0, 2.0, 13.0, 10.0, -10.0, -5.0, 5.0, 11.0, 4.0, 6.0, -7.0, 3.0, 13.0, 3.0, 5.0, 12.0, -5.0, 10.0, 8.0, 4.0, -7.0, 0.0, 9.0, -2.0, 8.0, 5.0, -13.0, 10.0, 13.0, -10.0, 6.0, 12.0, 7.0, 8.0, -7.0, 6.0, 8.0, -4.0, 5.0, 8.0, 6.0, 6.0, 5.0, -9.0, 13.0, -2.0, 9.0, 13.0, -5.0, 7.0, -11.0, 12.0, 7.0, 10.0, -12.0, 7.0, 10.0, 10.0, -6.0, 5.0, 6.0, -15.0, 9.0, 9.0, 12.0, 8.0, 8.0, 2.0, -3.0, 11.0, 13.0, 11.0, 321.0, 13.0, 8.0, -19.0, 13.0, -6.0, 10.0, 10.0, 1.0, 4.0, 9.0, -3.0, 5.0, 6.0, 9.0, -13.0, 13.0, 5.0, 0.0, -2.0, 12.0, -13.0, 8.0, 11.0, 9.0, -1.0, 13.0, -6.0, 9.0, 11.0, 7.0, -2.0, -1.0, 10.0, -5.0, 3.0, 7.0, -9.0, 4.0, 11.0, 9.0, 9.0, -12.0, 8.0, 10.0, -12.0, 7.0, 13.0, 7.0, 9.0, -5.0, -2.0, 13.0, 320.0, 12.0, 13.0, 10.0, 3.0, 6.0, -3.0, 9.0, 1.0, 4.0, -1.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18438660057668732, "mean_inference_ms": 1.068262820464078, "mean_action_processing_ms": 0.07155845988571298, "mean_env_wait_ms": 0.17480863992832796, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 187272, "agent_timesteps_total": 187272, "timers": {"sample_time_ms": 0.08, "sample_throughput": 69275699.572, "learn_time_ms": 16.182, "learn_throughput": 340388.365, "update_time_ms": 6.905}, "info": {"learner": {"learned": {"policy_loss": 1.2938790321350098, "vf_loss": 19.45233726501465, "total_loss": 20.7462158203125, "vf_explained_var": -0.002205967903137207, "model": {}}}, "num_steps_sampled": 187272, "num_agent_steps_sampled": 187272, "num_steps_trained": 187272, "num_agent_steps_trained": 187272}, "done": false, "episodes_total": 3672, "training_iteration": 34, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-37", "timestamp": 1626864457, "time_this_iter_s": 0.3498249053955078, "time_total_s": 12.833513021469116, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182862f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 12.833513021469116, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 76.6, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 5.0, 6.0, -3.0, -16.0, 12.0, 12.0, 7.0, 5.0, -2.0, 12.0, 0.0, 7.0, -11.0, 6.0, 13.0, 9.0, 12.0, 3.0, -9.0, 7.0, 4.0, -9.0, 13.0, 6.0, 6.0, 8.0, -5.0, 6.0, -10.0, 6.0, 13.0, 8.0, 6.0, -6.0, 7.0, -13.0, 14.0, 9.0, 5.0, 10.0, -9.0, 6.0, 8.0, 4.0, 4.0, 8.0, -1.0, 8.0, 7.0, 10.0, -10.0, 10.0, -4.0, 13.0, -4.0, 10.0, 12.0, 5.0, -12.0, 1.0, -9.0, 11.0, 12.0, 8.0, 7.0, 11.0, -11.0, 321.0, 13.0, 12.0, 10.0, 10.0, 6.0, -7.0, 6.0, 1.0, -3.0, 6.0, 11.0, 9.0, -2.0, 10.0, -2.0, 2.0, 10.0, 11.0, -8.0, -6.0, 6.0, 8.0, 7.0, 7.0, -2.0, -1.0, 11.0, 9.0, 2.0, 11.0, -7.0, 6.0, 10.0, 1.0, -2.0, 6.0, -3.0, 5.0, 7.0, 13.0, 5.0, -14.0, 11.0, 13.0, 11.0, -7.0, -2.0, -13.0, 11.0, 7.0, 10.0, -5.0, 6.0, 7.0, 7.0, 12.0, -9.0, 1.0, 11.0, 9.0, -10.0, 11.0, 5.0, 2.0, 12.0, 10.0, -9.0, 10.0, 6.0, -7.0, 6.0, 2.0, 4.0, -3.0, 12.0, 8.0, 8.0, -4.0, 3.0, 4.0, 9.0, -7.0, 9.0, 9.0, 12.0, 4.0, -10.0, 10.0, -15.0, 11.0, 9.0, 7.0, -7.0, 3.0, 12.0, 4.0, 12.0, -11.0, 10.0, 4.0, 12.0, 11.0, -12.0, 8.0, 7.0, -10.0, 10.0, 14.0, 12.0, -4.0, -7.0, 0.0, 11.0, 7.0, -3.0, 4.0, -2.0, 8.0, 5.0, 8.0, 8.0, 6.0, -7.0, 14.0, 2.0, -13.0, 12.0, -18.0, 14.0, 10.0, 9.0, 11.0, -5.0, 3.0, 6.0, 10.0, 2.0, -5.0, 8.0, 9.0, 9.0, 0.0, -3.0, 3.0, -5.0, 6.0, 11.0, -4.0, 7.0, 5.0, 7.0, 11.0, 2.0, -9.0, 11.0, 12.0, -8.0, 1.0, 10.0, -6.0, 11.0, -1.0, 11.0, 10.0, -11.0, 4.0, 12.0, 7.0, -2.0, 11.0, -1.0, 9.0, -6.0, 9.0, 3.0, -10.0, 5.0, 11.0, 9.0, 8.0, -10.0, 8.0, 9.0, 7.0, 4.0, 12.0, -8.0, 10.0, 13.0, 4.0, -12.0, 2.0, 13.0, -7.0, 7.0, 7.0, -6.0, 6.0, 8.0, 8.0, 5.0, -7.0, 9.0, 13.0, -3.0, -7.0, 12.0, -19.0, 14.0, 9.0, 11.0, -5.0, 7.0, 1.0, 12.0, 7.0, 3.0, -6.0, 11.0, 6.0, 0.0, 11.0, -2.0, 4.0, 13.0, 12.0, -14.0, 9.0, -14.0, 13.0, 7.0, 2.0, 8.0, -8.0, 13.0, 9.0, -12.0, 10.0, 8.0, 3.0, 11.0, -11.0, 12.0, 5.0, -3.0, 6.0, 7.0, 7.0, -10.0, 7.0, 11.0, 7.0, -12.0, 9.0, 11.0, 3.0, 12.0, -1.0, 1.0, -6.0, 5.0, 8.0, 8.0, 12.0, -3.0, 12.0, -6.0, 5.0, 7.0, 12.0, -9.0, -8.0, 13.0, 1.0, 9.0, -6.0, 6.0, 7.0, 8.0, 5.0, 9.0, 5.0, -4.0, 13.0, -8.0, -3.0, 13.0, 7.0, 11.0, 6.0, -9.0, -7.0, 12.0, 8.0, 2.0, 7.0, 10.0, -10.0, 8.0, 8.0, 8.0, 4.0, -5.0, -17.0, 13.0, 8.0, 11.0, 12.0, 7.0, -12.0, 8.0, 8.0, -7.0, 7.0, 7.0, 14.0, 7.0, -16.0, 10.0, -17.0, 14.0, 7.0, 11.0, 6.0, -10.0, 8.0, 11.0, 14.0, -1.0, -8.0, 10.0, 7.0, 5.0, 11.0, -8.0, 7.0, 8.0, -12.0, 12.0, 9.0, 12.0, -12.0, 6.0, 2.0, 6.0, -2.0, 9.0, 8.0, -9.0, 11.0, 5.0, 7.0, 4.0, -5.0, 9.0, -10.0, 11.0, 6.0, 8.0, 9.0, 0.0, 7.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1844589928625515, "mean_inference_ms": 1.0682004547934285, "mean_action_processing_ms": 0.07157705320925624, "mean_env_wait_ms": 0.17481298178122603, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 192780, "agent_timesteps_total": 192780, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67963417.494, "learn_time_ms": 15.993, "learn_throughput": 344403.262, "update_time_ms": 6.781}, "info": {"learner": {"learned": {"policy_loss": 1.2553552389144897, "vf_loss": 16.312591552734375, "total_loss": 17.567947387695312, "vf_explained_var": -0.0025985240936279297, "model": {}}}, "num_steps_sampled": 192780, "num_agent_steps_sampled": 192780, "num_steps_trained": 192780, "num_agent_steps_trained": 192780}, "done": false, "episodes_total": 3780, "training_iteration": 35, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-37", "timestamp": 1626864457, "time_this_iter_s": 0.3633723258972168, "time_total_s": 13.196885347366333, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 13.196885347366333, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 80.9, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -3.0, -1.0, 11.0, 5.0, 6.0, -1.0, 5.0, 8.0, 12.0, 8.0, -13.0, -9.0, 6.0, 12.0, 6.0, 9.0, 9.0, 10.0, -13.0, 7.0, 4.0, -1.0, 5.0, -7.0, 10.0, 6.0, 6.0, 12.0, -7.0, 13.0, -3.0, 5.0, 10.0, -5.0, 5.0, 8.0, 9.0, -8.0, 6.0, 8.0, 6.0, 8.0, -7.0, 11.0, 5.0, 3.0, -4.0, 3.0, 12.0, 3.0, -3.0, 4.0, 10.0, -6.0, 7.0, -1.0, 12.0, -4.0, 8.0, 8.0, -14.0, 11.0, 10.0, 9.0, 0.0, 5.0, 1.0, 9.0, 9.0, -1.0, -2.0, 11.0, 8.0, 3.0, -7.0, 0.0, -8.0, 13.0, 10.0, 9.0, -3.0, 8.0, 1.0, 2.0, 2.0, 13.0, -2.0, -9.0, 12.0, 6.0, 6.0, 5.0, 4.0, 13.0, -7.0, 9.0, 12.0, -14.0, 8.0, -1.0, 9.0, 8.0, -1.0, 5.0, 11.0, -2.0, 1.0, 12.0, -3.0, -7.0, 13.0, 8.0, -2.0, 11.0, -2.0, 2.0, 12.0, -6.0, 7.0, 7.0, 13.0, -8.0, 3.0, 8.0, 1.0, 8.0, -2.0, 14.0, -4.0, 3.0, 2.0, -9.0, 6.0, 13.0, 5.0, 11.0, 9.0, 8.0, -13.0, 12.0, -5.0, 13.0, -5.0, 14.0, 13.0, -14.0, 2.0, 12.0, 10.0, -7.0, 0.0, 9.0, 11.0, 7.0, -12.0, 0.0, 6.0, 13.0, -4.0, 4.0, -3.0, 9.0, 5.0, 5.0, 7.0, -3.0, 6.0, -9.0, 9.0, 4.0, 11.0, 13.0, -20.0, 13.0, 9.0, 14.0, 0.0, 7.0, -6.0, 3.0, 3.0, -2.0, 11.0, -9.0, 11.0, 2.0, 11.0, 5.0, -2.0, 13.0, -1.0, 9.0, -3.0, 6.0, 3.0, -8.0, 0.0, 10.0, 13.0, -2.0, 8.0, 8.0, 1.0, 8.0, 2.0, -8.0, 13.0, 12.0, 7.0, 4.0, -8.0, 4.0, 11.0, -1.0, 1.0, 7.0, 6.0, 12.0, -10.0, 10.0, -5.0, 13.0, -3.0, 9.0, 13.0, -8.0, 1.0, -4.0, 0.0, 8.0, 11.0, -3.0, 6.0, 4.0, 8.0, 11.0, -6.0, -3.0, 13.0, 14.0, -3.0, -1.0, 5.0, 12.0, 9.0, 8.0, -14.0, -12.0, 12.0, 5.0, 10.0, 7.0, 2.0, 9.0, -3.0, 9.0, -6.0, 10.0, 2.0, -11.0, 6.0, 12.0, 8.0, 3.0, 11.0, 12.0, -11.0, 11.0, -5.0, 13.0, -4.0, 13.0, 14.0, -8.0, -4.0, -3.0, 4.0, 13.0, 1.0, 7.0, 10.0, 6.0, -8.0, 13.0, -9.0, -2.0, 13.0, 14.0, -10.0, 7.0, 4.0, 11.0, 7.0, -6.0, 3.0, 1.0, -4.0, 11.0, 7.0, 13.0, -1.0, -3.0, 6.0, 5.0, -3.0, 2.0, 11.0, 7.0, 5.0, 13.0, -10.0, -13.0, 13.0, 5.0, 10.0, -12.0, 5.0, 10.0, 12.0, 9.0, 12.0, 9.0, -15.0, 2.0, 10.0, -5.0, 8.0, -2.0, 12.0, -2.0, 7.0, 8.0, 6.0, -10.0, 11.0, 9.0, 10.0, 4.0, -8.0, 6.0, 6.0, 4.0, -1.0, -2.0, 11.0, 6.0, 0.0, 9.0, -4.0, 13.0, -3.0, 14.0, 7.0, 5.0, -11.0, 7.0, 12.0, -1.0, -3.0, -13.0, 9.0, 10.0, 9.0, -3.0, 6.0, 6.0, 6.0, -6.0, 13.0, 9.0, -1.0, 5.0, 9.0, -10.0, 11.0, 8.0, -5.0, 2.0, 10.0, -3.0, -2.0, 12.0, 8.0, 14.0, -4.0, 2.0, 3.0, -8.0, 9.0, 11.0, 3.0, 10.0, -8.0, 3.0, 10.0, -1.0, -6.0, 12.0, 10.0, 0.0, 14.0, -10.0, 11.0, 10.0, -1.0, -2.0, 8.0, 1.0, 12.0, -8.0, 10.0, 9.0, 2.0, 12.0, -8.0, 13.0, 7.0, 4.0, -9.0, 11.0, 4.0, -3.0, 3.0, -2.0, 10.0, -1.0, 8.0, 13.0, -5.0, 11.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18448194757645298, "mean_inference_ms": 1.0681464380369552, "mean_action_processing_ms": 0.07156066898378359, "mean_env_wait_ms": 0.17479874135999296, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 198288, "agent_timesteps_total": 198288, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66184263.47, "learn_time_ms": 14.837, "learn_throughput": 371242.36, "update_time_ms": 6.318}, "info": {"learner": {"learned": {"policy_loss": 125901176832.0, "vf_loss": 134.66629028320312, "total_loss": 125901176832.0, "vf_explained_var": -0.0004100799560546875, "model": {}}}, "num_steps_sampled": 198288, "num_agent_steps_sampled": 198288, "num_steps_trained": 198288, "num_agent_steps_trained": 198288}, "done": false, "episodes_total": 3888, "training_iteration": 36, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-38", "timestamp": 1626864458, "time_this_iter_s": 0.35713982582092285, "time_total_s": 13.554025173187256, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 13.554025173187256, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 6.0, 13.0, -11.0, -16.0, 12.0, 12.0, 7.0, 10.0, 8.0, -14.0, 11.0, 7.0, 8.0, 4.0, -4.0, 8.0, 5.0, 7.0, -5.0, -2.0, 12.0, 8.0, -3.0, 12.0, -14.0, 10.0, 7.0, -8.0, 10.0, 9.0, 4.0, 6.0, 11.0, 2.0, -4.0, -12.0, 13.0, 8.0, 6.0, 13.0, -2.0, 11.0, -7.0, -11.0, 11.0, 4.0, 11.0, -8.0, 13.0, 8.0, 2.0, 7.0, -4.0, 8.0, 4.0, 11.0, 10.0, -6.0, 0.0, 2.0, 11.0, -8.0, 10.0, -2.0, 0.0, 7.0, 10.0, -16.0, 12.0, 7.0, 12.0, -4.0, 8.0, 5.0, 6.0, -15.0, 13.0, 9.0, 8.0, 6.0, 6.0, 12.0, -9.0, 1.0, -2.0, 9.0, 7.0, 14.0, 5.0, 5.0, -9.0, 8.0, -6.0, 8.0, 5.0, 5.0, 2.0, -4.0, 12.0, -9.0, 12.0, 2.0, 10.0, 13.0, 12.0, 3.0, -13.0, 2.0, 10.0, 11.0, -8.0, 9.0, -5.0, 6.0, 5.0, 7.0, -5.0, 2.0, 11.0, 11.0, 13.0, -16.0, 7.0, 8.0, 10.0, -6.0, 3.0, 8.0, 11.0, 12.0, -16.0, 318.0, 13.0, 11.0, 12.0, 11.0, 5.0, -12.0, 11.0, 10.0, 12.0, 6.0, -13.0, 10.0, -13.0, 12.0, 6.0, 0.0, 14.0, -9.0, 10.0, 11.0, 6.0, 2.0, -4.0, 7.0, -8.0, 6.0, 10.0, 7.0, 2.0, -6.0, 12.0, 10.0, -11.0, 9.0, 7.0, 9.0, 3.0, -3.0, 6.0, 9.0, -4.0, 4.0, 6.0, 7.0, 1.0, 13.0, -6.0, 3.0, -3.0, 10.0, 5.0, 14.0, 7.0, -17.0, 11.0, 12.0, -13.0, 10.0, 6.0, 6.0, 8.0, -12.0, 13.0, -7.0, 9.0, 3.0, 10.0, 12.0, 6.0, -13.0, 10.0, -5.0, 11.0, 10.0, -1.0, -13.0, 11.0, 9.0, 8.0, 4.0, 11.0, -6.0, 6.0, 10.0, 8.0, 9.0, -12.0, 1.0, 13.0, 3.0, -2.0, -10.0, 11.0, 12.0, 2.0, 7.0, 14.0, -9.0, 3.0, 13.0, 7.0, 11.0, -16.0, 7.0, 12.0, 9.0, -13.0, -11.0, 12.0, 12.0, 2.0, -12.0, 12.0, 6.0, 9.0, 9.0, 3.0, 11.0, -8.0, 3.0, -4.0, 4.0, 12.0, 8.0, -2.0, 12.0, -3.0, 9.0, 11.0, -16.0, 11.0, 13.0, 12.0, -2.0, -8.0, -8.0, 8.0, 6.0, 9.0, -9.0, 9.0, 3.0, 12.0, -12.0, 12.0, 4.0, 11.0, 12.0, 7.0, -10.0, 6.0, 2.0, 4.0, -2.0, 11.0, -3.0, 9.0, 8.0, 1.0, 4.0, -9.0, 10.0, 10.0, -3.0, 8.0, 7.0, 3.0, -9.0, 12.0, 5.0, 7.0, 8.0, 3.0, 12.0, -8.0, -3.0, -6.0, 12.0, 12.0, -6.0, 8.0, 6.0, 7.0, 2.0, 12.0, 11.0, -10.0, 7.0, -7.0, 13.0, 2.0, 6.0, -8.0, 11.0, 6.0, 13.0, 4.0, -13.0, 11.0, 2.0, -6.0, 11.0, 8.0, -11.0, 10.0, 9.0, 7.0, -10.0, 11.0, 5.0, 9.0, -3.0, 11.0, -4.0, 11.0, 11.0, 7.0, 11.0, -14.0, -11.0, 11.0, 8.0, 7.0, -14.0, 8.0, 11.0, 10.0, 13.0, 8.0, 10.0, -16.0, -6.0, 11.0, 8.0, 2.0, -6.0, 9.0, 13.0, -1.0, 2.0, 11.0, 5.0, -3.0, 10.0, 8.0, -10.0, 7.0, 1.0, 10.0, 12.0, -8.0, 7.0, -4.0, 7.0, 5.0, -6.0, 10.0, 9.0, 2.0, 11.0, 7.0, -9.0, 6.0, 7.0, -3.0, 8.0, 3.0, 8.0, 5.0, 12.0, -10.0, -10.0, 11.0, 11.0, 3.0, 13.0, 14.0, 9.0, 319.0, 1.0, -7.0, 11.0, 10.0, 3.0, 10.0, 8.0, -6.0, -1.0, -8.0, 11.0, 13.0, 12.0, 0.0, -4.0, 7.0, 10.0, 12.0, 7.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1845267966473658, "mean_inference_ms": 1.0682945287773373, "mean_action_processing_ms": 0.07155348357036592, "mean_env_wait_ms": 0.17480546018847953, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 203796, "agent_timesteps_total": 203796, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66081197.955, "learn_time_ms": 14.661, "learn_throughput": 375683.221, "update_time_ms": 6.403}, "info": {"learner": {"learned": {"policy_loss": 95865659392.0, "vf_loss": 136.9654541015625, "total_loss": 95865659392.0, "vf_explained_var": -0.0002752542495727539, "model": {}}}, "num_steps_sampled": 203796, "num_agent_steps_sampled": 203796, "num_steps_trained": 203796, "num_agent_steps_trained": 203796}, "done": false, "episodes_total": 3996, "training_iteration": 37, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-38", "timestamp": 1626864458, "time_this_iter_s": 0.3607172966003418, "time_total_s": 13.914742469787598, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a8310aea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 13.914742469787598, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 73.7, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.00925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.752314814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -1.0, 6.0, -2.0, 13.0, 13.0, 1.0, -12.0, -7.0, 6.0, 12.0, 4.0, 9.0, -1.0, -1.0, 8.0, -7.0, 6.0, 10.0, 6.0, 7.0, 10.0, 11.0, -13.0, 6.0, -10.0, 12.0, 7.0, 8.0, -3.0, 8.0, 2.0, 14.0, -3.0, -8.0, 12.0, 9.0, 11.0, 8.0, -13.0, -13.0, 7.0, 11.0, 10.0, 12.0, -8.0, 7.0, 4.0, -2.0, 1.0, 8.0, 8.0, 9.0, 7.0, -7.0, 6.0, 7.0, -8.0, 10.0, 6.0, 9.0, 12.0, 8.0, -14.0, -1.0, 9.0, -3.0, 10.0, 11.0, 9.0, -9.0, 4.0, 6.0, -11.0, 12.0, 8.0, -5.0, 13.0, 7.0, 0.0, -5.0, 6.0, 9.0, 5.0, 12.0, 11.0, 6.0, -14.0, -3.0, -7.0, 12.0, 13.0, 9.0, -6.0, 4.0, 8.0, -6.0, 5.0, 10.0, 6.0, 11.0, -14.0, 7.0, 11.0, -9.0, 12.0, 8.0, 4.0, 8.0, 8.0, 9.0, -10.0, 12.0, -7.0, 11.0, -1.0, 6.0, 10.0, 9.0, -10.0, -17.0, 7.0, 12.0, 13.0, 2.0, 10.0, 10.0, -7.0, -2.0, 7.0, 4.0, 6.0, 10.0, -9.0, 7.0, 7.0, -3.0, -5.0, 12.0, 11.0, 9.0, -2.0, 1.0, 7.0, -8.0, 6.0, 8.0, 9.0, 4.0, -9.0, 11.0, 9.0, 8.0, -4.0, 11.0, 0.0, 9.0, 6.0, 8.0, -7.0, 13.0, -5.0, -4.0, 11.0, 0.0, -3.0, 9.0, 9.0, 5.0, -5.0, 12.0, 3.0, 10.0, -2.0, 6.0, 1.0, 9.0, -5.0, 9.0, 2.0, 8.0, -9.0, 12.0, 4.0, -8.0, -1.0, 12.0, 12.0, 9.0, 5.0, -9.0, 10.0, -8.0, 10.0, 7.0, 6.0, 11.0, -8.0, 5.0, 7.0, -11.0, 4.0, 12.0, 10.0, 7.0, 13.0, 9.0, -14.0, 0.0, 3.0, 2.0, 10.0, 7.0, 10.0, 10.0, -12.0, -9.0, 2.0, 12.0, 10.0, 14.0, -4.0, 4.0, 1.0, 8.0, -10.0, 7.0, 10.0, -6.0, 10.0, 9.0, 2.0, 4.0, -6.0, 11.0, 6.0, 9.0, -5.0, 9.0, 2.0, -6.0, 1.0, 12.0, 8.0, 8.0, -6.0, 8.0, 5.0, 1.0, -7.0, 10.0, 11.0, 4.0, 7.0, 9.0, -5.0, -1.0, 3.0, 5.0, 8.0, -8.0, 12.0, 9.0, 2.0, -18.0, 13.0, 12.0, 8.0, 0.0, -1.0, 8.0, 8.0, 7.0, -9.0, 11.0, 6.0, 5.0, 8.0, 13.0, -11.0, -2.0, -7.0, 12.0, 12.0, -5.0, 11.0, 1.0, 8.0, 9.0, -8.0, 3.0, 11.0, -2.0, -6.0, 10.0, 13.0, -6.0, -3.0, 12.0, 12.0, -5.0, 10.0, 6.0, 4.0, -3.0, 5.0, 8.0, 5.0, -3.0, 14.0, 13.0, -9.0, -7.0, 11.0, 8.0, 3.0, 9.0, 11.0, 10.0, -15.0, 14.0, 7.0, -3.0, -3.0, 5.0, 9.0, 12.0, -11.0, 2.0, -1.0, 12.0, 2.0, 8.0, -2.0, -1.0, 10.0, 14.0, -11.0, 0.0, 12.0, 10.0, -7.0, 8.0, 4.0, -19.0, 11.0, 12.0, 11.0, 9.0, -5.0, 4.0, 7.0, -1.0, 8.0, 8.0, 0.0, 11.0, 8.0, -5.0, 1.0, 5.0, -14.0, 11.0, 13.0, -1.0, -2.0, 8.0, 10.0, -1.0, 6.0, 7.0, 3.0, 1.0, -7.0, 12.0, 9.0, 8.0, -4.0, 7.0, 4.0, 0.0, 4.0, 7.0, 4.0, 12.0, -13.0, 5.0, 11.0, 11.0, 8.0, -11.0, 7.0, 6.0, -9.0, 12.0, 6.0, 3.0, 0.0, 9.0, 3.0, -4.0, 2.0, 7.0, 10.0, 3.0, -2.0, 12.0, 2.0, -12.0, 13.0, 11.0, 3.0, 5.0, -3.0, 7.0, 6.0, 12.0, 6.0, -1.0, -2.0, 3.0, -7.0, 11.0, 8.0, 7.0, -3.0, 12.0, -1.0, -5.0, 11.0, 2.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18451583552836956, "mean_inference_ms": 1.0677781469894336, "mean_action_processing_ms": 0.0715200292977614, "mean_env_wait_ms": 0.17477296999183042, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 209304, "agent_timesteps_total": 209304, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68372588.569, "learn_time_ms": 14.727, "learn_throughput": 373994.908, "update_time_ms": 6.536}, "info": {"learner": {"learned": {"policy_loss": 69400862720.0, "vf_loss": 126.77519226074219, "total_loss": 69400862720.0, "vf_explained_var": -0.00016486644744873047, "model": {}}}, "num_steps_sampled": 209304, "num_agent_steps_sampled": 209304, "num_steps_trained": 209304, "num_agent_steps_trained": 209304}, "done": false, "episodes_total": 4104, "training_iteration": 38, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-39", "timestamp": 1626864459, "time_this_iter_s": 0.363750696182251, "time_total_s": 14.278493165969849, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 14.278493165969849, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -1.0, 10.0, -2.0, 13.0, 12.0, 4.0, -14.0, 12.0, 5.0, -4.0, 2.0, -17.0, 7.0, 12.0, 13.0, 9.0, -8.0, 11.0, 3.0, 13.0, 12.0, -7.0, -3.0, 14.0, 12.0, -10.0, -1.0, 10.0, -10.0, 7.0, 8.0, 8.0, -5.0, 1.0, 11.0, 12.0, -6.0, 8.0, 1.0, 14.0, 11.0, 2.0, -12.0, 9.0, 6.0, 11.0, -11.0, 10.0, -4.0, -2.0, 11.0, 11.0, 12.0, -9.0, 1.0, -2.0, -1.0, 11.0, 7.0, 10.0, -17.0, 9.0, 13.0, 11.0, -2.0, -4.0, 10.0, 12.0, 12.0, -8.0, -1.0, 11.0, -7.0, 9.0, 2.0, 8.0, -14.0, 13.0, 8.0, 3.0, -14.0, 13.0, 13.0, 9.0, -3.0, 10.0, -1.0, 2.0, 13.0, -3.0, 3.0, 10.0, -7.0, 5.0, 7.0, 9.0, -18.0, 11.0, 13.0, 11.0, -1.0, -2.0, 7.0, 11.0, -5.0, 1.0, 8.0, -6.0, 4.0, 9.0, 8.0, 14.0, -2.0, -4.0, 7.0, 8.0, 10.0, -9.0, 6.0, 13.0, -5.0, 5.0, 2.0, 10.0, -16.0, 13.0, 8.0, 9.0, -3.0, 10.0, -1.0, 6.0, 10.0, -8.0, 7.0, 11.0, 13.0, 6.0, -15.0, 4.0, -14.0, 12.0, 13.0, 8.0, 11.0, -12.0, 8.0, 13.0, 12.0, -1.0, -9.0, 3.0, 8.0, -1.0, 5.0, 12.0, -5.0, 6.0, 2.0, 13.0, -1.0, 11.0, -8.0, 10.0, 13.0, -19.0, 11.0, -5.0, 13.0, 8.0, -1.0, 7.0, -13.0, 13.0, 8.0, 7.0, -16.0, 11.0, 13.0, -6.0, 9.0, 5.0, 7.0, 12.0, 6.0, -10.0, 7.0, 10.0, -10.0, 7.0, 8.0, 14.0, 5.0, -9.0, 5.0, 13.0, 12.0, 0.0, -10.0, 13.0, -4.0, 9.0, -3.0, 8.0, -10.0, 9.0, 8.0, 13.0, -6.0, -2.0, 10.0, 13.0, 10.0, 7.0, -15.0, 12.0, 6.0, -7.0, 4.0, 5.0, -8.0, 10.0, 8.0, 5.0, 10.0, -3.0, 3.0, 12.0, 11.0, 5.0, -13.0, -8.0, 12.0, 7.0, 4.0, -6.0, -4.0, 12.0, 13.0, 7.0, -1.0, -4.0, 13.0, 13.0, 11.0, 7.0, -16.0, 11.0, 11.0, -13.0, 6.0, 7.0, -17.0, 12.0, 13.0, 8.0, 2.0, -5.0, 10.0, 10.0, 8.0, -10.0, 7.0, 11.0, 13.0, -6.0, -3.0, 11.0, 5.0, 10.0, -11.0, 7.0, 11.0, -15.0, 12.0, 12.0, 9.0, -13.0, 7.0, 13.0, -9.0, 10.0, 1.0, 1.0, -12.0, 13.0, 13.0, 4.0, 6.0, -6.0, 11.0, 14.0, -2.0, 4.0, -1.0, 0.0, 3.0, 9.0, 3.0, -1.0, -10.0, 13.0, 13.0, 11.0, -1.0, -7.0, 12.0, 12.0, -4.0, -5.0, 12.0, 13.0, 8.0, 2.0, -8.0, 11.0, -10.0, 8.0, 6.0, 9.0, -12.0, 6.0, 12.0, 13.0, -6.0, -2.0, 10.0, 2.0, 12.0, 2.0, -1.0, -1.0, -10.0, 13.0, 13.0, 8.0, 5.0, -6.0, 8.0, 13.0, -2.0, 2.0, 2.0, -1.0, 6.0, -2.0, 12.0, 7.0, -13.0, 13.0, 8.0, 8.0, -17.0, 12.0, 12.0, 9.0, 11.0, -10.0, 5.0, 9.0, 8.0, 5.0, -7.0, 1.0, -8.0, 13.0, 9.0, 12.0, 318.0, 11.0, 13.0, 12.0, -5.0, 1.0, 7.0, 13.0, 5.0, -9.0, 6.0, 0.0, 6.0, 10.0, -1.0, 8.0, -12.0, 8.0, 11.0, 12.0, 11.0, -13.0, 5.0, 13.0, -1.0, -5.0, 8.0, 10.0, -9.0, 9.0, 5.0, 6.0, 6.0, -5.0, 8.0, 9.0, 12.0, 0.0, -6.0, 7.0, -5.0, 10.0, 3.0, -1.0, -5.0, 13.0, 8.0, -7.0, 12.0, -1.0, 11.0, 14.0, 10.0, 6.0, -15.0, 12.0, 11.0, -7.0, -1.0, 10.0, -10.0, 13.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1845589588043779, "mean_inference_ms": 1.0678687567576353, "mean_action_processing_ms": 0.0715315175763704, "mean_env_wait_ms": 0.17484082291362288, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 214812, "agent_timesteps_total": 214812, "timers": {"sample_time_ms": 0.079, "sample_throughput": 70055925.311, "learn_time_ms": 14.891, "learn_throughput": 369883.001, "update_time_ms": 6.884}, "info": {"learner": {"learned": {"policy_loss": 1.2908401489257812, "vf_loss": 16.093847274780273, "total_loss": 17.384687423706055, "vf_explained_var": -0.0025370121002197266, "model": {}}}, "num_steps_sampled": 214812, "num_agent_steps_sampled": 214812, "num_steps_trained": 214812, "num_agent_steps_trained": 214812}, "done": false, "episodes_total": 4212, "training_iteration": 39, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-39", "timestamp": 1626864459, "time_this_iter_s": 0.37292933464050293, "time_total_s": 14.651422500610352, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 14.651422500610352, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 73.7, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 1.0, 13.0, -5.0, 1.0, 9.0, -5.0, 10.0, 8.0, -2.0, 5.0, 4.0, 4.0, 13.0, 6.0, -8.0, 12.0, 4.0, 12.0, -13.0, -8.0, 6.0, 12.0, 5.0, 8.0, 0.0, 5.0, 2.0, 10.0, 9.0, -12.0, 8.0, 12.0, 1.0, 12.0, -10.0, -11.0, 14.0, 5.0, 7.0, 13.0, -5.0, 2.0, 5.0, 12.0, 13.0, -5.0, -5.0, 5.0, 4.0, -7.0, 13.0, 7.0, 5.0, 9.0, -6.0, 4.0, -1.0, 6.0, 6.0, 11.0, 13.0, -17.0, 8.0, 7.0, -11.0, 11.0, 8.0, 8.0, 10.0, -14.0, 11.0, 1.0, -2.0, 10.0, 6.0, 11.0, 1.0, 4.0, -1.0, 5.0, -9.0, 6.0, 13.0, -5.0, 6.0, 2.0, 12.0, 3.0, -1.0, 10.0, 3.0, 8.0, 13.0, -6.0, 0.0, 10.0, 3.0, -11.0, 13.0, -12.0, 10.0, 5.0, 12.0, 9.0, -2.0, -1.0, 9.0, 12.0, 9.0, 1.0, -7.0, 10.0, -12.0, 8.0, 9.0, -6.0, 8.0, 2.0, 11.0, 6.0, 13.0, 1.0, -5.0, -6.0, 13.0, 7.0, 1.0, 13.0, 6.0, 2.0, -6.0, -9.0, 8.0, 3.0, 13.0, 9.0, 0.0, 2.0, 4.0, 10.0, 12.0, -5.0, -2.0, 14.0, 3.0, 13.0, -15.0, 0.0, 14.0, 7.0, -6.0, 1.0, 13.0, 8.0, -7.0, -3.0, 13.0, 4.0, 1.0, 14.0, 4.0, -10.0, 7.0, -13.0, 10.0, 8.0, 10.0, 13.0, 13.0, 2.0, -13.0, 12.0, 13.0, -6.0, -4.0, 9.0, 1.0, -5.0, 10.0, 9.0, 8.0, -11.0, 9.0, 4.0, 0.0, 4.0, 7.0, 14.0, 6.0, -10.0, 5.0, 9.0, 1.0, 13.0, -8.0, -18.0, 13.0, 8.0, 12.0, -1.0, -1.0, 9.0, 8.0, -6.0, 7.0, 6.0, 8.0, 6.0, 7.0, 7.0, -5.0, 9.0, 5.0, -11.0, 12.0, 3.0, 12.0, 7.0, -7.0, 2.0, 12.0, -8.0, 9.0, 12.0, 7.0, 2.0, -6.0, -4.0, 5.0, 1.0, 13.0, 12.0, -2.0, 0.0, 5.0, 11.0, 5.0, 0.0, -1.0, 3.0, 4.0, 13.0, -5.0, -9.0, 6.0, 9.0, 9.0, 8.0, 11.0, 4.0, -8.0, 10.0, 8.0, 1.0, -4.0, 13.0, 4.0, -5.0, 3.0, -3.0, 14.0, -4.0, 8.0, 6.0, -2.0, 8.0, 3.0, 10.0, 12.0, 10.0, -17.0, 8.0, 5.0, 8.0, -6.0, 3.0, 9.0, -7.0, 10.0, 5.0, -2.0, 7.0, 5.0, 4.0, 9.0, -10.0, 12.0, 7.0, -9.0, 13.0, 4.0, 10.0, 10.0, 10.0, -15.0, 6.0, 14.0, 4.0, -9.0, 9.0, 12.0, 1.0, -7.0, 10.0, -5.0, 4.0, 6.0, -20.0, 13.0, 11.0, 11.0, 8.0, 12.0, 8.0, -13.0, 13.0, 13.0, 11.0, 319.0, 7.0, 4.0, -9.0, 13.0, -1.0, 10.0, -6.0, 12.0, 3.0, 14.0, 9.0, -11.0, 10.0, 9.0, 3.0, -7.0, 6.0, 5.0, -8.0, 12.0, 6.0, 8.0, 5.0, -4.0, 9.0, 13.0, 1.0, -8.0, 12.0, 9.0, -4.0, -2.0, 4.0, -4.0, 10.0, 5.0, -17.0, 8.0, 12.0, 12.0, 9.0, 11.0, -1.0, -4.0, 11.0, 9.0, 7.0, -12.0, 7.0, -14.0, 9.0, 13.0, 6.0, 7.0, 12.0, -10.0, 9.0, -4.0, 6.0, 4.0, 9.0, 13.0, -3.0, -4.0, 8.0, 13.0, 4.0, -10.0, -4.0, 9.0, -2.0, 12.0, 9.0, -2.0, 5.0, 3.0, 10.0, 8.0, 7.0, -10.0, 7.0, 6.0, -10.0, 12.0, 6.0, 10.0, -10.0, 9.0, 14.0, 10.0, -1.0, -8.0, 12.0, 5.0, -10.0, 8.0, 11.0, 13.0, 5.0, -14.0, 6.0, 10.0, 2.0, -3.0, 7.0, -2.0, -2.0, 12.0, 11.0, 14.0, -6.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18456142919818502, "mean_inference_ms": 1.067746071694154, "mean_action_processing_ms": 0.0715461925927331, "mean_env_wait_ms": 0.17480740676610718, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 220320, "agent_timesteps_total": 220320, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69617181.475, "learn_time_ms": 14.773, "learn_throughput": 372836.048, "update_time_ms": 7.002}, "info": {"learner": {"learned": {"policy_loss": 93778878464.0, "vf_loss": 125.1854476928711, "total_loss": 93778878464.0, "vf_explained_var": -0.0004086494445800781, "model": {}}}, "num_steps_sampled": 220320, "num_agent_steps_sampled": 220320, "num_steps_trained": 220320, "num_agent_steps_trained": 220320}, "done": false, "episodes_total": 4320, "training_iteration": 40, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-39", "timestamp": 1626864459, "time_this_iter_s": 0.3554389476776123, "time_total_s": 15.006861448287964, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 15.006861448287964, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 81.5, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 366.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.52777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 329.0}, "policy_reward_mean": {"learned": 6.131944444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, -1.0, 8.0, 13.0, -10.0, 10.0, 11.0, 4.0, 11.0, -7.0, 6.0, 5.0, -6.0, 13.0, 9.0, -1.0, -1.0, 12.0, -5.0, 9.0, 0.0, 4.0, 12.0, -1.0, 11.0, 12.0, -7.0, -1.0, -15.0, 10.0, 10.0, 10.0, -20.0, 14.0, 9.0, 12.0, 12.0, 12.0, 11.0, -20.0, 13.0, -5.0, 8.0, -1.0, 8.0, 0.0, -4.0, 11.0, 1.0, 12.0, -7.0, 9.0, 9.0, -14.0, 10.0, 10.0, -10.0, 13.0, 0.0, 12.0, 0.0, 1.0, 2.0, 12.0, 4.0, -2.0, 11.0, 2.0, -5.0, 9.0, 2.0, 9.0, 1.0, -5.0, 11.0, 8.0, -2.0, 7.0, -1.0, 11.0, -15.0, 14.0, 10.0, 6.0, -5.0, 8.0, 0.0, 12.0, 12.0, 2.0, 9.0, -8.0, 3.0, 4.0, -3.0, 11.0, 6.0, -4.0, 12.0, 1.0, -1.0, 5.0, -1.0, 12.0, 12.0, 12.0, 5.0, -14.0, 1.0, -8.0, 10.0, 12.0, 319.0, 12.0, 11.0, 13.0, 12.0, -6.0, -3.0, 12.0, 13.0, 8.0, -7.0, 1.0, 11.0, -13.0, 6.0, 11.0, 329.0, 13.0, 11.0, 13.0, 12.0, -10.0, 9.0, 4.0, 11.0, 3.0, -4.0, 5.0, -12.0, 4.0, 13.0, 10.0, -17.0, 14.0, 6.0, 12.0, 5.0, -8.0, 7.0, 11.0, 13.0, 6.0, -11.0, 7.0, 6.0, 5.0, 8.0, -4.0, 315.0, 13.0, 12.0, 13.0, 8.0, 6.0, -11.0, 12.0, 10.0, 13.0, -8.0, 0.0, 2.0, -5.0, 11.0, 7.0, 0.0, -2.0, 12.0, 5.0, -6.0, 3.0, 8.0, 10.0, 9.0, -5.0, 1.0, 10.0, -7.0, 3.0, 10.0, 9.0, -7.0, 13.0, -2.0, 11.0, 11.0, 5.0, 0.0, -1.0, 13.0, 7.0, 11.0, -16.0, 6.0, 6.0, 11.0, -8.0, -22.0, 14.0, 10.0, 13.0, 7.0, 5.0, 8.0, -5.0, -4.0, 8.0, 1.0, 10.0, 10.0, 7.0, 10.0, -12.0, 9.0, -2.0, 7.0, 1.0, 12.0, 5.0, 6.0, -8.0, 9.0, 9.0, 6.0, -9.0, -2.0, 1.0, 6.0, 10.0, -16.0, 13.0, 5.0, 13.0, 12.0, -13.0, 5.0, 11.0, 13.0, -4.0, 6.0, 0.0, 11.0, -9.0, 9.0, 4.0, -4.0, -1.0, 9.0, 11.0, 8.0, -9.0, 9.0, 7.0, 8.0, 9.0, 5.0, -7.0, 12.0, -4.0, -2.0, 9.0, 5.0, -6.0, 8.0, 8.0, 10.0, 4.0, -2.0, 3.0, 10.0, 1.0, 8.0, -4.0, 7.0, 6.0, 11.0, -9.0, -21.0, 13.0, 13.0, 10.0, 10.0, -8.0, 11.0, 2.0, -5.0, 7.0, 10.0, 3.0, 2.0, 6.0, -5.0, 12.0, 5.0, -4.0, 11.0, 3.0, 10.0, 3.0, -8.0, 10.0, 13.0, 7.0, -7.0, 2.0, -11.0, 4.0, 10.0, 12.0, 0.0, 9.0, 12.0, -6.0, 12.0, -9.0, -1.0, 13.0, 7.0, -8.0, 4.0, 12.0, -5.0, 6.0, 9.0, 5.0, 5.0, -3.0, 7.0, 6.0, -9.0, 10.0, 1.0, 13.0, 9.0, 3.0, -4.0, 7.0, 0.0, 3.0, 0.0, 12.0, -2.0, -4.0, 12.0, 9.0, 12.0, 3.0, -11.0, 11.0, 12.0, 13.0, -2.0, -8.0, 11.0, 6.0, -8.0, 6.0, 9.0, -7.0, 9.0, 4.0, 11.0, -5.0, -2.0, 11.0, 8.0, 12.0, 7.0, -12.0, -8.0, 1.0, 12.0, 10.0, 0.0, -8.0, 10.0, 13.0, 10.0, 9.0, -13.0, 9.0, 10.0, 5.0, -11.0, 11.0, -4.0, 12.0, 11.0, -4.0, -11.0, 10.0, 11.0, 5.0, 10.0, -7.0, 0.0, 12.0, 5.0, -9.0, 12.0, 7.0, 7.0, -11.0, 7.0, 12.0, 2.0, -3.0, 10.0, 6.0, -2.0, 6.0, 8.0, 3.0, 9.0, 11.0, -8.0, 3.0, 12.0, -10.0, 12.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1845397435339649, "mean_inference_ms": 1.067829825626851, "mean_action_processing_ms": 0.07153596004203937, "mean_env_wait_ms": 0.17481758480980286, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 225828, "agent_timesteps_total": 225828, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70932580.657, "learn_time_ms": 14.708, "learn_throughput": 374481.109, "update_time_ms": 6.905}, "info": {"learner": {"learned": {"policy_loss": 94914510848.0, "vf_loss": 136.9276885986328, "total_loss": 94914510848.0, "vf_explained_var": -0.0002912282943725586, "model": {}}}, "num_steps_sampled": 225828, "num_agent_steps_sampled": 225828, "num_steps_trained": 225828, "num_agent_steps_trained": 225828}, "done": false, "episodes_total": 4428, "training_iteration": 41, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-40", "timestamp": 1626864460, "time_this_iter_s": 0.35378217697143555, "time_total_s": 15.3606436252594, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 15.3606436252594, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 12.0, -9.0, 13.0, 12.0, -17.0, 8.0, 12.0, 1.0, -2.0, 3.0, 13.0, -5.0, -1.0, 8.0, 13.0, 3.0, 11.0, 6.0, -5.0, -4.0, 14.0, 5.0, 0.0, 2.0, 13.0, -7.0, 7.0, -9.0, 1.0, 10.0, 13.0, -5.0, 13.0, -5.0, 12.0, -6.0, 8.0, 6.0, 7.0, 8.0, 10.0, 12.0, -15.0, -6.0, 9.0, 13.0, -1.0, -6.0, 12.0, -4.0, 13.0, -7.0, 4.0, 6.0, 12.0, 14.0, -7.0, -5.0, 13.0, 7.0, 9.0, 4.0, -5.0, -6.0, 13.0, -5.0, 13.0, 7.0, -1.0, 12.0, -3.0, -1.0, 5.0, 13.0, -2.0, -7.0, 11.0, 12.0, -1.0, -19.0, 12.0, 13.0, 9.0, 6.0, 1.0, 10.0, -2.0, 4.0, 3.0, 12.0, -4.0, 4.0, 6.0, 7.0, -2.0, -17.0, 12.0, 12.0, 8.0, 7.0, -4.0, 2.0, 10.0, -1.0, 4.0, 13.0, -1.0, -2.0, 10.0, 11.0, -4.0, 9.0, 8.0, 9.0, -11.0, 8.0, -12.0, 6.0, 13.0, 6.0, -6.0, 10.0, 5.0, 6.0, 4.0, 7.0, -2.0, -7.0, 11.0, 4.0, 7.0, -11.0, 8.0, 5.0, 13.0, 14.0, 12.0, 316.0, 12.0, 2.0, 8.0, 7.0, -2.0, -7.0, 13.0, -4.0, 13.0, 5.0, 4.0, 7.0, -1.0, 9.0, -13.0, 12.0, 7.0, 5.0, 6.0, 6.0, -2.0, -7.0, 11.0, -2.0, 13.0, -3.0, 4.0, 1.0, 13.0, 13.0, -18.0, 13.0, 7.0, -19.0, 8.0, 13.0, 13.0, -8.0, 7.0, 5.0, 11.0, -8.0, 8.0, 3.0, 12.0, 6.0, -8.0, 9.0, 8.0, -10.0, -1.0, 13.0, 13.0, 319.0, 13.0, 12.0, 11.0, -5.0, 9.0, 5.0, 6.0, 8.0, 13.0, -18.0, 12.0, -21.0, 11.0, 12.0, 13.0, 4.0, 8.0, 9.0, -6.0, -4.0, 14.0, 9.0, -4.0, 7.0, -10.0, 8.0, 10.0, 1.0, 6.0, 10.0, -2.0, -2.0, 5.0, 6.0, 6.0, -4.0, 8.0, 12.0, -1.0, 12.0, -1.0, -4.0, 8.0, -6.0, 11.0, 12.0, -2.0, 9.0, 11.0, -13.0, 8.0, 6.0, 4.0, 7.0, -2.0, 9.0, -2.0, 12.0, -4.0, 5.0, 5.0, 7.0, -2.0, -18.0, 12.0, 8.0, 13.0, 7.0, 8.0, -6.0, 6.0, 9.0, 1.0, -7.0, 12.0, -19.0, 9.0, 12.0, 13.0, -19.0, 11.0, 13.0, 10.0, 9.0, -14.0, 11.0, 9.0, -10.0, 9.0, 6.0, 10.0, -2.0, 8.0, 10.0, -1.0, 8.0, 12.0, 4.0, -9.0, -3.0, 9.0, 5.0, 4.0, 1.0, -10.0, 11.0, 13.0, -6.0, 11.0, 11.0, -1.0, 2.0, 13.0, 13.0, -13.0, 6.0, 10.0, 2.0, -3.0, 4.0, 12.0, -6.0, 5.0, -5.0, 11.0, 11.0, -2.0, 11.0, 13.0, 7.0, -16.0, 7.0, 0.0, 11.0, -3.0, 11.0, -7.0, 13.0, -2.0, 5.0, 7.0, 7.0, -4.0, 0.0, 10.0, 9.0, -4.0, 10.0, -2.0, -5.0, 12.0, 0.0, 12.0, 8.0, -5.0, -18.0, 7.0, 13.0, 13.0, -8.0, 13.0, -3.0, 13.0, -7.0, 8.0, 5.0, 9.0, 12.0, -5.0, -3.0, 11.0, 5.0, -9.0, 6.0, 13.0, -3.0, 11.0, 8.0, -1.0, 6.0, 5.0, 6.0, -2.0, -2.0, 13.0, -4.0, 8.0, -14.0, 4.0, 12.0, 13.0, 11.0, 12.0, 3.0, -11.0, -9.0, 8.0, 12.0, 4.0, 12.0, 4.0, -6.0, 5.0, 0.0, 11.0, 8.0, -4.0, -6.0, 12.0, 8.0, 1.0, 5.0, 7.0, -5.0, 8.0, 10.0, 1.0, 12.0, -8.0, 3.0, 8.0, 5.0, -1.0, -7.0, 13.0, -3.0, 12.0, 8.0, 3.0, 9.0, -5.0, 6.0, -16.0, 12.0, 13.0, -7.0, 2.0, 7.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18456712180498508, "mean_inference_ms": 1.067564106720025, "mean_action_processing_ms": 0.07152479364521579, "mean_env_wait_ms": 0.17481401885300296, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 231336, "agent_timesteps_total": 231336, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69355689.585, "learn_time_ms": 14.857, "learn_throughput": 370734.182, "update_time_ms": 7.238}, "info": {"learner": {"learned": {"policy_loss": 229956780032.0, "vf_loss": 248.14688110351562, "total_loss": 229956780032.0, "vf_explained_var": -4.589557647705078e-05, "model": {}}}, "num_steps_sampled": 231336, "num_agent_steps_sampled": 231336, "num_steps_trained": 231336, "num_agent_steps_trained": 231336}, "done": false, "episodes_total": 4536, "training_iteration": 42, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-40", "timestamp": 1626864460, "time_this_iter_s": 0.36238765716552734, "time_total_s": 15.723031282424927, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 15.723031282424927, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 75.3, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.60185185185185, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 6.900462962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -8.0, 6.0, 7.0, 6.0, 9.0, 7.0, -7.0, 10.0, 13.0, 2.0, -10.0, 8.0, 14.0, 13.0, 319.0, -13.0, 9.0, 11.0, 8.0, -8.0, 8.0, 5.0, 10.0, 4.0, 10.0, 4.0, -3.0, 9.0, 14.0, 11.0, -19.0, -4.0, 3.0, 9.0, 7.0, -6.0, 4.0, 9.0, 8.0, 12.0, 13.0, -20.0, 10.0, -2.0, 13.0, 9.0, -5.0, -2.0, 8.0, 7.0, 2.0, 9.0, 11.0, -15.0, 10.0, -10.0, 11.0, 6.0, 8.0, -5.0, 14.0, -6.0, 12.0, 4.0, 12.0, -9.0, 8.0, -2.0, 9.0, 2.0, 6.0, -9.0, 6.0, 6.0, 12.0, -4.0, 11.0, 13.0, -5.0, 5.0, 10.0, -7.0, 7.0, 8.0, 7.0, -2.0, 2.0, 8.0, -12.0, 8.0, 11.0, -3.0, 13.0, 2.0, 3.0, 10.0, -10.0, 10.0, 5.0, -10.0, 11.0, 8.0, 6.0, 7.0, -7.0, 3.0, 12.0, 10.0, 13.0, 11.0, -19.0, 11.0, 7.0, -4.0, 1.0, -6.0, 8.0, 1.0, 12.0, 2.0, 3.0, -1.0, 11.0, -7.0, 8.0, 7.0, 7.0, 11.0, -9.0, 12.0, 1.0, -1.0, 10.0, -1.0, 7.0, 2.0, 11.0, -3.0, 5.0, -3.0, 14.0, -6.0, 10.0, -3.0, 10.0, 4.0, 4.0, 12.0, -3.0, 1.0, 5.0, 9.0, -13.0, 12.0, 7.0, 9.0, 14.0, 11.0, -19.0, 5.0, -5.0, 10.0, 5.0, -7.0, 8.0, 2.0, 12.0, 12.0, 13.0, -15.0, 5.0, 7.0, 14.0, 4.0, -10.0, 0.0, 10.0, 4.0, 1.0, -7.0, 11.0, 6.0, 5.0, 14.0, 9.0, 5.0, -13.0, -4.0, 14.0, 8.0, -3.0, 11.0, 0.0, 8.0, -4.0, -6.0, 12.0, 3.0, 6.0, 8.0, 12.0, 8.0, -13.0, 10.0, 14.0, 12.0, 320.0, 11.0, -11.0, 5.0, 10.0, -1.0, 4.0, 8.0, 4.0, -10.0, 6.0, 7.0, 12.0, -3.0, 12.0, 13.0, -7.0, 7.0, -7.0, 12.0, 3.0, 4.0, -2.0, 9.0, 4.0, 6.0, -4.0, 0.0, 13.0, 10.0, 11.0, 6.0, -12.0, 11.0, -7.0, 9.0, 2.0, 12.0, 8.0, 6.0, -11.0, -7.0, 6.0, 5.0, 11.0, 10.0, 11.0, -11.0, 5.0, -2.0, 2.0, 5.0, 10.0, -9.0, 8.0, 9.0, 7.0, 4.0, 8.0, -7.0, 10.0, 9.0, 13.0, 13.0, 320.0, -6.0, 5.0, 10.0, 6.0, -1.0, 10.0, 7.0, -1.0, 6.0, 13.0, -16.0, 12.0, 12.0, 13.0, 8.0, -18.0, 10.0, -3.0, -3.0, 11.0, 13.0, 10.0, 7.0, -15.0, 6.0, 11.0, -14.0, 12.0, 8.0, 14.0, -10.0, 3.0, 13.0, 6.0, -9.0, 5.0, -6.0, 4.0, 9.0, 8.0, 8.0, 5.0, -9.0, 11.0, 10.0, 13.0, 13.0, 320.0, 6.0, -7.0, 4.0, 12.0, 8.0, -3.0, 4.0, 6.0, 7.0, 10.0, 11.0, -13.0, 9.0, 14.0, 9.0, -17.0, -8.0, 9.0, 2.0, 12.0, 12.0, 9.0, 10.0, -16.0, 13.0, 11.0, 2.0, -11.0, -3.0, 14.0, -6.0, 10.0, 11.0, -9.0, 12.0, 1.0, 4.0, 3.0, -5.0, 13.0, 13.0, 9.0, -15.0, 8.0, 9.0, 13.0, -9.0, 2.0, 12.0, -11.0, 5.0, 9.0, -1.0, 7.0, 2.0, 7.0, 7.0, 9.0, -9.0, 8.0, -1.0, 11.0, 7.0, -2.0, -2.0, 4.0, 3.0, 10.0, 13.0, -5.0, 4.0, 3.0, 4.0, 8.0, -8.0, 11.0, -11.0, 8.0, 6.0, 12.0, -4.0, 0.0, 11.0, 8.0, -11.0, 11.0, 8.0, 7.0, 4.0, 11.0, -3.0, 3.0, 10.0, 14.0, 1.0, -10.0, 10.0, -9.0, 3.0, 11.0, -1.0, 4.0, 6.0, 6.0, 7.0, -8.0, 9.0, 7.0, -12.0, 11.0, 7.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18452797023160694, "mean_inference_ms": 1.0673243426834138, "mean_action_processing_ms": 0.07150304449279916, "mean_env_wait_ms": 0.1748250896668161, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 236844, "agent_timesteps_total": 236844, "timers": {"sample_time_ms": 0.079, "sample_throughput": 70122102.266, "learn_time_ms": 13.656, "learn_throughput": 403347.046, "update_time_ms": 6.739}, "info": {"learner": {"learned": {"policy_loss": 205330055168.0, "vf_loss": 243.43414306640625, "total_loss": 205330055168.0, "vf_explained_var": -6.878376007080078e-05, "model": {}}}, "num_steps_sampled": 236844, "num_agent_steps_sampled": 236844, "num_steps_trained": 236844, "num_agent_steps_trained": 236844}, "done": false, "episodes_total": 4644, "training_iteration": 43, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-41", "timestamp": 1626864461, "time_this_iter_s": 0.3552107810974121, "time_total_s": 16.07824206352234, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 16.07824206352234, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 5.314814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -19.0, 13.0, 11.0, 14.0, 10.0, -6.0, -3.0, -5.0, 2.0, 10.0, 8.0, 13.0, 11.0, 0.0, -9.0, 10.0, -19.0, 12.0, 12.0, 8.0, 10.0, -2.0, -1.0, 10.0, 8.0, -10.0, 7.0, 13.0, 13.0, 2.0, -13.0, -9.0, -1.0, 13.0, 12.0, 14.0, 8.0, 6.0, -13.0, -5.0, 3.0, 11.0, 6.0, 10.0, 12.0, -12.0, 5.0, 11.0, -16.0, 13.0, 7.0, 13.0, 12.0, -3.0, -7.0, -6.0, 8.0, 6.0, 7.0, 12.0, 13.0, -11.0, 1.0, -14.0, 12.0, 6.0, 11.0, 14.0, 8.0, -7.0, 0.0, -5.0, 9.0, 7.0, 4.0, 12.0, 12.0, 1.0, -10.0, -11.0, 3.0, 12.0, 11.0, -1.0, 14.0, -5.0, 7.0, 11.0, 10.0, 13.0, -19.0, 11.0, 9.0, 1.0, -6.0, -9.0, 5.0, 6.0, 13.0, 13.0, 3.0, -4.0, 3.0, -2.0, 8.0, 0.0, 9.0, 14.0, 12.0, 1.0, -12.0, 9.0, -14.0, 10.0, 10.0, 9.0, 12.0, 8.0, -14.0, -8.0, 11.0, 5.0, 7.0, 10.0, 12.0, 6.0, -13.0, 7.0, -1.0, 10.0, -1.0, 14.0, 13.0, -3.0, -9.0, 10.0, 5.0, -3.0, 3.0, 11.0, 9.0, 2.0, -7.0, 7.0, -2.0, 13.0, -3.0, 13.0, 11.0, -6.0, -3.0, 5.0, 5.0, -6.0, 11.0, 13.0, 13.0, -3.0, -8.0, -4.0, -2.0, 13.0, 8.0, 9.0, 9.0, -7.0, 4.0, -4.0, 8.0, 4.0, 7.0, 10.0, 12.0, -14.0, 7.0, 0.0, 9.0, 13.0, -7.0, 9.0, 11.0, -6.0, 1.0, -4.0, 5.0, 10.0, 4.0, 12.0, 10.0, 3.0, -10.0, 14.0, 0.0, 7.0, -6.0, 14.0, 9.0, 2.0, -10.0, -7.0, 8.0, 3.0, 11.0, 11.0, 12.0, 8.0, -16.0, -5.0, 0.0, 7.0, 13.0, 9.0, 12.0, -1.0, -5.0, -9.0, 9.0, 9.0, 6.0, 14.0, 12.0, 2.0, -13.0, 12.0, 11.0, -16.0, 8.0, 12.0, 9.0, -3.0, -3.0, -9.0, 12.0, 10.0, 2.0, 6.0, 11.0, -9.0, 7.0, -6.0, -1.0, 13.0, 9.0, 14.0, -1.0, 5.0, -3.0, -14.0, 9.0, 13.0, 7.0, 12.0, 10.0, -10.0, 3.0, -3.0, 2.0, 12.0, 4.0, 8.0, 11.0, -7.0, 3.0, -9.0, 6.0, 7.0, 11.0, 13.0, -7.0, 4.0, 5.0, -4.0, -6.0, 13.0, 12.0, -5.0, 11.0, 7.0, 2.0, -6.0, 2.0, 6.0, 13.0, 13.0, -3.0, 11.0, -6.0, 14.0, -15.0, 5.0, 11.0, 13.0, 13.0, 10.0, 316.0, -12.0, 8.0, 7.0, 12.0, 10.0, 10.0, 9.0, -14.0, -3.0, -3.0, 12.0, 9.0, 9.0, 13.0, -7.0, 0.0, -5.0, 9.0, 3.0, 8.0, 13.0, 5.0, 11.0, -14.0, 10.0, 3.0, 13.0, -11.0, 8.0, 12.0, -2.0, -3.0, -4.0, 7.0, 1.0, 11.0, 12.0, 9.0, 6.0, -12.0, 6.0, -16.0, 13.0, 12.0, 10.0, 12.0, -3.0, -4.0, -7.0, 9.0, 5.0, 8.0, 9.0, 12.0, 10.0, -16.0, 13.0, -2.0, 13.0, -9.0, 9.0, 11.0, 1.0, -6.0, -5.0, 5.0, 9.0, 6.0, 11.0, 10.0, 5.0, -11.0, 14.0, 315.0, 13.0, 12.0, 3.0, 12.0, 4.0, -4.0, 9.0, 5.0, 11.0, -10.0, 13.0, 7.0, -7.0, 2.0, -7.0, 2.0, 12.0, 8.0, 14.0, -3.0, 12.0, -8.0, -5.0, 5.0, 11.0, 4.0, 13.0, 10.0, -13.0, 5.0, 9.0, 0.0, 13.0, -7.0, -17.0, 13.0, 10.0, 9.0, -4.0, 4.0, 11.0, 4.0, 13.0, -4.0, -5.0, 11.0, 8.0, 4.0, 5.0, -2.0, 0.0, 12.0, 9.0, -6.0, -3.0, 9.0, 10.0, -1.0, 10.0, 12.0, 8.0, -15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18450099634908496, "mean_inference_ms": 1.0673748244786931, "mean_action_processing_ms": 0.07148614961273655, "mean_env_wait_ms": 0.17480773809001113, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 242352, "agent_timesteps_total": 242352, "timers": {"sample_time_ms": 0.082, "sample_throughput": 66814171.854, "learn_time_ms": 13.867, "learn_throughput": 397193.888, "update_time_ms": 6.897}, "info": {"learner": {"learned": {"policy_loss": 136439996416.0, "vf_loss": 131.7763214111328, "total_loss": 136439996416.0, "vf_explained_var": -0.00028717517852783203, "model": {}}}, "num_steps_sampled": 242352, "num_agent_steps_sampled": 242352, "num_steps_trained": 242352, "num_agent_steps_trained": 242352}, "done": false, "episodes_total": 4752, "training_iteration": 44, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-41", "timestamp": 1626864461, "time_this_iter_s": 0.36652159690856934, "time_total_s": 16.444763660430908, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 16.444763660430908, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 72.4, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-18.0, 8.0, 12.0, 13.0, 12.0, 12.0, -10.0, 1.0, 5.0, 11.0, -9.0, 8.0, 9.0, 11.0, 5.0, -10.0, -21.0, 11.0, 13.0, 12.0, 12.0, 14.0, -16.0, 5.0, 2.0, 11.0, -10.0, 12.0, -6.0, 12.0, 5.0, 4.0, -13.0, 12.0, 12.0, 4.0, -3.0, 12.0, 5.0, 1.0, -2.0, 13.0, -4.0, 8.0, 8.0, 3.0, 6.0, -2.0, -9.0, 9.0, 8.0, 7.0, 11.0, 6.0, 5.0, -7.0, 7.0, 5.0, -10.0, 13.0, -11.0, 12.0, 3.0, 11.0, -1.0, 6.0, -2.0, 12.0, -3.0, 13.0, 3.0, 2.0, -8.0, 0.0, 10.0, 13.0, -15.0, 9.0, 11.0, 10.0, -19.0, 11.0, 11.0, 12.0, 11.0, 0.0, 3.0, 1.0, 8.0, 5.0, 11.0, -9.0, -4.0, -3.0, 10.0, 12.0, 0.0, 8.0, -4.0, 11.0, 13.0, -3.0, 4.0, 1.0, -7.0, 4.0, 5.0, 13.0, 4.0, 9.0, -8.0, 10.0, -12.0, 7.0, 10.0, 10.0, 11.0, -8.0, 1.0, 11.0, 6.0, 10.0, -14.0, 13.0, 7.0, -2.0, 11.0, -1.0, -15.0, 8.0, 11.0, 11.0, 10.0, 10.0, 11.0, -16.0, -14.0, 11.0, 12.0, 6.0, 5.0, 13.0, 11.0, -14.0, 1.0, 11.0, 6.0, -3.0, 12.0, -2.0, 5.0, 0.0, 8.0, 6.0, 5.0, -4.0, 7.0, -6.0, 3.0, 11.0, -17.0, 11.0, 10.0, 11.0, -6.0, 13.0, 2.0, 6.0, 9.0, 3.0, -9.0, 12.0, -2.0, -3.0, 9.0, 11.0, 11.0, 9.0, -4.0, -1.0, 13.0, 14.0, -18.0, 6.0, 2.0, 4.0, -4.0, 13.0, 4.0, 9.0, 11.0, -9.0, 1.0, 8.0, 11.0, -5.0, 11.0, 1.0, 6.0, -3.0, 1.0, 7.0, -6.0, 13.0, 4.0, 9.0, 11.0, -9.0, -9.0, 9.0, 4.0, 11.0, 12.0, 5.0, 11.0, -13.0, 7.0, 6.0, -4.0, 6.0, 8.0, 11.0, 11.0, -15.0, 1.0, 6.0, 10.0, -2.0, 10.0, 8.0, -10.0, 7.0, 2.0, 10.0, -9.0, 12.0, 7.0, -4.0, 5.0, 7.0, -10.0, 9.0, 8.0, 8.0, 9.0, 6.0, -6.0, 6.0, 5.0, 1.0, -3.0, 12.0, 4.0, 11.0, -12.0, 12.0, -15.0, 8.0, 9.0, 13.0, 11.0, -11.0, 11.0, 4.0, 4.0, 2.0, -4.0, 13.0, -7.0, 11.0, -1.0, 12.0, -3.0, 14.0, -5.0, 9.0, -2.0, 14.0, -1.0, 4.0, -6.0, 9.0, 10.0, 2.0, 1.0, 12.0, 6.0, -4.0, -2.0, 9.0, 11.0, -3.0, 11.0, 12.0, 5.0, -13.0, 7.0, 10.0, -14.0, 12.0, -15.0, 10.0, 13.0, 7.0, 6.0, 6.0, -2.0, 5.0, 13.0, 5.0, 11.0, -14.0, 8.0, 4.0, 12.0, -9.0, -5.0, 11.0, 0.0, 9.0, 4.0, 4.0, 8.0, -1.0, -1.0, 14.0, 1.0, 1.0, -7.0, 4.0, 11.0, 7.0, 8.0, -11.0, 8.0, 10.0, -13.0, 8.0, 7.0, 13.0, 10.0, 6.0, -11.0, 10.0, 2.0, 3.0, -2.0, 12.0, -13.0, 10.0, 7.0, 11.0, -14.0, 7.0, 11.0, 11.0, 13.0, 13.0, 0.0, -11.0, 7.0, 10.0, -10.0, 8.0, 9.0, 8.0, 6.0, -8.0, -16.0, 9.0, 13.0, 9.0, 12.0, 8.0, 5.0, -10.0, 1.0, 4.0, -3.0, 13.0, 8.0, 8.0, 7.0, -8.0, 6.0, 7.0, 11.0, -9.0, 13.0, 8.0, -10.0, 4.0, 1.0, 5.0, 12.0, -3.0, -13.0, 11.0, 6.0, 11.0, 0.0, 9.0, 10.0, -4.0, 7.0, 6.0, -10.0, 12.0, 9.0, 1.0, 10.0, -5.0, 9.0, 8.0, 10.0, -12.0, -17.0, 12.0, 8.0, 12.0, 12.0, 5.0, 0.0, -2.0, -11.0, 7.0, 7.0, 12.0, 4.0, 9.0, 9.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1844455851245966, "mean_inference_ms": 1.0666080354235665, "mean_action_processing_ms": 0.07143904700405021, "mean_env_wait_ms": 0.17475227381933425, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 247860, "agent_timesteps_total": 247860, "timers": {"sample_time_ms": 0.08, "sample_throughput": 69145423.624, "learn_time_ms": 13.844, "learn_throughput": 397860.139, "update_time_ms": 6.687}, "info": {"learner": {"learned": {"policy_loss": 1.2435193061828613, "vf_loss": 17.57379150390625, "total_loss": 18.817310333251953, "vf_explained_var": -0.002758622169494629, "model": {}}}, "num_steps_sampled": 247860, "num_agent_steps_sampled": 247860, "num_steps_trained": 247860, "num_agent_steps_trained": 247860}, "done": false, "episodes_total": 4860, "training_iteration": 45, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-42", "timestamp": 1626864462, "time_this_iter_s": 0.3431589603424072, "time_total_s": 16.787922620773315, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 16.787922620773315, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.074074074074074, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7685185185185186}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -7.0, 8.0, 5.0, -3.0, 12.0, 6.0, 0.0, 13.0, 12.0, -3.0, -7.0, 13.0, 3.0, -9.0, 8.0, -2.0, 1.0, 4.0, 12.0, 6.0, 6.0, 7.0, -4.0, 4.0, 12.0, -10.0, 9.0, 13.0, -3.0, -5.0, 10.0, 12.0, -16.0, 7.0, 12.0, -6.0, 14.0, 1.0, 6.0, 12.0, 11.0, 9.0, -16.0, 12.0, -2.0, -8.0, 13.0, 5.0, -11.0, 8.0, 13.0, -9.0, 8.0, 7.0, 9.0, -7.0, 14.0, 4.0, 4.0, 13.0, 3.0, -6.0, 5.0, 9.0, -11.0, 7.0, 10.0, 8.0, -2.0, 11.0, -2.0, -16.0, 13.0, 8.0, 10.0, 13.0, 0.0, -9.0, 11.0, -10.0, 10.0, 3.0, 12.0, -15.0, 6.0, 12.0, 12.0, 9.0, -5.0, 0.0, 11.0, 13.0, -4.0, -7.0, 13.0, -3.0, 8.0, -2.0, 12.0, -2.0, 12.0, -2.0, 7.0, 4.0, 13.0, -13.0, 11.0, 12.0, -5.0, -3.0, 11.0, 10.0, -10.0, 12.0, 3.0, -6.0, 6.0, 4.0, 11.0, -5.0, 14.0, 8.0, -1.0, -1.0, -2.0, 6.0, 12.0, 10.0, -11.0, 4.0, 12.0, 11.0, 13.0, 1.0, -10.0, -7.0, 13.0, 3.0, 7.0, 10.0, -2.0, -3.0, 10.0, -8.0, -3.0, 13.0, 13.0, -10.0, 13.0, 7.0, 5.0, -2.0, 13.0, -4.0, 8.0, 12.0, -19.0, 11.0, 11.0, -7.0, -3.0, 12.0, 13.0, -8.0, 13.0, 5.0, 5.0, 0.0, 14.0, -6.0, 7.0, 0.0, -8.0, 11.0, 12.0, 6.0, -10.0, 6.0, 13.0, -12.0, 13.0, 5.0, 9.0, -10.0, 13.0, 7.0, 5.0, 0.0, -7.0, 10.0, 12.0, 11.0, -16.0, 13.0, 7.0, -9.0, 11.0, 2.0, 11.0, 9.0, -1.0, 10.0, -2.0, 0.0, -7.0, 10.0, 12.0, -11.0, 2.0, 12.0, 12.0, 12.0, 13.0, -2.0, -8.0, -2.0, 14.0, 1.0, 2.0, 13.0, -1.0, -7.0, 10.0, -4.0, 0.0, 12.0, 7.0, -10.0, 12.0, 7.0, 6.0, -4.0, 13.0, 9.0, -2.0, -1.0, -2.0, 8.0, 10.0, 6.0, -17.0, 13.0, 13.0, -7.0, -1.0, 12.0, 11.0, 7.0, -4.0, 1.0, 11.0, 12.0, -2.0, -5.0, 10.0, 10.0, -1.0, 12.0, -6.0, -9.0, 8.0, 12.0, 4.0, 11.0, 10.0, 8.0, -14.0, 0.0, -5.0, 8.0, 12.0, -9.0, -1.0, 12.0, 13.0, -11.0, 9.0, 8.0, 9.0, 7.0, 10.0, -12.0, 10.0, 13.0, -5.0, -3.0, 10.0, -3.0, -2.0, 7.0, 13.0, -13.0, 12.0, 12.0, 4.0, -8.0, 14.0, 4.0, 5.0, 0.0, -7.0, 10.0, 12.0, 8.0, -12.0, 12.0, 7.0, 9.0, 7.0, 8.0, -9.0, 11.0, 9.0, -5.0, 1.0, 0.0, -5.0, 11.0, 9.0, 11.0, -10.0, 7.0, 7.0, -14.0, 14.0, 3.0, 12.0, 3.0, 13.0, -5.0, 5.0, 12.0, -3.0, -6.0, 12.0, -4.0, 6.0, 6.0, 7.0, -6.0, 13.0, 4.0, 4.0, 11.0, 13.0, -17.0, 8.0, 12.0, -3.0, -4.0, 10.0, -11.0, 12.0, 2.0, 12.0, 3.0, 7.0, 7.0, -2.0, 9.0, -3.0, -1.0, 10.0, 12.0, 7.0, 6.0, -10.0, 10.0, -11.0, 8.0, 8.0, 8.0, 14.0, 2.0, -9.0, 7.0, 14.0, 7.0, -12.0, 12.0, -1.0, -7.0, 11.0, 12.0, 5.0, 7.0, -9.0, -12.0, 11.0, 8.0, 8.0, -9.0, 7.0, 6.0, 11.0, 11.0, 0.0, -7.0, 11.0, 10.0, -12.0, 7.0, 10.0, -5.0, 1.0, 6.0, 13.0, -7.0, 14.0, 2.0, 6.0, -2.0, 1.0, 6.0, 10.0, -7.0, -1.0, 11.0, 12.0, -10.0, 14.0, 1.0, 10.0, 6.0, 13.0, -17.0, 13.0, 12.0, -16.0, 10.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18443624703118558, "mean_inference_ms": 1.0665120476128993, "mean_action_processing_ms": 0.07140052852767234, "mean_env_wait_ms": 0.17471587559839957, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 253368, "agent_timesteps_total": 253368, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68779329.144, "learn_time_ms": 14.256, "learn_throughput": 386355.869, "update_time_ms": 6.644}, "info": {"learner": {"learned": {"policy_loss": 256095911936.0, "vf_loss": 238.5457305908203, "total_loss": 256095911936.0, "vf_explained_var": -1.6689300537109375e-05, "model": {}}}, "num_steps_sampled": 253368, "num_agent_steps_sampled": 253368, "num_steps_trained": 253368, "num_agent_steps_trained": 253368}, "done": false, "episodes_total": 4968, "training_iteration": 46, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-42", "timestamp": 1626864462, "time_this_iter_s": 0.3598189353942871, "time_total_s": 17.147741556167603, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 17.147741556167603, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 75.3, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -23.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 14.0, -14.0, 4.0, -3.0, 8.0, -2.0, 12.0, 13.0, -11.0, 10.0, 3.0, 6.0, -2.0, 12.0, -1.0, 14.0, 12.0, 12.0, -23.0, 5.0, 12.0, -13.0, 11.0, 13.0, 3.0, -2.0, 1.0, 3.0, 8.0, -1.0, 5.0, -4.0, 14.0, 6.0, -1.0, -15.0, 13.0, 5.0, 12.0, 12.0, 0.0, -5.0, 8.0, -2.0, 0.0, 4.0, 13.0, 7.0, 14.0, -15.0, 9.0, 2.0, 8.0, 7.0, -2.0, 4.0, 5.0, 10.0, -4.0, -8.0, 6.0, 12.0, 5.0, 4.0, 14.0, -13.0, 10.0, 3.0, 9.0, 8.0, -5.0, -3.0, 11.0, -5.0, 12.0, 10.0, 8.0, -4.0, 1.0, 7.0, 11.0, -11.0, 8.0, 11.0, 7.0, -14.0, 11.0, 11.0, 0.0, -7.0, 11.0, 5.0, 9.0, -1.0, 2.0, 12.0, 14.0, -3.0, -8.0, 7.0, -3.0, 2.0, 9.0, 3.0, 8.0, 5.0, -1.0, 6.0, -10.0, 12.0, 7.0, 13.0, 0.0, -5.0, 7.0, 11.0, 8.0, 3.0, -7.0, -2.0, 10.0, 10.0, -3.0, -3.0, 6.0, 0.0, 12.0, -4.0, 14.0, 10.0, -5.0, -11.0, 8.0, 6.0, 12.0, 13.0, 7.0, 1.0, -6.0, 5.0, 6.0, 5.0, -1.0, 12.0, 14.0, -18.0, 7.0, -2.0, 10.0, 5.0, 2.0, 6.0, -13.0, 12.0, 10.0, -2.0, 12.0, 7.0, -2.0, 13.0, -1.0, -6.0, 9.0, -10.0, 13.0, 5.0, 7.0, 6.0, -6.0, 13.0, 2.0, 8.0, 7.0, 1.0, -1.0, 11.0, 14.0, -19.0, 9.0, -14.0, 13.0, 6.0, 10.0, 14.0, -16.0, 4.0, 13.0, 4.0, 12.0, -2.0, 1.0, 8.0, 14.0, 8.0, -15.0, 5.0, 7.0, 7.0, -4.0, -2.0, -1.0, 12.0, 6.0, 3.0, 6.0, 7.0, -1.0, -1.0, 14.0, -9.0, 11.0, 11.0, 13.0, -17.0, 8.0, 7.0, -15.0, 11.0, 12.0, -9.0, 13.0, 7.0, 4.0, 6.0, 0.0, -1.0, 10.0, 10.0, 9.0, -1.0, -3.0, 6.0, -11.0, 13.0, 7.0, 7.0, -11.0, 6.0, 13.0, 8.0, 10.0, -9.0, 6.0, 3.0, 12.0, -11.0, 11.0, 2.0, -2.0, 3.0, 12.0, 7.0, 8.0, -7.0, 7.0, 9.0, 14.0, -19.0, 11.0, 8.0, 7.0, -12.0, 12.0, -5.0, 10.0, 11.0, -1.0, -8.0, 8.0, 4.0, 11.0, 10.0, -1.0, 9.0, -3.0, 13.0, 7.0, -16.0, 11.0, 12.0, 2.0, -2.0, 3.0, 5.0, -13.0, 13.0, 10.0, 10.0, 10.0, -13.0, 8.0, -6.0, 11.0, 3.0, 7.0, 14.0, -6.0, 9.0, -2.0, 12.0, 2.0, 3.0, -2.0, 13.0, -5.0, -1.0, 8.0, 12.0, 6.0, -14.0, 11.0, 4.0, -7.0, 13.0, 5.0, 3.0, 11.0, -3.0, 4.0, 8.0, 14.0, 6.0, -13.0, 10.0, 8.0, -1.0, -2.0, -7.0, 12.0, -2.0, 12.0, -9.0, 13.0, 1.0, 10.0, 12.0, 0.0, -7.0, 10.0, 9.0, 9.0, 2.0, -5.0, 9.0, -2.0, 9.0, -1.0, 0.0, -2.0, 4.0, 13.0, 11.0, 14.0, -21.0, 11.0, 12.0, 7.0, -14.0, 10.0, 13.0, -4.0, -2.0, 8.0, 1.0, 12.0, 3.0, -1.0, 13.0, -1.0, -8.0, 11.0, -5.0, 9.0, 4.0, 7.0, -4.0, 13.0, -2.0, 8.0, 10.0, 6.0, 1.0, -2.0, 9.0, -13.0, 12.0, 7.0, -13.0, 9.0, 8.0, 11.0, 14.0, -15.0, 8.0, 8.0, 4.0, 8.0, -2.0, 5.0, 13.0, 14.0, -22.0, 10.0, 8.0, -6.0, 1.0, 12.0, 12.0, -5.0, 10.0, -2.0, -9.0, 12.0, -1.0, 13.0, 6.0, -7.0, 4.0, 12.0, 4.0, 13.0, 6.0, -8.0, 14.0, -6.0, 9.0, -2.0, 4.0, 10.0, 2.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18440027014785396, "mean_inference_ms": 1.0662435311629044, "mean_action_processing_ms": 0.07138834880621212, "mean_env_wait_ms": 0.17468998992174145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 258876, "agent_timesteps_total": 258876, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68839157.573, "learn_time_ms": 14.497, "learn_throughput": 379947.083, "update_time_ms": 6.594}, "info": {"learner": {"learned": {"policy_loss": 91198578688.0, "vf_loss": 125.10662841796875, "total_loss": 91198578688.0, "vf_explained_var": -0.00046503543853759766, "model": {}}}, "num_steps_sampled": 258876, "num_agent_steps_sampled": 258876, "num_steps_trained": 258876, "num_agent_steps_trained": 258876}, "done": false, "episodes_total": 5076, "training_iteration": 47, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-42", "timestamp": 1626864462, "time_this_iter_s": 0.3534066677093506, "time_total_s": 17.501148223876953, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18286b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 17.501148223876953, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 83.8, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.685185185185187, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 7.671296296296297}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 13.0, -1.0, -7.0, -7.0, 10.0, 4.0, 8.0, 13.0, 9.0, -19.0, 12.0, 13.0, 14.0, -15.0, 3.0, 12.0, -2.0, 10.0, -5.0, 12.0, 14.0, 11.0, -22.0, 13.0, 10.0, -4.0, -4.0, -2.0, 2.0, 8.0, 7.0, 8.0, 5.0, -3.0, 5.0, 13.0, 13.0, 13.0, 315.0, 11.0, 10.0, -17.0, 11.0, 0.0, 9.0, 9.0, -3.0, 5.0, 11.0, 1.0, -2.0, -2.0, 10.0, -5.0, 12.0, 13.0, 10.0, -13.0, 5.0, 13.0, 11.0, -7.0, -2.0, -4.0, 13.0, -5.0, 11.0, 13.0, 13.0, 12.0, 315.0, 3.0, 10.0, -6.0, 8.0, 10.0, 10.0, -10.0, 5.0, 12.0, 7.0, -8.0, 4.0, -1.0, 14.0, -10.0, 12.0, 0.0, 0.0, 6.0, 9.0, 12.0, 11.0, -7.0, -1.0, 6.0, -4.0, 7.0, 6.0, 14.0, -1.0, -8.0, 10.0, 11.0, 11.0, -2.0, -5.0, 12.0, 4.0, -5.0, 4.0, 8.0, -2.0, 6.0, 3.0, -2.0, 11.0, -4.0, 10.0, 11.0, -6.0, 1.0, 9.0, 14.0, 6.0, -7.0, 2.0, 12.0, -6.0, 9.0, 0.0, 14.0, 13.0, -4.0, -8.0, 8.0, -5.0, -1.0, 13.0, 12.0, 10.0, -8.0, 1.0, 4.0, 13.0, 6.0, -8.0, 13.0, 9.0, -1.0, -6.0, 13.0, 6.0, -12.0, 8.0, 12.0, 14.0, -10.0, -1.0, 1.0, 13.0, -10.0, 11.0, 11.0, 14.0, 11.0, 317.0, 13.0, 10.0, -1.0, -7.0, 10.0, 14.0, 4.0, -13.0, 14.0, 9.0, -17.0, 9.0, 10.0, 0.0, -4.0, 9.0, 9.0, 11.0, -15.0, 10.0, -15.0, 14.0, 9.0, 7.0, 9.0, -7.0, 11.0, 2.0, 12.0, 13.0, -6.0, -4.0, 8.0, 11.0, -11.0, 7.0, 0.0, 9.0, 1.0, 5.0, 4.0, 6.0, 8.0, -3.0, 13.0, 14.0, 318.0, 10.0, 11.0, -13.0, 4.0, 13.0, 0.0, 14.0, 3.0, -2.0, 14.0, 12.0, -19.0, 8.0, 0.0, 13.0, 10.0, -8.0, 11.0, 4.0, -6.0, 6.0, -2.0, 5.0, 6.0, 6.0, 10.0, -12.0, 4.0, 13.0, 12.0, 11.0, -17.0, 9.0, -3.0, 12.0, 0.0, 6.0, 13.0, 13.0, -9.0, -2.0, 11.0, -7.0, 5.0, 6.0, 11.0, 8.0, 10.0, -14.0, 8.0, 8.0, -14.0, 13.0, 13.0, 9.0, -8.0, 1.0, 12.0, -12.0, 12.0, 3.0, -3.0, 13.0, 11.0, -6.0, 2.0, -6.0, 6.0, 13.0, 11.0, 14.0, 2.0, -12.0, 10.0, 2.0, 9.0, -6.0, 13.0, 13.0, -20.0, 9.0, -4.0, 12.0, -1.0, 8.0, 12.0, 7.0, 10.0, -14.0, 4.0, 14.0, -10.0, 7.0, -3.0, 13.0, -3.0, 8.0, -3.0, 6.0, 6.0, 6.0, 12.0, 12.0, 4.0, -13.0, -5.0, 9.0, 8.0, 3.0, -2.0, 10.0, 7.0, 0.0, 7.0, 13.0, 3.0, -8.0, 12.0, 7.0, -10.0, 6.0, 7.0, 3.0, 8.0, -3.0, 13.0, 14.0, -18.0, 6.0, -4.0, 11.0, 2.0, 6.0, -2.0, 13.0, 8.0, -4.0, 11.0, -4.0, 5.0, 3.0, 11.0, 12.0, 11.0, -19.0, 12.0, 11.0, -3.0, -5.0, -2.0, 10.0, 4.0, 3.0, 7.0, 12.0, -15.0, 11.0, 12.0, 14.0, 317.0, 11.0, 13.0, 7.0, -18.0, 13.0, 7.0, -4.0, 6.0, 6.0, 14.0, 7.0, 6.0, -12.0, 0.0, 11.0, 10.0, -6.0, -2.0, 5.0, 4.0, 8.0, 12.0, 9.0, 0.0, -6.0, 4.0, 11.0, -1.0, 1.0, 10.0, 13.0, -2.0, -6.0, 13.0, -10.0, 2.0, 10.0, 14.0, 14.0, -15.0, 2.0, 5.0, 13.0, -9.0, 6.0, -1.0, 14.0, -9.0, 11.0, 10.0, 11.0, -14.0, 8.0, -2.0, 12.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18438856270007853, "mean_inference_ms": 1.0664989868643853, "mean_action_processing_ms": 0.07136619880334319, "mean_env_wait_ms": 0.17466689322382703, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 264384, "agent_timesteps_total": 264384, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68347898.941, "learn_time_ms": 14.259, "learn_throughput": 386293.85, "update_time_ms": 6.217}, "info": {"learner": {"learned": {"policy_loss": 255192449024.0, "vf_loss": 238.5070343017578, "total_loss": 255192449024.0, "vf_explained_var": -1.2040138244628906e-05, "model": {}}}, "num_steps_sampled": 264384, "num_agent_steps_sampled": 264384, "num_steps_trained": 264384, "num_agent_steps_trained": 264384}, "done": false, "episodes_total": 5184, "training_iteration": 48, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-43", "timestamp": 1626864463, "time_this_iter_s": 0.3583216667175293, "time_total_s": 17.859469890594482, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 17.859469890594482, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, -7.0, 7.0, 12.0, 8.0, -8.0, 9.0, 6.0, -9.0, 12.0, 0.0, 12.0, -6.0, 2.0, 8.0, 11.0, 7.0, -16.0, 11.0, 13.0, -9.0, 10.0, 2.0, 12.0, 11.0, 13.0, -14.0, 5.0, -11.0, 9.0, 7.0, 10.0, 4.0, -9.0, 12.0, 8.0, 13.0, 3.0, 2.0, -3.0, 13.0, 6.0, 7.0, -11.0, 2.0, 10.0, 4.0, -1.0, 9.0, 5.0, 13.0, -12.0, 13.0, 11.0, 1.0, -10.0, -8.0, 12.0, 5.0, 6.0, 4.0, 2.0, 12.0, -3.0, 8.0, -13.0, 13.0, 7.0, 12.0, 11.0, -6.0, -2.0, 8.0, -5.0, 5.0, 7.0, 3.0, 10.0, 7.0, -5.0, 3.0, -5.0, 4.0, 13.0, -1.0, 9.0, 11.0, -4.0, 14.0, 10.0, 8.0, -17.0, -10.0, 1.0, 13.0, 11.0, 2.0, -11.0, 13.0, 11.0, -10.0, 1.0, 12.0, 12.0, 5.0, 13.0, 7.0, -10.0, 9.0, 7.0, 8.0, -9.0, 6.0, -10.0, 13.0, 6.0, -7.0, 10.0, 12.0, 0.0, 12.0, -5.0, 7.0, 1.0, 7.0, 8.0, 8.0, -8.0, 1.0, -9.0, 12.0, 11.0, 6.0, 11.0, 7.0, -9.0, 7.0, 11.0, 7.0, -10.0, 7.0, 12.0, -4.0, 0.0, 6.0, -5.0, 13.0, 1.0, -9.0, 13.0, 4.0, 7.0, 12.0, 12.0, -13.0, 4.0, -6.0, 1.0, 8.0, 12.0, 0.0, -4.0, 7.0, 12.0, 5.0, -4.0, 12.0, 2.0, 14.0, 10.0, -14.0, 5.0, -9.0, 9.0, 5.0, 10.0, 6.0, 3.0, -1.0, 7.0, -6.0, 2.0, 7.0, 12.0, 9.0, -6.0, 5.0, 7.0, 9.0, 9.0, 2.0, -5.0, 5.0, -4.0, 8.0, 6.0, 11.0, -15.0, 8.0, 11.0, 12.0, 9.0, 7.0, -13.0, -8.0, 12.0, 12.0, -1.0, 5.0, -12.0, 10.0, 12.0, 10.0, 12.0, -8.0, 1.0, 14.0, 11.0, -1.0, -9.0, -5.0, 5.0, 11.0, 4.0, -6.0, 12.0, 11.0, -2.0, 8.0, -6.0, 2.0, 11.0, -11.0, 11.0, 5.0, 10.0, 7.0, 2.0, 13.0, -7.0, 13.0, 316.0, 12.0, 13.0, 7.0, -9.0, 11.0, 6.0, 3.0, -3.0, 13.0, 2.0, 4.0, 10.0, 8.0, -7.0, 13.0, -7.0, 8.0, 1.0, -8.0, 9.0, 4.0, 10.0, 14.0, 7.0, -13.0, 7.0, -11.0, 2.0, 13.0, 11.0, 0.0, 10.0, 12.0, -7.0, -7.0, 9.0, 8.0, 5.0, -14.0, 13.0, 9.0, 7.0, 6.0, 1.0, 13.0, -5.0, 3.0, -3.0, 7.0, 8.0, -7.0, 6.0, 10.0, 6.0, 6.0, 11.0, -12.0, 10.0, 7.0, 7.0, 13.0, -12.0, -8.0, 6.0, 8.0, 9.0, -5.0, 9.0, 0.0, 11.0, -1.0, 13.0, -9.0, 12.0, 4.0, 7.0, 8.0, -4.0, 4.0, 9.0, 13.0, -11.0, -7.0, -1.0, 11.0, 12.0, 8.0, 8.0, -8.0, 7.0, -7.0, 11.0, 7.0, 4.0, 6.0, -15.0, 13.0, 11.0, -9.0, 7.0, 4.0, 13.0, 1.0, 14.0, -6.0, 6.0, 3.0, 6.0, 7.0, -1.0, 5.0, 5.0, 13.0, -8.0, -12.0, 9.0, 7.0, 11.0, 14.0, -8.0, 3.0, 6.0, -9.0, 7.0, 7.0, 10.0, 11.0, -14.0, 12.0, 6.0, 9.0, -4.0, 5.0, 5.0, -7.0, 12.0, 5.0, 5.0, 2.0, 4.0, 13.0, -4.0, 8.0, -14.0, 13.0, 8.0, -12.0, 10.0, 5.0, 12.0, 14.0, 8.0, -20.0, 13.0, 13.0, 5.0, 4.0, -7.0, -13.0, 8.0, 8.0, 12.0, -3.0, 6.0, 10.0, 2.0, 7.0, 0.0, 5.0, 3.0, -10.0, 1.0, 12.0, 12.0, 7.0, -1.0, 13.0, -4.0, 7.0, 9.0, -13.0, 12.0, 2.0, 13.0, 4.0, -4.0, 4.0, 9.0, -8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1844172050754178, "mean_inference_ms": 1.066872168189865, "mean_action_processing_ms": 0.07135663085829867, "mean_env_wait_ms": 0.1746418710893849, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 269892, "agent_timesteps_total": 269892, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65647391.7, "learn_time_ms": 14.527, "learn_throughput": 379162.614, "update_time_ms": 6.039}, "info": {"learner": {"learned": {"policy_loss": 301563609088.0, "vf_loss": 429.3203125, "total_loss": 301563609088.0, "vf_explained_var": 7.700920104980469e-05, "model": {}}}, "num_steps_sampled": 269892, "num_agent_steps_sampled": 269892, "num_steps_trained": 269892, "num_agent_steps_trained": 269892}, "done": false, "episodes_total": 5292, "training_iteration": 49, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-43", "timestamp": 1626864463, "time_this_iter_s": 0.37328290939331055, "time_total_s": 18.232752799987793, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 18.232752799987793, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 73.0, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 12.0, 1.0, -12.0, -19.0, 13.0, 12.0, 9.0, 13.0, -1.0, 13.0, -10.0, -10.0, 6.0, 8.0, 11.0, 13.0, -1.0, -7.0, 10.0, -16.0, 14.0, 12.0, 5.0, 13.0, -5.0, -6.0, 13.0, -16.0, 13.0, 8.0, 10.0, 14.0, -8.0, -1.0, 10.0, -11.0, 13.0, 7.0, 6.0, 11.0, 7.0, 12.0, -15.0, 5.0, 5.0, -7.0, 12.0, 14.0, 10.0, -4.0, -5.0, 2.0, 13.0, 10.0, -10.0, 12.0, 13.0, 8.0, -18.0, -13.0, 8.0, 8.0, 12.0, 14.0, 11.0, -21.0, 11.0, -11.0, 14.0, 10.0, 2.0, 11.0, -5.0, 1.0, 8.0, -16.0, 14.0, 7.0, 10.0, 12.0, 12.0, 4.0, -13.0, 7.0, 14.0, -10.0, 4.0, 12.0, 8.0, 11.0, -16.0, -14.0, 13.0, 8.0, 8.0, 14.0, 7.0, 6.0, -12.0, 8.0, 9.0, -6.0, 4.0, 12.0, -3.0, -6.0, 12.0, 10.0, 11.0, 0.0, -6.0, 13.0, 8.0, 0.0, -6.0, -17.0, 13.0, 11.0, 8.0, 7.0, -5.0, 8.0, 5.0, -3.0, 9.0, -3.0, 12.0, 14.0, -6.0, -4.0, 11.0, -1.0, 13.0, -3.0, 6.0, 11.0, 8.0, -17.0, 13.0, -4.0, 14.0, 8.0, -3.0, 13.0, 9.0, -4.0, -3.0, 3.0, 14.0, 6.0, -8.0, 11.0, 11.0, -20.0, 13.0, -1.0, 13.0, 7.0, -4.0, 0.0, 12.0, 4.0, -1.0, 3.0, 9.0, 9.0, -6.0, 9.0, -1.0, -4.0, 11.0, 1.0, -4.0, 11.0, 7.0, -1.0, 11.0, -4.0, 9.0, 3.0, 14.0, -8.0, 6.0, 10.0, 8.0, 13.0, -16.0, -5.0, 7.0, 7.0, 6.0, 13.0, 11.0, -9.0, 0.0, 5.0, 8.0, 6.0, -4.0, 11.0, -7.0, 12.0, -1.0, -14.0, 10.0, 8.0, 11.0, 13.0, 11.0, -3.0, -6.0, 2.0, 13.0, 4.0, -4.0, 8.0, -9.0, 7.0, 9.0, -8.0, 7.0, 8.0, 8.0, 13.0, 5.0, 0.0, -3.0, 2.0, 14.0, -9.0, 8.0, 13.0, 9.0, 13.0, -20.0, 2.0, 8.0, -3.0, 8.0, 13.0, 13.0, -1.0, -10.0, -11.0, 14.0, 7.0, 5.0, 10.0, 6.0, 13.0, -14.0, 6.0, 8.0, 8.0, -7.0, 13.0, -6.0, 11.0, -3.0, -2.0, 13.0, -4.0, 8.0, 13.0, -5.0, 11.0, -4.0, -10.0, 7.0, 7.0, 11.0, -1.0, 7.0, -1.0, 10.0, -16.0, 14.0, 8.0, 9.0, 12.0, -2.0, 6.0, -1.0, -10.0, 14.0, 2.0, 9.0, 14.0, 11.0, -4.0, -6.0, -9.0, 14.0, 3.0, 7.0, 12.0, -7.0, 12.0, -2.0, -14.0, 10.0, 8.0, 11.0, 13.0, 12.0, -3.0, -7.0, 3.0, 13.0, -5.0, 4.0, 11.0, 0.0, 5.0, -1.0, -15.0, 11.0, 7.0, 12.0, 0.0, 14.0, -7.0, 8.0, 2.0, 7.0, 12.0, -6.0, 11.0, 8.0, 13.0, -17.0, 2.0, 10.0, 5.0, -2.0, -3.0, 8.0, -1.0, 11.0, -19.0, 14.0, 12.0, 8.0, 8.0, 5.0, 13.0, -11.0, -1.0, 14.0, -3.0, 5.0, 12.0, 11.0, -17.0, 9.0, 7.0, 10.0, 4.0, -6.0, 11.0, 0.0, -4.0, 8.0, -11.0, 10.0, 8.0, 8.0, -2.0, 13.0, -6.0, 10.0, -3.0, 13.0, 12.0, -7.0, 14.0, 10.0, -14.0, 5.0, -12.0, 14.0, 7.0, 6.0, 14.0, -1.0, -1.0, 3.0, 7.0, 13.0, -12.0, 7.0, -3.0, 12.0, 5.0, 1.0, 0.0, 12.0, 8.0, -5.0, 13.0, 13.0, -6.0, -5.0, 7.0, 14.0, -6.0, 0.0, 10.0, 9.0, 13.0, -17.0, -2.0, 13.0, 6.0, -2.0, 13.0, 12.0, -3.0, -7.0, -12.0, 14.0, 5.0, 8.0, 12.0, -7.0, 5.0, 5.0, -9.0, 13.0, 1.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18443954356363065, "mean_inference_ms": 1.0670518333409211, "mean_action_processing_ms": 0.07137199579857223, "mean_env_wait_ms": 0.17464294789264853, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 275400, "agent_timesteps_total": 275400, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65748636.588, "learn_time_ms": 14.543, "learn_throughput": 378726.265, "update_time_ms": 5.786}, "info": {"learner": {"learned": {"policy_loss": 89844760576.0, "vf_loss": 127.45108032226562, "total_loss": 89844760576.0, "vf_explained_var": -0.0003235340118408203, "model": {}}}, "num_steps_sampled": 275400, "num_agent_steps_sampled": 275400, "num_steps_trained": 275400, "num_agent_steps_trained": 275400}, "done": false, "episodes_total": 5400, "training_iteration": 50, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-44", "timestamp": 1626864464, "time_this_iter_s": 0.35104966163635254, "time_total_s": 18.583802461624146, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 18.583802461624146, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 14.0, -16.0, 8.0, 8.0, 7.0, 8.0, -8.0, 9.0, 12.0, 8.0, -14.0, 7.0, 12.0, 6.0, -10.0, 0.0, 13.0, 11.0, -9.0, 12.0, 4.0, -12.0, 11.0, -8.0, 12.0, 8.0, 3.0, 10.0, -8.0, 4.0, 9.0, 4.0, 0.0, 2.0, 9.0, 12.0, 7.0, 9.0, -13.0, 3.0, 12.0, -7.0, 7.0, 9.0, 12.0, 10.0, -16.0, 11.0, -7.0, 8.0, 3.0, 7.0, 10.0, 5.0, -7.0, 4.0, 0.0, 8.0, 3.0, -3.0, 13.0, 0.0, 5.0, 6.0, -6.0, 7.0, 8.0, 4.0, 12.0, 9.0, -10.0, 0.0, 13.0, 10.0, -8.0, -7.0, 12.0, 0.0, 10.0, 4.0, 13.0, -7.0, 5.0, 6.0, 12.0, -12.0, 9.0, 2.0, -1.0, 6.0, 8.0, 8.0, 12.0, -14.0, 9.0, 9.0, 9.0, 11.0, -14.0, 13.0, 10.0, -14.0, 6.0, 7.0, -6.0, 6.0, 8.0, 11.0, 13.0, -6.0, -3.0, -10.0, 14.0, 9.0, 2.0, 12.0, 4.0, -10.0, 9.0, -12.0, 14.0, 5.0, 8.0, 12.0, 9.0, 3.0, -9.0, 5.0, 8.0, -7.0, 9.0, 8.0, 6.0, -8.0, 9.0, 2.0, 13.0, 7.0, -7.0, 11.0, 13.0, 5.0, -14.0, 4.0, -4.0, 4.0, 11.0, 12.0, 7.0, -3.0, -1.0, 3.0, -2.0, 5.0, 9.0, -8.0, 13.0, 10.0, 0.0, 6.0, 12.0, -10.0, 7.0, 8.0, 11.0, 0.0, -4.0, 13.0, -1.0, 0.0, 3.0, 14.0, 13.0, -9.0, -3.0, 5.0, 6.0, -4.0, 8.0, 13.0, 5.0, 0.0, -3.0, -7.0, 14.0, 5.0, 3.0, 6.0, 12.0, -11.0, 8.0, 10.0, 13.0, -17.0, 9.0, 11.0, 6.0, 4.0, -6.0, -11.0, 13.0, 6.0, 7.0, 12.0, 8.0, -7.0, 2.0, 1.0, 0.0, 11.0, 3.0, 12.0, 2.0, -8.0, 9.0, 7.0, 12.0, 3.0, -7.0, 7.0, 12.0, 5.0, -9.0, 7.0, -5.0, 13.0, 0.0, 4.0, 9.0, 5.0, -3.0, 0.0, 0.0, 8.0, 7.0, -3.0, 10.0, 10.0, -2.0, -2.0, 13.0, -4.0, 8.0, 9.0, 13.0, -8.0, 1.0, -13.0, 12.0, 9.0, 7.0, 11.0, 14.0, 3.0, -13.0, -6.0, 5.0, 9.0, 7.0, 10.0, 8.0, 4.0, -7.0, 1.0, 13.0, 9.0, -8.0, 4.0, 13.0, -5.0, 3.0, 7.0, 6.0, -5.0, 7.0, 12.0, 12.0, 4.0, -13.0, 8.0, 13.0, -10.0, 4.0, -4.0, 10.0, 4.0, 5.0, 9.0, 9.0, 10.0, -13.0, 13.0, 12.0, -8.0, -2.0, 1.0, 7.0, 11.0, -4.0, -3.0, 13.0, 1.0, 4.0, 4.0, 0.0, 9.0, 2.0, 7.0, 11.0, -14.0, 11.0, -6.0, 14.0, 3.0, 4.0, 9.0, 13.0, -17.0, 10.0, 6.0, 10.0, 4.0, -5.0, 12.0, 5.0, 9.0, -11.0, 3.0, -3.0, 8.0, 7.0, 11.0, 9.0, 4.0, -9.0, 9.0, 14.0, -15.0, 7.0, 13.0, 12.0, -8.0, -2.0, 2.0, 7.0, 13.0, -7.0, 13.0, -5.0, 7.0, 0.0, 7.0, 11.0, -3.0, 0.0, 12.0, 12.0, 4.0, -13.0, 9.0, 8.0, 7.0, -9.0, -3.0, 12.0, 4.0, 2.0, 10.0, 14.0, 4.0, -13.0, 13.0, 7.0, 3.0, -8.0, -12.0, 12.0, 10.0, 5.0, 9.0, 13.0, -11.0, 4.0, 5.0, 9.0, 9.0, -8.0, 13.0, 6.0, 8.0, -12.0, 1.0, -1.0, 12.0, 3.0, 7.0, 13.0, -12.0, 7.0, 11.0, 14.0, -15.0, 5.0, 9.0, 12.0, -13.0, 7.0, 4.0, 0.0, 7.0, 4.0, 3.0, 13.0, -10.0, 9.0, 11.0, -8.0, 9.0, 3.0, 11.0, 12.0, -8.0, 0.0, 0.0, 13.0, 6.0, -4.0, 8.0, 13.0, -4.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18444330135102885, "mean_inference_ms": 1.0670778549264672, "mean_action_processing_ms": 0.07135675468894952, "mean_env_wait_ms": 0.1746545160527708, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 280908, "agent_timesteps_total": 280908, "timers": {"sample_time_ms": 0.086, "sample_throughput": 64296970.481, "learn_time_ms": 14.607, "learn_throughput": 377088.09, "update_time_ms": 5.741}, "info": {"learner": {"learned": {"policy_loss": 459025842176.0, "vf_loss": 466.1714782714844, "total_loss": 459025842176.0, "vf_explained_var": 1.6689300537109375e-05, "model": {}}}, "num_steps_sampled": 280908, "num_agent_steps_sampled": 280908, "num_steps_trained": 280908, "num_agent_steps_trained": 280908}, "done": false, "episodes_total": 5508, "training_iteration": 51, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-44", "timestamp": 1626864464, "time_this_iter_s": 0.3554408550262451, "time_total_s": 18.93924331665039, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 18.93924331665039, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 73.2, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 14.0, 10.0, -6.0, 8.0, -5.0, 6.0, 6.0, 14.0, 0.0, -8.0, 9.0, 9.0, -14.0, 10.0, 10.0, 9.0, 12.0, 12.0, -18.0, -2.0, 8.0, 13.0, -4.0, 11.0, -11.0, 7.0, 8.0, 11.0, -10.0, 8.0, 6.0, 0.0, 11.0, -9.0, 13.0, 12.0, -3.0, 0.0, 6.0, -18.0, 12.0, 9.0, 12.0, 12.0, -3.0, 11.0, -5.0, 3.0, 12.0, 6.0, -6.0, -12.0, 11.0, 11.0, 5.0, 13.0, -15.0, 11.0, 6.0, 11.0, -6.0, 12.0, -2.0, -12.0, 13.0, 8.0, 6.0, 10.0, -1.0, 2.0, 4.0, 10.0, 7.0, 6.0, -8.0, 6.0, -5.0, 10.0, 4.0, 6.0, 13.0, 4.0, -8.0, -7.0, 5.0, 6.0, 11.0, 11.0, 1.0, -4.0, 7.0, 9.0, -11.0, 6.0, 11.0, -6.0, 11.0, 12.0, -2.0, -3.0, 11.0, 5.0, 2.0, 13.0, -17.0, 9.0, 10.0, 8.0, -5.0, 7.0, 5.0, 0.0, 11.0, 5.0, -1.0, -2.0, 13.0, 9.0, -5.0, 13.0, 1.0, -10.0, 11.0, 13.0, 5.0, -9.0, 6.0, -3.0, 10.0, 9.0, -1.0, 1.0, -6.0, 13.0, 7.0, 11.0, 6.0, 6.0, -8.0, 10.0, -14.0, 9.0, 10.0, -6.0, 12.0, 7.0, 2.0, 0.0, 9.0, 10.0, -4.0, 13.0, -10.0, 7.0, 5.0, -5.0, 3.0, 12.0, 5.0, -18.0, 12.0, 9.0, 12.0, -3.0, -4.0, 13.0, 9.0, 11.0, -1.0, 12.0, -7.0, 13.0, -9.0, 3.0, 8.0, 10.0, -2.0, 9.0, -2.0, 8.0, 11.0, 5.0, -9.0, 9.0, 3.0, -2.0, 5.0, 8.0, 14.0, 3.0, -10.0, 3.0, 12.0, 7.0, -7.0, 8.0, 8.0, 8.0, -9.0, -2.0, -4.0, 9.0, 12.0, 12.0, 2.0, -11.0, 12.0, 2.0, -1.0, 12.0, 2.0, 1.0, 13.0, 8.0, -7.0, 12.0, 3.0, 8.0, -8.0, 12.0, 8.0, 12.0, -17.0, 8.0, 13.0, -8.0, 2.0, -8.0, 11.0, 8.0, 4.0, 12.0, -4.0, 10.0, -3.0, -1.0, 2.0, 9.0, 5.0, -3.0, 12.0, 7.0, -1.0, -2.0, 8.0, 12.0, -3.0, 8.0, 8.0, -8.0, 7.0, 11.0, 4.0, 10.0, -10.0, -9.0, 10.0, 9.0, 5.0, -10.0, 13.0, 12.0, 0.0, 13.0, 0.0, 8.0, -6.0, -5.0, 3.0, 12.0, 5.0, 8.0, 13.0, 8.0, -14.0, 12.0, -4.0, 2.0, 5.0, 13.0, 1.0, -4.0, 5.0, 10.0, -5.0, 12.0, -2.0, -12.0, 12.0, 6.0, 9.0, -9.0, 7.0, 6.0, 11.0, 14.0, -2.0, -2.0, 5.0, 9.0, 4.0, 12.0, -10.0, 7.0, 12.0, -2.0, -2.0, 3.0, 10.0, 8.0, -6.0, 11.0, 0.0, -3.0, 7.0, -2.0, 4.0, 4.0, 9.0, -15.0, 13.0, 9.0, 8.0, 11.0, 7.0, 6.0, -9.0, 14.0, 0.0, 9.0, -8.0, -5.0, 3.0, 11.0, 6.0, -1.0, 13.0, 9.0, -6.0, -4.0, 10.0, 13.0, -4.0, 13.0, -16.0, 12.0, 6.0, 11.0, -9.0, 8.0, 5.0, 9.0, 10.0, 7.0, -11.0, 2.0, 13.0, 8.0, -8.0, -1.0, 0.0, 7.0, 9.0, 9.0, 6.0, 7.0, -7.0, 4.0, 11.0, 6.0, -6.0, 7.0, 14.0, 7.0, -13.0, 11.0, 4.0, -8.0, 8.0, 6.0, 0.0, 10.0, -1.0, 8.0, 8.0, -2.0, 1.0, 6.0, 13.0, 5.0, -9.0, 12.0, -12.0, 9.0, 6.0, -3.0, 9.0, 1.0, 8.0, 9.0, 10.0, -3.0, -1.0, -15.0, 13.0, 6.0, 11.0, 13.0, -16.0, 10.0, 8.0, 9.0, -5.0, 2.0, 9.0, -1.0, 14.0, -5.0, 7.0, -15.0, 13.0, 9.0, 8.0, 13.0, 5.0, -9.0, 6.0, 11.0, 1.0, 12.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18443791034451437, "mean_inference_ms": 1.067069316573466, "mean_action_processing_ms": 0.07137200993533353, "mean_env_wait_ms": 0.17465941840045524, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 286416, "agent_timesteps_total": 286416, "timers": {"sample_time_ms": 0.086, "sample_throughput": 64034374.628, "learn_time_ms": 14.628, "learn_throughput": 376528.811, "update_time_ms": 5.413}, "info": {"learner": {"learned": {"policy_loss": 115493396480.0, "vf_loss": 132.5293731689453, "total_loss": 115493396480.0, "vf_explained_var": -0.0002925395965576172, "model": {}}}, "num_steps_sampled": 286416, "num_agent_steps_sampled": 286416, "num_steps_trained": 286416, "num_agent_steps_trained": 286416}, "done": false, "episodes_total": 5616, "training_iteration": 52, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-44", "timestamp": 1626864464, "time_this_iter_s": 0.35584568977355957, "time_total_s": 19.29508900642395, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 19.29508900642395, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 9.0, 6.0, 10.0, 9.0, -5.0, 3.0, 8.0, 9.0, -5.0, 8.0, 3.0, 14.0, -8.0, 5.0, 4.0, -1.0, 8.0, 0.0, 8.0, 14.0, 10.0, -13.0, 4.0, 6.0, -4.0, 9.0, 4.0, 14.0, -10.0, 13.0, -2.0, 14.0, 13.0, -5.0, -7.0, 14.0, 9.0, 6.0, -14.0, 14.0, -12.0, 2.0, 11.0, 14.0, 7.0, 11.0, -17.0, 11.0, 8.0, -16.0, 12.0, 0.0, -4.0, 7.0, 12.0, 7.0, -1.0, 12.0, -3.0, 14.0, 13.0, 317.0, 11.0, 10.0, 7.0, 12.0, -14.0, 10.0, 9.0, -4.0, 0.0, 12.0, 0.0, 9.0, -6.0, 11.0, 14.0, -21.0, 11.0, -1.0, 7.0, -3.0, 12.0, 9.0, -8.0, 6.0, 8.0, 13.0, -9.0, 6.0, 5.0, 13.0, 0.0, -5.0, 7.0, -8.0, 14.0, 10.0, -1.0, 13.0, -8.0, 8.0, 2.0, 6.0, 14.0, 4.0, -9.0, 13.0, 13.0, 2.0, -13.0, -1.0, 14.0, 6.0, -4.0, 8.0, 11.0, -9.0, 5.0, -6.0, 13.0, 8.0, 0.0, 14.0, -9.0, 11.0, -1.0, -5.0, 8.0, 0.0, 12.0, 14.0, 9.0, -11.0, 3.0, 11.0, 14.0, 7.0, -17.0, 12.0, -6.0, 0.0, 9.0, 12.0, -6.0, 9.0, 0.0, 9.0, 9.0, 4.0, -7.0, 14.0, 0.0, -4.0, 5.0, 11.0, 13.0, -19.0, 10.0, -5.0, 6.0, 11.0, 3.0, 10.0, 10.0, 7.0, -12.0, 9.0, 10.0, -12.0, 8.0, 14.0, 10.0, 4.0, -13.0, -5.0, 7.0, 2.0, 11.0, 9.0, -3.0, 10.0, -1.0, 14.0, 0.0, -10.0, 11.0, 9.0, 11.0, 9.0, -14.0, 12.0, -5.0, 4.0, 4.0, 5.0, -4.0, 9.0, 5.0, 13.0, 0.0, -6.0, 8.0, 14.0, -5.0, 5.0, 1.0, -2.0, 8.0, 3.0, 6.0, 14.0, 6.0, -10.0, 5.0, 13.0, 0.0, 7.0, -5.0, 11.0, 8.0, 0.0, -4.0, 12.0, 2.0, 11.0, -10.0, 14.0, 3.0, -5.0, 3.0, 6.0, -4.0, 5.0, 8.0, 9.0, -1.0, 11.0, -4.0, -5.0, 9.0, 4.0, 7.0, 13.0, -3.0, -1.0, 6.0, 13.0, 0.0, -9.0, 11.0, 14.0, 9.0, -15.0, 7.0, 13.0, 14.0, 7.0, -19.0, 14.0, 5.0, -7.0, 3.0, 8.0, -13.0, 11.0, 9.0, 11.0, 6.0, 4.0, -6.0, -2.0, 11.0, 6.0, 0.0, 14.0, 10.0, -16.0, 7.0, 9.0, -5.0, 5.0, 6.0, 11.0, 10.0, 1.0, -7.0, 14.0, 11.0, -19.0, 9.0, 9.0, 10.0, -10.0, 6.0, 13.0, -1.0, 11.0, -8.0, 14.0, -1.0, 0.0, 2.0, -1.0, 11.0, 8.0, -3.0, 4.0, -2.0, 6.0, 7.0, 13.0, -3.0, 11.0, -6.0, 14.0, 8.0, 10.0, -17.0, -1.0, 11.0, -2.0, 7.0, 6.0, 12.0, -5.0, 2.0, 13.0, 14.0, -21.0, 9.0, 14.0, 0.0, -2.0, 3.0, 6.0, 13.0, -7.0, 3.0, 9.0, -1.0, 6.0, 1.0, 13.0, -1.0, -8.0, 11.0, 12.0, -3.0, 2.0, 4.0, -3.0, 7.0, 1.0, 10.0, 5.0, -2.0, 4.0, 8.0, 13.0, 10.0, -5.0, -3.0, 14.0, -5.0, -5.0, 11.0, 0.0, 12.0, 3.0, 0.0, 8.0, 7.0, -7.0, 7.0, 11.0, 13.0, -19.0, 10.0, 9.0, 13.0, -5.0, -2.0, 14.0, 10.0, -5.0, -4.0, 9.0, -3.0, 6.0, 3.0, 0.0, 14.0, -5.0, 6.0, 12.0, 10.0, -15.0, 8.0, 13.0, -1.0, -3.0, 6.0, 14.0, 10.0, -15.0, 6.0, 9.0, -3.0, 3.0, 6.0, 14.0, 6.0, 0.0, -5.0, 0.0, 13.0, 1.0, 1.0, 13.0, 8.0, -8.0, 2.0, 14.0, 0.0, -8.0, 9.0, 14.0, -5.0, -6.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18439290261804414, "mean_inference_ms": 1.066887736911334, "mean_action_processing_ms": 0.07134347956135112, "mean_env_wait_ms": 0.1746282861345707, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 291924, "agent_timesteps_total": 291924, "timers": {"sample_time_ms": 0.088, "sample_throughput": 62916286.322, "learn_time_ms": 14.504, "learn_throughput": 379755.968, "update_time_ms": 5.395}, "info": {"learner": {"learned": {"policy_loss": 30034671616.0, "vf_loss": 123.98622131347656, "total_loss": 30034671616.0, "vf_explained_var": -0.00043082237243652344, "model": {}}}, "num_steps_sampled": 291924, "num_agent_steps_sampled": 291924, "num_steps_trained": 291924, "num_agent_steps_trained": 291924}, "done": false, "episodes_total": 5724, "training_iteration": 53, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-45", "timestamp": 1626864465, "time_this_iter_s": 0.35138773918151855, "time_total_s": 19.64647674560547, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18286ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 19.64647674560547, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 79.1, "ram_util_percent": 14.0}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 6.0, 11.0, -14.0, -2.0, -4.0, 11.0, 10.0, 10.0, 6.0, -5.0, 4.0, 5.0, 4.0, -2.0, 8.0, 12.0, 6.0, -1.0, -2.0, -10.0, 6.0, 13.0, 6.0, 5.0, -5.0, 8.0, 7.0, 9.0, -12.0, 7.0, 11.0, -2.0, 7.0, 5.0, 5.0, 5.0, 2.0, -5.0, 13.0, 8.0, -8.0, 5.0, 10.0, 5.0, -8.0, 7.0, 11.0, 10.0, 5.0, 8.0, -8.0, 11.0, 3.0, 12.0, -11.0, -6.0, 12.0, 13.0, -4.0, 5.0, 3.0, -2.0, 9.0, 14.0, 8.0, 10.0, -17.0, -9.0, 6.0, 8.0, 10.0, 11.0, -13.0, 11.0, 6.0, 9.0, -10.0, 10.0, 6.0, 12.0, 12.0, 10.0, -19.0, 9.0, 8.0, 9.0, -11.0, -6.0, 8.0, 8.0, 5.0, 0.0, 0.0, 12.0, 3.0, 10.0, 8.0, -1.0, -2.0, 5.0, 2.0, 13.0, -5.0, 9.0, 8.0, 6.0, -8.0, -14.0, 8.0, 9.0, 12.0, 14.0, 2.0, 10.0, -11.0, -9.0, 8.0, 4.0, 12.0, 11.0, 6.0, 8.0, -10.0, -14.0, 8.0, 9.0, 12.0, 13.0, 3.0, -2.0, 1.0, -7.0, 3.0, 11.0, 8.0, -4.0, 4.0, 10.0, 5.0, 8.0, -9.0, 6.0, 10.0, 13.0, -2.0, 10.0, -6.0, -8.0, 2.0, 11.0, 10.0, 13.0, -9.0, 6.0, 5.0, -8.0, 4.0, 8.0, 11.0, 11.0, 9.0, 12.0, -17.0, 4.0, 2.0, 13.0, -4.0, 8.0, 12.0, 5.0, -10.0, 13.0, -18.0, 10.0, 10.0, 14.0, 4.0, 10.0, -13.0, -4.0, 4.0, 12.0, 3.0, 10.0, 7.0, -7.0, 5.0, 8.0, -9.0, 3.0, 13.0, 14.0, 7.0, -4.0, -2.0, -15.0, 9.0, 12.0, 9.0, 9.0, 6.0, 6.0, -6.0, 12.0, -12.0, 3.0, 12.0, 12.0, 6.0, 11.0, -14.0, 9.0, 8.0, -8.0, 6.0, -5.0, 12.0, 8.0, 0.0, 13.0, -10.0, 12.0, 0.0, 12.0, 7.0, -7.0, 3.0, -4.0, -2.0, 13.0, 8.0, -10.0, 11.0, 13.0, 1.0, -1.0, 5.0, 0.0, 11.0, 7.0, 10.0, -14.0, 12.0, -3.0, 4.0, 3.0, 11.0, 8.0, 7.0, -3.0, 3.0, 8.0, -14.0, 12.0, 9.0, 9.0, 10.0, -16.0, 12.0, -5.0, 7.0, 2.0, 11.0, -7.0, 11.0, 8.0, 3.0, 3.0, -10.0, 12.0, 10.0, 11.0, 7.0, 10.0, -13.0, -9.0, 12.0, 5.0, 7.0, -10.0, 10.0, 9.0, 6.0, -7.0, 0.0, 10.0, 12.0, 13.0, 6.0, 11.0, -15.0, -9.0, 6.0, 11.0, 7.0, 12.0, 7.0, 6.0, -10.0, 4.0, 13.0, -11.0, 9.0, 12.0, 9.0, 8.0, -14.0, 5.0, 6.0, -9.0, 13.0, 9.0, 10.0, -17.0, 13.0, -1.0, 12.0, -6.0, 10.0, 11.0, 10.0, 11.0, -17.0, -9.0, 8.0, 3.0, 13.0, 8.0, -6.0, 7.0, 6.0, 13.0, -12.0, 12.0, 2.0, 8.0, 11.0, 7.0, -11.0, -10.0, 4.0, 12.0, 9.0, 9.0, 13.0, 13.0, -20.0, -6.0, -1.0, 12.0, 10.0, 13.0, 4.0, 8.0, -10.0, 3.0, -8.0, 11.0, 9.0, 14.0, 7.0, 7.0, -13.0, 8.0, -3.0, -1.0, 11.0, -2.0, 10.0, -5.0, 12.0, -5.0, 8.0, 11.0, 1.0, 10.0, -5.0, 9.0, 1.0, 7.0, 5.0, -9.0, 12.0, -4.0, 6.0, 11.0, 2.0, -13.0, 7.0, 13.0, 8.0, -1.0, 6.0, 7.0, 3.0, 9.0, -5.0, 0.0, 11.0, 12.0, 8.0, 9.0, -14.0, 9.0, 9.0, -10.0, 7.0, 9.0, 6.0, 8.0, -8.0, 3.0, -10.0, 11.0, 11.0, 11.0, 12.0, 11.0, -19.0, -9.0, 6.0, 11.0, 7.0, -1.0, -1.0, 13.0, 4.0, 0.0, -4.0, 8.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18434835781388917, "mean_inference_ms": 1.066486791372231, "mean_action_processing_ms": 0.07130475807759978, "mean_env_wait_ms": 0.1746628874763932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 297432, "agent_timesteps_total": 297432, "timers": {"sample_time_ms": 0.088, "sample_throughput": 62424561.77, "learn_time_ms": 14.859, "learn_throughput": 370675.888, "update_time_ms": 5.845}, "info": {"learner": {"learned": {"policy_loss": 115052593152.0, "vf_loss": 132.50283813476562, "total_loss": 115052593152.0, "vf_explained_var": -0.00030744075775146484, "model": {}}}, "num_steps_sampled": 297432, "num_agent_steps_sampled": 297432, "num_steps_trained": 297432, "num_agent_steps_trained": 297432}, "done": false, "episodes_total": 5832, "training_iteration": 54, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-45", "timestamp": 1626864465, "time_this_iter_s": 0.37274837493896484, "time_total_s": 20.019225120544434, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182711e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 20.019225120544434, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 80.8, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 11.0, -13.0, 11.0, 13.0, -15.0, 7.0, 10.0, 10.0, 8.0, 8.0, -11.0, 4.0, 13.0, 6.0, -8.0, 9.0, 8.0, -5.0, 3.0, 4.0, 11.0, -7.0, 7.0, 10.0, -8.0, 7.0, 6.0, 12.0, 12.0, -4.0, -5.0, 5.0, 14.0, 7.0, -11.0, 14.0, 9.0, -15.0, 7.0, 9.0, -5.0, 7.0, 4.0, 8.0, 10.0, 8.0, -11.0, 5.0, 14.0, 8.0, -12.0, 12.0, 11.0, 6.0, -14.0, 14.0, 5.0, 9.0, -13.0, 8.0, 10.0, 6.0, -9.0, 4.0, 14.0, -8.0, 5.0, -2.0, 9.0, -3.0, 11.0, 13.0, -8.0, -3.0, 13.0, -5.0, 14.0, 7.0, -1.0, 5.0, 7.0, 10.0, -7.0, 14.0, 14.0, -7.0, -6.0, 14.0, -20.0, 11.0, 10.0, 8.0, 11.0, 4.0, -8.0, 11.0, 14.0, 4.0, -14.0, 13.0, 14.0, 5.0, -17.0, 14.0, 7.0, -16.0, 10.0, -10.0, 13.0, 5.0, 7.0, 5.0, 12.0, -4.0, 2.0, 11.0, 12.0, -3.0, -5.0, 14.0, -14.0, 12.0, 3.0, 11.0, 4.0, -7.0, 7.0, 4.0, 14.0, -7.0, 4.0, 12.0, 13.0, 6.0, -16.0, 13.0, -12.0, 2.0, 12.0, 11.0, 10.0, 3.0, -9.0, 5.0, 14.0, 10.0, -14.0, 14.0, 13.0, -9.0, -3.0, 14.0, 0.0, 12.0, -11.0, 1.0, 13.0, 8.0, -7.0, 1.0, 8.0, -3.0, 9.0, -6.0, 9.0, 4.0, 8.0, 10.0, -9.0, 3.0, 11.0, 12.0, 4.0, 9.0, -10.0, 4.0, 12.0, 5.0, -6.0, 12.0, 12.0, 2.0, -11.0, 12.0, 6.0, -11.0, 8.0, 9.0, -7.0, 7.0, 6.0, -1.0, 14.0, -4.0, 6.0, 14.0, 14.0, -7.0, -6.0, 13.0, -8.0, 0.0, 10.0, 4.0, 10.0, -7.0, 8.0, 11.0, 14.0, -9.0, -1.0, 12.0, 10.0, 9.0, -16.0, 13.0, 2.0, 12.0, -12.0, 9.0, 11.0, 6.0, -11.0, 9.0, 14.0, -16.0, 8.0, 13.0, 12.0, 6.0, -16.0, 9.0, 13.0, 5.0, -12.0, 10.0, 10.0, -12.0, 7.0, 5.0, 14.0, -6.0, 2.0, -5.0, 11.0, -3.0, 12.0, 13.0, 0.0, 10.0, -8.0, 9.0, -13.0, 9.0, 10.0, 5.0, 14.0, -7.0, 3.0, 13.0, 14.0, -5.0, -7.0, 13.0, 3.0, -13.0, 12.0, -2.0, 7.0, 7.0, 3.0, 10.0, 11.0, 5.0, -11.0, 11.0, 12.0, -11.0, 3.0, 14.0, 8.0, -7.0, 0.0, -6.0, 13.0, 10.0, -2.0, 11.0, 14.0, -17.0, 7.0, 4.0, 13.0, 10.0, -12.0, 13.0, -11.0, 10.0, 3.0, 11.0, 8.0, -7.0, 3.0, 10.0, 9.0, -5.0, 1.0, 14.0, 14.0, 0.0, -13.0, 13.0, 9.0, -16.0, 9.0, -10.0, 14.0, 4.0, 7.0, -7.0, 14.0, 5.0, 3.0, 11.0, 14.0, -8.0, -2.0, 14.0, 8.0, -15.0, 8.0, -3.0, 12.0, -5.0, 11.0, 7.0, 9.0, -5.0, 4.0, 11.0, 12.0, -6.0, -2.0, 14.0, 2.0, 10.0, -11.0, -7.0, 9.0, 5.0, 8.0, 10.0, 14.0, 6.0, -15.0, 14.0, 13.0, -6.0, -6.0, 14.0, -11.0, 10.0, 2.0, 8.0, 8.0, 4.0, -5.0, 9.0, 14.0, -14.0, 6.0, 14.0, 12.0, -2.0, -9.0, 13.0, -15.0, 6.0, 11.0, 12.0, -9.0, 11.0, 1.0, 9.0, 14.0, -9.0, 1.0, 14.0, 10.0, -7.0, -2.0, -4.0, 12.0, 3.0, 4.0, 8.0, 11.0, 3.0, -7.0, 11.0, 8.0, -3.0, -1.0, 14.0, -17.0, 8.0, 10.0, 13.0, -8.0, -3.0, 13.0, -6.0, 12.0, 9.0, 0.0, 4.0, 14.0, 9.0, -12.0, 9.0, -16.0, 12.0, 10.0, 14.0, -9.0, 3.0, 7.0, 7.0, 9.0, 11.0, -12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18430786040393599, "mean_inference_ms": 1.0661993017384486, "mean_action_processing_ms": 0.0712788040835564, "mean_env_wait_ms": 0.17464172133165737, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 302940, "agent_timesteps_total": 302940, "timers": {"sample_time_ms": 0.092, "sample_throughput": 60066871.679, "learn_time_ms": 14.953, "learn_throughput": 368352.577, "update_time_ms": 6.384}, "info": {"learner": {"learned": {"policy_loss": 228085579776.0, "vf_loss": 230.66281127929688, "total_loss": 228085579776.0, "vf_explained_var": -6.306171417236328e-05, "model": {}}}, "num_steps_sampled": 302940, "num_agent_steps_sampled": 302940, "num_steps_trained": 302940, "num_agent_steps_trained": 302940}, "done": false, "episodes_total": 5940, "training_iteration": 55, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-46", "timestamp": 1626864466, "time_this_iter_s": 0.36661863327026367, "time_total_s": 20.385843753814697, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 20.385843753814697, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 368.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.416666666666668, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 5.354166666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 368.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 12.0, -10.0, 4.0, -15.0, 9.0, 10.0, 11.0, 13.0, 8.0, -12.0, 6.0, 8.0, -19.0, 13.0, 13.0, 9.0, 14.0, -13.0, 5.0, 2.0, 11.0, 12.0, -10.0, 12.0, 9.0, -14.0, 8.0, 7.0, 11.0, 10.0, -13.0, 11.0, 12.0, 1.0, -9.0, 8.0, 14.0, -18.0, 11.0, 9.0, -7.0, 5.0, 8.0, -13.0, 6.0, 13.0, 9.0, -6.0, 12.0, 4.0, 5.0, 6.0, 9.0, 11.0, -11.0, 12.0, -8.0, 9.0, 2.0, 8.0, -13.0, 12.0, 8.0, -3.0, 10.0, 3.0, 5.0, -18.0, 13.0, 11.0, 9.0, 12.0, -2.0, 1.0, 4.0, 11.0, 13.0, -14.0, 5.0, 8.0, 12.0, 3.0, -8.0, 320.0, 12.0, 9.0, 12.0, 13.0, 13.0, -8.0, -2.0, 4.0, 14.0, -3.0, 0.0, 13.0, 13.0, 3.0, -14.0, -15.0, 9.0, 10.0, 11.0, 10.0, 14.0, -11.0, 2.0, 8.0, 2.0, 13.0, -8.0, -3.0, 6.0, 11.0, 1.0, -4.0, 12.0, 11.0, -4.0, 10.0, -5.0, 3.0, 7.0, 4.0, -1.0, 9.0, 3.0, 12.0, 12.0, 5.0, -14.0, 2.0, 9.0, -4.0, 8.0, 10.0, -8.0, 6.0, 7.0, 12.0, 4.0, 6.0, -7.0, -1.0, 11.0, -1.0, 6.0, -5.0, 13.0, -3.0, 10.0, 12.0, 10.0, -4.0, -3.0, -5.0, 7.0, 9.0, 4.0, 0.0, 2.0, 4.0, 9.0, 0.0, 10.0, -5.0, 10.0, 13.0, 12.0, -9.0, -1.0, 3.0, 2.0, -2.0, 12.0, -5.0, 9.0, 3.0, 8.0, 9.0, -12.0, 10.0, 8.0, 9.0, -7.0, 8.0, 5.0, 9.0, 8.0, 12.0, -14.0, 8.0, 6.0, 9.0, -8.0, -5.0, 6.0, 3.0, 11.0, 9.0, 9.0, -7.0, 4.0, 5.0, 13.0, 9.0, -12.0, 13.0, 7.0, -12.0, 7.0, 8.0, 7.0, 7.0, -7.0, 13.0, 14.0, 332.0, 9.0, -3.0, 10.0, 4.0, 4.0, 8.0, 13.0, -12.0, 6.0, 7.0, 3.0, 10.0, -5.0, 10.0, 12.0, 2.0, -9.0, 9.0, 8.0, 12.0, -14.0, -1.0, 5.0, 8.0, 3.0, 8.0, 13.0, -12.0, 6.0, 12.0, 10.0, -7.0, 0.0, 3.0, 12.0, 11.0, -11.0, -1.0, 2.0, 4.0, 10.0, -14.0, 13.0, 6.0, 10.0, 12.0, 13.0, -18.0, 8.0, 5.0, 12.0, -5.0, 3.0, -5.0, 11.0, 4.0, 5.0, 1.0, 9.0, 9.0, -4.0, 11.0, 13.0, -15.0, 6.0, -10.0, 12.0, 12.0, 1.0, 3.0, 11.0, 7.0, -6.0, -11.0, 8.0, 8.0, 10.0, 13.0, 13.0, -10.0, -1.0, -2.0, 6.0, 1.0, 10.0, -6.0, 12.0, 0.0, 9.0, 4.0, 9.0, -3.0, 5.0, 13.0, 13.0, 3.0, -13.0, 4.0, 6.0, -4.0, 9.0, 13.0, 8.0, -11.0, 5.0, -5.0, 13.0, -3.0, 10.0, 12.0, 13.0, -3.0, -7.0, 9.0, -6.0, 4.0, 8.0, -7.0, 14.0, 5.0, 3.0, -5.0, 0.0, 9.0, 11.0, 9.0, 14.0, -16.0, 8.0, -10.0, 7.0, 12.0, 6.0, 6.0, -1.0, 8.0, 2.0, 1.0, 7.0, -4.0, 11.0, 12.0, 13.0, 6.0, -16.0, 5.0, -8.0, 10.0, 8.0, -11.0, 11.0, 10.0, 5.0, -16.0, 14.0, 11.0, 6.0, 12.0, 0.0, 3.0, 0.0, -7.0, 3.0, 13.0, 6.0, 13.0, 14.0, -15.0, 3.0, 1.0, 12.0, 5.0, -3.0, 11.0, -11.0, 12.0, 3.0, -9.0, 11.0, 12.0, 1.0, -2.0, 4.0, 9.0, 4.0, -12.0, 9.0, 8.0, 10.0, 12.0, 0.0, 3.0, 0.0, 7.0, 13.0, 1.0, -6.0, -11.0, 10.0, 10.0, 6.0, -7.0, 7.0, 10.0, 5.0, 11.0, 13.0, -12.0, 3.0, -15.0, 11.0, 13.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18430155905499354, "mean_inference_ms": 1.0662755472307044, "mean_action_processing_ms": 0.071265770710986, "mean_env_wait_ms": 0.17465726687172178, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 308448, "agent_timesteps_total": 308448, "timers": {"sample_time_ms": 0.092, "sample_throughput": 60088561.844, "learn_time_ms": 14.766, "learn_throughput": 373018.453, "update_time_ms": 6.47}, "info": {"learner": {"learned": {"policy_loss": 1.233201503753662, "vf_loss": 17.521015167236328, "total_loss": 18.75421714782715, "vf_explained_var": -0.003522157669067383, "model": {}}}, "num_steps_sampled": 308448, "num_agent_steps_sampled": 308448, "num_steps_trained": 308448, "num_agent_steps_trained": 308448}, "done": false, "episodes_total": 6048, "training_iteration": 56, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-46", "timestamp": 1626864466, "time_this_iter_s": 0.3641173839569092, "time_total_s": 20.749961137771606, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 20.749961137771606, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 68.4, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-11.0, 10.0, 7.0, 9.0, 5.0, -7.0, 9.0, 8.0, 11.0, 4.0, 10.0, -10.0, 7.0, 7.0, -11.0, 12.0, 4.0, 12.0, 12.0, -13.0, 7.0, -7.0, 5.0, 10.0, 13.0, 12.0, -13.0, 3.0, 14.0, 8.0, -2.0, -5.0, -8.0, 11.0, 5.0, 7.0, 6.0, -8.0, 6.0, 11.0, 11.0, 5.0, 7.0, -8.0, 5.0, 11.0, 6.0, -7.0, -9.0, 9.0, 11.0, 4.0, 1.0, 13.0, 10.0, -9.0, 8.0, 4.0, -8.0, 11.0, -10.0, 10.0, 8.0, 7.0, -16.0, 6.0, 12.0, 13.0, 7.0, -12.0, 7.0, 13.0, 13.0, 7.0, 4.0, -9.0, 12.0, 9.0, 11.0, -17.0, -8.0, 6.0, 12.0, 5.0, 6.0, -7.0, 4.0, 12.0, 8.0, 2.0, 8.0, -3.0, 12.0, 12.0, -9.0, 0.0, 1.0, 12.0, 10.0, -8.0, 1.0, -4.0, 11.0, 7.0, 8.0, -7.0, 5.0, 9.0, 2.0, 8.0, 9.0, -4.0, -12.0, 8.0, 9.0, 10.0, 5.0, -6.0, 10.0, 6.0, -2.0, 11.0, 7.0, -1.0, 14.0, 10.0, -7.0, -2.0, -5.0, 8.0, 7.0, 5.0, 6.0, 14.0, 7.0, -12.0, 12.0, 12.0, -9.0, 0.0, 13.0, 12.0, 8.0, -18.0, -15.0, 7.0, 12.0, 11.0, 6.0, 12.0, -7.0, 4.0, 13.0, 9.0, -18.0, 11.0, 10.0, 13.0, -10.0, 2.0, 5.0, 10.0, 12.0, -12.0, 2.0, -12.0, 12.0, 13.0, 11.0, -3.0, 5.0, 2.0, 7.0, 9.0, 6.0, -7.0, -10.0, 10.0, 8.0, 7.0, 7.0, 11.0, -5.0, 2.0, 11.0, 7.0, 5.0, -8.0, 13.0, 12.0, -17.0, 7.0, -16.0, 12.0, 11.0, 8.0, -7.0, 8.0, 6.0, 8.0, 7.0, 10.0, -1.0, -1.0, 8.0, 12.0, -13.0, 8.0, -10.0, 1.0, 12.0, 12.0, 1.0, -3.0, 8.0, 9.0, -1.0, 5.0, 5.0, 6.0, -1.0, 11.0, -7.0, 12.0, -10.0, 5.0, 12.0, 8.0, 5.0, 11.0, -10.0, 9.0, -5.0, 5.0, 5.0, 10.0, 11.0, 12.0, -15.0, 7.0, -2.0, 10.0, 2.0, 5.0, 2.0, -7.0, 8.0, 12.0, 9.0, 10.0, -7.0, 3.0, 10.0, 12.0, 0.0, -7.0, -8.0, 9.0, 2.0, 12.0, 7.0, -5.0, 10.0, 3.0, 11.0, 13.0, 6.0, -15.0, 5.0, 12.0, -7.0, 5.0, -6.0, 11.0, 6.0, 4.0, 8.0, 10.0, -5.0, 2.0, 12.0, 12.0, 5.0, -14.0, 8.0, 10.0, 9.0, -12.0, 1.0, 0.0, 12.0, 2.0, 1.0, 9.0, -8.0, 13.0, 8.0, 13.0, 5.0, -11.0, 13.0, 9.0, -8.0, 1.0, -13.0, 4.0, 12.0, 12.0, 6.0, -5.0, 10.0, 4.0, 8.0, 7.0, -11.0, 11.0, 8.0, 7.0, -12.0, 12.0, -9.0, 0.0, 11.0, 13.0, 12.0, 8.0, -7.0, 2.0, 7.0, 6.0, 9.0, -7.0, 14.0, 13.0, -2.0, -10.0, 9.0, 12.0, -18.0, 12.0, 3.0, 14.0, -15.0, 13.0, 10.0, 11.0, 0.0, -6.0, 4.0, -4.0, 9.0, 6.0, -14.0, 10.0, 12.0, 7.0, -10.0, 8.0, 5.0, 12.0, 11.0, 6.0, -8.0, 6.0, 14.0, 11.0, -6.0, -4.0, -14.0, 12.0, 4.0, 13.0, -11.0, 6.0, 11.0, 9.0, 12.0, 12.0, -11.0, 2.0, 8.0, 14.0, -15.0, 8.0, -6.0, 9.0, 0.0, 12.0, 5.0, 11.0, -8.0, 7.0, 4.0, 12.0, -9.0, 8.0, 6.0, -8.0, 11.0, 6.0, -12.0, 6.0, 11.0, 10.0, 4.0, 4.0, 11.0, -4.0, 13.0, 13.0, -2.0, -9.0, 8.0, 8.0, -6.0, 5.0, -16.0, 8.0, 11.0, 12.0, 4.0, -7.0, 12.0, 6.0, 11.0, 6.0, -12.0, 10.0, 14.0, 12.0, -8.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18438256854560056, "mean_inference_ms": 1.0664300006191398, "mean_action_processing_ms": 0.07129148260693739, "mean_env_wait_ms": 0.1746952019841321, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 313956, "agent_timesteps_total": 313956, "timers": {"sample_time_ms": 0.091, "sample_throughput": 60471254.203, "learn_time_ms": 14.559, "learn_throughput": 378333.046, "update_time_ms": 6.736}, "info": {"learner": {"learned": {"policy_loss": 1.42665696144104, "vf_loss": 15.64663314819336, "total_loss": 17.07328987121582, "vf_explained_var": -0.0036154985427856445, "model": {}}}, "num_steps_sampled": 313956, "num_agent_steps_sampled": 313956, "num_steps_trained": 313956, "num_agent_steps_trained": 313956}, "done": false, "episodes_total": 6156, "training_iteration": 57, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-46", "timestamp": 1626864466, "time_this_iter_s": 0.3640635013580322, "time_total_s": 21.11402463912964, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 21.11402463912964, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 369.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.27777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 335.0}, "policy_reward_mean": {"learned": 4.569444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 369.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-14.0, 9.0, 7.0, 13.0, 9.0, 6.0, -9.0, 9.0, 11.0, 12.0, -15.0, 7.0, 2.0, 11.0, -2.0, 4.0, -3.0, 5.0, 7.0, 6.0, 11.0, -13.0, 12.0, 5.0, 13.0, 11.0, -9.0, 0.0, 3.0, 7.0, -1.0, 6.0, 6.0, 9.0, 6.0, -6.0, 3.0, 13.0, 9.0, -10.0, -5.0, 9.0, 4.0, 7.0, 4.0, 7.0, 6.0, -2.0, -3.0, -1.0, 8.0, 11.0, 13.0, 9.0, 8.0, -15.0, 10.0, 7.0, 0.0, -2.0, 3.0, 12.0, -11.0, 11.0, 13.0, -14.0, 9.0, 7.0, 9.0, 12.0, 2.0, -8.0, -3.0, 8.0, 3.0, 7.0, -7.0, 8.0, 2.0, 12.0, 10.0, 7.0, 10.0, -12.0, 13.0, 14.0, -5.0, -7.0, -13.0, 12.0, 5.0, 11.0, 2.0, 13.0, 7.0, -7.0, -1.0, 9.0, 1.0, 6.0, 13.0, 5.0, 11.0, -14.0, -1.0, 5.0, 0.0, 11.0, 2.0, 12.0, 2.0, -1.0, 12.0, 8.0, -4.0, -1.0, 7.0, 0.0, -1.0, 9.0, -6.0, 0.0, 9.0, 12.0, 7.0, 6.0, -4.0, 6.0, -2.0, 12.0, -3.0, 8.0, 2.0, 9.0, 6.0, -2.0, 11.0, 11.0, 6.0, -13.0, 2.0, 9.0, 10.0, -6.0, 9.0, 4.0, -7.0, 9.0, 9.0, 6.0, 4.0, -4.0, -14.0, 7.0, 12.0, 10.0, 8.0, 12.0, 3.0, -8.0, 14.0, 7.0, 1.0, -7.0, 7.0, 14.0, 3.0, -9.0, 0.0, 10.0, 8.0, -3.0, -11.0, 13.0, 6.0, 7.0, 11.0, 14.0, -11.0, 1.0, 9.0, 7.0, 3.0, -4.0, -10.0, 12.0, 1.0, 12.0, -2.0, 8.0, 5.0, 4.0, 7.0, 6.0, -3.0, 5.0, 11.0, 7.0, -11.0, 8.0, -13.0, 6.0, 10.0, 12.0, 9.0, 8.0, 5.0, -7.0, 7.0, -12.0, 11.0, 9.0, 11.0, 14.0, -11.0, 1.0, -1.0, 7.0, 1.0, 8.0, 3.0, 9.0, -4.0, 7.0, -8.0, 8.0, 4.0, 11.0, -4.0, 14.0, 3.0, 2.0, -8.0, 11.0, 5.0, 7.0, 8.0, 10.0, -1.0, -2.0, 12.0, 11.0, 1.0, -9.0, 7.0, 12.0, -9.0, 5.0, -14.0, 12.0, 6.0, 11.0, 5.0, 7.0, 5.0, -2.0, 10.0, 5.0, 10.0, -10.0, -5.0, 13.0, 3.0, 4.0, -5.0, 11.0, 5.0, 4.0, 2.0, 13.0, -6.0, 6.0, -1.0, 7.0, 6.0, 3.0, -7.0, 11.0, 7.0, 4.0, 3.0, -13.0, 13.0, 12.0, -13.0, 9.0, 8.0, 11.0, 14.0, -7.0, 5.0, 3.0, -12.0, 14.0, 10.0, 3.0, 0.0, 7.0, 1.0, 7.0, -2.0, 12.0, -2.0, 7.0, 12.0, 9.0, -13.0, 7.0, 13.0, 11.0, -3.0, -6.0, -11.0, 3.0, 12.0, 11.0, -3.0, 13.0, -6.0, 11.0, 7.0, -3.0, 9.0, 2.0, 13.0, 9.0, -8.0, 1.0, 12.0, 13.0, -8.0, -2.0, -3.0, 7.0, 3.0, 8.0, 335.0, 13.0, 9.0, 12.0, 13.0, 13.0, 2.0, -13.0, -14.0, 6.0, 11.0, 12.0, 0.0, 11.0, 6.0, -2.0, 11.0, 13.0, -2.0, -7.0, 10.0, 13.0, 1.0, -9.0, -5.0, -1.0, 10.0, 11.0, 6.0, 12.0, 4.0, -7.0, -5.0, 12.0, 12.0, -4.0, 12.0, 7.0, 5.0, -9.0, -14.0, 6.0, 12.0, 11.0, -18.0, 11.0, 11.0, 11.0, 10.0, 6.0, 9.0, -10.0, 13.0, 14.0, -2.0, -10.0, -14.0, 11.0, 11.0, 7.0, 2.0, 13.0, 3.0, -3.0, -7.0, 13.0, -4.0, 13.0, 5.0, 14.0, 7.0, -11.0, -14.0, 6.0, 11.0, 12.0, -3.0, 2.0, 10.0, 6.0, 13.0, 8.0, 4.0, -10.0, 8.0, 9.0, -11.0, 9.0, -6.0, -1.0, 12.0, 10.0, 2.0, 3.0, -2.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18435318376698198, "mean_inference_ms": 1.06648434789423, "mean_action_processing_ms": 0.07126676251272913, "mean_env_wait_ms": 0.17469170201062825, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 319464, "agent_timesteps_total": 319464, "timers": {"sample_time_ms": 0.094, "sample_throughput": 58708414.937, "learn_time_ms": 14.821, "learn_throughput": 371623.96, "update_time_ms": 7.194}, "info": {"learner": {"learned": {"policy_loss": 1.2717300653457642, "vf_loss": 21.950258255004883, "total_loss": 23.221988677978516, "vf_explained_var": -0.0031555891036987305, "model": {}}}, "num_steps_sampled": 319464, "num_agent_steps_sampled": 319464, "num_steps_trained": 319464, "num_agent_steps_trained": 319464}, "done": false, "episodes_total": 6264, "training_iteration": 58, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-47", "timestamp": 1626864467, "time_this_iter_s": 0.3689568042755127, "time_total_s": 21.48298144340515, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 21.48298144340515, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 72.3, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.574074074074073, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.893518518518518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 1.0, 8.0, -7.0, -4.0, 13.0, -6.0, 12.0, 10.0, -8.0, 5.0, 8.0, 12.0, 10.0, -5.0, -2.0, 8.0, 12.0, 3.0, -8.0, 7.0, 13.0, -13.0, 8.0, 12.0, -12.0, 12.0, 3.0, 11.0, 12.0, -20.0, 12.0, 7.0, 8.0, 2.0, -2.0, 8.0, 13.0, 2.0, -8.0, 9.0, -9.0, 8.0, 7.0, 13.0, 9.0, -19.0, 12.0, 8.0, 3.0, 12.0, -8.0, 6.0, 14.0, -10.0, 5.0, 13.0, -11.0, 3.0, 10.0, 12.0, 10.0, -20.0, 13.0, 10.0, 12.0, -8.0, 1.0, -8.0, 11.0, 6.0, 6.0, -9.0, 8.0, 8.0, 8.0, 11.0, 12.0, -20.0, 12.0, 4.0, 9.0, 13.0, -11.0, 9.0, 13.0, -4.0, -3.0, 13.0, -13.0, 9.0, 6.0, 13.0, 10.0, 320.0, 11.0, 11.0, 5.0, 7.0, -8.0, 9.0, 13.0, 3.0, -10.0, -5.0, 3.0, 10.0, 7.0, 11.0, -6.0, -1.0, 11.0, 8.0, 4.0, 6.0, -3.0, -16.0, 13.0, 7.0, 11.0, -7.0, 3.0, 6.0, 13.0, 12.0, 10.0, -3.0, -4.0, 9.0, 4.0, -3.0, 5.0, 6.0, 10.0, 2.0, -3.0, 10.0, -10.0, 9.0, 6.0, 10.0, 12.0, -20.0, 13.0, 11.0, 0.0, 10.0, -6.0, 6.0, 11.0, 1.0, -3.0, -3.0, 0.0, 6.0, 12.0, 14.0, -4.0, -6.0, 11.0, 11.0, 2.0, 8.0, -6.0, 9.0, 13.0, 4.0, -11.0, 11.0, -12.0, 10.0, 6.0, 12.0, 9.0, -17.0, 11.0, 6.0, 2.0, -5.0, 12.0, 12.0, 7.0, 8.0, -12.0, 13.0, -14.0, 12.0, 4.0, 12.0, 12.0, 318.0, 13.0, 6.0, 10.0, 10.0, -11.0, 5.0, 13.0, -7.0, 4.0, 4.0, -3.0, 7.0, 7.0, 13.0, 12.0, 321.0, 10.0, 3.0, 7.0, 11.0, -6.0, -1.0, -2.0, 6.0, 12.0, 6.0, -2.0, 1.0, 10.0, 11.0, 12.0, 317.0, 13.0, 12.0, 6.0, 5.0, -8.0, 3.0, 13.0, 8.0, -9.0, -7.0, 11.0, 6.0, 5.0, 12.0, -1.0, -8.0, 12.0, 6.0, 10.0, 7.0, -8.0, 13.0, 13.0, 6.0, -17.0, 10.0, -11.0, 5.0, 11.0, 12.0, 11.0, -19.0, 11.0, 10.0, 11.0, -4.0, -2.0, -8.0, 9.0, 5.0, 9.0, -3.0, 0.0, 12.0, 6.0, 11.0, 13.0, -20.0, 11.0, 9.0, 8.0, 5.0, -7.0, -4.0, 4.0, 6.0, 9.0, -5.0, 6.0, 3.0, 11.0, 9.0, 13.0, -17.0, 10.0, 13.0, 0.0, 8.0, -6.0, 12.0, 4.0, 4.0, -5.0, 13.0, -10.0, 5.0, 7.0, 13.0, -5.0, -4.0, 11.0, 7.0, 12.0, -8.0, 4.0, 5.0, 9.0, -5.0, 6.0, 13.0, -6.0, 9.0, -1.0, 13.0, -3.0, -6.0, 11.0, 6.0, 3.0, -6.0, 12.0, -11.0, 9.0, 9.0, 8.0, 11.0, -12.0, 8.0, 8.0, 12.0, 11.0, -20.0, 12.0, 12.0, 13.0, -5.0, -5.0, 2.0, 12.0, 6.0, -5.0, 5.0, -2.0, 5.0, 7.0, 9.0, 11.0, -17.0, 12.0, 8.0, 7.0, 2.0, -2.0, 10.0, -9.0, 7.0, 7.0, 10.0, -10.0, 4.0, 11.0, 13.0, 12.0, -9.0, -1.0, 8.0, 7.0, 8.0, -8.0, -4.0, 14.0, 4.0, 1.0, -3.0, 5.0, 0.0, 13.0, 11.0, 12.0, -1.0, -7.0, 7.0, 7.0, 3.0, -2.0, 10.0, 6.0, 3.0, -4.0, -7.0, 6.0, 3.0, 13.0, 12.0, -2.0, -4.0, 9.0, 12.0, 5.0, -8.0, 6.0, 7.0, 6.0, 7.0, -5.0, -4.0, 12.0, 3.0, 4.0, 12.0, 12.0, -19.0, 10.0, 11.0, -1.0, -3.0, 8.0, 11.0, 11.0, 6.0, -13.0, -4.0, 1.0, 11.0, 7.0, 11.0, 10.0, -3.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18435248685277283, "mean_inference_ms": 1.0664776751676552, "mean_action_processing_ms": 0.07126439454338007, "mean_env_wait_ms": 0.174661465852653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 324972, "agent_timesteps_total": 324972, "timers": {"sample_time_ms": 0.093, "sample_throughput": 59136846.979, "learn_time_ms": 14.105, "learn_throughput": 390499.545, "update_time_ms": 7.289}, "info": {"learner": {"learned": {"policy_loss": 296909963264.0, "vf_loss": 429.0167541503906, "total_loss": 296909963264.0, "vf_explained_var": 0.00011599063873291016, "model": {}}}, "num_steps_sampled": 324972, "num_agent_steps_sampled": 324972, "num_steps_trained": 324972, "num_agent_steps_trained": 324972}, "done": false, "episodes_total": 6372, "training_iteration": 59, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-47", "timestamp": 1626864467, "time_this_iter_s": 0.3579702377319336, "time_total_s": 21.840951681137085, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1a45e2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 21.840951681137085, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 81.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 11.0, 0.0, -6.0, -8.0, 12.0, -1.0, 12.0, -8.0, 10.0, 6.0, 7.0, 10.0, -9.0, 12.0, 2.0, 11.0, 12.0, 10.0, -18.0, 7.0, 5.0, 11.0, -8.0, 13.0, 11.0, -15.0, 6.0, 12.0, -7.0, 8.0, 2.0, 0.0, 11.0, 12.0, -8.0, 318.0, 13.0, 12.0, 12.0, 11.0, -13.0, 11.0, 6.0, 13.0, 9.0, -18.0, 11.0, -2.0, 13.0, 12.0, -8.0, -8.0, 6.0, 6.0, 11.0, 10.0, 7.0, 6.0, -8.0, 12.0, 8.0, 7.0, -12.0, -1.0, 11.0, 13.0, -8.0, 12.0, 8.0, 12.0, -17.0, -2.0, 11.0, 4.0, 2.0, 11.0, -5.0, 10.0, -1.0, 10.0, 12.0, 13.0, -20.0, -6.0, 14.0, -5.0, 12.0, 12.0, 2.0, 12.0, -11.0, 12.0, -3.0, 9.0, -3.0, 8.0, -2.0, 12.0, -3.0, -7.0, 13.0, 10.0, -1.0, 12.0, 14.0, 4.0, -15.0, 11.0, 11.0, 8.0, -15.0, 11.0, 10.0, 13.0, -19.0, 1.0, 13.0, 10.0, -9.0, 11.0, 11.0, 4.0, -11.0, 11.0, -16.0, 9.0, 11.0, 3.0, -3.0, 9.0, 6.0, -7.0, 14.0, -1.0, 9.0, 12.0, 12.0, -15.0, 6.0, 6.0, 6.0, -9.0, 12.0, 10.0, 13.0, 10.0, -18.0, -2.0, 8.0, 11.0, -2.0, 13.0, 7.0, -9.0, 4.0, 13.0, 10.0, -16.0, 8.0, 12.0, 10.0, 11.0, -18.0, -3.0, 8.0, -1.0, 11.0, 11.0, 13.0, 7.0, -16.0, 13.0, 7.0, -14.0, 9.0, 4.0, 12.0, 12.0, -13.0, 11.0, 4.0, -2.0, 2.0, 12.0, 7.0, -11.0, 7.0, 9.0, 10.0, 8.0, -12.0, 11.0, -11.0, 10.0, 5.0, -12.0, 7.0, 13.0, 7.0, 8.0, 1.0, 10.0, -4.0, 12.0, 5.0, 7.0, -9.0, 4.0, 12.0, 10.0, -11.0, -3.0, 8.0, -1.0, 11.0, 11.0, 14.0, 1.0, -11.0, 12.0, -7.0, 6.0, 4.0, 5.0, 9.0, 8.0, -7.0, -4.0, 10.0, 10.0, -1.0, -4.0, 2.0, 5.0, 12.0, 2.0, 13.0, 12.0, -12.0, 319.0, 12.0, 11.0, 12.0, -9.0, 14.0, -2.0, 12.0, 14.0, 7.0, -1.0, -5.0, 12.0, 7.0, -13.0, 9.0, 0.0, 10.0, -7.0, 12.0, -3.0, 10.0, 10.0, -2.0, 14.0, 12.0, -15.0, 4.0, 12.0, -6.0, 11.0, -2.0, 9.0, 14.0, -1.0, -7.0, 8.0, 5.0, -5.0, 7.0, 12.0, 9.0, -9.0, 3.0, 13.0, -7.0, -4.0, 13.0, -10.0, 4.0, 13.0, 8.0, -1.0, 8.0, -4.0, 12.0, 9.0, 7.0, 5.0, -6.0, 13.0, 0.0, -11.0, 13.0, 6.0, 10.0, 9.0, -10.0, -1.0, 14.0, 12.0, -10.0, 11.0, 5.0, -9.0, 8.0, 11.0, -8.0, 4.0, 8.0, -5.0, 13.0, 11.0, -4.0, -9.0, 14.0, -1.0, 11.0, 13.0, -7.0, 0.0, 9.0, 4.0, -5.0, 11.0, 5.0, -2.0, 13.0, 13.0, -9.0, -6.0, 13.0, 12.0, -4.0, 11.0, 8.0, -11.0, 7.0, 9.0, -2.0, 2.0, 6.0, -11.0, 13.0, 13.0, 0.0, -4.0, 13.0, -3.0, 9.0, 2.0, 7.0, -4.0, 10.0, 9.0, 13.0, 13.0, -20.0, 5.0, 10.0, 11.0, -11.0, -1.0, 10.0, 11.0, -5.0, 14.0, 12.0, -15.0, 4.0, 12.0, -8.0, 13.0, -2.0, 7.0, 12.0, -10.0, 6.0, -22.0, 14.0, 11.0, 12.0, 9.0, 4.0, 3.0, -1.0, -5.0, 11.0, 6.0, 3.0, 0.0, 13.0, 11.0, -9.0, 1.0, 6.0, -4.0, 12.0, 11.0, -7.0, 5.0, 6.0, 13.0, 10.0, 8.0, -16.0, 8.0, 11.0, 9.0, -13.0, 4.0, 6.0, 6.0, -1.0, 11.0, 9.0, -12.0, 7.0, 8.0, -1.0, 13.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18436531220610294, "mean_inference_ms": 1.066768501631067, "mean_action_processing_ms": 0.07125859674525763, "mean_env_wait_ms": 0.17471815652642453, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 330480, "agent_timesteps_total": 330480, "timers": {"sample_time_ms": 0.092, "sample_throughput": 60086988.76, "learn_time_ms": 14.349, "learn_throughput": 383870.78, "update_time_ms": 7.333}, "info": {"learner": {"learned": {"policy_loss": 187515453440.0, "vf_loss": 227.72796630859375, "total_loss": 187515453440.0, "vf_explained_var": -0.00015974044799804688, "model": {}}}, "num_steps_sampled": 330480, "num_agent_steps_sampled": 330480, "num_steps_trained": 330480, "num_agent_steps_trained": 330480}, "done": false, "episodes_total": 6480, "training_iteration": 60, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-48", "timestamp": 1626864468, "time_this_iter_s": 0.3561713695526123, "time_total_s": 22.197123050689697, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18286598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 22.197123050689697, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.39814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 6.099537037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 13.0, 10.0, -9.0, 14.0, 11.0, 11.0, -21.0, -3.0, 1.0, 10.0, 7.0, 14.0, -10.0, 4.0, 7.0, 4.0, 9.0, -6.0, 8.0, 1.0, 8.0, -6.0, 12.0, 11.0, 6.0, 8.0, -10.0, 6.0, -8.0, 8.0, 9.0, -13.0, 11.0, 12.0, 5.0, -1.0, 12.0, -7.0, 11.0, 10.0, 5.0, 11.0, -11.0, 14.0, 9.0, -5.0, -3.0, 3.0, 14.0, -10.0, 8.0, 13.0, 13.0, 12.0, 315.0, 13.0, 9.0, 4.0, -11.0, 13.0, -17.0, 12.0, 7.0, 10.0, 4.0, 11.0, -10.0, -5.0, 10.0, 1.0, 9.0, 5.0, 9.0, 8.0, -7.0, 11.0, -11.0, 12.0, 3.0, 4.0, 13.0, 13.0, -15.0, 14.0, 13.0, 315.0, 11.0, 8.0, 12.0, 4.0, -9.0, 13.0, -15.0, 9.0, 8.0, -12.0, 11.0, 12.0, 4.0, -7.0, 8.0, 10.0, 4.0, 9.0, -16.0, 13.0, 9.0, 9.0, -4.0, 8.0, 2.0, 3.0, 10.0, 11.0, -9.0, 0.0, 11.0, 10.0, -6.0, 4.0, 14.0, 11.0, -14.0, 10.0, 4.0, -4.0, 5.0, 5.0, 12.0, -5.0, 3.0, -13.0, 12.0, 5.0, 11.0, 9.0, 6.0, -7.0, 7.0, 6.0, -4.0, 8.0, 5.0, 4.0, 12.0, -7.0, 6.0, -2.0, 6.0, -1.0, 12.0, 9.0, 2.0, -7.0, 11.0, 8.0, -1.0, 11.0, -3.0, 8.0, 13.0, 12.0, -18.0, -2.0, 11.0, -6.0, 12.0, 8.0, 10.0, 8.0, -11.0, 14.0, -7.0, 10.0, -2.0, 8.0, 12.0, 6.0, -11.0, 11.0, -5.0, 0.0, 9.0, 11.0, 14.0, -13.0, 3.0, 13.0, -19.0, 12.0, 9.0, 5.0, 13.0, -13.0, 10.0, -1.0, 7.0, 11.0, -2.0, 14.0, 4.0, -11.0, 8.0, 13.0, -18.0, 10.0, 10.0, 7.0, 9.0, 11.0, -12.0, 14.0, -9.0, 11.0, -1.0, 13.0, 4.0, 7.0, -9.0, 8.0, 7.0, 7.0, -7.0, 14.0, 8.0, -10.0, 3.0, 13.0, 10.0, -19.0, 11.0, 8.0, 9.0, 1.0, -3.0, 13.0, -15.0, 9.0, 8.0, -17.0, 14.0, 11.0, 7.0, 12.0, 9.0, -18.0, 12.0, 7.0, 9.0, 11.0, -12.0, 13.0, 0.0, -8.0, 10.0, 11.0, 9.0, 11.0, -16.0, -1.0, 10.0, 11.0, -5.0, 12.0, 13.0, -1.0, -9.0, 8.0, -9.0, 9.0, 7.0, -15.0, 14.0, 12.0, 4.0, 13.0, 8.0, 10.0, -16.0, 7.0, 9.0, -5.0, 4.0, 10.0, 5.0, -3.0, 3.0, 8.0, -3.0, 9.0, 1.0, 2.0, 9.0, -7.0, 11.0, -2.0, 14.0, -7.0, 10.0, 13.0, -16.0, 9.0, 9.0, 4.0, 14.0, -13.0, 10.0, 14.0, 13.0, 7.0, -19.0, 13.0, 13.0, 8.0, -19.0, 14.0, -20.0, 9.0, 12.0, 4.0, 11.0, -10.0, 10.0, 13.0, 10.0, 11.0, -19.0, 6.0, 14.0, -1.0, -4.0, 10.0, 2.0, 10.0, -7.0, -15.0, 14.0, 5.0, 11.0, 11.0, -5.0, 11.0, -2.0, 7.0, 7.0, 10.0, -9.0, 13.0, 5.0, -9.0, 6.0, -11.0, 12.0, 6.0, 8.0, 0.0, 14.0, 4.0, -3.0, -5.0, 3.0, 12.0, 5.0, 14.0, -20.0, 10.0, 11.0, 2.0, 7.0, 10.0, -4.0, 14.0, -2.0, -8.0, 11.0, 14.0, 6.0, 4.0, -9.0, 13.0, -12.0, 6.0, 8.0, -4.0, 13.0, 11.0, -5.0, 13.0, 13.0, 316.0, 12.0, 4.0, 6.0, 12.0, -7.0, 11.0, -16.0, 11.0, 9.0, 4.0, 9.0, 5.0, -3.0, 12.0, 14.0, 10.0, -21.0, 10.0, 7.0, -11.0, 9.0, 8.0, -8.0, 3.0, 12.0, 13.0, 8.0, -10.0, 4.0, 14.0, 4.0, 11.0, -14.0, 5.0, -10.0, 12.0, 8.0, 9.0, 13.0, 10.0, -17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18436828720451295, "mean_inference_ms": 1.06666710696639, "mean_action_processing_ms": 0.07123635510324204, "mean_env_wait_ms": 0.17469015961989848, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 335988, "agent_timesteps_total": 335988, "timers": {"sample_time_ms": 0.091, "sample_throughput": 60701840.346, "learn_time_ms": 14.707, "learn_throughput": 374510.855, "update_time_ms": 7.867}, "info": {"learner": {"learned": {"policy_loss": 1.3785353899002075, "vf_loss": 18.226484298706055, "total_loss": 19.60502052307129, "vf_explained_var": -0.004216313362121582, "model": {}}}, "num_steps_sampled": 335988, "num_agent_steps_sampled": 335988, "num_steps_trained": 335988, "num_agent_steps_trained": 335988}, "done": false, "episodes_total": 6588, "training_iteration": 61, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-48", "timestamp": 1626864468, "time_this_iter_s": 0.37009191513061523, "time_total_s": 22.567214965820312, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 22.567214965820312, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 73.6, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.305555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 5.326388888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-20.0, 11.0, 13.0, 11.0, 12.0, -15.0, 6.0, 12.0, 7.0, 11.0, -14.0, 11.0, -1.0, -2.0, 11.0, 7.0, 4.0, 12.0, -6.0, 5.0, 6.0, -5.0, 11.0, 3.0, 9.0, 10.0, 1.0, -5.0, -7.0, 3.0, 11.0, 8.0, -17.0, 13.0, 9.0, 10.0, -1.0, -2.0, 11.0, 7.0, 9.0, -5.0, 0.0, 11.0, -9.0, 12.0, 10.0, 2.0, 2.0, 10.0, 6.0, -3.0, -2.0, 2.0, 11.0, 4.0, 4.0, 8.0, -3.0, 6.0, 8.0, -10.0, 6.0, 11.0, -5.0, 9.0, 5.0, 6.0, 4.0, -9.0, 11.0, 9.0, 14.0, 3.0, 7.0, -9.0, 12.0, -8.0, 7.0, 4.0, 2.0, 7.0, 11.0, -5.0, -10.0, 5.0, 12.0, 8.0, 14.0, 4.0, 3.0, -6.0, -9.0, 8.0, 12.0, 4.0, -9.0, 12.0, 8.0, 4.0, 0.0, -5.0, 11.0, 9.0, 10.0, 6.0, -12.0, 11.0, 12.0, -18.0, 10.0, 11.0, -2.0, -4.0, 9.0, 12.0, 13.0, -3.0, 11.0, -6.0, -7.0, 9.0, 8.0, 5.0, -4.0, 5.0, 10.0, 4.0, -17.0, 11.0, 13.0, 8.0, -3.0, 4.0, 11.0, 3.0, 8.0, 9.0, 0.0, -2.0, 3.0, -11.0, 12.0, 11.0, -14.0, 12.0, 11.0, 6.0, 11.0, -14.0, 11.0, 7.0, 9.0, 10.0, -3.0, -1.0, 8.0, -11.0, 11.0, 7.0, 2.0, 10.0, 11.0, -8.0, 5.0, -7.0, 5.0, 12.0, 12.0, 7.0, -3.0, -1.0, 7.0, 10.0, 0.0, -2.0, -19.0, 11.0, 13.0, 10.0, -5.0, 7.0, 12.0, 1.0, 13.0, 4.0, 2.0, -4.0, 4.0, 1.0, 13.0, -3.0, -11.0, 11.0, 9.0, 6.0, -8.0, 10.0, 6.0, 7.0, -5.0, 9.0, 1.0, 10.0, 7.0, 4.0, 7.0, -3.0, -2.0, -1.0, 11.0, 7.0, -6.0, 2.0, 11.0, 8.0, 8.0, 12.0, 2.0, -7.0, -5.0, 4.0, 8.0, 8.0, -7.0, -1.0, 13.0, 10.0, 9.0, -10.0, 11.0, 5.0, 6.0, 10.0, -7.0, 6.0, 13.0, 320.0, 12.0, 11.0, 1.0, 12.0, 10.0, -8.0, 5.0, -11.0, 11.0, 10.0, 12.0, -1.0, 8.0, -4.0, 14.0, 6.0, 11.0, -16.0, -1.0, 8.0, 11.0, -3.0, -8.0, 7.0, 11.0, 5.0, -5.0, 9.0, 3.0, 8.0, 5.0, 11.0, 10.0, -11.0, -12.0, 12.0, 6.0, 9.0, -9.0, 9.0, 6.0, 9.0, 13.0, 10.0, -14.0, 6.0, 13.0, -13.0, 5.0, 10.0, -17.0, 11.0, 10.0, 11.0, -1.0, -6.0, 11.0, 11.0, 13.0, 5.0, -12.0, 9.0, 6.0, -8.0, 9.0, 8.0, -18.0, 11.0, 13.0, 9.0, -1.0, 4.0, 11.0, 1.0, 8.0, 10.0, 12.0, -15.0, 12.0, -17.0, 9.0, 11.0, 0.0, 12.0, 9.0, -6.0, -9.0, 5.0, 11.0, 8.0, 8.0, -8.0, 2.0, 13.0, -3.0, 2.0, 6.0, 10.0, -10.0, 7.0, 9.0, 9.0, -7.0, 2.0, 11.0, 9.0, 10.0, -9.0, 1.0, 13.0, 13.0, 320.0, 12.0, 10.0, -11.0, 6.0, 9.0, 11.0, 8.0, -11.0, 6.0, 12.0, 12.0, -13.0, 3.0, 13.0, 13.0, -17.0, 8.0, 11.0, 10.0, 10.0, 5.0, -10.0, 11.0, 0.0, 6.0, -2.0, 12.0, 8.0, -12.0, 7.0, 0.0, 11.0, 10.0, -6.0, 4.0, 11.0, 12.0, -12.0, -4.0, -4.0, 10.0, 13.0, 7.0, 9.0, -6.0, 5.0, 12.0, -19.0, 13.0, 9.0, -5.0, 12.0, 11.0, -3.0, -5.0, 13.0, 6.0, 1.0, 13.0, 7.0, 12.0, -17.0, 11.0, -18.0, 12.0, 10.0, 1.0, 4.0, 13.0, -3.0, 6.0, -14.0, 11.0, 12.0, 10.0, 9.0, -17.0, 13.0, 8.0, 7.0, 13.0, -13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18439990788341198, "mean_inference_ms": 1.066865241430207, "mean_action_processing_ms": 0.07124689270013813, "mean_env_wait_ms": 0.17470658976119915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 341496, "agent_timesteps_total": 341496, "timers": {"sample_time_ms": 0.091, "sample_throughput": 60524080.662, "learn_time_ms": 14.861, "learn_throughput": 370634.854, "update_time_ms": 8.236}, "info": {"learner": {"learned": {"policy_loss": 122157580288.0, "vf_loss": 134.45872497558594, "total_loss": 122157580288.0, "vf_explained_var": -0.0007358789443969727, "model": {}}}, "num_steps_sampled": 341496, "num_agent_steps_sampled": 341496, "num_steps_trained": 341496, "num_agent_steps_trained": 341496}, "done": false, "episodes_total": 6696, "training_iteration": 62, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-48", "timestamp": 1626864468, "time_this_iter_s": 0.36558961868286133, "time_total_s": 22.932804584503174, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 22.932804584503174, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 5.0, 8.0, -6.0, 12.0, 8.0, 2.0, -7.0, 0.0, 11.0, -9.0, 13.0, 11.0, 7.0, -15.0, 12.0, 8.0, 9.0, -7.0, 5.0, 12.0, -1.0, -1.0, 5.0, 7.0, 11.0, -15.0, 12.0, 12.0, 4.0, -7.0, 6.0, 5.0, -9.0, 8.0, 11.0, 8.0, 13.0, -16.0, 10.0, 1.0, 11.0, -9.0, 12.0, 6.0, 5.0, -8.0, 12.0, 14.0, -9.0, 2.0, 8.0, 12.0, 3.0, 2.0, -2.0, 7.0, 10.0, -14.0, 12.0, 9.0, 4.0, 12.0, -10.0, 2.0, 12.0, 10.0, -9.0, 12.0, 2.0, 11.0, -10.0, -5.0, 12.0, -4.0, 12.0, -6.0, 4.0, 6.0, 11.0, -1.0, -2.0, 6.0, 12.0, -2.0, 7.0, -1.0, 11.0, 2.0, -2.0, 2.0, 13.0, 13.0, 5.0, -8.0, 5.0, 12.0, -12.0, 7.0, 8.0, 12.0, 8.0, 2.0, -7.0, -7.0, 13.0, -4.0, 13.0, -1.0, 14.0, 11.0, -9.0, 14.0, -9.0, 8.0, 2.0, 13.0, 4.0, 9.0, -11.0, -10.0, 12.0, 4.0, 9.0, 13.0, 0.0, -10.0, 12.0, -11.0, 12.0, 7.0, 7.0, 8.0, 11.0, 12.0, -16.0, 4.0, -1.0, 7.0, 5.0, 8.0, 2.0, -7.0, 12.0, 14.0, -9.0, 6.0, 4.0, 13.0, 5.0, 7.0, -10.0, 3.0, 10.0, -11.0, 13.0, 10.0, 4.0, -12.0, 13.0, 4.0, 12.0, -4.0, 3.0, 13.0, 12.0, -3.0, -7.0, 9.0, -2.0, 0.0, 8.0, -5.0, 7.0, 10.0, 3.0, 1.0, -7.0, 8.0, 13.0, 13.0, 8.0, -5.0, -1.0, 4.0, 11.0, -12.0, 12.0, 12.0, 2.0, 3.0, -2.0, 9.0, -3.0, 7.0, 2.0, 12.0, 4.0, -9.0, 8.0, -13.0, 12.0, 3.0, 13.0, 13.0, 8.0, -18.0, 12.0, 7.0, 8.0, -12.0, 12.0, 11.0, 1.0, -3.0, 6.0, -6.0, 12.0, 11.0, -2.0, 7.0, 3.0, 7.0, -2.0, 1.0, -5.0, 7.0, 12.0, 12.0, -3.0, 12.0, -6.0, 5.0, 10.0, -13.0, 13.0, 2.0, 8.0, -3.0, 8.0, 6.0, 6.0, -5.0, 8.0, 2.0, 10.0, -9.0, 12.0, 4.0, 10.0, -12.0, 13.0, 8.0, 12.0, -3.0, -2.0, 5.0, 7.0, -5.0, 8.0, 12.0, 13.0, 318.0, 12.0, 3.0, 12.0, 10.0, -10.0, 8.0, 6.0, -12.0, 13.0, 13.0, -5.0, 5.0, 2.0, 7.0, 13.0, -16.0, 11.0, -11.0, 13.0, 1.0, 12.0, 10.0, 0.0, -7.0, 12.0, -6.0, 11.0, 8.0, 2.0, 11.0, 5.0, 7.0, -8.0, 1.0, -2.0, 4.0, 12.0, 12.0, 4.0, -9.0, 8.0, -6.0, 4.0, 8.0, 9.0, 12.0, 7.0, 8.0, -12.0, 2.0, 11.0, -11.0, 13.0, 11.0, 3.0, -11.0, 12.0, 13.0, 8.0, -7.0, 1.0, 3.0, 11.0, 2.0, -1.0, -11.0, 13.0, 3.0, 10.0, 10.0, 4.0, -2.0, 3.0, 14.0, -7.0, 1.0, 7.0, 3.0, 3.0, -1.0, 10.0, -6.0, 10.0, -1.0, 12.0, 10.0, 4.0, -10.0, 11.0, -5.0, 12.0, 7.0, 1.0, 13.0, 1.0, 11.0, -10.0, 2.0, 11.0, -11.0, 13.0, -1.0, 5.0, 5.0, 6.0, 9.0, -11.0, 9.0, 8.0, 9.0, 12.0, -17.0, 11.0, -11.0, 13.0, 0.0, 13.0, 13.0, 4.0, -4.0, 2.0, -3.0, -2.0, 12.0, 8.0, 14.0, 6.0, 5.0, -10.0, -11.0, 13.0, 1.0, 12.0, 8.0, 4.0, -10.0, 13.0, 8.0, -9.0, 9.0, 7.0, 13.0, 0.0, -9.0, 11.0, -8.0, 12.0, -1.0, 12.0, 10.0, 11.0, -19.0, 13.0, 14.0, -10.0, 4.0, 7.0, 2.0, 7.0, 8.0, -2.0, -6.0, 13.0, 11.0, -3.0, -4.0, 6.0, 0.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18437223495648322, "mean_inference_ms": 1.06682775989516, "mean_action_processing_ms": 0.07122650262344078, "mean_env_wait_ms": 0.1746845973057007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 347004, "agent_timesteps_total": 347004, "timers": {"sample_time_ms": 0.089, "sample_throughput": 61853725.3, "learn_time_ms": 14.953, "learn_throughput": 368351.403, "update_time_ms": 8.399}, "info": {"learner": {"learned": {"policy_loss": 185831636992.0, "vf_loss": 227.68052673339844, "total_loss": 185831636992.0, "vf_explained_var": -0.00016248226165771484, "model": {}}}, "num_steps_sampled": 347004, "num_agent_steps_sampled": 347004, "num_steps_trained": 347004, "num_agent_steps_trained": 347004}, "done": false, "episodes_total": 6804, "training_iteration": 63, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-49", "timestamp": 1626864469, "time_this_iter_s": 0.3502323627471924, "time_total_s": 23.283036947250366, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271158>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 23.283036947250366, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 70.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 10.0, -4.0, 5.0, 3.0, -2.0, 2.0, 12.0, -10.0, 12.0, 1.0, 12.0, 14.0, 9.0, -1.0, -7.0, -4.0, 12.0, 12.0, -5.0, -8.0, 12.0, 3.0, 8.0, -15.0, 12.0, 5.0, 13.0, 9.0, 12.0, -14.0, 8.0, 14.0, -5.0, 6.0, 0.0, -8.0, 6.0, 5.0, 12.0, -1.0, 12.0, -5.0, 9.0, 13.0, 10.0, -15.0, 7.0, 7.0, 12.0, -3.0, -1.0, 3.0, -4.0, 11.0, 5.0, 5.0, 13.0, -15.0, 12.0, 14.0, 9.0, 10.0, -18.0, 5.0, 9.0, -9.0, 10.0, 4.0, -4.0, 11.0, 4.0, -10.0, 7.0, 5.0, 13.0, 10.0, 10.0, -10.0, 5.0, 10.0, -9.0, 4.0, 10.0, -7.0, 9.0, 0.0, 13.0, 3.0, 12.0, -12.0, 12.0, 9.0, 6.0, 4.0, -4.0, 2.0, 7.0, 11.0, -5.0, -11.0, 13.0, 9.0, 4.0, 1.0, 13.0, -11.0, 12.0, 14.0, -8.0, 6.0, 3.0, 6.0, 9.0, 9.0, -9.0, 10.0, -1.0, 12.0, -6.0, 10.0, 12.0, 3.0, -10.0, 14.0, 7.0, -9.0, 3.0, 8.0, -3.0, 8.0, 2.0, 11.0, 13.0, 4.0, -13.0, 3.0, 12.0, -12.0, 12.0, 5.0, 2.0, -4.0, 12.0, 7.0, 9.0, 8.0, -9.0, 7.0, -16.0, 11.0, 13.0, 6.0, 11.0, -14.0, 12.0, 14.0, 12.0, 6.0, -17.0, 6.0, 14.0, 0.0, -5.0, -4.0, 12.0, -3.0, 10.0, 2.0, 13.0, -13.0, 13.0, 9.0, 11.0, -15.0, 10.0, 5.0, -1.0, 9.0, 2.0, -10.0, 14.0, 0.0, 11.0, -15.0, 13.0, 5.0, 12.0, 9.0, 12.0, -16.0, 10.0, -7.0, 14.0, 7.0, 1.0, -4.0, 13.0, -6.0, 12.0, 3.0, 10.0, -6.0, 8.0, 14.0, 11.0, -16.0, 6.0, 9.0, -1.0, 8.0, -1.0, 2.0, -2.0, 11.0, 4.0, 12.0, 10.0, 2.0, -9.0, 14.0, -6.0, 7.0, 0.0, 7.0, 7.0, -2.0, 3.0, -14.0, 6.0, 10.0, 13.0, -9.0, 12.0, 1.0, 11.0, 13.0, 6.0, -8.0, 4.0, 7.0, 7.0, 11.0, -10.0, 6.0, -2.0, -1.0, 12.0, 11.0, 12.0, 3.0, -11.0, 9.0, 11.0, -12.0, 7.0, 7.0, 7.0, 5.0, -4.0, 10.0, -3.0, 11.0, -3.0, 5.0, 13.0, -16.0, 13.0, 10.0, 1.0, -8.0, 12.0, 5.0, -7.0, 6.0, 11.0, 4.0, -11.0, 12.0, 10.0, 2.0, 12.0, -12.0, 13.0, 9.0, 8.0, -7.0, 5.0, 13.0, 5.0, -6.0, 3.0, 5.0, -10.0, 11.0, 9.0, 3.0, 10.0, -11.0, 13.0, 14.0, -13.0, 3.0, 11.0, 8.0, -8.0, 7.0, 8.0, -3.0, 13.0, -7.0, 12.0, 3.0, 12.0, -13.0, 13.0, 14.0, 0.0, -10.0, 11.0, -7.0, 11.0, 10.0, 1.0, 5.0, -8.0, 12.0, 6.0, 5.0, -5.0, 3.0, 12.0, 14.0, 13.0, -18.0, 6.0, 4.0, 0.0, 9.0, 2.0, 2.0, -6.0, 10.0, 9.0, -8.0, 10.0, 1.0, 12.0, 9.0, -8.0, 4.0, 10.0, 11.0, 3.0, 7.0, -6.0, -9.0, 9.0, 4.0, 11.0, 5.0, 12.0, -14.0, 12.0, 14.0, 11.0, -4.0, -6.0, -1.0, 7.0, 9.0, 0.0, 11.0, -1.0, 5.0, 0.0, -15.0, 12.0, 5.0, 13.0, -8.0, 13.0, 0.0, 10.0, 7.0, 10.0, -6.0, 4.0, -3.0, 8.0, 12.0, -2.0, -12.0, 13.0, 1.0, 13.0, -5.0, 5.0, 5.0, 10.0, 7.0, 14.0, -2.0, -4.0, 6.0, 12.0, -16.0, 13.0, 5.0, 12.0, -15.0, 13.0, 9.0, -7.0, 2.0, 11.0, 8.0, 14.0, -7.0, 0.0, 10.0, -7.0, 1.0, 11.0, 4.0, -2.0, 2.0, 11.0, 14.0, 8.0, -5.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843693518514917, "mean_inference_ms": 1.0667226647948853, "mean_action_processing_ms": 0.07124346005835408, "mean_env_wait_ms": 0.17472121967659782, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 352512, "agent_timesteps_total": 352512, "timers": {"sample_time_ms": 0.085, "sample_throughput": 64958345.626, "learn_time_ms": 14.497, "learn_throughput": 379937.71, "update_time_ms": 7.813}, "info": {"learner": {"learned": {"policy_loss": 89657049088.0, "vf_loss": 124.9217300415039, "total_loss": 89657049088.0, "vf_explained_var": -0.0006029605865478516, "model": {}}}, "num_steps_sampled": 352512, "num_agent_steps_sampled": 352512, "num_steps_trained": 352512, "num_agent_steps_trained": 352512}, "done": false, "episodes_total": 6912, "training_iteration": 64, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-49", "timestamp": 1626864469, "time_this_iter_s": 0.3554399013519287, "time_total_s": 23.638476848602295, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 23.638476848602295, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 82.6, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 14.0, -2.0, 9.0, 6.0, 4.0, -6.0, 11.0, 2.0, 10.0, 5.0, -2.0, -2.0, 4.0, 2.0, 11.0, 7.0, -2.0, 6.0, 4.0, -5.0, 8.0, 5.0, 7.0, 11.0, -2.0, 8.0, -2.0, -8.0, 10.0, 1.0, 12.0, -1.0, 5.0, 0.0, 11.0, 13.0, 5.0, -5.0, 2.0, -2.0, 5.0, 0.0, 12.0, -9.0, 5.0, 8.0, 11.0, 11.0, -12.0, 11.0, 5.0, -8.0, 6.0, 5.0, 12.0, 4.0, -1.0, 13.0, -1.0, 8.0, 9.0, 6.0, -8.0, -1.0, 12.0, -1.0, 5.0, 13.0, 5.0, -6.0, 3.0, -7.0, 9.0, 12.0, 1.0, 10.0, 4.0, 12.0, -11.0, 11.0, 10.0, -2.0, -4.0, 3.0, 7.0, 8.0, -3.0, -1.0, 2.0, 7.0, 7.0, -2.0, 3.0, 11.0, 3.0, 4.0, 10.0, -3.0, 4.0, 12.0, 8.0, -16.0, 11.0, -11.0, 6.0, 11.0, 9.0, -2.0, 5.0, 2.0, 10.0, 8.0, 11.0, -4.0, 0.0, 8.0, 11.0, 11.0, -15.0, 10.0, -7.0, 5.0, 7.0, -3.0, 6.0, -1.0, 13.0, -4.0, 8.0, 0.0, 11.0, 8.0, -13.0, 10.0, 10.0, 1.0, 12.0, 13.0, -11.0, -1.0, -4.0, 12.0, 8.0, -6.0, 6.0, 10.0, 5.0, 8.0, 12.0, -2.0, -3.0, -7.0, 9.0, 3.0, 10.0, -11.0, 7.0, 7.0, 12.0, -8.0, 12.0, 10.0, 1.0, 14.0, -8.0, 10.0, -1.0, 1.0, 12.0, 13.0, -11.0, 8.0, 11.0, -3.0, -1.0, 5.0, -6.0, 9.0, 7.0, 14.0, 1.0, 10.0, -10.0, 11.0, -9.0, 11.0, 2.0, -6.0, 6.0, 12.0, 3.0, 13.0, 10.0, -1.0, -7.0, 14.0, 2.0, -8.0, 7.0, -5.0, 7.0, 5.0, 8.0, -1.0, 3.0, 11.0, 2.0, 9.0, -3.0, 6.0, 3.0, 14.0, 10.0, -7.0, -2.0, -1.0, 5.0, 4.0, 7.0, -3.0, 2.0, 3.0, 13.0, -5.0, 9.0, 6.0, 5.0, 0.0, -5.0, 10.0, 10.0, -11.0, 9.0, 4.0, 13.0, -10.0, 10.0, 3.0, 12.0, 14.0, -4.0, -4.0, 9.0, 6.0, 8.0, -7.0, 8.0, 11.0, -8.0, 4.0, 8.0, -11.0, 12.0, 11.0, 3.0, -5.0, 6.0, 5.0, 9.0, 14.0, 2.0, 8.0, -9.0, 3.0, 12.0, -12.0, 12.0, -2.0, -3.0, 11.0, 9.0, 9.0, -2.0, 0.0, 8.0, 8.0, 13.0, -2.0, -4.0, 6.0, -5.0, 12.0, 2.0, -7.0, 8.0, 9.0, 5.0, 13.0, 6.0, -3.0, -1.0, -13.0, 7.0, 11.0, 10.0, 12.0, 4.0, -13.0, 12.0, -8.0, 6.0, 7.0, 10.0, 6.0, 7.0, -2.0, 4.0, 13.0, 11.0, -21.0, 12.0, 2.0, 12.0, -12.0, 13.0, 13.0, -1.0, 12.0, -9.0, 9.0, -8.0, 5.0, 9.0, 3.0, -2.0, 9.0, 5.0, 13.0, -1.0, 5.0, -2.0, 12.0, 8.0, -12.0, 7.0, 12.0, 9.0, -4.0, -2.0, -9.0, 9.0, 7.0, 8.0, 6.0, 4.0, -7.0, 12.0, -7.0, 12.0, -2.0, 12.0, 14.0, 9.0, -3.0, -5.0, 8.0, 4.0, -2.0, 5.0, -5.0, 12.0, 13.0, -5.0, -1.0, 10.0, 5.0, 1.0, 8.0, 10.0, -3.0, 0.0, 14.0, -14.0, 4.0, 11.0, 12.0, -1.0, 7.0, -3.0, -9.0, 3.0, 12.0, 9.0, -3.0, 8.0, 11.0, -1.0, 10.0, 9.0, 11.0, -15.0, -2.0, 10.0, -5.0, 12.0, -7.0, 7.0, 11.0, 4.0, -8.0, 13.0, 12.0, -2.0, 10.0, -3.0, 11.0, -3.0, -8.0, 13.0, 1.0, 9.0, 12.0, 11.0, -5.0, -3.0, 6.0, 9.0, 4.0, -4.0, 14.0, 1.0, 5.0, -5.0, 2.0, -3.0, 12.0, 4.0, -2.0, 7.0, 7.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843594770820902, "mean_inference_ms": 1.066561763006459, "mean_action_processing_ms": 0.07122482486764242, "mean_env_wait_ms": 0.1747119484226574, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 358020, "agent_timesteps_total": 358020, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66716651.9, "learn_time_ms": 14.412, "learn_throughput": 382179.677, "update_time_ms": 7.556}, "info": {"learner": {"learned": {"policy_loss": 1.3154419660568237, "vf_loss": 19.177167892456055, "total_loss": 20.49260902404785, "vf_explained_var": -0.003951311111450195, "model": {}}}, "num_steps_sampled": 358020, "num_agent_steps_sampled": 358020, "num_steps_trained": 358020, "num_agent_steps_trained": 358020}, "done": false, "episodes_total": 7020, "training_iteration": 65, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-50", "timestamp": 1626864470, "time_this_iter_s": 0.356046199798584, "time_total_s": 23.99452304840088, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 23.99452304840088, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.694444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 330.0}, "policy_reward_mean": {"learned": 6.923611111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 13.0, -1.0, -6.0, 14.0, 11.0, 11.0, 319.0, -10.0, 10.0, 12.0, 3.0, -9.0, 14.0, 11.0, -1.0, 13.0, 12.0, 10.0, -20.0, -7.0, 12.0, 12.0, -2.0, -11.0, 10.0, 6.0, 10.0, 4.0, 14.0, 10.0, -13.0, 7.0, 12.0, -15.0, 11.0, 12.0, 11.0, 12.0, -20.0, -3.0, 10.0, 1.0, 7.0, 1.0, 13.0, 11.0, -10.0, 7.0, 13.0, -15.0, 10.0, 11.0, 9.0, 12.0, -17.0, -7.0, 8.0, 7.0, 7.0, 6.0, 14.0, 7.0, -12.0, 2.0, 14.0, 11.0, -12.0, -8.0, 13.0, 12.0, -2.0, -18.0, 11.0, 11.0, 11.0, 1.0, 14.0, -10.0, 10.0, 2.0, 13.0, 12.0, -12.0, 14.0, 13.0, 12.0, 316.0, 8.0, 2.0, 8.0, -3.0, 7.0, 14.0, 10.0, -16.0, 1.0, 8.0, -4.0, 10.0, -1.0, 13.0, 9.0, -6.0, 10.0, 9.0, 6.0, -10.0, 5.0, 14.0, 0.0, -4.0, 2.0, -5.0, 12.0, 6.0, 12.0, 14.0, -3.0, -8.0, 6.0, 10.0, 11.0, -12.0, 6.0, 12.0, -6.0, 3.0, 9.0, 8.0, -5.0, 3.0, -2.0, 10.0, 11.0, -4.0, -10.0, 9.0, 5.0, 11.0, 1.0, 14.0, -4.0, 4.0, 8.0, 13.0, -15.0, 9.0, 13.0, 13.0, -21.0, 10.0, -3.0, 10.0, -2.0, 10.0, 8.0, 14.0, -15.0, 8.0, 7.0, 12.0, 0.0, -4.0, -1.0, 12.0, 7.0, -3.0, -8.0, 13.0, 11.0, -1.0, -13.0, 14.0, 2.0, 12.0, 11.0, 6.0, -1.0, -1.0, 14.0, 11.0, 316.0, 13.0, -1.0, 13.0, -4.0, 7.0, 2.0, 14.0, 9.0, -10.0, 0.0, 9.0, 13.0, -7.0, 13.0, 8.0, -2.0, -4.0, -2.0, 9.0, 3.0, 5.0, -2.0, 14.0, 10.0, -7.0, -16.0, 10.0, 13.0, 8.0, 13.0, 12.0, -21.0, 11.0, 5.0, -9.0, 12.0, 7.0, 4.0, 14.0, 9.0, -12.0, 6.0, 8.0, 4.0, -3.0, 9.0, 9.0, -8.0, 5.0, 11.0, 9.0, 10.0, -15.0, 5.0, 14.0, -13.0, 9.0, -13.0, 6.0, 10.0, 12.0, 12.0, 11.0, 11.0, -19.0, 12.0, 6.0, -10.0, 7.0, 2.0, 14.0, 11.0, -12.0, -12.0, 10.0, 13.0, 4.0, -2.0, 14.0, -9.0, 12.0, 3.0, -6.0, 7.0, 11.0, 3.0, 14.0, 12.0, -14.0, 9.0, 14.0, -3.0, -5.0, 12.0, 12.0, 330.0, 13.0, -7.0, 11.0, 4.0, 7.0, 6.0, 14.0, -8.0, 3.0, 12.0, 7.0, 10.0, -14.0, 10.0, 13.0, -21.0, 13.0, 11.0, 12.0, 2.0, -10.0, 4.0, 14.0, -10.0, 7.0, 13.0, 7.0, -10.0, 5.0, 8.0, 12.0, -18.0, 13.0, 9.0, 9.0, 10.0, -13.0, 4.0, 14.0, -12.0, 9.0, 7.0, 13.0, -11.0, 6.0, 13.0, 13.0, 10.0, -21.0, 12.0, -9.0, 1.0, 11.0, 4.0, 14.0, -15.0, 12.0, 11.0, 11.0, -8.0, 1.0, 8.0, 8.0, -14.0, 13.0, -7.0, 9.0, 2.0, 11.0, 3.0, 14.0, -3.0, 1.0, 11.0, 10.0, -5.0, -1.0, 11.0, 11.0, 9.0, -16.0, 12.0, 3.0, 3.0, -3.0, 6.0, 14.0, -4.0, -1.0, 7.0, 13.0, -8.0, 3.0, -9.0, 13.0, 12.0, -1.0, -7.0, 9.0, 9.0, 4.0, 9.0, 12.0, -4.0, -2.0, 3.0, 9.0, -2.0, 5.0, 13.0, 9.0, 12.0, -19.0, -1.0, 13.0, 2.0, 1.0, 4.0, 14.0, -5.0, 2.0, 0.0, 12.0, 6.0, -3.0, 11.0, 14.0, 12.0, -22.0, -15.0, 11.0, 12.0, 7.0, 7.0, 14.0, -14.0, 8.0, 3.0, 12.0, 9.0, -9.0, 13.0, 13.0, -16.0, 5.0, 11.0, -10.0, 10.0, 4.0, -13.0, 14.0, 12.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18440463703575916, "mean_inference_ms": 1.0668204114056448, "mean_action_processing_ms": 0.07122121795882198, "mean_env_wait_ms": 0.17474002509973532, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 363528, "agent_timesteps_total": 363528, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67951092.127, "learn_time_ms": 14.175, "learn_throughput": 388572.469, "update_time_ms": 7.334}, "info": {"learner": {"learned": {"policy_loss": 234259496960.0, "vf_loss": 242.1031494140625, "total_loss": 234259496960.0, "vf_explained_var": -0.000489354133605957, "model": {}}}, "num_steps_sampled": 363528, "num_agent_steps_sampled": 363528, "num_steps_trained": 363528, "num_agent_steps_trained": 363528}, "done": false, "episodes_total": 7128, "training_iteration": 66, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-50", "timestamp": 1626864470, "time_this_iter_s": 0.3572835922241211, "time_total_s": 24.351806640625, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 24.351806640625, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 75.8, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.037037037037036, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.759259259259259}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [3.0, 6.0, 8.0, -2.0, 1.0, 13.0, -5.0, 6.0, 4.0, -5.0, 10.0, 6.0, 10.0, 12.0, 13.0, -20.0, 14.0, 6.0, 11.0, -15.0, 12.0, 6.0, -12.0, 9.0, 11.0, 11.0, 8.0, -15.0, 10.0, 13.0, 2.0, -10.0, 14.0, 11.0, -11.0, 1.0, 3.0, 13.0, 10.0, -11.0, 0.0, -7.0, 11.0, 11.0, 11.0, 12.0, 5.0, -13.0, 7.0, 10.0, -10.0, 8.0, 13.0, 9.0, -9.0, 2.0, 6.0, 13.0, 13.0, -17.0, 11.0, 13.0, 7.0, -16.0, 8.0, 8.0, 9.0, -10.0, 8.0, 4.0, 7.0, -4.0, 9.0, 13.0, 12.0, -19.0, 1.0, 13.0, 13.0, -12.0, 8.0, 8.0, 10.0, -11.0, 13.0, 4.0, 8.0, -10.0, 6.0, -1.0, 13.0, -3.0, 9.0, 13.0, 2.0, -9.0, 10.0, 8.0, -8.0, 5.0, 11.0, 1.0, -4.0, 7.0, -13.0, 10.0, 9.0, 9.0, -1.0, 12.0, 1.0, 3.0, 9.0, 13.0, -3.0, -4.0, 6.0, 8.0, -10.0, 11.0, 3.0, -1.0, 7.0, 6.0, 10.0, 4.0, 7.0, -6.0, 8.0, 5.0, -4.0, 6.0, 8.0, 10.0, 3.0, -6.0, 10.0, 12.0, 11.0, -18.0, 13.0, 12.0, 7.0, -17.0, 5.0, 4.0, -4.0, 10.0, 7.0, -8.0, 10.0, 6.0, -4.0, 13.0, 7.0, -1.0, -8.0, 13.0, 8.0, 2.0, 10.0, 8.0, 9.0, -11.0, 13.0, 6.0, -6.0, 2.0, -15.0, 13.0, 9.0, 8.0, 12.0, 9.0, 6.0, -12.0, 10.0, 8.0, -5.0, 2.0, 12.0, 6.0, -4.0, 1.0, 6.0, 8.0, -5.0, 6.0, 12.0, -4.0, 3.0, 4.0, 8.0, 8.0, 10.0, -10.0, 8.0, 14.0, -9.0, 2.0, 6.0, -3.0, 6.0, 6.0, -6.0, 13.0, 2.0, 6.0, 10.0, 6.0, 11.0, -12.0, -7.0, 2.0, 10.0, 10.0, -14.0, 10.0, 13.0, 6.0, 13.0, 12.0, 3.0, -13.0, 13.0, 7.0, -1.0, -4.0, 6.0, 12.0, -8.0, 5.0, -4.0, -3.0, 10.0, 12.0, 6.0, 12.0, 13.0, -16.0, 13.0, 11.0, -11.0, 2.0, 5.0, -3.0, 8.0, 5.0, 0.0, -4.0, 12.0, 7.0, -9.0, 8.0, 8.0, 8.0, 9.0, 2.0, 10.0, -6.0, 13.0, 7.0, 4.0, -9.0, 7.0, 10.0, 11.0, -13.0, -11.0, 13.0, 13.0, 0.0, 12.0, 12.0, 9.0, -18.0, 13.0, 8.0, -10.0, 4.0, -10.0, 0.0, 13.0, 12.0, 12.0, 5.0, 8.0, -10.0, 8.0, 11.0, 11.0, -15.0, 11.0, 9.0, -11.0, 6.0, 12.0, 10.0, -12.0, 5.0, -9.0, 13.0, 3.0, 8.0, 4.0, 9.0, 10.0, -8.0, 5.0, 9.0, -4.0, 5.0, 12.0, -4.0, 8.0, -1.0, 10.0, 13.0, 1.0, -9.0, 10.0, 4.0, -9.0, 10.0, 13.0, 14.0, -10.0, -2.0, -5.0, -1.0, 10.0, 11.0, 10.0, 12.0, 6.0, -13.0, 9.0, 3.0, -3.0, 6.0, 13.0, 3.0, -13.0, 12.0, 9.0, 13.0, 13.0, -20.0, 9.0, 13.0, 7.0, -14.0, 4.0, 13.0, -5.0, 3.0, 12.0, -6.0, 10.0, -1.0, 11.0, 9.0, 12.0, -17.0, 11.0, 10.0, 5.0, -11.0, 9.0, 9.0, -13.0, 10.0, 8.0, -8.0, 10.0, 5.0, 10.0, 12.0, 9.0, -16.0, -6.0, 11.0, 3.0, 7.0, 14.0, 12.0, -3.0, -7.0, 3.0, 13.0, -13.0, 12.0, 4.0, 11.0, 13.0, -13.0, 11.0, 12.0, 5.0, -13.0, 9.0, 8.0, 1.0, -3.0, 13.0, 9.0, -4.0, -3.0, 5.0, -1.0, 8.0, 3.0, 12.0, 7.0, 8.0, -12.0, 5.0, 8.0, -4.0, 6.0, 9.0, 6.0, 11.0, -11.0, -3.0, -2.0, 10.0, 10.0, 12.0, 6.0, 9.0, -12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18435342928095025, "mean_inference_ms": 1.0663349023918305, "mean_action_processing_ms": 0.07119723371757936, "mean_env_wait_ms": 0.1747152165991142, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 369036, "agent_timesteps_total": 369036, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67845797.498, "learn_time_ms": 14.333, "learn_throughput": 384301.17, "update_time_ms": 7.286}, "info": {"learner": {"learned": {"policy_loss": 246789013504.0, "vf_loss": 348.80145263671875, "total_loss": 246789013504.0, "vf_explained_var": -0.00021076202392578125, "model": {}}}, "num_steps_sampled": 369036, "num_agent_steps_sampled": 369036, "num_steps_trained": 369036, "num_agent_steps_trained": 369036}, "done": false, "episodes_total": 7236, "training_iteration": 67, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-51", "timestamp": 1626864471, "time_this_iter_s": 0.35280585289001465, "time_total_s": 24.704612493515015, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182712f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 24.704612493515015, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.76851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 7.69212962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -11.0, 4.0, 13.0, -7.0, 13.0, 7.0, 2.0, 0.0, 13.0, 12.0, -10.0, 4.0, -8.0, 12.0, 7.0, 8.0, -13.0, 9.0, 11.0, 10.0, 14.0, -16.0, 7.0, -3.0, 13.0, 12.0, -7.0, 5.0, 7.0, -8.0, 11.0, 13.0, -4.0, -6.0, 12.0, 11.0, 7.0, 4.0, -7.0, 13.0, 12.0, 12.0, 319.0, 14.0, -17.0, 5.0, 13.0, 13.0, 1.0, -5.0, 6.0, 13.0, 9.0, -13.0, 6.0, 11.0, -1.0, 12.0, -7.0, -11.0, 3.0, 11.0, 12.0, 11.0, -6.0, 11.0, -1.0, -5.0, 8.0, 7.0, 5.0, 0.0, 13.0, 11.0, -9.0, 8.0, -12.0, 12.0, 7.0, 7.0, 5.0, -8.0, 11.0, 11.0, 10.0, 10.0, -16.0, 14.0, -3.0, 9.0, -5.0, 10.0, -12.0, 10.0, 7.0, 7.0, -15.0, 11.0, 12.0, 7.0, 9.0, 5.0, -6.0, 12.0, 12.0, 12.0, 319.0, 1.0, -9.0, 10.0, 13.0, 7.0, -14.0, 10.0, 12.0, 6.0, 14.0, -9.0, 4.0, 10.0, -3.0, 12.0, -4.0, 7.0, 9.0, 11.0, -12.0, 8.0, -16.0, 11.0, 12.0, 3.0, -4.0, 9.0, 7.0, 13.0, 12.0, 12.0, 319.0, -14.0, 5.0, 13.0, 11.0, 13.0, 0.0, 5.0, -3.0, 9.0, 13.0, 8.0, -15.0, -2.0, 7.0, 8.0, 2.0, 5.0, -14.0, 12.0, 12.0, 11.0, -15.0, 12.0, 7.0, 13.0, 10.0, -4.0, -4.0, 12.0, -2.0, 11.0, -6.0, 0.0, -7.0, 11.0, 11.0, -4.0, 0.0, 9.0, 10.0, 6.0, 10.0, 9.0, -10.0, 12.0, -9.0, 10.0, 2.0, 9.0, -16.0, 9.0, 13.0, -1.0, 0.0, 3.0, 13.0, -6.0, 10.0, 7.0, 4.0, 14.0, 9.0, 12.0, -20.0, 13.0, -14.0, 3.0, 13.0, 14.0, 2.0, 5.0, -6.0, 10.0, 14.0, 8.0, -17.0, -3.0, 12.0, 12.0, -6.0, 1.0, 9.0, -7.0, 12.0, 8.0, -1.0, 11.0, -3.0, -3.0, 13.0, 1.0, 4.0, 11.0, 13.0, 12.0, -21.0, 3.0, -12.0, 11.0, 13.0, -2.0, -1.0, 7.0, 11.0, 9.0, 14.0, -15.0, 7.0, 13.0, 12.0, 11.0, -21.0, 1.0, -2.0, 6.0, 10.0, 10.0, -17.0, 10.0, 12.0, 12.0, 5.0, 8.0, -10.0, 0.0, 13.0, 12.0, -10.0, 12.0, 3.0, 9.0, -9.0, 13.0, -15.0, 10.0, 7.0, -10.0, 7.0, 7.0, 11.0, 0.0, 10.0, 10.0, -5.0, 8.0, -11.0, 6.0, 12.0, -5.0, -1.0, 10.0, 11.0, 2.0, 11.0, -10.0, 12.0, 14.0, 13.0, 11.0, 317.0, 3.0, 10.0, -8.0, 10.0, 10.0, -18.0, 12.0, 11.0, 11.0, 8.0, -12.0, 8.0, 13.0, 10.0, 5.0, -13.0, 4.0, -7.0, 5.0, 13.0, 13.0, 1.0, 6.0, -5.0, -7.0, 8.0, 11.0, 3.0, 14.0, -5.0, 5.0, 1.0, 0.0, -3.0, 9.0, 9.0, -7.0, -1.0, 12.0, 11.0, 2.0, 12.0, 11.0, -10.0, 14.0, -4.0, 12.0, -7.0, 2.0, -10.0, 10.0, 13.0, -3.0, -5.0, 11.0, 12.0, 11.0, 2.0, 11.0, -9.0, 12.0, 13.0, 8.0, -18.0, -10.0, 3.0, 13.0, 9.0, 7.0, -1.0, -3.0, 12.0, -4.0, 12.0, 12.0, -5.0, 13.0, 12.0, 12.0, 319.0, 2.0, -8.0, 9.0, 12.0, 11.0, -6.0, 12.0, -2.0, 8.0, 10.0, -3.0, 0.0, 10.0, 12.0, 12.0, -19.0, 2.0, 8.0, 12.0, -7.0, 11.0, 1.0, -9.0, 12.0, 5.0, 14.0, -12.0, 8.0, 13.0, 11.0, 11.0, -20.0, 7.0, 1.0, -6.0, 13.0, 7.0, 7.0, -7.0, 8.0, 11.0, -10.0, 10.0, 4.0, 14.0, -3.0, 12.0, -8.0, 5.0, -11.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18435006680520113, "mean_inference_ms": 1.0660315072582518, "mean_action_processing_ms": 0.07118909616911644, "mean_env_wait_ms": 0.1747292348033308, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 374544, "agent_timesteps_total": 374544, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67814055.673, "learn_time_ms": 14.275, "learn_throughput": 385855.765, "update_time_ms": 7.03}, "info": {"learner": {"learned": {"policy_loss": 344784830464.0, "vf_loss": 433.3680419921875, "total_loss": 344784830464.0, "vf_explained_var": -9.608268737792969e-05, "model": {}}}, "num_steps_sampled": 374544, "num_agent_steps_sampled": 374544, "num_steps_trained": 374544, "num_agent_steps_trained": 374544}, "done": false, "episodes_total": 7344, "training_iteration": 68, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-51", "timestamp": 1626864471, "time_this_iter_s": 0.35491037368774414, "time_total_s": 25.05952286720276, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182719d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 25.05952286720276, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 73.1, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 1.0, 12.0, 8.0, -7.0, 7.0, 10.0, 5.0, 7.0, 7.0, -6.0, 7.0, -7.0, 4.0, 6.0, 12.0, 10.0, -6.0, 10.0, 1.0, 4.0, 13.0, -11.0, 9.0, 3.0, 10.0, -11.0, 13.0, 8.0, 10.0, -16.0, 13.0, -7.0, 2.0, 9.0, 11.0, -7.0, 8.0, 10.0, 4.0, 11.0, 10.0, -8.0, 2.0, 10.0, -8.0, 4.0, 9.0, -2.0, 1.0, 11.0, 5.0, -8.0, 13.0, 5.0, 5.0, 5.0, 12.0, 9.0, -11.0, 0.0, -11.0, 13.0, 13.0, 9.0, 9.0, 3.0, -6.0, -9.0, 13.0, 10.0, 1.0, -16.0, 9.0, 13.0, 9.0, 10.0, -12.0, 4.0, 13.0, 8.0, 5.0, 9.0, -7.0, -11.0, 9.0, 12.0, 5.0, 8.0, 10.0, -11.0, 8.0, 11.0, -2.0, -4.0, 10.0, 8.0, 4.0, 13.0, -10.0, -9.0, 8.0, 11.0, 5.0, 6.0, 10.0, -6.0, 5.0, -7.0, 8.0, 9.0, 5.0, 5.0, 12.0, -8.0, 6.0, -14.0, 13.0, 11.0, 5.0, 7.0, 7.0, -9.0, 10.0, 6.0, 7.0, -9.0, 11.0, 3.0, -6.0, 8.0, 10.0, -8.0, 13.0, 9.0, 1.0, 12.0, 6.0, 10.0, -13.0, -3.0, -2.0, 7.0, 13.0, 7.0, 6.0, 11.0, -9.0, 8.0, 12.0, -10.0, 5.0, 0.0, 8.0, -6.0, 13.0, 3.0, 7.0, -7.0, 12.0, -8.0, 6.0, 7.0, 10.0, -8.0, 8.0, 10.0, 5.0, 9.0, 14.0, 4.0, -12.0, 14.0, 6.0, -16.0, 11.0, 12.0, -7.0, -1.0, 11.0, -5.0, 9.0, 4.0, 7.0, 12.0, 8.0, -8.0, 3.0, 7.0, -10.0, 6.0, 12.0, 8.0, -11.0, 13.0, 5.0, 4.0, 12.0, -3.0, 2.0, 2.0, -3.0, 7.0, 9.0, 4.0, -9.0, 7.0, 13.0, 12.0, -11.0, 10.0, 4.0, 5.0, 13.0, -7.0, 4.0, 4.0, 13.0, -3.0, 1.0, 7.0, 7.0, 9.0, -8.0, -9.0, 0.0, 11.0, 13.0, 0.0, 13.0, -3.0, 5.0, 6.0, 6.0, 9.0, -6.0, 6.0, 1.0, -3.0, 11.0, 8.0, 8.0, 7.0, -8.0, -7.0, 8.0, 10.0, 4.0, 12.0, 4.0, -11.0, 10.0, -4.0, 1.0, 6.0, 12.0, 12.0, -13.0, 4.0, 12.0, 8.0, 8.0, -7.0, 6.0, 5.0, 14.0, 9.0, -13.0, 6.0, -9.0, 9.0, 9.0, 2.0, 12.0, -5.0, 6.0, -15.0, 13.0, 5.0, 12.0, 10.0, 12.0, -1.0, -6.0, -6.0, 8.0, 1.0, 12.0, 8.0, -12.0, 7.0, 12.0, -13.0, 12.0, 10.0, 6.0, 6.0, 6.0, 6.0, -3.0, 8.0, -8.0, 5.0, 10.0, 2.0, 5.0, -3.0, 11.0, -7.0, 8.0, 8.0, 6.0, 6.0, 10.0, 6.0, -7.0, 10.0, -9.0, 6.0, 8.0, 12.0, -9.0, 1.0, 11.0, -14.0, 12.0, 11.0, 6.0, 12.0, 4.0, 8.0, -9.0, 4.0, 4.0, -6.0, 13.0, 13.0, 7.0, 0.0, -5.0, -10.0, 13.0, 10.0, 2.0, 11.0, -11.0, 13.0, 2.0, -1.0, -8.0, 11.0, 13.0, 12.0, -11.0, 2.0, 12.0, -8.0, 12.0, 10.0, 1.0, 14.0, 8.0, -10.0, 3.0, -10.0, 2.0, 10.0, 13.0, -5.0, 4.0, 4.0, 12.0, 6.0, 9.0, -10.0, 10.0, 3.0, -1.0, 13.0, 0.0, 4.0, 7.0, 7.0, -3.0, 13.0, -13.0, 3.0, 12.0, -7.0, 8.0, 6.0, 8.0, 7.0, 10.0, -9.0, 7.0, 12.0, -11.0, 5.0, 9.0, 13.0, -8.0, 11.0, -1.0, -8.0, 12.0, 12.0, -1.0, -4.0, 11.0, 10.0, -2.0, -4.0, 1.0, 5.0, 13.0, 12.0, -9.0, 2.0, 10.0, 11.0, 13.0, -12.0, 3.0, 13.0, 9.0, -9.0, 2.0, 8.0, 4.0, -9.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843650533253461, "mean_inference_ms": 1.0656890115794144, "mean_action_processing_ms": 0.07118209337700078, "mean_env_wait_ms": 0.17475589616111126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 380052, "agent_timesteps_total": 380052, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68976313.005, "learn_time_ms": 14.45, "learn_throughput": 381172.023, "update_time_ms": 6.824}, "info": {"learner": {"learned": {"policy_loss": 1.2812366485595703, "vf_loss": 15.910598754882812, "total_loss": 17.191835403442383, "vf_explained_var": -0.0046694278717041016, "model": {}}}, "num_steps_sampled": 380052, "num_agent_steps_sampled": 380052, "num_steps_trained": 380052, "num_agent_steps_trained": 380052}, "done": false, "episodes_total": 7452, "training_iteration": 69, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-51", "timestamp": 1626864471, "time_this_iter_s": 0.3593943119049072, "time_total_s": 25.418917179107666, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 25.418917179107666, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.444444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.111111111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 2.0, 12.0, -3.0, 9.0, -12.0, 8.0, 10.0, 8.0, 13.0, -2.0, -4.0, -7.0, 14.0, 2.0, 6.0, -6.0, 4.0, 13.0, 4.0, 14.0, -3.0, -2.0, 6.0, 4.0, 5.0, 8.0, -2.0, -8.0, 11.0, 6.0, 6.0, 9.0, -11.0, 6.0, 11.0, 8.0, 5.0, -9.0, 11.0, 1.0, 5.0, -4.0, 13.0, 0.0, 11.0, 11.0, -7.0, -9.0, 7.0, 13.0, 4.0, 7.0, 7.0, 8.0, -7.0, -14.0, 6.0, 12.0, 11.0, 4.0, 11.0, 2.0, -2.0, -5.0, 2.0, 11.0, 7.0, 9.0, 8.0, -10.0, 8.0, 4.0, 6.0, 12.0, -7.0, -2.0, -2.0, 12.0, 7.0, -2.0, -1.0, 12.0, 6.0, 8.0, 8.0, -9.0, 8.0, 3.0, 9.0, -9.0, 12.0, -7.0, 12.0, 5.0, 5.0, -7.0, 4.0, 7.0, 11.0, 8.0, -13.0, 10.0, 10.0, -2.0, 14.0, -7.0, 10.0, -11.0, 10.0, 6.0, 10.0, 11.0, 1.0, 12.0, -9.0, 9.0, -16.0, 11.0, 11.0, -13.0, 9.0, 12.0, 7.0, -12.0, 10.0, 5.0, 12.0, -17.0, 10.0, 9.0, 13.0, 3.0, 6.0, 10.0, -4.0, -12.0, 5.0, 11.0, 11.0, -8.0, 7.0, 11.0, 5.0, -2.0, 3.0, 2.0, 12.0, 8.0, 1.0, 9.0, -3.0, -12.0, 8.0, 13.0, 6.0, -15.0, 12.0, 5.0, 13.0, -6.0, 4.0, 13.0, 4.0, 9.0, 7.0, 3.0, -4.0, -13.0, 6.0, 10.0, 12.0, -16.0, 11.0, 13.0, 7.0, -11.0, 5.0, 13.0, 8.0, 8.0, -10.0, 7.0, 10.0, -5.0, 1.0, 7.0, 12.0, -4.0, 12.0, -3.0, 10.0, 12.0, -18.0, 12.0, 9.0, 5.0, 4.0, 8.0, -2.0, 3.0, 2.0, 12.0, -2.0, -10.0, 13.0, 2.0, 10.0, 3.0, 6.0, 11.0, -5.0, 14.0, 6.0, -3.0, -2.0, 4.0, -8.0, 12.0, 7.0, 12.0, 11.0, -7.0, -1.0, 3.0, 8.0, 13.0, -9.0, 12.0, -13.0, 7.0, 9.0, -3.0, 14.0, -7.0, 11.0, 318.0, 12.0, 12.0, 12.0, 7.0, -2.0, 13.0, -3.0, 10.0, 0.0, 8.0, -3.0, 11.0, 14.0, 321.0, 9.0, -14.0, 8.0, 8.0, 13.0, -7.0, 2.0, 12.0, 8.0, 3.0, 7.0, -6.0, 11.0, 6.0, 6.0, 12.0, -9.0, 9.0, 12.0, 0.0, -6.0, 4.0, 3.0, 13.0, -5.0, 13.0, -14.0, 10.0, 6.0, 4.0, 5.0, 8.0, -2.0, 7.0, 6.0, -11.0, 13.0, 11.0, -16.0, 7.0, 13.0, 8.0, -1.0, -2.0, 10.0, -12.0, 4.0, 12.0, 11.0, 5.0, 12.0, 4.0, -6.0, 7.0, 1.0, 11.0, -4.0, 7.0, 3.0, -5.0, 10.0, -10.0, 2.0, 11.0, 12.0, -11.0, 11.0, 11.0, 4.0, -14.0, 8.0, 12.0, 9.0, 3.0, 12.0, -9.0, 9.0, 10.0, 6.0, -13.0, 12.0, 11.0, 11.0, -18.0, 11.0, -10.0, 6.0, 11.0, 8.0, -1.0, -4.0, 11.0, 9.0, 6.0, 6.0, -9.0, 12.0, 5.0, 11.0, 10.0, -11.0, -9.0, 1.0, 13.0, 10.0, 12.0, -12.0, 11.0, 4.0, 11.0, 14.0, -21.0, 11.0, -7.0, 10.0, 11.0, 1.0, -5.0, -4.0, 13.0, 11.0, 12.0, -17.0, 10.0, 10.0, -3.0, 13.0, -6.0, 11.0, -14.0, 13.0, 4.0, 12.0, 8.0, 13.0, 10.0, -16.0, 7.0, -6.0, 8.0, 6.0, 12.0, 14.0, 319.0, 11.0, -9.0, 13.0, 10.0, 1.0, -7.0, 3.0, 12.0, 7.0, 7.0, -12.0, 12.0, 8.0, -12.0, 4.0, 12.0, 11.0, -6.0, 7.0, 11.0, 3.0, -9.0, 0.0, 12.0, 12.0, 8.0, 3.0, 9.0, -5.0, -12.0, 4.0, 13.0, 10.0, -6.0, 13.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18433650198025994, "mean_inference_ms": 1.0652493371596388, "mean_action_processing_ms": 0.07116062085942441, "mean_env_wait_ms": 0.1747471040043377, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 385560, "agent_timesteps_total": 385560, "timers": {"sample_time_ms": 0.082, "sample_throughput": 67451725.955, "learn_time_ms": 14.24, "learn_throughput": 386786.672, "update_time_ms": 7.066}, "info": {"learner": {"learned": {"policy_loss": 459771346944.0, "vf_loss": 535.2473754882812, "total_loss": 459771346944.0, "vf_explained_var": -9.036064147949219e-05, "model": {}}}, "num_steps_sampled": 385560, "num_agent_steps_sampled": 385560, "num_steps_trained": 385560, "num_agent_steps_trained": 385560}, "done": false, "episodes_total": 7560, "training_iteration": 70, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-52", "timestamp": 1626864472, "time_this_iter_s": 0.34981870651245117, "time_total_s": 25.768735885620117, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 25.768735885620117, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 73.8, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.530092592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -7.0, 6.0, 6.0, 7.0, 14.0, 4.0, -10.0, -5.0, 11.0, 13.0, -4.0, 12.0, -1.0, 7.0, -3.0, 7.0, 8.0, -9.0, 9.0, 6.0, 10.0, -9.0, 8.0, 12.0, 13.0, 11.0, -21.0, 12.0, -6.0, 7.0, 2.0, -11.0, 9.0, 7.0, 10.0, 11.0, -4.0, 10.0, -2.0, 12.0, 12.0, 13.0, -22.0, -9.0, 12.0, 6.0, 6.0, 4.0, -6.0, 5.0, 12.0, 7.0, -5.0, 8.0, 5.0, 14.0, 10.0, 7.0, -16.0, 10.0, -2.0, 0.0, 7.0, 7.0, 8.0, -5.0, 5.0, 11.0, -5.0, 5.0, 4.0, -1.0, 12.0, -8.0, 12.0, 7.0, -2.0, -1.0, 11.0, -18.0, 9.0, 11.0, 13.0, 11.0, 9.0, 10.0, -15.0, 8.0, 12.0, 12.0, -17.0, -3.0, 13.0, 10.0, -5.0, 2.0, 8.0, -3.0, 8.0, 6.0, -5.0, 7.0, 7.0, 5.0, 7.0, 5.0, -2.0, -13.0, 14.0, 10.0, 4.0, 11.0, -16.0, 9.0, 11.0, 11.0, -5.0, 13.0, -4.0, 12.0, -7.0, -2.0, 12.0, 6.0, -10.0, 7.0, 12.0, 9.0, -7.0, 5.0, 8.0, 11.0, 3.0, 7.0, -6.0, 13.0, 9.0, 12.0, -19.0, -1.0, 13.0, 3.0, 0.0, 8.0, -11.0, 10.0, 8.0, 10.0, -2.0, 8.0, -1.0, -7.0, 12.0, 3.0, 7.0, -1.0, -1.0, 9.0, 8.0, 3.0, -7.0, 9.0, 10.0, -5.0, 7.0, 9.0, 4.0, -9.0, 13.0, 10.0, 1.0, -8.0, 12.0, 4.0, 7.0, -13.0, 9.0, 12.0, 7.0, 12.0, -3.0, 6.0, 0.0, 12.0, 11.0, 13.0, 316.0, -8.0, 13.0, 6.0, 4.0, 7.0, 8.0, 7.0, -7.0, 3.0, 12.0, 10.0, -10.0, 12.0, 6.0, -11.0, 8.0, 1.0, -1.0, 3.0, 12.0, 4.0, -7.0, 12.0, 6.0, 6.0, -2.0, 5.0, 6.0, 13.0, -8.0, 12.0, -2.0, 6.0, -1.0, 0.0, 10.0, 11.0, 8.0, 8.0, -12.0, 10.0, 10.0, 2.0, -7.0, 13.0, -13.0, 5.0, 10.0, 6.0, 12.0, 10.0, -13.0, 2.0, 8.0, -5.0, 10.0, 6.0, 10.0, 10.0, -11.0, 9.0, 12.0, 7.0, -13.0, -11.0, 13.0, 2.0, 11.0, 8.0, -7.0, 6.0, 8.0, 7.0, -3.0, 7.0, 4.0, -2.0, -3.0, 12.0, 8.0, -14.0, 13.0, 11.0, 5.0, -6.0, 4.0, 9.0, 8.0, 11.0, -6.0, 2.0, 8.0, 12.0, 9.0, 8.0, -14.0, -10.0, 14.0, 6.0, 5.0, -9.0, 8.0, 5.0, 11.0, 10.0, 0.0, 1.0, 4.0, -2.0, 13.0, 2.0, 2.0, -2.0, 12.0, 4.0, 1.0, 9.0, 7.0, 10.0, -11.0, 0.0, -1.0, 3.0, 13.0, 8.0, -6.0, 13.0, 0.0, 5.0, -2.0, 11.0, 1.0, 6.0, -6.0, 5.0, 10.0, 11.0, 10.0, 2.0, -8.0, 12.0, 11.0, -17.0, 9.0, -7.0, 13.0, 13.0, -4.0, -7.0, 9.0, 11.0, 2.0, 11.0, -6.0, 3.0, 7.0, -10.0, 8.0, 12.0, 5.0, -11.0, 12.0, 6.0, 8.0, 11.0, -16.0, 11.0, 9.0, -6.0, 11.0, 5.0, 5.0, 9.0, 9.0, 7.0, -10.0, -16.0, 13.0, 12.0, 6.0, 8.0, -16.0, 11.0, 12.0, 10.0, -6.0, 7.0, 4.0, 13.0, 11.0, 3.0, -12.0, -16.0, 13.0, 6.0, 12.0, -13.0, 8.0, 8.0, 12.0, 0.0, -2.0, 6.0, 11.0, -3.0, 10.0, -1.0, 9.0, 6.0, 12.0, 2.0, -5.0, 2.0, 8.0, -6.0, 11.0, 5.0, 12.0, 0.0, -2.0, 9.0, 13.0, 12.0, -19.0, 7.0, 11.0, -7.0, 4.0, 4.0, 6.0, -8.0, 13.0, 8.0, -1.0, 0.0, 8.0, 9.0, -1.0, 9.0, -2.0, 5.0, -1.0, 10.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18433805125848354, "mean_inference_ms": 1.0649669356160743, "mean_action_processing_ms": 0.0711461699995456, "mean_env_wait_ms": 0.17473102644636254, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 391068, "agent_timesteps_total": 391068, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68635343.3, "learn_time_ms": 13.649, "learn_throughput": 403555.601, "update_time_ms": 6.673}, "info": {"learner": {"learned": {"policy_loss": 342926786560.0, "vf_loss": 433.26239013671875, "total_loss": 342926786560.0, "vf_explained_var": -9.500980377197266e-05, "model": {}}}, "num_steps_sampled": 391068, "num_agent_steps_sampled": 391068, "num_steps_trained": 391068, "num_agent_steps_trained": 391068}, "done": false, "episodes_total": 7668, "training_iteration": 71, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-52", "timestamp": 1626864472, "time_this_iter_s": 0.3460962772369385, "time_total_s": 26.114832162857056, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 26.114832162857056, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 84.5, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 14.0, -4.0, -8.0, 0.0, -2.0, 12.0, 5.0, 4.0, -4.0, 2.0, 13.0, 10.0, 11.0, 2.0, -8.0, 8.0, 12.0, -12.0, 7.0, 8.0, -9.0, 5.0, 11.0, -4.0, 9.0, -2.0, 12.0, 9.0, -15.0, 10.0, 11.0, 12.0, 13.0, 4.0, -14.0, 8.0, -4.0, -2.0, 13.0, 12.0, -2.0, 7.0, -2.0, 9.0, -17.0, 11.0, 12.0, 8.0, 14.0, 5.0, -12.0, 8.0, -5.0, -1.0, 13.0, 10.0, -2.0, -1.0, 8.0, -9.0, 13.0, 7.0, 4.0, 5.0, 9.0, 4.0, -3.0, -8.0, 10.0, 7.0, 6.0, 5.0, -2.0, 0.0, 12.0, 13.0, -15.0, 11.0, 6.0, 12.0, 9.0, 10.0, -16.0, 9.0, 13.0, 12.0, -19.0, -10.0, 11.0, 6.0, 8.0, 2.0, -9.0, 10.0, 12.0, 6.0, 14.0, -11.0, 6.0, -8.0, -2.0, 12.0, 13.0, -8.0, 11.0, 10.0, 2.0, 4.0, 11.0, 10.0, -10.0, 8.0, 13.0, -4.0, -2.0, 7.0, -9.0, 5.0, 12.0, 5.0, -1.0, 11.0, 0.0, 3.0, 8.0, -2.0, 6.0, 5.0, 11.0, -14.0, 13.0, 4.0, -9.0, 8.0, 12.0, 11.0, -4.0, 5.0, 3.0, 8.0, 10.0, -10.0, 7.0, 4.0, 12.0, -11.0, 10.0, 12.0, -2.0, 2.0, 3.0, 10.0, -1.0, 0.0, 6.0, 11.0, 12.0, -5.0, -3.0, 4.0, 13.0, -12.0, 10.0, -4.0, 12.0, 7.0, 0.0, 5.0, 12.0, -9.0, 7.0, -11.0, 13.0, 2.0, 11.0, -13.0, 6.0, 11.0, 11.0, 7.0, -4.0, -1.0, 13.0, 11.0, -9.0, 1.0, 12.0, 13.0, 1.0, -10.0, 11.0, 8.0, -5.0, 0.0, 12.0, 10.0, 7.0, 12.0, -14.0, 13.0, -3.0, 0.0, 5.0, 10.0, -14.0, 6.0, 13.0, -7.0, 9.0, 3.0, 10.0, -7.0, 6.0, 9.0, 7.0, 10.0, 8.0, -14.0, 11.0, 11.0, 4.0, -4.0, 4.0, 5.0, 12.0, -14.0, 12.0, -9.0, 6.0, 11.0, 7.0, -2.0, 12.0, 6.0, -1.0, 10.0, -16.0, 9.0, 12.0, -13.0, 9.0, 11.0, 8.0, 4.0, -9.0, 8.0, 12.0, 9.0, -10.0, 3.0, 13.0, 5.0, -2.0, 8.0, 4.0, 8.0, 13.0, -3.0, -3.0, 6.0, -9.0, 12.0, 6.0, 7.0, -10.0, 11.0, 7.0, -5.0, 12.0, -4.0, 12.0, 1.0, 14.0, -10.0, 10.0, 7.0, -6.0, 12.0, 2.0, 10.0, -3.0, 1.0, 7.0, 11.0, -12.0, 5.0, 11.0, -6.0, 7.0, 9.0, 5.0, 6.0, -10.0, 6.0, 13.0, 9.0, 12.0, -3.0, -3.0, 14.0, -9.0, -2.0, 12.0, 7.0, 14.0, 10.0, -16.0, 7.0, -8.0, 8.0, 8.0, 10.0, 12.0, -15.0, 8.0, 12.0, 318.0, 13.0, 12.0, 12.0, 14.0, 8.0, -19.0, 7.0, 12.0, 12.0, -16.0, -2.0, 13.0, 2.0, 2.0, 2.0, 7.0, 9.0, -3.0, 7.0, 12.0, -15.0, 11.0, 4.0, -3.0, 7.0, 7.0, -2.0, 13.0, 5.0, -1.0, 1.0, -1.0, 9.0, 6.0, 6.0, 14.0, -3.0, -2.0, -2.0, 12.0, 1.0, 4.0, 12.0, -1.0, 3.0, 1.0, -2.0, 14.0, 8.0, -5.0, 6.0, 11.0, -13.0, 11.0, -8.0, 4.0, 11.0, 8.0, 6.0, -4.0, 7.0, 6.0, 3.0, -12.0, 12.0, 12.0, 11.0, 9.0, 11.0, -16.0, 10.0, -3.0, -5.0, 13.0, 13.0, -2.0, 8.0, -4.0, 3.0, 7.0, 10.0, -5.0, -9.0, 13.0, 9.0, 2.0, 2.0, -3.0, 3.0, 13.0, 12.0, -2.0, -5.0, 10.0, 13.0, -13.0, 12.0, 3.0, 12.0, 14.0, -3.0, -8.0, 8.0, -10.0, 4.0, 13.0, -13.0, 11.0, 7.0, 10.0, 14.0, -17.0, 11.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18434116077579155, "mean_inference_ms": 1.0648766821285705, "mean_action_processing_ms": 0.07113664779878347, "mean_env_wait_ms": 0.1747445615352431, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 396576, "agent_timesteps_total": 396576, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69449698.454, "learn_time_ms": 13.344, "learn_throughput": 412774.154, "update_time_ms": 6.43}, "info": {"learner": {"learned": {"policy_loss": 109561479168.0, "vf_loss": 128.82012939453125, "total_loss": 109561479168.0, "vf_explained_var": -0.0009065866470336914, "model": {}}}, "num_steps_sampled": 396576, "num_agent_steps_sampled": 396576, "num_steps_trained": 396576, "num_agent_steps_trained": 396576}, "done": false, "episodes_total": 7776, "training_iteration": 72, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-53", "timestamp": 1626864473, "time_this_iter_s": 0.35648441314697266, "time_total_s": 26.47131657600403, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182711e0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 26.47131657600403, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-11.0, 13.0, 10.0, 3.0, 4.0, 7.0, -8.0, 12.0, 14.0, -8.0, 9.0, 0.0, 11.0, 11.0, -4.0, -3.0, -14.0, 5.0, 11.0, 13.0, 8.0, 13.0, -5.0, -1.0, 13.0, 2.0, 6.0, -6.0, 14.0, 9.0, 10.0, -18.0, 10.0, 13.0, 8.0, -16.0, 2.0, 10.0, -7.0, 10.0, 12.0, -11.0, 11.0, 3.0, -1.0, 9.0, 12.0, -5.0, 10.0, 2.0, 5.0, -2.0, 2.0, 11.0, -2.0, 4.0, 7.0, -9.0, 11.0, 6.0, 8.0, 2.0, -1.0, 6.0, 2.0, 14.0, 9.0, -10.0, -12.0, 11.0, 11.0, 5.0, -1.0, 3.0, 8.0, 5.0, -5.0, 7.0, 13.0, 0.0, 3.0, 13.0, -8.0, 7.0, 2.0, 11.0, 11.0, -9.0, -1.0, 1.0, 8.0, 7.0, -1.0, 3.0, 8.0, 5.0, 3.0, 13.0, -6.0, 5.0, -12.0, 11.0, 4.0, 12.0, -9.0, 3.0, 13.0, 8.0, -8.0, 10.0, 9.0, 4.0, -3.0, 13.0, -5.0, 10.0, -8.0, 4.0, 6.0, 13.0, 13.0, -12.0, 10.0, 4.0, -1.0, 3.0, 13.0, 0.0, 0.0, 13.0, -10.0, 12.0, -5.0, 11.0, 3.0, 6.0, -5.0, 3.0, 7.0, 10.0, -1.0, -1.0, 10.0, 7.0, -10.0, 13.0, 7.0, 5.0, -18.0, 10.0, 11.0, 12.0, 14.0, -11.0, 3.0, 9.0, 8.0, 6.0, 7.0, -6.0, 5.0, 13.0, 8.0, -11.0, -14.0, 9.0, 11.0, 9.0, 13.0, -6.0, 7.0, 1.0, -1.0, 11.0, 12.0, -7.0, 5.0, 6.0, -8.0, 12.0, -3.0, 10.0, -2.0, 10.0, 12.0, -10.0, 11.0, 2.0, -5.0, 5.0, 12.0, 3.0, -6.0, 0.0, 11.0, 10.0, -10.0, 12.0, 9.0, 4.0, 14.0, -10.0, 6.0, 5.0, 8.0, -3.0, 9.0, 1.0, -11.0, 14.0, 4.0, 8.0, 9.0, 11.0, 9.0, -14.0, 13.0, -13.0, 10.0, 5.0, 7.0, 6.0, -5.0, 7.0, -11.0, 6.0, 12.0, 8.0, 13.0, 12.0, -7.0, -3.0, 14.0, -12.0, 2.0, 11.0, 13.0, 9.0, 0.0, -7.0, -1.0, 14.0, -9.0, 11.0, 12.0, 10.0, 2.0, -9.0, 9.0, -9.0, 3.0, 12.0, 8.0, 5.0, -5.0, 7.0, -9.0, 13.0, 8.0, 3.0, -15.0, 11.0, 11.0, 8.0, -9.0, -1.0, 12.0, 13.0, 13.0, 11.0, 9.0, -18.0, 9.0, 14.0, 11.0, -19.0, 8.0, 11.0, -1.0, -3.0, 5.0, -8.0, 8.0, 10.0, -1.0, 5.0, 6.0, 5.0, 0.0, 13.0, 10.0, -8.0, 8.0, -1.0, 10.0, -2.0, 13.0, -10.0, 11.0, 1.0, -1.0, 9.0, 13.0, -6.0, 2.0, 13.0, 9.0, -9.0, 7.0, -1.0, 3.0, 6.0, 7.0, -10.0, 10.0, 8.0, -1.0, 9.0, 13.0, -6.0, -1.0, 9.0, 10.0, -3.0, -12.0, 12.0, 4.0, 11.0, -4.0, 4.0, 4.0, 11.0, 9.0, 3.0, 13.0, -10.0, 7.0, 9.0, -13.0, 12.0, -8.0, 9.0, 8.0, 6.0, 6.0, -9.0, 7.0, 11.0, 7.0, 9.0, 12.0, -13.0, -13.0, 13.0, 6.0, 9.0, -16.0, 13.0, 11.0, 7.0, -2.0, 2.0, 4.0, 11.0, -5.0, 3.0, 13.0, 4.0, -7.0, 6.0, 5.0, 11.0, -6.0, 11.0, 3.0, 7.0, 13.0, -13.0, 9.0, 6.0, 13.0, 10.0, 13.0, 320.0, -15.0, 13.0, 10.0, 7.0, -15.0, 7.0, 12.0, 11.0, 13.0, -13.0, 4.0, 11.0, -8.0, 9.0, 7.0, 7.0, 6.0, 9.0, 11.0, -11.0, -10.0, 8.0, 5.0, 12.0, 0.0, 6.0, -1.0, 10.0, -9.0, 9.0, 13.0, 2.0, -11.0, 5.0, 8.0, 13.0, 2.0, 6.0, 11.0, -4.0, -5.0, 7.0, 6.0, 7.0, -1.0, 8.0, 1.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18436233252717887, "mean_inference_ms": 1.0647043173662682, "mean_action_processing_ms": 0.07114285271118026, "mean_env_wait_ms": 0.1747510483897382, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 402084, "agent_timesteps_total": 402084, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69439366.805, "learn_time_ms": 13.691, "learn_throughput": 402301.893, "update_time_ms": 6.375}, "info": {"learner": {"learned": {"policy_loss": 456763211776.0, "vf_loss": 535.1236572265625, "total_loss": 456763211776.0, "vf_explained_var": -9.465217590332031e-05, "model": {}}}, "num_steps_sampled": 402084, "num_agent_steps_sampled": 402084, "num_steps_trained": 402084, "num_agent_steps_trained": 402084}, "done": false, "episodes_total": 7884, "training_iteration": 73, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-53", "timestamp": 1626864473, "time_this_iter_s": 0.3643991947174072, "time_total_s": 26.835715770721436, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18286268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 26.835715770721436, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 73.3, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 13.0, -6.0, 13.0, 3.0, -8.0, 9.0, 11.0, -16.0, 7.0, 12.0, 12.0, 9.0, 12.0, -5.0, -1.0, -5.0, 0.0, 9.0, 11.0, 6.0, -11.0, 10.0, 10.0, -17.0, 12.0, 13.0, 7.0, 8.0, 3.0, 6.0, -2.0, 0.0, 11.0, 12.0, -8.0, 5.0, -13.0, 13.0, 10.0, -9.0, 3.0, 8.0, 13.0, -8.0, 13.0, 5.0, 5.0, -15.0, 11.0, 12.0, 7.0, 6.0, -11.0, 12.0, 8.0, 0.0, -1.0, 5.0, 11.0, 8.0, -10.0, 6.0, 11.0, -3.0, 10.0, -5.0, 13.0, 3.0, -8.0, 8.0, 12.0, -6.0, 9.0, 12.0, 0.0, 1.0, 11.0, 5.0, -2.0, 321.0, 11.0, 13.0, 10.0, 5.0, 6.0, -3.0, 7.0, -5.0, 0.0, 12.0, 8.0, 8.0, -7.0, 5.0, 9.0, -6.0, 14.0, -5.0, 12.0, 5.0, 7.0, -7.0, 10.0, -14.0, 11.0, 11.0, 7.0, -7.0, 11.0, 1.0, 10.0, -2.0, 13.0, 13.0, -9.0, 5.0, 4.0, 9.0, -3.0, -20.0, 13.0, 13.0, 9.0, 10.0, 12.0, 0.0, -7.0, -3.0, -4.0, 13.0, 9.0, 11.0, -13.0, 9.0, 8.0, -3.0, 3.0, 13.0, 2.0, 10.0, -15.0, 12.0, 8.0, -5.0, -2.0, 10.0, 12.0, 12.0, -15.0, 7.0, 11.0, -12.0, 13.0, 4.0, 10.0, 5.0, 9.0, -9.0, 10.0, -4.0, -2.0, 10.0, 11.0, -2.0, -5.0, 11.0, 11.0, -16.0, 8.0, 13.0, 10.0, 13.0, 4.0, -4.0, 2.0, -15.0, 12.0, 6.0, 12.0, 9.0, -16.0, 10.0, 12.0, -18.0, 13.0, 7.0, 13.0, 0.0, 11.0, 5.0, -1.0, -1.0, 12.0, -9.0, 13.0, 3.0, -4.0, 9.0, 7.0, -15.0, 8.0, 13.0, 9.0, 7.0, 12.0, -2.0, -2.0, -13.0, 11.0, 5.0, 12.0, 6.0, 4.0, 11.0, -6.0, -14.0, 8.0, 13.0, 8.0, -9.0, 6.0, 8.0, 10.0, -1.0, 12.0, -9.0, 13.0, 2.0, -7.0, 10.0, 10.0, -12.0, 12.0, 8.0, 7.0, 6.0, 11.0, -9.0, 7.0, 1.0, 12.0, 11.0, -9.0, 4.0, -6.0, 7.0, 10.0, -14.0, 6.0, 13.0, 10.0, 11.0, 8.0, 0.0, -4.0, 1.0, -2.0, 12.0, 4.0, 12.0, -14.0, 8.0, 9.0, 2.0, -8.0, 8.0, 13.0, 11.0, 5.0, 3.0, -4.0, -11.0, 10.0, 13.0, 3.0, 3.0, -9.0, 10.0, 11.0, -21.0, 12.0, 13.0, 11.0, -3.0, 12.0, 7.0, -1.0, -13.0, 12.0, 10.0, 6.0, 8.0, -8.0, 12.0, 3.0, -11.0, 12.0, 11.0, 3.0, 9.0, 6.0, -10.0, 10.0, -7.0, 13.0, 13.0, -4.0, 9.0, 5.0, 4.0, -3.0, 7.0, -10.0, 13.0, 5.0, 8.0, 10.0, 4.0, -7.0, 0.0, 12.0, 5.0, -2.0, 4.0, -10.0, 13.0, 8.0, -12.0, 3.0, 13.0, 11.0, 4.0, 1.0, -2.0, 12.0, 0.0, 10.0, 13.0, -8.0, 14.0, 1.0, 8.0, -8.0, -13.0, 12.0, 11.0, 5.0, 12.0, -13.0, 12.0, 4.0, -6.0, 11.0, 13.0, -3.0, 12.0, -11.0, 8.0, 6.0, -13.0, 11.0, 13.0, 4.0, 7.0, 10.0, 5.0, -7.0, -14.0, 12.0, 12.0, 5.0, 7.0, 5.0, -7.0, 10.0, -8.0, 10.0, 8.0, 5.0, 11.0, 2.0, -8.0, 10.0, -4.0, 13.0, 12.0, -6.0, 4.0, -8.0, 9.0, 10.0, -19.0, 14.0, 11.0, 9.0, 9.0, 5.0, -6.0, 7.0, -13.0, 10.0, 13.0, 5.0, 8.0, -2.0, 13.0, -4.0, -11.0, 7.0, 9.0, 10.0, -1.0, 5.0, 1.0, 10.0, -13.0, 10.0, 12.0, 6.0, 9.0, 0.0, 13.0, -7.0, -14.0, 12.0, 4.0, 13.0, 10.0, 11.0, -11.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18437603724139737, "mean_inference_ms": 1.0647099563094284, "mean_action_processing_ms": 0.07113961976769904, "mean_env_wait_ms": 0.17475323167271092, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 407592, "agent_timesteps_total": 407592, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69766911.875, "learn_time_ms": 13.554, "learn_throughput": 406365.184, "update_time_ms": 6.402}, "info": {"learner": {"learned": {"policy_loss": 109167386624.0, "vf_loss": 128.7981414794922, "total_loss": 109167386624.0, "vf_explained_var": -0.000946044921875, "model": {}}}, "num_steps_sampled": 407592, "num_agent_steps_sampled": 407592, "num_steps_trained": 407592, "num_agent_steps_trained": 407592}, "done": false, "episodes_total": 7992, "training_iteration": 74, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-53", "timestamp": 1626864473, "time_this_iter_s": 0.3552529811859131, "time_total_s": 27.19096875190735, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 27.19096875190735, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 369.0, "episode_reward_min": 15.0, "episode_reward_mean": 37.27777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 335.0}, "policy_reward_mean": {"learned": 9.319444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 355.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 369.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-7.0, 6.0, 8.0, 8.0, -1.0, 12.0, 6.0, -2.0, 12.0, 9.0, 4.0, -10.0, -5.0, -3.0, 11.0, 12.0, 10.0, -12.0, 11.0, 6.0, 9.0, 8.0, 11.0, -13.0, 5.0, 9.0, -12.0, 13.0, -6.0, -1.0, 9.0, 13.0, 9.0, 11.0, -13.0, 8.0, 8.0, 14.0, 5.0, -12.0, 13.0, 9.0, -13.0, 6.0, -6.0, 13.0, 9.0, -1.0, 5.0, -2.0, 8.0, 4.0, 7.0, 12.0, -10.0, 6.0, 14.0, 9.0, -18.0, 10.0, -7.0, 0.0, 9.0, 13.0, 3.0, -5.0, 6.0, 11.0, 10.0, 13.0, -18.0, 10.0, 2.0, 14.0, -9.0, 8.0, 3.0, 7.0, -5.0, 10.0, 5.0, 3.0, 12.0, -5.0, 9.0, 5.0, 3.0, -2.0, 7.0, 9.0, 6.0, -7.0, 320.0, 13.0, 11.0, 12.0, 12.0, 11.0, 321.0, 11.0, 10.0, 14.0, -18.0, 9.0, 13.0, 14.0, 313.0, 13.0, -6.0, 11.0, 11.0, -1.0, 5.0, -2.0, 7.0, 5.0, 7.0, 11.0, 13.0, -16.0, 14.0, 9.0, 0.0, -8.0, -5.0, -1.0, 11.0, 10.0, 13.0, 8.0, -4.0, -2.0, 7.0, 1.0, 12.0, -5.0, 11.0, 9.0, -13.0, 8.0, 9.0, 8.0, 2.0, -4.0, 12.0, -9.0, 7.0, 5.0, 7.0, 9.0, -12.0, 11.0, -1.0, 14.0, -7.0, 9.0, 319.0, 13.0, 13.0, 11.0, 7.0, 7.0, 9.0, -8.0, 6.0, 12.0, 7.0, -10.0, 7.0, 13.0, 6.0, -11.0, -7.0, 13.0, 10.0, -1.0, -6.0, 5.0, 8.0, 8.0, -1.0, 13.0, 11.0, -8.0, 9.0, 14.0, -15.0, 7.0, -5.0, 13.0, 8.0, -1.0, 7.0, 8.0, -6.0, 6.0, 4.0, 5.0, -1.0, 7.0, 11.0, 14.0, -17.0, 7.0, -3.0, -6.0, 12.0, 12.0, 4.0, -6.0, 6.0, 11.0, 12.0, 10.0, -6.0, -1.0, 14.0, 8.0, -20.0, 13.0, 11.0, -8.0, 12.0, 0.0, 2.0, -3.0, 8.0, 8.0, 9.0, 14.0, -20.0, 12.0, 9.0, 7.0, -9.0, 8.0, 1.0, -5.0, 7.0, 12.0, 12.0, -9.0, 11.0, 1.0, 11.0, 5.0, 8.0, -9.0, 4.0, 14.0, -10.0, 7.0, 6.0, -7.0, 11.0, 5.0, -7.0, 6.0, 11.0, 5.0, 7.0, 13.0, 10.0, -15.0, 10.0, 14.0, -17.0, 8.0, -6.0, 0.0, 10.0, 11.0, 14.0, 12.0, -11.0, 0.0, -7.0, 3.0, 11.0, 8.0, 10.0, 14.0, 2.0, -11.0, -8.0, 0.0, 10.0, 13.0, -7.0, 10.0, 9.0, 3.0, -15.0, 14.0, 4.0, 12.0, 8.0, 9.0, 4.0, -6.0, -4.0, -1.0, 11.0, 9.0, 13.0, 9.0, 11.0, -18.0, 9.0, 13.0, 10.0, -17.0, 9.0, 8.0, -14.0, 12.0, 7.0, -7.0, 10.0, 5.0, -8.0, 12.0, 10.0, 1.0, 10.0, 14.0, -7.0, -2.0, 10.0, 8.0, -15.0, 12.0, -8.0, 14.0, 10.0, -1.0, 13.0, 11.0, 10.0, 335.0, 12.0, -17.0, 12.0, 8.0, 4.0, 13.0, 8.0, -10.0, -6.0, 13.0, -5.0, 13.0, 14.0, 12.0, 11.0, 330.0, 10.0, 8.0, 12.0, -15.0, 12.0, 8.0, -12.0, 7.0, 10.0, 9.0, 1.0, -5.0, -3.0, -1.0, 12.0, 7.0, 8.0, 14.0, -2.0, -5.0, 14.0, 8.0, -15.0, 8.0, 2.0, 13.0, -4.0, 4.0, 14.0, 12.0, 318.0, 11.0, 6.0, 13.0, 9.0, -13.0, 13.0, 9.0, -18.0, 11.0, 13.0, -8.0, -1.0, 11.0, 13.0, -1.0, -5.0, 8.0, 10.0, 13.0, 4.0, -12.0, 3.0, 8.0, 13.0, -9.0, -5.0, -2.0, 11.0, 11.0, 5.0, -3.0, 5.0, 8.0, -3.0, 13.0, 10.0, -5.0, 10.0, 12.0, -13.0, 6.0, -8.0, 14.0, -2.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18437939083403332, "mean_inference_ms": 1.0644971061804993, "mean_action_processing_ms": 0.07112249260773391, "mean_env_wait_ms": 0.17473345725050723, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 413100, "agent_timesteps_total": 413100, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70734363.641, "learn_time_ms": 13.685, "learn_throughput": 402498.849, "update_time_ms": 6.152}, "info": {"learner": {"learned": {"policy_loss": 83677044736.0, "vf_loss": 127.20648193359375, "total_loss": 83677044736.0, "vf_explained_var": -0.0006409883499145508, "model": {}}}, "num_steps_sampled": 413100, "num_agent_steps_sampled": 413100, "num_steps_trained": 413100, "num_agent_steps_trained": 413100}, "done": false, "episodes_total": 8100, "training_iteration": 75, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-54", "timestamp": 1626864474, "time_this_iter_s": 0.3501870632171631, "time_total_s": 27.54115581512451, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 27.54115581512451, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 71.8, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 7.0, -5.0, 8.0, -9.0, 3.0, 11.0, 10.0, -2.0, -5.0, 12.0, 10.0, 7.0, 5.0, -8.0, 11.0, 5.0, 11.0, 1.0, -2.0, 14.0, -20.0, 11.0, 10.0, 2.0, 6.0, -4.0, 11.0, -5.0, 12.0, 4.0, 4.0, 7.0, 8.0, -11.0, 11.0, 6.0, -11.0, 11.0, 9.0, 13.0, -7.0, -2.0, 11.0, -1.0, 2.0, 4.0, 10.0, 8.0, -1.0, 6.0, 2.0, 7.0, -13.0, 12.0, 9.0, 10.0, -12.0, 6.0, 11.0, -16.0, 13.0, 12.0, 6.0, -9.0, 12.0, 10.0, 2.0, 12.0, -13.0, 4.0, 12.0, 10.0, 3.0, -7.0, 9.0, -9.0, 2.0, 11.0, 11.0, 7.0, 13.0, 10.0, -15.0, 7.0, 1.0, 10.0, -3.0, 9.0, -4.0, -3.0, 13.0, 5.0, 8.0, 11.0, -9.0, 7.0, 11.0, 6.0, -9.0, 12.0, 0.0, 7.0, -4.0, 8.0, 7.0, 2.0, -2.0, -11.0, 8.0, 5.0, 13.0, 8.0, 12.0, -17.0, 12.0, 9.0, 7.0, 4.0, -5.0, 11.0, 1.0, -7.0, 10.0, 13.0, -7.0, 3.0, 6.0, 8.0, 13.0, 12.0, -18.0, 13.0, -15.0, 9.0, 8.0, 10.0, 1.0, -4.0, 8.0, 8.0, -8.0, 8.0, 7.0, 7.0, 12.0, -17.0, 13.0, 9.0, 3.0, -8.0, 11.0, 13.0, 10.0, 6.0, -14.0, -17.0, 8.0, 12.0, 12.0, -6.0, 12.0, 11.0, -2.0, 14.0, -14.0, 12.0, 3.0, 12.0, 8.0, -8.0, 3.0, -6.0, -5.0, 13.0, 13.0, 9.0, 12.0, -13.0, 7.0, 9.0, -12.0, 9.0, 9.0, 10.0, 2.0, 5.0, -2.0, -3.0, 7.0, 5.0, 6.0, 13.0, 12.0, -12.0, 2.0, 14.0, 5.0, 5.0, -9.0, 8.0, 2.0, -8.0, 13.0, -3.0, 1.0, 10.0, 7.0, 6.0, 10.0, -13.0, 12.0, -1.0, 10.0, 10.0, -4.0, 7.0, 11.0, -10.0, 7.0, -15.0, 5.0, 13.0, 12.0, 4.0, 6.0, -2.0, 7.0, 8.0, 6.0, -9.0, 10.0, 6.0, 6.0, 11.0, -8.0, 8.0, -13.0, 7.0, 13.0, 7.0, 10.0, -2.0, 0.0, 9.0, -3.0, 11.0, -2.0, 2.0, 10.0, -8.0, 11.0, -4.0, 4.0, 5.0, 10.0, 9.0, 11.0, 4.0, -9.0, -2.0, -3.0, 11.0, 9.0, 10.0, 5.0, -2.0, 2.0, -13.0, 3.0, 12.0, 13.0, 8.0, 7.0, -10.0, 10.0, 13.0, -12.0, 11.0, 3.0, 12.0, 0.0, 5.0, -2.0, -10.0, 4.0, 9.0, 12.0, 7.0, 8.0, -4.0, 4.0, 12.0, -13.0, 4.0, 12.0, 13.0, 8.0, -8.0, 2.0, -9.0, 10.0, 9.0, 5.0, 7.0, 13.0, -9.0, 4.0, 10.0, -11.0, 12.0, 4.0, -7.0, 4.0, 6.0, 12.0, -1.0, -4.0, 13.0, 7.0, 5.0, -3.0, 12.0, 1.0, 12.0, -10.0, 6.0, 7.0, 9.0, 1.0, -3.0, 8.0, -13.0, 7.0, 11.0, 10.0, 5.0, 10.0, 6.0, -6.0, 7.0, 2.0, -4.0, 10.0, 13.0, 1.0, 12.0, -11.0, 10.0, -2.0, 7.0, 0.0, 11.0, -2.0, 1.0, 5.0, 12.0, 0.0, 7.0, -4.0, 8.0, 7.0, 10.0, -10.0, -14.0, 3.0, 13.0, 13.0, 5.0, 8.0, -6.0, 8.0, 7.0, -12.0, 10.0, 10.0, -4.0, 2.0, 12.0, 5.0, -14.0, 11.0, 5.0, 13.0, 11.0, 10.0, -15.0, 9.0, 12.0, 5.0, 10.0, -12.0, -4.0, 1.0, 6.0, 12.0, 12.0, -18.0, 9.0, 12.0, 12.0, 13.0, -16.0, 6.0, 14.0, -12.0, 4.0, 9.0, 13.0, 0.0, 6.0, -4.0, -8.0, 3.0, 9.0, 11.0, 4.0, 12.0, 12.0, -13.0, 7.0, -13.0, 12.0, 9.0, 13.0, 4.0, -7.0, 5.0, 7.0, 3.0, 6.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18434852576314747, "mean_inference_ms": 1.0644622016895893, "mean_action_processing_ms": 0.07112574799157327, "mean_env_wait_ms": 0.17472266046021354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 418608, "agent_timesteps_total": 418608, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70917146.212, "learn_time_ms": 13.946, "learn_throughput": 394953.062, "update_time_ms": 6.209}, "info": {"learner": {"learned": {"policy_loss": 96750247936.0, "vf_loss": 118.09058380126953, "total_loss": 96750247936.0, "vf_explained_var": -0.000577092170715332, "model": {}}}, "num_steps_sampled": 418608, "num_agent_steps_sampled": 418608, "num_steps_trained": 418608, "num_agent_steps_trained": 418608}, "done": false, "episodes_total": 8208, "training_iteration": 76, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-54", "timestamp": 1626864474, "time_this_iter_s": 0.35706090927124023, "time_total_s": 27.898216724395752, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 27.898216724395752, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 14.0, -2.0, -2.0, 13.0, 13.0, -20.0, 9.0, -8.0, 4.0, 9.0, 10.0, 11.0, 7.0, -8.0, 5.0, -2.0, 12.0, 5.0, 0.0, 1.0, 10.0, -6.0, 10.0, 11.0, 7.0, 1.0, -4.0, 6.0, -8.0, 7.0, 10.0, 14.0, 13.0, -7.0, -5.0, 0.0, 8.0, 12.0, -5.0, 0.0, 11.0, 10.0, -6.0, 5.0, 4.0, -7.0, 13.0, 10.0, 7.0, 9.0, -11.0, -15.0, 11.0, 10.0, 9.0, -8.0, 3.0, 9.0, 11.0, 7.0, 0.0, -3.0, 11.0, 12.0, -2.0, -5.0, 10.0, 9.0, 12.0, 10.0, -16.0, 8.0, 7.0, 4.0, -4.0, 5.0, -9.0, 11.0, 8.0, -4.0, 6.0, 6.0, 7.0, 0.0, 12.0, -10.0, 13.0, -7.0, 8.0, 8.0, 6.0, 7.0, 2.0, -5.0, 11.0, 10.0, 9.0, 10.0, -14.0, -1.0, 13.0, -4.0, 7.0, 14.0, 9.0, 4.0, -12.0, 9.0, 3.0, 11.0, -8.0, 5.0, 13.0, -9.0, 6.0, 12.0, 10.0, -16.0, 9.0, 7.0, 2.0, 9.0, -3.0, 11.0, 2.0, 12.0, -10.0, 11.0, 5.0, -3.0, 2.0, -15.0, 13.0, 5.0, 12.0, -5.0, 6.0, 10.0, 4.0, -6.0, 13.0, 5.0, 3.0, -4.0, 14.0, 0.0, 5.0, 10.0, 13.0, 10.0, -18.0, -10.0, 5.0, 10.0, 10.0, 10.0, -15.0, 9.0, 11.0, 11.0, 8.0, 4.0, -8.0, -18.0, 11.0, 13.0, 9.0, 10.0, 8.0, 3.0, -6.0, -1.0, -1.0, 11.0, 6.0, 8.0, 9.0, -6.0, 4.0, -6.0, 11.0, 12.0, -2.0, -2.0, 12.0, -1.0, 6.0, 6.0, 7.0, 9.0, -7.0, 9.0, 11.0, -12.0, 7.0, 5.0, 14.0, 1.0, -5.0, 7.0, 9.0, 10.0, -11.0, 10.0, -12.0, 5.0, 12.0, 14.0, 8.0, -10.0, 3.0, 6.0, 11.0, -8.0, 6.0, 7.0, 7.0, 7.0, -6.0, 7.0, -14.0, 11.0, 11.0, 6.0, 13.0, -9.0, 5.0, -17.0, 13.0, 12.0, 7.0, 9.0, 14.0, 3.0, -11.0, -9.0, 13.0, 6.0, 5.0, 10.0, 13.0, 9.0, -17.0, 5.0, 12.0, 1.0, -3.0, 9.0, 5.0, 10.0, -9.0, 3.0, 10.0, -3.0, 5.0, -5.0, 14.0, 2.0, 4.0, 0.0, 12.0, 8.0, -5.0, -12.0, 7.0, 11.0, 9.0, 9.0, 2.0, 8.0, -4.0, 7.0, 12.0, -9.0, 5.0, -4.0, 12.0, -2.0, 9.0, 9.0, 6.0, 10.0, -10.0, 4.0, -6.0, 11.0, 6.0, 14.0, 9.0, -13.0, 5.0, 12.0, 10.0, 6.0, -13.0, 7.0, 9.0, 9.0, -10.0, 13.0, 1.0, -3.0, 4.0, -3.0, 14.0, 3.0, 1.0, -7.0, 11.0, 6.0, 5.0, 6.0, 4.0, 9.0, -4.0, 2.0, 13.0, 4.0, -4.0, -8.0, 14.0, 3.0, 6.0, -19.0, 14.0, 11.0, 9.0, 12.0, 6.0, 7.0, -10.0, 13.0, -17.0, 9.0, 10.0, 12.0, 9.0, -12.0, 6.0, 5.0, 7.0, 7.0, -4.0, 9.0, 4.0, 10.0, -8.0, 9.0, 7.0, 8.0, -9.0, -4.0, 8.0, 1.0, 10.0, 5.0, 12.0, 8.0, -10.0, -3.0, 5.0, 3.0, 10.0, 6.0, -6.0, 9.0, 6.0, 6.0, 13.0, 5.0, -9.0, 7.0, 10.0, -12.0, 10.0, -1.0, 14.0, 8.0, -6.0, 12.0, 8.0, -9.0, 4.0, 8.0, 11.0, 5.0, -9.0, -5.0, 12.0, 1.0, 7.0, 12.0, 4.0, 4.0, -5.0, 11.0, 4.0, -2.0, 2.0, 10.0, 14.0, 5.0, -14.0, -11.0, 10.0, 6.0, 10.0, 0.0, 7.0, 5.0, 3.0, 6.0, 5.0, 11.0, -7.0, 11.0, 14.0, -8.0, -2.0, -18.0, 12.0, 9.0, 12.0, 9.0, 4.0, 5.0, -3.0, 5.0, 3.0, -3.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18431633471328507, "mean_inference_ms": 1.0641893023123243, "mean_action_processing_ms": 0.07110860667744937, "mean_env_wait_ms": 0.17470093376118356, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 424116, "agent_timesteps_total": 424116, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70370980.84, "learn_time_ms": 13.889, "learn_throughput": 396576.832, "update_time_ms": 6.297}, "info": {"learner": {"learned": {"policy_loss": 349549527040.0, "vf_loss": 555.4110107421875, "total_loss": 349549527040.0, "vf_explained_var": -0.0002295970916748047, "model": {}}}, "num_steps_sampled": 424116, "num_agent_steps_sampled": 424116, "num_steps_trained": 424116, "num_agent_steps_trained": 424116}, "done": false, "episodes_total": 8316, "training_iteration": 77, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-55", "timestamp": 1626864475, "time_this_iter_s": 0.35730671882629395, "time_total_s": 28.255523443222046, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 28.255523443222046, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 78.8, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.074074074074074, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7685185185185186}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-16.0, 14.0, 5.0, 12.0, 5.0, 7.0, 13.0, -10.0, 8.0, 13.0, -10.0, 4.0, 14.0, 8.0, -10.0, 3.0, 13.0, 13.0, 7.0, -18.0, -3.0, 7.0, 13.0, -2.0, 1.0, 14.0, -12.0, 12.0, -2.0, 11.0, 8.0, -2.0, 13.0, -4.0, -1.0, 7.0, -2.0, 8.0, 13.0, -4.0, -3.0, 0.0, 8.0, 10.0, -1.0, 10.0, 1.0, 5.0, 9.0, 14.0, -17.0, 9.0, 1.0, -8.0, 9.0, 13.0, 3.0, 8.0, -8.0, 12.0, 14.0, 12.0, -17.0, 6.0, 5.0, 0.0, 8.0, 2.0, 6.0, 14.0, -15.0, 10.0, 10.0, -6.0, 12.0, -1.0, 13.0, 8.0, -1.0, -4.0, 4.0, 0.0, 7.0, 4.0, 0.0, 5.0, 13.0, -3.0, -5.0, 11.0, 6.0, 3.0, -1.0, 12.0, 5.0, -1.0, -1.0, 0.0, 13.0, 3.0, 0.0, 9.0, 8.0, -2.0, 11.0, -3.0, 10.0, -3.0, 11.0, 12.0, 0.0, -7.0, -7.0, 14.0, 1.0, 7.0, -7.0, -3.0, 13.0, 12.0, -7.0, 0.0, 11.0, 11.0, -1.0, 10.0, 9.0, -3.0, 13.0, 14.0, 1.0, -13.0, 0.0, -2.0, 5.0, 12.0, 1.0, 13.0, -11.0, 12.0, 11.0, -3.0, -5.0, 12.0, 7.0, -1.0, 1.0, 8.0, 4.0, 4.0, -6.0, 13.0, 6.0, -1.0, 6.0, 4.0, 13.0, 8.0, -4.0, -2.0, 2.0, 0.0, 1.0, 12.0, 0.0, 9.0, 8.0, -2.0, 6.0, 13.0, 9.0, -13.0, -1.0, 12.0, 3.0, 1.0, -3.0, 14.0, -1.0, 5.0, -2.0, -4.0, 13.0, 8.0, 7.0, 12.0, -12.0, 8.0, 13.0, 8.0, 2.0, -8.0, 7.0, 0.0, 3.0, 5.0, -5.0, 9.0, 13.0, -2.0, 2.0, 12.0, -11.0, 12.0, 12.0, 11.0, -3.0, -4.0, 1.0, 14.0, -12.0, 12.0, 1.0, 11.0, 5.0, -2.0, -15.0, 12.0, 5.0, 13.0, 14.0, 13.0, -2.0, -9.0, 4.0, -2.0, 1.0, 12.0, 5.0, 11.0, -13.0, 12.0, 7.0, 13.0, 2.0, -7.0, 13.0, 11.0, -1.0, -7.0, 4.0, 14.0, 9.0, -12.0, 2.0, 4.0, 12.0, -3.0, 11.0, 9.0, 3.0, -8.0, 0.0, 9.0, 9.0, -3.0, 11.0, 14.0, -12.0, 2.0, 2.0, 9.0, 13.0, -9.0, 5.0, 13.0, 9.0, -12.0, 13.0, 11.0, -8.0, -1.0, 3.0, -1.0, 1.0, 12.0, -1.0, 8.0, -5.0, 13.0, 10.0, -7.0, 7.0, 5.0, 11.0, 14.0, -1.0, -9.0, 9.0, 13.0, -19.0, 12.0, -3.0, 9.0, 13.0, -4.0, 1.0, 13.0, 8.0, -7.0, -3.0, 11.0, 2.0, 5.0, 12.0, 14.0, 9.0, -20.0, -18.0, 10.0, 13.0, 10.0, 1.0, -2.0, 4.0, 12.0, 11.0, 11.0, -9.0, 2.0, 0.0, 13.0, 12.0, -10.0, 2.0, 8.0, -7.0, 12.0, 6.0, 12.0, 8.0, -11.0, 13.0, 11.0, -14.0, 6.0, 5.0, 14.0, -11.0, 7.0, 1.0, -5.0, 8.0, 11.0, 11.0, 13.0, 6.0, -15.0, 13.0, 7.0, 4.0, -9.0, 3.0, 0.0, 5.0, 7.0, -1.0, 13.0, 8.0, -5.0, 7.0, 13.0, 11.0, -16.0, -1.0, 10.0, 4.0, 2.0, 6.0, 14.0, -15.0, 10.0, 7.0, 4.0, -5.0, 9.0, 6.0, 12.0, -11.0, 8.0, -1.0, 6.0, 9.0, 1.0, 1.0, 14.0, -12.0, 12.0, 7.0, 1.0, 10.0, -3.0, -5.0, -1.0, 9.0, 12.0, -1.0, 9.0, 0.0, 8.0, 1.0, 14.0, -11.0, 11.0, -5.0, 9.0, 13.0, -2.0, -4.0, 11.0, -4.0, 12.0, -1.0, 9.0, 7.0, 0.0, 8.0, 12.0, 12.0, -17.0, -6.0, -2.0, 13.0, 10.0, 6.0, 12.0, 8.0, -11.0, 14.0, 13.0, -5.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18431283948803537, "mean_inference_ms": 1.0638453997925212, "mean_action_processing_ms": 0.07109507340520846, "mean_env_wait_ms": 0.17467544746003386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 429624, "agent_timesteps_total": 429624, "timers": {"sample_time_ms": 0.076, "sample_throughput": 72111041.625, "learn_time_ms": 13.65, "learn_throughput": 403515.423, "update_time_ms": 6.111}, "info": {"learner": {"learned": {"policy_loss": 1.2808533906936646, "vf_loss": 20.097774505615234, "total_loss": 21.37862777709961, "vf_explained_var": -0.005205988883972168, "model": {}}}, "num_steps_sampled": 429624, "num_agent_steps_sampled": 429624, "num_steps_trained": 429624, "num_agent_steps_trained": 429624}, "done": false, "episodes_total": 8424, "training_iteration": 78, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-55", "timestamp": 1626864475, "time_this_iter_s": 0.3479921817779541, "time_total_s": 28.603515625, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 28.603515625, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 78.6, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 12.0, 1.0, 8.0, 5.0, 9.0, 9.0, -8.0, 2.0, 9.0, -8.0, 12.0, -4.0, 2.0, 10.0, 7.0, 9.0, 11.0, -18.0, 13.0, 7.0, 8.0, 6.0, -6.0, -12.0, 9.0, 7.0, 11.0, 0.0, 11.0, -3.0, 7.0, -4.0, 11.0, 5.0, 3.0, 8.0, 12.0, -18.0, 13.0, -2.0, 4.0, 12.0, 1.0, 6.0, 12.0, -6.0, 3.0, 10.0, -5.0, 3.0, 7.0, 7.0, 3.0, 6.0, -1.0, -8.0, 14.0, -4.0, 13.0, 4.0, 12.0, -3.0, 2.0, -18.0, 13.0, 7.0, 13.0, 11.0, -14.0, 11.0, 7.0, 3.0, 9.0, -8.0, 11.0, 10.0, 2.0, 9.0, -6.0, 8.0, 11.0, -10.0, 6.0, 9.0, -8.0, 5.0, 9.0, 11.0, 4.0, 11.0, -11.0, 6.0, -6.0, 11.0, 4.0, -13.0, 10.0, 7.0, 11.0, 13.0, -16.0, 6.0, 12.0, -1.0, 13.0, -10.0, 13.0, -3.0, 13.0, 8.0, -3.0, -10.0, 11.0, 2.0, 12.0, 13.0, 3.0, 12.0, -13.0, -7.0, 5.0, 6.0, 11.0, 4.0, -3.0, 11.0, 3.0, -12.0, 9.0, 5.0, 13.0, -9.0, 5.0, 9.0, 10.0, 7.0, 14.0, -19.0, 13.0, 10.0, 6.0, -8.0, 7.0, -17.0, 12.0, 7.0, 13.0, 14.0, 11.0, -8.0, -2.0, -2.0, -2.0, 8.0, 11.0, -16.0, 12.0, 11.0, 8.0, -14.0, 7.0, 9.0, 13.0, 9.0, -7.0, 6.0, 7.0, 10.0, 4.0, -12.0, 13.0, -10.0, 8.0, 9.0, 8.0, -9.0, 8.0, 3.0, 13.0, 6.0, 6.0, 4.0, -1.0, 4.0, 13.0, -15.0, 13.0, 4.0, 9.0, -10.0, 12.0, 4.0, 13.0, -11.0, 9.0, 13.0, -6.0, 2.0, 6.0, 7.0, 6.0, -10.0, 12.0, -14.0, 13.0, 7.0, 9.0, 8.0, 7.0, -13.0, 13.0, 13.0, 4.0, 5.0, -7.0, -9.0, 9.0, 2.0, 13.0, 10.0, 10.0, 12.0, -17.0, 7.0, 11.0, -16.0, 13.0, 13.0, 13.0, -5.0, -6.0, 10.0, 14.0, -19.0, 10.0, 1.0, -1.0, 10.0, 5.0, -3.0, 13.0, -5.0, 10.0, 12.0, 3.0, -2.0, 2.0, -14.0, 14.0, 2.0, 13.0, 8.0, 10.0, -8.0, 5.0, 8.0, -4.0, 4.0, 7.0, 8.0, 7.0, 2.0, -2.0, -2.0, 14.0, -10.0, 13.0, 7.0, 13.0, -3.0, -2.0, -3.0, 5.0, 3.0, 10.0, 8.0, -1.0, 7.0, 1.0, -8.0, 9.0, 12.0, 2.0, 5.0, 10.0, -2.0, 2.0, 10.0, 7.0, -11.0, 9.0, 8.0, 8.0, -3.0, 2.0, -4.0, 14.0, 13.0, -8.0, 4.0, -3.0, 12.0, 2.0, -3.0, 8.0, -3.0, 13.0, 10.0, 13.0, 2.0, -10.0, 10.0, 9.0, -16.0, 12.0, 9.0, 5.0, -6.0, 7.0, -3.0, 7.0, -2.0, 13.0, 13.0, 0.0, 9.0, -7.0, -3.0, 5.0, 12.0, 1.0, 7.0, 8.0, -4.0, 4.0, -16.0, 7.0, 11.0, 13.0, 14.0, 5.0, -10.0, 6.0, -2.0, 8.0, -3.0, 12.0, 6.0, 12.0, -1.0, -2.0, -8.0, 7.0, 3.0, 13.0, 9.0, 8.0, -11.0, 9.0, -4.0, 14.0, 6.0, -1.0, 3.0, 12.0, -4.0, 4.0, 7.0, -3.0, 3.0, 8.0, 12.0, 6.0, -12.0, 9.0, -4.0, 9.0, -1.0, 11.0, 3.0, 11.0, -3.0, 4.0, 10.0, 5.0, -8.0, 8.0, 2.0, 6.0, 11.0, -4.0, -14.0, 14.0, 13.0, 2.0, -11.0, 12.0, 5.0, 9.0, 3.0, 4.0, -5.0, 13.0, 7.0, 7.0, -7.0, 8.0, 4.0, 14.0, -16.0, 13.0, 6.0, 13.0, -4.0, 0.0, 6.0, 11.0, -15.0, 13.0, 11.0, 2.0, 4.0, -2.0, 9.0, 9.0, -16.0, 13.0, -9.0, 12.0, 11.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843738507255711, "mean_inference_ms": 1.0640833979688091, "mean_action_processing_ms": 0.07112234647793103, "mean_env_wait_ms": 0.174713136847601, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 435132, "agent_timesteps_total": 435132, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70747537.488, "learn_time_ms": 13.609, "learn_throughput": 404727.08, "update_time_ms": 6.426}, "info": {"learner": {"learned": {"policy_loss": 1.2227654457092285, "vf_loss": 17.952560424804688, "total_loss": 19.175325393676758, "vf_explained_var": -0.006709933280944824, "model": {}}}, "num_steps_sampled": 435132, "num_agent_steps_sampled": 435132, "num_steps_trained": 435132, "num_agent_steps_trained": 435132}, "done": false, "episodes_total": 8532, "training_iteration": 79, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-55", "timestamp": 1626864475, "time_this_iter_s": 0.3684518337249756, "time_total_s": 28.971967458724976, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182860d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 28.971967458724976, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 352.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.530092592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 0.0, 7.0, 2.0, -3.0, -3.0, 12.0, 9.0, 11.0, -7.0, 5.0, 6.0, -14.0, 8.0, 10.0, 11.0, 1.0, 0.0, 6.0, 8.0, 8.0, 13.0, -8.0, 2.0, 8.0, 13.0, -10.0, 4.0, 7.0, -7.0, 3.0, 12.0, -7.0, 0.0, 9.0, 13.0, 1.0, 10.0, 8.0, -4.0, 9.0, 13.0, -15.0, 8.0, 8.0, 1.0, -2.0, 8.0, -10.0, 11.0, 8.0, 6.0, 6.0, 9.0, -3.0, 3.0, -4.0, -5.0, 11.0, 13.0, -13.0, 10.0, 6.0, 12.0, 4.0, -8.0, 8.0, 11.0, 13.0, 5.0, 6.0, -9.0, 10.0, 7.0, -13.0, 11.0, 14.0, -10.0, 4.0, 7.0, 0.0, -1.0, 7.0, 9.0, 9.0, 12.0, -17.0, 11.0, -10.0, 12.0, 6.0, 7.0, -15.0, 12.0, 5.0, 13.0, 0.0, -2.0, 7.0, 10.0, -10.0, 6.0, 8.0, 11.0, -1.0, 13.0, -10.0, 13.0, 5.0, -6.0, 10.0, 6.0, -7.0, 12.0, 9.0, 1.0, 10.0, 6.0, 12.0, -13.0, 4.0, -2.0, 5.0, 8.0, 2.0, -7.0, 11.0, 9.0, -8.0, 12.0, 8.0, 3.0, -1.0, 7.0, 10.0, -1.0, -3.0, 14.0, -9.0, 13.0, 12.0, 3.0, -6.0, 6.0, -8.0, 13.0, -2.0, 12.0, 13.0, 5.0, 12.0, -15.0, 4.0, 7.0, -7.0, 11.0, 2.0, -7.0, 10.0, 10.0, -3.0, -1.0, 10.0, 9.0, 5.0, 6.0, -4.0, 8.0, -11.0, 14.0, 0.0, 12.0, 12.0, -13.0, 11.0, 5.0, 5.0, 0.0, 6.0, 4.0, 9.0, 6.0, 9.0, -9.0, -4.0, 12.0, 6.0, 1.0, 9.0, -11.0, 7.0, 10.0, 5.0, 0.0, 2.0, 8.0, 10.0, 6.0, 11.0, -12.0, -6.0, 12.0, 3.0, 6.0, 6.0, 12.0, -6.0, 3.0, -12.0, 12.0, 7.0, 8.0, 12.0, 5.0, 8.0, -10.0, 10.0, 5.0, -12.0, 12.0, 9.0, -6.0, 2.0, 10.0, 11.0, -1.0, 9.0, -4.0, -1.0, 1.0, 4.0, 11.0, 2.0, 9.0, -9.0, 13.0, 13.0, -16.0, 12.0, 6.0, 6.0, -5.0, 2.0, 12.0, 6.0, 12.0, -8.0, 5.0, 9.0, -1.0, 6.0, 1.0, 8.0, 3.0, -5.0, 9.0, 1.0, -1.0, 6.0, 9.0, 10.0, 7.0, -8.0, 6.0, 12.0, 7.0, -14.0, 10.0, 0.0, 8.0, 13.0, -6.0, 1.0, -1.0, 5.0, 10.0, 8.0, -8.0, 9.0, 6.0, 9.0, 11.0, 5.0, -10.0, 7.0, -7.0, 8.0, 7.0, 8.0, -9.0, 8.0, 8.0, -3.0, 5.0, 7.0, 6.0, 8.0, 13.0, 318.0, 13.0, -15.0, 7.0, 11.0, 12.0, 6.0, -1.0, 0.0, 10.0, -2.0, 13.0, 4.0, 0.0, 2.0, 12.0, -12.0, 13.0, 13.0, 6.0, -7.0, 3.0, -8.0, 13.0, 3.0, 7.0, 13.0, -1.0, 13.0, -10.0, -9.0, 13.0, 8.0, 3.0, 9.0, 5.0, 3.0, -2.0, 6.0, -2.0, 3.0, 8.0, 13.0, 6.0, 12.0, -16.0, 6.0, 5.0, -9.0, 13.0, 9.0, 5.0, 7.0, -6.0, -3.0, -1.0, 8.0, 11.0, 11.0, 9.0, 7.0, -12.0, -5.0, 7.0, 0.0, 13.0, 13.0, 6.0, -8.0, 4.0, 11.0, -3.0, 6.0, 1.0, 9.0, 12.0, 2.0, -8.0, 8.0, 0.0, 2.0, 5.0, 14.0, -14.0, 4.0, 11.0, 4.0, -1.0, 1.0, 11.0, 12.0, 3.0, 13.0, -13.0, 3.0, 13.0, -14.0, 13.0, 9.0, 8.0, 6.0, -8.0, 4.0, -1.0, 11.0, 1.0, 13.0, 7.0, -17.0, 12.0, 9.0, -4.0, 8.0, 2.0, 13.0, 8.0, -10.0, 4.0, 4.0, -1.0, 9.0, 3.0, 11.0, 2.0, 11.0, -9.0, 5.0, 13.0, -6.0, 3.0, 8.0, 10.0, -12.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18435678607425512, "mean_inference_ms": 1.0638217381392647, "mean_action_processing_ms": 0.07111004454697419, "mean_env_wait_ms": 0.1746872851614911, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 440640, "agent_timesteps_total": 440640, "timers": {"sample_time_ms": 0.076, "sample_throughput": 72767050.273, "learn_time_ms": 13.688, "learn_throughput": 402399.295, "update_time_ms": 6.246}, "info": {"learner": {"learned": {"policy_loss": 783614672896.0, "vf_loss": 769.3607177734375, "total_loss": 783614672896.0, "vf_explained_var": -4.565715789794922e-05, "model": {}}}, "num_steps_sampled": 440640, "num_agent_steps_sampled": 440640, "num_steps_trained": 440640, "num_agent_steps_trained": 440640}, "done": false, "episodes_total": 8640, "training_iteration": 80, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-56", "timestamp": 1626864476, "time_this_iter_s": 0.3472476005554199, "time_total_s": 29.319215059280396, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 29.319215059280396, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 72.0, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.444444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 5.361111111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 2.0, 12.0, -4.0, 14.0, -17.0, 10.0, 8.0, 3.0, 7.0, -2.0, 7.0, -7.0, 12.0, 6.0, 4.0, 5.0, 5.0, -2.0, 7.0, 13.0, -16.0, 6.0, 12.0, 0.0, 12.0, -6.0, 9.0, 7.0, 12.0, 3.0, -7.0, 7.0, -11.0, 12.0, 8.0, 13.0, -11.0, 4.0, 9.0, 9.0, 1.0, -1.0, 6.0, 13.0, 5.0, 9.0, -12.0, 10.0, -17.0, 10.0, 12.0, 13.0, -13.0, 6.0, 9.0, -4.0, 10.0, 7.0, 2.0, 12.0, 5.0, 7.0, -9.0, 9.0, 0.0, -7.0, 13.0, 9.0, -2.0, -2.0, 10.0, -11.0, 5.0, 11.0, 10.0, 11.0, 12.0, 3.0, -11.0, -9.0, 8.0, 6.0, 10.0, 10.0, -2.0, 1.0, 6.0, 8.0, 5.0, -1.0, 3.0, 8.0, 7.0, 7.0, -7.0, 5.0, -13.0, 10.0, 13.0, 13.0, -18.0, 9.0, 11.0, 9.0, 11.0, -14.0, 9.0, 6.0, 12.0, 12.0, -15.0, 7.0, 2.0, 9.0, -3.0, 13.0, -14.0, 10.0, 6.0, -6.0, 10.0, 3.0, 8.0, 11.0, -15.0, 7.0, 12.0, 9.0, -8.0, 9.0, 5.0, 13.0, -16.0, 10.0, 8.0, 4.0, 6.0, -5.0, 10.0, 2.0, 12.0, 6.0, -5.0, 7.0, 2.0, -3.0, 9.0, 13.0, -9.0, 0.0, 11.0, 12.0, 5.0, -1.0, -1.0, 11.0, -3.0, 6.0, 1.0, 10.0, -4.0, 11.0, -2.0, 12.0, 7.0, -16.0, 12.0, -11.0, 12.0, 11.0, 3.0, 11.0, 11.0, 5.0, -12.0, 8.0, 2.0, 10.0, -5.0, 14.0, -1.0, 10.0, -8.0, 7.0, 3.0, 8.0, -3.0, 6.0, 12.0, 5.0, -8.0, -11.0, 7.0, 10.0, 10.0, 11.0, 4.0, -11.0, 11.0, 14.0, 7.0, -8.0, 2.0, 8.0, 13.0, 6.0, -12.0, 4.0, -12.0, 10.0, 13.0, 12.0, -12.0, 7.0, 8.0, 11.0, 8.0, -8.0, 4.0, 12.0, 7.0, -13.0, 9.0, 7.0, -14.0, 10.0, 12.0, 6.0, -13.0, 10.0, 12.0, -6.0, 11.0, 12.0, -2.0, 8.0, 12.0, 7.0, -12.0, 7.0, 1.0, -6.0, 13.0, 13.0, -8.0, -1.0, 11.0, 11.0, 2.0, 4.0, -2.0, 10.0, 7.0, -10.0, 8.0, 7.0, 2.0, 9.0, -3.0, 13.0, 323.0, 9.0, 12.0, 7.0, 6.0, 6.0, -4.0, 12.0, -7.0, 3.0, 7.0, 5.0, 6.0, 10.0, -6.0, 12.0, -11.0, 5.0, 9.0, 7.0, 1.0, -3.0, 10.0, -10.0, 12.0, 7.0, 6.0, 10.0, -18.0, 11.0, 12.0, 13.0, -9.0, 0.0, 11.0, 13.0, -3.0, 8.0, -3.0, 14.0, 6.0, -3.0, -2.0, 9.0, 0.0, 7.0, -1.0, 12.0, -7.0, 10.0, 0.0, 14.0, 2.0, 10.0, -11.0, 5.0, 13.0, -10.0, 7.0, 6.0, 6.0, 9.0, -6.0, 14.0, -10.0, 2.0, 9.0, 5.0, 10.0, -2.0, 2.0, 12.0, 13.0, 6.0, -16.0, 6.0, 2.0, 8.0, -1.0, 6.0, -7.0, 5.0, 11.0, 6.0, -5.0, 8.0, 6.0, 13.0, -14.0, 13.0, 3.0, -16.0, 5.0, 13.0, 13.0, 6.0, -12.0, 10.0, 11.0, 5.0, 6.0, -2.0, 6.0, 7.0, 11.0, 6.0, -9.0, 4.0, 2.0, -2.0, 11.0, 12.0, -2.0, -7.0, 12.0, 4.0, 2.0, 11.0, -2.0, 9.0, 4.0, 9.0, -7.0, 6.0, -13.0, 11.0, 11.0, 13.0, -11.0, 5.0, 8.0, 7.0, 13.0, 11.0, -16.0, 13.0, 4.0, 7.0, -9.0, 8.0, 3.0, 8.0, -4.0, 12.0, 2.0, -2.0, 3.0, 9.0, 12.0, 7.0, -13.0, 12.0, 13.0, -12.0, 2.0, 12.0, -2.0, 12.0, -7.0, 13.0, 331.0, 11.0, 12.0, 7.0, 10.0, 7.0, -9.0, 10.0, 4.0, 8.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843696405501928, "mean_inference_ms": 1.0637877625618062, "mean_action_processing_ms": 0.0710928983138497, "mean_env_wait_ms": 0.17466059851634408, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 446148, "agent_timesteps_total": 446148, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69604688.868, "learn_time_ms": 13.907, "learn_throughput": 396066.911, "update_time_ms": 6.218}, "info": {"learner": {"learned": {"policy_loss": 308247330816.0, "vf_loss": 330.63427734375, "total_loss": 308247330816.0, "vf_explained_var": -0.00020325183868408203, "model": {}}}, "num_steps_sampled": 446148, "num_agent_steps_sampled": 446148, "num_steps_trained": 446148, "num_agent_steps_trained": 446148}, "done": false, "episodes_total": 8748, "training_iteration": 81, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-56", "timestamp": 1626864476, "time_this_iter_s": 0.3603067398071289, "time_total_s": 29.679521799087524, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 29.679521799087524, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 5.0, 11.0, -11.0, 6.0, 12.0, -14.0, 11.0, 13.0, 13.0, -18.0, 7.0, 8.0, 13.0, -17.0, 11.0, 11.0, 7.0, 10.0, -13.0, 8.0, 9.0, 8.0, -10.0, 7.0, -4.0, 5.0, 7.0, 14.0, 8.0, -13.0, 6.0, -10.0, 6.0, 7.0, 12.0, 5.0, 8.0, -9.0, 11.0, 13.0, -1.0, 9.0, -6.0, 7.0, 13.0, 10.0, -15.0, -2.0, 8.0, 11.0, -2.0, 3.0, 6.0, -2.0, 8.0, 12.0, 4.0, 10.0, -11.0, 8.0, -5.0, 8.0, 4.0, -10.0, 8.0, 9.0, 8.0, 4.0, 9.0, 6.0, -4.0, 14.0, 11.0, 9.0, -19.0, 14.0, 12.0, 12.0, 317.0, 12.0, 13.0, 318.0, 12.0, -5.0, 7.0, 4.0, 9.0, 13.0, -4.0, 9.0, -3.0, 0.0, 14.0, 12.0, -11.0, -2.0, 7.0, 2.0, 8.0, 14.0, 5.0, 7.0, -11.0, 12.0, 10.0, 8.0, -15.0, 13.0, -3.0, -4.0, 9.0, -9.0, 7.0, 9.0, 8.0, 1.0, 8.0, 10.0, -4.0, 14.0, 10.0, 10.0, -19.0, 3.0, 13.0, -13.0, 12.0, -2.0, 9.0, 9.0, -1.0, 6.0, -3.0, 6.0, 6.0, 12.0, 10.0, 0.0, -7.0, 13.0, 13.0, 8.0, -19.0, 13.0, -9.0, 12.0, -1.0, -11.0, 9.0, 6.0, 11.0, 11.0, 13.0, 3.0, -12.0, 9.0, -4.0, 4.0, 6.0, -2.0, 3.0, 12.0, 2.0, 12.0, 8.0, -14.0, 9.0, 13.0, 12.0, -11.0, 1.0, 12.0, 6.0, -7.0, 4.0, -2.0, 8.0, 7.0, 2.0, -11.0, 11.0, 5.0, 10.0, 13.0, 4.0, 9.0, -11.0, 11.0, 9.0, -13.0, 8.0, 13.0, 11.0, -21.0, 12.0, 7.0, -6.0, 10.0, 4.0, 14.0, 10.0, 9.0, -18.0, 10.0, -3.0, 2.0, 6.0, -6.0, 11.0, 12.0, -2.0, 2.0, -8.0, 9.0, 12.0, 13.0, 10.0, 10.0, -18.0, 10.0, 13.0, 10.0, -18.0, 5.0, 5.0, -6.0, 11.0, 7.0, 10.0, -11.0, 9.0, 13.0, 11.0, 9.0, -18.0, 14.0, 11.0, 11.0, -21.0, 7.0, 6.0, -9.0, 11.0, 6.0, 8.0, -7.0, 8.0, 13.0, 5.0, 9.0, -12.0, 11.0, -2.0, 9.0, -3.0, -5.0, 4.0, 10.0, 6.0, 4.0, 7.0, -7.0, 11.0, 14.0, -8.0, 3.0, 6.0, 11.0, 13.0, 12.0, -21.0, -11.0, 9.0, 9.0, 8.0, -11.0, 6.0, 10.0, 10.0, 13.0, 10.0, 2.0, -10.0, 9.0, 11.0, -14.0, 9.0, -2.0, 13.0, -9.0, 13.0, -8.0, 14.0, 2.0, 7.0, 14.0, 6.0, 11.0, -16.0, 10.0, 13.0, 8.0, -16.0, 8.0, 10.0, -15.0, 12.0, -9.0, 12.0, 8.0, 4.0, 11.0, -3.0, 5.0, 2.0, 6.0, -2.0, 0.0, 11.0, -8.0, 12.0, 8.0, 3.0, 1.0, 11.0, -8.0, 11.0, 13.0, 12.0, 6.0, -16.0, 12.0, 5.0, -7.0, 5.0, -5.0, 7.0, 8.0, 5.0, 0.0, 13.0, -6.0, 8.0, 13.0, 9.0, 11.0, -18.0, 10.0, 12.0, -19.0, 12.0, 12.0, -7.0, 11.0, -1.0, 4.0, 14.0, 5.0, -8.0, 13.0, -4.0, 9.0, -3.0, 8.0, 13.0, 11.0, -17.0, 8.0, 9.0, 12.0, -14.0, 9.0, -3.0, 11.0, -2.0, 13.0, 10.0, -15.0, 7.0, 9.0, 13.0, -14.0, 7.0, 2.0, 8.0, 11.0, -6.0, -3.0, 13.0, -7.0, 12.0, 14.0, 12.0, -4.0, -7.0, 12.0, 11.0, -17.0, 9.0, -4.0, 8.0, 7.0, 4.0, 6.0, -3.0, 6.0, 6.0, 12.0, 10.0, -5.0, -2.0, 12.0, 13.0, -18.0, 8.0, 3.0, 6.0, 9.0, -3.0, 1.0, 8.0, -5.0, 11.0, 13.0, 9.0, 10.0, -17.0, 12.0, 9.0, -11.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843643752003804, "mean_inference_ms": 1.0637771820336523, "mean_action_processing_ms": 0.07109353952162517, "mean_env_wait_ms": 0.1746533033322777, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 451656, "agent_timesteps_total": 451656, "timers": {"sample_time_ms": 0.08, "sample_throughput": 69261325.736, "learn_time_ms": 13.732, "learn_throughput": 401098.425, "update_time_ms": 6.145}, "info": {"learner": {"learned": {"policy_loss": 1.3415597677230835, "vf_loss": 19.75459098815918, "total_loss": 21.09615135192871, "vf_explained_var": -0.0038069486618041992, "model": {}}}, "num_steps_sampled": 451656, "num_agent_steps_sampled": 451656, "num_steps_trained": 451656, "num_agent_steps_trained": 451656}, "done": false, "episodes_total": 8856, "training_iteration": 82, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-57", "timestamp": 1626864477, "time_this_iter_s": 0.34986114501953125, "time_total_s": 30.029382944107056, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182719d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 30.029382944107056, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 73.4, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 13.0, 4.0, -8.0, 14.0, 7.0, -13.0, 7.0, 11.0, 14.0, -6.0, -4.0, 6.0, -10.0, 10.0, 9.0, 8.0, 10.0, -15.0, 12.0, 5.0, 9.0, 13.0, -12.0, -10.0, 12.0, 0.0, 13.0, 13.0, -13.0, 2.0, 13.0, -17.0, 13.0, 8.0, 11.0, 9.0, 8.0, -13.0, 11.0, 9.0, -9.0, 9.0, 6.0, 11.0, 8.0, -17.0, 13.0, -14.0, 9.0, 7.0, 13.0, 12.0, 11.0, -10.0, 2.0, -6.0, 11.0, 9.0, 1.0, 12.0, 10.0, -14.0, 7.0, 0.0, 13.0, -5.0, 7.0, 12.0, 10.0, -8.0, 1.0, 7.0, -8.0, 5.0, 11.0, 12.0, 5.0, -15.0, 13.0, 8.0, 11.0, -10.0, 6.0, 8.0, 12.0, -7.0, 2.0, -13.0, 9.0, 7.0, 12.0, -5.0, -3.0, 12.0, 11.0, 4.0, 2.0, -4.0, 13.0, 7.0, 9.0, -13.0, 12.0, 8.0, 12.0, -16.0, 11.0, -1.0, 10.0, -2.0, 8.0, 8.0, 10.0, 11.0, -14.0, 9.0, 8.0, -8.0, 6.0, -12.0, 10.0, 5.0, 12.0, 11.0, 0.0, -9.0, 13.0, 7.0, -2.0, 11.0, -1.0, 11.0, 6.0, -8.0, 6.0, -8.0, 8.0, 5.0, 10.0, 11.0, -20.0, 11.0, 13.0, 2.0, 6.0, 9.0, -2.0, 2.0, 13.0, 6.0, -6.0, -13.0, 7.0, 12.0, 9.0, 12.0, 7.0, 6.0, -10.0, 12.0, -12.0, 12.0, 3.0, 13.0, 7.0, -5.0, 0.0, 2.0, -2.0, 5.0, 10.0, 10.0, -12.0, 11.0, 6.0, 6.0, 12.0, 10.0, -13.0, 2.0, 13.0, 9.0, -9.0, -7.0, 12.0, -2.0, 12.0, -6.0, 5.0, 4.0, 12.0, -2.0, -2.0, 9.0, 10.0, 12.0, 3.0, -2.0, 2.0, -5.0, 2.0, 12.0, 6.0, 11.0, -11.0, 12.0, 3.0, 2.0, -1.0, 6.0, 8.0, 8.0, 10.0, -10.0, 7.0, 13.0, -1.0, 8.0, -5.0, 12.0, 10.0, -15.0, 8.0, 8.0, 10.0, 10.0, -13.0, -4.0, 9.0, 9.0, 1.0, -9.0, 13.0, 13.0, -2.0, -2.0, 2.0, 6.0, 9.0, 8.0, -13.0, 11.0, 9.0, 4.0, 4.0, -5.0, 12.0, 2.0, -6.0, 11.0, 8.0, 6.0, 7.0, -11.0, 13.0, -14.0, 7.0, 10.0, 12.0, 3.0, 13.0, -5.0, 4.0, 11.0, 12.0, -4.0, -4.0, -1.0, -1.0, 4.0, 13.0, 6.0, 9.0, -5.0, 5.0, 3.0, 10.0, -3.0, 5.0, -8.0, 7.0, 5.0, 11.0, -1.0, 1.0, 5.0, 10.0, 8.0, 11.0, 8.0, -12.0, 12.0, 9.0, -13.0, 7.0, -10.0, 7.0, 10.0, 8.0, 12.0, 9.0, -12.0, 6.0, 1.0, 7.0, -3.0, 10.0, 7.0, 10.0, -9.0, 7.0, -7.0, 8.0, 11.0, 3.0, -9.0, 2.0, 9.0, 13.0, 3.0, 14.0, 3.0, -5.0, 13.0, 11.0, -10.0, 1.0, -1.0, 6.0, -1.0, 11.0, 8.0, 12.0, -17.0, 12.0, 6.0, 11.0, 11.0, -13.0, 8.0, 6.0, 8.0, -7.0, -7.0, 12.0, 6.0, 4.0, 11.0, -14.0, 11.0, 7.0, 4.0, 13.0, 1.0, -3.0, 6.0, 12.0, 9.0, -12.0, -6.0, 12.0, 9.0, 0.0, -8.0, 5.0, 9.0, 9.0, 8.0, 8.0, -9.0, 8.0, 13.0, 7.0, -11.0, 6.0, -12.0, 8.0, 10.0, 9.0, 8.0, 6.0, 6.0, -5.0, 6.0, 13.0, 8.0, -12.0, 7.0, 10.0, 6.0, -8.0, 11.0, 0.0, 11.0, -7.0, 12.0, -5.0, 12.0, -4.0, 8.0, 12.0, -8.0, 3.0, 13.0, 10.0, 3.0, -11.0, 5.0, 11.0, -10.0, 9.0, 10.0, 10.0, -10.0, 5.0, 7.0, 0.0, -4.0, 12.0, 14.0, 3.0, 5.0, -7.0, 7.0, -6.0, 7.0, 7.0, -4.0, 0.0, 6.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18435751425163183, "mean_inference_ms": 1.0636740403280374, "mean_action_processing_ms": 0.07108565984738414, "mean_env_wait_ms": 0.17465166786925912, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 457164, "agent_timesteps_total": 457164, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68303825.697, "learn_time_ms": 13.704, "learn_throughput": 401923.242, "update_time_ms": 6.131}, "info": {"learner": {"learned": {"policy_loss": 1.247042179107666, "vf_loss": 15.68941593170166, "total_loss": 16.936458587646484, "vf_explained_var": -0.0059642791748046875, "model": {}}}, "num_steps_sampled": 457164, "num_agent_steps_sampled": 457164, "num_steps_trained": 457164, "num_agent_steps_trained": 457164}, "done": false, "episodes_total": 8964, "training_iteration": 83, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-57", "timestamp": 1626864477, "time_this_iter_s": 0.3500993251800537, "time_total_s": 30.37948226928711, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 30.37948226928711, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 83.9, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 8.0, 3.0, -2.0, 8.0, -2.0, 9.0, 0.0, 10.0, -4.0, -4.0, 13.0, 10.0, 7.0, 10.0, -12.0, 0.0, 8.0, -5.0, 12.0, 13.0, 7.0, 3.0, -8.0, 12.0, 9.0, 9.0, -15.0, 6.0, -1.0, 6.0, 4.0, 8.0, 8.0, 1.0, -2.0, 9.0, 6.0, 7.0, -7.0, -4.0, 13.0, 3.0, 3.0, 5.0, 11.0, 5.0, -6.0, 7.0, 3.0, 7.0, -2.0, 7.0, 13.0, 5.0, -10.0, -5.0, 4.0, 12.0, 4.0, 0.0, 6.0, -2.0, 11.0, 3.0, 7.0, 7.0, -2.0, 10.0, 12.0, 10.0, -17.0, 10.0, -1.0, 0.0, 6.0, 4.0, 10.0, -1.0, 2.0, 9.0, 13.0, 0.0, -7.0, 11.0, -11.0, 5.0, 10.0, 13.0, -12.0, 9.0, 5.0, -12.0, 6.0, 9.0, 12.0, 6.0, 6.0, -9.0, 12.0, 11.0, 9.0, 9.0, -14.0, 7.0, -4.0, 7.0, 5.0, -11.0, 10.0, 6.0, 10.0, 2.0, 8.0, 6.0, -1.0, 4.0, 7.0, 10.0, -6.0, 0.0, -1.0, 8.0, 8.0, -12.0, 8.0, 6.0, 13.0, 4.0, 13.0, 5.0, -7.0, 5.0, 11.0, 7.0, -8.0, 9.0, -5.0, 8.0, 3.0, 6.0, -3.0, 3.0, 9.0, 9.0, 7.0, 1.0, -2.0, 11.0, -17.0, 8.0, 13.0, -2.0, 6.0, 3.0, 8.0, -13.0, 12.0, 9.0, 7.0, 9.0, 13.0, -6.0, -1.0, 8.0, 8.0, 5.0, -6.0, -9.0, 13.0, 5.0, 6.0, -4.0, 13.0, -4.0, 10.0, 5.0, 8.0, -10.0, 12.0, 10.0, -1.0, 9.0, -3.0, 5.0, -1.0, 5.0, 6.0, 4.0, 11.0, -7.0, 7.0, 4.0, 13.0, -8.0, 6.0, 3.0, 11.0, 8.0, -7.0, -9.0, 7.0, 8.0, 9.0, -1.0, 10.0, 5.0, 1.0, 5.0, 13.0, 2.0, -5.0, 12.0, -19.0, 12.0, 10.0, -7.0, 13.0, 9.0, 0.0, 3.0, 11.0, -7.0, 8.0, 7.0, 3.0, 7.0, -2.0, 10.0, 6.0, -12.0, 11.0, 12.0, -5.0, 7.0, 1.0, 5.0, 7.0, 12.0, -9.0, 6.0, 13.0, -10.0, 6.0, 6.0, 6.0, 10.0, -7.0, 13.0, -5.0, 11.0, -4.0, -4.0, 8.0, 5.0, 6.0, 3.0, 12.0, 7.0, -7.0, 6.0, 5.0, 5.0, -1.0, 8.0, -8.0, 3.0, 12.0, -8.0, 10.0, 7.0, 6.0, 5.0, 12.0, -13.0, 11.0, 7.0, -7.0, 9.0, 6.0, 6.0, -5.0, 9.0, 5.0, -10.0, 10.0, 2.0, 13.0, 13.0, 3.0, 2.0, -3.0, 6.0, 13.0, -11.0, 7.0, 11.0, 9.0, -18.0, 13.0, -12.0, 10.0, 7.0, 10.0, 7.0, 13.0, 2.0, -7.0, 11.0, -13.0, 10.0, 7.0, 8.0, -8.0, 7.0, 8.0, 6.0, -3.0, 6.0, 6.0, 7.0, 8.0, 6.0, -6.0, 3.0, 12.0, 8.0, -8.0, 11.0, -7.0, 11.0, 0.0, 11.0, 13.0, 10.0, -19.0, 9.0, 10.0, 2.0, -6.0, 10.0, 4.0, 6.0, -5.0, -8.0, 12.0, -2.0, 13.0, -8.0, 11.0, 10.0, 2.0, 4.0, 13.0, 2.0, -4.0, 6.0, -5.0, 1.0, 13.0, 8.0, -10.0, 8.0, 9.0, 8.0, 11.0, 11.0, -15.0, 1.0, 13.0, 2.0, -1.0, 11.0, 322.0, 10.0, 12.0, 8.0, -5.0, 2.0, 10.0, -1.0, 5.0, 10.0, 1.0, 8.0, 10.0, 4.0, -7.0, 9.0, -10.0, 6.0, 10.0, 8.0, -6.0, 8.0, 5.0, 8.0, 12.0, 2.0, -7.0, 5.0, 3.0, -5.0, 12.0, 6.0, 5.0, 8.0, -4.0, 9.0, 13.0, -14.0, 7.0, -1.0, 11.0, 12.0, -7.0, 5.0, 5.0, 8.0, -3.0, 4.0, 10.0, 11.0, -10.0, 8.0, 9.0, 2.0, -4.0, -9.0, 11.0, 7.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843632389694102, "mean_inference_ms": 1.0636714523294752, "mean_action_processing_ms": 0.07106794098040811, "mean_env_wait_ms": 0.1746331387957784, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 462672, "agent_timesteps_total": 462672, "timers": {"sample_time_ms": 0.082, "sample_throughput": 67570800.425, "learn_time_ms": 14.134, "learn_throughput": 389701.181, "update_time_ms": 5.947}, "info": {"learner": {"learned": {"policy_loss": 73946562560.0, "vf_loss": 126.7274398803711, "total_loss": 73946562560.0, "vf_explained_var": -0.0008869171142578125, "model": {}}}, "num_steps_sampled": 462672, "num_agent_steps_sampled": 462672, "num_steps_trained": 462672, "num_agent_steps_trained": 462672}, "done": false, "episodes_total": 9072, "training_iteration": 84, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-57", "timestamp": 1626864477, "time_this_iter_s": 0.35779428482055664, "time_total_s": 30.737276554107666, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 30.737276554107666, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.23148148148148, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.55787037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-17.0, 13.0, 11.0, 8.0, -1.0, 12.0, 10.0, -6.0, 4.0, 14.0, 0.0, -3.0, -15.0, 13.0, 6.0, 11.0, 12.0, 13.0, 2.0, -12.0, 2.0, 11.0, -6.0, 8.0, 9.0, -2.0, -4.0, 12.0, 1.0, 10.0, 12.0, -8.0, 14.0, -13.0, 8.0, 6.0, -9.0, 11.0, 9.0, 4.0, 5.0, 8.0, 5.0, -3.0, -3.0, 12.0, 0.0, 6.0, 4.0, 6.0, -5.0, 11.0, 3.0, 14.0, 7.0, -9.0, -9.0, 14.0, 0.0, 10.0, -5.0, 9.0, -1.0, 12.0, 13.0, 0.0, 8.0, -6.0, 1.0, 13.0, -6.0, 7.0, 7.0, -2.0, -3.0, 13.0, 5.0, -3.0, 5.0, 8.0, -4.0, 3.0, 6.0, 11.0, -18.0, 11.0, 10.0, 12.0, -9.0, 5.0, 7.0, 12.0, -16.0, 13.0, 12.0, 6.0, 12.0, 9.0, -14.0, 9.0, 3.0, 11.0, -1.0, 2.0, 3.0, -6.0, 6.0, 12.0, -8.0, 9.0, 6.0, 8.0, 7.0, 8.0, -7.0, 7.0, 7.0, 11.0, -8.0, 5.0, 8.0, 12.0, 2.0, -7.0, -15.0, 11.0, 12.0, 7.0, 8.0, 7.0, -10.0, 10.0, 1.0, 13.0, 5.0, -4.0, -8.0, 7.0, 6.0, 10.0, 3.0, 13.0, -9.0, 8.0, 5.0, 10.0, 8.0, -7.0, -3.0, 13.0, -7.0, 12.0, 9.0, 11.0, 2.0, -7.0, 4.0, -5.0, 7.0, 9.0, -12.0, 3.0, 12.0, 12.0, 3.0, 10.0, 6.0, -4.0, 5.0, -6.0, 4.0, 12.0, -1.0, -2.0, 12.0, 6.0, 13.0, 5.0, 5.0, -8.0, -2.0, 11.0, -3.0, 9.0, 7.0, 13.0, -11.0, 6.0, -7.0, 13.0, 12.0, -3.0, -11.0, 5.0, 11.0, 11.0, -8.0, 5.0, 11.0, 7.0, 3.0, 0.0, -1.0, 13.0, -14.0, 12.0, 12.0, 5.0, 0.0, 13.0, -10.0, 13.0, 5.0, 13.0, -6.0, 3.0, 4.0, 6.0, -7.0, 12.0, -16.0, 13.0, 9.0, 9.0, -14.0, 7.0, 10.0, 12.0, -18.0, 11.0, 12.0, 10.0, 7.0, 14.0, -3.0, -3.0, 0.0, 11.0, -2.0, 6.0, 2.0, 12.0, 9.0, -8.0, -2.0, 12.0, -4.0, 9.0, 3.0, -2.0, 3.0, 11.0, -2.0, 12.0, -7.0, 12.0, 14.0, 8.0, -16.0, 9.0, -7.0, 14.0, 8.0, 0.0, 5.0, 13.0, 5.0, -8.0, -17.0, 13.0, 12.0, 7.0, 7.0, -9.0, 8.0, 9.0, -13.0, 11.0, 7.0, 10.0, 5.0, -1.0, -2.0, 13.0, 319.0, 11.0, 12.0, 12.0, 13.0, 7.0, -14.0, 9.0, -2.0, -7.0, 12.0, 12.0, 10.0, -7.0, 0.0, 12.0, 4.0, -5.0, 3.0, 13.0, 7.0, 5.0, -5.0, 9.0, 7.0, 12.0, -3.0, -1.0, -3.0, 13.0, -6.0, 11.0, 12.0, -4.0, 3.0, 4.0, 9.0, 3.0, -2.0, 5.0, 3.0, 12.0, -4.0, 4.0, -10.0, 13.0, 1.0, 11.0, -10.0, 10.0, 3.0, 12.0, 2.0, 10.0, -8.0, 11.0, -1.0, 9.0, -2.0, 9.0, 7.0, 12.0, -14.0, 10.0, 2.0, 12.0, -9.0, 10.0, -3.0, -4.0, 10.0, 13.0, -8.0, 10.0, 6.0, 7.0, 4.0, -6.0, 7.0, 10.0, 5.0, 12.0, -7.0, 5.0, 12.0, 4.0, -4.0, 4.0, -7.0, 12.0, 6.0, 4.0, -8.0, 6.0, 6.0, 11.0, 2.0, 12.0, 8.0, -7.0, 13.0, 2.0, 7.0, -7.0, -10.0, 8.0, 9.0, 8.0, -10.0, 14.0, 1.0, 10.0, -16.0, 12.0, 9.0, 10.0, 7.0, 12.0, -15.0, 11.0, -16.0, 10.0, 10.0, 11.0, -8.0, 11.0, 0.0, 12.0, -10.0, 9.0, 9.0, 7.0, 3.0, 7.0, 8.0, -2.0, 7.0, 12.0, -12.0, 8.0, -5.0, 8.0, 2.0, 10.0, -8.0, 6.0, 7.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18434479806583728, "mean_inference_ms": 1.063600959119762, "mean_action_processing_ms": 0.0710528026634478, "mean_env_wait_ms": 0.17461446669656122, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 468180, "agent_timesteps_total": 468180, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68014694.53, "learn_time_ms": 13.887, "learn_throughput": 396621.087, "update_time_ms": 6.008}, "info": {"learner": {"learned": {"policy_loss": 128615161856.0, "vf_loss": 130.8702392578125, "total_loss": 128615161856.0, "vf_explained_var": -0.0010377168655395508, "model": {}}}, "num_steps_sampled": 468180, "num_agent_steps_sampled": 468180, "num_steps_trained": 468180, "num_agent_steps_trained": 468180}, "done": false, "episodes_total": 9180, "training_iteration": 85, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-58", "timestamp": 1626864478, "time_this_iter_s": 0.35089588165283203, "time_total_s": 31.088172435760498, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1a45e2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 31.088172435760498, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 75.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 9.0, -1.0, 13.0, 1.0, 3.0, -2.0, 13.0, -8.0, 14.0, 1.0, 8.0, -9.0, 6.0, 5.0, 13.0, 10.0, -10.0, 7.0, 8.0, 7.0, -11.0, 9.0, 10.0, 9.0, 12.0, 4.0, -10.0, -6.0, 10.0, 9.0, 2.0, 9.0, -8.0, 2.0, 12.0, -11.0, 5.0, 13.0, 8.0, 8.0, 13.0, -10.0, 4.0, 1.0, -5.0, 9.0, 10.0, 13.0, -16.0, 6.0, 12.0, 2.0, -9.0, 13.0, 9.0, -2.0, 12.0, 3.0, 2.0, 7.0, 9.0, 10.0, -11.0, -1.0, 1.0, 2.0, 13.0, 3.0, -9.0, 13.0, 8.0, -5.0, 6.0, 7.0, 7.0, 12.0, -6.0, 8.0, 1.0, 12.0, -16.0, 10.0, 9.0, 6.0, 3.0, 13.0, -7.0, -10.0, 13.0, 5.0, 7.0, -3.0, 4.0, 13.0, 1.0, 13.0, -7.0, -3.0, 12.0, 7.0, 0.0, 13.0, -5.0, 8.0, 13.0, 2.0, -8.0, -10.0, 5.0, 12.0, 8.0, 12.0, -8.0, -1.0, 12.0, -10.0, 5.0, 13.0, 7.0, -6.0, 14.0, 0.0, 7.0, -8.0, 10.0, 13.0, 0.0, -2.0, -3.0, 7.0, 13.0, 8.0, -3.0, 13.0, -3.0, 13.0, -4.0, 3.0, 3.0, 12.0, -10.0, 9.0, 4.0, -1.0, -4.0, 7.0, 13.0, 5.0, 2.0, 12.0, -4.0, 0.0, 12.0, 8.0, -5.0, 4.0, 8.0, 13.0, -10.0, 11.0, -10.0, 1.0, 13.0, 5.0, -12.0, 13.0, 9.0, -13.0, 14.0, 1.0, 13.0, 7.0, -3.0, 13.0, -2.0, 12.0, -12.0, 2.0, 13.0, 7.0, -7.0, 8.0, 7.0, -14.0, 14.0, 6.0, 9.0, -8.0, 9.0, 13.0, 1.0, 11.0, -17.0, 8.0, 13.0, 10.0, -3.0, -4.0, 12.0, -7.0, 14.0, 1.0, 7.0, 10.0, -4.0, 11.0, -2.0, -4.0, 2.0, 5.0, 12.0, 11.0, -13.0, 12.0, 5.0, -11.0, 13.0, 11.0, 2.0, 6.0, 8.0, 12.0, -11.0, 12.0, -5.0, -1.0, 9.0, 7.0, 1.0, 9.0, -2.0, -8.0, 13.0, 8.0, 2.0, 7.0, 10.0, -15.0, 13.0, 14.0, -6.0, -4.0, 11.0, 10.0, 2.0, 12.0, -9.0, 13.0, 12.0, 4.0, -14.0, -9.0, 13.0, 13.0, -2.0, -4.0, 4.0, 2.0, 13.0, -7.0, -3.0, 13.0, 12.0, -5.0, 14.0, 1.0, 5.0, -6.0, 8.0, 13.0, 0.0, 12.0, -9.0, 4.0, 8.0, -9.0, 3.0, 13.0, 8.0, 11.0, 11.0, -8.0, 1.0, 11.0, -7.0, 10.0, 1.0, 0.0, 7.0, -4.0, 12.0, -4.0, -5.0, 13.0, 11.0, -10.0, 12.0, 1.0, 12.0, -13.0, 10.0, 13.0, 5.0, 11.0, -12.0, 4.0, 12.0, -9.0, 5.0, 10.0, 9.0, -6.0, 12.0, -4.0, 13.0, 4.0, -6.0, 10.0, 7.0, 14.0, -7.0, 0.0, 8.0, 3.0, 5.0, 12.0, -5.0, 10.0, 12.0, 0.0, -7.0, 7.0, 9.0, -13.0, 12.0, -1.0, 9.0, 0.0, 7.0, -12.0, 4.0, 11.0, 12.0, 10.0, 14.0, 1.0, -10.0, -10.0, 8.0, 9.0, 8.0, 13.0, -13.0, 2.0, 13.0, 2.0, -8.0, 8.0, 13.0, -13.0, 14.0, 2.0, 12.0, 8.0, -5.0, 3.0, 9.0, 13.0, -17.0, 7.0, 12.0, 9.0, -15.0, 13.0, 8.0, -2.0, 14.0, 4.0, -1.0, 7.0, -3.0, 8.0, 3.0, 13.0, -16.0, 13.0, 5.0, 2.0, 4.0, 13.0, -4.0, 7.0, 14.0, -11.0, 5.0, 3.0, -8.0, 11.0, 9.0, 11.0, -14.0, 5.0, 13.0, 10.0, -2.0, 13.0, -6.0, 13.0, -10.0, 7.0, 5.0, 6.0, -6.0, 11.0, 4.0, -1.0, 7.0, -2.0, 11.0, 11.0, 2.0, 9.0, -7.0, 7.0, 13.0, 6.0, -11.0, -8.0, 8.0, 11.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18432694805716163, "mean_inference_ms": 1.0635472609278769, "mean_action_processing_ms": 0.07103427588891226, "mean_env_wait_ms": 0.174606911252266, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 473688, "agent_timesteps_total": 473688, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66366723.231, "learn_time_ms": 13.683, "learn_throughput": 402532.512, "update_time_ms": 5.846}, "info": {"learner": {"learned": {"policy_loss": 115767107584.0, "vf_loss": 126.46160888671875, "total_loss": 115767107584.0, "vf_explained_var": -0.0006670951843261719, "model": {}}}, "num_steps_sampled": 473688, "num_agent_steps_sampled": 473688, "num_steps_trained": 473688, "num_agent_steps_trained": 473688}, "done": false, "episodes_total": 9288, "training_iteration": 86, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-58", "timestamp": 1626864478, "time_this_iter_s": 0.34484410285949707, "time_total_s": 31.433016538619995, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18286620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 31.433016538619995, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 368.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.546296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 333.0}, "policy_reward_mean": {"learned": 6.136574074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 368.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [2.0, -3.0, 4.0, 12.0, 13.0, 13.0, -18.0, 7.0, -1.0, 10.0, -4.0, 10.0, 7.0, 13.0, 5.0, -10.0, 7.0, -3.0, -1.0, 12.0, 7.0, 14.0, -16.0, 10.0, -3.0, 10.0, -2.0, 10.0, 13.0, 12.0, -8.0, -2.0, -9.0, 10.0, 2.0, 12.0, 3.0, 7.0, 7.0, -2.0, 4.0, -7.0, 11.0, 7.0, 11.0, 14.0, -4.0, -6.0, -10.0, 9.0, 10.0, 6.0, 11.0, 8.0, -3.0, -1.0, 14.0, 6.0, -16.0, 11.0, 8.0, 14.0, 4.0, -11.0, -9.0, 10.0, 8.0, 6.0, 2.0, 12.0, 4.0, -3.0, 2.0, -7.0, 8.0, 12.0, 8.0, 13.0, 3.0, -9.0, 8.0, -10.0, 6.0, 11.0, 8.0, 7.0, 8.0, -8.0, 4.0, -7.0, 5.0, 13.0, 10.0, 14.0, 0.0, -9.0, 8.0, -5.0, 0.0, 12.0, 3.0, 4.0, 11.0, -3.0, -16.0, 10.0, 11.0, 10.0, 11.0, 13.0, -11.0, 2.0, 3.0, 8.0, 6.0, -2.0, 2.0, 7.0, -7.0, 13.0, 321.0, 12.0, 12.0, 11.0, 7.0, 14.0, 6.0, -12.0, 3.0, -4.0, 12.0, 4.0, 7.0, 12.0, 5.0, -9.0, -10.0, 10.0, 11.0, 4.0, 8.0, 12.0, 4.0, -9.0, 2.0, -4.0, 6.0, 11.0, 0.0, 13.0, -4.0, 6.0, 8.0, 6.0, -12.0, 13.0, 11.0, 6.0, -14.0, 12.0, 8.0, -9.0, 7.0, 9.0, 7.0, 4.0, -5.0, 9.0, 6.0, 9.0, 12.0, -12.0, 13.0, 13.0, 316.0, 10.0, 1.0, -2.0, 10.0, 6.0, 4.0, 14.0, 12.0, -15.0, 14.0, 1.0, -12.0, 12.0, 10.0, 8.0, 5.0, -8.0, 3.0, -4.0, 6.0, 10.0, -3.0, 13.0, -6.0, 11.0, -6.0, 4.0, 9.0, 8.0, 9.0, 13.0, -8.0, 1.0, 4.0, 10.0, 12.0, -11.0, -16.0, 12.0, 6.0, 13.0, -1.0, 7.0, -2.0, 11.0, 8.0, 13.0, -6.0, 0.0, 8.0, 8.0, 11.0, -12.0, -18.0, 13.0, 9.0, 11.0, -6.0, 7.0, 4.0, 10.0, 8.0, 13.0, -14.0, 8.0, 7.0, -7.0, 11.0, 4.0, 4.0, 8.0, 7.0, -4.0, -3.0, -4.0, 12.0, 10.0, 11.0, 13.0, 5.0, -14.0, -3.0, -1.0, 11.0, 8.0, 0.0, 13.0, 4.0, -2.0, -6.0, 2.0, 8.0, 11.0, 14.0, 13.0, -16.0, 4.0, -7.0, 5.0, 12.0, 5.0, -14.0, 9.0, 10.0, 10.0, 4.0, 3.0, -5.0, 13.0, 11.0, 12.0, 5.0, -13.0, -12.0, 11.0, 10.0, 6.0, 11.0, 14.0, -18.0, 8.0, 12.0, 2.0, -8.0, 9.0, 8.0, 13.0, -15.0, 9.0, -8.0, 4.0, 7.0, 12.0, -14.0, 9.0, 10.0, 10.0, -15.0, 7.0, 12.0, 11.0, 12.0, 7.0, 0.0, -4.0, 7.0, 10.0, -7.0, 5.0, 5.0, 13.0, 8.0, -11.0, -11.0, 6.0, 11.0, 9.0, -11.0, 12.0, 9.0, 5.0, 6.0, 5.0, 6.0, -2.0, 8.0, 6.0, 9.0, -8.0, 10.0, 2.0, -10.0, 13.0, 12.0, 11.0, -3.0, -5.0, 8.0, -6.0, 6.0, 7.0, -4.0, -3.0, 11.0, 11.0, 9.0, 11.0, 12.0, -17.0, 11.0, 12.0, -3.0, -5.0, 1.0, -5.0, 12.0, 7.0, 6.0, 7.0, 8.0, -6.0, 333.0, 11.0, 12.0, 12.0, 12.0, 9.0, -16.0, 10.0, 2.0, 10.0, 13.0, -10.0, 1.0, 13.0, 10.0, -9.0, -6.0, 4.0, 6.0, 11.0, 7.0, 13.0, -3.0, -2.0, 2.0, -3.0, 6.0, 10.0, 7.0, 10.0, 8.0, -10.0, 3.0, -9.0, 10.0, 11.0, -4.0, 13.0, 1.0, 5.0, 4.0, 11.0, 10.0, -10.0, -13.0, 11.0, 11.0, 6.0, -4.0, 9.0, -2.0, 12.0, 10.0, 12.0, 10.0, -17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18430781036631108, "mean_inference_ms": 1.0633965800341, "mean_action_processing_ms": 0.07102422819924575, "mean_env_wait_ms": 0.17459748322497398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 479196, "agent_timesteps_total": 479196, "timers": {"sample_time_ms": 0.082, "sample_throughput": 66795698.322, "learn_time_ms": 13.747, "learn_throughput": 400670.606, "update_time_ms": 5.516}, "info": {"learner": {"learned": {"policy_loss": 1.2094628810882568, "vf_loss": 16.108034133911133, "total_loss": 17.31749725341797, "vf_explained_var": -0.007319331169128418, "model": {}}}, "num_steps_sampled": 479196, "num_agent_steps_sampled": 479196, "num_steps_trained": 479196, "num_agent_steps_trained": 479196}, "done": false, "episodes_total": 9396, "training_iteration": 87, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-59", "timestamp": 1626864479, "time_this_iter_s": 0.35329437255859375, "time_total_s": 31.78631091117859, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 31.78631091117859, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 79.6, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 11.0, -8.0, 5.0, -10.0, 9.0, 5.0, 11.0, 0.0, 8.0, -4.0, 11.0, 9.0, 6.0, -2.0, 2.0, -1.0, 9.0, 8.0, -1.0, 10.0, 8.0, -8.0, 5.0, 5.0, 12.0, -10.0, 8.0, 12.0, -19.0, 10.0, 12.0, 7.0, -6.0, 3.0, 11.0, 6.0, -11.0, 8.0, 12.0, -3.0, -2.0, 9.0, 11.0, 13.0, 10.0, -5.0, -3.0, 3.0, 6.0, -7.0, 13.0, 12.0, -2.0, -1.0, 6.0, -13.0, 9.0, 6.0, 13.0, 13.0, -4.0, 7.0, -1.0, 10.0, 11.0, 4.0, -10.0, 7.0, 8.0, -7.0, 7.0, 11.0, -3.0, -6.0, 13.0, 13.0, 10.0, 5.0, -13.0, 2.0, 12.0, 4.0, -3.0, 4.0, -1.0, 2.0, 10.0, 0.0, 8.0, -2.0, 9.0, 12.0, 1.0, -5.0, 7.0, 4.0, 11.0, -8.0, 8.0, 7.0, -1.0, 12.0, -3.0, 5.0, -8.0, 10.0, 8.0, 2.0, -3.0, 9.0, 7.0, 11.0, 8.0, -10.0, 6.0, 6.0, 5.0, -6.0, 10.0, 5.0, -8.0, 10.0, 8.0, 10.0, 7.0, -4.0, 2.0, 7.0, 12.0, -9.0, 5.0, 5.0, 9.0, -10.0, 11.0, -7.0, 6.0, 10.0, 6.0, 9.0, -8.0, 10.0, 4.0, 7.0, 10.0, 2.0, -4.0, 4.0, 6.0, -4.0, 9.0, -7.0, 2.0, 12.0, 8.0, 13.0, -15.0, 10.0, 7.0, 2.0, 11.0, 4.0, -2.0, 5.0, 4.0, -6.0, 12.0, 7.0, -10.0, 12.0, 6.0, 11.0, 7.0, -11.0, 8.0, 1.0, 10.0, 5.0, -1.0, -5.0, 1.0, 8.0, 11.0, -7.0, 1.0, 11.0, 10.0, 11.0, 7.0, -2.0, -1.0, 7.0, 11.0, -15.0, 12.0, 1.0, -6.0, 10.0, 10.0, 2.0, -6.0, 7.0, 12.0, 9.0, 6.0, -7.0, 7.0, 3.0, 9.0, -9.0, 12.0, 3.0, 11.0, 10.0, -9.0, 6.0, 13.0, -11.0, 7.0, 8.0, 11.0, -2.0, -2.0, 12.0, 13.0, -11.0, 1.0, 9.0, 12.0, 0.0, -6.0, 9.0, 6.0, 8.0, -8.0, 8.0, 11.0, -4.0, 0.0, -2.0, 11.0, -6.0, 12.0, 3.0, -4.0, 10.0, 6.0, 0.0, 2.0, 8.0, 5.0, 8.0, -13.0, 8.0, 12.0, -3.0, 12.0, -6.0, 12.0, 5.0, 7.0, 10.0, -7.0, -11.0, 10.0, 7.0, 9.0, 10.0, 1.0, -2.0, 6.0, 0.0, 10.0, -2.0, 7.0, 3.0, 7.0, -6.0, 11.0, -7.0, 8.0, 8.0, 6.0, 13.0, -10.0, 6.0, 6.0, -3.0, -2.0, 8.0, 12.0, 1.0, 8.0, 10.0, -4.0, -6.0, 5.0, 8.0, 8.0, 12.0, -18.0, 10.0, 11.0, 12.0, -4.0, -5.0, 12.0, 13.0, 12.0, -3.0, -7.0, 7.0, 7.0, 4.0, -3.0, 12.0, 6.0, 9.0, -12.0, -1.0, 10.0, -6.0, 12.0, -15.0, 11.0, 8.0, 11.0, 6.0, 10.0, -14.0, 13.0, 12.0, 5.0, -5.0, 3.0, 7.0, 8.0, 5.0, -5.0, -11.0, 9.0, 11.0, 6.0, -6.0, 12.0, 2.0, 7.0, 12.0, -7.0, 9.0, 1.0, -4.0, 10.0, 10.0, -1.0, -13.0, 14.0, 10.0, 4.0, 3.0, 7.0, 12.0, -7.0, 7.0, 5.0, -3.0, 6.0, 2.0, -1.0, 3.0, 11.0, 9.0, -5.0, 9.0, 2.0, 13.0, -8.0, 1.0, 9.0, 8.0, 8.0, 10.0, -11.0, 2.0, 9.0, -9.0, 13.0, 9.0, 7.0, -8.0, 7.0, 10.0, 9.0, 1.0, -5.0, 7.0, -8.0, 11.0, 5.0, 7.0, -1.0, -2.0, 11.0, -10.0, 9.0, 10.0, 6.0, 12.0, -3.0, -7.0, 13.0, 13.0, 0.0, -7.0, 9.0, 0.0, 9.0, 12.0, -6.0, -11.0, 13.0, 9.0, 4.0, 6.0, -9.0, 9.0, 9.0, 8.0, -7.0, 8.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18427580924745454, "mean_inference_ms": 1.0631982726414275, "mean_action_processing_ms": 0.07101372123665425, "mean_env_wait_ms": 0.17455830648374995, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 484704, "agent_timesteps_total": 484704, "timers": {"sample_time_ms": 0.082, "sample_throughput": 66871684.789, "learn_time_ms": 13.702, "learn_throughput": 401996.677, "update_time_ms": 5.596}, "info": {"learner": {"learned": {"policy_loss": 110910742528.0, "vf_loss": 132.14361572265625, "total_loss": 110910742528.0, "vf_explained_var": -0.0005713701248168945, "model": {}}}, "num_steps_sampled": 484704, "num_agent_steps_sampled": 484704, "num_steps_trained": 484704, "num_agent_steps_trained": 484704}, "done": false, "episodes_total": 9504, "training_iteration": 88, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-59", "timestamp": 1626864479, "time_this_iter_s": 0.3473663330078125, "time_total_s": 32.1336772441864, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 32.1336772441864, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 12.0, 4.0, -5.0, 1.0, 13.0, 7.0, -6.0, 10.0, -7.0, 4.0, 8.0, 5.0, 12.0, -2.0, 0.0, 7.0, 14.0, 2.0, -8.0, 3.0, 8.0, 5.0, -1.0, -8.0, 9.0, 8.0, 6.0, -8.0, 13.0, -2.0, 12.0, -9.0, 9.0, 5.0, 10.0, 4.0, 13.0, 10.0, -12.0, -3.0, 0.0, 5.0, 13.0, 10.0, 13.0, 4.0, -12.0, 5.0, 12.0, 9.0, -11.0, 0.0, 14.0, 5.0, -4.0, 10.0, -2.0, 8.0, -1.0, 7.0, 13.0, -15.0, 10.0, 5.0, 13.0, -8.0, 5.0, 1.0, 13.0, -2.0, 3.0, 5.0, 0.0, 8.0, 2.0, 11.0, 14.0, 5.0, -15.0, 8.0, 10.0, -13.0, 10.0, 5.0, -3.0, 6.0, 7.0, -3.0, 13.0, -3.0, 8.0, 4.0, 12.0, 11.0, -12.0, 8.0, 11.0, -9.0, 5.0, -11.0, 13.0, 6.0, 7.0, 11.0, -1.0, 3.0, 2.0, 7.0, 12.0, -14.0, 10.0, 5.0, 13.0, -8.0, 5.0, 7.0, 11.0, 5.0, -8.0, 10.0, 6.0, -5.0, 4.0, 5.0, 11.0, -12.0, 11.0, 7.0, 9.0, -12.0, 11.0, 4.0, 14.0, 5.0, -8.0, 11.0, 10.0, -2.0, -4.0, 8.0, 7.0, 5.0, -5.0, 7.0, 12.0, -9.0, 5.0, 5.0, 13.0, -9.0, 6.0, 9.0, -10.0, 12.0, 4.0, 12.0, 13.0, 6.0, -16.0, -8.0, 13.0, 5.0, 5.0, 8.0, 11.0, 6.0, -10.0, -7.0, 13.0, 1.0, 8.0, 3.0, 12.0, 11.0, -11.0, -11.0, 8.0, 11.0, 7.0, 1.0, 13.0, -2.0, 3.0, 8.0, -12.0, 7.0, 12.0, 4.0, 13.0, -14.0, 12.0, 8.0, 13.0, -15.0, 9.0, 8.0, 14.0, 2.0, -9.0, 11.0, -1.0, 1.0, 4.0, 13.0, 10.0, 9.0, -17.0, 12.0, 11.0, 2.0, -10.0, 3.0, 13.0, -5.0, 4.0, 9.0, 8.0, 8.0, -10.0, 4.0, -4.0, 5.0, 10.0, -4.0, 10.0, -3.0, 12.0, 12.0, 10.0, 0.0, -7.0, -3.0, 8.0, 2.0, 8.0, 14.0, 11.0, -2.0, -8.0, -9.0, 14.0, 2.0, 8.0, 6.0, 12.0, -9.0, 6.0, 11.0, -2.0, -1.0, 7.0, 10.0, 14.0, -10.0, 1.0, -11.0, 13.0, 9.0, 4.0, 10.0, 11.0, -9.0, 3.0, 13.0, -9.0, 4.0, 7.0, 8.0, 14.0, 6.0, -13.0, -1.0, 9.0, 0.0, 7.0, 3.0, 14.0, 4.0, -6.0, -10.0, 12.0, 5.0, 8.0, 6.0, 14.0, 5.0, -10.0, -16.0, 10.0, 11.0, 10.0, 3.0, 14.0, 11.0, -13.0, 11.0, -7.0, 7.0, 4.0, -8.0, 14.0, 10.0, -1.0, -11.0, 13.0, 2.0, 11.0, 5.0, 12.0, -14.0, 12.0, 11.0, -7.0, 11.0, 0.0, 12.0, 8.0, 12.0, -17.0, 7.0, 13.0, 4.0, -9.0, 9.0, 11.0, 4.0, -9.0, -2.0, 12.0, -1.0, 6.0, 13.0, 12.0, -14.0, 4.0, 7.0, 13.0, -8.0, 3.0, 8.0, 14.0, 7.0, -14.0, 12.0, -12.0, 10.0, 5.0, 11.0, 13.0, 0.0, -9.0, 9.0, 13.0, 2.0, -9.0, 8.0, 9.0, 6.0, -8.0, -9.0, 13.0, 3.0, 8.0, 6.0, 14.0, 10.0, -15.0, 8.0, 13.0, -13.0, 7.0, 14.0, 14.0, -18.0, 5.0, 13.0, -1.0, -1.0, 4.0, 8.0, 14.0, 5.0, -12.0, 2.0, -3.0, 7.0, 9.0, 10.0, 14.0, -12.0, 3.0, 8.0, -4.0, 9.0, 2.0, 4.0, 13.0, -3.0, 1.0, -1.0, 10.0, 0.0, 6.0, -2.0, 14.0, 8.0, -5.0, 7.0, -1.0, 3.0, 6.0, 1.0, 11.0, 9.0, -6.0, 8.0, 8.0, -5.0, 4.0, 7.0, -3.0, 6.0, 5.0, -5.0, 9.0, 9.0, 2.0, 12.0, 13.0, -14.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18430912806324856, "mean_inference_ms": 1.0633917647909152, "mean_action_processing_ms": 0.07101549388134158, "mean_env_wait_ms": 0.17455848130917212, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 490212, "agent_timesteps_total": 490212, "timers": {"sample_time_ms": 0.085, "sample_throughput": 64590650.314, "learn_time_ms": 14.232, "learn_throughput": 387012.159, "update_time_ms": 5.287}, "info": {"learner": {"learned": {"policy_loss": 247537647616.0, "vf_loss": 232.68563842773438, "total_loss": 247537647616.0, "vf_explained_var": -0.0007585287094116211, "model": {}}}, "num_steps_sampled": 490212, "num_agent_steps_sampled": 490212, "num_steps_trained": 490212, "num_agent_steps_trained": 490212}, "done": false, "episodes_total": 9612, "training_iteration": 89, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-47-59", "timestamp": 1626864479, "time_this_iter_s": 0.37318897247314453, "time_total_s": 32.506866216659546, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 32.506866216659546, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 73.8, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.87037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 330.0}, "policy_reward_mean": {"learned": 7.717592592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [320.0, 13.0, 11.0, 11.0, 8.0, -7.0, 1.0, 13.0, -17.0, 13.0, 8.0, 11.0, 13.0, 319.0, 11.0, 12.0, 2.0, 12.0, -3.0, 4.0, 7.0, 8.0, 6.0, -6.0, -14.0, 7.0, 13.0, 9.0, 0.0, -2.0, 6.0, 11.0, 6.0, 13.0, -3.0, -1.0, -10.0, 12.0, 5.0, 8.0, -10.0, 9.0, 13.0, 3.0, 14.0, -20.0, 9.0, 12.0, -4.0, 11.0, -1.0, 9.0, -11.0, 12.0, 1.0, 13.0, -12.0, 14.0, 13.0, 0.0, 9.0, -16.0, 10.0, 12.0, 12.0, 11.0, -3.0, -5.0, 11.0, 14.0, -14.0, 4.0, 6.0, 14.0, -18.0, 13.0, -1.0, 2.0, 6.0, 8.0, 13.0, 8.0, -2.0, -4.0, -15.0, 12.0, 9.0, 9.0, -4.0, 14.0, -8.0, 13.0, 13.0, -20.0, 10.0, 12.0, -1.0, 8.0, 0.0, 8.0, -13.0, 12.0, 10.0, 6.0, -14.0, 6.0, 10.0, 13.0, 9.0, -12.0, 6.0, 12.0, 5.0, 14.0, 1.0, -5.0, -2.0, 1.0, 13.0, 3.0, -15.0, 9.0, 8.0, 13.0, -1.0, 2.0, 3.0, 11.0, 0.0, 7.0, 11.0, -3.0, 6.0, -5.0, 7.0, 7.0, 5.0, 9.0, 13.0, -12.0, -3.0, 0.0, 10.0, 8.0, -5.0, 6.0, 5.0, 9.0, 5.0, -5.0, 6.0, 9.0, -17.0, 14.0, 10.0, 8.0, 0.0, -8.0, 11.0, 12.0, 6.0, 10.0, -9.0, 8.0, -10.0, 12.0, 12.0, 1.0, -10.0, 1.0, 11.0, 13.0, 14.0, -21.0, 10.0, 12.0, 2.0, 9.0, 10.0, -6.0, 12.0, 11.0, -13.0, 5.0, -17.0, 13.0, 13.0, 6.0, 0.0, -6.0, 9.0, 12.0, -1.0, 14.0, 2.0, 0.0, -13.0, 10.0, 13.0, 5.0, -15.0, 7.0, 11.0, 12.0, -6.0, -3.0, 12.0, 12.0, 8.0, -7.0, 10.0, 4.0, -8.0, 11.0, 12.0, 0.0, 2.0, 5.0, -4.0, 12.0, 8.0, -2.0, -3.0, 12.0, -17.0, 13.0, 12.0, 7.0, -11.0, 11.0, 12.0, 3.0, -15.0, 9.0, 13.0, 8.0, -3.0, 0.0, 11.0, 7.0, -7.0, 13.0, 8.0, 1.0, -6.0, 6.0, 8.0, 7.0, -1.0, 6.0, -3.0, 13.0, -4.0, -3.0, 11.0, 11.0, -8.0, 9.0, 10.0, 4.0, -11.0, 11.0, 12.0, 3.0, -4.0, 12.0, -6.0, 13.0, 13.0, 321.0, 11.0, 12.0, -8.0, 13.0, 11.0, -1.0, -1.0, 4.0, 12.0, 0.0, 5.0, 13.0, -16.0, 13.0, 13.0, -5.0, 12.0, -5.0, 9.0, 7.0, 9.0, -10.0, -2.0, 14.0, 4.0, -1.0, 7.0, 0.0, 13.0, -5.0, -1.0, -7.0, 11.0, 12.0, -11.0, 10.0, 6.0, 10.0, -12.0, 11.0, 4.0, 12.0, 4.0, 8.0, -8.0, 11.0, 13.0, 320.0, 10.0, 12.0, 12.0, 7.0, -8.0, 4.0, 11.0, 11.0, -12.0, 5.0, -10.0, 6.0, 11.0, 8.0, 0.0, -8.0, 12.0, 11.0, 0.0, 7.0, 8.0, 0.0, 6.0, -7.0, 12.0, 4.0, 6.0, 14.0, -18.0, 13.0, 0.0, -7.0, 11.0, 11.0, 9.0, 11.0, 7.0, -12.0, -5.0, 9.0, 8.0, 3.0, -12.0, 8.0, 11.0, 8.0, 12.0, 0.0, 10.0, -7.0, -17.0, 13.0, 8.0, 11.0, -1.0, 13.0, 3.0, 0.0, -15.0, 6.0, 13.0, 11.0, -1.0, -1.0, 12.0, 5.0, 13.0, 10.0, -5.0, -3.0, 6.0, -7.0, 6.0, 10.0, 3.0, 9.0, 13.0, -10.0, 13.0, 330.0, 12.0, 12.0, 0.0, 9.0, -4.0, 10.0, -7.0, 7.0, 5.0, 10.0, -8.0, 8.0, 2.0, 13.0, 0.0, 1.0, 7.0, 7.0, 7.0, 14.0, 7.0, -13.0, 5.0, 11.0, 8.0, -9.0, -20.0, 13.0, 13.0, 9.0, 0.0, -8.0, 11.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18434646913054187, "mean_inference_ms": 1.0634991096672162, "mean_action_processing_ms": 0.0710158055131056, "mean_env_wait_ms": 0.17457634895488033, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 495720, "agent_timesteps_total": 495720, "timers": {"sample_time_ms": 0.087, "sample_throughput": 63366938.167, "learn_time_ms": 14.389, "learn_throughput": 382798.375, "update_time_ms": 5.208}, "info": {"learner": {"learned": {"policy_loss": 1.278053879737854, "vf_loss": 20.086423873901367, "total_loss": 21.364477157592773, "vf_explained_var": -0.0054732561111450195, "model": {}}}, "num_steps_sampled": 495720, "num_agent_steps_sampled": 495720, "num_steps_trained": 495720, "num_agent_steps_trained": 495720}, "done": false, "episodes_total": 9720, "training_iteration": 90, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-00", "timestamp": 1626864480, "time_this_iter_s": 0.35954976081848145, "time_total_s": 32.86641597747803, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 32.86641597747803, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 79.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -12.0, 10.0, 10.0, -1.0, -3.0, 8.0, 11.0, 11.0, 9.0, -2.0, -3.0, 5.0, 11.0, -13.0, 12.0, 9.0, 2.0, 10.0, -6.0, -4.0, -3.0, 10.0, 12.0, -1.0, 8.0, 12.0, -4.0, 10.0, -4.0, 5.0, 4.0, -7.0, 6.0, 10.0, 6.0, -3.0, 11.0, 3.0, 4.0, -5.0, 7.0, 7.0, 6.0, 7.0, -2.0, 2.0, 8.0, 9.0, -13.0, 10.0, 9.0, 5.0, -9.0, 6.0, 13.0, 4.0, 9.0, -6.0, 8.0, 13.0, 11.0, -19.0, 10.0, -8.0, 7.0, 4.0, 12.0, -17.0, 10.0, 10.0, 12.0, -7.0, 4.0, 6.0, 12.0, 6.0, 0.0, 2.0, 7.0, 4.0, -7.0, 9.0, 9.0, -5.0, 10.0, 6.0, 4.0, 2.0, 10.0, 5.0, -2.0, 4.0, 9.0, -9.0, 11.0, 4.0, -7.0, 7.0, 11.0, -10.0, 12.0, 1.0, 12.0, 0.0, 11.0, 11.0, -7.0, 9.0, -4.0, 0.0, 10.0, 0.0, 6.0, 8.0, 1.0, 5.0, -3.0, 4.0, 9.0, -19.0, 13.0, 10.0, 11.0, 8.0, -4.0, 4.0, 7.0, -6.0, 8.0, 6.0, 7.0, 0.0, -3.0, 6.0, 12.0, 0.0, 14.0, -8.0, 9.0, 1.0, -2.0, 10.0, 6.0, 8.0, 4.0, 12.0, -9.0, 1.0, -2.0, 4.0, 12.0, 7.0, 4.0, 8.0, -4.0, 8.0, -2.0, -3.0, 12.0, 4.0, -7.0, 9.0, 9.0, -1.0, -3.0, 7.0, 12.0, 7.0, 14.0, -3.0, -3.0, 2.0, -3.0, 10.0, 6.0, 14.0, -7.0, 2.0, 6.0, 2.0, -2.0, 6.0, 9.0, -13.0, 12.0, 12.0, 4.0, 13.0, 7.0, -10.0, 5.0, 6.0, 8.0, 7.0, -6.0, -12.0, 9.0, 6.0, 12.0, 4.0, 11.0, -8.0, 8.0, 13.0, -3.0, 2.0, 3.0, 2.0, 7.0, 11.0, -5.0, 0.0, -2.0, 7.0, 10.0, -15.0, 11.0, 7.0, 12.0, 10.0, -6.0, 3.0, 8.0, -7.0, 11.0, 1.0, 10.0, -14.0, 11.0, 5.0, 13.0, -2.0, 8.0, 7.0, 2.0, 14.0, -7.0, 0.0, 8.0, -3.0, 7.0, 1.0, 10.0, -9.0, 13.0, 6.0, 5.0, -2.0, 11.0, 12.0, -6.0, 8.0, 0.0, -3.0, 10.0, -7.0, 11.0, -2.0, 13.0, -14.0, 8.0, 11.0, 10.0, 0.0, 10.0, 11.0, -6.0, 3.0, 9.0, -4.0, 7.0, -4.0, 1.0, 8.0, 10.0, -18.0, 13.0, 9.0, 11.0, 2.0, 10.0, -6.0, 9.0, 13.0, 9.0, -9.0, 2.0, -5.0, 5.0, 11.0, 4.0, -13.0, 9.0, 7.0, 12.0, -1.0, 12.0, 12.0, -8.0, 8.0, -5.0, 1.0, 11.0, -11.0, 6.0, 9.0, 11.0, -1.0, -3.0, 6.0, 13.0, 3.0, 14.0, 10.0, -12.0, 1.0, -2.0, 9.0, 7.0, -10.0, 6.0, 9.0, 10.0, -14.0, 11.0, 5.0, 13.0, 13.0, 8.0, 9.0, -15.0, -3.0, 0.0, 7.0, 11.0, -1.0, 2.0, 10.0, 4.0, 11.0, -3.0, 3.0, 4.0, -11.0, 13.0, 6.0, 7.0, 6.0, -2.0, -1.0, 12.0, 7.0, 6.0, 7.0, -5.0, -14.0, 12.0, 5.0, 12.0, 11.0, 7.0, 1.0, -4.0, 14.0, 8.0, -17.0, 10.0, 9.0, 8.0, -13.0, 11.0, 5.0, -2.0, 6.0, 6.0, 5.0, 14.0, 10.0, -14.0, 3.0, -2.0, 4.0, 10.0, -6.0, 8.0, 5.0, 8.0, 7.0, -4.0, 7.0, 5.0, -15.0, 12.0, 13.0, 5.0, 3.0, 6.0, -4.0, 10.0, -8.0, 3.0, 9.0, 11.0, -6.0, -2.0, 10.0, 13.0, 9.0, 4.0, 11.0, -9.0, 7.0, 11.0, -10.0, 7.0, 8.0, 1.0, 10.0, -4.0, -6.0, -1.0, 10.0, 12.0, -7.0, 6.0, 9.0, 7.0, 2.0, -1.0, 2.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18432873578260947, "mean_inference_ms": 1.0634159399928456, "mean_action_processing_ms": 0.07100400232050853, "mean_env_wait_ms": 0.17456617525722107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 501228, "agent_timesteps_total": 501228, "timers": {"sample_time_ms": 0.086, "sample_throughput": 63914075.691, "learn_time_ms": 14.552, "learn_throughput": 378507.847, "update_time_ms": 5.23}, "info": {"learner": {"learned": {"policy_loss": 1.289803385734558, "vf_loss": 21.257848739624023, "total_loss": 22.547651290893555, "vf_explained_var": -0.005807638168334961, "model": {}}}, "num_steps_sampled": 501228, "num_agent_steps_sampled": 501228, "num_steps_trained": 501228, "num_agent_steps_trained": 501228}, "done": false, "episodes_total": 9828, "training_iteration": 91, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-00", "timestamp": 1626864480, "time_this_iter_s": 0.3585987091064453, "time_total_s": 33.22501468658447, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a183469d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 33.22501468658447, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.212962962962962, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.5532407407407405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 12.0, 9.0, -10.0, 11.0, -10.0, 10.0, 4.0, 3.0, 12.0, -13.0, 13.0, 10.0, 3.0, -6.0, 8.0, 3.0, 10.0, 9.0, -7.0, 12.0, -13.0, 8.0, 8.0, 8.0, 12.0, -3.0, -2.0, 8.0, 11.0, 4.0, -7.0, 1.0, -7.0, 12.0, 9.0, -2.0, 3.0, 7.0, 7.0, -3.0, 13.0, -5.0, 10.0, 8.0, 3.0, 7.0, -3.0, 5.0, 12.0, 6.0, -8.0, 10.0, 11.0, -6.0, 0.0, -10.0, 11.0, 2.0, 12.0, -12.0, 7.0, 9.0, 11.0, 7.0, 13.0, 5.0, -10.0, -6.0, 7.0, 8.0, 6.0, 12.0, 12.0, -19.0, 10.0, 7.0, 13.0, -9.0, 4.0, 8.0, -2.0, 11.0, -2.0, 13.0, 6.0, -9.0, 5.0, 3.0, 12.0, -11.0, 11.0, 4.0, -8.0, 9.0, 10.0, 4.0, 11.0, 4.0, -4.0, 10.0, 6.0, 11.0, -12.0, 8.0, 13.0, -9.0, 3.0, -2.0, 12.0, -4.0, 9.0, 5.0, 7.0, 6.0, -3.0, 11.0, 9.0, -10.0, 5.0, 6.0, 12.0, -16.0, 13.0, 11.0, -8.0, 8.0, 4.0, 6.0, 11.0, -2.0, 0.0, 13.0, -7.0, 8.0, 1.0, 12.0, 11.0, -16.0, 8.0, 7.0, 2.0, 11.0, -4.0, 2.0, 9.0, -3.0, 7.0, 11.0, 4.0, 8.0, -8.0, 6.0, -6.0, 7.0, 8.0, 4.0, 8.0, -7.0, 10.0, 4.0, 12.0, 8.0, -9.0, 11.0, 6.0, -7.0, 5.0, 7.0, 12.0, -11.0, 7.0, 14.0, -19.0, 11.0, 9.0, 6.0, -1.0, 2.0, 8.0, -16.0, 10.0, 8.0, 13.0, 10.0, 12.0, -20.0, 13.0, 2.0, 12.0, -9.0, 10.0, 8.0, 13.0, 0.0, -6.0, 11.0, -10.0, 9.0, 5.0, 11.0, 11.0, 321.0, 13.0, 3.0, 13.0, 11.0, -12.0, 4.0, 13.0, -14.0, 12.0, -8.0, 6.0, 9.0, 8.0, 9.0, 14.0, 12.0, -20.0, 6.0, 4.0, -5.0, 10.0, 8.0, 12.0, 5.0, -10.0, -11.0, 12.0, 6.0, 8.0, 6.0, 12.0, -10.0, 7.0, 4.0, 13.0, -8.0, 6.0, 4.0, 5.0, -5.0, 11.0, 8.0, 11.0, -6.0, 2.0, 5.0, 12.0, 12.0, -14.0, 4.0, 13.0, 6.0, -7.0, 3.0, 14.0, 11.0, -13.0, -7.0, 5.0, 9.0, 8.0, 11.0, -2.0, -6.0, 12.0, 7.0, 7.0, -9.0, 11.0, 5.0, 11.0, 7.0, -8.0, -1.0, 6.0, 8.0, 2.0, 2.0, 12.0, -8.0, 9.0, 12.0, 7.0, -9.0, 6.0, 8.0, 13.0, 10.0, -16.0, 13.0, -10.0, 7.0, 5.0, 4.0, 13.0, 12.0, -14.0, 6.0, 13.0, -9.0, 5.0, 7.0, 9.0, -9.0, 8.0, 13.0, 6.0, -5.0, 1.0, 11.0, 12.0, -17.0, 9.0, 3.0, 13.0, -8.0, 7.0, 6.0, 3.0, -4.0, 10.0, 12.0, 6.0, -7.0, 4.0, 7.0, -2.0, 12.0, -2.0, 9.0, 6.0, 5.0, -4.0, 5.0, -1.0, 9.0, 2.0, 9.0, 7.0, 2.0, -3.0, 4.0, 11.0, 2.0, -2.0, 7.0, -12.0, 9.0, 11.0, 9.0, 8.0, 9.0, -11.0, 13.0, 6.0, -14.0, 10.0, 6.0, 13.0, -14.0, 10.0, -12.0, 14.0, 8.0, 5.0, 8.0, 12.0, 3.0, -8.0, -3.0, 3.0, 10.0, 5.0, 11.0, -3.0, -5.0, 12.0, -9.0, 8.0, 7.0, 9.0, 1.0, 12.0, 8.0, -6.0, 12.0, 2.0, 6.0, -5.0, 6.0, 11.0, -15.0, 13.0, 7.0, 13.0, 7.0, -12.0, 13.0, 4.0, -4.0, 2.0, -3.0, 6.0, 3.0, 9.0, 12.0, 13.0, -6.0, -4.0, -2.0, 12.0, 8.0, -3.0, -12.0, 13.0, 10.0, 4.0, 11.0, -2.0, -1.0, 7.0, 8.0, 12.0, 6.0, -11.0, 12.0, 9.0, -7.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1843282031162511, "mean_inference_ms": 1.0634316289503913, "mean_action_processing_ms": 0.07099956973567928, "mean_env_wait_ms": 0.17454968219206007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 506736, "agent_timesteps_total": 506736, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65734198.908, "learn_time_ms": 14.772, "learn_throughput": 372864.33, "update_time_ms": 5.39}, "info": {"learner": {"learned": {"policy_loss": 1.2692521810531616, "vf_loss": 21.864639282226562, "total_loss": 23.133892059326172, "vf_explained_var": -0.004630565643310547, "model": {}}}, "num_steps_sampled": 506736, "num_agent_steps_sampled": 506736, "num_steps_trained": 506736, "num_agent_steps_trained": 506736}, "done": false, "episodes_total": 9936, "training_iteration": 92, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-01", "timestamp": 1626864481, "time_this_iter_s": 0.35633134841918945, "time_total_s": 33.58134603500366, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 33.58134603500366, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 76.4, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.083333333333334, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7708333333333335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-11.0, 12.0, 6.0, 8.0, 5.0, 10.0, -7.0, 7.0, 12.0, 13.0, -2.0, -8.0, 9.0, -13.0, 9.0, 11.0, 0.0, -1.0, 12.0, 4.0, 9.0, -6.0, 8.0, 4.0, 13.0, 9.0, -5.0, -2.0, 13.0, 3.0, 9.0, -10.0, 5.0, -2.0, 10.0, 2.0, -1.0, 12.0, -1.0, 5.0, 14.0, 3.0, 2.0, -4.0, 11.0, 9.0, -10.0, 5.0, -12.0, 13.0, 11.0, 3.0, -4.0, 8.0, 4.0, 7.0, 13.0, 0.0, -7.0, 9.0, 12.0, -9.0, 5.0, 8.0, 10.0, -6.0, 12.0, -1.0, -7.0, 5.0, 7.0, 10.0, 12.0, 6.0, 4.0, -7.0, 10.0, -1.0, 10.0, -3.0, -8.0, 13.0, 9.0, 1.0, 14.0, 10.0, -11.0, 2.0, 7.0, 11.0, -2.0, -1.0, 13.0, 1.0, -11.0, 12.0, 7.0, 14.0, 12.0, -18.0, -5.0, 10.0, 10.0, 0.0, 2.0, 10.0, -4.0, 7.0, 12.0, -7.0, 4.0, 6.0, -14.0, 13.0, 13.0, 3.0, 0.0, 10.0, 5.0, 0.0, 13.0, 6.0, 2.0, -6.0, 14.0, 4.0, -2.0, -1.0, 7.0, 11.0, 10.0, -13.0, 8.0, 12.0, 1.0, -6.0, 13.0, 7.0, 5.0, -10.0, 14.0, 10.0, -4.0, -5.0, -6.0, 13.0, 12.0, -4.0, 8.0, -7.0, 2.0, 12.0, 12.0, 1.0, 6.0, -4.0, 14.0, 9.0, -20.0, 12.0, -9.0, 14.0, 11.0, -1.0, 13.0, 8.0, -9.0, 3.0, 13.0, 7.0, 4.0, -9.0, 12.0, -5.0, 9.0, -1.0, 7.0, 13.0, 9.0, -14.0, -1.0, 11.0, 3.0, 2.0, 14.0, -2.0, -6.0, 9.0, 14.0, -8.0, 0.0, 10.0, -6.0, 12.0, 12.0, -3.0, -15.0, 13.0, 6.0, 11.0, 13.0, 6.0, -1.0, -3.0, 14.0, 7.0, -2.0, -4.0, -1.0, 14.0, 13.0, -11.0, -1.0, 5.0, 5.0, 6.0, 12.0, 7.0, -4.0, 0.0, 14.0, 3.0, 4.0, -5.0, 3.0, -5.0, 12.0, 5.0, -6.0, 13.0, -3.0, 11.0, 14.0, 4.0, -10.0, 7.0, 13.0, 4.0, 6.0, -8.0, 7.0, -2.0, 12.0, -2.0, 9.0, 9.0, 2.0, -5.0, 10.0, 12.0, -6.0, -1.0, 11.0, 5.0, -9.0, 8.0, -9.0, 13.0, 6.0, 5.0, -8.0, 12.0, 7.0, 4.0, 13.0, 10.0, -11.0, 3.0, 14.0, -11.0, 13.0, -1.0, 6.0, 11.0, 12.0, -14.0, -13.0, 12.0, 10.0, 6.0, 11.0, 6.0, -1.0, -1.0, 13.0, -7.0, -3.0, 13.0, -4.0, 14.0, 7.0, -2.0, 6.0, -7.0, 10.0, 6.0, -2.0, 7.0, -2.0, 12.0, 10.0, -8.0, 9.0, 5.0, 7.0, 6.0, 12.0, -10.0, 13.0, 7.0, 2.0, -7.0, 12.0, 6.0, -3.0, 0.0, 13.0, 2.0, -5.0, 5.0, 9.0, 14.0, 12.0, -20.0, -11.0, 11.0, 7.0, 8.0, 14.0, 7.0, 4.0, -10.0, 12.0, 10.0, -5.0, -2.0, -6.0, 13.0, 10.0, -2.0, 9.0, -3.0, -3.0, 12.0, -1.0, 12.0, 10.0, -6.0, 14.0, 9.0, -4.0, -3.0, 4.0, -1.0, 13.0, -1.0, 9.0, -8.0, 11.0, 3.0, 13.0, 8.0, -11.0, 5.0, 12.0, 6.0, 6.0, -9.0, 4.0, -4.0, 13.0, 2.0, -9.0, 10.0, 10.0, 4.0, 13.0, 9.0, -7.0, 0.0, 14.0, 6.0, 11.0, -15.0, 2.0, -4.0, 10.0, 7.0, -12.0, 11.0, 8.0, 8.0, 13.0, 5.0, -6.0, 3.0, 14.0, 8.0, 11.0, -18.0, 8.0, -4.0, 11.0, 0.0, -2.0, 10.0, -2.0, 9.0, 6.0, 12.0, -3.0, 0.0, 14.0, -8.0, 10.0, -1.0, 6.0, 12.0, -14.0, 11.0, 6.0, -1.0, 3.0, 7.0, 12.0, 9.0, 2.0, -8.0, 14.0, 7.0, 11.0, -17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18432355553558044, "mean_inference_ms": 1.0633082919948473, "mean_action_processing_ms": 0.07098897682795995, "mean_env_wait_ms": 0.17455335046157677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 512244, "agent_timesteps_total": 512244, "timers": {"sample_time_ms": 0.082, "sample_throughput": 67249791.036, "learn_time_ms": 14.351, "learn_throughput": 383814.02, "update_time_ms": 5.302}, "info": {"learner": {"learned": {"policy_loss": 210177261568.0, "vf_loss": 330.3544921875, "total_loss": 210177261568.0, "vf_explained_var": -0.0001512765884399414, "model": {}}}, "num_steps_sampled": 512244, "num_agent_steps_sampled": 512244, "num_steps_trained": 512244, "num_agent_steps_trained": 512244}, "done": false, "episodes_total": 10044, "training_iteration": 93, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-01", "timestamp": 1626864481, "time_this_iter_s": 0.3458857536315918, "time_total_s": 33.927231788635254, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182710d0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 33.927231788635254, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.074074074074074, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7685185185185186}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, 6.0, 6.0, 7.0, 12.0, 12.0, 5.0, -13.0, -1.0, 1.0, 6.0, 9.0, 10.0, 3.0, 6.0, -4.0, -12.0, 6.0, 13.0, 8.0, -4.0, 3.0, 5.0, 12.0, 10.0, -11.0, 8.0, 8.0, 10.0, -12.0, 7.0, 10.0, 6.0, 2.0, 13.0, -6.0, 11.0, 12.0, -14.0, 7.0, 13.0, -18.0, 9.0, 11.0, 11.0, 0.0, 6.0, -2.0, -8.0, 1.0, 13.0, 9.0, 11.0, -1.0, 2.0, 3.0, -13.0, 11.0, 7.0, 10.0, 13.0, -1.0, -2.0, 5.0, 7.0, 5.0, 8.0, -5.0, 12.0, -1.0, 5.0, 0.0, -8.0, 6.0, 8.0, 9.0, 11.0, 0.0, -3.0, 7.0, -6.0, 4.0, 13.0, 4.0, 13.0, 11.0, 6.0, -15.0, 4.0, -1.0, 7.0, 5.0, 9.0, 5.0, -11.0, 12.0, -7.0, 5.0, 13.0, 4.0, 12.0, 3.0, -8.0, 9.0, 0.0, 5.0, 8.0, 2.0, 9.0, 7.0, -7.0, 6.0, -9.0, 8.0, 13.0, 3.0, 14.0, 6.0, 10.0, -15.0, 4.0, -3.0, 5.0, 9.0, 6.0, 6.0, 9.0, -6.0, -11.0, 5.0, 13.0, 8.0, 12.0, 11.0, 3.0, -10.0, 2.0, 8.0, -1.0, 6.0, 10.0, 11.0, -8.0, 2.0, -14.0, 5.0, 11.0, 13.0, -3.0, 8.0, 7.0, 3.0, -13.0, 8.0, 12.0, 8.0, 4.0, 8.0, -2.0, 5.0, 5.0, 8.0, 3.0, -1.0, 13.0, 14.0, 0.0, -12.0, 8.0, -5.0, 1.0, 11.0, 9.0, -1.0, -4.0, 11.0, -2.0, 10.0, 2.0, 5.0, 12.0, 12.0, -17.0, 8.0, -7.0, 9.0, 12.0, 1.0, 9.0, 2.0, 11.0, -7.0, 0.0, 5.0, 13.0, -3.0, 13.0, 7.0, 10.0, -15.0, -10.0, 9.0, 6.0, 10.0, 12.0, -5.0, -2.0, 10.0, -11.0, 0.0, 13.0, 13.0, 11.0, 14.0, -15.0, 5.0, -7.0, 12.0, 4.0, 6.0, 12.0, -4.0, -2.0, 9.0, 13.0, 12.0, -9.0, -1.0, 11.0, -2.0, 2.0, 4.0, 7.0, -3.0, 7.0, 4.0, 7.0, 4.0, 6.0, -2.0, -10.0, 4.0, 13.0, 8.0, 13.0, 9.0, 11.0, -17.0, -7.0, 11.0, 4.0, 7.0, -3.0, -3.0, 9.0, 12.0, 4.0, 3.0, 13.0, -5.0, -3.0, 12.0, 9.0, -3.0, 11.0, 11.0, -16.0, 9.0, -2.0, -6.0, 12.0, 11.0, 4.0, -1.0, 13.0, -1.0, 13.0, -12.0, 9.0, 5.0, 11.0, -14.0, 9.0, 9.0, 10.0, 1.0, -4.0, 8.0, 8.0, -3.0, 13.0, -3.0, 12.0, 12.0, 6.0, -15.0, -2.0, 5.0, 0.0, 12.0, -1.0, 2.0, 3.0, 11.0, -6.0, 10.0, 9.0, 2.0, -2.0, 13.0, -4.0, 8.0, 6.0, 14.0, -7.0, 2.0, 9.0, 7.0, -7.0, 6.0, 6.0, 4.0, 13.0, -8.0, -7.0, 12.0, 1.0, 9.0, -4.0, 10.0, 8.0, 1.0, 12.0, 4.0, -12.0, 11.0, -7.0, 6.0, 13.0, 3.0, 11.0, -10.0, 4.0, 10.0, 11.0, -14.0, 9.0, 9.0, 10.0, 8.0, -5.0, 2.0, 6.0, 8.0, -11.0, 12.0, 13.0, 7.0, -4.0, -1.0, 0.0, 7.0, -2.0, 10.0, 9.0, 9.0, -9.0, 6.0, 9.0, 10.0, 13.0, -17.0, -5.0, 14.0, 7.0, -1.0, 8.0, -13.0, 9.0, 11.0, 11.0, 8.0, -8.0, 4.0, 7.0, 4.0, 13.0, -9.0, 10.0, -5.0, 0.0, 10.0, 12.0, -6.0, 0.0, 9.0, 11.0, -1.0, 8.0, -3.0, -9.0, 3.0, 8.0, 13.0, 10.0, -6.0, 5.0, 6.0, 9.0, 10.0, -9.0, 5.0, 5.0, 8.0, -9.0, 11.0, -10.0, 9.0, 4.0, 12.0, -3.0, 10.0, 3.0, 6.0, -1.0, 5.0, 8.0, 3.0, 13.0, -5.0, -4.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18430746668618156, "mean_inference_ms": 1.063046216651146, "mean_action_processing_ms": 0.07097746181326509, "mean_env_wait_ms": 0.17453430473808268, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 517752, "agent_timesteps_total": 517752, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69365471.974, "learn_time_ms": 14.051, "learn_throughput": 391995.019, "update_time_ms": 5.412}, "info": {"learner": {"learned": {"policy_loss": 130527010816.0, "vf_loss": 121.7409896850586, "total_loss": 130527010816.0, "vf_explained_var": -0.0010898113250732422, "model": {}}}, "num_steps_sampled": 517752, "num_agent_steps_sampled": 517752, "num_steps_trained": 517752, "num_agent_steps_trained": 517752}, "done": false, "episodes_total": 10152, "training_iteration": 94, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-01", "timestamp": 1626864481, "time_this_iter_s": 0.35216641426086426, "time_total_s": 34.27939820289612, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 34.27939820289612, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 73.5, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -4.0, 7.0, 2.0, -17.0, 13.0, 9.0, 10.0, -10.0, 9.0, 3.0, 13.0, 6.0, 4.0, -8.0, 13.0, 11.0, -4.0, 6.0, 2.0, 10.0, 10.0, 3.0, -8.0, 4.0, -5.0, 3.0, 13.0, 11.0, 0.0, -8.0, 12.0, -11.0, 9.0, 12.0, 5.0, 6.0, 4.0, -6.0, 11.0, 7.0, -8.0, 4.0, 12.0, -8.0, 0.0, 10.0, 13.0, 7.0, 12.0, -8.0, 4.0, 9.0, 10.0, 6.0, -10.0, -6.0, -4.0, 12.0, 13.0, 12.0, 1.0, -10.0, 12.0, 11.0, 12.0, -11.0, 3.0, 8.0, -5.0, 8.0, 4.0, -10.0, 10.0, 6.0, 9.0, 11.0, 6.0, -9.0, 7.0, 12.0, -6.0, 3.0, 6.0, 12.0, 7.0, 11.0, -15.0, -15.0, 10.0, 8.0, 12.0, 8.0, 2.0, -7.0, 12.0, 13.0, -5.0, 8.0, -1.0, 13.0, 13.0, 4.0, -15.0, 11.0, -7.0, -2.0, 13.0, 11.0, -14.0, 7.0, 11.0, 7.0, -4.0, 8.0, 4.0, 12.0, 13.0, 6.0, -16.0, 8.0, -9.0, 3.0, 13.0, 5.0, -8.0, 5.0, 13.0, 12.0, -4.0, 2.0, 5.0, -5.0, 10.0, -1.0, 11.0, 2.0, -7.0, 7.0, 13.0, 8.0, 10.0, -15.0, 12.0, 12.0, -6.0, 1.0, 8.0, -16.0, 11.0, 8.0, 12.0, -4.0, 9.0, 8.0, 2.0, 6.0, 5.0, -8.0, 12.0, 11.0, -5.0, 4.0, 5.0, 11.0, 10.0, -17.0, 11.0, 6.0, -5.0, 5.0, 9.0, 6.0, -5.0, 2.0, 12.0, -13.0, 11.0, 13.0, 4.0, 7.0, 12.0, 6.0, -10.0, 1.0, -5.0, 6.0, 13.0, 11.0, -12.0, 11.0, 5.0, -12.0, 11.0, 13.0, 3.0, 9.0, -5.0, 6.0, 5.0, -21.0, 11.0, 12.0, 13.0, 7.0, 4.0, -4.0, 8.0, 12.0, -7.0, 11.0, -1.0, 8.0, 12.0, 4.0, -9.0, -8.0, -1.0, 12.0, 12.0, 11.0, 8.0, -10.0, 6.0, 7.0, -1.0, 11.0, -2.0, -16.0, 10.0, 10.0, 11.0, 5.0, -7.0, 4.0, 13.0, -6.0, 10.0, 4.0, 7.0, -4.0, 6.0, 9.0, 4.0, -13.0, 5.0, 12.0, 11.0, 11.0, -13.0, 4.0, 13.0, 7.0, 4.0, -9.0, 13.0, 11.0, -9.0, 11.0, 2.0, 13.0, 5.0, 2.0, -5.0, 7.0, -8.0, 8.0, 8.0, 11.0, -1.0, -8.0, 13.0, 6.0, -2.0, 12.0, -1.0, 6.0, 11.0, 6.0, -8.0, 12.0, -4.0, -6.0, 13.0, 8.0, -12.0, 6.0, 13.0, 6.0, -8.0, 11.0, 6.0, 9.0, 14.0, 3.0, -11.0, 13.0, -10.0, -1.0, 13.0, 3.0, 6.0, -7.0, 13.0, 5.0, -3.0, 6.0, 7.0, 10.0, 6.0, -5.0, 4.0, 3.0, -7.0, 10.0, 9.0, 11.0, 5.0, -12.0, 11.0, 12.0, -1.0, 2.0, 2.0, 10.0, 12.0, -1.0, -6.0, 0.0, -5.0, 8.0, 12.0, 7.0, 6.0, -9.0, 11.0, 11.0, 4.0, -6.0, 6.0, 14.0, 10.0, 11.0, -20.0, 8.0, -10.0, 8.0, 9.0, 11.0, -10.0, 1.0, 13.0, 5.0, -4.0, 13.0, 1.0, 7.0, 3.0, -7.0, 12.0, 7.0, -9.0, 8.0, 9.0, 8.0, -10.0, 5.0, 12.0, -2.0, 6.0, 5.0, 6.0, 7.0, 7.0, 5.0, -4.0, 10.0, -8.0, 1.0, 12.0, 10.0, -3.0, 5.0, 3.0, 11.0, -8.0, 7.0, 5.0, 8.0, 12.0, -2.0, -3.0, 7.0, -9.0, 4.0, 13.0, 5.0, 9.0, 6.0, -5.0, 12.0, -10.0, 6.0, 7.0, 13.0, 10.0, 11.0, -19.0, -1.0, -5.0, 12.0, 9.0, 13.0, 0.0, 11.0, -9.0, 7.0, -2.0, 6.0, 4.0, 14.0, 0.0, -7.0, 8.0, 8.0, -9.0, 4.0, 12.0, 13.0, 9.0, -19.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18429672148731566, "mean_inference_ms": 1.0629846899145303, "mean_action_processing_ms": 0.07097165752554843, "mean_env_wait_ms": 0.17453765670127014, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 523260, "agent_timesteps_total": 523260, "timers": {"sample_time_ms": 0.08, "sample_throughput": 69178858.961, "learn_time_ms": 14.177, "learn_throughput": 388504.51, "update_time_ms": 5.447}, "info": {"learner": {"learned": {"policy_loss": 219291811840.0, "vf_loss": 247.3343048095703, "total_loss": 219291811840.0, "vf_explained_var": -0.0001481771469116211, "model": {}}}, "num_steps_sampled": 523260, "num_agent_steps_sampled": 523260, "num_steps_trained": 523260, "num_agent_steps_trained": 523260}, "done": false, "episodes_total": 10260, "training_iteration": 95, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-02", "timestamp": 1626864482, "time_this_iter_s": 0.35053086280822754, "time_total_s": 34.629929065704346, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 34.629929065704346, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [331.0, 13.0, 12.0, 11.0, -4.0, 10.0, -2.0, 11.0, 1.0, 5.0, 10.0, -1.0, 8.0, -11.0, 8.0, 10.0, 2.0, 7.0, 8.0, -2.0, -4.0, 12.0, 0.0, 7.0, 4.0, -11.0, 10.0, 12.0, 10.0, 3.0, 7.0, -5.0, 6.0, 13.0, 5.0, -9.0, 10.0, 2.0, 8.0, -5.0, 6.0, -9.0, 7.0, 11.0, 11.0, 5.0, -11.0, 10.0, -6.0, 10.0, 7.0, 4.0, 9.0, 2.0, -9.0, 13.0, 3.0, -12.0, 13.0, 11.0, 10.0, -6.0, 1.0, 10.0, -2.0, 13.0, 10.0, -6.0, -5.0, 9.0, 8.0, 3.0, 6.0, -15.0, 12.0, 12.0, 8.0, 7.0, -7.0, 7.0, 1.0, -9.0, 12.0, 11.0, 13.0, 4.0, 8.0, -10.0, 6.0, 3.0, -7.0, 13.0, 10.0, 9.0, -9.0, 5.0, 5.0, -2.0, 1.0, 11.0, -5.0, 0.0, 8.0, 12.0, 5.0, -2.0, 13.0, -1.0, -11.0, 12.0, 6.0, 8.0, 1.0, -4.0, 10.0, 8.0, -1.0, 8.0, -2.0, 10.0, -11.0, 5.0, 13.0, 8.0, 11.0, 13.0, -12.0, 3.0, 6.0, 13.0, -11.0, 7.0, -3.0, 1.0, 6.0, 11.0, -9.0, -1.0, 13.0, 12.0, 12.0, 8.0, -2.0, -3.0, -1.0, -2.0, 11.0, 7.0, -4.0, 0.0, 10.0, 9.0, 6.0, 6.0, 7.0, -4.0, 10.0, -5.0, 0.0, 10.0, 1.0, 10.0, 8.0, -4.0, -1.0, 6.0, 1.0, 9.0, 11.0, -2.0, 11.0, -5.0, 11.0, -10.0, 1.0, 13.0, 1.0, -2.0, 13.0, 3.0, -7.0, 13.0, 8.0, 1.0, 4.0, 5.0, 13.0, -7.0, 6.0, 4.0, 8.0, -3.0, 3.0, 10.0, 5.0, -3.0, -1.0, 6.0, 11.0, -1.0, 5.0, -9.0, 10.0, 9.0, 12.0, -13.0, 4.0, 12.0, 3.0, -8.0, 9.0, 11.0, -3.0, 12.0, -6.0, 12.0, 7.0, -2.0, 13.0, -3.0, 12.0, 6.0, -1.0, -2.0, 6.0, -6.0, 10.0, 5.0, -5.0, 3.0, 10.0, 7.0, 11.0, -1.0, 11.0, -6.0, 11.0, -5.0, 0.0, 9.0, 0.0, 14.0, 12.0, -11.0, -1.0, 5.0, 11.0, 0.0, 6.0, -16.0, 12.0, 13.0, 12.0, -15.0, 6.0, 12.0, 7.0, 10.0, 5.0, -7.0, -2.0, 7.0, 1.0, 9.0, -8.0, 2.0, 13.0, 8.0, 7.0, 12.0, -9.0, 5.0, 4.0, 12.0, 6.0, -7.0, 12.0, 8.0, -14.0, 9.0, 4.0, 10.0, 8.0, -7.0, 8.0, 12.0, 5.0, -10.0, 12.0, 13.0, 0.0, -10.0, -8.0, 9.0, 8.0, 6.0, 1.0, 7.0, 13.0, -6.0, 11.0, 7.0, -15.0, 12.0, 7.0, -3.0, 2.0, 9.0, -4.0, 7.0, 6.0, 6.0, 6.0, -11.0, 9.0, 11.0, 10.0, 2.0, 7.0, -4.0, -1.0, -4.0, 8.0, 12.0, -2.0, 13.0, 10.0, -6.0, 6.0, -10.0, 11.0, 8.0, 12.0, -6.0, 2.0, 7.0, -13.0, 11.0, 10.0, 7.0, -1.0, 12.0, 5.0, -1.0, 5.0, 5.0, 13.0, -8.0, 10.0, -8.0, 1.0, 12.0, -5.0, -2.0, 12.0, 10.0, -2.0, 11.0, -6.0, 12.0, 2.0, 5.0, 10.0, -2.0, 12.0, 13.0, 5.0, -15.0, -2.0, 13.0, 12.0, -8.0, -3.0, 12.0, 6.0, 0.0, 2.0, -13.0, 13.0, 13.0, 10.0, -8.0, 0.0, 13.0, 8.0, -2.0, 11.0, -2.0, -8.0, 7.0, 3.0, 13.0, -10.0, 4.0, 13.0, 8.0, 7.0, -5.0, 3.0, 10.0, 2.0, 13.0, 7.0, -7.0, 11.0, 7.0, -14.0, 11.0, 5.0, 4.0, 13.0, -7.0, 11.0, 8.0, 7.0, -11.0, -9.0, 13.0, 6.0, 5.0, -6.0, 5.0, 11.0, 5.0, 5.0, -13.0, 11.0, 12.0, 11.0, -7.0, 7.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18427122759554598, "mean_inference_ms": 1.0629648263209681, "mean_action_processing_ms": 0.07095363335130656, "mean_env_wait_ms": 0.17451381350606468, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 528768, "agent_timesteps_total": 528768, "timers": {"sample_time_ms": 0.082, "sample_throughput": 67525984.385, "learn_time_ms": 14.603, "learn_throughput": 377176.128, "update_time_ms": 5.83}, "info": {"learner": {"learned": {"policy_loss": 1.3859964609146118, "vf_loss": 20.788616180419922, "total_loss": 22.174612045288086, "vf_explained_var": -0.00528717041015625, "model": {}}}, "num_steps_sampled": 528768, "num_agent_steps_sampled": 528768, "num_steps_trained": 528768, "num_agent_steps_trained": 528768}, "done": false, "episodes_total": 10368, "training_iteration": 96, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-02", "timestamp": 1626864482, "time_this_iter_s": 0.36687231063842773, "time_total_s": 34.99680137634277, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 34.99680137634277, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 78.0, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 366.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.65740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 328.0}, "policy_reward_mean": {"learned": 6.914351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -3.0, -2.0, 8.0, 9.0, 4.0, -5.0, 7.0, 12.0, 10.0, -14.0, 7.0, 7.0, -5.0, 8.0, 5.0, 12.0, -6.0, 10.0, -1.0, 13.0, 3.0, -9.0, 8.0, 10.0, 12.0, -20.0, 13.0, -2.0, 8.0, 12.0, -3.0, 11.0, 10.0, -9.0, 3.0, 13.0, -9.0, 9.0, 2.0, 10.0, 14.0, -21.0, 12.0, 9.0, -19.0, 13.0, 12.0, 11.0, -7.0, 10.0, 1.0, 11.0, 4.0, -8.0, 8.0, 11.0, 12.0, -21.0, 13.0, -3.0, -7.0, 13.0, 12.0, 7.0, 10.0, -10.0, 8.0, 14.0, 3.0, -13.0, 11.0, 8.0, 14.0, -20.0, 13.0, -17.0, 12.0, 10.0, 10.0, 4.0, 10.0, 11.0, -10.0, 14.0, 3.0, -14.0, 12.0, 12.0, 14.0, 315.0, 12.0, 6.0, -8.0, 10.0, 7.0, -6.0, 7.0, 12.0, 2.0, 13.0, 1.0, -5.0, 6.0, 12.0, 13.0, 316.0, 13.0, 12.0, -12.0, 8.0, 7.0, 8.0, 3.0, -5.0, 9.0, 10.0, 7.0, -2.0, 0.0, -5.0, 14.0, -6.0, 12.0, -6.0, 11.0, -3.0, 13.0, -2.0, 2.0, 7.0, 8.0, 13.0, -11.0, 11.0, 2.0, -5.0, 14.0, -6.0, 12.0, -12.0, 10.0, 9.0, 8.0, -3.0, 13.0, 8.0, -3.0, 9.0, -10.0, 4.0, 12.0, -13.0, 11.0, 4.0, 13.0, -17.0, 13.0, 11.0, 8.0, 3.0, 10.0, -3.0, 5.0, 14.0, 4.0, -15.0, 12.0, 13.0, 13.0, 7.0, -18.0, 3.0, -11.0, 10.0, 13.0, -5.0, 9.0, 3.0, 8.0, 11.0, 2.0, -5.0, 7.0, 10.0, 12.0, -20.0, 13.0, -16.0, 6.0, 13.0, 12.0, 11.0, 9.0, -13.0, 8.0, 14.0, 2.0, -4.0, 3.0, 10.0, 13.0, -16.0, 8.0, -5.0, -5.0, 13.0, 12.0, 12.0, 11.0, -11.0, 3.0, 11.0, 8.0, -3.0, -1.0, 13.0, 12.0, -6.0, -4.0, -18.0, 12.0, 13.0, 8.0, 13.0, -6.0, 0.0, 8.0, 14.0, 2.0, -6.0, 5.0, 12.0, 12.0, -22.0, 13.0, 4.0, 8.0, -8.0, 11.0, 12.0, 10.0, 2.0, -9.0, 13.0, -2.0, -2.0, 6.0, 12.0, 12.0, -18.0, 9.0, 4.0, 12.0, -14.0, 13.0, 10.0, -10.0, 8.0, 7.0, 10.0, -4.0, -3.0, 12.0, -3.0, 13.0, -8.0, 13.0, -2.0, -8.0, 13.0, 12.0, 13.0, -9.0, 11.0, 0.0, 13.0, 8.0, -15.0, 9.0, 9.0, 11.0, -18.0, 13.0, 8.0, -13.0, 7.0, 13.0, -1.0, 8.0, 0.0, 8.0, 12.0, -7.0, 13.0, -3.0, 9.0, 14.0, -17.0, 9.0, 11.0, -10.0, 6.0, 8.0, 12.0, 4.0, -8.0, 7.0, 14.0, -10.0, 2.0, 9.0, 12.0, 13.0, 328.0, 13.0, 0.0, -5.0, 11.0, 9.0, -5.0, 4.0, 8.0, 8.0, 7.0, -13.0, 11.0, 10.0, 13.0, 11.0, -22.0, 13.0, -11.0, 7.0, 9.0, 10.0, 2.0, 12.0, -7.0, 8.0, 13.0, -8.0, 12.0, -2.0, 10.0, 14.0, -22.0, 13.0, 3.0, -10.0, 9.0, 13.0, -3.0, 10.0, 0.0, 8.0, 9.0, 3.0, -6.0, 9.0, 11.0, 14.0, 7.0, -17.0, 5.0, -9.0, 13.0, 6.0, 12.0, 6.0, -12.0, 9.0, 7.0, 3.0, 11.0, -6.0, 10.0, 11.0, 7.0, -13.0, 2.0, -7.0, 11.0, 9.0, 7.0, 10.0, -5.0, 3.0, 13.0, 0.0, -5.0, 7.0, 3.0, 14.0, -15.0, 13.0, -14.0, 12.0, 5.0, 12.0, -9.0, 11.0, 5.0, 8.0, 11.0, 7.0, -11.0, 8.0, 10.0, 14.0, 317.0, 13.0, -1.0, 12.0, 10.0, -6.0, -6.0, 10.0, 7.0, 4.0, 13.0, -9.0, 11.0, 0.0, -2.0, 12.0, -8.0, 13.0, -16.0, 8.0, 11.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1842533007320167, "mean_inference_ms": 1.0627510776091011, "mean_action_processing_ms": 0.07094461521635151, "mean_env_wait_ms": 0.174500580017186, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 534276, "agent_timesteps_total": 534276, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67787348.846, "learn_time_ms": 14.495, "learn_throughput": 379999.579, "update_time_ms": 6.1}, "info": {"learner": {"learned": {"policy_loss": 1.2534210681915283, "vf_loss": 16.457319259643555, "total_loss": 17.71074104309082, "vf_explained_var": -0.005282878875732422, "model": {}}}, "num_steps_sampled": 534276, "num_agent_steps_sampled": 534276, "num_steps_trained": 534276, "num_agent_steps_trained": 534276}, "done": false, "episodes_total": 10476, "training_iteration": 97, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-03", "timestamp": 1626864483, "time_this_iter_s": 0.3513350486755371, "time_total_s": 35.34813642501831, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 35.34813642501831, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 80.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-16.0, 10.0, 10.0, 11.0, 14.0, -4.0, -2.0, 7.0, 1.0, -1.0, 4.0, 11.0, 4.0, 14.0, -10.0, 7.0, 11.0, 9.0, -7.0, 2.0, 13.0, 7.0, 8.0, -13.0, 13.0, 13.0, 12.0, 317.0, 3.0, 13.0, -13.0, 12.0, 13.0, 5.0, 1.0, -4.0, 14.0, 7.0, 6.0, -12.0, 8.0, -1.0, -4.0, 12.0, 3.0, 14.0, 6.0, -8.0, -3.0, 9.0, 7.0, 2.0, 14.0, 12.0, 5.0, -16.0, 13.0, 9.0, -17.0, 10.0, 5.0, 13.0, -2.0, -1.0, 13.0, -9.0, 1.0, 10.0, -1.0, 7.0, 8.0, 1.0, 11.0, -6.0, 13.0, -3.0, 0.0, 14.0, -11.0, 12.0, -7.0, 5.0, 4.0, 13.0, 8.0, -6.0, 8.0, 5.0, 12.0, -4.0, -6.0, 13.0, -1.0, 14.0, -8.0, 10.0, -6.0, 5.0, 12.0, 4.0, 9.0, 13.0, 5.0, -12.0, 10.0, -6.0, 13.0, -2.0, -3.0, 14.0, 7.0, -3.0, -6.0, 10.0, 4.0, 7.0, 14.0, -4.0, 5.0, 0.0, 13.0, -2.0, -9.0, 13.0, 2.0, 13.0, -4.0, 4.0, 3.0, 13.0, 10.0, -11.0, -6.0, 13.0, -1.0, 9.0, 9.0, 13.0, -18.0, 11.0, 3.0, 14.0, -8.0, 6.0, 7.0, -10.0, 9.0, 9.0, -10.0, 12.0, 8.0, 5.0, 9.0, -1.0, -2.0, 9.0, -3.0, 13.0, -3.0, 8.0, 3.0, -2.0, 6.0, 8.0, 13.0, 7.0, 7.0, -12.0, 7.0, 13.0, -11.0, 6.0, 5.0, 11.0, -13.0, 12.0, 4.0, -6.0, 8.0, 9.0, -9.0, 12.0, 7.0, 5.0, 4.0, 12.0, 11.0, -12.0, 3.0, 13.0, -8.0, 7.0, 0.0, -6.0, 9.0, 12.0, -5.0, 13.0, 6.0, 1.0, 12.0, 12.0, 13.0, -22.0, 4.0, 11.0, -7.0, 7.0, -5.0, 7.0, 10.0, 3.0, 0.0, 8.0, 6.0, 1.0, 12.0, 13.0, 11.0, 318.0, 10.0, 14.0, 2.0, -11.0, -7.0, 6.0, 8.0, 8.0, -2.0, 11.0, 8.0, -2.0, 13.0, -4.0, -3.0, 9.0, -16.0, 13.0, 6.0, 12.0, 7.0, -4.0, 12.0, 0.0, 9.0, 12.0, -1.0, -5.0, 12.0, 11.0, 5.0, -13.0, 5.0, 9.0, -5.0, 6.0, 6.0, 5.0, 9.0, -5.0, -5.0, 12.0, 3.0, 5.0, 13.0, -3.0, -7.0, 12.0, 4.0, 12.0, -9.0, 8.0, 7.0, 12.0, -16.0, 12.0, 9.0, -2.0, 5.0, 3.0, 9.0, -1.0, -4.0, 11.0, -1.0, 13.0, 5.0, -2.0, 12.0, 6.0, 7.0, -10.0, 13.0, 12.0, -7.0, -3.0, 9.0, 12.0, -17.0, 11.0, 0.0, 13.0, -7.0, 9.0, -7.0, 10.0, 3.0, 9.0, 14.0, 11.0, 7.0, -17.0, 14.0, -1.0, -6.0, 8.0, -5.0, 13.0, 4.0, 3.0, 6.0, 8.0, 8.0, -7.0, 9.0, 12.0, 7.0, -13.0, 12.0, -2.0, 11.0, -6.0, -18.0, 14.0, 12.0, 7.0, -9.0, 11.0, 11.0, 2.0, 13.0, 10.0, 5.0, -13.0, 14.0, -2.0, -8.0, 11.0, 2.0, 13.0, -7.0, 7.0, -12.0, 10.0, 10.0, 7.0, -4.0, 13.0, -1.0, 7.0, 13.0, -2.0, 9.0, -5.0, 4.0, 14.0, -9.0, 6.0, -8.0, 5.0, 9.0, 9.0, 10.0, 5.0, 8.0, -8.0, 1.0, -4.0, 9.0, 9.0, 2.0, 14.0, -9.0, 8.0, 9.0, -9.0, 10.0, 5.0, 11.0, 13.0, -17.0, 8.0, 7.0, 13.0, 11.0, -16.0, 3.0, 13.0, 6.0, -7.0, -7.0, 8.0, 10.0, 4.0, -5.0, 12.0, 8.0, 0.0, 12.0, -1.0, 12.0, -8.0, 5.0, 11.0, -9.0, 8.0, -3.0, 12.0, 3.0, 3.0, 6.0, 13.0, -8.0, 4.0, 12.0, -4.0, 9.0, -2.0, 5.0, 11.0, -3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18424496752571506, "mean_inference_ms": 1.0625943711431902, "mean_action_processing_ms": 0.07094308457868476, "mean_env_wait_ms": 0.17450056194753163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 539784, "agent_timesteps_total": 539784, "timers": {"sample_time_ms": 0.082, "sample_throughput": 67568065.018, "learn_time_ms": 14.494, "learn_throughput": 380010.831, "update_time_ms": 6.235}, "info": {"learner": {"learned": {"policy_loss": 1.3819128274917603, "vf_loss": 18.70553970336914, "total_loss": 20.087451934814453, "vf_explained_var": -0.006244182586669922, "model": {}}}, "num_steps_sampled": 539784, "num_agent_steps_sampled": 539784, "num_steps_trained": 539784, "num_agent_steps_trained": 539784}, "done": false, "episodes_total": 10584, "training_iteration": 98, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-03", "timestamp": 1626864483, "time_this_iter_s": 0.3487422466278076, "time_total_s": 35.69687867164612, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271950>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 35.69687867164612, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 7.0, 7.0, 7.0, 13.0, 11.0, -14.0, 5.0, 0.0, 2.0, 3.0, 10.0, 9.0, 11.0, -4.0, -1.0, -6.0, 9.0, 6.0, 6.0, 9.0, 12.0, 9.0, -15.0, -12.0, 11.0, 5.0, 11.0, 13.0, 10.0, -6.0, -2.0, 14.0, -7.0, 1.0, 7.0, 14.0, 2.0, 11.0, -12.0, 6.0, -8.0, 5.0, 12.0, 13.0, 9.0, -19.0, 12.0, 12.0, 10.0, -8.0, 1.0, 8.0, 12.0, 11.0, -16.0, 7.0, 8.0, -13.0, 13.0, 4.0, 13.0, 11.0, -13.0, 12.0, 11.0, -11.0, 3.0, -8.0, 12.0, 11.0, 0.0, 6.0, -13.0, 12.0, 10.0, 13.0, 10.0, -3.0, -5.0, 2.0, -3.0, 5.0, 11.0, 10.0, 12.0, 5.0, -12.0, 4.0, 0.0, -2.0, 13.0, 14.0, 8.0, -3.0, -4.0, 12.0, 10.0, -11.0, 4.0, 9.0, 8.0, 11.0, -13.0, 14.0, -12.0, 0.0, 13.0, 2.0, 13.0, -7.0, 7.0, 14.0, 12.0, -16.0, 5.0, 5.0, 8.0, 8.0, -6.0, 9.0, -6.0, -1.0, 13.0, 9.0, 7.0, -12.0, 11.0, 4.0, -3.0, 2.0, 12.0, 14.0, 13.0, 4.0, -16.0, 3.0, 7.0, 13.0, -8.0, 14.0, 1.0, 3.0, -3.0, 12.0, -6.0, 13.0, -4.0, -7.0, 12.0, 6.0, 4.0, 9.0, -4.0, -1.0, 11.0, 13.0, 7.0, -1.0, -4.0, 5.0, -8.0, 5.0, 13.0, 14.0, 3.0, 4.0, -6.0, 8.0, -15.0, 10.0, 12.0, 8.0, 7.0, -8.0, 8.0, -1.0, 6.0, 5.0, 5.0, 4.0, 6.0, 11.0, -6.0, 5.0, -7.0, 12.0, 5.0, 8.0, 6.0, 9.0, -8.0, 12.0, -9.0, 6.0, 6.0, 14.0, 10.0, 9.0, -18.0, -1.0, -4.0, 11.0, 9.0, 8.0, 6.0, 4.0, -3.0, 13.0, -10.0, 3.0, 9.0, 9.0, -10.0, 12.0, 4.0, 4.0, -6.0, 5.0, 12.0, 8.0, 7.0, 9.0, -9.0, 13.0, -7.0, 9.0, 0.0, 5.0, 11.0, 10.0, -11.0, 10.0, 2.0, -2.0, 5.0, 13.0, 8.0, -3.0, -3.0, 9.0, -7.0, 7.0, 6.0, 13.0, -16.0, 9.0, 9.0, 9.0, 4.0, -8.0, 10.0, 14.0, 10.0, -2.0, -7.0, 12.0, -9.0, 1.0, 11.0, 10.0, 6.0, 10.0, -11.0, 9.0, -7.0, 3.0, 10.0, 12.0, 12.0, -6.0, -3.0, -6.0, 10.0, 4.0, 7.0, 14.0, 9.0, 8.0, -16.0, 13.0, -11.0, 2.0, 11.0, 8.0, 7.0, 2.0, -2.0, 8.0, 12.0, -13.0, 8.0, 8.0, -10.0, 10.0, 7.0, 10.0, -9.0, 6.0, 8.0, 13.0, 1.0, -6.0, 7.0, -3.0, 12.0, 5.0, 1.0, 14.0, 8.0, 10.0, -17.0, 5.0, -6.0, 3.0, 13.0, 10.0, 13.0, 12.0, -20.0, 12.0, -4.0, 0.0, 7.0, 7.0, 3.0, -3.0, 8.0, 7.0, -1.0, 12.0, -3.0, 12.0, 13.0, 11.0, 320.0, 5.0, -9.0, 13.0, 6.0, 7.0, 13.0, 6.0, -11.0, 11.0, -18.0, 10.0, 12.0, 10.0, 5.0, -2.0, 2.0, -6.0, 5.0, 12.0, 4.0, 3.0, 7.0, 11.0, -6.0, 14.0, 11.0, -21.0, 11.0, 14.0, 3.0, -15.0, 13.0, -5.0, 11.0, 6.0, 3.0, 10.0, 8.0, 10.0, -13.0, 9.0, 2.0, 13.0, -9.0, 14.0, 12.0, -2.0, -9.0, 12.0, -8.0, 4.0, 7.0, 13.0, 12.0, -16.0, 6.0, 14.0, -11.0, 0.0, 12.0, 8.0, 12.0, -3.0, -2.0, 5.0, 10.0, 8.0, -8.0, 14.0, 7.0, 2.0, -8.0, 4.0, -5.0, 3.0, 13.0, 12.0, 13.0, -5.0, -5.0, 9.0, 9.0, -7.0, 4.0, 5.0, 11.0, 12.0, -13.0, -8.0, 9.0, 11.0, 3.0, 9.0, 14.0, -3.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1842461895439591, "mean_inference_ms": 1.0625002033408337, "mean_action_processing_ms": 0.07092827358483238, "mean_env_wait_ms": 0.17450060632663392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 545292, "agent_timesteps_total": 545292, "timers": {"sample_time_ms": 0.076, "sample_throughput": 72598247.515, "learn_time_ms": 14.007, "learn_throughput": 393233.402, "update_time_ms": 6.201}, "info": {"learner": {"learned": {"policy_loss": 1.3813947439193726, "vf_loss": 18.70395851135254, "total_loss": 20.08535385131836, "vf_explained_var": -0.006264209747314453, "model": {}}}, "num_steps_sampled": 545292, "num_agent_steps_sampled": 545292, "num_steps_trained": 545292, "num_agent_steps_trained": 545292}, "done": false, "episodes_total": 10692, "training_iteration": 99, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-03", "timestamp": 1626864483, "time_this_iter_s": 0.34621191024780273, "time_total_s": 36.04309058189392, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182868c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 36.04309058189392, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 82.1, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.50925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 5.377314814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 2.0, 7.0, -5.0, 12.0, -9.0, 7.0, 5.0, -3.0, 7.0, 5.0, 6.0, -6.0, 8.0, 2.0, 11.0, -3.0, 4.0, 7.0, 7.0, 10.0, -3.0, 10.0, -2.0, -1.0, 11.0, 1.0, 4.0, 2.0, 3.0, -2.0, 12.0, 13.0, 13.0, -4.0, -7.0, 13.0, -11.0, 10.0, 3.0, 11.0, -15.0, 11.0, 8.0, 2.0, -9.0, 11.0, 11.0, 13.0, 5.0, -10.0, 7.0, 14.0, -6.0, 0.0, 7.0, -1.0, 4.0, 5.0, 7.0, 12.0, -1.0, -7.0, 11.0, 6.0, 4.0, 11.0, -6.0, 14.0, -8.0, 4.0, 5.0, 9.0, -8.0, 2.0, 12.0, 6.0, 0.0, 11.0, -2.0, 7.0, 10.0, -8.0, 6.0, 13.0, -6.0, 8.0, 0.0, 10.0, -19.0, 11.0, 13.0, -12.0, 5.0, 11.0, 11.0, 12.0, 11.0, 5.0, -13.0, -7.0, 11.0, 11.0, 0.0, 12.0, -16.0, 8.0, 11.0, 10.0, 3.0, -8.0, 10.0, 9.0, 5.0, -7.0, 8.0, 0.0, 3.0, 11.0, 1.0, -1.0, -1.0, 6.0, 11.0, -14.0, 10.0, 8.0, 11.0, 3.0, 3.0, 12.0, -3.0, 12.0, -10.0, 8.0, 5.0, -5.0, -1.0, 8.0, 13.0, 8.0, 4.0, -8.0, 11.0, 13.0, 11.0, -4.0, -5.0, 11.0, -11.0, 8.0, 7.0, -3.0, 9.0, 8.0, 1.0, 7.0, 4.0, -5.0, 9.0, -7.0, 1.0, 11.0, 10.0, -7.0, 5.0, 11.0, 6.0, -5.0, 0.0, 7.0, 13.0, 13.0, 4.0, -6.0, 4.0, -5.0, 13.0, -1.0, 8.0, 11.0, 0.0, 11.0, -7.0, -1.0, 9.0, 4.0, 3.0, 9.0, 5.0, -11.0, 12.0, 11.0, 13.0, -7.0, -2.0, -7.0, 12.0, 2.0, 8.0, 13.0, -9.0, 8.0, 3.0, 12.0, 331.0, 12.0, 11.0, 11.0, 5.0, 5.0, -6.0, -1.0, 0.0, 11.0, 5.0, -2.0, 6.0, 2.0, 9.0, 12.0, 1.0, -8.0, 10.0, -8.0, 4.0, 8.0, 11.0, 12.0, -18.0, 9.0, 12.0, 9.0, -12.0, 5.0, 13.0, 9.0, -2.0, -3.0, 11.0, 11.0, -5.0, 3.0, 6.0, 11.0, -8.0, 8.0, 4.0, -4.0, -2.0, 10.0, 11.0, -6.0, 3.0, 6.0, 12.0, 7.0, 7.0, -6.0, 7.0, -6.0, 3.0, 11.0, 7.0, -2.0, -6.0, 10.0, 13.0, 3.0, 12.0, 10.0, -10.0, 9.0, 4.0, -5.0, 7.0, -2.0, -1.0, 12.0, 6.0, -7.0, 4.0, 5.0, 13.0, 6.0, -11.0, 8.0, 12.0, 14.0, 8.0, 6.0, -13.0, 10.0, -13.0, 13.0, 5.0, -2.0, -6.0, 13.0, 10.0, -9.0, 5.0, 11.0, 8.0, 6.0, 8.0, -5.0, 6.0, 11.0, 7.0, 10.0, -13.0, -2.0, 4.0, 1.0, 12.0, -14.0, 9.0, 11.0, 9.0, -6.0, 1.0, 9.0, 11.0, -5.0, -1.0, 12.0, 9.0, -1.0, 9.0, 4.0, 3.0, -10.0, 10.0, 3.0, 12.0, -3.0, 1.0, 7.0, 10.0, 13.0, -13.0, 8.0, 7.0, -2.0, 3.0, 4.0, 10.0, 11.0, -6.0, -1.0, 11.0, 2.0, 8.0, -2.0, 7.0, 8.0, -9.0, 10.0, 6.0, 12.0, -9.0, 7.0, 5.0, -7.0, 0.0, 10.0, 12.0, -10.0, 9.0, 8.0, 8.0, 11.0, -4.0, 8.0, 0.0, -1.0, 10.0, 2.0, 4.0, 6.0, 4.0, -4.0, 9.0, -6.0, 11.0, 6.0, 4.0, 11.0, -14.0, 13.0, 5.0, -4.0, -3.0, 10.0, 12.0, -8.0, 5.0, 8.0, 10.0, 7.0, 9.0, 5.0, -6.0, -2.0, 2.0, 12.0, 3.0, -1.0, 10.0, 2.0, 4.0, 13.0, 332.0, 11.0, 11.0, 12.0, 11.0, -7.0, -1.0, 13.0, -2.0, 10.0, -6.0, 14.0, -13.0, 3.0, 11.0, 8.0, -11.0, 11.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18423556243549827, "mean_inference_ms": 1.0624250790775516, "mean_action_processing_ms": 0.07091421414138237, "mean_env_wait_ms": 0.17448393623114883, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 550800, "agent_timesteps_total": 550800, "timers": {"sample_time_ms": 0.076, "sample_throughput": 72505739.484, "learn_time_ms": 14.153, "learn_throughput": 389188.451, "update_time_ms": 6.599}, "info": {"learner": {"learned": {"policy_loss": 1.2845244407653809, "vf_loss": 21.2508544921875, "total_loss": 22.53537940979004, "vf_explained_var": -0.006083965301513672, "model": {}}}, "num_steps_sampled": 550800, "num_agent_steps_sampled": 550800, "num_steps_trained": 550800, "num_agent_steps_trained": 550800}, "done": false, "episodes_total": 10800, "training_iteration": 100, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-04", "timestamp": 1626864484, "time_this_iter_s": 0.36388349533081055, "time_total_s": 36.40697407722473, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 36.40697407722473, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -1.0, 8.0, 1.0, 2.0, -3.0, 4.0, 12.0, -1.0, 11.0, -2.0, 7.0, 0.0, -2.0, 4.0, 13.0, 13.0, -8.0, 10.0, 0.0, -1.0, 8.0, -3.0, 11.0, -5.0, 5.0, 12.0, 3.0, -14.0, 12.0, 4.0, 13.0, 7.0, 11.0, -12.0, 9.0, -8.0, 11.0, 10.0, 2.0, -7.0, 5.0, 11.0, 6.0, 3.0, 13.0, -14.0, 13.0, 7.0, -7.0, 11.0, 4.0, -4.0, 11.0, -3.0, 11.0, -9.0, 4.0, 7.0, 13.0, 3.0, 3.0, -4.0, 13.0, 8.0, 4.0, 10.0, -7.0, 4.0, 10.0, 9.0, -8.0, 8.0, -17.0, 12.0, 12.0, 1.0, 7.0, -6.0, 13.0, 1.0, 11.0, 5.0, -2.0, 7.0, 11.0, 9.0, -12.0, 11.0, 3.0, -11.0, 12.0, -10.0, 13.0, 12.0, 0.0, 5.0, -2.0, 7.0, 5.0, 14.0, 7.0, -18.0, 12.0, -5.0, 7.0, 13.0, 0.0, -14.0, 13.0, 3.0, 13.0, 4.0, 6.0, -2.0, 7.0, 2.0, 10.0, -8.0, 11.0, -10.0, 12.0, 5.0, 8.0, 7.0, 8.0, -13.0, 13.0, 5.0, -3.0, 11.0, 2.0, 9.0, 8.0, 12.0, -14.0, -11.0, 12.0, 6.0, 8.0, -2.0, -2.0, 6.0, 13.0, 8.0, -2.0, 3.0, 6.0, 2.0, -2.0, 5.0, 10.0, -9.0, 8.0, 9.0, 7.0, 3.0, 9.0, -10.0, 13.0, 6.0, -1.0, 4.0, 6.0, 7.0, -4.0, 7.0, 5.0, -12.0, 8.0, 12.0, 7.0, 4.0, 12.0, -11.0, 10.0, 2.0, -2.0, 4.0, 11.0, 1.0, 9.0, -3.0, 8.0, 11.0, 8.0, -16.0, 12.0, -14.0, 13.0, 3.0, 13.0, 7.0, -7.0, 11.0, 4.0, 1.0, 11.0, 6.0, -3.0, -5.0, 5.0, 3.0, 12.0, 8.0, 8.0, -13.0, 12.0, 9.0, 12.0, 12.0, -18.0, 5.0, 9.0, 11.0, -10.0, 2.0, 12.0, 6.0, -5.0, 2.0, 11.0, 12.0, -10.0, 7.0, 8.0, 4.0, -4.0, 2.0, -5.0, 9.0, 9.0, 11.0, 6.0, -5.0, 3.0, -7.0, 12.0, 6.0, 4.0, 13.0, 8.0, -5.0, -1.0, -2.0, 11.0, -5.0, 11.0, -4.0, 10.0, 5.0, 4.0, -11.0, 9.0, 4.0, 13.0, 14.0, -8.0, 10.0, -1.0, 4.0, 11.0, -11.0, 11.0, -15.0, 10.0, 13.0, 7.0, -5.0, 8.0, -1.0, 13.0, 12.0, 3.0, -3.0, 3.0, 8.0, -3.0, 6.0, 4.0, -6.0, 3.0, 13.0, 5.0, -9.0, 10.0, 10.0, 4.0, 5.0, 12.0, -2.0, 0.0, 4.0, 11.0, 10.0, -10.0, 8.0, 3.0, -4.0, 8.0, -10.0, 7.0, 5.0, 13.0, 7.0, 13.0, 5.0, -10.0, -5.0, -3.0, 11.0, 12.0, 2.0, 11.0, 11.0, -9.0, 0.0, 8.0, -6.0, 13.0, 7.0, 6.0, 5.0, -3.0, 6.0, 7.0, -10.0, 12.0, -6.0, 6.0, 3.0, 12.0, -4.0, -2.0, 8.0, 13.0, 8.0, -3.0, 4.0, 6.0, 5.0, -2.0, 1.0, 11.0, 11.0, 10.0, 8.0, -14.0, 6.0, -3.0, -1.0, 13.0, 6.0, 13.0, -5.0, 1.0, 4.0, 10.0, 9.0, -8.0, -10.0, 9.0, 8.0, 8.0, 5.0, 5.0, -7.0, 12.0, 7.0, -2.0, 11.0, -1.0, 0.0, 11.0, 11.0, -7.0, -9.0, 12.0, 8.0, 4.0, -1.0, 9.0, -5.0, 12.0, 13.0, -3.0, 8.0, -3.0, 2.0, 9.0, 11.0, -7.0, 11.0, 3.0, -5.0, 6.0, -13.0, 13.0, 10.0, 5.0, 9.0, 1.0, -6.0, 11.0, 4.0, 9.0, 12.0, -10.0, -8.0, 8.0, 12.0, 3.0, 7.0, 12.0, -11.0, 7.0, 11.0, 4.0, -6.0, 6.0, 8.0, 8.0, 2.0, -3.0, 11.0, 7.0, -9.0, 6.0, -14.0, 13.0, 4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18424821857563234, "mean_inference_ms": 1.0624035131557719, "mean_action_processing_ms": 0.07092440244142643, "mean_env_wait_ms": 0.1745002630392964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 556308, "agent_timesteps_total": 556308, "timers": {"sample_time_ms": 0.073, "sample_throughput": 75196284.573, "learn_time_ms": 14.008, "learn_throughput": 393209.307, "update_time_ms": 6.425}, "info": {"learner": {"learned": {"policy_loss": 108974563328.0, "vf_loss": 125.72166442871094, "total_loss": 108974563328.0, "vf_explained_var": -0.00040340423583984375, "model": {}}}, "num_steps_sampled": 556308, "num_agent_steps_sampled": 556308, "num_steps_trained": 556308, "num_agent_steps_trained": 556308}, "done": false, "episodes_total": 10908, "training_iteration": 101, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-04", "timestamp": 1626864484, "time_this_iter_s": 0.35222554206848145, "time_total_s": 36.75919961929321, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a78c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 36.75919961929321, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 76.9, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.444444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.111111111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 11.0, -3.0, 9.0, 7.0, -11.0, 6.0, 13.0, 3.0, 11.0, 11.0, -10.0, 11.0, -4.0, 11.0, -3.0, 5.0, 13.0, 12.0, -15.0, 13.0, -8.0, 1.0, 9.0, -1.0, 3.0, 11.0, 2.0, -7.0, 13.0, 9.0, 0.0, 5.0, 14.0, -14.0, 10.0, 14.0, 7.0, -13.0, 7.0, -9.0, 0.0, 13.0, 11.0, 4.0, 13.0, 12.0, -14.0, 10.0, 11.0, -17.0, 11.0, 9.0, -6.0, 0.0, 12.0, 8.0, 5.0, -1.0, 3.0, 12.0, 14.0, -20.0, 9.0, 4.0, 11.0, 4.0, -4.0, 13.0, 320.0, 9.0, 13.0, 2.0, 14.0, 4.0, -5.0, -10.0, 13.0, 9.0, 3.0, 12.0, 14.0, 8.0, 321.0, 13.0, -18.0, 8.0, 12.0, 5.0, 0.0, -1.0, 11.0, 6.0, 13.0, -3.0, -1.0, 11.0, 10.0, -17.0, 11.0, 14.0, -6.0, -5.0, 12.0, 5.0, 1.0, 11.0, -2.0, -7.0, 8.0, 10.0, 4.0, 6.0, 14.0, 9.0, -14.0, 7.0, -2.0, 8.0, 2.0, -12.0, 9.0, 11.0, 7.0, 11.0, 2.0, -9.0, 11.0, -11.0, 14.0, 5.0, 7.0, 10.0, -10.0, 2.0, 13.0, 4.0, 8.0, -9.0, 12.0, 14.0, 10.0, 9.0, -18.0, 10.0, 13.0, -2.0, -6.0, 14.0, -4.0, -1.0, 6.0, 2.0, -1.0, 8.0, 6.0, 13.0, -8.0, 12.0, -2.0, 4.0, 13.0, -13.0, 11.0, 14.0, -3.0, 4.0, 0.0, 0.0, -2.0, 6.0, 11.0, 6.0, -2.0, 10.0, 1.0, -15.0, 8.0, 9.0, 13.0, 12.0, 10.0, -11.0, 4.0, 6.0, 12.0, 11.0, -14.0, 7.0, -14.0, 12.0, 10.0, 2.0, -2.0, 5.0, 10.0, 13.0, -5.0, 7.0, 0.0, 11.0, 3.0, 6.0, -5.0, 8.0, 13.0, 1.0, -7.0, 2.0, 11.0, 9.0, -7.0, 9.0, 12.0, 6.0, -12.0, 2.0, -2.0, 4.0, 11.0, 13.0, 14.0, -7.0, -5.0, 9.0, 13.0, 1.0, -8.0, 13.0, 2.0, -11.0, 11.0, -11.0, 7.0, 10.0, 9.0, 13.0, 5.0, -13.0, 10.0, 11.0, 13.0, 8.0, -17.0, 14.0, 2.0, -7.0, 6.0, 4.0, 5.0, -6.0, 12.0, 8.0, 8.0, 11.0, -12.0, 12.0, 14.0, 9.0, 320.0, 14.0, -12.0, 1.0, 12.0, 7.0, 0.0, -1.0, 9.0, 10.0, 12.0, 11.0, -18.0, 6.0, 13.0, 10.0, -14.0, 12.0, 10.0, 7.0, -14.0, 0.0, 7.0, 9.0, -1.0, 11.0, 0.0, 11.0, -7.0, 12.0, 14.0, -17.0, 6.0, 12.0, -18.0, 9.0, 12.0, -12.0, 9.0, 13.0, 5.0, 12.0, -3.0, 9.0, -3.0, 9.0, 10.0, 2.0, -6.0, 11.0, -13.0, 7.0, 10.0, 5.0, 13.0, 7.0, -10.0, 6.0, 14.0, 10.0, -15.0, 0.0, 6.0, -2.0, 11.0, 14.0, -8.0, 6.0, 3.0, -3.0, 8.0, 12.0, -2.0, 7.0, 13.0, 8.0, -13.0, 13.0, 14.0, 6.0, -18.0, 14.0, 10.0, -6.0, -3.0, 3.0, 12.0, 12.0, -12.0, 13.0, 13.0, 8.0, -19.0, 8.0, -4.0, -1.0, 12.0, 14.0, 9.0, -11.0, 3.0, -10.0, 11.0, 5.0, 9.0, -1.0, 13.0, 5.0, -2.0, 9.0, 8.0, -14.0, 12.0, 14.0, -19.0, 8.0, 12.0, 4.0, -6.0, 4.0, 13.0, 13.0, 12.0, 6.0, -16.0, 8.0, -7.0, 4.0, 10.0, 14.0, 2.0, 7.0, -8.0, -5.0, 2.0, 8.0, 10.0, 13.0, 13.0, -18.0, 7.0, 10.0, 13.0, -15.0, 7.0, 14.0, -4.0, 1.0, 4.0, -3.0, 7.0, 0.0, 11.0, 8.0, 7.0, 10.0, -10.0, -16.0, 11.0, 8.0, 12.0, 14.0, -14.0, 7.0, 8.0, -1.0, 3.0, 8.0, 5.0, 8.0, -4.0, 0.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18422714995043787, "mean_inference_ms": 1.0623240044286275, "mean_action_processing_ms": 0.07092297424404073, "mean_env_wait_ms": 0.17448976944038194, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 561816, "agent_timesteps_total": 561816, "timers": {"sample_time_ms": 0.076, "sample_throughput": 72364566.359, "learn_time_ms": 14.054, "learn_throughput": 391907.241, "update_time_ms": 6.297}, "info": {"learner": {"learned": {"policy_loss": 79687598080.0, "vf_loss": 127.04331970214844, "total_loss": 79687598080.0, "vf_explained_var": -0.0008789300918579102, "model": {}}}, "num_steps_sampled": 561816, "num_agent_steps_sampled": 561816, "num_steps_trained": 561816, "num_agent_steps_trained": 561816}, "done": false, "episodes_total": 11016, "training_iteration": 102, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-05", "timestamp": 1626864485, "time_this_iter_s": 0.357729434967041, "time_total_s": 37.116929054260254, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 37.116929054260254, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 9.0, 9.0, -14.0, 6.0, 14.0, 0.0, -5.0, 14.0, 4.0, 5.0, -8.0, 8.0, -3.0, 12.0, -2.0, 2.0, 4.0, 11.0, -2.0, -10.0, 9.0, 13.0, 3.0, 14.0, -12.0, 8.0, 5.0, -8.0, 7.0, 10.0, 6.0, 4.0, 7.0, 7.0, -3.0, 6.0, 13.0, -13.0, 9.0, 11.0, -3.0, 6.0, 1.0, 10.0, 6.0, 6.0, -7.0, 6.0, 7.0, 12.0, -10.0, -1.0, -5.0, 13.0, 8.0, 14.0, 1.0, -5.0, 5.0, -6.0, 6.0, 9.0, 6.0, 9.0, 8.0, 9.0, -11.0, -9.0, 12.0, 7.0, 5.0, 14.0, -19.0, 7.0, 13.0, 4.0, -8.0, 12.0, 7.0, 5.0, 13.0, 7.0, -10.0, -15.0, 13.0, 5.0, 12.0, 9.0, -12.0, 6.0, 12.0, 0.0, -6.0, 12.0, 9.0, 5.0, 8.0, 9.0, -7.0, -9.0, 3.0, 8.0, 13.0, 12.0, 10.0, 2.0, -9.0, -9.0, 9.0, 11.0, 4.0, 8.0, 5.0, -7.0, 9.0, 7.0, 0.0, 0.0, 8.0, 10.0, 1.0, -8.0, 12.0, -13.0, 14.0, 12.0, 2.0, 8.0, 13.0, 1.0, -7.0, -9.0, 13.0, 3.0, 8.0, 13.0, -11.0, 5.0, 8.0, 6.0, -8.0, 8.0, 9.0, 9.0, 8.0, -8.0, 6.0, -9.0, 8.0, 5.0, 11.0, 9.0, -4.0, 6.0, 4.0, 8.0, 5.0, -7.0, 9.0, 7.0, 12.0, 11.0, -15.0, -16.0, 13.0, 11.0, 7.0, 13.0, 5.0, 3.0, -6.0, 12.0, -16.0, 10.0, 9.0, 6.0, 13.0, -6.0, 2.0, -12.0, 7.0, 8.0, 12.0, 13.0, -12.0, 5.0, 9.0, 4.0, -9.0, 11.0, 9.0, 8.0, 8.0, 6.0, -7.0, -6.0, 9.0, 8.0, 4.0, 12.0, -11.0, 11.0, 3.0, 5.0, -6.0, 10.0, 6.0, 9.0, 9.0, -11.0, 8.0, 1.0, -5.0, 9.0, 10.0, 12.0, 0.0, -9.0, 12.0, 10.0, -12.0, 6.0, 11.0, 1.0, 9.0, 8.0, -3.0, -11.0, 12.0, 7.0, 7.0, 10.0, -13.0, 6.0, 12.0, 5.0, -1.0, 5.0, 6.0, 5.0, 8.0, -4.0, 6.0, 0.0, 12.0, 11.0, -8.0, 11.0, -15.0, 12.0, 7.0, 3.0, -4.0, 5.0, 11.0, 12.0, 7.0, 10.0, -14.0, 9.0, 12.0, -16.0, 10.0, -2.0, 7.0, 11.0, -1.0, 7.0, -7.0, 4.0, 11.0, 11.0, 4.0, 8.0, -8.0, -12.0, 12.0, 3.0, 12.0, 10.0, -14.0, 7.0, 12.0, 6.0, -8.0, 10.0, 7.0, 7.0, 9.0, -2.0, 1.0, -8.0, 13.0, 7.0, 3.0, -11.0, 9.0, 11.0, 6.0, -11.0, 8.0, 12.0, 6.0, 2.0, 4.0, -3.0, 12.0, 11.0, 0.0, -2.0, 6.0, 13.0, -8.0, 3.0, 7.0, 8.0, 5.0, -9.0, 11.0, 10.0, 8.0, -5.0, 2.0, 7.0, 13.0, -11.0, 6.0, 9.0, -15.0, 11.0, 10.0, 7.0, 10.0, -3.0, 1.0, 10.0, -1.0, 13.0, -7.0, 11.0, 12.0, -11.0, 3.0, 13.0, -3.0, 3.0, 2.0, 6.0, -11.0, 12.0, 8.0, 10.0, 8.0, -2.0, -1.0, 5.0, 10.0, -10.0, 10.0, 12.0, 3.0, -5.0, 5.0, 5.0, 11.0, -3.0, 2.0, 8.0, 5.0, -7.0, 9.0, -6.0, 12.0, -2.0, 11.0, 13.0, -1.0, 11.0, -8.0, 3.0, 8.0, 11.0, -7.0, 5.0, 9.0, 11.0, -10.0, -9.0, 13.0, 1.0, 10.0, 12.0, -13.0, 9.0, 7.0, 9.0, -12.0, 10.0, 8.0, 2.0, 7.0, -1.0, 7.0, -14.0, 7.0, 12.0, 10.0, 14.0, -9.0, 5.0, 5.0, 11.0, -13.0, 13.0, 4.0, 4.0, 9.0, 13.0, -11.0, -15.0, 8.0, 9.0, 13.0, 13.0, -11.0, 5.0, 8.0, 1.0, -5.0, 11.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18423160930373006, "mean_inference_ms": 1.0625184858653054, "mean_action_processing_ms": 0.07093091257479331, "mean_env_wait_ms": 0.17449999737824162, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 567324, "agent_timesteps_total": 567324, "timers": {"sample_time_ms": 0.079, "sample_throughput": 70072591.94, "learn_time_ms": 14.471, "learn_throughput": 380613.114, "update_time_ms": 6.502}, "info": {"learner": {"learned": {"policy_loss": 1.2391117811203003, "vf_loss": 19.264806747436523, "total_loss": 20.503917694091797, "vf_explained_var": -0.007590055465698242, "model": {}}}, "num_steps_sampled": 567324, "num_agent_steps_sampled": 567324, "num_steps_trained": 567324, "num_agent_steps_trained": 567324}, "done": false, "episodes_total": 11124, "training_iteration": 103, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-05", "timestamp": 1626864485, "time_this_iter_s": 0.3739438056945801, "time_total_s": 37.490872859954834, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18271ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 37.490872859954834, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 73.5, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 353.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.12962962962963, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.532407407407407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 1.0, 12.0, -10.0, 13.0, -16.0, 7.0, 11.0, 10.0, 7.0, -7.0, 5.0, -9.0, 6.0, 7.0, 11.0, 11.0, -8.0, 11.0, 1.0, 8.0, -9.0, 11.0, 5.0, -1.0, 5.0, 4.0, 7.0, 7.0, 13.0, -1.0, -4.0, 7.0, 7.0, 11.0, -10.0, 11.0, 5.0, 9.0, -10.0, 13.0, 0.0, -5.0, 7.0, -10.0, 13.0, 7.0, 5.0, 6.0, -8.0, 7.0, 10.0, -7.0, 13.0, 12.0, -3.0, 8.0, 8.0, 4.0, -5.0, -6.0, 13.0, 2.0, 6.0, 3.0, 14.0, -10.0, 8.0, 13.0, 12.0, 0.0, -10.0, 7.0, 9.0, 5.0, -6.0, -10.0, 13.0, 5.0, 7.0, 2.0, 9.0, 8.0, -4.0, 12.0, -12.0, 5.0, 10.0, 12.0, 7.0, -12.0, 8.0, -2.0, 14.0, 7.0, -4.0, 7.0, -4.0, 1.0, 11.0, 8.0, 7.0, 5.0, -5.0, 1.0, 10.0, 9.0, -5.0, 3.0, 13.0, 4.0, -5.0, 12.0, 2.0, 12.0, -11.0, 6.0, 12.0, 9.0, -12.0, 3.0, 9.0, -9.0, 12.0, 6.0, 14.0, -14.0, 9.0, 0.0, 13.0, -5.0, 7.0, -8.0, 7.0, 8.0, 8.0, 12.0, 5.0, -12.0, 10.0, 10.0, 13.0, 12.0, -20.0, 7.0, 6.0, -9.0, 11.0, 8.0, -8.0, 9.0, 6.0, 7.0, 10.0, 6.0, -8.0, -4.0, 13.0, 8.0, -2.0, -8.0, 3.0, 12.0, 8.0, 13.0, 316.0, 11.0, 13.0, 12.0, 12.0, -15.0, 6.0, -3.0, 11.0, 5.0, 2.0, -9.0, 7.0, 11.0, 6.0, 4.0, 7.0, -5.0, 9.0, -6.0, 5.0, 7.0, 9.0, -3.0, 14.0, 7.0, -3.0, 2.0, 3.0, 11.0, -1.0, 1.0, 7.0, -2.0, 9.0, 11.0, 6.0, 8.0, -10.0, -17.0, 13.0, 12.0, 7.0, 8.0, 8.0, 8.0, -9.0, 13.0, -15.0, 5.0, 12.0, 13.0, -9.0, 5.0, 6.0, -3.0, 14.0, -7.0, 11.0, -8.0, 4.0, 11.0, 8.0, -4.0, 10.0, 4.0, 5.0, 11.0, 9.0, -10.0, 5.0, 6.0, 13.0, 4.0, -8.0, 8.0, -13.0, 9.0, 11.0, 8.0, -6.0, 5.0, 8.0, -7.0, 8.0, 11.0, 3.0, -3.0, 12.0, 9.0, -3.0, -14.0, 8.0, 11.0, 10.0, 9.0, -11.0, 12.0, 5.0, 4.0, 8.0, -3.0, 6.0, 11.0, 4.0, -6.0, 6.0, -6.0, 2.0, 11.0, 8.0, 13.0, -6.0, -1.0, 9.0, -10.0, 5.0, 8.0, 12.0, 7.0, 13.0, -7.0, 2.0, -1.0, 11.0, 9.0, -4.0, 3.0, 11.0, -3.0, 4.0, 8.0, -10.0, 5.0, 12.0, -5.0, 13.0, 12.0, -5.0, 8.0, 9.0, -8.0, 6.0, 12.0, 0.0, 12.0, -9.0, 13.0, 9.0, 5.0, -12.0, 7.0, 14.0, 1.0, -7.0, 1.0, -8.0, 10.0, 12.0, 13.0, 5.0, 3.0, -6.0, 13.0, 9.0, -14.0, 7.0, -10.0, 13.0, 5.0, 7.0, 2.0, 9.0, -5.0, 9.0, 12.0, 7.0, 2.0, -6.0, 13.0, -13.0, 7.0, 8.0, -13.0, 12.0, 5.0, 11.0, 7.0, 13.0, 9.0, -14.0, 4.0, 7.0, 8.0, -4.0, 13.0, 6.0, -10.0, 6.0, -11.0, 14.0, 7.0, 5.0, 1.0, 10.0, 7.0, -3.0, 6.0, 9.0, -10.0, 10.0, 2.0, 10.0, -3.0, 6.0, -1.0, 14.0, -7.0, 9.0, 6.0, 8.0, 10.0, -9.0, 12.0, 7.0, -7.0, 3.0, 13.0, 6.0, 3.0, -7.0, 10.0, 14.0, 4.0, -13.0, 2.0, 7.0, -4.0, 10.0, 6.0, -8.0, 12.0, 5.0, 13.0, 11.0, -14.0, 5.0, 5.0, 13.0, 4.0, -7.0, 8.0, 1.0, 11.0, -5.0, 12.0, 6.0, -10.0, 7.0, 12.0, 6.0, 12.0, -15.0, -11.0, 13.0, 7.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18425607825526102, "mean_inference_ms": 1.0626465820126687, "mean_action_processing_ms": 0.07093962968728532, "mean_env_wait_ms": 0.1744849140236178, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 572832, "agent_timesteps_total": 572832, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67755828.446, "learn_time_ms": 14.606, "learn_throughput": 377097.323, "update_time_ms": 6.58}, "info": {"learner": {"learned": {"policy_loss": 1.2818328142166138, "vf_loss": 19.069429397583008, "total_loss": 20.35126304626465, "vf_explained_var": -0.006673216819763184, "model": {}}}, "num_steps_sampled": 572832, "num_agent_steps_sampled": 572832, "num_steps_trained": 572832, "num_agent_steps_trained": 572832}, "done": false, "episodes_total": 11232, "training_iteration": 104, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-05", "timestamp": 1626864485, "time_this_iter_s": 0.3631415367126465, "time_total_s": 37.85401439666748, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a2297e620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 37.85401439666748, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.453703703703702, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 6.113425925925926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [2.0, 9.0, -7.0, 11.0, -9.0, 8.0, 8.0, 8.0, 11.0, -12.0, 10.0, 6.0, 3.0, -5.0, 8.0, 9.0, 10.0, 6.0, -12.0, 11.0, -11.0, 13.0, 5.0, 8.0, 11.0, 3.0, 9.0, -8.0, -13.0, 6.0, 10.0, 12.0, -6.0, 8.0, 1.0, 12.0, 9.0, -9.0, 7.0, 8.0, 12.0, 5.0, 4.0, -6.0, 13.0, 8.0, 10.0, -16.0, -3.0, 14.0, -4.0, 8.0, 10.0, 12.0, 0.0, -7.0, 9.0, -4.0, 6.0, 4.0, -10.0, 10.0, 2.0, 13.0, 13.0, 5.0, -11.0, 8.0, 4.0, -6.0, 10.0, 7.0, 13.0, -12.0, 10.0, 4.0, 13.0, 8.0, 7.0, -13.0, 11.0, 10.0, -14.0, 8.0, -14.0, 14.0, 11.0, 4.0, 14.0, -1.0, 9.0, -7.0, -3.0, 7.0, -2.0, 13.0, -15.0, 11.0, 8.0, 11.0, 5.0, 8.0, 10.0, -8.0, 13.0, -9.0, 6.0, 5.0, -9.0, 6.0, 9.0, 9.0, -13.0, 8.0, 8.0, 12.0, -11.0, 14.0, 5.0, 7.0, 12.0, -14.0, 12.0, 5.0, 7.0, -11.0, 7.0, 12.0, -5.0, 13.0, -1.0, 8.0, 4.0, 10.0, -4.0, 5.0, 10.0, -15.0, 11.0, 9.0, -2.0, 12.0, 12.0, -7.0, -9.0, 7.0, 5.0, 12.0, 5.0, 11.0, -10.0, 9.0, 12.0, -17.0, 7.0, 13.0, -8.0, 4.0, 7.0, 12.0, 10.0, 9.0, -11.0, 7.0, -20.0, 14.0, 8.0, 13.0, 14.0, 2.0, 5.0, -6.0, 7.0, -9.0, 5.0, 12.0, -2.0, 9.0, 7.0, 1.0, -18.0, 14.0, 7.0, 12.0, 11.0, 4.0, 7.0, -7.0, -16.0, 11.0, 8.0, 12.0, 12.0, 8.0, -17.0, 12.0, 1.0, 10.0, -5.0, 9.0, 11.0, -1.0, -8.0, 13.0, -10.0, 8.0, 9.0, 8.0, 11.0, 8.0, -13.0, 9.0, 2.0, 10.0, 9.0, -6.0, 13.0, 321.0, 11.0, 10.0, -11.0, 11.0, 2.0, 13.0, -6.0, 9.0, 2.0, 10.0, 0.0, 14.0, -9.0, 10.0, 10.0, 0.0, 11.0, -6.0, -9.0, 5.0, 6.0, 13.0, 12.0, 9.0, -18.0, 12.0, 0.0, -3.0, 11.0, 7.0, 11.0, 5.0, 11.0, -12.0, 9.0, 9.0, -15.0, 12.0, 2.0, 9.0, -8.0, 12.0, 1.0, 14.0, 13.0, -13.0, 11.0, -4.0, 11.0, -3.0, 3.0, 9.0, -10.0, 13.0, -4.0, 12.0, -5.0, 12.0, -9.0, 14.0, 3.0, 7.0, 12.0, 2.0, 4.0, -3.0, -7.0, 9.0, 8.0, 5.0, 13.0, 12.0, -13.0, 3.0, -15.0, 14.0, 9.0, 7.0, 12.0, -1.0, 10.0, -6.0, 7.0, -10.0, 6.0, 12.0, 6.0, 8.0, -6.0, 7.0, 6.0, 11.0, 9.0, -11.0, 10.0, -13.0, 11.0, 7.0, 8.0, -9.0, 8.0, 8.0, 320.0, 13.0, 10.0, 12.0, 7.0, 11.0, 2.0, -5.0, 14.0, -3.0, 10.0, -6.0, -13.0, 12.0, 8.0, 8.0, -6.0, 13.0, -4.0, 12.0, 1.0, 10.0, 12.0, -8.0, 10.0, -7.0, 8.0, 4.0, -8.0, 6.0, 5.0, 12.0, 2.0, 8.0, -7.0, 12.0, -8.0, 9.0, 7.0, 7.0, 11.0, 5.0, 12.0, -13.0, 1.0, -7.0, 12.0, 9.0, 322.0, 13.0, 9.0, 12.0, -8.0, 11.0, 11.0, 1.0, 10.0, 6.0, 11.0, -12.0, -5.0, 7.0, 8.0, 5.0, 11.0, 5.0, -7.0, 6.0, 6.0, 10.0, 9.0, -10.0, -2.0, 7.0, 6.0, 4.0, 6.0, -6.0, 3.0, 12.0, -2.0, 8.0, 2.0, 7.0, -6.0, 7.0, 6.0, 8.0, 11.0, 2.0, 9.0, -7.0, 5.0, -8.0, 6.0, 12.0, -2.0, 4.0, 3.0, 10.0, -6.0, 13.0, 0.0, 8.0, 13.0, 5.0, -10.0, 7.0, -3.0, 2.0, 8.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18426763931349155, "mean_inference_ms": 1.0625529128930467, "mean_action_processing_ms": 0.07093308748248146, "mean_env_wait_ms": 0.17446900247091127, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 578340, "agent_timesteps_total": 578340, "timers": {"sample_time_ms": 0.081, "sample_throughput": 67795692.574, "learn_time_ms": 14.532, "learn_throughput": 379023.893, "update_time_ms": 7.075}, "info": {"learner": {"learned": {"policy_loss": 1.2818360328674316, "vf_loss": 21.247596740722656, "total_loss": 22.52943229675293, "vf_explained_var": -0.006209135055541992, "model": {}}}, "num_steps_sampled": 578340, "num_agent_steps_sampled": 578340, "num_steps_trained": 578340, "num_agent_steps_trained": 578340}, "done": false, "episodes_total": 11340, "training_iteration": 105, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-06", "timestamp": 1626864486, "time_this_iter_s": 0.3672809600830078, "time_total_s": 38.22129535675049, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182862f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 38.22129535675049, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 77.4, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, 11.0, -16.0, 6.0, 14.0, -9.0, -2.0, 12.0, 3.0, 9.0, -7.0, 10.0, 13.0, -13.0, 11.0, 4.0, 13.0, 13.0, 2.0, -13.0, 10.0, 0.0, -7.0, 12.0, 6.0, 10.0, -13.0, 12.0, 12.0, -5.0, 11.0, -3.0, 6.0, 12.0, -10.0, 7.0, 10.0, 1.0, 12.0, -8.0, 5.0, -3.0, 4.0, 9.0, 6.0, -6.0, 9.0, 6.0, 12.0, 7.0, 8.0, -12.0, 14.0, -10.0, 0.0, 11.0, 7.0, 7.0, -9.0, 10.0, 9.0, -9.0, 2.0, 13.0, 13.0, 12.0, 6.0, -16.0, 5.0, -14.0, 11.0, 13.0, 3.0, 11.0, 7.0, -6.0, 10.0, -7.0, 0.0, 12.0, 13.0, 6.0, 6.0, -10.0, 10.0, 8.0, -13.0, 10.0, 3.0, 4.0, 10.0, -2.0, 10.0, -4.0, -1.0, 10.0, 12.0, 13.0, -15.0, 5.0, 14.0, 0.0, 12.0, -11.0, 4.0, 3.0, -1.0, 9.0, -2.0, 6.0, -1.0, 12.0, 13.0, 6.0, 6.0, -10.0, 13.0, 1.0, -10.0, 11.0, 3.0, -8.0, 9.0, 11.0, 9.0, -11.0, 6.0, 11.0, 6.0, 6.0, 9.0, -6.0, 9.0, 3.0, 13.0, -10.0, 9.0, -16.0, 10.0, 12.0, -3.0, 7.0, -1.0, 12.0, 9.0, 11.0, 10.0, -15.0, 3.0, 6.0, -4.0, 10.0, 4.0, -6.0, 5.0, 12.0, 11.0, -8.0, 0.0, 12.0, 8.0, 14.0, 4.0, -11.0, 9.0, -17.0, 10.0, 13.0, 3.0, 11.0, 3.0, -2.0, 9.0, 7.0, 7.0, -8.0, 11.0, 11.0, 8.0, -15.0, 6.0, -15.0, 13.0, 11.0, 1.0, -8.0, 10.0, 12.0, 12.0, -2.0, -4.0, 9.0, 13.0, 9.0, 9.0, -16.0, 9.0, -13.0, 11.0, 8.0, 14.0, 2.0, 6.0, -7.0, 11.0, -9.0, 0.0, 13.0, 10.0, 12.0, 1.0, -8.0, 14.0, -3.0, 13.0, -9.0, 9.0, -1.0, -1.0, 8.0, 12.0, -5.0, 12.0, -4.0, 8.0, 13.0, 9.0, -15.0, 9.0, 9.0, 10.0, -13.0, 7.0, -7.0, 13.0, 2.0, 10.0, -9.0, 2.0, 12.0, 12.0, 12.0, 4.0, -13.0, 9.0, 1.0, 10.0, -5.0, 3.0, 12.0, 4.0, -4.0, -4.0, 0.0, 11.0, 8.0, -9.0, 13.0, 4.0, 7.0, 14.0, -14.0, 3.0, 12.0, 4.0, 2.0, 10.0, -1.0, -2.0, 11.0, 12.0, -6.0, -7.0, 12.0, 0.0, 10.0, 10.0, 3.0, -8.0, 10.0, 9.0, 6.0, 5.0, -5.0, 9.0, -10.0, 4.0, 12.0, 12.0, 9.0, 4.0, -10.0, 7.0, -15.0, 13.0, 10.0, 11.0, 2.0, -9.0, 11.0, 10.0, -2.0, -5.0, 12.0, 7.0, 13.0, 5.0, -10.0, 14.0, -5.0, -4.0, 10.0, 14.0, 1.0, 9.0, -9.0, -3.0, 4.0, 1.0, 13.0, 1.0, 11.0, 9.0, -6.0, 10.0, 6.0, -12.0, 11.0, 13.0, 3.0, 2.0, -3.0, -3.0, 10.0, 0.0, 8.0, 8.0, 13.0, -11.0, 5.0, 14.0, -11.0, 11.0, 1.0, 8.0, 10.0, -10.0, 7.0, 11.0, -3.0, -6.0, 13.0, -1.0, 11.0, 11.0, -6.0, 10.0, -11.0, 4.0, 12.0, -2.0, 11.0, -6.0, 12.0, 10.0, -9.0, 8.0, 6.0, 13.0, 8.0, 9.0, -15.0, 9.0, -12.0, 11.0, 7.0, -1.0, -8.0, 12.0, 12.0, 9.0, -9.0, 9.0, 6.0, 12.0, 8.0, 9.0, -14.0, 14.0, -15.0, 6.0, 10.0, 8.0, -10.0, 11.0, 6.0, 10.0, -12.0, 11.0, 6.0, 8.0, 13.0, -8.0, 2.0, 14.0, 0.0, 3.0, -2.0, 8.0, 1.0, 9.0, -3.0, -4.0, 4.0, 13.0, 2.0, 9.0, 11.0, 7.0, -12.0, 14.0, -9.0, 4.0, 6.0, 1.0, 11.0, 11.0, -8.0, 11.0, -13.0, 12.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18426677864742758, "mean_inference_ms": 1.0624114603946258, "mean_action_processing_ms": 0.07093076516055266, "mean_env_wait_ms": 0.17446493648201564, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 583848, "agent_timesteps_total": 583848, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69497631.291, "learn_time_ms": 14.128, "learn_throughput": 389861.645, "update_time_ms": 6.896}, "info": {"learner": {"learned": {"policy_loss": 1.3248831033706665, "vf_loss": 19.712297439575195, "total_loss": 21.037179946899414, "vf_explained_var": -0.004611015319824219, "model": {}}}, "num_steps_sampled": 583848, "num_agent_steps_sampled": 583848, "num_steps_trained": 583848, "num_agent_steps_trained": 583848}, "done": false, "episodes_total": 11448, "training_iteration": 106, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-06", "timestamp": 1626864486, "time_this_iter_s": 0.3567655086517334, "time_total_s": 38.57806086540222, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a78c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 38.57806086540222, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 76.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, -2.0, 1.0, 12.0, 10.0, -6.0, 12.0, -1.0, -11.0, 5.0, 11.0, 10.0, 1.0, 11.0, -6.0, 9.0, 5.0, -15.0, 12.0, 13.0, 10.0, 1.0, 6.0, -2.0, -12.0, 10.0, 5.0, 12.0, 2.0, 12.0, -3.0, 4.0, 10.0, -14.0, 7.0, 12.0, 9.0, 3.0, 6.0, -3.0, 10.0, -7.0, 5.0, 7.0, -11.0, 10.0, 8.0, 8.0, 10.0, -8.0, 5.0, 8.0, -5.0, 2.0, 6.0, 12.0, 5.0, 14.0, 6.0, -10.0, 0.0, 8.0, 8.0, -1.0, 6.0, -8.0, 10.0, 7.0, 10.0, 0.0, 6.0, -1.0, -15.0, 11.0, 8.0, 11.0, 14.0, -1.0, -6.0, 8.0, 11.0, -4.0, 0.0, 8.0, 9.0, 1.0, -7.0, 12.0, 3.0, 5.0, -2.0, 9.0, 3.0, -6.0, 10.0, 8.0, 7.0, -12.0, 8.0, 12.0, 9.0, -4.0, 12.0, -2.0, -12.0, 4.0, 12.0, 11.0, 7.0, -10.0, 11.0, 7.0, -9.0, 7.0, 6.0, 11.0, 11.0, -5.0, 12.0, -3.0, -15.0, 13.0, 8.0, 9.0, -9.0, 5.0, 8.0, 11.0, -7.0, 7.0, 3.0, 12.0, 4.0, 11.0, 2.0, -2.0, -14.0, 11.0, 11.0, 7.0, 14.0, 8.0, 4.0, -11.0, 10.0, -13.0, 11.0, 7.0, 11.0, -6.0, 12.0, -2.0, -14.0, 11.0, 10.0, 8.0, 9.0, 4.0, -6.0, 8.0, 12.0, -11.0, 6.0, 8.0, 10.0, 332.0, 12.0, 13.0, -12.0, 5.0, 10.0, 12.0, 14.0, 7.0, -5.0, -1.0, 5.0, -5.0, 7.0, 8.0, 6.0, -9.0, 5.0, 13.0, -12.0, 12.0, 10.0, 5.0, 8.0, 8.0, -3.0, 2.0, -2.0, 8.0, -2.0, 11.0, 11.0, 7.0, -1.0, -2.0, 6.0, 3.0, -6.0, 12.0, 10.0, -13.0, 6.0, 12.0, 8.0, -7.0, 6.0, 8.0, 10.0, 1.0, -5.0, 9.0, 0.0, 11.0, -4.0, 8.0, -2.0, 11.0, -1.0, 7.0, -1.0, -1.0, 5.0, 12.0, 7.0, 3.0, 6.0, -1.0, 2.0, 10.0, -2.0, 5.0, 9.0, 11.0, 4.0, -9.0, 7.0, -5.0, 8.0, 5.0, 10.0, 0.0, 8.0, -3.0, -7.0, 6.0, 5.0, 11.0, 13.0, -9.0, 4.0, 7.0, 4.0, -9.0, 7.0, 13.0, 10.0, 12.0, -4.0, -3.0, -14.0, 7.0, 12.0, 10.0, 8.0, -10.0, 9.0, 8.0, 1.0, -1.0, 8.0, 7.0, 11.0, -1.0, 6.0, -1.0, -6.0, 4.0, 5.0, 12.0, 9.0, 5.0, -1.0, 2.0, 11.0, -10.0, 8.0, 6.0, 6.0, 6.0, 5.0, -2.0, 2.0, -8.0, 10.0, 11.0, 14.0, 6.0, -12.0, 7.0, -7.0, 2.0, 8.0, 12.0, 10.0, -17.0, 10.0, 12.0, 3.0, -7.0, 7.0, 12.0, 11.0, 5.0, -8.0, 7.0, 8.0, 8.0, -14.0, 13.0, 10.0, -18.0, 11.0, 12.0, -12.0, 12.0, 5.0, 10.0, 9.0, 10.0, -11.0, 7.0, -9.0, 8.0, 3.0, 13.0, 10.0, 2.0, -9.0, 12.0, -12.0, 9.0, 12.0, 6.0, 12.0, 9.0, -3.0, -3.0, 6.0, -8.0, 10.0, 7.0, -3.0, 0.0, 7.0, 11.0, 4.0, 3.0, 11.0, -3.0, -13.0, 13.0, 12.0, 3.0, 12.0, -16.0, 7.0, 12.0, 8.0, 12.0, -4.0, -1.0, -11.0, 4.0, 11.0, 11.0, 9.0, 11.0, -3.0, -2.0, 7.0, -12.0, 7.0, 13.0, -3.0, 1.0, 5.0, 12.0, -11.0, 12.0, 2.0, 12.0, 9.0, -8.0, 2.0, 12.0, -7.0, 11.0, 8.0, 3.0, -5.0, 6.0, 3.0, 11.0, -13.0, 12.0, 5.0, 11.0, 7.0, 9.0, -8.0, 7.0, -3.0, 9.0, 1.0, 8.0, 9.0, 3.0, 5.0, -2.0, 2.0, -7.0, 11.0, 9.0, 8.0, 3.0, -7.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18424147138952643, "mean_inference_ms": 1.062330203542143, "mean_action_processing_ms": 0.07092256201513118, "mean_env_wait_ms": 0.17444533920924316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 589356, "agent_timesteps_total": 589356, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69559067.978, "learn_time_ms": 14.16, "learn_throughput": 388969.59, "update_time_ms": 6.512}, "info": {"learner": {"learned": {"policy_loss": 1.2612199783325195, "vf_loss": 21.852964401245117, "total_loss": 23.114185333251953, "vf_explained_var": -0.0048291683197021484, "model": {}}}, "num_steps_sampled": 589356, "num_agent_steps_sampled": 589356, "num_steps_trained": 589356, "num_agent_steps_trained": 589356}, "done": false, "episodes_total": 11556, "training_iteration": 107, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-07", "timestamp": 1626864487, "time_this_iter_s": 0.3471531867980957, "time_total_s": 38.92521405220032, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 38.92521405220032, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 0.0, 9.0, -3.0, -2.0, 11.0, -7.0, 13.0, 14.0, 9.0, -16.0, 8.0, 11.0, 7.0, -14.0, 11.0, 4.0, 5.0, 11.0, -5.0, 7.0, 10.0, 10.0, -12.0, 9.0, -2.0, 5.0, 3.0, 11.0, 6.0, -15.0, 13.0, 13.0, 2.0, 8.0, -8.0, -1.0, 8.0, 13.0, -5.0, 5.0, -3.0, 5.0, 8.0, -4.0, 12.0, -6.0, 13.0, 1.0, 5.0, 12.0, -3.0, -2.0, 13.0, 10.0, -6.0, 9.0, 5.0, 9.0, -8.0, 11.0, 5.0, 12.0, -13.0, 3.0, 7.0, 10.0, -5.0, 7.0, -8.0, 4.0, 12.0, 7.0, 12.0, 4.0, -8.0, -14.0, 5.0, 12.0, 12.0, 13.0, -17.0, 12.0, 7.0, 5.0, -2.0, 9.0, 3.0, -8.0, 9.0, 6.0, 8.0, 6.0, -15.0, 11.0, 13.0, 6.0, -8.0, 12.0, 5.0, 12.0, 11.0, 11.0, -19.0, 14.0, 10.0, 5.0, -14.0, -8.0, 8.0, 12.0, 3.0, 13.0, -1.0, 8.0, -5.0, 8.0, -4.0, 12.0, -1.0, -2.0, 11.0, 10.0, -4.0, 4.0, 7.0, -9.0, 13.0, 5.0, -9.0, 11.0, 8.0, 7.0, -9.0, 5.0, 12.0, 10.0, 9.0, 7.0, -11.0, -3.0, -1.0, 7.0, 12.0, -7.0, 7.0, 12.0, 3.0, -2.0, 9.0, 13.0, -5.0, 9.0, 10.0, 5.0, -9.0, 5.0, 13.0, -14.0, 11.0, 9.0, -11.0, 10.0, 7.0, 10.0, -4.0, 12.0, -3.0, 14.0, 8.0, -1.0, -6.0, -6.0, 8.0, 12.0, 1.0, -14.0, 8.0, 13.0, 8.0, 11.0, 11.0, 12.0, 322.0, 3.0, -3.0, 12.0, 3.0, 11.0, 9.0, -17.0, 12.0, 1.0, 12.0, -3.0, 5.0, 11.0, -3.0, 12.0, -5.0, 8.0, -3.0, 7.0, 3.0, -2.0, -5.0, 11.0, 11.0, 8.0, 8.0, 11.0, -12.0, -2.0, 13.0, 10.0, -6.0, 14.0, 3.0, 7.0, -9.0, -4.0, -1.0, 7.0, 13.0, 13.0, 318.0, 13.0, 10.0, -7.0, 11.0, 12.0, -1.0, 14.0, 13.0, 1.0, -13.0, -11.0, 12.0, 8.0, 6.0, 9.0, -2.0, -1.0, 9.0, 11.0, -1.0, -7.0, 12.0, 14.0, 12.0, 3.0, -14.0, -1.0, 6.0, 12.0, -2.0, 5.0, -8.0, 11.0, 7.0, 11.0, 13.0, 2.0, -11.0, 7.0, 9.0, -14.0, 13.0, -10.0, 7.0, 5.0, 13.0, 1.0, 9.0, 9.0, -4.0, 10.0, -7.0, -1.0, 13.0, -3.0, -3.0, 11.0, 10.0, -2.0, 2.0, 10.0, 5.0, 2.0, -7.0, 11.0, 9.0, 12.0, 8.0, -8.0, 3.0, 2.0, 12.0, 10.0, -9.0, 11.0, 10.0, 12.0, -18.0, -1.0, 10.0, 10.0, -4.0, -6.0, 11.0, -1.0, 11.0, 9.0, -8.0, 3.0, 11.0, 7.0, 9.0, -14.0, 13.0, 9.0, 0.0, 10.0, -4.0, -2.0, 12.0, -8.0, 13.0, 9.0, 8.0, 11.0, -13.0, 4.0, 13.0, 11.0, -13.0, 3.0, 4.0, 11.0, -3.0, 6.0, 8.0, -11.0, 12.0, 14.0, -3.0, 4.0, 0.0, 2.0, 5.0, 12.0, -4.0, 3.0, 6.0, 10.0, -4.0, 11.0, -5.0, -2.0, 11.0, -18.0, 11.0, 9.0, 13.0, -8.0, 1.0, 9.0, 13.0, 9.0, -15.0, 12.0, 9.0, -3.0, 12.0, 11.0, -5.0, 9.0, -9.0, 4.0, 11.0, -7.0, 13.0, -1.0, 10.0, -8.0, 3.0, 11.0, 9.0, 10.0, -4.0, 5.0, 4.0, 6.0, -11.0, 10.0, 10.0, 9.0, 2.0, 12.0, -8.0, 6.0, 1.0, 12.0, -4.0, 6.0, -8.0, 7.0, 10.0, 9.0, -5.0, 9.0, 2.0, -2.0, 4.0, 0.0, 13.0, 3.0, 3.0, 12.0, -3.0, 11.0, -7.0, 12.0, -1.0, -8.0, 7.0, 8.0, 8.0, 6.0, 13.0, -16.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18424286882239524, "mean_inference_ms": 1.0622196456604025, "mean_action_processing_ms": 0.0709214939098637, "mean_env_wait_ms": 0.17444270942077889, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 594864, "agent_timesteps_total": 594864, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70815301.913, "learn_time_ms": 14.222, "learn_throughput": 387290.492, "update_time_ms": 6.354}, "info": {"learner": {"learned": {"policy_loss": 109661732864.0, "vf_loss": 132.0401611328125, "total_loss": 109661732864.0, "vf_explained_var": -0.0006011724472045898, "model": {}}}, "num_steps_sampled": 594864, "num_agent_steps_sampled": 594864, "num_steps_trained": 594864, "num_agent_steps_trained": 594864}, "done": false, "episodes_total": 11664, "training_iteration": 108, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-07", "timestamp": 1626864487, "time_this_iter_s": 0.3520393371582031, "time_total_s": 39.27725338935852, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7d08>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 39.27725338935852, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 74.5, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 34.01851851851852, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 8.50462962962963}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 367.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 5.0, -13.0, 12.0, 12.0, -4.0, 7.0, 0.0, 12.0, 320.0, 12.0, 12.0, 13.0, -12.0, 11.0, 3.0, 13.0, 10.0, 11.0, -19.0, 12.0, -5.0, 3.0, 5.0, 13.0, -10.0, 4.0, 8.0, 11.0, -6.0, 7.0, 3.0, 10.0, 10.0, 11.0, -16.0, 12.0, -1.0, 10.0, -6.0, 12.0, -18.0, 13.0, 8.0, 9.0, -6.0, 5.0, 7.0, 14.0, -6.0, 3.0, 4.0, -1.0, 8.0, -3.0, 11.0, 12.0, 9.0, -9.0, 3.0, -2.0, 7.0, 4.0, 6.0, 14.0, -9.0, 3.0, 7.0, 11.0, 4.0, -10.0, 10.0, 9.0, -1.0, -2.0, 9.0, 14.0, 7.0, 11.0, -17.0, 12.0, 4.0, 12.0, -13.0, 11.0, -5.0, 1.0, 8.0, 12.0, 317.0, 13.0, 13.0, 13.0, 12.0, 331.0, 11.0, 13.0, 3.0, -2.0, 1.0, 10.0, 7.0, 6.0, -8.0, 11.0, 320.0, 13.0, 12.0, 8.0, 7.0, 8.0, -8.0, 13.0, -14.0, 12.0, 4.0, 12.0, -10.0, 10.0, 3.0, 12.0, -1.0, 11.0, -7.0, 11.0, 14.0, 11.0, -21.0, 12.0, 14.0, 11.0, -22.0, -2.0, 7.0, 2.0, 8.0, -2.0, -3.0, 11.0, 9.0, 0.0, 12.0, 3.0, 0.0, 14.0, 4.0, 12.0, -15.0, -3.0, 11.0, -1.0, 8.0, 12.0, -18.0, 8.0, 13.0, 14.0, -8.0, 4.0, 5.0, 14.0, -13.0, 5.0, 9.0, 7.0, -4.0, 0.0, 12.0, 8.0, 4.0, 12.0, -9.0, 10.0, 7.0, 1.0, -3.0, 14.0, 0.0, -2.0, 3.0, 12.0, 6.0, -9.0, 6.0, 11.0, -11.0, 12.0, 3.0, 11.0, -6.0, 5.0, 5.0, 13.0, 8.0, 11.0, -17.0, -4.0, 11.0, -2.0, 10.0, 13.0, -2.0, 11.0, -7.0, -4.0, 13.0, 12.0, -6.0, 9.0, 10.0, -11.0, 7.0, 13.0, 8.0, -11.0, 5.0, 11.0, -12.0, 13.0, 3.0, 11.0, 13.0, 3.0, -12.0, 12.0, 2.0, 8.0, -7.0, -4.0, 11.0, -1.0, 9.0, 11.0, -22.0, 13.0, 13.0, -5.0, 8.0, 8.0, 4.0, 13.0, -8.0, 0.0, 10.0, 11.0, 9.0, -18.0, 13.0, 9.0, 10.0, 4.0, -8.0, 9.0, 3.0, 7.0, -4.0, 14.0, -9.0, 2.0, 8.0, 14.0, -6.0, 3.0, 4.0, 12.0, -5.0, 11.0, -3.0, 10.0, 13.0, -15.0, 7.0, 13.0, 10.0, -2.0, -6.0, -2.0, 6.0, 3.0, 8.0, 12.0, 317.0, 13.0, 13.0, 9.0, -6.0, 7.0, 5.0, 7.0, 14.0, 12.0, -18.0, 11.0, -5.0, 3.0, 6.0, 12.0, -16.0, 12.0, 7.0, 12.0, 6.0, 10.0, -13.0, 11.0, -4.0, 11.0, -3.0, 11.0, 10.0, -17.0, 11.0, -7.0, 6.0, 10.0, 6.0, 14.0, 8.0, -7.0, 0.0, 13.0, 9.0, -18.0, 11.0, -1.0, 7.0, 4.0, 5.0, 10.0, -5.0, 10.0, 0.0, 9.0, 13.0, 11.0, -18.0, 7.0, 5.0, -8.0, 11.0, 13.0, 4.0, -6.0, 4.0, 12.0, 319.0, 11.0, 13.0, 13.0, 8.0, -16.0, 10.0, 13.0, -11.0, 10.0, 3.0, -3.0, 11.0, 2.0, 5.0, 12.0, -14.0, 6.0, 11.0, -1.0, 12.0, 9.0, -5.0, 14.0, -6.0, 9.0, -2.0, 7.0, -2.0, 4.0, 6.0, 12.0, 2.0, 9.0, -8.0, -8.0, 7.0, 12.0, 4.0, 9.0, 5.0, -11.0, 12.0, 10.0, -1.0, 2.0, 4.0, 12.0, 4.0, 12.0, -13.0, 14.0, 12.0, -6.0, -5.0, 13.0, -7.0, 4.0, 5.0, 10.0, 11.0, -13.0, 7.0, 8.0, -14.0, 13.0, 8.0, 12.0, 14.0, -15.0, 4.0, 12.0, 4.0, 5.0, -6.0, 13.0, 12.0, 6.0, -16.0, 12.0, -16.0, 6.0, 13.0, 10.0, -9.0, 10.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18422450711677388, "mean_inference_ms": 1.0620645658012302, "mean_action_processing_ms": 0.07092078849657263, "mean_env_wait_ms": 0.17443859229656689, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 600372, "agent_timesteps_total": 600372, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66347616.888, "learn_time_ms": 14.417, "learn_throughput": 382048.848, "update_time_ms": 6.542}, "info": {"learner": {"learned": {"policy_loss": 276600356864.0, "vf_loss": 241.5709228515625, "total_loss": 276600356864.0, "vf_explained_var": -0.0005991458892822266, "model": {}}}, "num_steps_sampled": 600372, "num_agent_steps_sampled": 600372, "num_steps_trained": 600372, "num_agent_steps_trained": 600372}, "done": false, "episodes_total": 11772, "training_iteration": 109, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-07", "timestamp": 1626864487, "time_this_iter_s": 0.36290717124938965, "time_total_s": 39.64016056060791, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182869d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 39.64016056060791, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-10.0, 11.0, 9.0, 5.0, 4.0, 14.0, -4.0, 1.0, -10.0, 7.0, 7.0, 11.0, 14.0, 11.0, 4.0, -14.0, 6.0, 7.0, -10.0, 12.0, 11.0, 14.0, -11.0, 1.0, 11.0, 8.0, 2.0, -6.0, 7.0, 12.0, -5.0, 1.0, -11.0, 13.0, 12.0, 1.0, 13.0, 9.0, -8.0, 1.0, 11.0, -2.0, -3.0, 9.0, 12.0, 13.0, -7.0, -3.0, 5.0, 10.0, -5.0, 5.0, 4.0, 14.0, 0.0, -3.0, 11.0, -12.0, 7.0, 9.0, 9.0, 9.0, 4.0, -7.0, -6.0, 5.0, 9.0, 7.0, 12.0, 10.0, -12.0, 5.0, 8.0, -3.0, 9.0, 1.0, 12.0, 13.0, 0.0, -10.0, 10.0, 14.0, 2.0, -11.0, 12.0, 14.0, 1.0, -12.0, -3.0, 7.0, -2.0, 13.0, 12.0, 3.0, -12.0, 12.0, 11.0, 12.0, 4.0, -12.0, 13.0, 4.0, -7.0, 5.0, 0.0, -2.0, 8.0, 9.0, 8.0, 14.0, -15.0, 8.0, 7.0, 13.0, -11.0, 6.0, 12.0, 14.0, 0.0, -11.0, -4.0, 7.0, 11.0, 1.0, 14.0, 10.0, -4.0, -5.0, 12.0, 6.0, 8.0, -11.0, 14.0, -9.0, 8.0, 2.0, -2.0, 14.0, -9.0, 12.0, 14.0, 14.0, -1.0, -12.0, 8.0, 9.0, 1.0, -3.0, 7.0, 6.0, 7.0, -5.0, -13.0, 13.0, 6.0, 9.0, -1.0, 8.0, 5.0, 3.0, -2.0, 10.0, 7.0, 0.0, 10.0, 9.0, 9.0, -13.0, -4.0, 2.0, 12.0, 5.0, 13.0, 13.0, -14.0, 3.0, 13.0, 9.0, 8.0, -15.0, -5.0, 14.0, 8.0, -2.0, 11.0, -12.0, 6.0, 10.0, 4.0, 6.0, 6.0, -1.0, 10.0, 13.0, -9.0, 1.0, 14.0, 13.0, -11.0, -1.0, -5.0, 9.0, 8.0, 3.0, 4.0, 10.0, -7.0, 8.0, 7.0, 6.0, 11.0, -9.0, 7.0, 10.0, -5.0, 3.0, 2.0, -5.0, 11.0, 7.0, 4.0, 13.0, 3.0, -5.0, 12.0, 6.0, -14.0, 11.0, 8.0, 13.0, -10.0, 4.0, -1.0, 1.0, 2.0, 13.0, 3.0, -8.0, 8.0, 12.0, 7.0, 11.0, -13.0, 10.0, -2.0, 13.0, 3.0, 1.0, -7.0, 5.0, 8.0, 9.0, -1.0, 12.0, 2.0, 2.0, 9.0, 14.0, -14.0, 6.0, 13.0, 14.0, -2.0, -10.0, 12.0, 5.0, 5.0, -7.0, 12.0, -4.0, 1.0, 6.0, 13.0, 11.0, -16.0, 7.0, 10.0, 12.0, -10.0, 3.0, -4.0, 9.0, -2.0, 12.0, 13.0, -4.0, -3.0, 9.0, 6.0, 6.0, -3.0, 6.0, 13.0, 9.0, 2.0, -9.0, 10.0, -16.0, 9.0, 12.0, 13.0, 11.0, -9.0, 0.0, 9.0, 11.0, -8.0, 3.0, -3.0, 13.0, 1.0, 4.0, 12.0, 8.0, 1.0, -6.0, 9.0, 10.0, 1.0, -5.0, 6.0, 10.0, 10.0, -11.0, 14.0, 7.0, 7.0, -13.0, -2.0, 11.0, -1.0, 7.0, 10.0, 11.0, -6.0, 0.0, -3.0, 5.0, 4.0, 9.0, 11.0, 10.0, 1.0, -7.0, -5.0, 11.0, 6.0, 3.0, 14.0, 12.0, 6.0, -17.0, 13.0, 11.0, -14.0, 5.0, 0.0, 7.0, 5.0, 3.0, 9.0, -12.0, 11.0, 7.0, 10.0, 6.0, 0.0, -1.0, -10.0, 12.0, 4.0, 9.0, -2.0, 13.0, 0.0, 4.0, -5.0, 14.0, -4.0, 10.0, 4.0, 12.0, 4.0, -5.0, 12.0, 13.0, 7.0, -17.0, 10.0, 14.0, -10.0, 1.0, 9.0, -8.0, 7.0, 7.0, 7.0, 10.0, 3.0, -5.0, 9.0, 10.0, 1.0, -5.0, 13.0, 8.0, 1.0, -7.0, 5.0, -6.0, 11.0, 5.0, 5.0, 10.0, 5.0, -5.0, 13.0, 12.0, -14.0, 4.0, -4.0, 10.0, 4.0, 5.0, 13.0, 10.0, -13.0, 5.0, 11.0, 5.0, 6.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1842360362757875, "mean_inference_ms": 1.0620678242618464, "mean_action_processing_ms": 0.07092199961489205, "mean_env_wait_ms": 0.17446714873682267, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 605880, "agent_timesteps_total": 605880, "timers": {"sample_time_ms": 0.082, "sample_throughput": 67513237.92, "learn_time_ms": 14.059, "learn_throughput": 391773.655, "update_time_ms": 6.213}, "info": {"learner": {"learned": {"policy_loss": 77275701248.0, "vf_loss": 129.2793426513672, "total_loss": 77275701248.0, "vf_explained_var": -0.0007028579711914062, "model": {}}}, "num_steps_sampled": 605880, "num_agent_steps_sampled": 605880, "num_steps_trained": 605880, "num_agent_steps_trained": 605880}, "done": false, "episodes_total": 11880, "training_iteration": 110, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-08", "timestamp": 1626864488, "time_this_iter_s": 0.35083627700805664, "time_total_s": 39.99099683761597, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18286048>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 39.99099683761597, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 72.5, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 13.0, 1.0, -11.0, 12.0, 13.0, 9.0, -19.0, 5.0, 13.0, 5.0, -8.0, 10.0, 12.0, -17.0, 10.0, -11.0, 13.0, 8.0, 5.0, 11.0, 14.0, -3.0, -7.0, -7.0, 12.0, 4.0, 6.0, -3.0, 12.0, -4.0, 10.0, 7.0, 11.0, -10.0, 7.0, -11.0, 7.0, 13.0, 6.0, 7.0, 2.0, 11.0, -5.0, -18.0, 11.0, 10.0, 12.0, 6.0, 10.0, 10.0, -11.0, 12.0, 7.0, 10.0, -14.0, 10.0, 12.0, 1.0, -8.0, -13.0, 8.0, 7.0, 13.0, 6.0, 11.0, -6.0, 4.0, 5.0, 11.0, 8.0, -9.0, -7.0, 13.0, 2.0, 7.0, 11.0, -7.0, 0.0, 11.0, 11.0, 14.0, -2.0, -8.0, 8.0, 11.0, 7.0, -11.0, 9.0, 3.0, 5.0, -2.0, 11.0, 9.0, -11.0, 6.0, -1.0, 11.0, 7.0, -2.0, 11.0, 8.0, -10.0, 6.0, 11.0, 9.0, -13.0, 8.0, 1.0, -1.0, 6.0, 9.0, 7.0, 12.0, -2.0, -2.0, 12.0, 9.0, 8.0, -14.0, 10.0, 12.0, -8.0, 1.0, 8.0, 7.0, -10.0, 10.0, -14.0, 13.0, 4.0, 12.0, 8.0, 10.0, 6.0, -9.0, 10.0, 13.0, 4.0, -12.0, 12.0, 9.0, -13.0, 7.0, 1.0, 13.0, 10.0, -9.0, 9.0, 14.0, 0.0, -8.0, 10.0, 13.0, -20.0, 12.0, -11.0, 2.0, 11.0, 13.0, 2.0, 13.0, 5.0, -5.0, 5.0, 14.0, 7.0, -11.0, 4.0, 9.0, -6.0, 8.0, 5.0, -4.0, 1.0, 13.0, 11.0, 9.0, 11.0, -16.0, 6.0, 13.0, 3.0, -7.0, -2.0, 9.0, 3.0, 5.0, 10.0, -8.0, 1.0, 12.0, 14.0, 12.0, 5.0, -16.0, 11.0, 13.0, 11.0, -20.0, 8.0, 9.0, -3.0, 1.0, -7.0, 7.0, 11.0, 4.0, 8.0, 12.0, -15.0, 10.0, 4.0, 13.0, 9.0, -11.0, 12.0, 11.0, -16.0, 8.0, -1.0, -8.0, 11.0, 13.0, 7.0, 13.0, 6.0, -11.0, 11.0, 13.0, 3.0, -12.0, 3.0, 9.0, -9.0, 12.0, 13.0, -1.0, -1.0, 4.0, 10.0, 10.0, -4.0, -1.0, 11.0, 8.0, 2.0, -6.0, 12.0, 4.0, 4.0, -5.0, 2.0, -8.0, 8.0, 13.0, 12.0, 11.0, -2.0, -6.0, 11.0, 7.0, 3.0, -6.0, 10.0, 13.0, 4.0, -12.0, 1.0, -7.0, 11.0, 10.0, 6.0, 13.0, 3.0, -7.0, 10.0, 14.0, 6.0, -15.0, -1.0, -3.0, 13.0, 6.0, 10.0, 1.0, -9.0, 13.0, 14.0, 10.0, 11.0, -20.0, 8.0, 8.0, 1.0, -2.0, 11.0, 9.0, 8.0, -13.0, 3.0, 5.0, -5.0, 12.0, 14.0, 12.0, -5.0, -6.0, -11.0, 13.0, 11.0, 2.0, 11.0, 8.0, -8.0, 4.0, -7.0, 9.0, 0.0, 13.0, 7.0, 13.0, 7.0, -12.0, 8.0, 13.0, 9.0, -15.0, 6.0, 8.0, 7.0, -6.0, 5.0, -6.0, 3.0, 13.0, 0.0, 12.0, 8.0, -5.0, 13.0, 11.0, 6.0, -15.0, -2.0, 8.0, 4.0, 5.0, 10.0, -8.0, 4.0, 9.0, 8.0, 12.0, 4.0, -9.0, -4.0, 14.0, 5.0, 0.0, 13.0, 10.0, -4.0, -4.0, 0.0, -9.0, 11.0, 13.0, 13.0, 5.0, -5.0, 2.0, 11.0, 5.0, 11.0, -12.0, 11.0, 0.0, -8.0, 12.0, 3.0, -5.0, 9.0, 8.0, 2.0, 13.0, 7.0, -7.0, 10.0, 9.0, 9.0, -13.0, -2.0, 7.0, -1.0, 11.0, -5.0, 8.0, 5.0, 7.0, 10.0, 8.0, -6.0, 3.0, 4.0, 14.0, -10.0, 7.0, 11.0, 13.0, 5.0, -14.0, -10.0, 5.0, 11.0, 9.0, 2.0, 12.0, 7.0, -6.0, 9.0, 13.0, 9.0, -16.0, 9.0, 8.0, 3.0, -5.0, 2.0, -5.0, 11.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18424052586475195, "mean_inference_ms": 1.0620209475921312, "mean_action_processing_ms": 0.0709216614953718, "mean_env_wait_ms": 0.17446397474547284, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 611388, "agent_timesteps_total": 611388, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66117210.38, "learn_time_ms": 14.265, "learn_throughput": 386113.076, "update_time_ms": 6.273}, "info": {"learner": {"learned": {"policy_loss": 439832182784.0, "vf_loss": 534.3162841796875, "total_loss": 439832182784.0, "vf_explained_var": -0.00012767314910888672, "model": {}}}, "num_steps_sampled": 611388, "num_agent_steps_sampled": 611388, "num_steps_trained": 611388, "num_agent_steps_trained": 611388}, "done": false, "episodes_total": 11988, "training_iteration": 111, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-08", "timestamp": 1626864488, "time_this_iter_s": 0.3556244373321533, "time_total_s": 40.34662127494812, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18286ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 40.34662127494812, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 83.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 5.0, -13.0, 13.0, 10.0, 9.0, -3.0, -1.0, -5.0, 14.0, 11.0, -5.0, 12.0, 9.0, -2.0, -4.0, 10.0, -11.0, 5.0, 11.0, -8.0, 13.0, -2.0, 12.0, -20.0, 12.0, 12.0, 11.0, 3.0, -5.0, 4.0, 13.0, 6.0, 14.0, -18.0, 13.0, 10.0, 5.0, 1.0, -1.0, 7.0, 9.0, -6.0, 5.0, 6.0, 6.0, -10.0, 13.0, 3.0, -10.0, 9.0, 13.0, 12.0, 5.0, -13.0, 11.0, -7.0, 12.0, 6.0, 4.0, 10.0, 6.0, -9.0, 8.0, 10.0, 9.0, -16.0, 12.0, -3.0, 9.0, 11.0, -2.0, 5.0, 13.0, 3.0, -6.0, 7.0, 12.0, -17.0, 13.0, 4.0, -11.0, 12.0, 10.0, 10.0, 2.0, -8.0, 11.0, -5.0, 13.0, 12.0, -5.0, 9.0, 6.0, -13.0, 13.0, 6.0, -7.0, 13.0, 3.0, 1.0, 13.0, -9.0, 10.0, 3.0, 14.0, 7.0, -9.0, 12.0, 11.0, -3.0, -5.0, 5.0, 14.0, -16.0, 12.0, -5.0, 9.0, 0.0, 11.0, 12.0, 2.0, 3.0, -2.0, 9.0, 4.0, -10.0, 12.0, 10.0, 9.0, 12.0, -16.0, 8.0, -6.0, 3.0, 10.0, -6.0, 14.0, -2.0, 9.0, 7.0, 8.0, -13.0, 13.0, 10.0, 8.0, 12.0, -15.0, -7.0, 10.0, 6.0, 6.0, 1.0, 14.0, 8.0, -8.0, 8.0, -6.0, 2.0, 11.0, -14.0, 8.0, 13.0, 8.0, -2.0, 8.0, -3.0, 12.0, 321.0, 12.0, 11.0, 12.0, 8.0, 10.0, -15.0, 12.0, 10.0, 7.0, -15.0, 13.0, 13.0, -3.0, -7.0, 12.0, -5.0, 12.0, -3.0, 11.0, 14.0, 4.0, -10.0, 7.0, 11.0, 9.0, -18.0, 13.0, 11.0, 5.0, -13.0, 12.0, 7.0, 12.0, -5.0, 1.0, 8.0, 9.0, -2.0, 0.0, -13.0, 6.0, 13.0, 9.0, 13.0, 10.0, -14.0, 6.0, 3.0, 14.0, -12.0, 10.0, 4.0, 10.0, -7.0, 8.0, 5.0, 4.0, -6.0, 12.0, 7.0, 8.0, -11.0, 11.0, 1.0, 13.0, 8.0, -7.0, 11.0, -10.0, 8.0, 6.0, 11.0, 5.0, 11.0, -12.0, -1.0, 11.0, 6.0, -1.0, -4.0, 13.0, -4.0, 10.0, 2.0, 10.0, -9.0, 12.0, 8.0, 14.0, -20.0, 13.0, 11.0, 8.0, -15.0, 11.0, 7.0, 5.0, 7.0, -4.0, 8.0, 2.0, -3.0, 8.0, 9.0, -14.0, 8.0, 12.0, 10.0, 5.0, -12.0, 12.0, -6.0, 12.0, 12.0, -3.0, 6.0, 9.0, -8.0, 8.0, 6.0, -12.0, 11.0, 10.0, -19.0, 13.0, 9.0, 12.0, 13.0, 10.0, -6.0, -2.0, 9.0, -9.0, 2.0, 13.0, 6.0, -12.0, 13.0, 8.0, 5.0, 10.0, 7.0, -7.0, 8.0, 6.0, -7.0, 8.0, 14.0, 6.0, 8.0, -13.0, 3.0, -10.0, 13.0, 9.0, -11.0, 6.0, 7.0, 13.0, 1.0, 13.0, 9.0, -8.0, 6.0, -9.0, 10.0, 8.0, 4.0, 10.0, 13.0, -12.0, -5.0, 9.0, -1.0, 12.0, 6.0, 11.0, -11.0, 9.0, 3.0, -8.0, 7.0, 13.0, -10.0, 3.0, 10.0, 12.0, 5.0, 8.0, -10.0, 12.0, 8.0, 6.0, 4.0, -3.0, 13.0, 2.0, 6.0, -6.0, -1.0, 7.0, -4.0, 13.0, -17.0, 13.0, 8.0, 11.0, 1.0, 13.0, -10.0, 11.0, 5.0, 7.0, -8.0, 11.0, 10.0, -15.0, 10.0, 10.0, 9.0, 8.0, -13.0, 11.0, -5.0, 8.0, 2.0, 10.0, 12.0, 10.0, 0.0, -7.0, 9.0, 9.0, 13.0, -16.0, 9.0, 8.0, -13.0, 11.0, 13.0, 12.0, -14.0, 4.0, 12.0, 3.0, 1.0, -1.0, -3.0, 4.0, 2.0, 12.0, 318.0, 13.0, 13.0, 10.0, 4.0, 9.0, -5.0, 7.0, 10.0, 2.0, 7.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18420743744932183, "mean_inference_ms": 1.0619472889272876, "mean_action_processing_ms": 0.07091743578783843, "mean_env_wait_ms": 0.17444576175666374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 616896, "agent_timesteps_total": 616896, "timers": {"sample_time_ms": 0.082, "sample_throughput": 66931655.125, "learn_time_ms": 14.11, "learn_throughput": 390360.321, "update_time_ms": 6.173}, "info": {"learner": {"learned": {"policy_loss": 214436413440.0, "vf_loss": 241.58792114257812, "total_loss": 214436413440.0, "vf_explained_var": -0.0006804466247558594, "model": {}}}, "num_steps_sampled": 616896, "num_agent_steps_sampled": 616896, "num_steps_trained": 616896, "num_agent_steps_trained": 616896}, "done": false, "episodes_total": 12096, "training_iteration": 112, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-09", "timestamp": 1626864489, "time_this_iter_s": 0.34994959831237793, "time_total_s": 40.6965708732605, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182942f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 40.6965708732605, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-20.0, 14.0, 11.0, 10.0, 11.0, 8.0, -13.0, 9.0, -9.0, 9.0, 11.0, 4.0, 1.0, -5.0, 11.0, 8.0, 2.0, 12.0, 6.0, -5.0, 5.0, 2.0, 12.0, -4.0, 7.0, 12.0, 6.0, -10.0, -13.0, 5.0, 11.0, 12.0, 5.0, 8.0, 6.0, -4.0, 8.0, 1.0, -4.0, 10.0, -6.0, 11.0, 7.0, 3.0, 5.0, -5.0, 11.0, 4.0, 13.0, -4.0, -3.0, 9.0, -9.0, 7.0, 6.0, 11.0, 9.0, 1.0, -1.0, 6.0, 13.0, -15.0, 11.0, 6.0, 0.0, 14.0, 6.0, -5.0, -10.0, 10.0, 8.0, 7.0, -2.0, -6.0, 11.0, 12.0, 13.0, -13.0, 11.0, 4.0, 4.0, 14.0, -12.0, 9.0, 11.0, 2.0, -10.0, 12.0, 9.0, -5.0, 8.0, 3.0, 11.0, -4.0, -3.0, 11.0, 13.0, 14.0, -4.0, -8.0, -6.0, 9.0, 1.0, 11.0, 7.0, -5.0, 6.0, 7.0, 11.0, -14.0, 11.0, 7.0, 7.0, 12.0, 1.0, -5.0, 8.0, 7.0, -4.0, 4.0, 11.0, 13.0, 9.0, -18.0, 6.0, -8.0, 7.0, 10.0, 13.0, -1.0, -2.0, 5.0, 11.0, -13.0, 5.0, 12.0, 10.0, -9.0, 1.0, 13.0, -1.0, -2.0, 6.0, 12.0, 7.0, 4.0, 11.0, -7.0, 5.0, 5.0, 9.0, -4.0, 10.0, 13.0, -3.0, -5.0, -16.0, 12.0, 7.0, 12.0, 7.0, 13.0, -12.0, 7.0, 6.0, 7.0, 6.0, -4.0, 8.0, 14.0, -8.0, 1.0, -6.0, 6.0, 8.0, 7.0, 10.0, 9.0, -11.0, 7.0, 8.0, 12.0, -7.0, 2.0, 13.0, -16.0, 13.0, 5.0, -11.0, 12.0, 9.0, 5.0, 8.0, 13.0, -14.0, 8.0, 14.0, 1.0, -7.0, 7.0, 12.0, -14.0, 10.0, 7.0, -1.0, -5.0, 9.0, 12.0, 5.0, 5.0, 11.0, -6.0, 8.0, 9.0, 6.0, -8.0, 11.0, -1.0, 13.0, -8.0, -7.0, 1.0, 9.0, 12.0, 13.0, 9.0, -16.0, 9.0, 12.0, 3.0, -7.0, 7.0, -11.0, 12.0, 11.0, 3.0, -13.0, 4.0, 12.0, 12.0, -2.0, 14.0, 6.0, -3.0, 7.0, 11.0, 1.0, -4.0, 9.0, -12.0, 6.0, 12.0, 6.0, -4.0, 11.0, 2.0, 2.0, 7.0, -4.0, 10.0, 12.0, 1.0, 6.0, -4.0, -4.0, -2.0, 10.0, 11.0, -14.0, 12.0, 7.0, 10.0, -2.0, 13.0, -7.0, 11.0, 3.0, 11.0, 7.0, -6.0, 10.0, -10.0, 13.0, 2.0, -9.0, 7.0, 6.0, 11.0, 4.0, 12.0, -12.0, 11.0, 13.0, 3.0, 10.0, -11.0, 11.0, 4.0, -2.0, 2.0, -9.0, 12.0, 0.0, 12.0, 0.0, 13.0, 6.0, -4.0, -2.0, 11.0, -5.0, 11.0, 7.0, 0.0, -5.0, 13.0, 0.0, -3.0, 11.0, 7.0, 6.0, 14.0, -10.0, 5.0, 12.0, 13.0, -5.0, -5.0, 6.0, 6.0, -8.0, 11.0, -16.0, 11.0, 12.0, 8.0, 8.0, 14.0, -1.0, -6.0, 7.0, 10.0, -10.0, 8.0, -14.0, 13.0, 11.0, 5.0, -9.0, 11.0, 1.0, 12.0, 0.0, 14.0, -6.0, 7.0, 13.0, 9.0, -1.0, -6.0, 7.0, 7.0, 9.0, -8.0, 1.0, -1.0, 11.0, 4.0, -2.0, 9.0, 11.0, -3.0, 10.0, 8.0, 8.0, -11.0, 6.0, 5.0, 12.0, -8.0, 2.0, -3.0, 9.0, 7.0, 4.0, 9.0, 9.0, -7.0, 3.0, 9.0, -6.0, 9.0, 10.0, -9.0, 6.0, 8.0, -11.0, 9.0, 7.0, 10.0, 2.0, 13.0, -6.0, 6.0, 6.0, 12.0, -10.0, 7.0, 7.0, 9.0, 12.0, -13.0, 4.0, -7.0, 6.0, 12.0, 4.0, 14.0, -6.0, 3.0, 11.0, 6.0, 8.0, -10.0, -6.0, 7.0, 11.0, 3.0, 10.0, -14.0, 13.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1842216239006498, "mean_inference_ms": 1.06195964642027, "mean_action_processing_ms": 0.07091801125062229, "mean_env_wait_ms": 0.17445031481596288, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 622404, "agent_timesteps_total": 622404, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68159712.468, "learn_time_ms": 13.888, "learn_throughput": 396599.299, "update_time_ms": 6.209}, "info": {"learner": {"learned": {"policy_loss": 1.2797490358352661, "vf_loss": 21.24225425720215, "total_loss": 22.522003173828125, "vf_explained_var": -0.0061463117599487305, "model": {}}}, "num_steps_sampled": 622404, "num_agent_steps_sampled": 622404, "num_steps_trained": 622404, "num_agent_steps_trained": 622404}, "done": false, "episodes_total": 12204, "training_iteration": 113, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-09", "timestamp": 1626864489, "time_this_iter_s": 0.35817909240722656, "time_total_s": 41.054749965667725, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182867b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 41.054749965667725, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 76.4, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 28.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.157407407407407, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.7893518518518516}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 10.0, -2.0, -2.0, -4.0, -3.0, 13.0, 9.0, 13.0, 6.0, 3.0, -7.0, 12.0, -1.0, 13.0, -9.0, 12.0, -2.0, 11.0, -6.0, 4.0, 8.0, -9.0, 12.0, 5.0, 11.0, 11.0, -12.0, 7.0, 5.0, 8.0, -5.0, -4.0, 9.0, 1.0, 10.0, 4.0, 6.0, 12.0, -7.0, 2.0, 8.0, 11.0, -6.0, -2.0, 5.0, 8.0, 4.0, 10.0, 12.0, -17.0, 10.0, 6.0, 9.0, -7.0, 7.0, 3.0, 10.0, 8.0, -6.0, 11.0, 4.0, 12.0, -12.0, 10.0, -2.0, -1.0, 8.0, 5.0, 13.0, -9.0, 6.0, 2.0, 12.0, 12.0, -11.0, -8.0, 14.0, 1.0, 8.0, 14.0, 3.0, -13.0, 11.0, 5.0, -2.0, 6.0, 6.0, 2.0, 9.0, 11.0, -7.0, 12.0, 5.0, 8.0, -10.0, 9.0, 14.0, -18.0, 10.0, 4.0, 10.0, 5.0, -4.0, 8.0, 11.0, -5.0, 1.0, 6.0, 8.0, 8.0, -7.0, 8.0, 14.0, -3.0, 9.0, 8.0, 12.0, -10.0, 5.0, -5.0, 11.0, 10.0, -1.0, 4.0, 7.0, 8.0, -4.0, -3.0, 11.0, 12.0, -5.0, 5.0, 13.0, -5.0, 2.0, -2.0, 11.0, 9.0, -3.0, 8.0, -14.0, 12.0, 9.0, 0.0, 12.0, -4.0, 7.0, 3.0, 10.0, -11.0, 13.0, 7.0, 10.0, 4.0, -6.0, 2.0, 13.0, 9.0, -9.0, 11.0, 10.0, 1.0, -7.0, 0.0, 11.0, -4.0, 8.0, 3.0, 9.0, 10.0, -7.0, 1.0, 4.0, 13.0, -3.0, -1.0, 7.0, -3.0, 12.0, 0.0, -6.0, 11.0, 10.0, 11.0, 10.0, 7.0, -13.0, -5.0, 3.0, 12.0, 5.0, -1.0, 12.0, -4.0, 9.0, -1.0, -4.0, 8.0, 12.0, 6.0, 13.0, 8.0, -12.0, 4.0, 13.0, 2.0, -4.0, 13.0, -3.0, 10.0, -5.0, -1.0, 13.0, -9.0, 12.0, 1.0, 11.0, 10.0, -7.0, -18.0, 8.0, 13.0, 12.0, 14.0, 11.0, -20.0, 10.0, 8.0, 12.0, -6.0, 1.0, 1.0, 13.0, 6.0, -5.0, -4.0, 13.0, -5.0, 11.0, -3.0, 8.0, 11.0, -1.0, 4.0, 11.0, -9.0, 9.0, 8.0, 8.0, 11.0, -12.0, 1.0, 9.0, 6.0, -1.0, 13.0, 12.0, -21.0, 11.0, 3.0, -5.0, 6.0, 11.0, 11.0, 11.0, 6.0, -13.0, 8.0, 3.0, 7.0, -3.0, 8.0, -2.0, -3.0, 12.0, 8.0, 7.0, -12.0, 12.0, -1.0, 14.0, 10.0, -8.0, 8.0, 8.0, 7.0, -8.0, -2.0, 5.0, 10.0, 2.0, 8.0, 9.0, -2.0, 0.0, 5.0, 11.0, 11.0, -12.0, 6.0, 4.0, 9.0, -4.0, -1.0, 13.0, -3.0, 6.0, 5.0, 10.0, -7.0, 7.0, 2.0, -5.0, 11.0, 7.0, -8.0, 14.0, 0.0, 9.0, 13.0, 12.0, -6.0, -4.0, 6.0, -1.0, 1.0, 9.0, 6.0, -3.0, 10.0, 2.0, 5.0, 1.0, 13.0, -4.0, 10.0, -5.0, 10.0, 0.0, -5.0, 11.0, 11.0, -2.0, 4.0, 10.0, 9.0, -8.0, 11.0, 10.0, -1.0, -5.0, 14.0, -7.0, -2.0, 10.0, 5.0, 6.0, 6.0, -2.0, 4.0, -2.0, 11.0, 2.0, 5.0, 2.0, 13.0, -5.0, 10.0, 5.0, -12.0, 13.0, -1.0, 12.0, -8.0, 12.0, 7.0, 10.0, 6.0, -8.0, -6.0, 10.0, 2.0, 9.0, 12.0, 3.0, 13.0, -13.0, 8.0, 13.0, -6.0, 0.0, 4.0, -6.0, 10.0, 7.0, -6.0, 1.0, 12.0, 8.0, 12.0, 9.0, 10.0, -16.0, 9.0, 13.0, -6.0, -1.0, -12.0, 13.0, 10.0, 4.0, 3.0, 13.0, 3.0, -4.0, -2.0, 8.0, -2.0, 11.0, 6.0, 12.0, 0.0, -3.0, 0.0, 12.0, 10.0, -7.0, 2.0, 11.0, -2.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1842264228561728, "mean_inference_ms": 1.0620240316840095, "mean_action_processing_ms": 0.07091560672741425, "mean_env_wait_ms": 0.17445121061499702, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 627912, "agent_timesteps_total": 627912, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68543780.565, "learn_time_ms": 14.075, "learn_throughput": 391336.317, "update_time_ms": 6.379}, "info": {"learner": {"learned": {"policy_loss": 116237361152.0, "vf_loss": 118.8976058959961, "total_loss": 116237361152.0, "vf_explained_var": -0.0007500648498535156, "model": {}}}, "num_steps_sampled": 627912, "num_agent_steps_sampled": 627912, "num_steps_trained": 627912, "num_agent_steps_trained": 627912}, "done": false, "episodes_total": 12312, "training_iteration": 114, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-09", "timestamp": 1626864489, "time_this_iter_s": 0.3626530170440674, "time_total_s": 41.41740298271179, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18286bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 41.41740298271179, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.444444444444443, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 6.111111111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 14.0, 2.0, 8.0, -8.0, 13.0, 13.0, -3.0, 13.0, 12.0, 318.0, 12.0, -9.0, 12.0, 2.0, 10.0, -3.0, 8.0, 8.0, 2.0, 13.0, 11.0, -16.0, 7.0, 11.0, 12.0, -21.0, 13.0, 6.0, -7.0, 5.0, 11.0, -9.0, 10.0, 3.0, 11.0, 13.0, -3.0, 0.0, 5.0, 13.0, -2.0, -8.0, 12.0, -12.0, 4.0, 11.0, 12.0, -4.0, 12.0, 9.0, -2.0, -1.0, 12.0, 10.0, -6.0, 11.0, -1.0, -7.0, 12.0, -6.0, 1.0, 7.0, 13.0, -5.0, 14.0, 4.0, 2.0, -9.0, 13.0, 10.0, 1.0, 11.0, 14.0, -20.0, 10.0, 7.0, -5.0, 10.0, 3.0, -9.0, 13.0, 5.0, 6.0, -9.0, 10.0, 4.0, 10.0, 5.0, 10.0, -13.0, 13.0, -8.0, 12.0, 0.0, 11.0, 1.0, 14.0, -6.0, 6.0, -6.0, 14.0, 10.0, -3.0, 12.0, 13.0, 318.0, 13.0, 7.0, -8.0, 6.0, 10.0, 3.0, 5.0, -3.0, 10.0, 6.0, 14.0, 8.0, -13.0, 14.0, -1.0, 12.0, -10.0, 5.0, -12.0, 9.0, 13.0, 11.0, 2.0, -5.0, 7.0, 8.0, 7.0, -9.0, 9.0, 12.0, 12.0, -1.0, -8.0, 4.0, 9.0, 12.0, -10.0, 6.0, 14.0, 2.0, -7.0, 6.0, 12.0, 3.0, -6.0, 8.0, 13.0, -18.0, 12.0, 5.0, -8.0, 7.0, 11.0, -1.0, 9.0, 3.0, 4.0, 4.0, 11.0, 2.0, -2.0, 12.0, 13.0, -8.0, -2.0, 6.0, -5.0, 6.0, 8.0, -7.0, 14.0, 0.0, 8.0, 6.0, 14.0, 4.0, -9.0, 13.0, 13.0, -9.0, -2.0, 10.0, 9.0, 11.0, -15.0, -13.0, 14.0, 2.0, 12.0, 9.0, 5.0, -8.0, 9.0, 12.0, 13.0, 317.0, 12.0, 0.0, -9.0, 12.0, 12.0, -11.0, 14.0, 9.0, 3.0, -11.0, 10.0, 3.0, 13.0, 12.0, 13.0, -4.0, -6.0, 0.0, 11.0, 11.0, -7.0, -12.0, 14.0, 10.0, 3.0, -20.0, 13.0, 12.0, 10.0, 8.0, 8.0, -2.0, 1.0, -15.0, 10.0, 8.0, 12.0, -2.0, 14.0, 1.0, 2.0, 8.0, 13.0, -13.0, 7.0, 10.0, 14.0, -6.0, -3.0, 4.0, -8.0, 12.0, 7.0, 10.0, 9.0, -8.0, 4.0, 3.0, 13.0, 3.0, -4.0, 13.0, 12.0, -15.0, 5.0, 7.0, 8.0, 3.0, -3.0, 11.0, 10.0, -8.0, 2.0, 6.0, 12.0, -11.0, 8.0, 13.0, -2.0, -9.0, 13.0, 2.0, -5.0, 6.0, 12.0, 7.0, 14.0, -11.0, 5.0, 7.0, -6.0, 4.0, 10.0, 12.0, -1.0, -7.0, 11.0, -1.0, 13.0, -8.0, 11.0, -8.0, 14.0, 10.0, -1.0, -8.0, 10.0, 6.0, 7.0, 10.0, 13.0, -6.0, -2.0, 5.0, -8.0, 6.0, 12.0, -12.0, 8.0, 9.0, 10.0, -6.0, 11.0, 2.0, 8.0, 14.0, 11.0, -13.0, 3.0, -8.0, 10.0, 0.0, 13.0, 4.0, 13.0, 10.0, -12.0, 6.0, 13.0, -9.0, 5.0, 13.0, 13.0, -9.0, -2.0, -9.0, 11.0, 7.0, 6.0, -5.0, 14.0, 8.0, -2.0, 7.0, 11.0, 4.0, -7.0, 13.0, -1.0, -6.0, 9.0, 7.0, -4.0, 3.0, 9.0, -1.0, 12.0, 4.0, 0.0, -6.0, 13.0, 7.0, 1.0, 11.0, 12.0, -4.0, -4.0, 1.0, -6.0, 7.0, 13.0, 1.0, 14.0, 10.0, -10.0, -1.0, 13.0, 11.0, -8.0, 13.0, 13.0, -4.0, -7.0, 3.0, 13.0, -11.0, 10.0, 6.0, 13.0, -5.0, 1.0, -1.0, 10.0, 10.0, -4.0, 13.0, 13.0, -9.0, -2.0, 2.0, -2.0, 6.0, 9.0, -3.0, 10.0, 4.0, 4.0, 0.0, 14.0, 8.0, -7.0, 10.0, 0.0, -6.0, 11.0, -17.0, 13.0, 10.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18421922282729597, "mean_inference_ms": 1.061967814520078, "mean_action_processing_ms": 0.07092422461311237, "mean_env_wait_ms": 0.17445363061776864, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 633420, "agent_timesteps_total": 633420, "timers": {"sample_time_ms": 0.08, "sample_throughput": 69028178.885, "learn_time_ms": 14.137, "learn_throughput": 389625.598, "update_time_ms": 5.808}, "info": {"learner": {"learned": {"policy_loss": 268759646208.0, "vf_loss": 324.62237548828125, "total_loss": 268759646208.0, "vf_explained_var": -3.0994415283203125e-05, "model": {}}}, "num_steps_sampled": 633420, "num_agent_steps_sampled": 633420, "num_steps_trained": 633420, "num_agent_steps_trained": 633420}, "done": false, "episodes_total": 12420, "training_iteration": 115, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-10", "timestamp": 1626864490, "time_this_iter_s": 0.34850239753723145, "time_total_s": 41.76590538024902, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 41.76590538024902, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 72.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -9.0, 10.0, 3.0, -1.0, 14.0, -6.0, 8.0, -4.0, 9.0, 12.0, -2.0, 10.0, -10.0, 5.0, 10.0, 7.0, 12.0, 12.0, -16.0, 6.0, 2.0, 11.0, -4.0, -8.0, 14.0, -4.0, 13.0, 8.0, -7.0, 2.0, 12.0, 10.0, -1.0, 7.0, -1.0, 7.0, 3.0, 8.0, -3.0, 7.0, 7.0, -5.0, 6.0, 14.0, 7.0, -3.0, -3.0, 5.0, -6.0, 8.0, 8.0, 7.0, 9.0, 2.0, -3.0, -8.0, 13.0, 13.0, -3.0, 8.0, 12.0, -10.0, 5.0, 8.0, -4.0, 9.0, 2.0, 7.0, 14.0, 3.0, -9.0, -22.0, 13.0, 11.0, 13.0, 9.0, -3.0, -3.0, 12.0, 13.0, 9.0, 11.0, -18.0, 7.0, 3.0, 8.0, -3.0, -9.0, 14.0, -3.0, 13.0, 6.0, 10.0, 3.0, -4.0, 12.0, 9.0, 9.0, -15.0, 13.0, -1.0, -9.0, 12.0, 321.0, 11.0, 11.0, 13.0, 11.0, 13.0, -4.0, -5.0, 12.0, -1.0, 8.0, -4.0, 8.0, 3.0, -8.0, 12.0, 1.0, 11.0, 11.0, -8.0, 9.0, -2.0, 12.0, -4.0, 11.0, -10.0, 11.0, 3.0, 8.0, 1.0, 9.0, -3.0, -7.0, 13.0, 13.0, -4.0, 12.0, 8.0, 4.0, -9.0, 4.0, 9.0, -8.0, 10.0, 12.0, -1.0, 9.0, -5.0, -4.0, 13.0, -5.0, 11.0, 8.0, 9.0, 3.0, -5.0, 10.0, -5.0, 8.0, 2.0, 12.0, 0.0, 8.0, -5.0, 318.0, 13.0, 11.0, 12.0, 7.0, -7.0, 5.0, 10.0, 3.0, 11.0, 13.0, -12.0, 7.0, -1.0, 12.0, -3.0, 3.0, 10.0, 11.0, -9.0, 12.0, 6.0, 0.0, -3.0, 5.0, 7.0, 10.0, -7.0, 8.0, 12.0, 2.0, -7.0, 7.0, 13.0, -16.0, 11.0, 5.0, 3.0, 10.0, -3.0, 10.0, 5.0, 10.0, -10.0, 10.0, 5.0, -10.0, 10.0, 6.0, 9.0, 11.0, -11.0, 10.0, 4.0, 6.0, -5.0, -1.0, 12.0, 12.0, -8.0, -1.0, 13.0, 8.0, -5.0, -12.0, 13.0, 9.0, 5.0, 9.0, 11.0, -1.0, -4.0, 12.0, 12.0, 5.0, -14.0, 13.0, 7.0, -10.0, 5.0, -6.0, 13.0, -4.0, 12.0, 9.0, -4.0, 7.0, 3.0, 12.0, -7.0, 9.0, 1.0, 4.0, 5.0, -3.0, 9.0, 1.0, 14.0, -3.0, 3.0, 3.0, 5.0, 8.0, -1.0, 7.0, 13.0, 10.0, -15.0, 6.0, 4.0, 11.0, -6.0, -2.0, 14.0, -10.0, 13.0, 14.0, 8.0, -5.0, -2.0, 9.0, -10.0, 11.0, 5.0, 7.0, 1.0, -6.0, 13.0, -4.0, 11.0, 10.0, -2.0, 14.0, 8.0, 5.0, -12.0, 12.0, 12.0, 4.0, -13.0, -7.0, 3.0, 10.0, 9.0, -6.0, 14.0, -4.0, 11.0, 4.0, 8.0, -6.0, 9.0, 10.0, -8.0, 11.0, 2.0, 12.0, -3.0, -5.0, 11.0, -7.0, 14.0, -3.0, 11.0, 5.0, 12.0, -14.0, 12.0, 5.0, 11.0, 10.0, -11.0, 9.0, 8.0, 6.0, -8.0, -5.0, 13.0, 10.0, -3.0, 9.0, 6.0, -3.0, 3.0, 10.0, 4.0, 7.0, -6.0, 8.0, 8.0, -12.0, 11.0, 2.0, 12.0, 10.0, -9.0, 9.0, 9.0, -2.0, -1.0, 10.0, 13.0, -8.0, 0.0, 8.0, 1.0, -5.0, 11.0, 3.0, 14.0, -14.0, 12.0, 8.0, 10.0, 0.0, -3.0, 9.0, 7.0, 10.0, -11.0, 13.0, -9.0, 3.0, 8.0, -1.0, 12.0, -7.0, 11.0, 4.0, 11.0, 4.0, -4.0, 5.0, -5.0, 4.0, 11.0, 10.0, 2.0, 8.0, -5.0, 5.0, 13.0, 8.0, -11.0, 10.0, -11.0, 5.0, 11.0, 12.0, 6.0, -2.0, -1.0, 8.0, 10.0, 6.0, -9.0, -5.0, 14.0, -5.0, 11.0, 6.0, 10.0, -4.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1842137047839826, "mean_inference_ms": 1.0618382542195517, "mean_action_processing_ms": 0.07091929750979602, "mean_env_wait_ms": 0.1744506502590674, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 638928, "agent_timesteps_total": 638928, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70329019.161, "learn_time_ms": 14.255, "learn_throughput": 386377.192, "update_time_ms": 5.56}, "info": {"learner": {"learned": {"policy_loss": 434041061376.0, "vf_loss": 429.32952880859375, "total_loss": 434041061376.0, "vf_explained_var": 5.185604095458984e-06, "model": {}}}, "num_steps_sampled": 638928, "num_agent_steps_sampled": 638928, "num_steps_trained": 638928, "num_agent_steps_trained": 638928}, "done": false, "episodes_total": 12528, "training_iteration": 116, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-10", "timestamp": 1626864490, "time_this_iter_s": 0.34756970405578613, "time_total_s": 42.11347508430481, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 42.11347508430481, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 4.0, 11.0, -7.0, 12.0, 12.0, -16.0, 7.0, 3.0, -6.0, 8.0, 10.0, 10.0, 11.0, -6.0, 0.0, 8.0, 5.0, 12.0, -10.0, 11.0, -5.0, 3.0, 6.0, -12.0, 11.0, 7.0, 9.0, -8.0, 5.0, 7.0, 11.0, -3.0, 7.0, 7.0, 4.0, 10.0, 11.0, -12.0, 6.0, 5.0, 12.0, -13.0, 11.0, 3.0, 14.0, 9.0, -11.0, 9.0, 5.0, 9.0, -8.0, -9.0, 8.0, 9.0, 7.0, 9.0, 6.0, -9.0, 9.0, -7.0, 14.0, 2.0, 6.0, 8.0, 8.0, -5.0, 4.0, -7.0, 12.0, -3.0, 13.0, 8.0, 6.0, 8.0, -7.0, 12.0, 14.0, -6.0, -5.0, -7.0, 5.0, 5.0, 12.0, 10.0, 11.0, -18.0, 12.0, -12.0, 12.0, 4.0, 11.0, 9.0, 0.0, 4.0, 2.0, -11.0, 7.0, 9.0, 10.0, -2.0, 13.0, 12.0, -8.0, 10.0, 8.0, -11.0, 8.0, 9.0, 4.0, -10.0, 12.0, 7.0, 8.0, 13.0, -13.0, 10.0, -1.0, -1.0, 7.0, 14.0, 7.0, -14.0, 8.0, 11.0, 5.0, 10.0, -11.0, 10.0, 3.0, 9.0, -7.0, -2.0, 9.0, 3.0, 5.0, 8.0, 13.0, -14.0, 8.0, 7.0, 2.0, -5.0, 11.0, 4.0, 8.0, 12.0, -9.0, 10.0, 11.0, 3.0, -9.0, -9.0, 12.0, 2.0, 10.0, -5.0, 12.0, 7.0, 1.0, -4.0, 8.0, 12.0, -1.0, -4.0, 7.0, 0.0, 12.0, -5.0, 12.0, 11.0, -3.0, 8.0, 4.0, 12.0, -9.0, 8.0, 9.0, -15.0, 13.0, 5.0, 12.0, -1.0, -1.0, 13.0, 13.0, -18.0, 7.0, 12.0, 10.0, -12.0, 5.0, 6.0, -5.0, 5.0, 9.0, -2.0, 11.0, 1.0, 5.0, 9.0, 12.0, -16.0, 10.0, 10.0, -8.0, 7.0, 6.0, 9.0, 12.0, -11.0, 5.0, 11.0, 11.0, -2.0, -5.0, 13.0, 9.0, 7.0, -14.0, -7.0, 14.0, 8.0, 0.0, 9.0, 9.0, 13.0, -16.0, 10.0, 12.0, 5.0, -12.0, 13.0, 9.0, -13.0, 6.0, 8.0, -1.0, 2.0, 6.0, 9.0, 9.0, -10.0, 7.0, 11.0, 13.0, -8.0, -1.0, -7.0, 0.0, 10.0, 12.0, 8.0, -5.0, 5.0, 7.0, 4.0, 7.0, 12.0, -8.0, 10.0, 11.0, -13.0, 7.0, -7.0, 9.0, 1.0, 12.0, 10.0, -2.0, 1.0, 6.0, 11.0, 1.0, 5.0, -2.0, 10.0, 10.0, 7.0, -12.0, -6.0, 2.0, 6.0, 13.0, 13.0, -8.0, 5.0, 5.0, 10.0, 9.0, 11.0, -15.0, 10.0, 12.0, -19.0, 12.0, 2.0, 12.0, -12.0, 13.0, -3.0, 7.0, 9.0, 2.0, 5.0, 3.0, -3.0, 10.0, 12.0, 7.0, 7.0, -11.0, 13.0, 7.0, 8.0, -13.0, 10.0, -8.0, 8.0, 5.0, 9.0, 7.0, -11.0, 10.0, -8.0, 11.0, 2.0, 10.0, 2.0, 11.0, -9.0, 11.0, 4.0, -4.0, 3.0, 12.0, 1.0, 5.0, 11.0, -2.0, -6.0, 10.0, 4.0, 7.0, 3.0, 13.0, -13.0, 12.0, 9.0, 5.0, -10.0, 11.0, -7.0, 7.0, 11.0, 4.0, 11.0, 9.0, 8.0, -13.0, 10.0, 12.0, 321.0, 12.0, 11.0, -7.0, 5.0, 6.0, 11.0, 5.0, -9.0, 8.0, -4.0, 11.0, 2.0, 6.0, -5.0, 11.0, 12.0, -3.0, 2.0, 0.0, 5.0, 8.0, -3.0, 1.0, 9.0, 8.0, 9.0, -3.0, 6.0, 3.0, -12.0, 12.0, 4.0, 11.0, 7.0, -6.0, 7.0, 7.0, 6.0, 10.0, 6.0, -7.0, 10.0, 12.0, -1.0, -6.0, -1.0, -8.0, 13.0, 11.0, 11.0, -5.0, 11.0, -2.0, 1.0, 7.0, 12.0, -5.0, 10.0, 10.0, 1.0, -6.0, 9.0, 5.0, -10.0, 11.0, 11.0, -2.0, 10.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841894595261276, "mean_inference_ms": 1.061722239706649, "mean_action_processing_ms": 0.07091976709762564, "mean_env_wait_ms": 0.17443886574019235, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 644436, "agent_timesteps_total": 644436, "timers": {"sample_time_ms": 0.076, "sample_throughput": 72024949.534, "learn_time_ms": 14.037, "learn_throughput": 392399.17, "update_time_ms": 5.586}, "info": {"learner": {"learned": {"policy_loss": 1.2566343545913696, "vf_loss": 21.84596824645996, "total_loss": 23.102602005004883, "vf_explained_var": -0.004845023155212402, "model": {}}}, "num_steps_sampled": 644436, "num_agent_steps_sampled": 644436, "num_steps_trained": 644436, "num_agent_steps_trained": 644436}, "done": false, "episodes_total": 12636, "training_iteration": 117, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-11", "timestamp": 1626864491, "time_this_iter_s": 0.34456968307495117, "time_total_s": 42.45804476737976, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 42.45804476737976, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 75.7, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.425925925925927, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -24.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 6.106481481481482}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-15.0, 7.0, 12.0, 11.0, 14.0, 13.0, -11.0, -1.0, 9.0, 10.0, 1.0, -5.0, 13.0, -13.0, 11.0, 4.0, -2.0, 12.0, -8.0, 13.0, 9.0, 13.0, -6.0, -1.0, 4.0, 13.0, -13.0, 11.0, 12.0, -3.0, -2.0, 8.0, 11.0, 13.0, 317.0, 13.0, 9.0, 13.0, -6.0, -1.0, 10.0, 13.0, -19.0, 11.0, 12.0, -10.0, 6.0, 7.0, 14.0, -11.0, 12.0, 0.0, 12.0, 8.0, -12.0, 7.0, 7.0, 0.0, 11.0, -3.0, 9.0, -5.0, 12.0, -1.0, 5.0, -1.0, 0.0, 11.0, -1.0, 13.0, 4.0, -1.0, 8.0, 8.0, 7.0, -8.0, 12.0, -4.0, 8.0, -1.0, -12.0, 12.0, 11.0, 4.0, 14.0, 4.0, -11.0, 8.0, 13.0, 13.0, -3.0, -8.0, 9.0, 1.0, -3.0, 8.0, -10.0, 10.0, 10.0, 5.0, 13.0, 3.0, 10.0, -11.0, 10.0, -3.0, 6.0, 2.0, 11.0, 3.0, -3.0, 4.0, -2.0, 9.0, 8.0, 0.0, 9.0, 14.0, -7.0, -1.0, 12.0, 5.0, 3.0, -5.0, 8.0, -2.0, -4.0, 13.0, -19.0, 13.0, 11.0, 10.0, 13.0, 10.0, -7.0, -1.0, 9.0, -7.0, 7.0, 6.0, 3.0, -12.0, 11.0, 13.0, 6.0, -2.0, 7.0, 4.0, 14.0, 13.0, 315.0, 13.0, 5.0, -6.0, 5.0, 11.0, 9.0, 3.0, 10.0, -7.0, -3.0, 12.0, -7.0, 13.0, 11.0, 13.0, -8.0, -1.0, -12.0, 8.0, 7.0, 12.0, 5.0, 1.0, 12.0, -3.0, 11.0, -2.0, 11.0, -5.0, 1.0, 8.0, 7.0, -1.0, -7.0, 13.0, 11.0, -2.0, 13.0, -5.0, -5.0, 12.0, -10.0, 8.0, 5.0, 12.0, 8.0, 14.0, -15.0, 8.0, -9.0, 9.0, 7.0, 8.0, -2.0, 3.0, 6.0, 8.0, 8.0, 13.0, 13.0, -19.0, 11.0, 13.0, -8.0, -1.0, 8.0, 9.0, 12.0, -14.0, 12.0, -17.0, 12.0, 8.0, 2.0, -3.0, 4.0, 12.0, 12.0, 10.0, -12.0, 5.0, 6.0, -1.0, 11.0, -1.0, 6.0, 0.0, 10.0, -1.0, 3.0, -5.0, 9.0, 8.0, 7.0, 6.0, 6.0, -4.0, 8.0, -3.0, 7.0, 3.0, 7.0, -9.0, 9.0, 8.0, 7.0, 12.0, 13.0, -17.0, 13.0, 7.0, 4.0, -9.0, 10.0, 13.0, -21.0, 13.0, -11.0, 2.0, 12.0, 12.0, -9.0, 11.0, 4.0, 9.0, 12.0, 13.0, -9.0, -1.0, -9.0, 9.0, 10.0, 5.0, 4.0, 4.0, 12.0, -5.0, 4.0, 12.0, 6.0, -7.0, 10.0, 14.0, -22.0, 13.0, 7.0, 9.0, 5.0, -6.0, 12.0, 5.0, 9.0, -11.0, 5.0, -13.0, 13.0, 10.0, 12.0, 13.0, 2.0, -12.0, 11.0, -6.0, 7.0, 3.0, 11.0, -2.0, -3.0, 9.0, 5.0, 12.0, 8.0, -10.0, 12.0, 14.0, -24.0, 13.0, 10.0, -3.0, 6.0, 2.0, 12.0, -1.0, -1.0, 5.0, -9.0, 2.0, 11.0, 11.0, 14.0, 4.0, -10.0, 7.0, 13.0, -2.0, 12.0, -8.0, 13.0, 2.0, 7.0, -7.0, -9.0, 10.0, 7.0, 7.0, 13.0, 13.0, -19.0, 8.0, 3.0, -5.0, 7.0, 10.0, 5.0, -10.0, 11.0, 9.0, 5.0, -2.0, 10.0, 2.0, 11.0, 13.0, -8.0, -1.0, 11.0, -6.0, 4.0, 6.0, 1.0, 3.0, -2.0, 13.0, -11.0, 13.0, 10.0, 3.0, 12.0, 14.0, 315.0, 13.0, 8.0, 13.0, 11.0, -17.0, 11.0, 1.0, 12.0, -9.0, 5.0, 12.0, -9.0, 7.0, 9.0, 10.0, 5.0, -9.0, 11.0, -5.0, 11.0, -2.0, 7.0, 1.0, 9.0, -2.0, 0.0, 9.0, -3.0, 9.0, 9.0, 10.0, -6.0, 2.0, 9.0, -2.0, 12.0, -4.0, 5.0, 8.0, 10.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841694437233852, "mean_inference_ms": 1.0617081879396022, "mean_action_processing_ms": 0.0709142903719173, "mean_env_wait_ms": 0.17443176305308844, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 649944, "agent_timesteps_total": 649944, "timers": {"sample_time_ms": 0.077, "sample_throughput": 71600069.024, "learn_time_ms": 14.188, "learn_throughput": 388213.339, "update_time_ms": 5.45}, "info": {"learner": {"learned": {"policy_loss": 231460618240.0, "vf_loss": 234.77989196777344, "total_loss": 231460618240.0, "vf_explained_var": -0.0003434419631958008, "model": {}}}, "num_steps_sampled": 649944, "num_agent_steps_sampled": 649944, "num_steps_trained": 649944, "num_agent_steps_trained": 649944}, "done": false, "episodes_total": 12744, "training_iteration": 118, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-11", "timestamp": 1626864491, "time_this_iter_s": 0.34908342361450195, "time_total_s": 42.80712819099426, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 42.80712819099426, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 83.8, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 0.0, -7.0, 12.0, -8.0, 6.0, 9.0, 8.0, -6.0, 8.0, 4.0, 9.0, 9.0, 11.0, -3.0, -2.0, 10.0, -12.0, 6.0, 11.0, -6.0, 7.0, 5.0, 9.0, 10.0, -7.0, 6.0, 6.0, 14.0, 5.0, -3.0, -1.0, -1.0, -4.0, 10.0, 10.0, -1.0, 7.0, 7.0, 2.0, -3.0, 2.0, 6.0, 10.0, 14.0, 8.0, -4.0, -3.0, -2.0, 5.0, 8.0, 4.0, 6.0, -2.0, 7.0, 4.0, 4.0, 10.0, 4.0, -3.0, 14.0, 7.0, -17.0, 11.0, 10.0, -5.0, 11.0, -1.0, 6.0, 9.0, 2.0, -2.0, 8.0, 10.0, -5.0, 2.0, 12.0, 7.0, -2.0, -2.0, 12.0, 2.0, 6.0, -5.0, -2.0, -1.0, 9.0, 9.0, -6.0, 5.0, 9.0, 7.0, 12.0, 2.0, -9.0, 10.0, 11.0, -14.0, 12.0, 6.0, 6.0, 8.0, 6.0, -5.0, -3.0, 12.0, 9.0, -3.0, 10.0, 7.0, 0.0, -2.0, 7.0, -5.0, 10.0, 3.0, -8.0, 7.0, 7.0, 9.0, -4.0, 12.0, 13.0, -6.0, 10.0, 5.0, 1.0, -1.0, -2.0, 7.0, 4.0, 6.0, -2.0, 6.0, 0.0, 11.0, -10.0, 5.0, 8.0, 12.0, 12.0, 12.0, -6.0, -3.0, 11.0, 3.0, 9.0, -8.0, 13.0, -6.0, 0.0, 8.0, 6.0, 6.0, -4.0, 7.0, 13.0, 3.0, -10.0, 9.0, 11.0, -19.0, 11.0, 12.0, 12.0, -13.0, 5.0, 11.0, -6.0, 6.0, 4.0, 11.0, 11.0, 2.0, 5.0, -3.0, 11.0, -11.0, 11.0, 4.0, 8.0, 0.0, 10.0, -3.0, -3.0, 12.0, 10.0, -4.0, 13.0, 6.0, -16.0, 12.0, 7.0, -5.0, 7.0, 6.0, 10.0, -6.0, 0.0, 11.0, 6.0, 2.0, -3.0, 10.0, 8.0, 11.0, -1.0, -3.0, 5.0, -6.0, 10.0, 6.0, -1.0, 7.0, 12.0, -3.0, -10.0, 5.0, 8.0, 12.0, 13.0, 8.0, -4.0, -2.0, 12.0, -12.0, 12.0, 3.0, 8.0, 4.0, 12.0, -9.0, 10.0, 14.0, 10.0, -19.0, 13.0, 0.0, -11.0, 13.0, -2.0, 7.0, 12.0, -2.0, -5.0, 0.0, 11.0, 9.0, -4.0, 12.0, 2.0, 5.0, 12.0, 6.0, -2.0, -1.0, 11.0, 1.0, 8.0, -5.0, 9.0, 6.0, 11.0, -11.0, 11.0, 10.0, 10.0, -16.0, 13.0, 3.0, -13.0, 12.0, 12.0, -11.0, 10.0, 4.0, -7.0, 0.0, 11.0, 11.0, 8.0, 3.0, -2.0, 6.0, 12.0, 7.0, -16.0, 12.0, 7.0, -9.0, 11.0, 6.0, -2.0, 8.0, 12.0, -3.0, -2.0, 1.0, 6.0, 10.0, 12.0, 7.0, -1.0, -3.0, -2.0, 1.0, 5.0, 11.0, -3.0, 2.0, 6.0, 10.0, 9.0, -7.0, 7.0, 6.0, 9.0, 1.0, -8.0, 13.0, 6.0, 6.0, 6.0, -3.0, 8.0, 6.0, 7.0, -6.0, 11.0, -14.0, 10.0, 8.0, 12.0, 7.0, -15.0, 11.0, 12.0, -6.0, 13.0, -4.0, 0.0, 4.0, 6.0, 5.0, -5.0, 2.0, 12.0, 6.0, 13.0, 6.0, -2.0, -2.0, 7.0, 7.0, 8.0, -7.0, 5.0, 2.0, 11.0, -3.0, -2.0, 0.0, 12.0, 5.0, 14.0, 3.0, 12.0, -14.0, -7.0, 7.0, 6.0, 9.0, -7.0, 6.0, 7.0, 9.0, 13.0, -16.0, 7.0, 11.0, 14.0, 7.0, 9.0, -15.0, 12.0, 2.0, 11.0, -10.0, -2.0, 4.0, 2.0, 11.0, 6.0, 2.0, 9.0, -2.0, 12.0, 2.0, 5.0, -4.0, 9.0, -10.0, 13.0, 3.0, -1.0, 1.0, 7.0, 8.0, -5.0, 13.0, 6.0, 1.0, 13.0, 5.0, -1.0, -2.0, 9.0, -13.0, 13.0, 6.0, 9.0, -9.0, 5.0, 10.0, 10.0, -4.0, 1.0, 8.0, 13.0, 8.0, -3.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18417574930908398, "mean_inference_ms": 1.0618331622105064, "mean_action_processing_ms": 0.07091957867144538, "mean_env_wait_ms": 0.1744394741363389, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 655452, "agent_timesteps_total": 655452, "timers": {"sample_time_ms": 0.074, "sample_throughput": 74703788.649, "learn_time_ms": 13.865, "learn_throughput": 397249.21, "update_time_ms": 5.226}, "info": {"learner": {"learned": {"policy_loss": 110560460800.0, "vf_loss": 126.25829315185547, "total_loss": 110560460800.0, "vf_explained_var": -0.0007891654968261719, "model": {}}}, "num_steps_sampled": 655452, "num_agent_steps_sampled": 655452, "num_steps_trained": 655452, "num_agent_steps_trained": 655452}, "done": false, "episodes_total": 12852, "training_iteration": 119, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-11", "timestamp": 1626864491, "time_this_iter_s": 0.3539121150970459, "time_total_s": 43.16104030609131, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 43.16104030609131, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, 7.0, 12.0, 2.0, 9.0, -4.0, 13.0, -3.0, 14.0, -7.0, 12.0, -4.0, -10.0, 14.0, 6.0, 5.0, -5.0, 13.0, 13.0, -6.0, -8.0, 7.0, 12.0, 4.0, 11.0, 0.0, 8.0, -4.0, -8.0, 9.0, 9.0, 5.0, 13.0, 12.0, -1.0, -9.0, 11.0, 7.0, -10.0, 7.0, 13.0, 2.0, 6.0, -6.0, -4.0, 14.0, 10.0, -5.0, -4.0, 13.0, 8.0, -2.0, 13.0, -4.0, 0.0, 6.0, 11.0, 4.0, 6.0, -6.0, -12.0, 10.0, 9.0, 8.0, 10.0, 10.0, 13.0, -18.0, 13.0, 4.0, 13.0, -15.0, 12.0, -7.0, 13.0, -3.0, -7.0, 14.0, 5.0, 3.0, -11.0, 12.0, 8.0, 6.0, -3.0, 14.0, 6.0, -2.0, 13.0, 2.0, 4.0, -4.0, -2.0, 12.0, -3.0, 8.0, -8.0, 0.0, 11.0, 12.0, 12.0, 12.0, -11.0, 2.0, 14.0, -8.0, 12.0, -3.0, -16.0, 14.0, 11.0, 6.0, -3.0, 13.0, 8.0, -3.0, 0.0, 9.0, 13.0, -7.0, 12.0, 4.0, 0.0, -1.0, -13.0, 13.0, 9.0, 6.0, -13.0, 11.0, 13.0, 4.0, 13.0, 0.0, 6.0, -4.0, 13.0, -7.0, 12.0, -3.0, -3.0, 10.0, 11.0, -3.0, -8.0, 4.0, 6.0, 13.0, 12.0, -4.0, 10.0, -3.0, 13.0, -1.0, 9.0, -6.0, 10.0, -2.0, 0.0, 7.0, 14.0, 11.0, 4.0, -14.0, 12.0, 8.0, -1.0, -4.0, 13.0, 321.0, 12.0, 10.0, -8.0, 11.0, 5.0, 7.0, -8.0, 11.0, 12.0, 0.0, -4.0, 10.0, 7.0, 2.0, 13.0, -1.0, 6.0, -3.0, -11.0, 11.0, 9.0, 6.0, -7.0, 6.0, 3.0, 13.0, 8.0, 12.0, 8.0, -13.0, 12.0, -2.0, 9.0, -4.0, -5.0, 13.0, 1.0, 6.0, 11.0, 13.0, -21.0, 12.0, 9.0, -3.0, 12.0, -3.0, 12.0, -5.0, 12.0, -4.0, 3.0, 14.0, -7.0, 5.0, -4.0, 7.0, 1.0, 11.0, 9.0, 13.0, -9.0, 2.0, 11.0, 0.0, 8.0, -4.0, -2.0, 12.0, 6.0, -1.0, 10.0, 13.0, 13.0, -21.0, -14.0, 12.0, 13.0, 4.0, 7.0, -17.0, 13.0, 12.0, -8.0, 13.0, 3.0, 7.0, 11.0, 4.0, 13.0, -13.0, 6.0, -1.0, 5.0, 5.0, 10.0, -19.0, 13.0, 11.0, -8.0, 10.0, 5.0, 8.0, 11.0, 10.0, 12.0, -18.0, 4.0, -6.0, 11.0, 6.0, 13.0, -2.0, -8.0, 12.0, -4.0, 11.0, 2.0, 6.0, 10.0, -4.0, 8.0, 1.0, 8.0, 13.0, -8.0, 2.0, 13.0, -15.0, 8.0, 9.0, -1.0, 9.0, 2.0, 5.0, -15.0, 13.0, 4.0, 13.0, 13.0, 9.0, 5.0, -12.0, 13.0, 3.0, 1.0, -2.0, 5.0, -3.0, 5.0, 8.0, -2.0, 12.0, 7.0, -2.0, 12.0, 11.0, 6.0, -14.0, 14.0, 1.0, 5.0, -5.0, -6.0, 11.0, 6.0, 4.0, 11.0, 13.0, 8.0, -17.0, 12.0, 11.0, 7.0, -15.0, 9.0, 3.0, 4.0, -1.0, 2.0, 0.0, 6.0, 7.0, -5.0, 11.0, 13.0, -4.0, 11.0, -1.0, 1.0, 4.0, -4.0, 4.0, 3.0, 12.0, -15.0, 12.0, 12.0, 6.0, -6.0, 8.0, 13.0, 0.0, 11.0, 6.0, 9.0, -11.0, 13.0, -5.0, 12.0, -5.0, -5.0, 14.0, -2.0, 8.0, 11.0, 14.0, -17.0, 7.0, 10.0, -8.0, 13.0, 0.0, 10.0, 1.0, -9.0, 13.0, 5.0, -1.0, 11.0, 0.0, 13.0, 14.0, -8.0, -4.0, 12.0, 13.0, 5.0, -15.0, 11.0, -10.0, 4.0, 10.0, 6.0, 14.0, -10.0, 5.0, 10.0, -4.0, 13.0, -4.0, -2.0, 14.0, 12.0, -9.0, 7.0, 2.0, 13.0, -7.0, 7.0, -5.0, 6.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18415305514221847, "mean_inference_ms": 1.061724536372424, "mean_action_processing_ms": 0.0709125233031408, "mean_env_wait_ms": 0.17441197169487022, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 660960, "agent_timesteps_total": 660960, "timers": {"sample_time_ms": 0.075, "sample_throughput": 73280736.248, "learn_time_ms": 13.805, "learn_throughput": 398976.688, "update_time_ms": 5.422}, "info": {"learner": {"learned": {"policy_loss": 77898964992.0, "vf_loss": 124.52226257324219, "total_loss": 77898964992.0, "vf_explained_var": -0.0011272430419921875, "model": {}}}, "num_steps_sampled": 660960, "num_agent_steps_sampled": 660960, "num_steps_trained": 660960, "num_agent_steps_trained": 660960}, "done": false, "episodes_total": 12960, "training_iteration": 120, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-12", "timestamp": 1626864492, "time_this_iter_s": 0.3518717288970947, "time_total_s": 43.5129120349884, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7e18>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 43.5129120349884, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 77.1, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 5.0, 13.0, 6.0, 9.0, 10.0, -5.0, 1.0, 3.0, 13.0, -10.0, 9.0, -11.0, 10.0, 8.0, 8.0, 9.0, -10.0, 9.0, 7.0, 8.0, 14.0, -10.0, 3.0, 13.0, 12.0, -21.0, 11.0, 13.0, -11.0, 8.0, 5.0, -8.0, 10.0, 6.0, 7.0, 14.0, 13.0, -3.0, -9.0, 7.0, 10.0, -4.0, 2.0, 9.0, 11.0, 7.0, -12.0, 7.0, -2.0, 11.0, -1.0, 7.0, 8.0, 6.0, -6.0, -8.0, 6.0, 10.0, 7.0, 4.0, 7.0, 11.0, -7.0, -1.0, 4.0, 8.0, 4.0, 7.0, 12.0, -1.0, -3.0, 9.0, 10.0, -6.0, 2.0, 10.0, 1.0, 13.0, -9.0, 7.0, -3.0, 7.0, 4.0, 14.0, 13.0, -12.0, 0.0, 8.0, 11.0, 6.0, -10.0, 5.0, 9.0, 10.0, -9.0, 9.0, -4.0, 6.0, 4.0, 9.0, 6.0, 9.0, -9.0, 2.0, 6.0, 12.0, -5.0, 9.0, -2.0, 12.0, -4.0, 7.0, -3.0, 6.0, 5.0, 14.0, 8.0, 10.0, -17.0, 3.0, 11.0, -10.0, 11.0, 2.0, 10.0, 12.0, -9.0, 6.0, -10.0, 6.0, 13.0, 4.0, 11.0, -5.0, 5.0, -10.0, 7.0, 10.0, 8.0, 8.0, -6.0, 5.0, 8.0, 14.0, 5.0, 9.0, -13.0, 13.0, 11.0, 5.0, -14.0, 7.0, 10.0, -14.0, 12.0, 3.0, -2.0, 12.0, 2.0, 13.0, -10.0, 4.0, 8.0, 13.0, 10.0, -13.0, 5.0, -1.0, 12.0, -7.0, 11.0, 6.0, -9.0, 8.0, 10.0, 4.0, -10.0, 12.0, 9.0, 7.0, 7.0, -3.0, 4.0, -11.0, 12.0, 6.0, 8.0, 7.0, 9.0, 8.0, -9.0, -8.0, 2.0, 9.0, 12.0, 14.0, 9.0, -2.0, -6.0, 7.0, 8.0, -13.0, 13.0, 0.0, 10.0, 12.0, -7.0, 9.0, 5.0, 7.0, -6.0, 8.0, 6.0, -5.0, 6.0, 5.0, 4.0, 12.0, -6.0, 8.0, -9.0, 8.0, 8.0, 8.0, 11.0, 7.0, -11.0, -11.0, 13.0, 9.0, 4.0, 5.0, 8.0, -6.0, 8.0, 8.0, 9.0, 12.0, -14.0, 14.0, -13.0, 8.0, 6.0, 9.0, 11.0, 2.0, -7.0, 4.0, 13.0, 4.0, -6.0, 7.0, -1.0, 8.0, 1.0, 0.0, -5.0, 7.0, 13.0, -1.0, 5.0, 2.0, 9.0, -1.0, 12.0, -4.0, 8.0, 7.0, 12.0, 8.0, -12.0, 7.0, -10.0, 11.0, 7.0, 7.0, 10.0, 5.0, -7.0, 4.0, 11.0, -9.0, 9.0, 5.0, -4.0, 8.0, 6.0, -11.0, 8.0, 5.0, 13.0, 14.0, 12.0, -15.0, 4.0, 9.0, 6.0, 11.0, -11.0, 9.0, 11.0, 6.0, -11.0, 10.0, 1.0, -9.0, 13.0, 13.0, 8.0, -10.0, 4.0, 1.0, 9.0, -8.0, 13.0, -4.0, 4.0, 12.0, 3.0, 7.0, 7.0, 8.0, -7.0, -10.0, 11.0, 8.0, 6.0, 8.0, 6.0, -7.0, 8.0, 10.0, 12.0, 8.0, -15.0, -7.0, 9.0, 10.0, 3.0, 9.0, 12.0, -17.0, 11.0, 3.0, 8.0, -4.0, 8.0, 13.0, -11.0, 6.0, 7.0, 7.0, -6.0, 8.0, 6.0, -5.0, 12.0, 8.0, 0.0, -1.0, 12.0, -8.0, 12.0, 7.0, 10.0, 10.0, -12.0, -8.0, 5.0, 8.0, 10.0, 8.0, -4.0, 1.0, 10.0, 9.0, 12.0, -14.0, 8.0, -14.0, 13.0, 11.0, 5.0, 13.0, 2.0, -7.0, 7.0, 9.0, 6.0, -6.0, 6.0, 0.0, 10.0, -4.0, 9.0, 6.0, 9.0, 5.0, -5.0, 8.0, -2.0, 3.0, 6.0, 13.0, 11.0, -15.0, 6.0, -5.0, 10.0, 7.0, 3.0, -5.0, 13.0, 8.0, -1.0, -1.0, -5.0, 12.0, 9.0, 3.0, 13.0, 8.0, -9.0, -13.0, 11.0, 6.0, 11.0, 5.0, 12.0, 11.0, -13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841589097383799, "mean_inference_ms": 1.0616514335584644, "mean_action_processing_ms": 0.07091268850888344, "mean_env_wait_ms": 0.1744036908841871, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 666468, "agent_timesteps_total": 666468, "timers": {"sample_time_ms": 0.075, "sample_throughput": 72965625.925, "learn_time_ms": 13.796, "learn_throughput": 399242.833, "update_time_ms": 5.669}, "info": {"learner": {"learned": {"policy_loss": 127986180096.0, "vf_loss": 121.60709381103516, "total_loss": 127986180096.0, "vf_explained_var": -0.0012229681015014648, "model": {}}}, "num_steps_sampled": 666468, "num_agent_steps_sampled": 666468, "num_steps_trained": 666468, "num_agent_steps_trained": 666468}, "done": false, "episodes_total": 13068, "training_iteration": 121, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-12", "timestamp": 1626864492, "time_this_iter_s": 0.36305880546569824, "time_total_s": 43.8759708404541, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 43.8759708404541, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -2.0, -4.0, 11.0, 12.0, -9.0, 1.0, 11.0, 4.0, 13.0, 11.0, -13.0, -13.0, 10.0, 9.0, 9.0, 1.0, 8.0, 11.0, -5.0, 14.0, -12.0, 6.0, 7.0, 5.0, -2.0, 6.0, 6.0, 11.0, 10.0, 4.0, -10.0, 7.0, 7.0, -4.0, 5.0, 11.0, 8.0, -3.0, -1.0, 5.0, 14.0, 8.0, -12.0, 3.0, 5.0, -4.0, 11.0, 6.0, -7.0, 6.0, 10.0, 12.0, 9.0, 0.0, -6.0, 11.0, 13.0, 0.0, -9.0, 11.0, 12.0, -12.0, 4.0, -8.0, 13.0, 1.0, 9.0, 8.0, -3.0, 6.0, 4.0, 7.0, -4.0, 12.0, 0.0, 5.0, 12.0, 3.0, -5.0, 7.0, 13.0, -1.0, -4.0, 12.0, 8.0, 0.0, -5.0, 4.0, 8.0, 10.0, -7.0, -6.0, 12.0, 12.0, -3.0, 3.0, 4.0, 12.0, -4.0, 7.0, 12.0, -6.0, 2.0, 6.0, 12.0, 12.0, -15.0, -4.0, -1.0, 10.0, 10.0, 9.0, 7.0, 4.0, -5.0, 7.0, 13.0, -10.0, 5.0, 8.0, -2.0, 12.0, -3.0, -4.0, 12.0, 9.0, -2.0, 13.0, -3.0, -4.0, 9.0, 11.0, -12.0, 8.0, 8.0, -13.0, 13.0, 3.0, 12.0, 0.0, -3.0, 8.0, 10.0, 8.0, -1.0, -5.0, 13.0, 12.0, -9.0, 3.0, 9.0, 6.0, -5.0, 13.0, 1.0, -2.0, 13.0, -3.0, 7.0, 12.0, -12.0, 11.0, 4.0, 13.0, -1.0, 9.0, -6.0, 8.0, 7.0, 12.0, -12.0, 3.0, -2.0, 5.0, 9.0, 3.0, -4.0, 6.0, 10.0, 4.0, 12.0, 10.0, -11.0, 11.0, -4.0, 12.0, -4.0, 12.0, 13.0, -14.0, 4.0, 9.0, -3.0, -2.0, 11.0, 13.0, -3.0, 2.0, 3.0, 1.0, 10.0, 12.0, -8.0, -3.0, 12.0, 3.0, 3.0, 6.0, 14.0, -14.0, 9.0, 13.0, -3.0, 1.0, 4.0, 11.0, 11.0, 7.0, -14.0, 11.0, 10.0, -11.0, 5.0, 10.0, 14.0, 11.0, -20.0, 12.0, 12.0, 1.0, -10.0, 8.0, 7.0, 12.0, -12.0, -11.0, 8.0, 6.0, 12.0, 5.0, 13.0, -15.0, 12.0, 10.0, -2.0, -1.0, 8.0, 5.0, 12.0, 11.0, -13.0, -2.0, 12.0, 0.0, 5.0, -4.0, 9.0, 6.0, 4.0, 9.0, 13.0, -7.0, 0.0, 5.0, 12.0, 12.0, -14.0, 13.0, 13.0, 2.0, -13.0, 3.0, 7.0, -6.0, 11.0, 14.0, 3.0, 1.0, -3.0, 11.0, 7.0, 12.0, -15.0, -19.0, 13.0, 8.0, 13.0, 12.0, 6.0, -3.0, 0.0, 13.0, -8.0, 7.0, 3.0, 5.0, 12.0, 12.0, -14.0, 7.0, 10.0, 12.0, -14.0, 6.0, 12.0, 1.0, -4.0, -6.0, 13.0, 6.0, 2.0, -10.0, 9.0, 13.0, 3.0, 0.0, 8.0, -3.0, 10.0, 6.0, -6.0, 10.0, 5.0, 11.0, 13.0, -19.0, 10.0, 8.0, 8.0, 10.0, -11.0, 5.0, 11.0, -8.0, 7.0, 8.0, 14.0, -4.0, -3.0, 7.0, -3.0, 7.0, 4.0, 7.0, 9.0, 9.0, -10.0, 320.0, 12.0, 13.0, 11.0, 6.0, 0.0, 10.0, -1.0, 11.0, 9.0, 10.0, -15.0, -1.0, 13.0, 12.0, -9.0, -2.0, 10.0, -2.0, 9.0, 6.0, 8.0, -5.0, 6.0, 14.0, -11.0, 6.0, 6.0, 4.0, -2.0, 10.0, 3.0, -15.0, 10.0, 9.0, 11.0, 1.0, -1.0, 11.0, 4.0, 5.0, -7.0, 8.0, 9.0, 7.0, 12.0, -3.0, -1.0, 14.0, 13.0, -14.0, 2.0, 5.0, 9.0, 6.0, -5.0, 5.0, -2.0, 1.0, 11.0, 10.0, -4.0, 4.0, 5.0, 1.0, 11.0, 10.0, -7.0, 1.0, 14.0, 4.0, -4.0, 12.0, 0.0, 6.0, -3.0, 7.0, -1.0, 11.0, -2.0, -13.0, 11.0, 11.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841600628587941, "mean_inference_ms": 1.0616202878545227, "mean_action_processing_ms": 0.0709159174388546, "mean_env_wait_ms": 0.17441552676784677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 671976, "agent_timesteps_total": 671976, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70433070.962, "learn_time_ms": 14.041, "learn_throughput": 392271.909, "update_time_ms": 6.04}, "info": {"learner": {"learned": {"policy_loss": 1.2368830442428589, "vf_loss": 16.328298568725586, "total_loss": 17.565181732177734, "vf_explained_var": -0.008597016334533691, "model": {}}}, "num_steps_sampled": 671976, "num_agent_steps_sampled": 671976, "num_steps_trained": 671976, "num_agent_steps_trained": 671976}, "done": false, "episodes_total": 13176, "training_iteration": 122, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-13", "timestamp": 1626864493, "time_this_iter_s": 0.3647925853729248, "time_total_s": 44.240763425827026, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829a268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 44.240763425827026, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 73.8, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.27777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.319444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 10.0, 10.0, -18.0, 8.0, 12.0, -8.0, 3.0, 11.0, -17.0, 8.0, 13.0, 4.0, 13.0, -6.0, 4.0, 13.0, 13.0, 5.0, -16.0, -15.0, 11.0, 11.0, 8.0, -3.0, -1.0, 9.0, 10.0, 7.0, 11.0, -11.0, 8.0, 13.0, 10.0, 2.0, -10.0, 9.0, 10.0, -12.0, 8.0, 13.0, 2.0, 9.0, -9.0, 7.0, 14.0, 0.0, -6.0, 9.0, 8.0, -10.0, 8.0, 12.0, 11.0, 6.0, -14.0, -3.0, 1.0, 7.0, 10.0, 11.0, -6.0, 3.0, 7.0, 5.0, 11.0, 3.0, -4.0, 13.0, 11.0, -18.0, 9.0, 11.0, -6.0, -1.0, 11.0, 11.0, -4.0, 1.0, 7.0, 9.0, 9.0, 8.0, -11.0, 1.0, 11.0, -6.0, 9.0, -4.0, 0.0, 9.0, 10.0, 9.0, 9.0, -13.0, 10.0, 0.0, 11.0, -8.0, 12.0, 8.0, 12.0, 1.0, -6.0, -2.0, -2.0, 11.0, 8.0, 12.0, -3.0, 10.0, -4.0, 319.0, 13.0, 11.0, 11.0, 9.0, 11.0, -8.0, 3.0, -2.0, -1.0, 7.0, 11.0, -9.0, 12.0, 3.0, 9.0, 13.0, -12.0, 2.0, 12.0, -1.0, 12.0, 11.0, -7.0, -3.0, 5.0, 8.0, 5.0, 10.0, 12.0, -17.0, 10.0, 13.0, 11.0, 9.0, -18.0, 5.0, 11.0, 8.0, -9.0, -3.0, -2.0, 8.0, 12.0, 2.0, 10.0, -7.0, 10.0, 14.0, 12.0, 6.0, -17.0, 9.0, 12.0, -12.0, 6.0, -4.0, 1.0, 11.0, 7.0, 7.0, 10.0, -12.0, 10.0, 9.0, 4.0, -7.0, 9.0, 6.0, 12.0, 8.0, -11.0, -3.0, -1.0, 12.0, 7.0, -4.0, 11.0, 5.0, 3.0, -11.0, 10.0, 5.0, 11.0, 6.0, 12.0, -10.0, 7.0, -7.0, 2.0, 11.0, 9.0, 10.0, 10.0, -16.0, 11.0, 8.0, 8.0, -9.0, 8.0, 4.0, 11.0, 6.0, -6.0, -3.0, 1.0, 12.0, 5.0, 9.0, 10.0, 6.0, -10.0, 9.0, 7.0, 3.0, -4.0, 3.0, 12.0, -6.0, 6.0, -3.0, 0.0, 8.0, 10.0, -5.0, 13.0, 4.0, 3.0, 14.0, -10.0, 0.0, 11.0, 3.0, 10.0, -6.0, 8.0, -3.0, -3.0, 9.0, 12.0, -10.0, 11.0, 7.0, 7.0, -3.0, 10.0, -3.0, 11.0, 7.0, 11.0, 5.0, -8.0, -1.0, -5.0, 12.0, 9.0, 9.0, 10.0, -9.0, 5.0, 13.0, 13.0, 13.0, 315.0, 8.0, 11.0, 4.0, -8.0, -2.0, 4.0, 7.0, 6.0, 5.0, 13.0, 4.0, -7.0, 11.0, 11.0, 13.0, -20.0, 4.0, 12.0, -8.0, 7.0, 13.0, 2.0, -8.0, 8.0, 2.0, 8.0, -8.0, 13.0, 7.0, 12.0, 12.0, -16.0, 5.0, 12.0, 7.0, -9.0, 10.0, 1.0, 10.0, -6.0, 7.0, 12.0, -12.0, 8.0, 10.0, 11.0, 8.0, -14.0, 3.0, 12.0, 3.0, -3.0, -3.0, -2.0, 8.0, 12.0, 11.0, 12.0, -6.0, -2.0, 8.0, 11.0, 13.0, -17.0, 13.0, 12.0, -18.0, 8.0, 8.0, -15.0, 11.0, 11.0, 0.0, 8.0, 12.0, -5.0, 9.0, 9.0, -12.0, 9.0, 13.0, 6.0, 6.0, -10.0, -4.0, 1.0, 11.0, 7.0, 7.0, 12.0, -7.0, 3.0, 9.0, 2.0, 9.0, -5.0, 13.0, 12.0, -1.0, -9.0, -4.0, 5.0, 8.0, 6.0, 11.0, 12.0, 3.0, -11.0, 8.0, 11.0, 11.0, -15.0, 8.0, 12.0, -12.0, 7.0, 13.0, 1.0, 10.0, -9.0, 7.0, 11.0, 8.0, -11.0, -8.0, 10.0, 13.0, 0.0, 1.0, 11.0, -5.0, 8.0, -3.0, -5.0, 10.0, 13.0, 9.0, 12.0, -11.0, 5.0, -2.0, -8.0, 12.0, 13.0, 0.0, 11.0, -6.0, 10.0, -2.0, -7.0, 12.0, 12.0, 7.0, 9.0, -12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18414225214629784, "mean_inference_ms": 1.061675368769422, "mean_action_processing_ms": 0.07091598902227936, "mean_env_wait_ms": 0.17440375524216456, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 677484, "agent_timesteps_total": 677484, "timers": {"sample_time_ms": 0.077, "sample_throughput": 71195076.445, "learn_time_ms": 13.94, "learn_throughput": 395128.694, "update_time_ms": 5.753}, "info": {"learner": {"learned": {"policy_loss": 1.2693839073181152, "vf_loss": 19.045757293701172, "total_loss": 20.315141677856445, "vf_explained_var": -0.007469058036804199, "model": {}}}, "num_steps_sampled": 677484, "num_agent_steps_sampled": 677484, "num_steps_trained": 677484, "num_agent_steps_trained": 677484}, "done": false, "episodes_total": 13284, "training_iteration": 123, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-13", "timestamp": 1626864493, "time_this_iter_s": 0.35645151138305664, "time_total_s": 44.59721493721008, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829ab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 44.59721493721008, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 8.0, -17.0, 12.0, -15.0, 10.0, 10.0, 10.0, 14.0, 4.0, 8.0, -11.0, -16.0, 14.0, 6.0, 11.0, 11.0, 3.0, -2.0, 3.0, -17.0, 12.0, 11.0, 9.0, 14.0, 9.0, 3.0, -11.0, -14.0, 13.0, 4.0, 12.0, -7.0, 9.0, 2.0, 11.0, 2.0, -3.0, 11.0, 5.0, 11.0, 5.0, 7.0, -8.0, 8.0, 10.0, -14.0, 11.0, 10.0, 7.0, 3.0, -5.0, -1.0, -3.0, 8.0, 11.0, 13.0, -4.0, -2.0, 8.0, -14.0, 14.0, 12.0, 3.0, 13.0, 5.0, 9.0, -12.0, 10.0, -12.0, 7.0, 10.0, 8.0, 5.0, 8.0, -6.0, -4.0, 13.0, 12.0, -6.0, -2.0, 2.0, 8.0, 7.0, 7.0, 8.0, -13.0, 13.0, 11.0, 8.0, -12.0, 8.0, -13.0, 12.0, 4.0, 12.0, -5.0, 4.0, 9.0, 7.0, 8.0, 12.0, -18.0, 13.0, 9.0, 9.0, -8.0, 5.0, -1.0, 14.0, 5.0, -3.0, 12.0, 4.0, -4.0, 3.0, 1.0, -5.0, 8.0, 11.0, 13.0, 6.0, -7.0, 3.0, 5.0, 9.0, 11.0, -10.0, 12.0, 3.0, -13.0, 13.0, 3.0, -4.0, 10.0, 6.0, 6.0, 14.0, 4.0, -9.0, -15.0, 13.0, 11.0, 6.0, -3.0, 2.0, 7.0, 9.0, -2.0, -3.0, 10.0, 10.0, 5.0, 14.0, -12.0, 8.0, -5.0, 6.0, 4.0, 10.0, -4.0, 2.0, 5.0, 12.0, -3.0, 10.0, -3.0, 11.0, 5.0, 12.0, 8.0, -10.0, -14.0, 12.0, 5.0, 12.0, -4.0, 4.0, 3.0, 12.0, 5.0, -3.0, 10.0, 3.0, 8.0, 8.0, 12.0, -13.0, 320.0, 14.0, 10.0, 11.0, 7.0, 8.0, -12.0, 12.0, 0.0, 6.0, -4.0, 13.0, 8.0, 6.0, -6.0, 7.0, 8.0, 12.0, -2.0, -3.0, 13.0, 7.0, -15.0, 10.0, 4.0, -8.0, 6.0, 13.0, 2.0, -5.0, 10.0, 8.0, 8.0, 13.0, 12.0, -18.0, -3.0, 4.0, 4.0, 10.0, 7.0, -8.0, 5.0, 11.0, 4.0, 8.0, 9.0, -6.0, -7.0, 14.0, -4.0, 12.0, -2.0, 9.0, 9.0, -1.0, -2.0, 11.0, 10.0, -4.0, 6.0, 5.0, -9.0, 13.0, 7.0, 13.0, 11.0, -16.0, 11.0, 5.0, -8.0, 7.0, -1.0, -3.0, 11.0, 8.0, 12.0, 2.0, 8.0, -7.0, -16.0, 14.0, 11.0, 6.0, -1.0, -1.0, 5.0, 12.0, 8.0, -7.0, 4.0, 10.0, 7.0, 5.0, -9.0, 12.0, -11.0, 13.0, 12.0, 1.0, 11.0, 3.0, 5.0, -4.0, 7.0, 6.0, -8.0, 10.0, 8.0, 5.0, -5.0, 7.0, -10.0, 14.0, 11.0, 0.0, -5.0, 4.0, 5.0, 11.0, 9.0, 11.0, 8.0, -13.0, 13.0, 7.0, 3.0, -8.0, 12.0, 6.0, 12.0, -15.0, 11.0, 7.0, 6.0, -9.0, 10.0, 10.0, -15.0, 10.0, 10.0, -6.0, 7.0, 4.0, -17.0, 12.0, 9.0, 11.0, 6.0, 8.0, -11.0, 12.0, 3.0, 11.0, 8.0, -7.0, 13.0, -13.0, 12.0, 3.0, -1.0, 13.0, -9.0, 12.0, 10.0, 10.0, -3.0, -2.0, 0.0, 11.0, 11.0, -7.0, 11.0, 9.0, -3.0, -2.0, -16.0, 13.0, 6.0, 12.0, 12.0, 9.0, -16.0, 10.0, 1.0, -9.0, 11.0, 12.0, 2.0, 11.0, 12.0, -10.0, -4.0, 10.0, 2.0, 7.0, 12.0, 8.0, -7.0, 2.0, 10.0, 10.0, -13.0, 8.0, 11.0, 2.0, 8.0, -6.0, 0.0, 5.0, 2.0, 8.0, 11.0, 9.0, -2.0, -3.0, -2.0, 8.0, -4.0, 13.0, 5.0, 9.0, 11.0, -10.0, 0.0, 13.0, -10.0, 12.0, 9.0, 9.0, -14.0, 11.0, 12.0, -2.0, -3.0, 8.0, 3.0, 10.0, 11.0, -9.0, 3.0, 6.0, 9.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18414671495098356, "mean_inference_ms": 1.0618352141128864, "mean_action_processing_ms": 0.0709197462842423, "mean_env_wait_ms": 0.17440388787174435, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 682992, "agent_timesteps_total": 682992, "timers": {"sample_time_ms": 0.076, "sample_throughput": 72493619.538, "learn_time_ms": 13.908, "learn_throughput": 396035.678, "update_time_ms": 5.712}, "info": {"learner": {"learned": {"policy_loss": 1.2181473970413208, "vf_loss": 21.958086013793945, "total_loss": 23.176233291625977, "vf_explained_var": -0.006528258323669434, "model": {}}}, "num_steps_sampled": 682992, "num_agent_steps_sampled": 682992, "num_steps_trained": 682992, "num_agent_steps_trained": 682992}, "done": false, "episodes_total": 13392, "training_iteration": 124, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-13", "timestamp": 1626864493, "time_this_iter_s": 0.3704414367675781, "time_total_s": 44.96765637397766, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829aea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 44.96765637397766, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 73.0, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-8.0, 13.0, -1.0, 11.0, 12.0, 12.0, 8.0, -17.0, -1.0, 1.0, 4.0, 11.0, 2.0, 13.0, 5.0, -5.0, -7.0, 7.0, 12.0, 3.0, 9.0, 12.0, 13.0, -19.0, -1.0, 14.0, 10.0, -8.0, 8.0, 5.0, 5.0, -3.0, -5.0, 12.0, 3.0, 5.0, 6.0, 11.0, 0.0, -2.0, 9.0, 9.0, -14.0, 11.0, 5.0, 12.0, 6.0, -8.0, -1.0, 10.0, 4.0, 2.0, 5.0, 12.0, -7.0, 5.0, 12.0, 1.0, -9.0, 11.0, -3.0, 13.0, 7.0, -2.0, -8.0, 6.0, 13.0, 4.0, 11.0, 6.0, -12.0, 10.0, 7.0, 13.0, -16.0, 11.0, 8.0, 8.0, 6.0, -7.0, -5.0, 7.0, 5.0, 8.0, -13.0, 12.0, 4.0, 12.0, 7.0, 11.0, 9.0, -12.0, 11.0, 13.0, -8.0, -1.0, 11.0, 9.0, -6.0, 1.0, 12.0, -4.0, 0.0, 7.0, 6.0, 9.0, -6.0, 6.0, 0.0, 10.0, 7.0, -2.0, 10.0, 10.0, 5.0, -10.0, 5.0, 12.0, 13.0, -15.0, 4.0, 14.0, 5.0, -8.0, 12.0, -1.0, 6.0, -2.0, -7.0, 13.0, 3.0, 6.0, 12.0, 10.0, -11.0, 4.0, 13.0, 5.0, -13.0, 10.0, -6.0, 14.0, 8.0, -1.0, -2.0, 5.0, 8.0, 4.0, 6.0, -2.0, 6.0, 5.0, 13.0, -3.0, -5.0, 10.0, 3.0, 14.0, -10.0, 8.0, -4.0, 10.0, 5.0, 4.0, 6.0, 11.0, 6.0, -8.0, -13.0, 13.0, 4.0, 11.0, -1.0, 11.0, -3.0, 8.0, 9.0, 8.0, 6.0, -8.0, 11.0, 9.0, -14.0, 9.0, -13.0, 13.0, 10.0, 5.0, 4.0, 12.0, -7.0, 6.0, 10.0, 10.0, 3.0, -8.0, 7.0, 10.0, 10.0, -12.0, 12.0, 10.0, -18.0, 11.0, 8.0, 13.0, 7.0, -13.0, -7.0, 12.0, 3.0, 7.0, 13.0, 12.0, 10.0, -20.0, 9.0, 10.0, 10.0, -14.0, 0.0, 13.0, 9.0, -7.0, 11.0, 5.0, 7.0, -8.0, 10.0, 5.0, 6.0, -6.0, 9.0, 11.0, 0.0, -5.0, -1.0, 13.0, -3.0, 6.0, -9.0, 9.0, 11.0, 4.0, 6.0, 4.0, -2.0, 7.0, 14.0, 1.0, -11.0, 11.0, 8.0, 8.0, -9.0, 8.0, 6.0, 3.0, 8.0, -2.0, 6.0, 5.0, 7.0, -3.0, 13.0, 6.0, 0.0, -4.0, 3.0, 13.0, 7.0, -8.0, -5.0, 6.0, 4.0, 10.0, 12.0, 12.0, -13.0, 4.0, 11.0, -11.0, 10.0, 5.0, 6.0, 6.0, 11.0, -8.0, 13.0, 4.0, 10.0, -12.0, 6.0, -10.0, 6.0, 13.0, 11.0, -10.0, 3.0, 11.0, 10.0, 3.0, -2.0, 4.0, -7.0, 13.0, 3.0, 6.0, 13.0, 12.0, -14.0, 4.0, -12.0, 13.0, 5.0, 9.0, -1.0, 7.0, 11.0, -2.0, 12.0, -1.0, -9.0, 13.0, 6.0, 7.0, -7.0, 9.0, 12.0, -11.0, 8.0, 6.0, 9.0, 12.0, 8.0, -14.0, 9.0, 3.0, 11.0, -8.0, 7.0, -9.0, 11.0, 6.0, 14.0, -14.0, 4.0, 11.0, 9.0, 9.0, -8.0, 5.0, 8.0, -8.0, 8.0, 7.0, 12.0, 10.0, 6.0, -13.0, 0.0, 11.0, -6.0, 10.0, 8.0, 4.0, 9.0, -6.0, -3.0, -1.0, 6.0, 13.0, 12.0, -10.0, 10.0, 3.0, 13.0, 10.0, -18.0, 10.0, 5.0, 8.0, 6.0, -4.0, -1.0, 1.0, 7.0, 8.0, 11.0, 7.0, 12.0, -15.0, 9.0, -4.0, 4.0, 6.0, 9.0, 8.0, 11.0, -13.0, 10.0, 6.0, -9.0, 8.0, 13.0, 7.0, 11.0, -16.0, 14.0, 3.0, -11.0, 9.0, 5.0, 1.0, 10.0, -1.0, -6.0, 8.0, 10.0, 3.0, 13.0, 11.0, 11.0, -20.0, 8.0, 10.0, -11.0, 8.0, 4.0, 13.0, 1.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416619521660824, "mean_inference_ms": 1.061757484895565, "mean_action_processing_ms": 0.07091958109896777, "mean_env_wait_ms": 0.17441054840294218, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 688500, "agent_timesteps_total": 688500, "timers": {"sample_time_ms": 0.082, "sample_throughput": 67208925.627, "learn_time_ms": 13.938, "learn_throughput": 395192.23, "update_time_ms": 6.155}, "info": {"learner": {"learned": {"policy_loss": 1.142799973487854, "vf_loss": 20.430387496948242, "total_loss": 21.57318687438965, "vf_explained_var": -0.00928950309753418, "model": {}}}, "num_steps_sampled": 688500, "num_agent_steps_sampled": 688500, "num_steps_trained": 688500, "num_agent_steps_trained": 688500}, "done": false, "episodes_total": 13500, "training_iteration": 125, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-14", "timestamp": 1626864494, "time_this_iter_s": 0.3645751476287842, "time_total_s": 45.332231521606445, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182862f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 45.332231521606445, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 83.2, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -6.0, 11.0, 2.0, 2.0, 13.0, 6.0, -6.0, 10.0, 7.0, 6.0, -8.0, 14.0, 11.0, 6.0, -16.0, 3.0, 5.0, -1.0, 8.0, -10.0, 9.0, 7.0, 9.0, 8.0, -12.0, 7.0, 12.0, 11.0, 6.0, -10.0, 8.0, 10.0, 5.0, -7.0, 7.0, 9.0, 7.0, -11.0, 10.0, 10.0, -14.0, 11.0, 8.0, 12.0, 11.0, 12.0, 320.0, -5.0, 5.0, 8.0, 7.0, 4.0, 7.0, 10.0, -6.0, 11.0, 1.0, -7.0, 10.0, 12.0, 7.0, 10.0, -14.0, -10.0, 8.0, 9.0, 8.0, 5.0, 12.0, 10.0, -12.0, 7.0, -9.0, 4.0, 13.0, 14.0, 10.0, 13.0, -22.0, 10.0, -9.0, 7.0, 7.0, -14.0, 12.0, 7.0, 10.0, 10.0, -6.0, 0.0, 11.0, 12.0, -2.0, 11.0, -6.0, -2.0, 7.0, 8.0, 2.0, 7.0, 8.0, 12.0, -12.0, 10.0, -2.0, 0.0, 7.0, 14.0, 10.0, 8.0, -17.0, -13.0, 11.0, 11.0, 6.0, 2.0, 12.0, 9.0, -8.0, -3.0, 1.0, 6.0, 11.0, -1.0, 11.0, 7.0, -2.0, 10.0, -8.0, 6.0, 7.0, 9.0, 3.0, -8.0, 11.0, 13.0, 1.0, -7.0, 8.0, -13.0, 11.0, 13.0, 4.0, -5.0, -2.0, 9.0, 13.0, 6.0, 8.0, 12.0, -11.0, 0.0, 4.0, -2.0, 13.0, 6.0, 11.0, 12.0, -14.0, -6.0, 13.0, 7.0, 1.0, 14.0, 2.0, 4.0, -5.0, 12.0, -6.0, -4.0, 13.0, 13.0, 5.0, 13.0, -16.0, -12.0, 12.0, 7.0, 8.0, 7.0, 6.0, 11.0, -9.0, 11.0, 5.0, 10.0, -11.0, 5.0, -3.0, 13.0, 0.0, 5.0, 12.0, -3.0, 1.0, 3.0, 13.0, 10.0, -11.0, 9.0, 4.0, -7.0, 9.0, 11.0, -3.0, 11.0, -4.0, 12.0, -21.0, 12.0, 12.0, -10.0, 8.0, 10.0, 7.0, -2.0, 7.0, 12.0, -2.0, 10.0, 6.0, 12.0, -13.0, 4.0, 14.0, -4.0, 1.0, 4.0, 12.0, -9.0, 8.0, 13.0, -9.0, 5.0, 6.0, -7.0, 5.0, 10.0, 7.0, -4.0, 12.0, 12.0, -5.0, 2.0, 12.0, 11.0, -10.0, 12.0, 6.0, 5.0, -8.0, 12.0, -7.0, 9.0, 1.0, 11.0, 4.0, -7.0, 7.0, -3.0, 12.0, -6.0, 12.0, -2.0, 11.0, -2.0, 8.0, -4.0, 7.0, 4.0, 8.0, -11.0, 10.0, 7.0, 9.0, 4.0, 13.0, 5.0, -7.0, 7.0, -5.0, 8.0, 5.0, 6.0, -3.0, 8.0, 4.0, 6.0, 11.0, -4.0, 2.0, 6.0, 13.0, 7.0, -11.0, 14.0, 9.0, -5.0, -3.0, 6.0, 10.0, 13.0, -14.0, -8.0, 9.0, 7.0, 7.0, 9.0, 5.0, 12.0, -11.0, 10.0, 2.0, -8.0, 11.0, 14.0, -10.0, 4.0, 7.0, -4.0, 12.0, 6.0, 1.0, 7.0, 7.0, 7.0, -6.0, 10.0, 0.0, -4.0, 9.0, -4.0, 12.0, 11.0, -4.0, -11.0, 12.0, 8.0, 6.0, 10.0, 5.0, 13.0, -13.0, 12.0, -8.0, 6.0, 5.0, 12.0, -2.0, 13.0, -8.0, 7.0, -1.0, 7.0, 2.0, 9.0, 8.0, 11.0, -13.0, 8.0, 5.0, 8.0, -6.0, 2.0, 10.0, 13.0, -10.0, 8.0, 11.0, -7.0, 3.0, 6.0, 2.0, -5.0, 12.0, 12.0, 7.0, 8.0, -12.0, 4.0, 10.0, 13.0, -12.0, 8.0, -4.0, -1.0, 12.0, 7.0, 6.0, 13.0, -11.0, 10.0, -3.0, -4.0, 12.0, -3.0, 12.0, 13.0, -7.0, 9.0, 0.0, 9.0, -3.0, 4.0, 6.0, 13.0, -8.0, 9.0, -13.0, 6.0, 13.0, 11.0, 3.0, 13.0, -12.0, -2.0, 6.0, 11.0, 0.0, 3.0, 8.0, 11.0, -7.0, 10.0, -10.0, 7.0, 8.0, 13.0, 6.0, 12.0, -16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418261533312297, "mean_inference_ms": 1.0618946886131668, "mean_action_processing_ms": 0.07092920247954707, "mean_env_wait_ms": 0.17442739111111258, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 694008, "agent_timesteps_total": 694008, "timers": {"sample_time_ms": 0.086, "sample_throughput": 63903100.865, "learn_time_ms": 14.18, "learn_throughput": 388437.881, "update_time_ms": 6.842}, "info": {"learner": {"learned": {"policy_loss": 119828545536.0, "vf_loss": 134.61428833007812, "total_loss": 119828545536.0, "vf_explained_var": -0.0008274316787719727, "model": {}}}, "num_steps_sampled": 694008, "num_agent_steps_sampled": 694008, "num_steps_trained": 694008, "num_agent_steps_trained": 694008}, "done": false, "episodes_total": 13608, "training_iteration": 126, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-14", "timestamp": 1626864494, "time_this_iter_s": 0.37534523010253906, "time_total_s": 45.707576751708984, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829a378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 45.707576751708984, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.425925925925927, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 6.106481481481482}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -11.0, 3.0, 13.0, 3.0, 2.0, 13.0, -3.0, 4.0, -4.0, 3.0, 12.0, 2.0, 9.0, 11.0, -7.0, 6.0, -10.0, 7.0, 12.0, 12.0, 13.0, 315.0, 13.0, -10.0, 9.0, 7.0, 9.0, 14.0, 0.0, -10.0, 11.0, 6.0, -12.0, 8.0, 13.0, 7.0, 12.0, -14.0, 10.0, 2.0, -10.0, 10.0, 13.0, 2.0, 13.0, 6.0, -6.0, 1.0, -3.0, 5.0, 12.0, -10.0, 8.0, 9.0, 8.0, 5.0, 8.0, 9.0, -7.0, -6.0, 12.0, 5.0, 4.0, 5.0, -9.0, 7.0, 12.0, 3.0, -3.0, 6.0, 9.0, -13.0, 8.0, 12.0, 8.0, 5.0, 7.0, -8.0, 11.0, 6.0, -11.0, 7.0, 13.0, 12.0, -4.0, -2.0, 9.0, -11.0, 2.0, 12.0, 12.0, 10.0, 1.0, 12.0, -8.0, -13.0, 8.0, 8.0, 12.0, 6.0, 13.0, 11.0, -15.0, 321.0, 10.0, 12.0, 12.0, -4.0, 12.0, 5.0, 2.0, 2.0, -5.0, 5.0, 13.0, 12.0, 13.0, -5.0, -5.0, 4.0, -5.0, 3.0, 13.0, -8.0, 10.0, 2.0, 11.0, 3.0, 9.0, 13.0, -10.0, 12.0, 12.0, -20.0, 11.0, 2.0, 9.0, 6.0, -2.0, 10.0, 13.0, -13.0, 5.0, 5.0, 10.0, 8.0, -8.0, 11.0, 13.0, -4.0, -5.0, -16.0, 10.0, 8.0, 13.0, -5.0, -1.0, 12.0, 9.0, -10.0, 11.0, 2.0, 12.0, 9.0, -1.0, 3.0, 4.0, -6.0, 9.0, 0.0, 12.0, 13.0, 8.0, -13.0, 7.0, 4.0, 9.0, 4.0, -2.0, 10.0, -2.0, 11.0, -4.0, -9.0, 9.0, 3.0, 12.0, 14.0, -1.0, -9.0, 11.0, 2.0, 11.0, 7.0, -5.0, -9.0, 2.0, 12.0, 10.0, -14.0, 10.0, 12.0, 7.0, 11.0, 1.0, -4.0, 7.0, -2.0, -4.0, 9.0, 12.0, 14.0, -2.0, 7.0, -4.0, 12.0, -5.0, -4.0, 12.0, 13.0, 8.0, -10.0, 4.0, 4.0, -7.0, 5.0, 13.0, 14.0, 11.0, 9.0, -19.0, -9.0, 9.0, 9.0, 6.0, 0.0, 12.0, -3.0, 6.0, 6.0, -1.0, 11.0, -1.0, 9.0, 13.0, 11.0, -18.0, 6.0, -7.0, 3.0, 13.0, 13.0, 13.0, 0.0, -11.0, 10.0, -8.0, 8.0, 5.0, 10.0, 13.0, -6.0, -2.0, 5.0, 6.0, 10.0, -6.0, 14.0, 6.0, 7.0, -12.0, 5.0, 3.0, 8.0, -1.0, -2.0, 12.0, 1.0, 4.0, 1.0, 7.0, -4.0, 11.0, 9.0, 7.0, -10.0, 9.0, -2.0, -3.0, 8.0, 12.0, 11.0, 10.0, 12.0, -18.0, 3.0, -4.0, 9.0, 7.0, 14.0, 8.0, 3.0, -10.0, 1.0, 11.0, -2.0, 5.0, -5.0, 9.0, 2.0, 9.0, 12.0, 9.0, 2.0, -8.0, 5.0, 8.0, -2.0, 4.0, 2.0, -3.0, 7.0, 9.0, 8.0, 3.0, -6.0, 10.0, -7.0, 6.0, 4.0, 12.0, 4.0, 10.0, 2.0, -1.0, 5.0, -3.0, 7.0, 6.0, 6.0, 8.0, -6.0, 7.0, -2.0, -3.0, 12.0, 8.0, 14.0, 1.0, 11.0, -11.0, 4.0, 9.0, 4.0, -2.0, -1.0, 8.0, 11.0, -3.0, 14.0, 9.0, 319.0, 13.0, 8.0, 7.0, -7.0, 7.0, 4.0, -11.0, 13.0, 9.0, -8.0, 10.0, 3.0, 10.0, -10.0, 9.0, 5.0, 11.0, 0.0, -2.0, 6.0, 11.0, 4.0, -8.0, 11.0, 8.0, 5.0, 8.0, 11.0, -9.0, 9.0, -11.0, 9.0, 8.0, 13.0, 13.0, -9.0, -2.0, 6.0, 7.0, 8.0, -6.0, 6.0, -6.0, 8.0, 7.0, 2.0, 5.0, 9.0, -1.0, 5.0, 8.0, -7.0, 9.0, -4.0, 0.0, 6.0, 13.0, 12.0, -2.0, -1.0, 6.0, -13.0, 10.0, 5.0, 13.0, 14.0, 6.0, -11.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418397844998488, "mean_inference_ms": 1.0618865520207532, "mean_action_processing_ms": 0.07093163713187912, "mean_env_wait_ms": 0.1744218237795138, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 699516, "agent_timesteps_total": 699516, "timers": {"sample_time_ms": 0.089, "sample_throughput": 61736974.357, "learn_time_ms": 14.391, "learn_throughput": 382736.859, "update_time_ms": 7.051}, "info": {"learner": {"learned": {"policy_loss": 514463858688.0, "vf_loss": 668.1572875976562, "total_loss": 514463858688.0, "vf_explained_var": -2.205371856689453e-05, "model": {}}}, "num_steps_sampled": 699516, "num_agent_steps_sampled": 699516, "num_steps_trained": 699516, "num_agent_steps_trained": 699516}, "done": false, "episodes_total": 13716, "training_iteration": 127, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-15", "timestamp": 1626864495, "time_this_iter_s": 0.3625221252441406, "time_total_s": 46.070098876953125, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829a510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 46.070098876953125, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 69.8, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -11.0, 6.0, 13.0, 12.0, 12.0, -19.0, 10.0, 14.0, 7.0, 6.0, -12.0, 7.0, 10.0, 8.0, -10.0, 14.0, 4.0, 1.0, -4.0, 13.0, 6.0, -16.0, 12.0, 9.0, -5.0, -1.0, 12.0, 11.0, 7.0, -1.0, -2.0, 9.0, -14.0, 10.0, 10.0, 9.0, -2.0, -4.0, 12.0, 13.0, -3.0, 4.0, 1.0, 12.0, 5.0, 1.0, -3.0, 10.0, 1.0, 7.0, -3.0, 13.0, -11.0, 2.0, 11.0, 12.0, -9.0, 13.0, -1.0, 11.0, -8.0, 1.0, 11.0, 13.0, 6.0, 11.0, -15.0, 12.0, -14.0, 6.0, 11.0, 11.0, -5.0, 7.0, 2.0, 8.0, 8.0, -12.0, 11.0, 8.0, 4.0, 13.0, -10.0, 6.0, -6.0, 2.0, 13.0, 12.0, -9.0, 13.0, -1.0, 10.0, -2.0, 1.0, 6.0, 8.0, 3.0, 11.0, -7.0, 13.0, -10.0, 1.0, 11.0, 13.0, 9.0, -7.0, 0.0, 6.0, 12.0, -13.0, 10.0, 13.0, -6.0, 6.0, 2.0, 12.0, 6.0, -9.0, 6.0, 5.0, -6.0, 12.0, 4.0, 7.0, -3.0, 0.0, 11.0, 9.0, 8.0, -8.0, 6.0, 12.0, 11.0, 9.0, -17.0, 14.0, -8.0, 12.0, -3.0, 3.0, 11.0, 9.0, -8.0, 14.0, 5.0, 12.0, -16.0, 12.0, 3.0, -12.0, 12.0, 10.0, -2.0, -3.0, 10.0, 7.0, -6.0, 3.0, 11.0, 5.0, -6.0, 12.0, 4.0, 8.0, 11.0, -16.0, 12.0, 6.0, -3.0, 4.0, 8.0, 4.0, 9.0, -10.0, 12.0, 9.0, -4.0, 3.0, 7.0, 13.0, 11.0, -20.0, 11.0, 7.0, -9.0, 9.0, 8.0, 5.0, 10.0, 1.0, -1.0, 8.0, -1.0, 12.0, -4.0, 10.0, 0.0, -7.0, 12.0, 12.0, -8.0, -2.0, 13.0, -1.0, 7.0, 12.0, -3.0, 2.0, 5.0, 11.0, -3.0, 14.0, 6.0, -17.0, 12.0, 11.0, -2.0, -4.0, 10.0, 12.0, 10.0, -5.0, -2.0, 7.0, -9.0, 6.0, 11.0, 13.0, 10.0, -19.0, 11.0, 13.0, 12.0, -7.0, -3.0, -1.0, -3.0, 13.0, 6.0, 3.0, -4.0, 13.0, 3.0, 10.0, 4.0, -12.0, 13.0, 11.0, -7.0, -1.0, 12.0, 12.0, 12.0, -10.0, 1.0, 6.0, -8.0, 8.0, 9.0, 13.0, 4.0, -14.0, 12.0, 7.0, -2.0, 3.0, 7.0, 8.0, -8.0, 10.0, 5.0, 5.0, -7.0, 8.0, 9.0, 10.0, 8.0, -15.0, 12.0, 7.0, -2.0, 11.0, -1.0, 7.0, 6.0, -4.0, 6.0, 8.0, -13.0, 9.0, 11.0, 9.0, 8.0, -13.0, 11.0, 8.0, -2.0, 7.0, 2.0, 6.0, -4.0, 8.0, 5.0, 8.0, -10.0, 10.0, 7.0, 13.0, 12.0, 318.0, 12.0, 5.0, 12.0, -14.0, 12.0, 8.0, -7.0, 4.0, 10.0, 14.0, -9.0, 6.0, 4.0, 13.0, 12.0, 318.0, 12.0, 11.0, -3.0, 12.0, -5.0, 10.0, -7.0, 3.0, 9.0, 10.0, -10.0, 9.0, 6.0, 9.0, -2.0, -4.0, 12.0, 3.0, -7.0, 7.0, 12.0, 10.0, 10.0, -4.0, -1.0, -7.0, 6.0, 10.0, 6.0, 13.0, 10.0, -13.0, 5.0, 9.0, -8.0, 2.0, 12.0, 12.0, 10.0, -14.0, 7.0, -8.0, 5.0, 13.0, 5.0, 11.0, 11.0, -19.0, 12.0, 8.0, -4.0, 5.0, 6.0, 12.0, -8.0, 4.0, 7.0, 14.0, -11.0, 10.0, 2.0, 13.0, 12.0, -21.0, 11.0, 9.0, -2.0, 2.0, 6.0, 3.0, -8.0, 9.0, 11.0, 10.0, 5.0, 7.0, -7.0, 13.0, -16.0, 6.0, 12.0, 12.0, -5.0, 7.0, 1.0, 8.0, -5.0, 7.0, 5.0, 1.0, 5.0, 13.0, -4.0, 12.0, -7.0, -3.0, 13.0, 13.0, -7.0, 5.0, 4.0, 7.0, 12.0, 11.0, -15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418460405048856, "mean_inference_ms": 1.06193038115227, "mean_action_processing_ms": 0.07093478682191139, "mean_env_wait_ms": 0.1744236797701973, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 705024, "agent_timesteps_total": 705024, "timers": {"sample_time_ms": 0.089, "sample_throughput": 61848793.703, "learn_time_ms": 14.441, "learn_throughput": 381409.269, "update_time_ms": 7.345}, "info": {"learner": {"learned": {"policy_loss": 92149088256.0, "vf_loss": 128.15113830566406, "total_loss": 92149088256.0, "vf_explained_var": -0.0007685422897338867, "model": {}}}, "num_steps_sampled": 705024, "num_agent_steps_sampled": 705024, "num_steps_trained": 705024, "num_agent_steps_trained": 705024}, "done": false, "episodes_total": 13824, "training_iteration": 128, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-15", "timestamp": 1626864495, "time_this_iter_s": 0.36041998863220215, "time_total_s": 46.43051886558533, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a8310aea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 46.43051886558533, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 28.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.37962962962963, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.8449074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 28.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -5.0, -1.0, 12.0, 10.0, 8.0, 8.0, -11.0, 13.0, 9.0, 13.0, -20.0, 10.0, 7.0, -9.0, 7.0, 13.0, 5.0, -16.0, 13.0, 6.0, 2.0, 11.0, -4.0, 12.0, -6.0, 11.0, -2.0, 7.0, 8.0, -7.0, 7.0, 12.0, 1.0, -11.0, 13.0, 7.0, 3.0, 11.0, -6.0, 11.0, 10.0, -18.0, 12.0, 6.0, 9.0, -12.0, 12.0, 13.0, -14.0, 13.0, 3.0, 5.0, -5.0, 7.0, 8.0, 11.0, 12.0, -1.0, -7.0, 9.0, -1.0, 5.0, 2.0, 9.0, 10.0, 13.0, -17.0, -1.0, 8.0, 12.0, -4.0, 12.0, -3.0, 12.0, -6.0, 5.0, 10.0, -10.0, 10.0, 0.0, 0.0, 13.0, 2.0, 1.0, 12.0, 7.0, -5.0, 11.0, 13.0, -2.0, -7.0, 2.0, 14.0, 10.0, -11.0, 14.0, 0.0, -11.0, 12.0, 8.0, 13.0, -10.0, 4.0, 6.0, 14.0, -1.0, -4.0, 8.0, 9.0, -14.0, 12.0, 14.0, 1.0, -11.0, 11.0, -1.0, 0.0, 6.0, 10.0, 11.0, -6.0, -1.0, 11.0, -2.0, 5.0, 9.0, 3.0, 14.0, 9.0, -21.0, 13.0, 7.0, -1.0, 1.0, 8.0, 12.0, -1.0, 12.0, -8.0, -8.0, 9.0, 6.0, 8.0, 1.0, 13.0, -12.0, 13.0, 8.0, 7.0, 6.0, -6.0, 8.0, -6.0, 12.0, 1.0, 8.0, 14.0, -19.0, 12.0, 13.0, -9.0, 0.0, 11.0, 8.0, 8.0, 6.0, -7.0, 7.0, -9.0, 5.0, 12.0, 6.0, 13.0, 5.0, -9.0, 12.0, 7.0, -16.0, 12.0, 11.0, -1.0, 9.0, -4.0, 13.0, 6.0, -2.0, -2.0, 8.0, 14.0, -10.0, 3.0, 14.0, -11.0, 0.0, 12.0, 8.0, 12.0, 1.0, -6.0, 11.0, -8.0, 5.0, 7.0, 12.0, 10.0, -11.0, 4.0, -1.0, 2.0, 2.0, 13.0, 7.0, -1.0, 5.0, 4.0, 6.0, 10.0, 7.0, -8.0, -18.0, 12.0, 11.0, 10.0, 14.0, 3.0, -14.0, 12.0, -5.0, 1.0, 8.0, 11.0, 11.0, 6.0, -14.0, 12.0, 13.0, 3.0, -10.0, 9.0, 3.0, 4.0, 8.0, 13.0, 0.0, -3.0, 10.0, 8.0, 11.0, 10.0, 6.0, -12.0, 12.0, 11.0, -20.0, 12.0, 13.0, 8.0, -18.0, 12.0, 2.0, 0.0, 4.0, 9.0, 7.0, 7.0, 3.0, -2.0, 11.0, 10.0, -6.0, 0.0, 9.0, 13.0, -19.0, 12.0, 6.0, 8.0, -5.0, 6.0, 10.0, -13.0, 6.0, 12.0, 3.0, 10.0, 5.0, -3.0, 4.0, 6.0, 5.0, 13.0, 12.0, 7.0, 6.0, -10.0, 12.0, 5.0, -2.0, 0.0, 3.0, 8.0, -8.0, 12.0, 13.0, -12.0, 1.0, 13.0, 3.0, 6.0, 11.0, -5.0, 12.0, 1.0, 3.0, -1.0, 2.0, 12.0, -2.0, 3.0, 8.0, 1.0, -7.0, 13.0, -11.0, 12.0, 8.0, 6.0, 7.0, -8.0, 11.0, 5.0, 2.0, 13.0, -10.0, 10.0, -4.0, -2.0, 10.0, 12.0, 4.0, 12.0, 11.0, -12.0, 11.0, 10.0, 13.0, -19.0, 6.0, 8.0, -6.0, 7.0, 9.0, 4.0, -11.0, 13.0, 3.0, 7.0, -6.0, 11.0, 12.0, -10.0, 1.0, 12.0, 13.0, 14.0, -20.0, 8.0, 9.0, 3.0, -10.0, 13.0, 4.0, -1.0, 6.0, 6.0, 11.0, -5.0, 8.0, 1.0, 10.0, 12.0, -12.0, 5.0, 9.0, 2.0, 4.0, 13.0, 8.0, 7.0, 12.0, -12.0, 10.0, -4.0, 7.0, 2.0, -6.0, 13.0, 10.0, -2.0, 9.0, 11.0, 5.0, -10.0, 3.0, 6.0, 12.0, -6.0, 8.0, -6.0, 12.0, 1.0, -19.0, 14.0, 7.0, 13.0, 13.0, 0.0, -10.0, 12.0, 11.0, 6.0, 4.0, -6.0, 12.0, 1.0, -1.0, 3.0, 11.0, 14.0, -7.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18417879006350335, "mean_inference_ms": 1.0618735086580682, "mean_action_processing_ms": 0.07093598250435591, "mean_env_wait_ms": 0.17441841240021697, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 710532, "agent_timesteps_total": 710532, "timers": {"sample_time_ms": 0.088, "sample_throughput": 62770947.523, "learn_time_ms": 14.513, "learn_throughput": 379509.551, "update_time_ms": 7.493}, "info": {"learner": {"learned": {"policy_loss": 92608028672.0, "vf_loss": 117.69361877441406, "total_loss": 92608028672.0, "vf_explained_var": -0.0009096860885620117, "model": {}}}, "num_steps_sampled": 710532, "num_agent_steps_sampled": 710532, "num_steps_trained": 710532, "num_agent_steps_trained": 710532}, "done": false, "episodes_total": 13932, "training_iteration": 129, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-16", "timestamp": 1626864496, "time_this_iter_s": 0.35693359375, "time_total_s": 46.78745245933533, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 46.78745245933533, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 71.9, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 11.0, -13.0, 8.0, 5.0, 3.0, 8.0, -1.0, 5.0, 12.0, -13.0, 11.0, 4.0, 12.0, 3.0, -4.0, -1.0, 9.0, 6.0, 1.0, 11.0, 7.0, -15.0, 12.0, 6.0, 10.0, -9.0, 8.0, 1.0, 13.0, 12.0, -11.0, 13.0, 7.0, 1.0, -6.0, 12.0, 10.0, -20.0, 13.0, 13.0, 11.0, -13.0, 4.0, 2.0, 12.0, 5.0, -4.0, 9.0, 11.0, 6.0, -11.0, 11.0, 1.0, -8.0, 11.0, 8.0, -7.0, 6.0, 8.0, 13.0, 12.0, -6.0, -4.0, -8.0, 13.0, 4.0, 6.0, 7.0, 5.0, 4.0, -1.0, 8.0, -6.0, 9.0, 4.0, 11.0, 14.0, 8.0, -18.0, 13.0, 5.0, 3.0, -6.0, 9.0, 9.0, -11.0, 8.0, 9.0, -7.0, 8.0, 5.0, 0.0, 12.0, 10.0, -7.0, 0.0, 8.0, 6.0, 1.0, 8.0, 1.0, -7.0, 13.0, 11.0, -5.0, 0.0, 9.0, 12.0, 10.0, -4.0, -3.0, 13.0, 7.0, 2.0, -7.0, 13.0, 11.0, -18.0, 9.0, 2.0, 11.0, 3.0, -1.0, -15.0, 12.0, 9.0, 9.0, 13.0, 6.0, 2.0, -6.0, 8.0, 11.0, -2.0, -2.0, 9.0, -5.0, 1.0, 10.0, 1.0, 14.0, -9.0, 9.0, 12.0, 8.0, -12.0, 7.0, 13.0, 6.0, 0.0, -4.0, 11.0, 8.0, 8.0, -12.0, 5.0, 13.0, 1.0, -4.0, 13.0, 7.0, 3.0, -8.0, 11.0, 3.0, -2.0, 3.0, -9.0, 8.0, 8.0, 8.0, -2.0, 12.0, -6.0, 11.0, 13.0, 4.0, 5.0, -7.0, 12.0, -6.0, -2.0, 11.0, 0.0, 12.0, 4.0, -1.0, -12.0, 13.0, 2.0, 12.0, 12.0, 7.0, 3.0, -7.0, 9.0, 3.0, 7.0, -4.0, 10.0, 2.0, 13.0, -10.0, 1.0, 13.0, 6.0, -5.0, 9.0, 11.0, -3.0, -2.0, 13.0, -6.0, -4.0, 12.0, 12.0, 8.0, -5.0, 0.0, 5.0, 13.0, 1.0, -4.0, 13.0, 13.0, -17.0, 6.0, 11.0, 0.0, 11.0, -7.0, 6.0, -2.0, 6.0, 5.0, 12.0, 11.0, -6.0, -2.0, 13.0, 5.0, 11.0, -14.0, 9.0, 9.0, -15.0, 12.0, 6.0, -5.0, 9.0, 5.0, -1.0, -2.0, 8.0, 10.0, 13.0, 10.0, -15.0, 7.0, 9.0, 4.0, -5.0, 7.0, 2.0, -4.0, 9.0, 8.0, -6.0, 10.0, 9.0, 2.0, -1.0, 11.0, -3.0, 8.0, 10.0, 4.0, -12.0, 13.0, 12.0, -15.0, 8.0, 10.0, 3.0, 9.0, -5.0, 8.0, 14.0, 5.0, -10.0, 6.0, 12.0, 5.0, -12.0, 10.0, 11.0, 10.0, 8.0, -14.0, 7.0, 12.0, -15.0, 11.0, 14.0, 6.0, -3.0, -2.0, 7.0, 8.0, -2.0, 2.0, 6.0, 11.0, 1.0, -3.0, -11.0, 13.0, 4.0, 9.0, -8.0, 5.0, 11.0, 7.0, 6.0, 2.0, 9.0, -2.0, 8.0, 9.0, -13.0, 11.0, 0.0, 13.0, 6.0, -4.0, 13.0, 11.0, -16.0, 7.0, 11.0, 8.0, -17.0, 13.0, 13.0, 2.0, -4.0, 4.0, 0.0, 10.0, 8.0, -3.0, -1.0, 9.0, 5.0, 2.0, 10.0, 11.0, -16.0, 10.0, 13.0, -1.0, -5.0, 8.0, 1.0, 11.0, 9.0, -6.0, 5.0, 6.0, 10.0, -6.0, 7.0, 11.0, -2.0, -1.0, 9.0, 12.0, -18.0, 12.0, 12.0, 12.0, 317.0, 13.0, 12.0, -9.0, 6.0, 6.0, 12.0, -1.0, 12.0, -8.0, -5.0, 11.0, 11.0, -2.0, -9.0, 14.0, -1.0, 11.0, 14.0, 8.0, -6.0, -1.0, 5.0, 9.0, -11.0, 12.0, 10.0, 5.0, -7.0, 7.0, -2.0, 8.0, 13.0, -4.0, 13.0, 12.0, 1.0, -11.0, 7.0, 0.0, -3.0, 11.0, 3.0, 11.0, -11.0, 12.0, 0.0, 13.0, 6.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418609673873215, "mean_inference_ms": 1.061971712859113, "mean_action_processing_ms": 0.07093646524681879, "mean_env_wait_ms": 0.17440354704185465, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 716040, "agent_timesteps_total": 716040, "timers": {"sample_time_ms": 0.09, "sample_throughput": 61046501.951, "learn_time_ms": 14.764, "learn_throughput": 373075.077, "update_time_ms": 7.322}, "info": {"learner": {"learned": {"policy_loss": 1.2456783056259155, "vf_loss": 21.851625442504883, "total_loss": 23.09730339050293, "vf_explained_var": -0.0056029558181762695, "model": {}}}, "num_steps_sampled": 716040, "num_agent_steps_sampled": 716040, "num_steps_trained": 716040, "num_agent_steps_trained": 716040}, "done": false, "episodes_total": 14040, "training_iteration": 130, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-16", "timestamp": 1626864496, "time_this_iter_s": 0.36779332160949707, "time_total_s": 47.155245780944824, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 47.155245780944824, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 82.4, "ram_util_percent": 14.1}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -3.0, 8.0, -1.0, 7.0, -13.0, 9.0, 12.0, -10.0, 8.0, 5.0, 12.0, -12.0, 9.0, 11.0, 7.0, 6.0, 10.0, 7.0, -8.0, 4.0, -8.0, 13.0, 6.0, -5.0, -2.0, 10.0, 12.0, 6.0, 5.0, 9.0, -5.0, 6.0, 13.0, -7.0, 3.0, 3.0, -8.0, 13.0, 7.0, 1.0, 0.0, 10.0, 4.0, 6.0, 5.0, 9.0, -5.0, 9.0, 11.0, -8.0, 3.0, -1.0, -4.0, 13.0, 7.0, -7.0, 9.0, 1.0, 12.0, -12.0, 13.0, 2.0, 12.0, 10.0, 10.0, -11.0, 6.0, -1.0, -7.0, 12.0, 11.0, -12.0, 8.0, 13.0, 6.0, -17.0, 14.0, 6.0, 12.0, 6.0, 12.0, -9.0, 6.0, 4.0, 12.0, 13.0, -14.0, -10.0, 8.0, 9.0, 8.0, 6.0, -7.0, 8.0, 8.0, 4.0, 12.0, 4.0, -5.0, -19.0, 14.0, 8.0, 12.0, 11.0, -15.0, 13.0, 6.0, 12.0, 7.0, -11.0, 7.0, 7.0, 11.0, -10.0, 7.0, 4.0, -8.0, 6.0, 13.0, -6.0, 4.0, 10.0, 7.0, 2.0, 10.0, -4.0, 7.0, 8.0, 7.0, -9.0, 9.0, -10.0, 2.0, 13.0, 10.0, -7.0, 8.0, 4.0, 10.0, 3.0, 8.0, -8.0, 12.0, 8.0, 12.0, 5.0, -10.0, 9.0, -13.0, 13.0, 6.0, -6.0, 3.0, 12.0, 6.0, -7.0, 6.0, 8.0, 8.0, 7.0, 13.0, 5.0, -10.0, 3.0, -3.0, 13.0, 2.0, -11.0, 8.0, 12.0, 6.0, 2.0, 13.0, 8.0, -8.0, 9.0, 11.0, 1.0, -6.0, 1.0, -5.0, 12.0, 7.0, -9.0, 9.0, 3.0, 12.0, 3.0, 10.0, -5.0, 7.0, 9.0, 12.0, -13.0, 7.0, 9.0, -8.0, 12.0, 2.0, -8.0, 8.0, 9.0, 6.0, -14.0, 10.0, 12.0, 7.0, 8.0, 12.0, 2.0, -7.0, 1.0, -3.0, 4.0, 13.0, -4.0, -1.0, 11.0, 9.0, 4.0, 10.0, -7.0, 8.0, 6.0, 8.0, -6.0, 7.0, 1.0, 10.0, 12.0, -8.0, 13.0, 1.0, -6.0, 7.0, -6.0, 5.0, 7.0, 9.0, 7.0, 12.0, -13.0, 9.0, 2.0, 6.0, 13.0, -6.0, -12.0, 13.0, 11.0, 3.0, -14.0, 13.0, 7.0, 9.0, 10.0, 12.0, -13.0, 6.0, -1.0, 6.0, 12.0, -2.0, -16.0, 8.0, 10.0, 13.0, 8.0, 5.0, -10.0, 12.0, 9.0, -14.0, 13.0, 7.0, 2.0, -4.0, 13.0, 4.0, -2.0, 7.0, 5.0, 5.0, -1.0, 4.0, 7.0, 5.0, 6.0, -8.0, 8.0, 9.0, 3.0, -4.0, 13.0, 3.0, -13.0, 9.0, 13.0, 6.0, 12.0, 5.0, -14.0, 12.0, 4.0, 11.0, -6.0, 6.0, -4.0, -2.0, 8.0, 13.0, -6.0, 9.0, 6.0, 6.0, 8.0, 11.0, 6.0, -10.0, 8.0, 8.0, 3.0, -4.0, 6.0, -9.0, 12.0, 6.0, 9.0, -5.0, 4.0, 7.0, 2.0, -8.0, 9.0, 12.0, 9.0, 0.0, -6.0, 12.0, 2.0, 5.0, 12.0, -4.0, -16.0, 14.0, 4.0, 13.0, -7.0, 10.0, 8.0, 4.0, 8.0, 13.0, 4.0, -10.0, 5.0, 0.0, -3.0, 13.0, -6.0, 8.0, 2.0, 11.0, 1.0, 11.0, 8.0, -5.0, 5.0, 10.0, -11.0, 11.0, -12.0, 10.0, 12.0, 5.0, -13.0, 13.0, 9.0, 6.0, 2.0, 13.0, -7.0, 7.0, -2.0, 13.0, 1.0, 3.0, 1.0, 6.0, -1.0, 9.0, -4.0, 1.0, 8.0, 10.0, -11.0, 10.0, 8.0, 8.0, 9.0, 11.0, -15.0, 10.0, -12.0, 12.0, 13.0, 2.0, -5.0, 14.0, 1.0, 5.0, -2.0, 1.0, 8.0, 8.0, 6.0, 2.0, 8.0, -1.0, -19.0, 10.0, 13.0, 11.0, 10.0, -18.0, 11.0, 12.0, -13.0, 14.0, 8.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18421127432469733, "mean_inference_ms": 1.0621587031473179, "mean_action_processing_ms": 0.07094133479701824, "mean_env_wait_ms": 0.1744178823120764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 721548, "agent_timesteps_total": 721548, "timers": {"sample_time_ms": 0.093, "sample_throughput": 59187112.018, "learn_time_ms": 14.971, "learn_throughput": 367920.818, "update_time_ms": 6.895}, "info": {"learner": {"learned": {"policy_loss": 96116105216.0, "vf_loss": 130.79623413085938, "total_loss": 96116105216.0, "vf_explained_var": -0.0011181831359863281, "model": {}}}, "num_steps_sampled": 721548, "num_agent_steps_sampled": 721548, "num_steps_trained": 721548, "num_agent_steps_trained": 721548}, "done": false, "episodes_total": 14148, "training_iteration": 131, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-16", "timestamp": 1626864496, "time_this_iter_s": 0.378131628036499, "time_total_s": 47.53337740898132, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1828a400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 47.53337740898132, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 3.0, 9.0, -3.0, 6.0, 5.0, 6.0, -2.0, 12.0, -6.0, 1.0, 8.0, -2.0, 12.0, -3.0, 8.0, 2.0, -8.0, 12.0, 9.0, 4.0, 9.0, -11.0, 13.0, -1.0, 9.0, 2.0, 5.0, -1.0, 7.0, -1.0, 10.0, 9.0, -3.0, 12.0, -3.0, 10.0, 2.0, 5.0, -2.0, -5.0, 11.0, 2.0, 7.0, 6.0, 4.0, -7.0, 12.0, 7.0, 3.0, -3.0, 8.0, 13.0, -4.0, 6.0, 0.0, -3.0, 14.0, 1.0, 3.0, 2.0, 3.0, 13.0, -3.0, 5.0, -11.0, 10.0, 11.0, 2.0, 10.0, 7.0, -4.0, 11.0, 14.0, 11.0, -21.0, 9.0, -14.0, 8.0, 12.0, 7.0, 1.0, 11.0, -4.0, 13.0, -10.0, 1.0, 11.0, 11.0, -10.0, 6.0, 8.0, 11.0, -10.0, 9.0, 5.0, 14.0, -15.0, 9.0, 7.0, 4.0, 6.0, 8.0, -3.0, 0.0, 14.0, -8.0, 9.0, 9.0, 9.0, 7.0, -10.0, 10.0, -1.0, 7.0, -1.0, 4.0, 7.0, -5.0, 9.0, 12.0, 9.0, -15.0, 9.0, 9.0, 5.0, 9.0, -8.0, 14.0, -6.0, 8.0, -1.0, 3.0, 12.0, 12.0, -12.0, 13.0, -13.0, 3.0, 12.0, 7.0, 2.0, -5.0, 11.0, 14.0, -10.0, 8.0, 3.0, 5.0, 6.0, -5.0, 9.0, 13.0, -1.0, 0.0, 3.0, 12.0, 4.0, 8.0, -9.0, 3.0, -11.0, 12.0, 11.0, 9.0, 5.0, -10.0, 11.0, 9.0, 10.0, 5.0, -9.0, -7.0, 12.0, -1.0, 11.0, 11.0, 0.0, -3.0, 7.0, 4.0, -6.0, 10.0, 7.0, -2.0, 2.0, 4.0, 11.0, 5.0, 8.0, 7.0, -5.0, 3.0, 6.0, 12.0, -6.0, 14.0, 318.0, 11.0, 12.0, 11.0, 12.0, -16.0, 8.0, 3.0, 8.0, 7.0, -3.0, 9.0, -16.0, 12.0, 10.0, 14.0, -3.0, 8.0, -4.0, -2.0, 1.0, 4.0, 12.0, 9.0, -4.0, 2.0, 8.0, 6.0, -13.0, 10.0, 12.0, 6.0, 9.0, 10.0, -10.0, 13.0, -6.0, -2.0, 10.0, 10.0, -13.0, 7.0, 11.0, 14.0, -8.0, 8.0, 1.0, 6.0, -3.0, 13.0, -1.0, -5.0, 10.0, 3.0, 7.0, 6.0, 0.0, -4.0, 13.0, 9.0, -2.0, 12.0, -4.0, 8.0, 12.0, -16.0, 11.0, 4.0, 3.0, -4.0, 12.0, 10.0, 7.0, 6.0, -8.0, 14.0, -12.0, 12.0, 1.0, -19.0, 14.0, 12.0, 8.0, 13.0, -10.0, 5.0, 7.0, 4.0, -9.0, 12.0, 8.0, 14.0, 4.0, 3.0, -6.0, 5.0, -2.0, 2.0, 10.0, 12.0, 3.0, -12.0, 12.0, 10.0, 4.0, -7.0, 8.0, 10.0, 1.0, 13.0, -9.0, 13.0, -10.0, 2.0, 10.0, 8.0, 13.0, 4.0, -10.0, -8.0, -1.0, 12.0, 12.0, 10.0, 3.0, 10.0, -8.0, 12.0, -8.0, -2.0, 13.0, 12.0, -7.0, 12.0, -2.0, 8.0, 2.0, 12.0, -7.0, 11.0, -13.0, 11.0, 6.0, 12.0, -1.0, -6.0, 10.0, 13.0, 8.0, 6.0, -12.0, 10.0, -1.0, 7.0, -1.0, 8.0, -11.0, 7.0, 11.0, -1.0, 12.0, -4.0, 8.0, 9.0, -5.0, -1.0, 12.0, 3.0, -5.0, 12.0, 5.0, 6.0, -14.0, 12.0, 11.0, 13.0, 1.0, -7.0, 8.0, 13.0, -6.0, -3.0, 11.0, -7.0, 11.0, -2.0, 13.0, 7.0, -14.0, 12.0, 10.0, 13.0, -20.0, 12.0, 10.0, 14.0, 0.0, -6.0, 7.0, 8.0, 3.0, 11.0, -7.0, 9.0, -12.0, 10.0, 8.0, 5.0, -11.0, 12.0, 9.0, -3.0, 5.0, 3.0, 10.0, 2.0, 7.0, 10.0, -4.0, 6.0, 2.0, 11.0, -4.0, -14.0, 11.0, 8.0, 10.0, 9.0, -5.0, -1.0, 12.0, 10.0, 12.0, -8.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.184219045302457, "mean_inference_ms": 1.0621943208935898, "mean_action_processing_ms": 0.0709457347802082, "mean_env_wait_ms": 0.17441348718497676, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 727056, "agent_timesteps_total": 727056, "timers": {"sample_time_ms": 0.091, "sample_throughput": 60585461.508, "learn_time_ms": 14.88, "learn_throughput": 370166.886, "update_time_ms": 6.842}, "info": {"learner": {"learned": {"policy_loss": 165366677504.0, "vf_loss": 226.77096557617188, "total_loss": 165366677504.0, "vf_explained_var": -0.00032651424407958984, "model": {}}}, "num_steps_sampled": 727056, "num_agent_steps_sampled": 727056, "num_steps_trained": 727056, "num_agent_steps_trained": 727056}, "done": false, "episodes_total": 14256, "training_iteration": 132, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-17", "timestamp": 1626864497, "time_this_iter_s": 0.359039306640625, "time_total_s": 47.89241671562195, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a78c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 47.89241671562195, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 70.5, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -1.0, 12.0, -6.0, 8.0, 8.0, -11.0, 10.0, 0.0, 9.0, 10.0, -4.0, 7.0, -5.0, 12.0, 1.0, 4.0, -10.0, 9.0, 12.0, 13.0, 0.0, 7.0, -5.0, -8.0, 5.0, 7.0, 11.0, -3.0, -4.0, 13.0, 9.0, -6.0, 6.0, 12.0, 3.0, 9.0, 8.0, 6.0, -8.0, -14.0, 7.0, 11.0, 11.0, -9.0, 5.0, 7.0, 12.0, -8.0, 3.0, 10.0, 10.0, 6.0, 14.0, -16.0, 11.0, -7.0, 9.0, 5.0, 8.0, -2.0, -8.0, 12.0, 13.0, 13.0, 12.0, 3.0, -13.0, 6.0, -7.0, 12.0, 4.0, -6.0, 4.0, 9.0, 8.0, -8.0, 0.0, 13.0, 10.0, 12.0, -2.0, -5.0, 10.0, 12.0, 4.0, 7.0, -8.0, -6.0, 11.0, -3.0, 13.0, 2.0, 11.0, 13.0, -11.0, 13.0, -2.0, 5.0, -1.0, 13.0, 0.0, 10.0, -8.0, 4.0, 6.0, 12.0, -7.0, 4.0, 1.0, 11.0, -1.0, -2.0, 12.0, 8.0, -3.0, 12.0, 1.0, 6.0, -4.0, 8.0, 9.0, -14.0, 12.0, -15.0, 9.0, 13.0, 8.0, -1.0, 11.0, 11.0, -6.0, -8.0, 13.0, 12.0, -2.0, -11.0, 13.0, 1.0, 12.0, 2.0, -5.0, 11.0, 7.0, 13.0, 7.0, -16.0, 11.0, 8.0, 2.0, 12.0, -7.0, 2.0, 8.0, -3.0, 8.0, -1.0, -4.0, 7.0, 13.0, -2.0, 5.0, 6.0, 6.0, 7.0, -9.0, 8.0, 9.0, 2.0, 8.0, 6.0, -1.0, -6.0, 10.0, 13.0, -2.0, 12.0, -11.0, 9.0, 5.0, 9.0, 4.0, -1.0, 3.0, 13.0, 2.0, 2.0, -2.0, 5.0, -5.0, 11.0, 4.0, -8.0, 1.0, 10.0, 12.0, 8.0, 7.0, -13.0, 13.0, -12.0, 4.0, 12.0, 11.0, -12.0, 10.0, 12.0, 5.0, 14.0, 5.0, 2.0, -6.0, 9.0, -15.0, 12.0, 9.0, -8.0, 14.0, -3.0, 12.0, 7.0, -11.0, 6.0, 13.0, 4.0, -13.0, 12.0, 12.0, 14.0, 5.0, 11.0, -15.0, 3.0, 9.0, 10.0, -7.0, -1.0, -7.0, 13.0, 10.0, 11.0, -7.0, 5.0, 6.0, 13.0, -10.0, 4.0, 8.0, -14.0, 5.0, 13.0, 11.0, -10.0, 9.0, 13.0, 3.0, -1.0, 2.0, 5.0, 9.0, -9.0, -1.0, 12.0, 13.0, 2.0, 9.0, 5.0, -1.0, -8.0, 4.0, 13.0, 6.0, -2.0, 5.0, 9.0, 3.0, 12.0, 6.0, 3.0, -6.0, 3.0, 6.0, 7.0, -1.0, -12.0, 5.0, 13.0, 9.0, 9.0, -3.0, 12.0, -3.0, 13.0, -18.0, 8.0, 12.0, -6.0, -2.0, 12.0, 11.0, -9.0, 9.0, 12.0, 3.0, 13.0, -5.0, -1.0, 8.0, 8.0, -17.0, 13.0, 11.0, 0.0, 5.0, 11.0, -1.0, 11.0, -13.0, 5.0, 12.0, -4.0, 3.0, 9.0, 7.0, 8.0, 10.0, -11.0, 8.0, -14.0, 6.0, 13.0, 10.0, -11.0, 10.0, 13.0, 3.0, 10.0, -11.0, 10.0, 6.0, -1.0, -6.0, 12.0, 10.0, 5.0, 2.0, -1.0, 9.0, 12.0, -13.0, 13.0, 3.0, -2.0, 4.0, 4.0, 9.0, -6.0, 10.0, 13.0, -2.0, 0.0, 6.0, -3.0, 12.0, -6.0, 4.0, 4.0, 13.0, 12.0, 5.0, 9.0, -11.0, 6.0, -11.0, 7.0, 13.0, -12.0, 4.0, 10.0, 13.0, -11.0, 10.0, 13.0, 3.0, 12.0, 0.0, -9.0, 12.0, -10.0, 4.0, 10.0, 11.0, 4.0, 4.0, 11.0, -4.0, -3.0, 0.0, 8.0, 10.0, -1.0, 5.0, 9.0, 2.0, 7.0, 5.0, 7.0, -4.0, -16.0, 10.0, 9.0, 12.0, -9.0, 11.0, 0.0, 13.0, -6.0, 4.0, 8.0, 9.0, 13.0, -15.0, 6.0, 11.0, 7.0, 7.0, -6.0, 7.0, 3.0, -4.0, 3.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18421918033063148, "mean_inference_ms": 1.0622493353007576, "mean_action_processing_ms": 0.07094567248037621, "mean_env_wait_ms": 0.17441970812031687, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 732564, "agent_timesteps_total": 732564, "timers": {"sample_time_ms": 0.093, "sample_throughput": 59035559.61, "learn_time_ms": 14.762, "learn_throughput": 373125.089, "update_time_ms": 7.07}, "info": {"learner": {"learned": {"policy_loss": 199161167872.0, "vf_loss": 329.8407287597656, "total_loss": 199161167872.0, "vf_explained_var": -0.00015604496002197266, "model": {}}}, "num_steps_sampled": 732564, "num_agent_steps_sampled": 732564, "num_steps_trained": 732564, "num_agent_steps_trained": 732564}, "done": false, "episodes_total": 14364, "training_iteration": 133, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-17", "timestamp": 1626864497, "time_this_iter_s": 0.3570590019226074, "time_total_s": 48.249475717544556, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 48.249475717544556, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-6.0, -2.0, 10.0, 13.0, -2.0, 8.0, -2.0, 11.0, -1.0, -1.0, 5.0, 12.0, 10.0, 0.0, 12.0, -7.0, 6.0, -12.0, 13.0, 8.0, 4.0, -1.0, 7.0, 5.0, 8.0, -2.0, -1.0, 10.0, 10.0, 0.0, 7.0, -2.0, -8.0, 3.0, 8.0, 12.0, 9.0, 13.0, -13.0, 6.0, 9.0, -6.0, 7.0, 5.0, 12.0, 0.0, 7.0, -4.0, -12.0, 2.0, 13.0, 12.0, 10.0, 9.0, 10.0, -14.0, 3.0, 0.0, 6.0, 6.0, 6.0, 14.0, -2.0, -3.0, -7.0, -4.0, 13.0, 13.0, -16.0, 13.0, 10.0, 8.0, 7.0, 12.0, -1.0, -3.0, 6.0, 12.0, -16.0, 13.0, 7.0, -13.0, 8.0, 13.0, 8.0, -1.0, 2.0, 6.0, 3.0, -2.0, 3.0, 11.0, 7.0, -3.0, 4.0, 7.0, -10.0, 7.0, 5.0, 13.0, 12.0, 10.0, -3.0, -4.0, 9.0, 6.0, -3.0, 3.0, 9.0, -6.0, 0.0, 12.0, 8.0, -14.0, 8.0, 13.0, 6.0, 14.0, -5.0, 0.0, 4.0, 12.0, 1.0, -2.0, 12.0, -4.0, 11.0, -4.0, -5.0, -2.0, 10.0, 12.0, 9.0, 12.0, -3.0, -3.0, 8.0, 1.0, -2.0, 8.0, 12.0, 0.0, 11.0, -8.0, 10.0, 3.0, -10.0, 12.0, 10.0, 6.0, 3.0, -4.0, 10.0, -12.0, 11.0, 6.0, 9.0, 14.0, 1.0, -9.0, 5.0, 4.0, -7.0, 13.0, -10.0, 9.0, 10.0, 6.0, 13.0, -8.0, 10.0, 0.0, 11.0, 14.0, -9.0, -1.0, 4.0, 3.0, -5.0, 13.0, 10.0, 12.0, -8.0, 1.0, 8.0, 12.0, -3.0, -2.0, 8.0, 14.0, -10.0, 3.0, 8.0, -13.0, 12.0, 8.0, 9.0, 0.0, -1.0, 7.0, 9.0, -13.0, 12.0, 7.0, 6.0, -5.0, 6.0, 8.0, -6.0, 1.0, 12.0, 8.0, 6.0, 9.0, 2.0, -2.0, 3.0, -3.0, 3.0, 12.0, 13.0, -5.0, 7.0, 0.0, 8.0, -18.0, 12.0, 13.0, 4.0, 14.0, -4.0, 1.0, 13.0, 8.0, -16.0, 10.0, 5.0, 5.0, 9.0, -4.0, -9.0, 4.0, 7.0, 13.0, 6.0, 0.0, 10.0, -1.0, -1.0, -2.0, 11.0, 7.0, 12.0, 2.0, 4.0, -3.0, -6.0, 2.0, 13.0, 6.0, 1.0, -5.0, 11.0, 8.0, 1.0, -2.0, 8.0, 8.0, 9.0, 13.0, -7.0, 0.0, 3.0, -2.0, 6.0, 8.0, 4.0, 12.0, -3.0, 2.0, 8.0, 6.0, -9.0, 10.0, 10.0, 13.0, -6.0, -2.0, 9.0, -17.0, 10.0, 13.0, 2.0, 14.0, -13.0, 12.0, 8.0, 4.0, -5.0, 8.0, 12.0, 14.0, -5.0, -6.0, 6.0, 11.0, -15.0, 13.0, 3.0, 13.0, 12.0, -13.0, 4.0, -10.0, 11.0, 10.0, 10.0, 0.0, 9.0, -4.0, 8.0, -18.0, 12.0, 13.0, 12.0, 12.0, 4.0, -13.0, 4.0, 13.0, -14.0, 12.0, 10.0, -1.0, -4.0, 10.0, 6.0, -10.0, 11.0, 8.0, 7.0, 13.0, -5.0, 0.0, 14.0, 12.0, -1.0, -10.0, 10.0, 0.0, 11.0, -6.0, 10.0, -14.0, 7.0, 12.0, 6.0, 14.0, -5.0, 0.0, 3.0, 11.0, -2.0, 3.0, 12.0, -2.0, -7.0, 12.0, 8.0, -7.0, 1.0, 13.0, 12.0, 12.0, -6.0, -3.0, 8.0, -8.0, 12.0, 3.0, 11.0, 10.0, 0.0, -6.0, -8.0, 4.0, 6.0, 13.0, 10.0, 8.0, 11.0, -14.0, 8.0, 12.0, -2.0, -3.0, 12.0, 14.0, 11.0, 318.0, 7.0, 1.0, -1.0, 8.0, 6.0, 12.0, -5.0, 2.0, 13.0, -2.0, -2.0, 6.0, 12.0, 4.0, 4.0, -5.0, -9.0, 2.0, 10.0, 12.0, 11.0, 11.0, 3.0, -10.0, 8.0, 13.0, -4.0, -2.0, 10.0, 0.0, 9.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18421494421459458, "mean_inference_ms": 1.0622251246312044, "mean_action_processing_ms": 0.07094211509656949, "mean_env_wait_ms": 0.1744174513320724, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 738072, "agent_timesteps_total": 738072, "timers": {"sample_time_ms": 0.095, "sample_throughput": 58259019.985, "learn_time_ms": 14.682, "learn_throughput": 375147.591, "update_time_ms": 6.756}, "info": {"learner": {"learned": {"policy_loss": 1.237423062324524, "vf_loss": 20.530513763427734, "total_loss": 21.76793670654297, "vf_explained_var": -0.0060808658599853516, "model": {}}}, "num_steps_sampled": 738072, "num_agent_steps_sampled": 738072, "num_steps_trained": 738072, "num_agent_steps_trained": 738072}, "done": false, "episodes_total": 14472, "training_iteration": 134, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-18", "timestamp": 1626864498, "time_this_iter_s": 0.3541879653930664, "time_total_s": 48.60366368293762, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 48.60366368293762, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 72.6, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.333333333333332, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 4.583333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, 3.0, -2.0, 13.0, -1.0, -6.0, 9.0, 13.0, 6.0, 13.0, -12.0, 8.0, 8.0, 12.0, -10.0, 5.0, 2.0, 13.0, 10.0, -10.0, 0.0, 12.0, -9.0, 12.0, 4.0, 14.0, -12.0, 9.0, 13.0, 7.0, -10.0, 6.0, 3.0, -5.0, 7.0, 10.0, 3.0, 0.0, 7.0, 5.0, -9.0, 7.0, 11.0, 6.0, 9.0, 2.0, -4.0, 8.0, 9.0, 10.0, -10.0, 6.0, 2.0, 14.0, 9.0, -10.0, -13.0, 14.0, 12.0, 2.0, 7.0, 2.0, 8.0, -2.0, 8.0, 11.0, 5.0, -9.0, -12.0, 12.0, 4.0, 11.0, -11.0, 13.0, 10.0, 3.0, -3.0, 1.0, 7.0, 10.0, 9.0, 10.0, 11.0, -15.0, 1.0, 4.0, -3.0, 13.0, 7.0, 13.0, -13.0, 8.0, 13.0, 13.0, 6.0, -17.0, 6.0, 10.0, -12.0, 11.0, -12.0, 5.0, 11.0, 11.0, 1.0, 13.0, 7.0, -6.0, 6.0, 6.0, 13.0, -10.0, 7.0, 7.0, 8.0, -7.0, -2.0, -1.0, 11.0, 7.0, 4.0, 4.0, -3.0, 10.0, 14.0, 8.0, -4.0, -2.0, 8.0, 10.0, 5.0, -8.0, 0.0, -1.0, 7.0, 9.0, 11.0, 13.0, -16.0, 7.0, 10.0, -5.0, -3.0, 13.0, 7.0, -1.0, 0.0, 9.0, 2.0, 13.0, -6.0, 6.0, -16.0, 14.0, 6.0, 11.0, 8.0, -16.0, 13.0, 10.0, -17.0, 13.0, 12.0, 7.0, 1.0, 10.0, -8.0, 12.0, -9.0, 14.0, 11.0, -1.0, 9.0, -16.0, 12.0, 10.0, -3.0, -3.0, 11.0, 10.0, -2.0, 12.0, 10.0, -5.0, -9.0, 13.0, 5.0, 6.0, 9.0, -3.0, -4.0, 13.0, 8.0, 11.0, 9.0, -13.0, 0.0, 13.0, 10.0, -8.0, -11.0, 13.0, 10.0, 3.0, -5.0, 5.0, 11.0, 5.0, 7.0, 5.0, 10.0, -7.0, -1.0, 0.0, 4.0, 12.0, 6.0, 13.0, 5.0, -9.0, -1.0, 8.0, 5.0, 4.0, -9.0, 9.0, 5.0, 10.0, 0.0, 13.0, -4.0, 6.0, 9.0, -3.0, 0.0, 9.0, -8.0, 4.0, 6.0, 13.0, -9.0, 7.0, 6.0, 11.0, 332.0, 13.0, 10.0, 12.0, -11.0, 13.0, 1.0, 12.0, -2.0, 7.0, 1.0, 9.0, 3.0, 9.0, -9.0, 12.0, 0.0, 9.0, -3.0, 9.0, 7.0, 14.0, 6.0, -12.0, -4.0, 0.0, 11.0, 8.0, 2.0, -12.0, 12.0, 13.0, -8.0, 12.0, 7.0, 4.0, -16.0, 12.0, 6.0, 13.0, 10.0, 3.0, -2.0, 5.0, -13.0, 11.0, 11.0, 6.0, 1.0, -5.0, 12.0, 7.0, 10.0, 11.0, 11.0, -17.0, 13.0, -7.0, -3.0, 13.0, 12.0, 8.0, -17.0, 12.0, -14.0, 13.0, 10.0, 6.0, 7.0, 7.0, 13.0, -12.0, 1.0, -7.0, 8.0, 13.0, 11.0, 12.0, 3.0, -11.0, -18.0, 11.0, 12.0, 10.0, -15.0, 12.0, 8.0, 10.0, 12.0, 7.0, -6.0, 2.0, -16.0, 9.0, 11.0, 11.0, -1.0, 11.0, -3.0, 8.0, 3.0, 9.0, -9.0, 12.0, -2.0, -1.0, 11.0, 8.0, -4.0, 11.0, 10.0, -2.0, -1.0, 8.0, 10.0, -2.0, -10.0, 8.0, 5.0, 12.0, 11.0, 8.0, 2.0, -6.0, 4.0, -8.0, 7.0, 12.0, 3.0, -1.0, 5.0, 8.0, 3.0, 14.0, 10.0, -12.0, 12.0, 3.0, -10.0, 11.0, 5.0, 10.0, -10.0, 10.0, -13.0, 13.0, 7.0, 8.0, -3.0, 14.0, -9.0, 13.0, 4.0, 6.0, 7.0, -2.0, 7.0, -4.0, 4.0, 8.0, -7.0, 0.0, 9.0, 13.0, 3.0, 8.0, 5.0, -1.0, 12.0, 9.0, 4.0, -10.0, -1.0, 6.0, 11.0, -1.0, -11.0, 3.0, 11.0, 12.0, -8.0, 9.0, 6.0, 8.0, 5.0, 9.0, -5.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1842159672138776, "mean_inference_ms": 1.062264129123231, "mean_action_processing_ms": 0.07094232837385561, "mean_env_wait_ms": 0.17442618563742815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 743580, "agent_timesteps_total": 743580, "timers": {"sample_time_ms": 0.089, "sample_throughput": 61838933.754, "learn_time_ms": 14.57, "learn_throughput": 378030.934, "update_time_ms": 6.211}, "info": {"learner": {"learned": {"policy_loss": 507057799168.0, "vf_loss": 667.8365478515625, "total_loss": 507057799168.0, "vf_explained_var": -5.125999450683594e-06, "model": {}}}, "num_steps_sampled": 743580, "num_agent_steps_sampled": 743580, "num_steps_trained": 743580, "num_agent_steps_trained": 743580}, "done": false, "episodes_total": 14580, "training_iteration": 135, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-18", "timestamp": 1626864498, "time_this_iter_s": 0.352846622467041, "time_total_s": 48.95651030540466, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1828a840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 48.95651030540466, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 80.5, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -2.0, 10.0, -3.0, 5.0, 11.0, -6.0, 5.0, 10.0, -19.0, 12.0, 12.0, -5.0, 4.0, 8.0, 8.0, 9.0, 4.0, -10.0, 12.0, 0.0, 12.0, -8.0, 11.0, 7.0, -14.0, 11.0, 11.0, -2.0, 14.0, -3.0, 6.0, 12.0, 7.0, 8.0, -12.0, -1.0, 10.0, 13.0, -7.0, -5.0, 7.0, 7.0, 6.0, -9.0, 14.0, 6.0, 4.0, 13.0, 12.0, -17.0, 7.0, 1.0, 11.0, 8.0, -5.0, 10.0, -8.0, 10.0, 3.0, -10.0, 10.0, 8.0, 7.0, 8.0, -5.0, 11.0, 1.0, 3.0, 12.0, -6.0, 6.0, 12.0, -13.0, 11.0, 5.0, -5.0, 14.0, 3.0, 3.0, 7.0, -1.0, 12.0, -3.0, -17.0, 13.0, 13.0, 6.0, 11.0, -15.0, 12.0, 7.0, -8.0, 14.0, 8.0, 1.0, 5.0, -2.0, -1.0, 13.0, 5.0, 12.0, -3.0, 1.0, 11.0, -7.0, 9.0, 2.0, -4.0, 11.0, 0.0, 8.0, 12.0, -2.0, -3.0, 8.0, 8.0, 9.0, 3.0, -5.0, 11.0, -11.0, 6.0, 9.0, -8.0, 9.0, 3.0, 11.0, 5.0, 11.0, -14.0, 13.0, -9.0, 11.0, 13.0, 0.0, 9.0, -2.0, 0.0, 8.0, 7.0, 14.0, -10.0, 4.0, 11.0, -1.0, 10.0, -5.0, -4.0, 12.0, 3.0, 4.0, 13.0, 12.0, -6.0, -4.0, 12.0, 14.0, 7.0, -18.0, 9.0, 11.0, 12.0, -17.0, 13.0, 12.0, -2.0, -8.0, 9.0, -11.0, 10.0, 7.0, 10.0, 14.0, 13.0, -22.0, 9.0, 10.0, -17.0, 13.0, 12.0, 12.0, -2.0, -7.0, -6.0, 8.0, 13.0, 0.0, -9.0, 6.0, 8.0, 10.0, 6.0, -9.0, 11.0, 7.0, -16.0, 12.0, 11.0, 8.0, 11.0, 0.0, 11.0, -7.0, -10.0, 14.0, 9.0, 2.0, 10.0, -2.0, 0.0, 7.0, 9.0, 11.0, -3.0, -2.0, -10.0, 7.0, 5.0, 13.0, -11.0, 13.0, 11.0, 2.0, 10.0, 11.0, -17.0, 11.0, 12.0, 12.0, -1.0, -8.0, -12.0, 11.0, 8.0, 8.0, 6.0, 7.0, -9.0, 11.0, 8.0, -8.0, 12.0, 3.0, -1.0, 13.0, -10.0, 13.0, 9.0, -18.0, 11.0, 13.0, -9.0, 11.0, 9.0, 4.0, 8.0, 11.0, -17.0, 13.0, 4.0, 6.0, 9.0, -4.0, 11.0, 10.0, 9.0, -15.0, -9.0, 14.0, 2.0, 8.0, 3.0, -7.0, 11.0, 8.0, -1.0, 13.0, 11.0, -8.0, 4.0, -3.0, 2.0, 12.0, -6.0, 7.0, 6.0, 8.0, 10.0, 9.0, 12.0, -16.0, 3.0, 8.0, -7.0, 11.0, 11.0, -2.0, 2.0, 4.0, 11.0, 13.0, -7.0, -2.0, 10.0, -8.0, 2.0, 11.0, -9.0, 11.0, 9.0, 4.0, 13.0, -14.0, 11.0, 5.0, 12.0, 14.0, 9.0, -20.0, 12.0, 11.0, -14.0, 6.0, 0.0, 12.0, 13.0, -10.0, -2.0, 11.0, 7.0, -1.0, -8.0, 9.0, 1.0, 13.0, 10.0, -6.0, 11.0, 0.0, -1.0, 12.0, 7.0, -3.0, 13.0, 7.0, -8.0, 3.0, -7.0, 10.0, 4.0, 8.0, 12.0, 4.0, 2.0, -3.0, -2.0, 12.0, 12.0, -7.0, 5.0, -4.0, 7.0, 7.0, 3.0, 9.0, -8.0, 11.0, 6.0, -2.0, 12.0, -1.0, 12.0, 13.0, -3.0, -7.0, -7.0, 2.0, 12.0, 8.0, -6.0, 10.0, 7.0, 4.0, 9.0, 5.0, -7.0, 8.0, 0.0, 12.0, 13.0, -10.0, 13.0, -6.0, -4.0, 12.0, -10.0, 13.0, 13.0, -1.0, 6.0, -2.0, 12.0, -1.0, -12.0, 6.0, 11.0, 10.0, 11.0, -18.0, 12.0, 10.0, -11.0, 14.0, 7.0, 5.0, 11.0, 7.0, 10.0, -13.0, -1.0, 13.0, 13.0, -10.0, 13.0, -8.0, -1.0, 11.0, -1.0, 7.0, 10.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18420684918691935, "mean_inference_ms": 1.062140322485542, "mean_action_processing_ms": 0.0709363510861966, "mean_env_wait_ms": 0.17441682246554027, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 749088, "agent_timesteps_total": 749088, "timers": {"sample_time_ms": 0.087, "sample_throughput": 63128433.473, "learn_time_ms": 14.125, "learn_throughput": 389953.774, "update_time_ms": 5.621}, "info": {"learner": {"learned": {"policy_loss": 105888432128.0, "vf_loss": 121.66792297363281, "total_loss": 105888432128.0, "vf_explained_var": -0.0013391971588134766, "model": {}}}, "num_steps_sampled": 749088, "num_agent_steps_sampled": 749088, "num_steps_trained": 749088, "num_agent_steps_trained": 749088}, "done": false, "episodes_total": 14688, "training_iteration": 136, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-18", "timestamp": 1626864498, "time_this_iter_s": 0.3498237133026123, "time_total_s": 49.306334018707275, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1828ab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 49.306334018707275, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 16.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.046296296296296, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.761574074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, 11.0, 1.0, -9.0, 7.0, -1.0, 5.0, 4.0, -10.0, 8.0, 6.0, 11.0, 4.0, 1.0, 13.0, -3.0, 12.0, 7.0, -5.0, 1.0, 6.0, -9.0, 13.0, 5.0, -8.0, 4.0, 8.0, 11.0, -9.0, 5.0, 11.0, 8.0, 13.0, 5.0, -3.0, 0.0, 8.0, -13.0, 13.0, 7.0, -15.0, 13.0, 10.0, 7.0, 6.0, 1.0, -5.0, 13.0, -1.0, 6.0, -2.0, 12.0, 13.0, -19.0, 8.0, 13.0, -6.0, 7.0, 10.0, 4.0, -11.0, 7.0, 8.0, 11.0, 12.0, 7.0, 7.0, -11.0, 13.0, -9.0, 5.0, 6.0, 5.0, 12.0, 6.0, -7.0, 6.0, 7.0, -8.0, 10.0, 8.0, 10.0, 10.0, -13.0, 10.0, -12.0, 11.0, 6.0, -3.0, 5.0, 10.0, 3.0, 1.0, 4.0, -3.0, 13.0, -1.0, 7.0, 9.0, 0.0, 7.0, -1.0, 2.0, 7.0, 8.0, -7.0, 6.0, 8.0, -7.0, 0.0, 10.0, 12.0, 12.0, 12.0, -18.0, 9.0, 9.0, 10.0, 3.0, -7.0, -9.0, 7.0, 10.0, 7.0, -2.0, 0.0, 13.0, 4.0, -1.0, 12.0, 8.0, -4.0, 4.0, -9.0, 7.0, 13.0, -5.0, 7.0, 1.0, 12.0, -7.0, 14.0, -4.0, 12.0, -4.0, 12.0, 1.0, 6.0, 13.0, 8.0, 0.0, -6.0, 11.0, -12.0, 4.0, 12.0, -3.0, 3.0, 7.0, 8.0, 13.0, 12.0, -19.0, 9.0, 9.0, -8.0, 12.0, 2.0, -3.0, 13.0, -2.0, 7.0, -16.0, 10.0, 8.0, 13.0, 12.0, 12.0, -19.0, 10.0, 7.0, -9.0, 9.0, 8.0, -2.0, 6.0, 6.0, 5.0, -6.0, 7.0, 13.0, 1.0, 10.0, 14.0, -2.0, -7.0, 12.0, -4.0, 1.0, 6.0, 5.0, -8.0, 12.0, 7.0, -11.0, 9.0, 8.0, 9.0, 8.0, 7.0, 7.0, -7.0, 7.0, -3.0, -2.0, 13.0, 12.0, -8.0, -1.0, 12.0, -12.0, 7.0, 8.0, 12.0, 3.0, 6.0, 7.0, -1.0, 13.0, -11.0, 5.0, 8.0, 3.0, 10.0, -9.0, 11.0, 6.0, 5.0, 10.0, -6.0, -1.0, 13.0, -1.0, 4.0, 10.0, -14.0, 12.0, 7.0, -7.0, 5.0, 7.0, 10.0, -10.0, 6.0, 7.0, 12.0, 7.0, 13.0, 7.0, -12.0, 13.0, -11.0, 5.0, 8.0, -3.0, 12.0, 5.0, 1.0, 8.0, 2.0, 6.0, -1.0, 12.0, 7.0, -13.0, 9.0, 13.0, -10.0, -1.0, 13.0, -5.0, 8.0, 7.0, 6.0, 1.0, 10.0, 8.0, -4.0, 9.0, 10.0, 11.0, -15.0, 14.0, -8.0, -3.0, 12.0, -9.0, 7.0, 11.0, 6.0, 3.0, -5.0, 10.0, 7.0, 12.0, 12.0, 10.0, -19.0, 9.0, -11.0, 9.0, 8.0, -6.0, 3.0, 12.0, 7.0, -6.0, 8.0, 10.0, 3.0, -6.0, 10.0, -2.0, 13.0, 12.0, 5.0, 6.0, -8.0, 4.0, -3.0, 8.0, 6.0, 4.0, 11.0, 13.0, -13.0, 12.0, 8.0, 11.0, -16.0, 10.0, -16.0, 8.0, 13.0, 10.0, -4.0, 5.0, 4.0, -4.0, 3.0, 5.0, 11.0, 12.0, 11.0, 10.0, -18.0, 3.0, -6.0, 10.0, 8.0, 6.0, -4.0, 3.0, 10.0, 9.0, 6.0, 7.0, -7.0, -1.0, 12.0, -7.0, 11.0, 2.0, -12.0, 12.0, 13.0, 11.0, -6.0, 7.0, 3.0, -16.0, 6.0, 12.0, 13.0, 10.0, 8.0, 11.0, -14.0, 12.0, -9.0, 6.0, 6.0, 12.0, -13.0, 10.0, 6.0, -5.0, 11.0, 11.0, -2.0, 11.0, 11.0, 7.0, -14.0, 13.0, -8.0, 8.0, 2.0, -13.0, 6.0, 10.0, 12.0, -10.0, 8.0, 10.0, 7.0, 0.0, 9.0, -1.0, 7.0, 9.0, 11.0, -15.0, 10.0, -12.0, 12.0, 12.0, 4.0, -4.0, 7.0, 6.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18419935773218102, "mean_inference_ms": 1.0620368836232439, "mean_action_processing_ms": 0.07092965918931825, "mean_env_wait_ms": 0.17441026254442685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 754596, "agent_timesteps_total": 754596, "timers": {"sample_time_ms": 0.085, "sample_throughput": 64720203.92, "learn_time_ms": 13.98, "learn_throughput": 393997.934, "update_time_ms": 5.543}, "info": {"learner": {"learned": {"policy_loss": 197017288704.0, "vf_loss": 241.27757263183594, "total_loss": 197017288704.0, "vf_explained_var": -0.0007810592651367188, "model": {}}}, "num_steps_sampled": 754596, "num_agent_steps_sampled": 754596, "num_steps_trained": 754596, "num_agent_steps_trained": 754596}, "done": false, "episodes_total": 14796, "training_iteration": 137, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-19", "timestamp": 1626864499, "time_this_iter_s": 0.35016465187072754, "time_total_s": 49.656498670578, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1828aea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 49.656498670578, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 79.2, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, -3.0, 7.0, 6.0, 6.0, 11.0, 5.0, -7.0, 14.0, 11.0, 316.0, 13.0, -2.0, 7.0, -3.0, 13.0, 2.0, -5.0, 10.0, 8.0, 2.0, -3.0, 6.0, 10.0, 5.0, -11.0, 8.0, 13.0, 12.0, -6.0, -3.0, 12.0, 3.0, -5.0, 11.0, 6.0, 5.0, -10.0, 11.0, 9.0, 10.0, -9.0, 8.0, 6.0, 9.0, 0.0, 8.0, -2.0, -12.0, 8.0, 7.0, 12.0, 8.0, -10.0, 7.0, 11.0, 7.0, -14.0, 9.0, 13.0, 13.0, -7.0, -4.0, 13.0, -5.0, 10.0, 7.0, 3.0, 3.0, -10.0, 10.0, 12.0, 7.0, -6.0, 6.0, 8.0, 12.0, -13.0, 9.0, 7.0, -10.0, 10.0, 2.0, 13.0, 1.0, -7.0, 10.0, 11.0, 9.0, -11.0, 4.0, 13.0, 10.0, 1.0, -1.0, 5.0, 6.0, -7.0, 9.0, 7.0, 8.0, 11.0, -6.0, 2.0, 10.0, -17.0, 11.0, 11.0, 13.0, -5.0, 12.0, -5.0, 12.0, -10.0, 0.0, 13.0, 7.0, 4.0, -8.0, 12.0, 12.0, 6.0, -3.0, 0.0, 11.0, 3.0, -5.0, 6.0, -2.0, -2.0, 12.0, 7.0, 0.0, -3.0, 8.0, 10.0, 12.0, 3.0, -13.0, 13.0, 13.0, 4.0, -2.0, 0.0, -15.0, 14.0, 12.0, 4.0, 4.0, 0.0, 6.0, 6.0, 7.0, -7.0, 10.0, 5.0, 9.0, 4.0, -1.0, 3.0, -4.0, 5.0, 6.0, 8.0, 4.0, -7.0, 10.0, 8.0, 14.0, -21.0, 10.0, 12.0, -5.0, -3.0, 13.0, 10.0, 7.0, -11.0, 7.0, 12.0, 4.0, 9.0, -7.0, 9.0, 14.0, -19.0, 10.0, 10.0, 13.0, -12.0, 10.0, 4.0, 4.0, -2.0, 7.0, 6.0, 5.0, -11.0, 13.0, 8.0, 13.0, -1.0, 11.0, -8.0, 12.0, -8.0, 6.0, 5.0, 9.0, 12.0, 3.0, -9.0, 13.0, 10.0, -8.0, 0.0, 10.0, -4.0, 3.0, 6.0, 13.0, -9.0, 13.0, -2.0, 6.0, -5.0, 11.0, 3.0, 9.0, -12.0, 9.0, 9.0, 14.0, -8.0, 12.0, -3.0, -4.0, 12.0, -6.0, 13.0, 11.0, -8.0, 11.0, 1.0, 9.0, 4.0, 6.0, -4.0, 13.0, -5.0, -6.0, 13.0, 11.0, 2.0, -2.0, 4.0, -10.0, 11.0, 3.0, 11.0, 3.0, -8.0, 11.0, 9.0, 11.0, -1.0, -8.0, 13.0, 13.0, -10.0, 7.0, 5.0, 8.0, 9.0, 7.0, -9.0, 4.0, -6.0, 11.0, 6.0, 12.0, -18.0, 9.0, 12.0, 6.0, 6.0, -9.0, 12.0, -11.0, 13.0, 5.0, 8.0, 3.0, 8.0, 10.0, -6.0, 12.0, -19.0, 9.0, 13.0, 12.0, 4.0, -2.0, 1.0, -11.0, 6.0, 11.0, 9.0, 1.0, -3.0, 6.0, 11.0, 13.0, -1.0, 12.0, -9.0, 11.0, -12.0, 5.0, 11.0, 0.0, -3.0, 12.0, 6.0, 10.0, 3.0, -5.0, 7.0, 12.0, -17.0, 8.0, 12.0, 9.0, 6.0, 5.0, -5.0, 6.0, 6.0, 11.0, -8.0, 7.0, -8.0, 6.0, 10.0, 13.0, 7.0, -13.0, 8.0, 11.0, 10.0, -11.0, 5.0, -4.0, 1.0, 11.0, 7.0, 6.0, -8.0, 11.0, 6.0, 12.0, -21.0, 11.0, 13.0, 3.0, 7.0, -8.0, 13.0, -4.0, 10.0, 1.0, 8.0, 8.0, 4.0, 12.0, -9.0, 9.0, -11.0, 4.0, 13.0, 11.0, 4.0, -8.0, 8.0, 3.0, -1.0, 4.0, 9.0, 4.0, -12.0, 10.0, 13.0, 11.0, -2.0, -7.0, 13.0, 12.0, -1.0, -4.0, 8.0, 4.0, -4.0, 12.0, 3.0, 4.0, -5.0, 11.0, 5.0, 12.0, 0.0, -5.0, 8.0, -1.0, -10.0, 13.0, 13.0, 8.0, 13.0, -14.0, 8.0, 4.0, 4.0, -4.0, 11.0, 4.0, 10.0, -6.0, 7.0, 7.0, 9.0, -7.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841890045364024, "mean_inference_ms": 1.0619187134510957, "mean_action_processing_ms": 0.07092538374871975, "mean_env_wait_ms": 0.17440418348640577, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 760104, "agent_timesteps_total": 760104, "timers": {"sample_time_ms": 0.087, "sample_throughput": 63321844.745, "learn_time_ms": 14.204, "learn_throughput": 387773.495, "update_time_ms": 5.734}, "info": {"learner": {"learned": {"policy_loss": 1.1876585483551025, "vf_loss": 18.998937606811523, "total_loss": 20.186595916748047, "vf_explained_var": -0.009548187255859375, "model": {}}}, "num_steps_sampled": 760104, "num_agent_steps_sampled": 760104, "num_steps_trained": 760104, "num_agent_steps_trained": 760104}, "done": false, "episodes_total": 14904, "training_iteration": 138, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-19", "timestamp": 1626864499, "time_this_iter_s": 0.3668830394744873, "time_total_s": 50.02338171005249, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829a2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 50.02338171005249, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.574074074074073, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 6.893518518518518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-1.0, 5.0, 7.0, 4.0, 14.0, 11.0, 0.0, -10.0, -12.0, 2.0, 12.0, 13.0, 9.0, 2.0, 9.0, -5.0, -4.0, 4.0, 9.0, 6.0, 13.0, 7.0, 8.0, -13.0, 5.0, 0.0, 12.0, -2.0, 11.0, 7.0, -15.0, 12.0, 0.0, 8.0, 1.0, 6.0, 14.0, -14.0, 4.0, 11.0, -6.0, 5.0, 10.0, 6.0, 11.0, 7.0, 11.0, -14.0, -1.0, 3.0, 4.0, 9.0, 13.0, 318.0, 11.0, 13.0, -11.0, 1.0, 12.0, 13.0, 11.0, 0.0, 12.0, -8.0, 12.0, 0.0, -4.0, 7.0, 9.0, 10.0, 6.0, -10.0, 9.0, -14.0, 11.0, 9.0, 13.0, 5.0, -15.0, 12.0, 14.0, -5.0, -5.0, 11.0, 14.0, 1.0, -3.0, 3.0, 3.0, -8.0, 13.0, 7.0, -2.0, 6.0, 11.0, 0.0, -3.0, -4.0, 10.0, 12.0, 9.0, 12.0, 4.0, -10.0, 11.0, -11.0, 11.0, 4.0, -1.0, 8.0, 12.0, -4.0, 14.0, 12.0, -17.0, 6.0, 9.0, -16.0, 12.0, 10.0, 9.0, 6.0, 11.0, -11.0, -3.0, 7.0, 0.0, 11.0, 13.0, 0.0, 12.0, -10.0, 13.0, 320.0, 11.0, 12.0, 9.0, 5.0, 11.0, -10.0, 8.0, 8.0, -12.0, 11.0, -3.0, 4.0, 8.0, 6.0, 14.0, -21.0, 11.0, 11.0, -8.0, -1.0, 13.0, 11.0, -3.0, 1.0, 12.0, 5.0, 0.0, 1.0, 9.0, 5.0, 9.0, 8.0, 4.0, -6.0, 1.0, 5.0, 12.0, -3.0, 10.0, 6.0, 13.0, -14.0, 14.0, 6.0, -8.0, 3.0, 13.0, 316.0, 13.0, 12.0, -6.0, 7.0, 10.0, 4.0, 11.0, 0.0, 12.0, -8.0, 0.0, -1.0, 6.0, 10.0, 14.0, -6.0, 12.0, -5.0, 6.0, -10.0, 11.0, 8.0, 12.0, 5.0, -14.0, 12.0, 12.0, 5.0, 5.0, -7.0, 9.0, 11.0, 3.0, -8.0, -12.0, 7.0, 13.0, 7.0, -2.0, -6.0, 11.0, 12.0, 14.0, 7.0, -13.0, 7.0, 10.0, 5.0, 4.0, -4.0, -6.0, 3.0, 13.0, 5.0, 13.0, 6.0, 11.0, -15.0, 13.0, 5.0, 4.0, -7.0, 9.0, 10.0, 4.0, -8.0, 8.0, 4.0, 10.0, -7.0, 10.0, 6.0, 13.0, -14.0, -3.0, 5.0, 6.0, 7.0, 12.0, -3.0, -6.0, 12.0, 7.0, 4.0, 12.0, -8.0, 10.0, 8.0, -14.0, 11.0, 12.0, -1.0, 12.0, -8.0, 13.0, -8.0, 12.0, -2.0, -11.0, 2.0, 11.0, 13.0, 11.0, 13.0, 11.0, 318.0, 12.0, 4.0, -3.0, 2.0, 13.0, -9.0, 12.0, -1.0, -13.0, 9.0, 12.0, 7.0, 11.0, -13.0, 12.0, 5.0, 14.0, 6.0, 6.0, -11.0, 13.0, -7.0, 12.0, -3.0, 8.0, -12.0, 10.0, 9.0, -5.0, 5.0, 13.0, 2.0, -1.0, 6.0, 5.0, 5.0, 14.0, -17.0, 7.0, 11.0, 1.0, 10.0, 12.0, -8.0, 11.0, 2.0, 13.0, -11.0, -4.0, -5.0, 13.0, 11.0, 14.0, -16.0, 7.0, 10.0, 11.0, 7.0, 11.0, -14.0, -4.0, 6.0, 8.0, 5.0, 14.0, 7.0, -8.0, 2.0, 9.0, 11.0, 2.0, -7.0, -3.0, 12.0, 5.0, 1.0, 11.0, 9.0, 12.0, -17.0, -2.0, -2.0, 8.0, 11.0, 13.0, 11.0, -2.0, -7.0, 3.0, -10.0, 11.0, 11.0, -3.0, 11.0, 10.0, -3.0, 0.0, 1.0, 7.0, 7.0, 6.0, 10.0, 7.0, -8.0, 11.0, 10.0, 11.0, -17.0, 12.0, 11.0, -20.0, 12.0, 10.0, 6.0, 3.0, -4.0, 13.0, 10.0, 4.0, -12.0, 5.0, -10.0, 12.0, 8.0, 13.0, 7.0, -17.0, 12.0, 12.0, -11.0, 9.0, 5.0, 8.0, 5.0, -6.0, 8.0, 8.0, 2.0, 13.0, -8.0, -7.0, -2.0, 12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18419206181583855, "mean_inference_ms": 1.0618919414390577, "mean_action_processing_ms": 0.0709267438502234, "mean_env_wait_ms": 0.17440077680992253, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 765612, "agent_timesteps_total": 765612, "timers": {"sample_time_ms": 0.088, "sample_throughput": 62408152.612, "learn_time_ms": 14.201, "learn_throughput": 387846.408, "update_time_ms": 5.774}, "info": {"learner": {"learned": {"policy_loss": 1.3569499254226685, "vf_loss": 15.293072700500488, "total_loss": 16.650022506713867, "vf_explained_var": -0.009239673614501953, "model": {}}}, "num_steps_sampled": 765612, "num_agent_steps_sampled": 765612, "num_steps_trained": 765612, "num_agent_steps_trained": 765612}, "done": false, "episodes_total": 15012, "training_iteration": 139, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-20", "timestamp": 1626864500, "time_this_iter_s": 0.35546398162841797, "time_total_s": 50.37884569168091, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1828a730>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 50.37884569168091, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 72.8, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -7.0, 1.0, 13.0, 7.0, -8.0, 10.0, 6.0, -12.0, 7.0, 7.0, 13.0, 4.0, -10.0, 9.0, 12.0, 8.0, -1.0, 7.0, 1.0, -20.0, 14.0, 10.0, 11.0, -8.0, 9.0, 3.0, 11.0, -1.0, 5.0, 7.0, 4.0, 8.0, -15.0, 9.0, 13.0, -13.0, 14.0, 3.0, 11.0, -4.0, 2.0, 5.0, 12.0, 8.0, -5.0, 2.0, 10.0, 2.0, 8.0, 11.0, -6.0, -18.0, 12.0, 10.0, 11.0, 4.0, 9.0, -10.0, 12.0, -2.0, 7.0, 2.0, 8.0, 10.0, 1.0, 10.0, -6.0, -15.0, 12.0, 8.0, 10.0, 9.0, -10.0, 4.0, 12.0, -17.0, 8.0, 13.0, 11.0, 10.0, -6.0, 12.0, -1.0, -17.0, 12.0, 12.0, 8.0, -10.0, 9.0, 4.0, 12.0, -5.0, 5.0, 8.0, 7.0, 3.0, 12.0, -12.0, 12.0, 8.0, 6.0, 4.0, -3.0, -9.0, 9.0, 3.0, 12.0, 11.0, -4.0, 5.0, 3.0, -3.0, 12.0, 9.0, -3.0, -11.0, 12.0, 7.0, 7.0, -1.0, 7.0, 2.0, 7.0, -3.0, 4.0, 11.0, 3.0, 7.0, 12.0, -15.0, 11.0, 5.0, -9.0, 9.0, 10.0, 10.0, 2.0, -3.0, 6.0, 12.0, 6.0, 7.0, -10.0, 5.0, 14.0, -12.0, 8.0, 319.0, 12.0, 13.0, 12.0, -4.0, 7.0, 0.0, 12.0, -4.0, 8.0, 8.0, 3.0, 4.0, -9.0, 7.0, 13.0, -19.0, 12.0, 11.0, 11.0, 0.0, 13.0, -10.0, 12.0, -5.0, 9.0, 1.0, 10.0, 9.0, -8.0, 4.0, 10.0, -20.0, 11.0, 11.0, 13.0, -5.0, -4.0, 12.0, 12.0, 13.0, -5.0, 0.0, 7.0, 9.0, 9.0, 7.0, -10.0, 7.0, 11.0, -14.0, 11.0, 7.0, 9.0, -13.0, 12.0, -7.0, 5.0, 11.0, 6.0, 13.0, 12.0, 7.0, -17.0, 5.0, 10.0, 7.0, -7.0, 8.0, -17.0, 12.0, 12.0, -12.0, 13.0, 11.0, 3.0, 4.0, 8.0, 11.0, -8.0, -12.0, 13.0, 8.0, 6.0, -3.0, -2.0, 9.0, 11.0, -4.0, 8.0, 2.0, 9.0, 4.0, 0.0, 12.0, -1.0, -5.0, 13.0, 9.0, -2.0, -3.0, 7.0, -2.0, 13.0, -4.0, 8.0, 10.0, 1.0, -11.0, 13.0, 1.0, 12.0, -10.0, 10.0, 6.0, 9.0, 5.0, 9.0, -12.0, 13.0, 7.0, -8.0, 6.0, 10.0, 12.0, 14.0, -14.0, 3.0, 6.0, 11.0, -13.0, 11.0, -1.0, -8.0, 12.0, 12.0, 2.0, 12.0, 6.0, -5.0, 8.0, 8.0, 11.0, -12.0, -8.0, 11.0, 10.0, 2.0, 5.0, 9.0, -11.0, 12.0, -9.0, 9.0, 6.0, 9.0, 13.0, -6.0, 0.0, 8.0, -7.0, 12.0, -2.0, 12.0, 7.0, 7.0, -12.0, 13.0, -12.0, 12.0, 3.0, 12.0, -16.0, 13.0, 11.0, 7.0, 4.0, 6.0, 10.0, -5.0, 7.0, 8.0, -12.0, 12.0, 12.0, -10.0, 8.0, 5.0, 1.0, -1.0, 4.0, 11.0, -19.0, 11.0, 11.0, 12.0, 9.0, 7.0, -13.0, 12.0, -9.0, 10.0, 6.0, 8.0, 13.0, -2.0, -3.0, 7.0, -15.0, 12.0, 9.0, 9.0, 3.0, 8.0, -7.0, 11.0, 11.0, 6.0, -11.0, 9.0, -10.0, 12.0, 6.0, 7.0, -4.0, -3.0, 10.0, 12.0, -9.0, 9.0, 2.0, 13.0, -3.0, 7.0, 2.0, 9.0, 10.0, -1.0, 7.0, -1.0, -15.0, 12.0, 11.0, 7.0, -5.0, 5.0, 2.0, 13.0, 8.0, 6.0, -9.0, 10.0, 7.0, 0.0, 1.0, 7.0, -13.0, 14.0, 8.0, 6.0, 5.0, 8.0, -10.0, 12.0, 5.0, 12.0, -13.0, 11.0, 3.0, -1.0, 0.0, 13.0, -13.0, 10.0, 11.0, 7.0, 0.0, 8.0, -5.0, 12.0, -2.0, 12.0, -2.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18419453374858868, "mean_inference_ms": 1.0617842771453483, "mean_action_processing_ms": 0.07092120972999884, "mean_env_wait_ms": 0.17439399964361305, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 771120, "agent_timesteps_total": 771120, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65273811.277, "learn_time_ms": 14.324, "learn_throughput": 384537.209, "update_time_ms": 5.73}, "info": {"learner": {"learned": {"policy_loss": 325479563264.0, "vf_loss": 431.8573913574219, "total_loss": 325479563264.0, "vf_explained_var": -0.00018799304962158203, "model": {}}}, "num_steps_sampled": 771120, "num_agent_steps_sampled": 771120, "num_steps_trained": 771120, "num_agent_steps_trained": 771120}, "done": false, "episodes_total": 15120, "training_iteration": 140, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-20", "timestamp": 1626864500, "time_this_iter_s": 0.35454273223876953, "time_total_s": 50.73338842391968, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1828a598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 50.73338842391968, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25925925925926, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 4.564814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, -1.0, 5.0, 6.0, -11.0, 11.0, 3.0, 12.0, 12.0, 13.0, -15.0, 5.0, 0.0, 0.0, 9.0, 6.0, 1.0, 13.0, -5.0, 6.0, 10.0, 6.0, 3.0, -4.0, -4.0, 13.0, 0.0, 6.0, 11.0, -1.0, -4.0, 9.0, 12.0, -1.0, -4.0, 8.0, 9.0, 11.0, 5.0, -10.0, -3.0, 11.0, 1.0, 6.0, 6.0, 13.0, 8.0, -12.0, 1.0, -1.0, 9.0, 6.0, 5.0, -2.0, -1.0, 13.0, 11.0, 8.0, 5.0, -9.0, 11.0, 9.0, -2.0, -3.0, 3.0, 12.0, -8.0, 8.0, 9.0, 7.0, 9.0, -10.0, 12.0, 11.0, 5.0, -13.0, 2.0, -7.0, 10.0, 10.0, 0.0, 0.0, 6.0, 9.0, 13.0, 7.0, -17.0, 12.0, 8.0, 7.0, 8.0, -8.0, 12.0, 14.0, -8.0, -3.0, -13.0, 13.0, 8.0, 7.0, -8.0, 4.0, 7.0, 12.0, -4.0, 2.0, 11.0, 6.0, 2.0, -7.0, 12.0, 8.0, 5.0, 11.0, -8.0, 7.0, 10.0, 7.0, 3.0, -5.0, -4.0, 13.0, 9.0, -3.0, 3.0, 0.0, 1.0, 11.0, 13.0, 11.0, -20.0, 11.0, 5.0, 12.0, 9.0, -11.0, 14.0, 7.0, 3.0, -9.0, 4.0, -4.0, 8.0, 7.0, 14.0, -13.0, 10.0, 4.0, 10.0, 10.0, 13.0, -18.0, 10.0, 11.0, 1.0, -7.0, -3.0, 13.0, 10.0, -5.0, 1.0, -2.0, 3.0, 13.0, 3.0, 6.0, -7.0, 13.0, 2.0, 10.0, 12.0, -9.0, 8.0, 12.0, 3.0, -8.0, 13.0, 0.0, -3.0, 5.0, -5.0, 13.0, -6.0, 13.0, 14.0, 4.0, -12.0, 9.0, 7.0, 14.0, 1.0, -7.0, 9.0, -6.0, 4.0, 8.0, 6.0, -2.0, -2.0, 13.0, 14.0, 10.0, -3.0, -6.0, 2.0, 0.0, 10.0, 3.0, 6.0, -2.0, 4.0, 7.0, 6.0, 5.0, -8.0, 12.0, 9.0, -10.0, 5.0, 11.0, 3.0, 13.0, 6.0, -7.0, -7.0, -2.0, 11.0, 13.0, 12.0, 11.0, 7.0, -15.0, 13.0, 8.0, 0.0, -6.0, 8.0, 0.0, 3.0, 4.0, 7.0, -13.0, 10.0, 11.0, 8.0, -14.0, 9.0, 12.0, -3.0, 12.0, -4.0, 10.0, 10.0, 9.0, -12.0, 8.0, 1.0, -2.0, 10.0, 6.0, 8.0, -5.0, -1.0, 13.0, 13.0, 14.0, -3.0, -9.0, 8.0, 4.0, 6.0, -3.0, 12.0, 10.0, -15.0, 8.0, -9.0, 8.0, 5.0, 11.0, 11.0, 6.0, 2.0, -4.0, 5.0, 12.0, 5.0, -7.0, 4.0, 12.0, -13.0, 12.0, 8.0, -3.0, -3.0, 13.0, 14.0, 11.0, 331.0, 11.0, 11.0, 13.0, -6.0, -3.0, 2.0, 7.0, -6.0, 12.0, 11.0, 13.0, 9.0, -18.0, 8.0, 10.0, 4.0, -7.0, 7.0, 12.0, -6.0, 2.0, 4.0, 14.0, -14.0, 11.0, 2.0, -1.0, 2.0, 12.0, 14.0, 11.0, 1.0, -11.0, 9.0, -6.0, 4.0, 8.0, 9.0, -1.0, 4.0, 3.0, 12.0, 10.0, 1.0, -8.0, 9.0, 12.0, -5.0, -1.0, 4.0, 9.0, 10.0, -8.0, 1.0, 0.0, 7.0, 7.0, -10.0, 5.0, 9.0, 11.0, 13.0, 14.0, -3.0, -9.0, 6.0, -1.0, 7.0, 3.0, -1.0, 13.0, -6.0, 9.0, -4.0, 8.0, 1.0, 10.0, -2.0, 11.0, 1.0, 5.0, 2.0, 13.0, 5.0, -5.0, 11.0, 13.0, 5.0, -14.0, 5.0, 14.0, -14.0, 10.0, -6.0, 10.0, 3.0, 8.0, -2.0, -4.0, 11.0, 10.0, 7.0, 13.0, -1.0, -4.0, 3.0, 0.0, 1.0, 11.0, 13.0, 4.0, 9.0, -11.0, 8.0, 12.0, -18.0, 13.0, 8.0, -1.0, -4.0, 12.0, 8.0, -5.0, 1.0, 11.0, 12.0, 11.0, 0.0, -8.0, 2.0, 13.0, 7.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18420016076958634, "mean_inference_ms": 1.061816825517723, "mean_action_processing_ms": 0.0709220459943925, "mean_env_wait_ms": 0.174404239721463, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 776628, "agent_timesteps_total": 776628, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69769563.129, "learn_time_ms": 14.02, "learn_throughput": 392866.945, "update_time_ms": 5.841}, "info": {"learner": {"learned": {"policy_loss": 95436726272.0, "vf_loss": 127.77037811279297, "total_loss": 95436726272.0, "vf_explained_var": -0.001096963882446289, "model": {}}}, "num_steps_sampled": 776628, "num_agent_steps_sampled": 776628, "num_steps_trained": 776628, "num_agent_steps_trained": 776628}, "done": false, "episodes_total": 15228, "training_iteration": 141, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-20", "timestamp": 1626864500, "time_this_iter_s": 0.3605990409851074, "time_total_s": 51.093987464904785, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1a4312f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 51.093987464904785, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 75.1, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.62037037037037, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 6.905092592592593}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 12.0, 4.0, 12.0, 4.0, 13.0, 9.0, -11.0, 12.0, 7.0, 5.0, -9.0, 14.0, 0.0, -5.0, 6.0, 2.0, -11.0, 11.0, 13.0, -11.0, 13.0, 9.0, 4.0, 11.0, 3.0, 6.0, -5.0, 10.0, -3.0, 4.0, 4.0, -6.0, 4.0, 12.0, 5.0, -5.0, 9.0, 3.0, 8.0, 8.0, 10.0, 4.0, -7.0, 10.0, 13.0, 1.0, -9.0, 5.0, 10.0, 4.0, -4.0, 3.0, 13.0, -10.0, 9.0, 12.0, 9.0, -2.0, -4.0, 11.0, -1.0, 6.0, -1.0, -13.0, 12.0, 4.0, 12.0, 6.0, 12.0, 2.0, -5.0, 11.0, 7.0, 7.0, -10.0, 14.0, -8.0, 3.0, 6.0, 12.0, 7.0, 8.0, -12.0, 11.0, 12.0, -18.0, 10.0, 11.0, 2.0, -5.0, 7.0, 14.0, -8.0, 2.0, 7.0, 12.0, 12.0, 11.0, 321.0, -9.0, 13.0, 7.0, 4.0, 11.0, 6.0, 11.0, -13.0, 14.0, -2.0, 3.0, 0.0, -10.0, 12.0, 9.0, 4.0, 2.0, 9.0, -3.0, 7.0, 12.0, 9.0, -1.0, -5.0, 7.0, -2.0, 3.0, 7.0, -9.0, 13.0, 6.0, 5.0, 4.0, 4.0, -5.0, 12.0, 12.0, 14.0, -1.0, -10.0, 3.0, 0.0, 9.0, 3.0, -8.0, 11.0, 7.0, 5.0, 5.0, 8.0, -6.0, 8.0, 1.0, -11.0, 13.0, 12.0, 13.0, 11.0, -11.0, 2.0, 10.0, 11.0, 11.0, -17.0, -11.0, 9.0, 8.0, 9.0, 10.0, 13.0, -12.0, 4.0, 12.0, 13.0, 5.0, -15.0, 11.0, 13.0, 9.0, 322.0, 4.0, 13.0, -7.0, 5.0, 9.0, -17.0, 13.0, 10.0, 13.0, -6.0, 1.0, 7.0, -12.0, 11.0, 4.0, 12.0, -7.0, 13.0, 13.0, -4.0, 8.0, 11.0, 6.0, -10.0, 13.0, -3.0, -2.0, 7.0, 6.0, 8.0, 10.0, -9.0, 10.0, 12.0, -6.0, -1.0, 11.0, -13.0, 10.0, 7.0, 14.0, 12.0, -8.0, -3.0, -15.0, 7.0, 10.0, 13.0, 10.0, 8.0, -14.0, 11.0, 11.0, 14.0, 4.0, -14.0, 13.0, -4.0, -1.0, 7.0, 6.0, 10.0, 6.0, -7.0, -3.0, 9.0, 4.0, 5.0, 12.0, 13.0, -1.0, -9.0, 14.0, -1.0, -4.0, 6.0, 5.0, 9.0, 4.0, -3.0, 10.0, 8.0, -5.0, 2.0, 11.0, 12.0, -9.0, 1.0, 13.0, -1.0, 4.0, -1.0, 4.0, 10.0, 3.0, -2.0, 10.0, 12.0, -1.0, -6.0, 9.0, 11.0, -16.0, 11.0, 14.0, -1.0, -2.0, 4.0, 1.0, 12.0, 11.0, -9.0, 11.0, 8.0, -1.0, -3.0, 10.0, 12.0, 13.0, -20.0, 14.0, -7.0, -4.0, 12.0, 13.0, 12.0, 321.0, 10.0, -6.0, 12.0, 13.0, -4.0, 4.0, 4.0, 9.0, -2.0, 13.0, -2.0, 0.0, 4.0, -10.0, 8.0, 6.0, 11.0, -8.0, 10.0, 3.0, 10.0, 11.0, -2.0, 13.0, -7.0, 13.0, -9.0, 3.0, 8.0, 6.0, -6.0, 2.0, 13.0, 6.0, 13.0, 1.0, -5.0, 9.0, 5.0, -1.0, 2.0, 13.0, -2.0, 4.0, 0.0, 12.0, 12.0, 10.0, 322.0, -10.0, 10.0, 5.0, 10.0, 11.0, 7.0, 13.0, -16.0, 10.0, 10.0, 9.0, -14.0, -1.0, 2.0, 8.0, 6.0, 9.0, 13.0, -6.0, -1.0, 12.0, 5.0, -7.0, 5.0, 14.0, -3.0, 9.0, -5.0, -7.0, 12.0, 9.0, 1.0, 11.0, 12.0, -1.0, -7.0, 12.0, 5.0, 11.0, -13.0, 13.0, -3.0, 8.0, -3.0, 12.0, 11.0, 5.0, -13.0, 8.0, 12.0, -17.0, 12.0, 10.0, 5.0, -5.0, 5.0, 11.0, -6.0, -1.0, 11.0, 7.0, 2.0, 10.0, -4.0, -3.0, 12.0, 13.0, -7.0, 12.0, 7.0, 6.0, -10.0, 8.0, -2.0, 3.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18417487573650057, "mean_inference_ms": 1.0616459129689009, "mean_action_processing_ms": 0.07091479428666031, "mean_env_wait_ms": 0.17437849855217458, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 782136, "agent_timesteps_total": 782136, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69949874.454, "learn_time_ms": 14.038, "learn_throughput": 392373.178, "update_time_ms": 5.892}, "info": {"learner": {"learned": {"policy_loss": 1.2099905014038086, "vf_loss": 18.563278198242188, "total_loss": 19.773269653320312, "vf_explained_var": -0.0063163042068481445, "model": {}}}, "num_steps_sampled": 782136, "num_agent_steps_sampled": 782136, "num_steps_trained": 782136, "num_agent_steps_trained": 782136}, "done": false, "episodes_total": 15336, "training_iteration": 142, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-21", "timestamp": 1626864501, "time_this_iter_s": 0.3571162223815918, "time_total_s": 51.45110368728638, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7ae8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 51.45110368728638, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 79.3, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 3.0, -3.0, 5.0, -5.0, 11.0, 13.0, -4.0, -10.0, 12.0, 6.0, 7.0, -1.0, 7.0, 8.0, 1.0, -10.0, 5.0, 9.0, 11.0, -18.0, 11.0, 11.0, 11.0, 14.0, -8.0, 2.0, 7.0, 8.0, -4.0, 12.0, -1.0, 3.0, -8.0, 9.0, 11.0, -9.0, 5.0, 7.0, 12.0, -2.0, 2.0, 12.0, 3.0, -2.0, 11.0, 2.0, 4.0, -1.0, -1.0, 10.0, 7.0, -1.0, 10.0, 12.0, -6.0, -3.0, 6.0, 12.0, 0.0, 8.0, -3.0, 11.0, -1.0, -10.0, 9.0, 7.0, 9.0, -14.0, 11.0, 8.0, 10.0, 0.0, -7.0, 11.0, 11.0, -2.0, 7.0, 7.0, 3.0, -6.0, 7.0, 11.0, 3.0, -5.0, 10.0, 13.0, -3.0, -1.0, 5.0, 6.0, 5.0, -5.0, 8.0, 7.0, 5.0, -5.0, 10.0, 11.0, -1.0, 0.0, -8.0, 11.0, 12.0, -12.0, 8.0, 7.0, 12.0, 10.0, -9.0, 11.0, 3.0, 12.0, -7.0, 6.0, 4.0, 0.0, 9.0, 12.0, -6.0, 7.0, -6.0, 12.0, 2.0, -6.0, 5.0, 8.0, 8.0, -2.0, 2.0, 12.0, 3.0, -8.0, 12.0, 8.0, 3.0, -8.0, 7.0, 9.0, 7.0, 11.0, -6.0, 6.0, 4.0, 11.0, -10.0, 7.0, 7.0, -11.0, 11.0, 8.0, 7.0, -8.0, 11.0, 11.0, 1.0, -7.0, 11.0, 12.0, -1.0, 6.0, -7.0, 10.0, 6.0, -3.0, 4.0, 2.0, 12.0, -6.0, 2.0, 12.0, 7.0, -2.0, 7.0, 12.0, -2.0, -7.0, 9.0, 8.0, 5.0, -13.0, 9.0, 8.0, 11.0, -18.0, 9.0, 12.0, 12.0, -10.0, 12.0, 5.0, 8.0, -7.0, 12.0, 6.0, 4.0, -18.0, 9.0, 11.0, 13.0, -2.0, 5.0, 6.0, 6.0, -4.0, 5.0, 10.0, 4.0, 0.0, 7.0, -3.0, 11.0, 5.0, -8.0, 8.0, 10.0, -5.0, 8.0, 11.0, 1.0, -11.0, 11.0, 12.0, 3.0, -9.0, 10.0, 8.0, 6.0, 2.0, 12.0, 9.0, -8.0, -14.0, 10.0, 6.0, 13.0, -2.0, 11.0, 2.0, 4.0, -4.0, 1.0, 6.0, 12.0, -20.0, 12.0, 13.0, 10.0, 11.0, -11.0, 8.0, 7.0, 2.0, 13.0, 11.0, -11.0, 11.0, -3.0, 5.0, 2.0, 0.0, -7.0, 13.0, 9.0, 10.0, 7.0, 9.0, -11.0, -6.0, 5.0, 13.0, 3.0, -5.0, 6.0, 12.0, 2.0, 12.0, 4.0, 2.0, -3.0, -10.0, 9.0, 10.0, 6.0, 11.0, -5.0, 12.0, -3.0, 7.0, -1.0, 8.0, 1.0, 6.0, 5.0, -6.0, 10.0, 12.0, -10.0, 9.0, 4.0, -3.0, 2.0, 8.0, 8.0, -1.0, 2.0, 11.0, 3.0, -8.0, 10.0, 2.0, 11.0, -1.0, 2.0, 2.0, 12.0, -4.0, 7.0, 11.0, 1.0, -9.0, 7.0, 13.0, 4.0, -9.0, 9.0, 5.0, 10.0, -16.0, 8.0, 11.0, 12.0, 11.0, -5.0, 6.0, 3.0, 7.0, -2.0, 12.0, -2.0, 6.0, 6.0, 6.0, -3.0, -7.0, 5.0, 12.0, 5.0, -2.0, 5.0, 7.0, 5.0, 4.0, -7.0, 7.0, 11.0, 7.0, 5.0, 8.0, -5.0, -6.0, 12.0, 2.0, 7.0, -13.0, 12.0, 12.0, 4.0, -8.0, 7.0, 11.0, 5.0, -14.0, 4.0, 12.0, 13.0, -14.0, 9.0, 12.0, 8.0, -9.0, 11.0, 10.0, 3.0, -10.0, 3.0, 10.0, 12.0, -14.0, 12.0, 6.0, 11.0, 5.0, 9.0, 8.0, -7.0, -3.0, 6.0, 13.0, -1.0, 10.0, -11.0, 11.0, 5.0, 7.0, 7.0, -10.0, 11.0, -12.0, 8.0, 12.0, 7.0, -5.0, 13.0, 3.0, 4.0, -7.0, 1.0, 12.0, 9.0, 6.0, -8.0, 9.0, 8.0, -14.0, 12.0, 11.0, 6.0, -6.0, 12.0, 12.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418111181133417, "mean_inference_ms": 1.0617054501075829, "mean_action_processing_ms": 0.07091535648880659, "mean_env_wait_ms": 0.1743898755179305, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 787644, "agent_timesteps_total": 787644, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69691701.595, "learn_time_ms": 14.522, "learn_throughput": 379283.378, "update_time_ms": 6.088}, "info": {"learner": {"learned": {"policy_loss": 1.2046895027160645, "vf_loss": 19.265348434448242, "total_loss": 20.47003746032715, "vf_explained_var": -0.01043403148651123, "model": {}}}, "num_steps_sampled": 787644, "num_agent_steps_sampled": 787644, "num_steps_trained": 787644, "num_agent_steps_trained": 787644}, "done": false, "episodes_total": 15444, "training_iteration": 143, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-21", "timestamp": 1626864501, "time_this_iter_s": 0.37000393867492676, "time_total_s": 51.821107625961304, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a77b8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 51.821107625961304, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 6.0, -13.0, 9.0, 11.0, -1.0, -1.0, 6.0, 0.0, -3.0, 6.0, 12.0, -3.0, 9.0, 2.0, 7.0, 10.0, 4.0, 11.0, -10.0, 6.0, 9.0, 10.0, -10.0, 14.0, 5.0, 3.0, -7.0, 13.0, 0.0, -10.0, 12.0, 12.0, 2.0, -3.0, 4.0, 6.0, -14.0, 11.0, 12.0, 0.0, 5.0, 12.0, -2.0, 11.0, 11.0, -11.0, 4.0, 4.0, 13.0, -4.0, 2.0, 8.0, 3.0, 12.0, -8.0, 14.0, 1.0, -13.0, 13.0, 11.0, -12.0, 12.0, 4.0, 4.0, 8.0, 10.0, -7.0, 2.0, -2.0, 9.0, 6.0, 0.0, 5.0, -2.0, 12.0, -1.0, -2.0, 11.0, 7.0, 7.0, -13.0, 10.0, 11.0, 12.0, 4.0, -14.0, 13.0, 5.0, 6.0, -9.0, 13.0, 13.0, 10.0, -14.0, 6.0, -7.0, 1.0, 12.0, 9.0, 4.0, 8.0, 9.0, -6.0, 0.0, 0.0, 12.0, 3.0, 12.0, 7.0, 7.0, -11.0, -6.0, 6.0, 12.0, 3.0, 6.0, -8.0, 4.0, 13.0, -3.0, 6.0, -1.0, 13.0, 11.0, 4.0, -2.0, 2.0, 9.0, 7.0, -13.0, 12.0, 4.0, 11.0, -10.0, 10.0, 12.0, 0.0, -10.0, 13.0, 13.0, 11.0, -7.0, -2.0, 9.0, -2.0, 11.0, -3.0, 13.0, 5.0, -11.0, 8.0, 9.0, 6.0, -13.0, 13.0, 11.0, 8.0, 4.0, -8.0, 2.0, 11.0, -9.0, 11.0, 7.0, 10.0, 4.0, -6.0, 11.0, 2.0, -10.0, 12.0, 9.0, 11.0, -7.0, 2.0, -9.0, 7.0, 11.0, 6.0, 8.0, 7.0, -13.0, 13.0, -5.0, 8.0, 4.0, 8.0, 7.0, 5.0, -7.0, 10.0, -9.0, 4.0, 10.0, 10.0, 3.0, 5.0, -6.0, 13.0, 14.0, 0.0, -12.0, 13.0, -9.0, 10.0, 3.0, 11.0, -12.0, 13.0, 3.0, 11.0, -2.0, -2.0, 7.0, 12.0, 0.0, 2.0, 0.0, 13.0, 10.0, -9.0, 3.0, 11.0, 1.0, 9.0, -6.0, 11.0, 13.0, -16.0, 12.0, 6.0, 0.0, 5.0, -3.0, 13.0, 11.0, 13.0, -14.0, 5.0, -5.0, 12.0, 7.0, 1.0, 0.0, 7.0, -3.0, 11.0, 14.0, 5.0, -17.0, 13.0, 12.0, -7.0, 4.0, 6.0, 11.0, -1.0, 7.0, -2.0, 8.0, 3.0, -7.0, 11.0, 13.0, -6.0, -4.0, 12.0, 11.0, -6.0, 6.0, 4.0, -5.0, 7.0, 6.0, 7.0, 8.0, -3.0, -3.0, 13.0, 14.0, -3.0, -8.0, 12.0, 11.0, 10.0, 6.0, -12.0, 7.0, -8.0, 5.0, 11.0, 8.0, 5.0, -3.0, 5.0, 14.0, -6.0, -5.0, 12.0, 11.0, 11.0, -18.0, 11.0, 11.0, 3.0, 3.0, -2.0, 13.0, -14.0, 7.0, 9.0, -3.0, 7.0, 12.0, -1.0, 11.0, -12.0, 11.0, 5.0, 8.0, 7.0, 8.0, -8.0, 10.0, -16.0, 10.0, 11.0, 14.0, 5.0, -17.0, 13.0, 13.0, 4.0, -9.0, 7.0, -5.0, 2.0, 9.0, 9.0, 6.0, -10.0, 11.0, 8.0, -4.0, 6.0, 12.0, 1.0, 6.0, 12.0, -9.0, 6.0, 7.0, -7.0, 10.0, 5.0, 4.0, -2.0, 3.0, 10.0, 0.0, 2.0, 3.0, 10.0, 13.0, 6.0, 6.0, -10.0, 12.0, 5.0, 11.0, -13.0, 13.0, -3.0, -8.0, 13.0, 11.0, 6.0, 12.0, -14.0, 6.0, -2.0, 7.0, 4.0, 8.0, 6.0, 5.0, -4.0, 4.0, 6.0, -7.0, 12.0, -9.0, 8.0, 6.0, 10.0, 7.0, -6.0, 7.0, 7.0, 6.0, -7.0, 5.0, 11.0, 7.0, -2.0, 7.0, 3.0, 12.0, 0.0, -10.0, 13.0, 12.0, 10.0, 1.0, -8.0, 8.0, 8.0, 4.0, -5.0, 5.0, 7.0, -9.0, 12.0, 5.0, 12.0, -14.0, 12.0, 10.0, 14.0, -20.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416882633169318, "mean_inference_ms": 1.061665889757318, "mean_action_processing_ms": 0.07091300060827328, "mean_env_wait_ms": 0.17438717493471467, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 793152, "agent_timesteps_total": 793152, "timers": {"sample_time_ms": 0.079, "sample_throughput": 70002503.767, "learn_time_ms": 14.617, "learn_throughput": 376815.004, "update_time_ms": 6.574}, "info": {"learner": {"learned": {"policy_loss": 103547355136.0, "vf_loss": 126.02885437011719, "total_loss": 103547355136.0, "vf_explained_var": -0.0010117292404174805, "model": {}}}, "num_steps_sampled": 793152, "num_agent_steps_sampled": 793152, "num_steps_trained": 793152, "num_agent_steps_trained": 793152}, "done": false, "episodes_total": 15552, "training_iteration": 144, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-22", "timestamp": 1626864502, "time_this_iter_s": 0.364518404006958, "time_total_s": 52.18562602996826, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a22970840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 52.18562602996826, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 77.7, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-9.0, 14.0, 0.0, 10.0, 12.0, 7.0, -6.0, 2.0, 11.0, 11.0, -4.0, -3.0, 11.0, -7.0, 7.0, 4.0, 13.0, 9.0, 10.0, -17.0, 3.0, 9.0, -8.0, 11.0, 13.0, -17.0, 10.0, 9.0, -2.0, 0.0, 5.0, 12.0, 11.0, -6.0, -1.0, 11.0, 9.0, 11.0, -10.0, 5.0, 13.0, 11.0, -7.0, -2.0, -9.0, 7.0, 11.0, 6.0, -5.0, 5.0, 7.0, 8.0, 11.0, 11.0, 4.0, -11.0, 14.0, 2.0, 4.0, -5.0, 8.0, 10.0, 11.0, -14.0, 7.0, 12.0, -15.0, 11.0, 12.0, 8.0, 11.0, -16.0, 8.0, -3.0, -1.0, 11.0, 6.0, 14.0, 11.0, -16.0, -7.0, 10.0, 10.0, 2.0, 4.0, 12.0, 3.0, -4.0, 8.0, -15.0, 12.0, 10.0, 6.0, 8.0, 5.0, -4.0, 3.0, 9.0, -9.0, 12.0, 12.0, 10.0, -6.0, -1.0, 11.0, -8.0, 12.0, 0.0, -13.0, 13.0, 5.0, 10.0, 10.0, 9.0, -17.0, 13.0, 4.0, 11.0, 8.0, -8.0, 14.0, 11.0, -7.0, -3.0, 13.0, 1.0, -9.0, 10.0, 12.0, 1.0, -10.0, 12.0, 12.0, 11.0, 2.0, -10.0, 13.0, 1.0, -6.0, 7.0, 10.0, 8.0, 5.0, -8.0, -4.0, 9.0, 4.0, 6.0, -2.0, 7.0, 3.0, 7.0, 14.0, 3.0, 3.0, -5.0, -4.0, 8.0, 1.0, 10.0, 3.0, 9.0, 11.0, -8.0, 12.0, 5.0, 10.0, -12.0, 0.0, 11.0, 9.0, -5.0, 12.0, 1.0, -6.0, 8.0, -9.0, 12.0, 11.0, 1.0, 12.0, 6.0, -12.0, 9.0, 12.0, -3.0, 5.0, 1.0, -5.0, 13.0, 11.0, -4.0, 12.0, 3.0, 10.0, -10.0, 12.0, 5.0, 3.0, -5.0, 14.0, 2.0, -6.0, 5.0, -8.0, 11.0, 11.0, 1.0, 11.0, -10.0, 2.0, 12.0, 11.0, 7.0, -8.0, 5.0, 12.0, -1.0, -8.0, 12.0, -4.0, 2.0, 5.0, 12.0, 12.0, 9.0, 10.0, -16.0, 12.0, 7.0, -2.0, -2.0, 8.0, -10.0, 12.0, 5.0, -8.0, 7.0, 7.0, 9.0, 6.0, -8.0, 4.0, 13.0, 11.0, 11.0, -14.0, 7.0, 10.0, -9.0, 9.0, 5.0, 9.0, 13.0, -9.0, 2.0, -3.0, 2.0, 3.0, 13.0, 12.0, 13.0, -3.0, -7.0, 12.0, -16.0, 7.0, 12.0, 9.0, 10.0, 8.0, -12.0, -6.0, 13.0, -4.0, 12.0, -2.0, 3.0, 12.0, 2.0, 10.0, 6.0, -2.0, 1.0, 12.0, 5.0, -10.0, 8.0, 5.0, -4.0, 4.0, 10.0, 12.0, 9.0, -8.0, 2.0, 14.0, 10.0, -7.0, -2.0, 11.0, 11.0, 11.0, -18.0, -1.0, 4.0, 10.0, 2.0, 12.0, 10.0, 4.0, -11.0, 14.0, 5.0, -11.0, 7.0, 13.0, -17.0, 11.0, 8.0, 11.0, -7.0, 3.0, 8.0, 12.0, 10.0, -13.0, 6.0, 13.0, -6.0, 12.0, -4.0, -1.0, -2.0, 8.0, 10.0, 10.0, -17.0, 11.0, 11.0, 12.0, 6.0, 13.0, -16.0, 12.0, -2.0, -6.0, 11.0, 10.0, 7.0, 7.0, -9.0, -1.0, 7.0, 0.0, 9.0, 12.0, 6.0, -14.0, 11.0, 0.0, 4.0, 13.0, -2.0, -1.0, 6.0, 0.0, 10.0, 12.0, -8.0, 12.0, -1.0, 5.0, 10.0, 10.0, -10.0, 5.0, 6.0, -1.0, 5.0, 9.0, -5.0, 5.0, 6.0, -2.0, 13.0, -1.0, 5.0, 7.0, 11.0, -13.0, 10.0, 9.0, -7.0, 8.0, 5.0, 13.0, -11.0, 6.0, 7.0, 6.0, 6.0, 4.0, -1.0, 11.0, 10.0, 7.0, -13.0, 12.0, -3.0, 6.0, 0.0, 14.0, -16.0, 7.0, 10.0, -4.0, 14.0, 6.0, -1.0, 5.0, 12.0, 8.0, -10.0, 9.0, -10.0, 5.0, 11.0, 14.0, -17.0, 8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841589207911546, "mean_inference_ms": 1.0616388054255075, "mean_action_processing_ms": 0.07091300741526144, "mean_env_wait_ms": 0.17439176069320683, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 798660, "agent_timesteps_total": 798660, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68157856.862, "learn_time_ms": 14.66, "learn_throughput": 375717.436, "update_time_ms": 6.987}, "info": {"learner": {"learned": {"policy_loss": 23790094336.0, "vf_loss": 122.90544128417969, "total_loss": 23790094336.0, "vf_explained_var": -0.0013124942779541016, "model": {}}}, "num_steps_sampled": 798660, "num_agent_steps_sampled": 798660, "num_steps_trained": 798660, "num_agent_steps_trained": 798660}, "done": false, "episodes_total": 15660, "training_iteration": 145, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-22", "timestamp": 1626864502, "time_this_iter_s": 0.3596518039703369, "time_total_s": 52.5452778339386, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7378>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 52.5452778339386, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 366.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.25, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 328.0}, "policy_reward_mean": {"learned": 4.5625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, -6.0, 13.0, 12.0, 5.0, -15.0, 12.0, 13.0, 12.0, -3.0, 12.0, -6.0, 7.0, 7.0, -12.0, 13.0, -1.0, 0.0, 10.0, 6.0, 5.0, 6.0, 7.0, -3.0, 7.0, -15.0, 10.0, 13.0, 6.0, -2.0, -2.0, 13.0, 6.0, 13.0, -13.0, 9.0, 8.0, -15.0, 10.0, 12.0, 8.0, -6.0, 11.0, 2.0, 13.0, -16.0, 5.0, 13.0, 9.0, 5.0, -11.0, 12.0, 9.0, 3.0, -9.0, 12.0, 6.0, -12.0, 12.0, 9.0, 13.0, 5.0, -16.0, 13.0, 10.0, 0.0, 11.0, -6.0, 13.0, 328.0, 12.0, 13.0, 10.0, -12.0, 11.0, 6.0, 12.0, 1.0, -11.0, 13.0, 7.0, -1.0, 10.0, -1.0, 10.0, -3.0, -4.0, 12.0, 1.0, -5.0, 12.0, 7.0, 12.0, -1.0, -5.0, 9.0, 6.0, 6.0, 8.0, -5.0, 12.0, -1.0, -9.0, 13.0, 10.0, 2.0, -10.0, 13.0, -1.0, 5.0, -2.0, 13.0, 7.0, 3.0, -6.0, 11.0, 7.0, 3.0, -8.0, 13.0, 12.0, -14.0, 11.0, 6.0, 13.0, 5.0, -12.0, 9.0, 11.0, 8.0, -13.0, 9.0, 12.0, -5.0, -3.0, 11.0, 9.0, -5.0, 6.0, 5.0, -7.0, 5.0, 4.0, 13.0, 9.0, -12.0, 13.0, 5.0, 4.0, -11.0, 12.0, 10.0, 3.0, -9.0, 9.0, 12.0, -5.0, 0.0, 7.0, 13.0, -5.0, 2.0, 13.0, 5.0, 7.0, -18.0, 13.0, 13.0, 9.0, -14.0, 12.0, 8.0, -1.0, 3.0, 0.0, 13.0, -15.0, 7.0, 10.0, 13.0, 1.0, -10.0, 12.0, 12.0, 9.0, -11.0, 6.0, 11.0, 8.0, -2.0, -4.0, 13.0, 8.0, 9.0, -6.0, 4.0, 8.0, -10.0, 12.0, 5.0, 6.0, -4.0, 11.0, 2.0, -1.0, 13.0, -6.0, 9.0, -3.0, -1.0, 6.0, 13.0, 5.0, 2.0, -5.0, 13.0, 13.0, -8.0, 11.0, -1.0, 6.0, 0.0, 3.0, 6.0, 6.0, 7.0, -9.0, 11.0, 8.0, 5.0, -11.0, 13.0, 13.0, -10.0, 11.0, 1.0, -8.0, 13.0, 3.0, 7.0, 6.0, -1.0, 0.0, 10.0, 8.0, 10.0, -11.0, 8.0, 12.0, -10.0, 7.0, 6.0, 7.0, 0.0, -5.0, 13.0, 7.0, 4.0, 11.0, -7.0, 10.0, -16.0, 8.0, 13.0, 9.0, 10.0, 10.0, -14.0, 11.0, 4.0, -13.0, 13.0, 11.0, 11.0, -14.0, 7.0, 9.0, 4.0, 11.0, -9.0, 10.0, -12.0, 9.0, 8.0, 12.0, 7.0, -17.0, 13.0, -1.0, -1.0, 8.0, 9.0, 10.0, 4.0, -10.0, 11.0, 12.0, -17.0, 13.0, 7.0, -1.0, -1.0, 4.0, 13.0, 8.0, -1.0, -1.0, 9.0, 4.0, -4.0, 3.0, 12.0, 13.0, -12.0, 8.0, 6.0, -6.0, 8.0, 0.0, 13.0, 10.0, -5.0, 11.0, -1.0, 6.0, -12.0, 9.0, 12.0, 10.0, -15.0, 12.0, 8.0, 10.0, -6.0, -2.0, 13.0, -16.0, 8.0, 11.0, 12.0, 9.0, 1.0, 10.0, -5.0, -8.0, 3.0, 12.0, 8.0, 8.0, 11.0, -11.0, 7.0, -13.0, 13.0, 9.0, 6.0, 3.0, -4.0, 11.0, 5.0, 5.0, -11.0, 12.0, 9.0, -1.0, 5.0, -1.0, 12.0, 9.0, 2.0, 10.0, -6.0, 3.0, 10.0, 12.0, -10.0, 7.0, -12.0, 8.0, 12.0, -5.0, 11.0, 1.0, 8.0, 9.0, 1.0, 6.0, -1.0, 10.0, 0.0, 12.0, -7.0, 12.0, -17.0, 11.0, 9.0, -5.0, 7.0, 0.0, 13.0, -3.0, 13.0, 2.0, 3.0, 13.0, -20.0, 11.0, 11.0, 11.0, -12.0, 9.0, 7.0, 7.0, 12.0, -10.0, 6.0, -2.0, 13.0, 2.0, 2.0, 9.0, -14.0, 8.0, 12.0, 11.0, -11.0, 7.0, 8.0, -6.0, 6.0, 2.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18413953290353782, "mean_inference_ms": 1.0615335634923275, "mean_action_processing_ms": 0.07089983105903329, "mean_env_wait_ms": 0.17437230703230203, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 804168, "agent_timesteps_total": 804168, "timers": {"sample_time_ms": 0.078, "sample_throughput": 70684709.944, "learn_time_ms": 15.201, "learn_throughput": 362342.395, "update_time_ms": 7.033}, "info": {"learner": {"learned": {"policy_loss": 1.2913215160369873, "vf_loss": 21.10847282409668, "total_loss": 22.39979362487793, "vf_explained_var": -0.009155631065368652, "model": {}}}, "num_steps_sampled": 804168, "num_agent_steps_sampled": 804168, "num_steps_trained": 804168, "num_agent_steps_trained": 804168}, "done": false, "episodes_total": 15768, "training_iteration": 146, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-22", "timestamp": 1626864502, "time_this_iter_s": 0.35404229164123535, "time_total_s": 52.899320125579834, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a78c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 52.899320125579834, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 71.2, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 9.0, 4.0, 7.0, 8.0, -13.0, 9.0, 11.0, 4.0, 8.0, -7.0, 10.0, 10.0, 13.0, -4.0, -4.0, -5.0, 6.0, 9.0, 5.0, 8.0, -9.0, 10.0, 6.0, 3.0, 13.0, -4.0, 3.0, -15.0, 11.0, 7.0, 12.0, 11.0, -5.0, -2.0, 11.0, 5.0, -11.0, 10.0, 11.0, 4.0, -3.0, 4.0, 10.0, 319.0, 12.0, 11.0, 12.0, 11.0, 13.0, -2.0, -7.0, 2.0, -9.0, 10.0, 12.0, 6.0, 14.0, -13.0, 8.0, 3.0, 9.0, -2.0, 5.0, 12.0, 9.0, -2.0, -4.0, 13.0, -9.0, 0.0, 11.0, 2.0, 9.0, 7.0, -3.0, 2.0, 8.0, 11.0, -6.0, 10.0, -10.0, 8.0, 7.0, 13.0, -7.0, -3.0, 12.0, 8.0, -13.0, 7.0, 13.0, -6.0, 10.0, -2.0, 13.0, 12.0, 9.0, 11.0, -17.0, 12.0, 322.0, 12.0, 10.0, 3.0, 9.0, -7.0, 10.0, -4.0, 10.0, -4.0, 13.0, -6.0, 6.0, 11.0, 4.0, 8.0, -8.0, 10.0, 5.0, 12.0, 8.0, 2.0, -7.0, -9.0, 11.0, 8.0, 5.0, -5.0, 9.0, 10.0, 1.0, 5.0, -7.0, 10.0, 7.0, 5.0, 14.0, 5.0, -9.0, 4.0, 10.0, -11.0, 12.0, 10.0, 14.0, 8.0, -17.0, -6.0, 6.0, 11.0, 4.0, 7.0, 14.0, -11.0, 5.0, -4.0, 11.0, -2.0, 10.0, 6.0, 7.0, 6.0, -4.0, -6.0, 7.0, 6.0, 8.0, -10.0, 9.0, 10.0, 6.0, -7.0, 13.0, -2.0, 11.0, 11.0, 5.0, 5.0, -6.0, 10.0, -10.0, 4.0, 11.0, 7.0, 7.0, 6.0, -5.0, -11.0, 4.0, 12.0, 10.0, 6.0, 14.0, -4.0, -1.0, 10.0, -7.0, 1.0, 11.0, -1.0, 14.0, -8.0, 10.0, 4.0, 3.0, 11.0, -3.0, 11.0, 6.0, -5.0, 3.0, 13.0, -10.0, 6.0, 6.0, 10.0, 8.0, -16.0, 13.0, 0.0, 10.0, -2.0, 7.0, 8.0, 13.0, -5.0, -1.0, 10.0, -6.0, 0.0, 11.0, -8.0, 6.0, 9.0, 8.0, 14.0, 13.0, -12.0, 0.0, 3.0, 14.0, -8.0, 6.0, 14.0, -11.0, 2.0, 10.0, 7.0, 13.0, 7.0, -12.0, -5.0, 11.0, 11.0, -2.0, 7.0, 11.0, 1.0, -4.0, -6.0, 6.0, 4.0, 11.0, -1.0, 13.0, -7.0, 10.0, 4.0, 6.0, -7.0, 12.0, 9.0, 14.0, -4.0, -4.0, -1.0, 8.0, 4.0, 4.0, 7.0, 9.0, 4.0, -5.0, 1.0, 8.0, -5.0, 11.0, -2.0, 5.0, 6.0, 6.0, -9.0, 6.0, 8.0, 10.0, 10.0, 14.0, 12.0, -21.0, -2.0, 13.0, 12.0, -8.0, 14.0, 9.0, -5.0, -3.0, 6.0, -6.0, 6.0, 9.0, 4.0, 10.0, 4.0, -3.0, 4.0, 9.0, -3.0, 5.0, 12.0, 5.0, -4.0, 2.0, 9.0, -6.0, 11.0, 1.0, 2.0, 13.0, 4.0, -4.0, -4.0, 10.0, 11.0, -2.0, 5.0, 13.0, -3.0, 0.0, 4.0, -8.0, 9.0, 10.0, 6.0, 10.0, 12.0, -13.0, 2.0, 9.0, -7.0, 11.0, 5.0, 14.0, -5.0, 1.0, 12.0, -12.0, 11.0, 4.0, 5.0, 9.0, -11.0, 12.0, 0.0, -5.0, 12.0, 8.0, 13.0, 4.0, 7.0, -9.0, -1.0, 7.0, -1.0, 10.0, 4.0, 14.0, 11.0, -14.0, -20.0, 12.0, 11.0, 12.0, 8.0, 8.0, 5.0, -6.0, 14.0, -18.0, 8.0, 11.0, 8.0, 8.0, -14.0, 13.0, -1.0, 8.0, -3.0, 11.0, 3.0, 10.0, -4.0, 6.0, 13.0, -6.0, 3.0, 5.0, 3.0, 12.0, 5.0, -5.0, -11.0, 10.0, 10.0, 6.0, 1.0, 13.0, -4.0, 5.0, 6.0, -6.0, 4.0, 11.0, 11.0, 9.0, 12.0, -17.0, 6.0, 4.0, -3.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841526836596278, "mean_inference_ms": 1.0616302518501757, "mean_action_processing_ms": 0.07089843654927372, "mean_env_wait_ms": 0.174369945374869, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 809676, "agent_timesteps_total": 809676, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68980718.351, "learn_time_ms": 15.693, "learn_throughput": 350985.649, "update_time_ms": 7.061}, "info": {"learner": {"learned": {"policy_loss": 1.2243038415908813, "vf_loss": 20.557573318481445, "total_loss": 21.781877517700195, "vf_explained_var": -0.0072879791259765625, "model": {}}}, "num_steps_sampled": 809676, "num_agent_steps_sampled": 809676, "num_steps_trained": 809676, "num_agent_steps_trained": 809676}, "done": false, "episodes_total": 15876, "training_iteration": 147, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-23", "timestamp": 1626864503, "time_this_iter_s": 0.3673827648162842, "time_total_s": 53.26670289039612, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a7e2e2f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 53.26670289039612, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [1.0, -4.0, 10.0, 8.0, 11.0, 10.0, -3.0, -3.0, 14.0, 8.0, 2.0, -9.0, -7.0, 7.0, 4.0, 11.0, 13.0, 321.0, 10.0, 11.0, 9.0, -2.0, -3.0, 11.0, 13.0, 12.0, 0.0, -10.0, 9.0, 7.0, -6.0, 5.0, 13.0, -18.0, 11.0, 9.0, 12.0, 9.0, 0.0, -6.0, 12.0, 10.0, -12.0, 5.0, -8.0, 12.0, 3.0, 8.0, 12.0, -17.0, 9.0, 11.0, 12.0, 9.0, -16.0, 10.0, 7.0, 13.0, -2.0, -3.0, -2.0, 11.0, 10.0, -4.0, 13.0, -13.0, 10.0, 5.0, 10.0, 4.0, 2.0, -1.0, -5.0, 3.0, 8.0, 9.0, 11.0, -7.0, 7.0, 4.0, 0.0, -6.0, 10.0, 11.0, 11.0, 9.0, -3.0, -2.0, 6.0, 11.0, -9.0, 7.0, 2.0, 12.0, -4.0, 5.0, 7.0, 7.0, 7.0, -6.0, 10.0, 9.0, -1.0, -3.0, 5.0, 6.0, -6.0, 10.0, 11.0, -7.0, 4.0, 7.0, 6.0, 9.0, 11.0, -11.0, 6.0, 9.0, 3.0, -3.0, 5.0, -4.0, 3.0, 11.0, 8.0, -5.0, 4.0, 8.0, 4.0, -2.0, 7.0, 6.0, 12.0, 2.0, -10.0, 11.0, 4.0, 12.0, 7.0, -8.0, -8.0, 12.0, 4.0, 7.0, 13.0, -18.0, 7.0, 13.0, 12.0, 10.0, 2.0, -9.0, 5.0, 4.0, 11.0, -5.0, -5.0, 8.0, 8.0, 4.0, 1.0, -2.0, 10.0, 6.0, -7.0, 2.0, 11.0, 9.0, 10.0, 10.0, 8.0, -13.0, 10.0, 9.0, 4.0, -8.0, 8.0, -7.0, 8.0, 6.0, 3.0, 14.0, 1.0, -3.0, 5.0, 6.0, -2.0, 6.0, 4.0, -2.0, 6.0, 7.0, 10.0, 6.0, 10.0, -11.0, 10.0, 6.0, 1.0, -2.0, 0.0, 11.0, -6.0, 10.0, -5.0, 6.0, 8.0, 6.0, 13.0, -4.0, 1.0, 5.0, 10.0, 5.0, -2.0, 2.0, 11.0, -10.0, 3.0, 11.0, 14.0, -5.0, 4.0, 2.0, 0.0, -6.0, 11.0, 10.0, 12.0, 9.0, 1.0, -7.0, 13.0, 9.0, -14.0, 7.0, -1.0, -2.0, 10.0, 8.0, 9.0, 7.0, -9.0, 8.0, -2.0, 4.0, 3.0, 10.0, 13.0, 10.0, -13.0, 5.0, 6.0, 12.0, -8.0, 5.0, 12.0, -19.0, 9.0, 13.0, 6.0, 5.0, -6.0, 10.0, 12.0, 11.0, 1.0, -9.0, 11.0, 11.0, -4.0, -3.0, 8.0, -5.0, 5.0, 7.0, 13.0, 9.0, -14.0, 7.0, 8.0, 8.0, -9.0, 8.0, 12.0, 1.0, -5.0, 7.0, 13.0, 320.0, 12.0, 10.0, 13.0, 3.0, -4.0, 3.0, 13.0, 8.0, 0.0, -6.0, -11.0, 13.0, 6.0, 7.0, 5.0, 10.0, 12.0, -12.0, 7.0, 14.0, -4.0, -2.0, 14.0, 8.0, 1.0, -8.0, 4.0, -1.0, 5.0, 7.0, -12.0, 11.0, 4.0, 12.0, 9.0, 11.0, -17.0, 12.0, 5.0, 10.0, 10.0, -10.0, 7.0, 7.0, 8.0, -7.0, -1.0, -6.0, 11.0, 11.0, 11.0, 6.0, 1.0, -3.0, 8.0, 13.0, 4.0, -10.0, -9.0, 9.0, 11.0, 4.0, 2.0, -3.0, 9.0, 7.0, -1.0, 11.0, -4.0, 9.0, 12.0, 9.0, -11.0, 5.0, 2.0, -1.0, 8.0, 6.0, 14.0, -17.0, 12.0, 6.0, -4.0, 9.0, 6.0, 4.0, 13.0, 10.0, -7.0, -1.0, -5.0, 5.0, 11.0, 4.0, 14.0, 2.0, -7.0, 6.0, 11.0, 9.0, 12.0, -17.0, 4.0, 9.0, 7.0, -5.0, -7.0, 10.0, 6.0, 6.0, 8.0, -10.0, 8.0, 9.0, 11.0, 8.0, -2.0, -2.0, 11.0, -7.0, 3.0, 8.0, -13.0, 11.0, 9.0, 8.0, 13.0, -18.0, 10.0, 10.0, 7.0, 9.0, 2.0, -3.0, 9.0, 11.0, 12.0, -17.0, 4.0, 8.0, 9.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18415612067912776, "mean_inference_ms": 1.061615866365206, "mean_action_processing_ms": 0.07089428015095946, "mean_env_wait_ms": 0.17438148770801287, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 815184, "agent_timesteps_total": 815184, "timers": {"sample_time_ms": 0.082, "sample_throughput": 66912547.016, "learn_time_ms": 15.785, "learn_throughput": 348944.077, "update_time_ms": 7.095}, "info": {"learner": {"learned": {"policy_loss": 108833472512.0, "vf_loss": 131.0290985107422, "total_loss": 108833472512.0, "vf_explained_var": -0.000812530517578125, "model": {}}}, "num_steps_sampled": 815184, "num_agent_steps_sampled": 815184, "num_steps_trained": 815184, "num_agent_steps_trained": 815184}, "done": false, "episodes_total": 15984, "training_iteration": 148, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-23", "timestamp": 1626864503, "time_this_iter_s": 0.3672199249267578, "time_total_s": 53.633922815322876, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 53.633922815322876, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 73.3, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 1.0, 7.0, -2.0, 0.0, 5.0, 0.0, 10.0, -4.0, 5.0, 3.0, 11.0, 9.0, 0.0, -3.0, 9.0, 11.0, -5.0, 12.0, -3.0, 12.0, 10.0, -14.0, 7.0, -3.0, 8.0, -2.0, 12.0, 4.0, 11.0, -3.0, 3.0, 5.0, 8.0, 6.0, -4.0, -8.0, 3.0, 8.0, 12.0, 4.0, 12.0, 11.0, -12.0, 14.0, 6.0, -4.0, -1.0, 10.0, 11.0, 8.0, -14.0, 5.0, 13.0, 8.0, -11.0, 3.0, 10.0, -10.0, 12.0, 14.0, -6.0, 2.0, 5.0, 5.0, 13.0, -16.0, 13.0, 13.0, 12.0, -3.0, -7.0, 12.0, 11.0, -21.0, 13.0, 3.0, 7.0, -6.0, 11.0, 4.0, 12.0, 6.0, -7.0, 12.0, 11.0, -13.0, 5.0, -13.0, 6.0, 10.0, 12.0, 6.0, -1.0, 11.0, -1.0, 3.0, -1.0, 12.0, 1.0, -7.0, 10.0, 7.0, 5.0, 7.0, 11.0, 9.0, -12.0, 14.0, -13.0, 5.0, 9.0, 11.0, 14.0, -15.0, 5.0, 0.0, 4.0, 3.0, 8.0, 1.0, 13.0, -2.0, 3.0, 7.0, -7.0, 12.0, 3.0, 5.0, 7.0, -9.0, 12.0, 10.0, 12.0, -20.0, 13.0, -13.0, 10.0, 5.0, 13.0, 13.0, -11.0, 4.0, 9.0, 12.0, 11.0, 12.0, 321.0, 9.0, 7.0, -3.0, 2.0, 4.0, 2.0, -4.0, 13.0, 11.0, -6.0, 5.0, 5.0, 6.0, 8.0, 12.0, -11.0, -1.0, 9.0, 3.0, 4.0, -3.0, 8.0, 3.0, 7.0, 10.0, -6.0, 9.0, 2.0, 7.0, 13.0, 8.0, -13.0, 11.0, -4.0, 4.0, 4.0, -9.0, 13.0, 2.0, 9.0, 14.0, 4.0, -2.0, -1.0, 5.0, 12.0, -13.0, 11.0, 0.0, 10.0, -1.0, 6.0, -16.0, 8.0, 11.0, 12.0, 9.0, 4.0, -5.0, 7.0, 3.0, 12.0, 9.0, -9.0, -5.0, 7.0, 3.0, 10.0, 5.0, 7.0, -5.0, 8.0, 4.0, 0.0, 12.0, -1.0, 8.0, 10.0, -11.0, 8.0, -7.0, 12.0, 11.0, -1.0, 0.0, 7.0, -4.0, 12.0, 14.0, 9.0, 1.0, -9.0, 11.0, 4.0, 8.0, -8.0, 10.0, 5.0, -11.0, 11.0, 7.0, 1.0, -5.0, 12.0, 8.0, 8.0, -6.0, 5.0, -16.0, 9.0, 12.0, 10.0, -1.0, 5.0, 12.0, -1.0, 2.0, 11.0, 6.0, -4.0, 13.0, 8.0, -2.0, -4.0, 7.0, 9.0, 12.0, -13.0, 13.0, 9.0, -17.0, 10.0, 6.0, 13.0, -10.0, 6.0, 4.0, -5.0, 6.0, 10.0, 6.0, 11.0, -6.0, 4.0, 13.0, 8.0, -11.0, 5.0, 9.0, 12.0, 3.0, -9.0, 6.0, 1.0, -1.0, 9.0, 4.0, 10.0, 12.0, -11.0, 12.0, -10.0, 0.0, 13.0, 7.0, 8.0, -12.0, 12.0, 13.0, -5.0, 2.0, 5.0, 14.0, 11.0, -4.0, -6.0, -2.0, 10.0, 7.0, 0.0, 9.0, 13.0, -20.0, 13.0, 8.0, 3.0, -1.0, 5.0, 7.0, 6.0, -5.0, 7.0, 13.0, -10.0, 4.0, 8.0, 9.0, 11.0, -17.0, 12.0, 12.0, -3.0, -6.0, 12.0, 7.0, -5.0, 10.0, 3.0, -5.0, 9.0, 6.0, 5.0, -6.0, 10.0, 0.0, 11.0, 9.0, -9.0, 9.0, 6.0, 9.0, 9.0, 4.0, -7.0, 9.0, 3.0, -8.0, 11.0, 1.0, 12.0, -11.0, 13.0, 9.0, 0.0, -1.0, 7.0, 13.0, -4.0, -3.0, 9.0, 13.0, 12.0, -16.0, 6.0, 9.0, 12.0, 11.0, -17.0, 4.0, 9.0, -4.0, 6.0, 7.0, 13.0, -8.0, 3.0, 10.0, -9.0, 7.0, 7.0, 6.0, 4.0, -6.0, 11.0, 9.0, 8.0, -2.0, 0.0, 10.0, 4.0, 6.0, -5.0, 7.0, 0.0, -1.0, 9.0, -11.0, 11.0, 4.0, 11.0, 14.0, -10.0, 5.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841717160367902, "mean_inference_ms": 1.0616760988149918, "mean_action_processing_ms": 0.07089148330380313, "mean_env_wait_ms": 0.1743834176091269, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 820692, "agent_timesteps_total": 820692, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65786094.719, "learn_time_ms": 16.244, "learn_throughput": 339088.372, "update_time_ms": 7.216}, "info": {"learner": {"learned": {"policy_loss": 1.2570545673370361, "vf_loss": 24.796123504638672, "total_loss": 26.053178787231445, "vf_explained_var": -0.008869409561157227, "model": {}}}, "num_steps_sampled": 820692, "num_agent_steps_sampled": 820692, "num_steps_trained": 820692, "num_agent_steps_trained": 820692}, "done": false, "episodes_total": 16092, "training_iteration": 149, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-24", "timestamp": 1626864504, "time_this_iter_s": 0.37644147872924805, "time_total_s": 54.010364294052124, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826db70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 54.010364294052124, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 82.1, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.296296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.324074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, -3.0, 11.0, -1.0, 13.0, 8.0, -18.0, 12.0, 7.0, -3.0, 6.0, 5.0, 8.0, 1.0, 13.0, -7.0, 5.0, 1.0, -2.0, 11.0, 4.0, 6.0, -7.0, 12.0, 9.0, 2.0, 5.0, -1.0, -7.0, 1.0, 10.0, 11.0, 3.0, -13.0, 13.0, 12.0, 11.0, 10.0, 11.0, -17.0, 12.0, 12.0, 318.0, 13.0, -8.0, 0.0, 12.0, 11.0, 5.0, 6.0, -5.0, 9.0, 12.0, -13.0, 4.0, 12.0, 12.0, 3.0, -10.0, 10.0, -8.0, 2.0, 12.0, 9.0, 13.0, -3.0, -5.0, 10.0, -10.0, 9.0, 4.0, 12.0, 13.0, 6.0, -17.0, 13.0, 13.0, -2.0, 9.0, -5.0, 6.0, 5.0, -6.0, 10.0, 11.0, -16.0, 8.0, 12.0, 6.0, 6.0, 4.0, -1.0, 12.0, -3.0, 12.0, -6.0, 13.0, -16.0, 7.0, 11.0, -12.0, 9.0, 11.0, 7.0, 9.0, -3.0, -2.0, 11.0, -5.0, 6.0, 7.0, 7.0, 9.0, 6.0, -8.0, 8.0, 9.0, 8.0, -13.0, 11.0, 12.0, -2.0, 1.0, 4.0, 13.0, -8.0, 12.0, -2.0, 12.0, -2.0, 12.0, -7.0, -9.0, 6.0, 8.0, 10.0, 9.0, 11.0, -15.0, 10.0, 14.0, -3.0, -3.0, 7.0, 12.0, -3.0, -2.0, 8.0, -16.0, 8.0, 10.0, 13.0, 13.0, 11.0, 319.0, 12.0, -3.0, -3.0, 13.0, 8.0, 3.0, -6.0, 8.0, 10.0, 11.0, 3.0, 4.0, -3.0, 8.0, -12.0, 6.0, 13.0, 6.0, 1.0, -4.0, 12.0, 11.0, -8.0, -1.0, 13.0, -9.0, 4.0, 8.0, 12.0, 10.0, -1.0, 13.0, -7.0, -7.0, 13.0, 1.0, 8.0, 12.0, -19.0, 12.0, 10.0, -17.0, 9.0, 11.0, 12.0, 7.0, -3.0, 3.0, 8.0, -3.0, 2.0, 7.0, 9.0, 9.0, 6.0, 4.0, -4.0, -10.0, 10.0, 3.0, 12.0, 11.0, -3.0, -6.0, 13.0, 5.0, 6.0, -6.0, 10.0, 12.0, -3.0, -2.0, 8.0, 10.0, -14.0, 8.0, 11.0, 12.0, -4.0, -1.0, 8.0, 8.0, 1.0, -7.0, 13.0, 13.0, -7.0, 12.0, -3.0, 8.0, 0.0, 9.0, -2.0, 6.0, 1.0, 9.0, -1.0, -2.0, 0.0, 4.0, 13.0, 9.0, -11.0, 5.0, 12.0, 11.0, 3.0, -10.0, 11.0, 13.0, -2.0, -8.0, 12.0, 8.0, 8.0, -3.0, 2.0, 4.0, 12.0, -4.0, 3.0, 0.0, 13.0, -10.0, 12.0, 12.0, 9.0, -19.0, 13.0, 7.0, 1.0, -6.0, 13.0, -4.0, -4.0, 12.0, 11.0, 12.0, 10.0, -18.0, 11.0, 13.0, 0.0, -6.0, 8.0, -4.0, 8.0, 6.0, 5.0, 6.0, 0.0, -1.0, 10.0, -22.0, 12.0, 12.0, 13.0, 13.0, 9.0, -6.0, -1.0, 11.0, 2.0, 5.0, -3.0, 6.0, -13.0, 13.0, 9.0, 7.0, 3.0, -7.0, 12.0, 8.0, 12.0, -16.0, 11.0, 11.0, 8.0, -10.0, 6.0, 5.0, 2.0, -4.0, 12.0, 6.0, 3.0, 8.0, -2.0, 6.0, -6.0, 2.0, 13.0, -7.0, 2.0, 7.0, 13.0, 3.0, 11.0, 9.0, -8.0, -11.0, 9.0, 5.0, 12.0, 7.0, 6.0, 12.0, -10.0, -6.0, 5.0, 7.0, 9.0, 12.0, 1.0, -1.0, 3.0, 13.0, 7.0, -16.0, 11.0, 4.0, -2.0, 0.0, 13.0, 13.0, -1.0, 9.0, -6.0, 8.0, -17.0, 12.0, 12.0, -10.0, 4.0, 10.0, 11.0, 12.0, 9.0, -15.0, 9.0, 8.0, 5.0, 7.0, -5.0, 1.0, -8.0, 12.0, 10.0, 13.0, 8.0, -17.0, 11.0, 12.0, 4.0, 4.0, -5.0, -8.0, 5.0, 13.0, 5.0, 8.0, 12.0, -11.0, 6.0, 13.0, 5.0, 5.0, -8.0, 10.0, -7.0, 0.0, 12.0, -13.0, 6.0, 10.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841789985928967, "mean_inference_ms": 1.0616275435717513, "mean_action_processing_ms": 0.0708884986675484, "mean_env_wait_ms": 0.17438661771570263, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 826200, "agent_timesteps_total": 826200, "timers": {"sample_time_ms": 0.085, "sample_throughput": 64567556.602, "learn_time_ms": 15.822, "learn_throughput": 348126.423, "update_time_ms": 7.203}, "info": {"learner": {"learned": {"policy_loss": 190514298880.0, "vf_loss": 242.0526580810547, "total_loss": 190514298880.0, "vf_explained_var": -0.00043487548828125, "model": {}}}, "num_steps_sampled": 826200, "num_agent_steps_sampled": 826200, "num_steps_trained": 826200, "num_agent_steps_trained": 826200}, "done": false, "episodes_total": 16200, "training_iteration": 150, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-24", "timestamp": 1626864504, "time_this_iter_s": 0.3515195846557617, "time_total_s": 54.361883878707886, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826dea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 54.361883878707886, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [12.0, -12.0, 7.0, 8.0, -2.0, 7.0, 4.0, 6.0, 8.0, 7.0, -6.0, 6.0, 7.0, 6.0, -10.0, 12.0, 12.0, 4.0, -12.0, 11.0, -1.0, 4.0, 7.0, 5.0, 9.0, 9.0, 3.0, -6.0, 8.0, 12.0, 8.0, -13.0, -3.0, 4.0, 10.0, 4.0, 11.0, 10.0, 7.0, -13.0, -10.0, 11.0, 2.0, 12.0, 0.0, 12.0, 9.0, -6.0, -5.0, 14.0, 2.0, 4.0, 2.0, 12.0, 4.0, -3.0, 11.0, 8.0, 3.0, -7.0, -12.0, 14.0, 6.0, 7.0, 12.0, -4.0, 8.0, -1.0, 13.0, 4.0, 7.0, -9.0, 12.0, -9.0, 5.0, 7.0, -8.0, 10.0, 3.0, 10.0, 13.0, -6.0, 8.0, 0.0, 14.0, 12.0, -21.0, 10.0, -5.0, 10.0, -2.0, 12.0, -5.0, 5.0, 3.0, 12.0, -3.0, 6.0, 5.0, 7.0, -14.0, 13.0, 11.0, 5.0, 3.0, 6.0, -7.0, 13.0, 6.0, 12.0, -5.0, 2.0, 12.0, 4.0, 5.0, -6.0, 13.0, 13.0, 8.0, -19.0, -5.0, 9.0, 6.0, 5.0, 11.0, 12.0, 8.0, -16.0, -6.0, 8.0, 2.0, 11.0, 11.0, 14.0, 8.0, -18.0, -14.0, 10.0, 12.0, 7.0, 11.0, 12.0, -10.0, 2.0, -5.0, 8.0, 3.0, 9.0, -3.0, 13.0, -2.0, 7.0, -19.0, 11.0, 11.0, 12.0, 6.0, -10.0, 7.0, 12.0, -1.0, 3.0, 3.0, 10.0, -12.0, 12.0, 10.0, 5.0, 7.0, 8.0, -12.0, 12.0, -13.0, 13.0, 7.0, 8.0, -3.0, 13.0, 11.0, -6.0, -7.0, 12.0, 9.0, 1.0, 13.0, 12.0, -9.0, -1.0, 6.0, -6.0, 9.0, 6.0, -6.0, 4.0, 7.0, 10.0, -10.0, 12.0, 10.0, 3.0, -8.0, 11.0, 0.0, 12.0, -7.0, 13.0, 2.0, 7.0, -5.0, 9.0, -1.0, 12.0, 5.0, 13.0, 8.0, -11.0, 12.0, 10.0, 1.0, -8.0, -7.0, 12.0, 7.0, 3.0, -7.0, 6.0, 5.0, 11.0, 13.0, 10.0, -15.0, 7.0, 4.0, 9.0, 8.0, -6.0, 8.0, 9.0, 4.0, -6.0, -2.0, 10.0, 8.0, -1.0, 0.0, 10.0, 7.0, -2.0, 5.0, 9.0, 7.0, -6.0, 5.0, 6.0, -4.0, 8.0, 9.0, -12.0, 10.0, 8.0, 12.0, 3.0, 9.0, -9.0, -7.0, 10.0, 5.0, 7.0, 8.0, -6.0, 9.0, 4.0, 11.0, -4.0, 3.0, 5.0, 11.0, 6.0, 6.0, -8.0, 13.0, 4.0, -8.0, 6.0, -8.0, 11.0, 8.0, 4.0, -2.0, 5.0, 4.0, 8.0, 14.0, 13.0, -5.0, -7.0, -5.0, 9.0, 8.0, 3.0, 7.0, 14.0, -4.0, -2.0, -1.0, 3.0, 3.0, 10.0, 13.0, 13.0, 9.0, -20.0, 11.0, 10.0, -18.0, 12.0, 7.0, -14.0, 9.0, 13.0, -6.0, 9.0, 10.0, 2.0, 10.0, 8.0, -8.0, 5.0, 10.0, 7.0, -10.0, 8.0, -7.0, 5.0, 9.0, 8.0, -1.0, 1.0, 11.0, 4.0, 13.0, 11.0, 9.0, -18.0, 7.0, 6.0, -1.0, 3.0, -9.0, 12.0, 4.0, 8.0, 12.0, -14.0, 4.0, 13.0, 2.0, 13.0, 12.0, -12.0, -7.0, 8.0, 2.0, 12.0, -3.0, -5.0, 10.0, 13.0, 12.0, -10.0, 2.0, 11.0, -1.0, 5.0, 6.0, 5.0, 4.0, 5.0, -2.0, 8.0, -14.0, 8.0, 12.0, 9.0, -5.0, 3.0, 7.0, 10.0, -13.0, 12.0, 9.0, 7.0, 11.0, 10.0, 0.0, -6.0, -12.0, 11.0, 6.0, 10.0, 11.0, 7.0, 8.0, -11.0, 9.0, 4.0, 9.0, -7.0, -9.0, 7.0, 5.0, 12.0, 7.0, 3.0, -8.0, 13.0, -4.0, 5.0, 10.0, 4.0, -6.0, 7.0, 8.0, 6.0, 12.0, -6.0, 2.0, 7.0, 8.0, 11.0, 10.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416790288386164, "mean_inference_ms": 1.06146964301511, "mean_action_processing_ms": 0.0708833612464043, "mean_env_wait_ms": 0.17438091846174758, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 831708, "agent_timesteps_total": 831708, "timers": {"sample_time_ms": 0.087, "sample_throughput": 62986435.09, "learn_time_ms": 15.72, "learn_throughput": 350387.838, "update_time_ms": 7.068}, "info": {"learner": {"learned": {"policy_loss": 64088928256.0, "vf_loss": 125.04759216308594, "total_loss": 64088928256.0, "vf_explained_var": -0.0015146732330322266, "model": {}}}, "num_steps_sampled": 831708, "num_agent_steps_sampled": 831708, "num_steps_trained": 831708, "num_agent_steps_trained": 831708}, "done": false, "episodes_total": 16308, "training_iteration": 151, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-25", "timestamp": 1626864505, "time_this_iter_s": 0.34088873863220215, "time_total_s": 54.70277261734009, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829a2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 54.70277261734009, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 72.0, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, 10.0, 4.0, -8.0, 10.0, 6.0, 7.0, -8.0, 9.0, 2.0, 11.0, -7.0, 4.0, -3.0, 10.0, 4.0, 12.0, 5.0, 6.0, -8.0, 13.0, -10.0, 1.0, 11.0, 6.0, 10.0, 12.0, -13.0, 13.0, 3.0, -1.0, 0.0, 6.0, 5.0, -6.0, 10.0, 8.0, 6.0, -7.0, 8.0, 4.0, 5.0, -6.0, 12.0, 5.0, 0.0, -2.0, 12.0, 7.0, 11.0, -10.0, 7.0, 3.0, 8.0, 8.0, -4.0, 13.0, -4.0, 13.0, -7.0, 0.0, 6.0, 11.0, -2.0, 12.0, 4.0, 7.0, -8.0, 12.0, -8.0, 0.0, 11.0, 7.0, -2.0, 6.0, 4.0, 7.0, 13.0, -5.0, 0.0, 11.0, 13.0, -2.0, -7.0, 6.0, 14.0, 11.0, -16.0, 5.0, 11.0, 6.0, -7.0, -6.0, 12.0, -2.0, 11.0, 9.0, 7.0, 11.0, -12.0, 9.0, 10.0, 1.0, -5.0, 9.0, 1.0, 7.0, -2.0, 7.0, -2.0, 11.0, -1.0, 7.0, 6.0, 11.0, -9.0, 10.0, 6.0, 12.0, -13.0, 6.0, 2.0, -5.0, 12.0, 2.0, 10.0, 8.0, -5.0, 10.0, 5.0, 2.0, -2.0, 8.0, -6.0, 2.0, 11.0, 6.0, 7.0, 9.0, -7.0, -2.0, 8.0, 11.0, -2.0, 10.0, 3.0, -7.0, 9.0, 9.0, 9.0, 3.0, -6.0, 9.0, 1.0, -1.0, 6.0, 4.0, 11.0, -1.0, 1.0, 8.0, 2.0, -2.0, 7.0, -5.0, 10.0, 4.0, 6.0, 8.0, 10.0, 12.0, -15.0, 10.0, -10.0, 8.0, 7.0, 12.0, 12.0, 5.0, -14.0, 14.0, 7.0, 2.0, -8.0, 6.0, -8.0, 10.0, 7.0, 2.0, -4.0, 10.0, 7.0, 9.0, 7.0, -2.0, 1.0, 9.0, 6.0, 10.0, -10.0, 12.0, 317.0, 13.0, 13.0, -14.0, 11.0, 10.0, 8.0, 10.0, 3.0, -3.0, 5.0, 5.0, 10.0, 10.0, -10.0, 9.0, 10.0, 6.0, -10.0, -9.0, 2.0, 10.0, 12.0, 8.0, 13.0, 1.0, -7.0, 10.0, 7.0, 1.0, -3.0, 6.0, 11.0, -9.0, 7.0, 0.0, 12.0, 11.0, -8.0, 7.0, 10.0, -4.0, 2.0, 4.0, 10.0, -6.0, 7.0, 7.0, 5.0, 5.0, -2.0, 3.0, -6.0, 11.0, 7.0, 12.0, 3.0, 4.0, -4.0, 12.0, 4.0, 0.0, -1.0, 2.0, -12.0, 13.0, 12.0, -10.0, 10.0, 9.0, 6.0, 7.0, 7.0, -5.0, 6.0, 9.0, -10.0, 4.0, 12.0, 8.0, -12.0, 12.0, 7.0, -2.0, 12.0, -2.0, 7.0, 9.0, 14.0, -9.0, 1.0, 13.0, -3.0, -3.0, 8.0, 2.0, 4.0, -3.0, 12.0, 2.0, 10.0, -2.0, 5.0, 12.0, 10.0, 3.0, -10.0, 7.0, 8.0, 2.0, -2.0, 6.0, 8.0, 8.0, -7.0, 6.0, 10.0, 12.0, -13.0, 13.0, 7.0, -9.0, 4.0, 8.0, -5.0, 11.0, 1.0, 8.0, 1.0, 11.0, -5.0, -4.0, 11.0, -2.0, 10.0, 13.0, 10.0, -8.0, 0.0, 4.0, 9.0, 7.0, -5.0, 9.0, -3.0, -3.0, 12.0, -5.0, 12.0, -2.0, 10.0, 9.0, 6.0, 4.0, -4.0, 14.0, -11.0, 2.0, 10.0, 9.0, 7.0, 6.0, -7.0, -1.0, 11.0, -1.0, 6.0, 9.0, 9.0, 3.0, -6.0, 13.0, 8.0, -3.0, -3.0, 6.0, 9.0, -7.0, 7.0, 6.0, -10.0, 12.0, 7.0, 4.0, 13.0, 6.0, -8.0, 9.0, -2.0, 2.0, 6.0, 9.0, -8.0, 13.0, 1.0, 6.0, 10.0, -7.0, 6.0, 12.0, 11.0, -6.0, -2.0, 8.0, 11.0, -11.0, 7.0, 7.0, -4.0, 5.0, 7.0, 3.0, 5.0, -5.0, 12.0, 12.0, 3.0, 7.0, -7.0, 7.0, 12.0, 1.0, -5.0, 9.0, 2.0, 6.0, -2.0, 9.0, -18.0, 11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416294208603848, "mean_inference_ms": 1.0614033394446207, "mean_action_processing_ms": 0.07087748667120429, "mean_env_wait_ms": 0.17437546818775815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 837216, "agent_timesteps_total": 837216, "timers": {"sample_time_ms": 0.085, "sample_throughput": 64647128.416, "learn_time_ms": 15.485, "learn_throughput": 355691.383, "update_time_ms": 6.603}, "info": {"learner": {"learned": {"policy_loss": 125342810112.0, "vf_loss": 130.6133270263672, "total_loss": 125342810112.0, "vf_explained_var": -0.001447439193725586, "model": {}}}, "num_steps_sampled": 837216, "num_agent_steps_sampled": 837216, "num_steps_trained": 837216, "num_agent_steps_trained": 837216}, "done": false, "episodes_total": 16416, "training_iteration": 152, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-25", "timestamp": 1626864505, "time_this_iter_s": 0.3468189239501953, "time_total_s": 55.04959154129028, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 55.04959154129028, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.14814814814815, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.537037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -8.0, 7.0, 7.0, 4.0, 11.0, -7.0, 7.0, 11.0, 13.0, 5.0, -14.0, -7.0, 11.0, 1.0, 10.0, 13.0, -12.0, 8.0, 6.0, 4.0, 6.0, -5.0, 10.0, 13.0, -5.0, -4.0, 11.0, 7.0, 8.0, 7.0, -7.0, 13.0, 10.0, -19.0, 11.0, -12.0, 4.0, 10.0, 13.0, 7.0, 13.0, -14.0, 9.0, 0.0, 12.0, 8.0, -5.0, 6.0, -12.0, 13.0, 8.0, -14.0, 9.0, 8.0, 12.0, 13.0, 14.0, -9.0, -3.0, 11.0, 8.0, -3.0, -1.0, 5.0, 13.0, -14.0, 11.0, 5.0, 9.0, -8.0, 9.0, 13.0, 2.0, 9.0, -9.0, -3.0, 1.0, 8.0, 9.0, 0.0, 13.0, -11.0, 13.0, 5.0, 8.0, 5.0, -3.0, 4.0, 14.0, -14.0, 11.0, 5.0, -1.0, 5.0, 6.0, 7.0, 10.0, -8.0, 6.0, 13.0, 11.0, -6.0, -3.0, -8.0, 3.0, 9.0, 11.0, -3.0, 8.0, 6.0, 4.0, 8.0, -6.0, 2.0, 11.0, 12.0, 7.0, -13.0, 9.0, 14.0, 6.0, 2.0, -7.0, 8.0, 12.0, -4.0, -1.0, 6.0, 11.0, -8.0, 6.0, 11.0, 12.0, -11.0, 3.0, 7.0, 13.0, -15.0, 10.0, 7.0, 6.0, -4.0, 6.0, 10.0, -5.0, 3.0, 7.0, 7.0, 9.0, -10.0, 9.0, 8.0, -4.0, -1.0, 12.0, 8.0, -10.0, 6.0, 11.0, 13.0, 4.0, -8.0, 6.0, 5.0, 10.0, -12.0, 12.0, 2.0, 14.0, 9.0, -10.0, 10.0, 4.0, -7.0, 8.0, 8.0, 6.0, -6.0, 7.0, 11.0, -16.0, 9.0, 11.0, 13.0, 4.0, -12.0, 10.0, 8.0, 8.0, -9.0, 8.0, 10.0, 8.0, -11.0, 8.0, 3.0, 11.0, -12.0, 13.0, 12.0, 4.0, 8.0, -9.0, 7.0, -1.0, 12.0, -3.0, 8.0, -10.0, 7.0, 10.0, 7.0, 9.0, -5.0, 4.0, 14.0, 321.0, 12.0, 8.0, 11.0, -1.0, -3.0, 8.0, 13.0, 1.0, -12.0, 13.0, 6.0, 10.0, -11.0, 10.0, 6.0, 13.0, -8.0, 4.0, 11.0, 12.0, -9.0, 1.0, 11.0, -15.0, 7.0, 12.0, 8.0, 9.0, 11.0, -13.0, 5.0, 9.0, 9.0, -8.0, 4.0, -1.0, 1.0, 11.0, 9.0, -11.0, 4.0, 13.0, 3.0, -10.0, 11.0, 11.0, 10.0, 13.0, -13.0, 5.0, 7.0, 5.0, -4.0, 7.0, 13.0, 5.0, -13.0, 10.0, 3.0, 10.0, 4.0, -2.0, 9.0, 0.0, -6.0, 12.0, 6.0, 12.0, -11.0, 8.0, 9.0, 4.0, -11.0, 13.0, -4.0, 8.0, 4.0, 7.0, 6.0, 6.0, 11.0, -8.0, 11.0, 1.0, -10.0, 13.0, 10.0, 2.0, -2.0, 5.0, 9.0, 7.0, -12.0, 11.0, 8.0, 13.0, 7.0, -13.0, 12.0, 0.0, 11.0, -8.0, 8.0, 5.0, -6.0, 8.0, 7.0, 13.0, -15.0, 10.0, 9.0, 9.0, -9.0, 6.0, 4.0, 7.0, 7.0, -3.0, 7.0, 11.0, -8.0, 5.0, -3.0, 10.0, 2.0, 6.0, 10.0, -8.0, 0.0, 13.0, 4.0, 9.0, -6.0, 8.0, 8.0, 10.0, -15.0, 12.0, 5.0, 1.0, -3.0, 12.0, 5.0, 9.0, 5.0, -4.0, -3.0, 0.0, 13.0, 5.0, 8.0, 4.0, -8.0, 11.0, 10.0, 11.0, -6.0, 0.0, 6.0, 14.0, -4.0, -1.0, 9.0, 0.0, 8.0, -2.0, 9.0, 8.0, -9.0, 7.0, 12.0, 8.0, -3.0, -2.0, 6.0, 13.0, 6.0, -10.0, 7.0, 3.0, 6.0, -1.0, 4.0, 12.0, -11.0, 10.0, 7.0, -15.0, 12.0, 11.0, 9.0, 14.0, 10.0, -18.0, 13.0, -5.0, 12.0, -5.0, 5.0, 8.0, -9.0, 11.0, 11.0, -9.0, 6.0, 7.0, 5.0, 14.0, 7.0, -11.0, 7.0, 6.0, 13.0, -11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416815008979673, "mean_inference_ms": 1.061298858540153, "mean_action_processing_ms": 0.07087593104776349, "mean_env_wait_ms": 0.17437000032468777, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 842724, "agent_timesteps_total": 842724, "timers": {"sample_time_ms": 0.085, "sample_throughput": 65049330.167, "learn_time_ms": 15.112, "learn_throughput": 364487.888, "update_time_ms": 6.142}, "info": {"learner": {"learned": {"policy_loss": 141237846016.0, "vf_loss": 134.781005859375, "total_loss": 141237846016.0, "vf_explained_var": -0.0018041133880615234, "model": {}}}, "num_steps_sampled": 842724, "num_agent_steps_sampled": 842724, "num_steps_trained": 842724, "num_agent_steps_trained": 842724}, "done": false, "episodes_total": 16524, "training_iteration": 153, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-25", "timestamp": 1626864505, "time_this_iter_s": 0.3461189270019531, "time_total_s": 55.395710468292236, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 55.395710468292236, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 76.5, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 2.0, 13.0, -8.0, 3.0, -7.0, 8.0, 11.0, -4.0, 2.0, 5.0, 12.0, 14.0, 5.0, -2.0, -2.0, -5.0, 0.0, 13.0, 7.0, 11.0, 7.0, 12.0, -15.0, 7.0, -17.0, 13.0, 12.0, 13.0, 11.0, 4.0, -13.0, -8.0, 0.0, 13.0, 10.0, 8.0, -11.0, 12.0, 6.0, 13.0, -14.0, 12.0, 4.0, 7.0, -2.0, -3.0, 13.0, 11.0, -2.0, 11.0, -5.0, 13.0, 11.0, 318.0, 13.0, -8.0, 2.0, 13.0, 8.0, 8.0, -4.0, 7.0, 4.0, -5.0, 0.0, 11.0, 9.0, 8.0, -6.0, 5.0, 8.0, -14.0, 4.0, 13.0, 12.0, 8.0, -2.0, 5.0, 4.0, -9.0, 2.0, 13.0, 9.0, 14.0, 10.0, 317.0, 13.0, -8.0, 3.0, 12.0, 8.0, 8.0, -8.0, 7.0, 8.0, 8.0, -1.0, 11.0, -3.0, 14.0, 10.0, 4.0, -13.0, -2.0, 0.0, 11.0, 6.0, 4.0, -1.0, 9.0, 3.0, 10.0, -1.0, 11.0, -5.0, 6.0, -2.0, 10.0, 1.0, -8.0, 3.0, 13.0, 7.0, 8.0, 7.0, 13.0, -13.0, 6.0, 9.0, 8.0, -8.0, 1.0, 7.0, -4.0, 11.0, 4.0, -12.0, 11.0, 12.0, 8.0, 11.0, 3.0, -7.0, 6.0, 3.0, 11.0, -5.0, 7.0, 10.0, -12.0, 10.0, 6.0, 5.0, 12.0, -8.0, 13.0, 9.0, -13.0, 6.0, -8.0, -1.0, 13.0, 11.0, 5.0, -1.0, 10.0, 1.0, -10.0, 2.0, 11.0, 12.0, 7.0, 7.0, -11.0, 12.0, 7.0, -14.0, 12.0, 10.0, 12.0, 11.0, -1.0, -7.0, 12.0, -8.0, 6.0, 5.0, 6.0, -3.0, 0.0, 12.0, 6.0, 8.0, -9.0, 10.0, 7.0, 12.0, -17.0, 13.0, 6.0, -7.0, 11.0, 5.0, 13.0, 11.0, -9.0, 0.0, 1.0, 8.0, 13.0, -7.0, 6.0, -2.0, -2.0, 13.0, -7.0, 0.0, 10.0, 12.0, 13.0, 10.0, 1.0, -9.0, 7.0, -1.0, -1.0, 10.0, 9.0, 7.0, 9.0, -10.0, -9.0, 4.0, 12.0, 8.0, 8.0, 11.0, 12.0, -16.0, 12.0, 1.0, 11.0, -9.0, 14.0, -6.0, 10.0, -3.0, -11.0, 2.0, 13.0, 11.0, 7.0, -3.0, 6.0, 5.0, 5.0, 0.0, 13.0, -3.0, 5.0, 9.0, 12.0, -11.0, -3.0, -1.0, 12.0, 7.0, 9.0, 9.0, -10.0, 7.0, -15.0, 9.0, 11.0, 10.0, 12.0, 11.0, -8.0, 0.0, 6.0, -10.0, 6.0, 13.0, 8.0, -5.0, 1.0, 11.0, -7.0, -2.0, 13.0, 11.0, 10.0, 11.0, -3.0, -3.0, -9.0, 2.0, 13.0, 9.0, 9.0, 10.0, 8.0, -12.0, 8.0, -3.0, -1.0, 11.0, 12.0, 7.0, 13.0, -17.0, 9.0, -7.0, 6.0, 7.0, 7.0, -5.0, 1.0, 12.0, 3.0, 4.0, 13.0, -5.0, 13.0, 5.0, 12.0, -15.0, 10.0, -8.0, 9.0, 4.0, 13.0, -5.0, 6.0, 1.0, -2.0, -3.0, 11.0, 9.0, 8.0, 7.0, 2.0, -2.0, -14.0, 12.0, 6.0, 11.0, 14.0, 7.0, -6.0, 0.0, 9.0, 3.0, 11.0, -8.0, 5.0, -2.0, -1.0, 13.0, 11.0, -17.0, 13.0, 8.0, 12.0, -5.0, 8.0, 0.0, 2.0, 3.0, 13.0, -3.0, 7.0, 10.0, -14.0, 12.0, -8.0, 6.0, 5.0, 12.0, 8.0, -4.0, 13.0, -2.0, 8.0, 3.0, 12.0, -8.0, 14.0, 12.0, -11.0, 0.0, 7.0, -9.0, 12.0, 5.0, 6.0, 11.0, -1.0, -1.0, 11.0, 2.0, 8.0, -6.0, 3.0, -10.0, 12.0, 10.0, 10.0, 3.0, -6.0, 8.0, 8.0, 8.0, 8.0, -9.0, -10.0, 2.0, 13.0, 10.0, 8.0, 2.0, -3.0, 8.0, -4.0, 3.0, 13.0, 3.0, 8.0, 7.0, 9.0, -9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18415368539441607, "mean_inference_ms": 1.0612966486300948, "mean_action_processing_ms": 0.07087228789660195, "mean_env_wait_ms": 0.17436143555156344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 848232, "agent_timesteps_total": 848232, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65396259.911, "learn_time_ms": 14.744, "learn_throughput": 373582.447, "update_time_ms": 5.746}, "info": {"learner": {"learned": {"policy_loss": 191129649152.0, "vf_loss": 233.7324981689453, "total_loss": 191129649152.0, "vf_explained_var": -0.00047135353088378906, "model": {}}}, "num_steps_sampled": 848232, "num_agent_steps_sampled": 848232, "num_steps_trained": 848232, "num_agent_steps_trained": 848232}, "done": false, "episodes_total": 16632, "training_iteration": 154, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-26", "timestamp": 1626864506, "time_this_iter_s": 0.34886956214904785, "time_total_s": 55.744580030441284, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a183469d8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 55.744580030441284, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.15740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -16.0}, "policy_reward_max": {"learned": 320.0}, "policy_reward_mean": {"learned": 4.539351851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [4.0, 11.0, -9.0, 9.0, 9.0, 10.0, 2.0, -6.0, 9.0, -6.0, 11.0, 1.0, -4.0, 11.0, -2.0, 10.0, 0.0, 10.0, 11.0, -6.0, 5.0, 5.0, 11.0, -6.0, 11.0, -2.0, -6.0, 12.0, 0.0, 11.0, -5.0, 9.0, -2.0, 12.0, 7.0, -2.0, 1.0, -1.0, 5.0, 10.0, 12.0, 2.0, 12.0, -11.0, 11.0, 4.0, -12.0, 12.0, -15.0, 12.0, 10.0, 8.0, 12.0, -1.0, -6.0, 10.0, -3.0, 8.0, 11.0, -1.0, 13.0, -9.0, 10.0, 1.0, 0.0, 13.0, 6.0, -4.0, 13.0, 9.0, -4.0, -3.0, 14.0, -7.0, 11.0, -3.0, -1.0, 10.0, 0.0, 6.0, -14.0, 10.0, 10.0, 9.0, 13.0, -9.0, 3.0, 8.0, 12.0, 3.0, 11.0, -11.0, 14.0, 6.0, 9.0, -14.0, 6.0, 8.0, 6.0, -5.0, 11.0, 14.0, -2.0, -8.0, 6.0, 2.0, 9.0, -2.0, 13.0, -1.0, 5.0, -2.0, -2.0, -1.0, 6.0, 12.0, 11.0, 11.0, -12.0, 5.0, 9.0, -7.0, 11.0, 2.0, 14.0, 7.0, 3.0, -9.0, 1.0, 12.0, -5.0, 7.0, 1.0, 7.0, -4.0, 11.0, 13.0, -3.0, -7.0, 12.0, 10.0, -8.0, 13.0, 0.0, -13.0, 11.0, 5.0, 12.0, 13.0, -3.0, 5.0, 0.0, 13.0, -9.0, 12.0, -1.0, 14.0, 8.0, -11.0, 4.0, 0.0, -1.0, 11.0, 5.0, 14.0, 9.0, 3.0, -11.0, -1.0, 5.0, 12.0, -1.0, -3.0, 5.0, 3.0, 10.0, -14.0, 13.0, 10.0, 6.0, 4.0, 12.0, 12.0, -13.0, 14.0, -8.0, -3.0, 12.0, 13.0, 10.0, -6.0, -2.0, 7.0, -2.0, 6.0, 4.0, 14.0, 9.0, 7.0, -15.0, 13.0, -1.0, 10.0, -7.0, 13.0, 5.0, -1.0, -2.0, -6.0, 13.0, 13.0, -5.0, 10.0, -6.0, 9.0, 2.0, 4.0, -2.0, 1.0, 12.0, -1.0, 11.0, -4.0, 9.0, -1.0, 9.0, -4.0, 11.0, 10.0, -8.0, 6.0, 7.0, 6.0, -12.0, 10.0, 11.0, 14.0, 11.0, 11.0, 320.0, -2.0, -2.0, 10.0, 9.0, 13.0, 11.0, 1.0, -10.0, 10.0, -13.0, 11.0, 7.0, -13.0, 12.0, 3.0, 13.0, -5.0, 11.0, 13.0, -4.0, 13.0, -3.0, 11.0, -6.0, 7.0, 13.0, 5.0, -10.0, 13.0, -4.0, -5.0, 11.0, 1.0, 10.0, 7.0, -3.0, 14.0, 14.0, -2.0, -11.0, 9.0, -6.0, 7.0, 5.0, -1.0, 9.0, -3.0, 10.0, 0.0, 9.0, 9.0, -3.0, 2.0, 13.0, -8.0, 8.0, 8.0, 8.0, -5.0, 4.0, 12.0, 9.0, -2.0, -4.0, 2.0, 7.0, -4.0, 10.0, 13.0, -2.0, 2.0, 2.0, 8.0, -8.0, 12.0, 3.0, -7.0, 10.0, 10.0, 2.0, -3.0, 12.0, -7.0, 13.0, 12.0, -6.0, 10.0, -1.0, 10.0, 8.0, 11.0, -14.0, 0.0, 3.0, 11.0, 1.0, -2.0, 9.0, -3.0, 11.0, 13.0, -3.0, -2.0, 7.0, 6.0, 0.0, 11.0, -2.0, 0.0, 5.0, 12.0, -2.0, -3.0, 12.0, 8.0, -2.0, -7.0, 12.0, 9.0, 1.0, 14.0, -12.0, 11.0, 2.0, 14.0, -6.0, 1.0, 6.0, -5.0, 13.0, 10.0, -3.0, 10.0, -6.0, 6.0, 5.0, 9.0, 2.0, 11.0, -7.0, 12.0, 11.0, -6.0, -2.0, -15.0, 8.0, 10.0, 12.0, 7.0, 9.0, 7.0, -8.0, -6.0, 3.0, 11.0, 7.0, -1.0, 10.0, 11.0, -5.0, 2.0, 13.0, -7.0, 7.0, 1.0, 12.0, 5.0, -3.0, 9.0, -10.0, 10.0, 6.0, -2.0, 10.0, -4.0, 11.0, -2.0, 13.0, -4.0, 8.0, -5.0, 13.0, 4.0, 3.0, 14.0, -16.0, 7.0, 10.0, 0.0, 9.0, 7.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416484074946418, "mean_inference_ms": 1.0612892999022814, "mean_action_processing_ms": 0.07087343461679951, "mean_env_wait_ms": 0.1743707483197343, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 853740, "agent_timesteps_total": 853740, "timers": {"sample_time_ms": 0.082, "sample_throughput": 66997926.071, "learn_time_ms": 14.47, "learn_throughput": 380651.996, "update_time_ms": 5.375}, "info": {"learner": {"learned": {"policy_loss": 1.2987152338027954, "vf_loss": 17.813034057617188, "total_loss": 19.11174964904785, "vf_explained_var": -0.011246323585510254, "model": {}}}, "num_steps_sampled": 853740, "num_agent_steps_sampled": 853740, "num_steps_trained": 853740, "num_agent_steps_trained": 853740}, "done": false, "episodes_total": 16740, "training_iteration": 155, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-26", "timestamp": 1626864506, "time_this_iter_s": 0.3464846611022949, "time_total_s": 56.09106469154358, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7d90>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 56.09106469154358, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 78.0, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 357.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.166666666666668, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 4.541666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 357.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -1.0, 13.0, -4.0, 8.0, 1.0, -5.0, 11.0, 13.0, -1.0, -10.0, 13.0, -4.0, 14.0, -7.0, 12.0, 12.0, -4.0, 12.0, -5.0, 6.0, 2.0, 13.0, -6.0, 12.0, -1.0, -3.0, 7.0, 6.0, -1.0, 0.0, 10.0, 13.0, -7.0, 10.0, -1.0, 13.0, -2.0, -1.0, 5.0, 11.0, 11.0, 11.0, -18.0, -2.0, 0.0, 6.0, 11.0, -10.0, 13.0, 7.0, 5.0, 5.0, 12.0, -1.0, -1.0, 11.0, 13.0, -3.0, -6.0, -3.0, 13.0, -2.0, 7.0, 11.0, -3.0, 12.0, -5.0, 10.0, 2.0, -1.0, 4.0, 12.0, -1.0, 11.0, -7.0, -3.0, 13.0, -1.0, 6.0, 6.0, 8.0, 11.0, -10.0, 5.0, 2.0, -1.0, 9.0, 12.0, -8.0, 12.0, -1.0, -11.0, 14.0, 10.0, 2.0, 12.0, -1.0, 12.0, -8.0, -9.0, 7.0, 12.0, 5.0, 13.0, 12.0, -2.0, -8.0, -13.0, 14.0, 10.0, 4.0, 13.0, -3.0, 11.0, -6.0, 3.0, 5.0, -1.0, 8.0, 9.0, 4.0, 7.0, -5.0, 6.0, -7.0, 13.0, 3.0, 4.0, 8.0, 10.0, -7.0, -4.0, 12.0, 13.0, -6.0, 11.0, 0.0, 12.0, -8.0, -6.0, 9.0, 1.0, 11.0, 12.0, -3.0, 10.0, -4.0, -11.0, 6.0, 11.0, 9.0, 13.0, -9.0, 12.0, -1.0, 5.0, -3.0, 12.0, 1.0, 3.0, 5.0, -6.0, 13.0, 4.0, 8.0, 9.0, -6.0, 12.0, 12.0, -2.0, -7.0, 3.0, 13.0, 6.0, -7.0, 4.0, 4.0, 11.0, -4.0, -2.0, 5.0, 12.0, 0.0, 11.0, -20.0, 12.0, 12.0, -13.0, 14.0, 7.0, 7.0, 6.0, 8.0, 10.0, -9.0, 9.0, 5.0, 9.0, -8.0, 12.0, -6.0, 12.0, -3.0, -2.0, 14.0, -1.0, 4.0, 12.0, -19.0, 12.0, 10.0, 3.0, 2.0, 13.0, -3.0, 12.0, 14.0, -2.0, -9.0, -14.0, 14.0, 10.0, 5.0, 13.0, -5.0, 13.0, -6.0, 13.0, 0.0, -1.0, 3.0, 11.0, -17.0, 11.0, 10.0, 1.0, -5.0, 8.0, 11.0, 8.0, -7.0, 9.0, 5.0, -6.0, -1.0, 13.0, 9.0, 4.0, 12.0, 8.0, -9.0, -9.0, 7.0, 12.0, 5.0, 4.0, 6.0, 11.0, -6.0, 7.0, 6.0, -1.0, 3.0, 12.0, 10.0, -15.0, 8.0, -14.0, 10.0, 12.0, 7.0, 9.0, 8.0, 11.0, -13.0, 12.0, 1.0, 13.0, -11.0, 10.0, 12.0, 5.0, -12.0, 2.0, 10.0, -4.0, 7.0, 12.0, 2.0, 10.0, -9.0, 10.0, -1.0, 13.0, -7.0, 7.0, 14.0, -10.0, 4.0, 4.0, 14.0, -8.0, 5.0, 4.0, 7.0, 12.0, -8.0, 12.0, 2.0, -4.0, 5.0, 12.0, -1.0, 7.0, -3.0, 321.0, 14.0, 10.0, 12.0, 9.0, -1.0, -4.0, 11.0, 5.0, 11.0, 13.0, -14.0, 8.0, 12.0, -3.0, -2.0, -6.0, 0.0, 11.0, 10.0, 13.0, -4.0, 12.0, -6.0, -6.0, 7.0, 12.0, 2.0, 5.0, 11.0, 12.0, -13.0, -15.0, 14.0, 5.0, 11.0, 2.0, 13.0, 11.0, -11.0, 3.0, 3.0, 12.0, -3.0, 6.0, 4.0, 12.0, -7.0, 3.0, -1.0, 13.0, 0.0, 7.0, 7.0, -9.0, 10.0, 4.0, 5.0, -5.0, 11.0, 6.0, 14.0, 5.0, -10.0, -12.0, 14.0, 10.0, 3.0, 10.0, -2.0, 11.0, -4.0, 12.0, 11.0, -1.0, -7.0, 8.0, 4.0, 12.0, -9.0, -2.0, 13.0, -6.0, 10.0, 10.0, -16.0, 12.0, 9.0, 13.0, 0.0, -4.0, 6.0, 12.0, -2.0, 7.0, -2.0, -10.0, 13.0, 11.0, 1.0, 13.0, 3.0, 7.0, -8.0, 8.0, 7.0, -1.0, 1.0, 4.0, 8.0, 12.0, -9.0, -13.0, 14.0, 4.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418366927547877, "mean_inference_ms": 1.0613742197525136, "mean_action_processing_ms": 0.0708697848072925, "mean_env_wait_ms": 0.1743805704324643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 859248, "agent_timesteps_total": 859248, "timers": {"sample_time_ms": 0.086, "sample_throughput": 64265762.413, "learn_time_ms": 13.827, "learn_throughput": 398355.458, "update_time_ms": 5.313}, "info": {"learner": {"learned": {"policy_loss": 81372946432.0, "vf_loss": 127.92169189453125, "total_loss": 81372946432.0, "vf_explained_var": -0.0009948015213012695, "model": {}}}, "num_steps_sampled": 859248, "num_agent_steps_sampled": 859248, "num_steps_trained": 859248, "num_agent_steps_trained": 859248}, "done": false, "episodes_total": 16848, "training_iteration": 156, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-27", "timestamp": 1626864507, "time_this_iter_s": 0.3484678268432617, "time_total_s": 56.43953251838684, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 56.43953251838684, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 84.1, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [9.0, -9.0, 2.0, 13.0, 2.0, 13.0, 12.0, -12.0, 12.0, 11.0, 5.0, -13.0, 13.0, 8.0, -17.0, 11.0, 13.0, 3.0, -14.0, 13.0, 12.0, 13.0, -18.0, 8.0, -3.0, 7.0, 11.0, 0.0, -1.0, 14.0, 12.0, -10.0, 14.0, 7.0, -19.0, 13.0, 9.0, 14.0, -15.0, 7.0, -4.0, 7.0, 7.0, 5.0, 11.0, 13.0, -19.0, 10.0, 9.0, 2.0, -6.0, 10.0, 10.0, 4.0, 9.0, -8.0, -1.0, 7.0, 6.0, 3.0, -19.0, 12.0, 11.0, 11.0, 13.0, 2.0, -8.0, 8.0, -3.0, 14.0, -8.0, 12.0, -1.0, 13.0, -6.0, 9.0, 6.0, 8.0, 11.0, -10.0, 13.0, 5.0, -15.0, 12.0, 5.0, 14.0, -13.0, 9.0, 9.0, 8.0, 6.0, -8.0, 5.0, 7.0, 6.0, -3.0, 14.0, -8.0, -4.0, 13.0, 8.0, 14.0, -16.0, 9.0, 7.0, 12.0, 7.0, -11.0, 5.0, 9.0, 12.0, -11.0, 7.0, 6.0, -11.0, 13.0, -16.0, 14.0, 13.0, 4.0, 6.0, 10.0, -5.0, 4.0, 5.0, 10.0, -12.0, 12.0, 14.0, 11.0, -15.0, 5.0, 11.0, 13.0, 1.0, -10.0, 12.0, 5.0, 10.0, -12.0, -7.0, 12.0, 11.0, -1.0, 13.0, -2.0, -9.0, 13.0, -3.0, 12.0, -7.0, 13.0, -4.0, 8.0, 7.0, 4.0, 6.0, 14.0, -15.0, 10.0, 13.0, -17.0, 6.0, 13.0, -6.0, 9.0, 6.0, 6.0, 10.0, 12.0, 8.0, -15.0, -4.0, 14.0, -7.0, 12.0, 12.0, 4.0, -13.0, 12.0, -8.0, 13.0, 1.0, 9.0, 13.0, 7.0, 7.0, -12.0, 4.0, 13.0, 5.0, -7.0, 11.0, -9.0, 4.0, 9.0, 5.0, 9.0, 12.0, -11.0, -1.0, 7.0, 7.0, 2.0, -11.0, 9.0, 4.0, 13.0, 14.0, -2.0, -9.0, 12.0, 7.0, 10.0, 11.0, -13.0, -4.0, 12.0, 10.0, -3.0, 6.0, 13.0, 11.0, -15.0, 14.0, 6.0, 1.0, -6.0, -3.0, 13.0, 13.0, -8.0, 7.0, 10.0, -12.0, 10.0, 10.0, 1.0, 10.0, -6.0, 11.0, 1.0, -10.0, 13.0, -12.0, 9.0, 13.0, 5.0, 12.0, 8.0, -13.0, 8.0, 12.0, 6.0, -15.0, 12.0, 7.0, -14.0, 10.0, 12.0, -19.0, 13.0, 12.0, 9.0, -11.0, 13.0, 7.0, 6.0, 12.0, 7.0, -12.0, 8.0, 13.0, -7.0, -4.0, 13.0, -5.0, 13.0, 13.0, -6.0, 5.0, 13.0, 7.0, -10.0, 3.0, 14.0, -1.0, -1.0, 13.0, -5.0, -6.0, 13.0, 12.0, -6.0, -1.0, 10.0, -1.0, 7.0, 9.0, 0.0, -16.0, 14.0, 12.0, 5.0, 13.0, 3.0, -13.0, 12.0, 10.0, 13.0, -10.0, 2.0, 0.0, 13.0, -6.0, 8.0, 4.0, 9.0, -9.0, 11.0, 14.0, -6.0, -3.0, 10.0, 4.0, 13.0, 9.0, -11.0, -1.0, 7.0, 11.0, -2.0, 5.0, 11.0, -10.0, 9.0, 14.0, 9.0, 2.0, -10.0, -2.0, 9.0, -5.0, 13.0, 11.0, 7.0, 9.0, -12.0, 3.0, 9.0, 6.0, -3.0, 9.0, -13.0, 6.0, 13.0, 4.0, 9.0, 13.0, -11.0, 13.0, 8.0, -4.0, -2.0, -13.0, 8.0, 10.0, 10.0, 14.0, -1.0, -10.0, 12.0, -5.0, 10.0, 4.0, 6.0, -6.0, 12.0, 8.0, 1.0, 7.0, 12.0, -14.0, 10.0, 14.0, 3.0, -15.0, 13.0, 9.0, 9.0, 13.0, -16.0, 11.0, 6.0, -8.0, 6.0, 4.0, 14.0, 12.0, -15.0, 12.0, -11.0, 5.0, 9.0, 5.0, 11.0, -13.0, 12.0, 12.0, 7.0, 11.0, -15.0, -2.0, 13.0, -1.0, 5.0, 14.0, -3.0, -4.0, 8.0, 318.0, 13.0, 13.0, 10.0, -2.0, 13.0, 9.0, -5.0, 2.0, 13.0, 6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418239863146915, "mean_inference_ms": 1.0613133510884296, "mean_action_processing_ms": 0.07086984385735638, "mean_env_wait_ms": 0.17437203719995917, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 864756, "agent_timesteps_total": 864756, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65628931.929, "learn_time_ms": 13.437, "learn_throughput": 409902.474, "update_time_ms": 5.403}, "info": {"learner": {"learned": {"policy_loss": 216661868544.0, "vf_loss": 229.57460021972656, "total_loss": 216661868544.0, "vf_explained_var": -0.00037300586700439453, "model": {}}}, "num_steps_sampled": 864756, "num_agent_steps_sampled": 864756, "num_steps_trained": 864756, "num_agent_steps_trained": 864756}, "done": false, "episodes_total": 16956, "training_iteration": 157, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-27", "timestamp": 1626864507, "time_this_iter_s": 0.35251855850219727, "time_total_s": 56.79205107688904, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18210400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 56.79205107688904, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-11.0, 4.0, 13.0, 9.0, 10.0, 0.0, 2.0, 3.0, 6.0, 6.0, -4.0, 7.0, 8.0, -3.0, 9.0, 1.0, 11.0, -5.0, -3.0, 12.0, 9.0, -1.0, 2.0, 5.0, 13.0, 9.0, 7.0, -14.0, 6.0, 9.0, -1.0, 1.0, -4.0, 0.0, 11.0, 8.0, -8.0, 11.0, 4.0, 8.0, 9.0, 1.0, 12.0, -7.0, 12.0, 5.0, -7.0, 5.0, -9.0, 8.0, 9.0, 7.0, -7.0, 14.0, 12.0, -4.0, 14.0, 7.0, 12.0, -18.0, 7.0, 9.0, 9.0, -10.0, 10.0, 7.0, -10.0, 8.0, 9.0, 0.0, 10.0, -4.0, 13.0, 2.0, -1.0, 1.0, 2.0, 13.0, 13.0, -13.0, 2.0, 11.0, 8.0, -6.0, 9.0, 14.0, -7.0, -1.0, 13.0, -9.0, 7.0, 4.0, 8.0, 10.0, -4.0, 1.0, -2.0, -4.0, 11.0, 10.0, -6.0, 14.0, 5.0, 2.0, 13.0, 8.0, 6.0, -12.0, 2.0, 7.0, 9.0, -3.0, -2.0, -7.0, 12.0, 12.0, 5.0, 14.0, 3.0, -7.0, 8.0, 7.0, -8.0, 8.0, 8.0, -4.0, -2.0, 13.0, -7.0, 8.0, 2.0, 12.0, 6.0, 7.0, -10.0, 12.0, 12.0, -6.0, 5.0, 4.0, 7.0, 9.0, -7.0, 6.0, 6.0, 11.0, -14.0, 12.0, 3.0, 0.0, -1.0, 13.0, 10.0, -10.0, 12.0, 3.0, 2.0, 12.0, 8.0, -7.0, 4.0, 13.0, -8.0, 6.0, -5.0, 11.0, 4.0, 5.0, 8.0, 0.0, -1.0, 8.0, 5.0, 12.0, -12.0, 10.0, -1.0, 6.0, 11.0, -1.0, 11.0, 14.0, -15.0, 5.0, 5.0, 2.0, -5.0, 13.0, 9.0, 10.0, -16.0, 12.0, -3.0, -4.0, 11.0, 11.0, -5.0, 6.0, 8.0, 6.0, -4.0, 4.0, 7.0, 8.0, 8.0, 0.0, -4.0, 11.0, 1.0, 8.0, -3.0, 9.0, 3.0, 0.0, 0.0, 12.0, 13.0, 3.0, -6.0, 5.0, 9.0, 12.0, -2.0, -4.0, 10.0, 6.0, -8.0, 7.0, 11.0, -1.0, 7.0, -2.0, -14.0, 10.0, 11.0, 8.0, 0.0, 13.0, -4.0, 6.0, -15.0, 12.0, 7.0, 11.0, 10.0, 13.0, 3.0, -11.0, 11.0, 6.0, 9.0, -11.0, 12.0, 8.0, -5.0, 0.0, -6.0, 6.0, 10.0, 5.0, 11.0, -3.0, 9.0, -2.0, 11.0, 9.0, -8.0, 3.0, -9.0, 13.0, 6.0, 5.0, 5.0, 7.0, -3.0, 6.0, -6.0, 14.0, 7.0, 0.0, 5.0, 5.0, -8.0, 13.0, 10.0, 12.0, 2.0, -9.0, -12.0, 11.0, 8.0, 8.0, 6.0, 0.0, 2.0, 7.0, 12.0, 7.0, -6.0, 2.0, 8.0, 13.0, -18.0, 12.0, -17.0, 12.0, 11.0, 9.0, 3.0, -3.0, 8.0, 7.0, -3.0, 10.0, 8.0, 0.0, -4.0, 7.0, 9.0, 3.0, -3.0, 6.0, 9.0, 3.0, 10.0, 13.0, -3.0, -5.0, -2.0, 10.0, 10.0, -3.0, 8.0, 9.0, -2.0, 0.0, 9.0, 8.0, 8.0, -10.0, -6.0, 11.0, 3.0, 7.0, 12.0, 8.0, 12.0, -17.0, 5.0, -12.0, 12.0, 10.0, -3.0, -8.0, 13.0, 13.0, 10.0, -2.0, 6.0, 1.0, 12.0, 8.0, 1.0, -6.0, 6.0, 13.0, -16.0, 12.0, -2.0, -6.0, 12.0, 11.0, 11.0, 5.0, -8.0, 7.0, 11.0, -6.0, 7.0, 3.0, 8.0, 13.0, -13.0, 7.0, -11.0, 12.0, 2.0, 12.0, -11.0, 13.0, 7.0, 6.0, -6.0, 7.0, 11.0, 3.0, 2.0, 13.0, -2.0, 2.0, -12.0, 8.0, 8.0, 11.0, 9.0, -4.0, 5.0, 5.0, 13.0, 8.0, 6.0, -12.0, 6.0, 12.0, 13.0, -16.0, -8.0, 7.0, 5.0, 11.0, -13.0, 11.0, 11.0, 6.0, 11.0, 9.0, -6.0, 1.0, 8.0, 13.0, -15.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418508022361835, "mean_inference_ms": 1.061227050408832, "mean_action_processing_ms": 0.0708700651618375, "mean_env_wait_ms": 0.17435835071788316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 870264, "agent_timesteps_total": 870264, "timers": {"sample_time_ms": 0.081, "sample_throughput": 68039899.978, "learn_time_ms": 13.16, "learn_throughput": 418536.792, "update_time_ms": 5.24}, "info": {"learner": {"learned": {"policy_loss": 79828541440.0, "vf_loss": 136.22352600097656, "total_loss": 79828541440.0, "vf_explained_var": -0.001226663589477539, "model": {}}}, "num_steps_sampled": 870264, "num_agent_steps_sampled": 870264, "num_steps_trained": 870264, "num_agent_steps_trained": 870264}, "done": false, "episodes_total": 17064, "training_iteration": 158, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-27", "timestamp": 1626864507, "time_this_iter_s": 0.3596975803375244, "time_total_s": 57.15174865722656, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a78c8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 57.15174865722656, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 74.5, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, 5.0, -13.0, 13.0, -9.0, 8.0, 7.0, 9.0, 4.0, -6.0, 8.0, 9.0, 5.0, 14.0, 12.0, -16.0, -3.0, 11.0, -3.0, 10.0, -11.0, 2.0, 13.0, 11.0, 7.0, 12.0, -6.0, 2.0, -1.0, 7.0, 2.0, 7.0, 8.0, 12.0, -12.0, 7.0, -13.0, 7.0, 10.0, 11.0, -9.0, 14.0, 7.0, 3.0, 7.0, 9.0, 10.0, -11.0, 3.0, -5.0, 8.0, 9.0, 12.0, 4.0, -6.0, 5.0, 2.0, 14.0, -12.0, 11.0, 7.0, 10.0, 5.0, -7.0, 3.0, -6.0, 9.0, 9.0, -17.0, 12.0, 13.0, 7.0, 0.0, -8.0, 11.0, 12.0, -8.0, 14.0, -3.0, 12.0, 9.0, 3.0, -6.0, 9.0, -16.0, 10.0, 9.0, 12.0, -1.0, 12.0, -6.0, 10.0, 7.0, 4.0, 7.0, -3.0, 0.0, 10.0, -4.0, 9.0, 8.0, 4.0, -4.0, 7.0, -1.0, 13.0, -3.0, 6.0, 13.0, 8.0, 9.0, -15.0, 6.0, -11.0, 11.0, 9.0, 2.0, 4.0, -2.0, 11.0, 3.0, 13.0, 6.0, -7.0, 9.0, 14.0, -9.0, 1.0, 5.0, -9.0, 6.0, 13.0, -10.0, 9.0, 8.0, 8.0, -11.0, 14.0, 9.0, 3.0, 12.0, 10.0, -10.0, 3.0, 2.0, 6.0, -6.0, 13.0, 10.0, -13.0, 10.0, 8.0, 7.0, 2.0, -3.0, 9.0, 3.0, 9.0, -8.0, 11.0, 11.0, -1.0, -7.0, 12.0, 7.0, 3.0, 6.0, -1.0, 8.0, 14.0, 7.0, -14.0, 11.0, 14.0, 6.0, -16.0, 5.0, -3.0, 0.0, 13.0, -2.0, 9.0, 1.0, 7.0, -3.0, 13.0, -3.0, 8.0, 7.0, 14.0, 10.0, -16.0, 1.0, -4.0, 6.0, 12.0, 8.0, 14.0, -12.0, 5.0, -9.0, 8.0, 8.0, 8.0, 7.0, 9.0, 9.0, -10.0, 1.0, -9.0, 10.0, 13.0, -7.0, -2.0, 13.0, 11.0, 6.0, 7.0, 11.0, -9.0, 7.0, 14.0, -14.0, 8.0, 4.0, 6.0, -8.0, 13.0, 10.0, 10.0, 4.0, -9.0, -3.0, 14.0, -2.0, 6.0, -2.0, 5.0, 8.0, 4.0, 4.0, -6.0, 5.0, 12.0, -4.0, 10.0, 6.0, 3.0, 12.0, 14.0, 5.0, -16.0, 11.0, 10.0, 0.0, -6.0, -12.0, 6.0, 8.0, 13.0, -16.0, 12.0, 11.0, 8.0, 3.0, 13.0, -12.0, 11.0, 10.0, 9.0, -3.0, -1.0, 5.0, 9.0, -12.0, 13.0, 11.0, -7.0, 7.0, 4.0, 4.0, 7.0, -6.0, 10.0, 11.0, 8.0, -10.0, 6.0, 4.0, 9.0, -6.0, 8.0, -3.0, 11.0, 9.0, -2.0, -18.0, 11.0, 10.0, 12.0, -4.0, 10.0, 6.0, 3.0, 5.0, 8.0, -11.0, 13.0, 12.0, 0.0, -7.0, 10.0, -3.0, 13.0, 10.0, -5.0, -8.0, 9.0, 7.0, 7.0, 3.0, -11.0, 11.0, 12.0, -14.0, 8.0, 10.0, 11.0, -7.0, 14.0, -2.0, 10.0, 13.0, 4.0, 8.0, -10.0, 7.0, 3.0, -8.0, 13.0, -13.0, 8.0, 7.0, 13.0, -9.0, 8.0, 7.0, 9.0, 10.0, 10.0, 7.0, -12.0, 0.0, 12.0, -10.0, 13.0, 5.0, 3.0, 8.0, -1.0, 3.0, 10.0, 12.0, -10.0, 12.0, 5.0, -4.0, 2.0, 6.0, 11.0, -14.0, 12.0, -4.0, 13.0, 7.0, -1.0, -10.0, 8.0, 9.0, 8.0, 5.0, 14.0, 11.0, -15.0, -1.0, 5.0, -2.0, 13.0, 1.0, -9.0, 10.0, 13.0, 1.0, 12.0, -8.0, 10.0, 4.0, 8.0, 10.0, -7.0, -1.0, -8.0, 11.0, 13.0, 4.0, 5.0, 11.0, -5.0, 3.0, 14.0, 9.0, -11.0, 12.0, 8.0, -12.0, 7.0, -7.0, 11.0, -2.0, 13.0, -10.0, 2.0, 11.0, 12.0, -2.0, 13.0, 7.0, -3.0, -4.0, 9.0, 11.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18419566031775128, "mean_inference_ms": 1.0612337048988503, "mean_action_processing_ms": 0.0708690082861275, "mean_env_wait_ms": 0.17435686513307103, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 875772, "agent_timesteps_total": 875772, "timers": {"sample_time_ms": 0.08, "sample_throughput": 68956192.528, "learn_time_ms": 12.681, "learn_throughput": 434334.835, "update_time_ms": 5.152}, "info": {"learner": {"learned": {"policy_loss": 1.1652758121490479, "vf_loss": 16.096481323242188, "total_loss": 17.261756896972656, "vf_explained_var": -0.012513875961303711, "model": {}}}, "num_steps_sampled": 875772, "num_agent_steps_sampled": 875772, "num_steps_trained": 875772, "num_agent_steps_trained": 875772}, "done": false, "episodes_total": 17172, "training_iteration": 159, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-28", "timestamp": 1626864508, "time_this_iter_s": 0.36070919036865234, "time_total_s": 57.512457847595215, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7f28>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 57.512457847595215, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 7.0, 7.0, -6.0, 2.0, -8.0, 10.0, 11.0, 0.0, 7.0, 5.0, 3.0, -3.0, 7.0, 4.0, 7.0, -2.0, -3.0, 8.0, 12.0, -9.0, 3.0, 12.0, 9.0, 12.0, -9.0, 2.0, 10.0, -5.0, 9.0, 11.0, 0.0, 8.0, -8.0, 4.0, 11.0, 7.0, -10.0, 11.0, 7.0, 13.0, 7.0, -4.0, -1.0, -2.0, 10.0, 5.0, 2.0, 12.0, -17.0, 7.0, 13.0, 6.0, -11.0, 13.0, 7.0, 12.0, -2.0, 4.0, 1.0, 11.0, 11.0, -13.0, 6.0, -7.0, 4.0, 9.0, 9.0, 5.0, -7.0, 12.0, 5.0, 12.0, 1.0, 12.0, -10.0, 6.0, -3.0, 10.0, 2.0, -6.0, 11.0, 5.0, 5.0, -8.0, 2.0, 9.0, 12.0, 5.0, -12.0, 11.0, 11.0, 2.0, 11.0, -2.0, 4.0, -10.0, 13.0, 6.0, 6.0, -5.0, 6.0, 13.0, 1.0, 8.0, 7.0, 3.0, -3.0, -5.0, 10.0, 11.0, -1.0, -2.0, -1.0, 6.0, 12.0, -9.0, 2.0, 13.0, 9.0, 12.0, -11.0, 12.0, 2.0, 12.0, 11.0, -12.0, 4.0, 5.0, 10.0, -1.0, 1.0, -2.0, 4.0, 11.0, 2.0, 11.0, 12.0, -9.0, 1.0, 11.0, 7.0, -15.0, 12.0, -2.0, -4.0, 9.0, 12.0, -10.0, 3.0, 13.0, 9.0, 14.0, 14.0, -15.0, 2.0, -1.0, 11.0, 2.0, 3.0, 13.0, -13.0, 7.0, 8.0, -5.0, -1.0, 13.0, 8.0, -6.0, 8.0, 3.0, 10.0, 9.0, -5.0, 8.0, 3.0, 3.0, 13.0, -2.0, 1.0, -10.0, 3.0, 12.0, 10.0, 12.0, 9.0, 1.0, -7.0, -1.0, 7.0, -4.0, 13.0, 7.0, -1.0, -1.0, 10.0, -13.0, 4.0, 12.0, 12.0, 14.0, 3.0, 7.0, -9.0, -3.0, 1.0, 11.0, 6.0, -12.0, 12.0, 2.0, 13.0, -9.0, 2.0, 13.0, 9.0, 14.0, -12.0, 10.0, 3.0, 10.0, 4.0, -3.0, 4.0, -6.0, 8.0, 1.0, 12.0, -7.0, 2.0, 12.0, 8.0, 12.0, 12.0, 6.0, -15.0, 11.0, 6.0, -15.0, 13.0, -4.0, 12.0, 4.0, 3.0, 3.0, -8.0, 13.0, 7.0, 11.0, -12.0, 12.0, 4.0, 12.0, 0.0, -2.0, 5.0, 11.0, -7.0, 8.0, 3.0, 2.0, -6.0, 7.0, 12.0, 10.0, 6.0, 10.0, -11.0, 8.0, 2.0, 11.0, -6.0, -14.0, 12.0, 12.0, 5.0, 7.0, -12.0, 13.0, 7.0, 14.0, -8.0, 2.0, 7.0, -3.0, 11.0, 3.0, 4.0, -4.0, 11.0, 6.0, 2.0, -8.0, 1.0, 10.0, 12.0, 14.0, -3.0, 0.0, 4.0, 9.0, 7.0, -3.0, 2.0, 11.0, -4.0, 1.0, 7.0, -12.0, 6.0, 9.0, 12.0, 13.0, -5.0, 1.0, 6.0, -3.0, 11.0, 7.0, 0.0, 10.0, -8.0, 7.0, 6.0, -9.0, 0.0, 13.0, 11.0, 14.0, 12.0, 0.0, -11.0, 5.0, 11.0, -5.0, 4.0, 13.0, -20.0, 10.0, 12.0, 3.0, -10.0, 13.0, 9.0, 14.0, -6.0, 6.0, 1.0, 12.0, 0.0, -8.0, 11.0, 7.0, 12.0, -10.0, 6.0, 2.0, -6.0, 9.0, 10.0, 5.0, 10.0, 11.0, -11.0, -4.0, 7.0, 0.0, 12.0, 5.0, 9.0, 9.0, -8.0, -7.0, 6.0, 13.0, 3.0, 14.0, -7.0, 5.0, 3.0, -3.0, 11.0, -1.0, 8.0, 9.0, -5.0, 4.0, 7.0, -10.0, 2.0, 12.0, 11.0, 14.0, -12.0, 6.0, 7.0, 11.0, 8.0, -11.0, 7.0, 7.0, -11.0, 7.0, 12.0, 5.0, -13.0, 12.0, 11.0, 13.0, 7.0, -7.0, 2.0, -2.0, 5.0, -1.0, 13.0, 11.0, -16.0, 9.0, 11.0, -5.0, -4.0, 12.0, 12.0, 13.0, -2.0, 5.0, -1.0, 12.0, 6.0, -6.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.184196628578837, "mean_inference_ms": 1.0612478772469531, "mean_action_processing_ms": 0.07087141953924944, "mean_env_wait_ms": 0.1743617282117038, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 881280, "agent_timesteps_total": 881280, "timers": {"sample_time_ms": 0.079, "sample_throughput": 69440504.741, "learn_time_ms": 12.851, "learn_throughput": 428597.627, "update_time_ms": 5.231}, "info": {"learner": {"learned": {"policy_loss": 201735831552.0, "vf_loss": 240.66412353515625, "total_loss": 201735831552.0, "vf_explained_var": -0.0007429122924804688, "model": {}}}, "num_steps_sampled": 881280, "num_agent_steps_sampled": 881280, "num_steps_trained": 881280, "num_agent_steps_trained": 881280}, "done": false, "episodes_total": 17280, "training_iteration": 160, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-28", "timestamp": 1626864508, "time_this_iter_s": 0.3575477600097656, "time_total_s": 57.87000560760498, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1a45e400>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 57.87000560760498, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 71.6, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -9.0, 9.0, 2.0, 13.0, 3.0, 7.0, -8.0, -7.0, 0.0, 9.0, 13.0, 6.0, 12.0, -14.0, 11.0, -1.0, 12.0, 7.0, -3.0, 6.0, 13.0, -7.0, 3.0, 9.0, -17.0, 11.0, 12.0, 8.0, 5.0, 7.0, -5.0, 12.0, 7.0, 0.0, -4.0, 8.0, 3.0, -6.0, 10.0, 5.0, -10.0, 12.0, 8.0, 11.0, -3.0, -3.0, 10.0, 12.0, 2.0, 7.0, -6.0, 4.0, -1.0, 5.0, 7.0, -4.0, 8.0, -1.0, 12.0, 11.0, -12.0, 5.0, 11.0, 10.0, 4.0, 11.0, -10.0, 9.0, 12.0, -9.0, 3.0, 5.0, -10.0, 8.0, 12.0, 10.0, 7.0, 8.0, -10.0, 12.0, -5.0, 0.0, 8.0, 8.0, 12.0, -10.0, 5.0, 10.0, -1.0, 5.0, 1.0, 13.0, 5.0, -12.0, 9.0, 9.0, 2.0, 9.0, -5.0, -4.0, 13.0, 3.0, 3.0, 12.0, -5.0, 6.0, 2.0, 11.0, -17.0, 9.0, 12.0, 8.0, 4.0, -7.0, 10.0, 14.0, 12.0, -14.0, 3.0, 7.0, 3.0, 7.0, -2.0, 10.0, -4.0, -2.0, 11.0, 11.0, 7.0, -7.0, 4.0, 14.0, 5.0, -8.0, 4.0, -1.0, 11.0, 5.0, 0.0, 9.0, -12.0, 11.0, 7.0, -5.0, -1.0, 10.0, 11.0, 12.0, 13.0, 2.0, -12.0, 11.0, 4.0, -2.0, 2.0, 13.0, 7.0, 10.0, -15.0, 7.0, 8.0, 2.0, -2.0, -9.0, 14.0, 10.0, 0.0, 12.0, 12.0, -16.0, 7.0, 13.0, -1.0, -9.0, 12.0, 8.0, 0.0, 12.0, -5.0, 0.0, 14.0, 6.0, -5.0, -6.0, 7.0, 3.0, 11.0, 13.0, 2.0, -9.0, 9.0, -5.0, 4.0, 10.0, 6.0, 14.0, 10.0, 1.0, -10.0, 8.0, 6.0, 7.0, -6.0, 13.0, 3.0, -11.0, 10.0, 7.0, -8.0, 6.0, 10.0, 9.0, 11.0, 2.0, -7.0, 4.0, 1.0, -1.0, 11.0, 9.0, 3.0, 12.0, -9.0, 9.0, -10.0, 5.0, 11.0, 6.0, 13.0, -14.0, 10.0, 7.0, 3.0, -2.0, 7.0, 11.0, 9.0, -15.0, 10.0, 8.0, 3.0, 10.0, -6.0, -1.0, 6.0, -1.0, 11.0, 4.0, 2.0, 11.0, -2.0, 13.0, 2.0, -10.0, 10.0, 12.0, -11.0, 3.0, 11.0, 14.0, -6.0, 5.0, 2.0, -4.0, 9.0, 11.0, -1.0, 10.0, -6.0, -2.0, 13.0, 0.0, 4.0, 9.0, 2.0, 8.0, 12.0, 4.0, -9.0, 2.0, 4.0, 11.0, -2.0, 7.0, 10.0, 11.0, -13.0, 7.0, 2.0, 12.0, -6.0, 11.0, 13.0, -10.0, 1.0, -5.0, 6.0, 4.0, 10.0, 10.0, -3.0, -5.0, 13.0, 8.0, -1.0, 11.0, -3.0, 14.0, 8.0, -16.0, 9.0, 6.0, -14.0, 11.0, 12.0, 13.0, 6.0, -9.0, 5.0, -5.0, 2.0, 8.0, 10.0, 4.0, 13.0, 8.0, -10.0, 11.0, -4.0, 3.0, 5.0, 8.0, 6.0, -8.0, 9.0, 7.0, -9.0, 11.0, 6.0, 9.0, 12.0, -14.0, 8.0, 8.0, -18.0, 13.0, 12.0, 9.0, 5.0, 13.0, -12.0, 13.0, -9.0, 2.0, 9.0, 10.0, -7.0, -1.0, 13.0, 11.0, -10.0, 12.0, 2.0, 13.0, -1.0, -4.0, 7.0, 8.0, 7.0, 5.0, -5.0, 10.0, 9.0, -9.0, 5.0, 11.0, 12.0, 13.0, -21.0, 11.0, -2.0, -4.0, 10.0, 12.0, 7.0, 10.0, -14.0, 7.0, -5.0, 3.0, 10.0, -3.0, 12.0, 6.0, 0.0, 11.0, -3.0, -4.0, 11.0, -6.0, 2.0, 11.0, 8.0, 8.0, 8.0, 7.0, -8.0, 7.0, -9.0, 13.0, 4.0, 11.0, 4.0, -4.0, 4.0, 14.0, 12.0, -5.0, -6.0, 9.0, -9.0, 10.0, 5.0, 7.0, 2.0, -4.0, 10.0, 8.0, 4.0, 10.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1842024130562676, "mean_inference_ms": 1.0612111561479693, "mean_action_processing_ms": 0.07086946136171263, "mean_env_wait_ms": 0.17436413356223765, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 886788, "agent_timesteps_total": 886788, "timers": {"sample_time_ms": 0.077, "sample_throughput": 71197193.522, "learn_time_ms": 12.872, "learn_throughput": 427901.419, "update_time_ms": 5.263}, "info": {"learner": {"learned": {"policy_loss": 69457952768.0, "vf_loss": 126.77714538574219, "total_loss": 69457952768.0, "vf_explained_var": -0.0014033317565917969, "model": {}}}, "num_steps_sampled": 886788, "num_agent_steps_sampled": 886788, "num_steps_trained": 886788, "num_agent_steps_trained": 886788}, "done": false, "episodes_total": 17388, "training_iteration": 161, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-29", "timestamp": 1626864509, "time_this_iter_s": 0.353468656539917, "time_total_s": 58.2234742641449, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829a268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 58.2234742641449, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.833333333333332, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 7.708333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -10.0, -1.0, 13.0, 13.0, 5.0, 6.0, -9.0, -8.0, 4.0, 7.0, 12.0, -1.0, 8.0, -5.0, 13.0, 8.0, -10.0, 4.0, 13.0, -12.0, 13.0, 5.0, 9.0, 10.0, -3.0, 4.0, 4.0, 5.0, 12.0, 2.0, -4.0, 8.0, -1.0, 8.0, 0.0, -7.0, 8.0, 2.0, 12.0, -17.0, 14.0, 7.0, 11.0, 12.0, -5.0, -4.0, 12.0, 12.0, -13.0, 5.0, 11.0, -3.0, -6.0, 12.0, 12.0, 12.0, -3.0, 12.0, -6.0, 0.0, -7.0, 10.0, 12.0, 8.0, -3.0, -1.0, 11.0, 3.0, 12.0, 11.0, -11.0, 10.0, 12.0, 319.0, 11.0, 6.0, 4.0, -5.0, 10.0, 8.0, -6.0, 13.0, 0.0, 8.0, 8.0, -9.0, 8.0, 7.0, -3.0, 12.0, -1.0, 8.0, 3.0, -4.0, 8.0, 7.0, 12.0, -6.0, 2.0, -8.0, 2.0, 11.0, 10.0, 12.0, -4.0, 11.0, -4.0, 7.0, 0.0, 12.0, -4.0, 6.0, 10.0, -12.0, 11.0, 10.0, -17.0, 13.0, 9.0, 11.0, 12.0, -20.0, 12.0, 7.0, 1.0, -6.0, 13.0, 14.0, -18.0, 9.0, 10.0, 14.0, 13.0, -10.0, -2.0, 12.0, 7.0, 11.0, -15.0, 6.0, -11.0, 10.0, 10.0, 6.0, 10.0, -11.0, 10.0, 9.0, 5.0, 8.0, -7.0, -8.0, 14.0, -3.0, 12.0, 4.0, 9.0, 9.0, -7.0, 13.0, -14.0, 11.0, 5.0, -11.0, 9.0, 9.0, 8.0, 10.0, 10.0, -17.0, 12.0, 7.0, 5.0, 12.0, -9.0, 14.0, 9.0, -16.0, 8.0, 6.0, 10.0, 9.0, -10.0, 12.0, -3.0, 12.0, -6.0, 10.0, -12.0, 11.0, 6.0, 8.0, -6.0, 1.0, 12.0, -1.0, -3.0, 11.0, 8.0, 9.0, 10.0, 11.0, -15.0, -1.0, 0.0, 10.0, 6.0, 13.0, -9.0, 3.0, 8.0, 11.0, 14.0, 318.0, 12.0, 6.0, -3.0, 12.0, 0.0, 9.0, 0.0, 10.0, -4.0, 14.0, -9.0, -1.0, 11.0, 11.0, 11.0, -16.0, 9.0, 12.0, 12.0, -17.0, 8.0, 5.0, 5.0, 10.0, -5.0, 13.0, -12.0, 2.0, 12.0, -10.0, 7.0, 12.0, 6.0, -10.0, 11.0, 12.0, 2.0, 7.0, -11.0, 12.0, 7.0, 8.0, -3.0, 4.0, 6.0, 12.0, 12.0, -19.0, 10.0, -9.0, 11.0, 9.0, 4.0, 12.0, -6.0, -3.0, 12.0, 12.0, 12.0, 7.0, -16.0, 12.0, 5.0, -15.0, 13.0, -10.0, 9.0, 4.0, 12.0, 7.0, 3.0, -6.0, 11.0, 12.0, 8.0, -14.0, 9.0, 12.0, 12.0, 320.0, 12.0, 11.0, 11.0, 12.0, -19.0, 6.0, 8.0, -9.0, 10.0, 9.0, -9.0, 5.0, 10.0, -9.0, 5.0, 13.0, 6.0, -2.0, 13.0, -3.0, 7.0, 2.0, -8.0, 12.0, 9.0, 13.0, -13.0, 13.0, 2.0, 12.0, 13.0, 317.0, 13.0, 2.0, -1.0, 10.0, 4.0, 2.0, 8.0, -6.0, 11.0, 8.0, -6.0, 13.0, 0.0, 2.0, 12.0, 6.0, -5.0, 12.0, -4.0, 11.0, -4.0, 2.0, -7.0, 7.0, 13.0, 13.0, -10.0, 13.0, -1.0, 9.0, 4.0, 6.0, -4.0, 6.0, 0.0, 5.0, 4.0, -1.0, -3.0, 7.0, 12.0, 13.0, -4.0, 0.0, 6.0, -2.0, -2.0, 10.0, 9.0, 11.0, -4.0, 9.0, -1.0, 8.0, -8.0, 12.0, 3.0, 14.0, -10.0, 2.0, 9.0, -10.0, 5.0, 9.0, 11.0, 5.0, -3.0, 7.0, 6.0, 4.0, -11.0, 9.0, 13.0, 14.0, -7.0, 4.0, 4.0, -2.0, 2.0, 11.0, 4.0, 10.0, 11.0, -14.0, 8.0, 7.0, -13.0, 8.0, 13.0, 10.0, 5.0, 3.0, -3.0, 12.0, 332.0, 11.0, 12.0, 8.0, -4.0, 10.0, 1.0, 7.0, 2.0, -7.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418868200281968, "mean_inference_ms": 1.0612474167416275, "mean_action_processing_ms": 0.0708677419109628, "mean_env_wait_ms": 0.17435529718060008, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 892296, "agent_timesteps_total": 892296, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66277521.003, "learn_time_ms": 13.434, "learn_throughput": 409991.951, "update_time_ms": 5.783}, "info": {"learner": {"learned": {"policy_loss": 72731222016.0, "vf_loss": 122.5841064453125, "total_loss": 72731222016.0, "vf_explained_var": -0.0013997554779052734, "model": {}}}, "num_steps_sampled": 892296, "num_agent_steps_sampled": 892296, "num_steps_trained": 892296, "num_agent_steps_trained": 892296}, "done": false, "episodes_total": 17496, "training_iteration": 162, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-29", "timestamp": 1626864509, "time_this_iter_s": 0.3728199005126953, "time_total_s": 58.59629416465759, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829ab70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 58.59629416465759, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 78.9, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [5.0, 9.0, -11.0, 12.0, 10.0, -9.0, 1.0, 13.0, -6.0, 13.0, -5.0, 13.0, 2.0, 14.0, 5.0, -6.0, 6.0, -12.0, 12.0, 9.0, 8.0, -10.0, 4.0, 13.0, -8.0, 12.0, 0.0, 11.0, 1.0, 11.0, 7.0, -4.0, 7.0, -2.0, 12.0, -2.0, 1.0, -10.0, 11.0, 13.0, -6.0, 3.0, 6.0, 12.0, -10.0, 11.0, 3.0, 11.0, 6.0, 12.0, -16.0, 13.0, 10.0, -9.0, 13.0, 1.0, 7.0, 14.0, 1.0, -7.0, 3.0, 14.0, -13.0, 11.0, -9.0, 11.0, 12.0, 1.0, 1.0, 6.0, 9.0, -1.0, -6.0, 9.0, 4.0, 8.0, -11.0, 14.0, 6.0, 6.0, 6.0, -2.0, -2.0, 13.0, 7.0, -9.0, 13.0, 4.0, -9.0, 14.0, 3.0, 7.0, 4.0, 14.0, -15.0, 12.0, 11.0, 10.0, -19.0, 13.0, 10.0, 10.0, 8.0, -13.0, -5.0, 14.0, -5.0, 11.0, 2.0, 14.0, 1.0, -2.0, -10.0, 11.0, 1.0, 13.0, 8.0, 4.0, 4.0, -1.0, -8.0, 12.0, 3.0, 8.0, 6.0, 11.0, 8.0, -10.0, 7.0, 12.0, 12.0, -16.0, 12.0, -11.0, 4.0, 10.0, -12.0, 13.0, 7.0, 7.0, -8.0, 13.0, 1.0, 9.0, 9.0, -2.0, -5.0, 13.0, -8.0, 5.0, 5.0, 13.0, 1.0, 14.0, -7.0, 7.0, 4.0, 12.0, -6.0, 5.0, 10.0, -1.0, -2.0, 8.0, 8.0, -9.0, 10.0, 6.0, 7.0, 7.0, -9.0, 10.0, 1.0, 5.0, -3.0, 12.0, 6.0, -1.0, 7.0, 3.0, 9.0, 5.0, 3.0, -2.0, 12.0, 7.0, -8.0, 4.0, -9.0, 13.0, -1.0, 12.0, 6.0, -4.0, 1.0, 12.0, 5.0, -7.0, 10.0, 7.0, -4.0, 8.0, 10.0, 1.0, 4.0, 13.0, 5.0, -7.0, -8.0, 10.0, 0.0, 13.0, 7.0, -5.0, 13.0, 0.0, -5.0, 13.0, 0.0, 7.0, 4.0, 2.0, 11.0, -2.0, 5.0, -2.0, 0.0, 12.0, 5.0, -8.0, 12.0, 6.0, 4.0, 9.0, -9.0, 11.0, 9.0, 5.0, -8.0, 9.0, -6.0, 7.0, 12.0, 2.0, 12.0, -9.0, 12.0, 0.0, 10.0, 6.0, 5.0, -6.0, -2.0, 7.0, 6.0, 4.0, 12.0, -3.0, 12.0, -6.0, 13.0, 9.0, -19.0, 12.0, -4.0, 12.0, -4.0, 11.0, -8.0, 4.0, 11.0, 8.0, 0.0, 0.0, 5.0, 10.0, 12.0, 10.0, 8.0, -15.0, -5.0, 14.0, 2.0, 4.0, 10.0, 0.0, -3.0, 8.0, 13.0, -10.0, -1.0, 13.0, 10.0, -3.0, 6.0, 2.0, 8.0, 0.0, 4.0, 3.0, 8.0, 14.0, 11.0, -18.0, 11.0, -10.0, 12.0, 2.0, 10.0, 1.0, -9.0, 13.0, -4.0, 14.0, -6.0, 11.0, -8.0, 3.0, 8.0, 12.0, 5.0, -1.0, -2.0, 13.0, 12.0, -3.0, 10.0, -4.0, 10.0, 14.0, -16.0, 7.0, 7.0, 11.0, -4.0, 1.0, -15.0, 11.0, 6.0, 13.0, 8.0, 10.0, 13.0, -16.0, -8.0, 13.0, -3.0, 13.0, 10.0, 5.0, 3.0, -3.0, -1.0, -1.0, 5.0, 12.0, 10.0, 9.0, -17.0, 13.0, -7.0, 14.0, -3.0, 11.0, 11.0, 4.0, 11.0, -11.0, -12.0, 10.0, 4.0, 13.0, 6.0, 5.0, 13.0, -9.0, 10.0, 8.0, -8.0, 5.0, -11.0, 14.0, 0.0, 12.0, 2.0, -7.0, 7.0, 13.0, 11.0, -8.0, 1.0, 11.0, -7.0, 14.0, -2.0, 10.0, -3.0, 0.0, 6.0, 12.0, -7.0, 7.0, 12.0, 3.0, 13.0, 8.0, 7.0, -13.0, -6.0, 10.0, 6.0, 5.0, 12.0, 11.0, 6.0, -14.0, 5.0, -3.0, 1.0, 12.0, 12.0, 9.0, 8.0, -14.0, -8.0, 14.0, 0.0, 9.0, -5.0, 11.0, 7.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418048564791872, "mean_inference_ms": 1.0611169466600918, "mean_action_processing_ms": 0.07085940216397255, "mean_env_wait_ms": 0.17434829794485082, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 897804, "agent_timesteps_total": 897804, "timers": {"sample_time_ms": 0.083, "sample_throughput": 66541106.881, "learn_time_ms": 13.416, "learn_throughput": 410564.648, "update_time_ms": 6.031}, "info": {"learner": {"learned": {"policy_loss": 1.2164889574050903, "vf_loss": 19.60828971862793, "total_loss": 20.824779510498047, "vf_explained_var": -0.009817242622375488, "model": {}}}, "num_steps_sampled": 897804, "num_agent_steps_sampled": 897804, "num_steps_trained": 897804, "num_agent_steps_trained": 897804}, "done": false, "episodes_total": 17604, "training_iteration": 163, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-29", "timestamp": 1626864509, "time_this_iter_s": 0.3511824607849121, "time_total_s": 58.947476625442505, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829aea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 58.947476625442505, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 78.0, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.13888888888889, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 4.534722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 13.0, -12.0, 8.0, 10.0, -5.0, 11.0, -1.0, 6.0, 12.0, 2.0, -5.0, 7.0, -2.0, -2.0, 12.0, 13.0, 14.0, 8.0, -20.0, 8.0, -5.0, 0.0, 12.0, -1.0, 13.0, -7.0, 10.0, 5.0, 7.0, 7.0, -4.0, -6.0, 13.0, -3.0, 11.0, 7.0, -4.0, 7.0, 5.0, 11.0, 12.0, 9.0, -17.0, 11.0, 11.0, -11.0, 4.0, -19.0, 14.0, 10.0, 10.0, -5.0, 9.0, -1.0, 12.0, 9.0, 12.0, -2.0, -4.0, 12.0, 5.0, -9.0, 7.0, -2.0, 14.0, 10.0, -7.0, 4.0, -3.0, 3.0, 11.0, -5.0, 13.0, -2.0, 9.0, 5.0, 4.0, 10.0, -4.0, 1.0, 13.0, -8.0, 9.0, 12.0, -4.0, 3.0, 4.0, 14.0, 12.0, -7.0, -4.0, 5.0, 1.0, -2.0, 11.0, -14.0, 14.0, 5.0, 10.0, 9.0, -11.0, 8.0, 9.0, -2.0, 10.0, -4.0, 11.0, 5.0, 12.0, -11.0, 9.0, 8.0, 14.0, 1.0, -8.0, 8.0, 12.0, -17.0, 12.0, -6.0, 12.0, -2.0, 11.0, 11.0, 6.0, 6.0, -8.0, -4.0, 14.0, 6.0, -1.0, 9.0, -9.0, 12.0, 3.0, -3.0, 11.0, -3.0, 10.0, 11.0, 0.0, -9.0, 13.0, 1.0, 9.0, -5.0, 10.0, 6.0, -10.0, 12.0, 7.0, -1.0, 12.0, -7.0, 11.0, 14.0, -8.0, 12.0, -3.0, 8.0, -10.0, 4.0, 13.0, 9.0, -7.0, 2.0, 11.0, -3.0, 13.0, -3.0, 8.0, 6.0, 9.0, 8.0, -8.0, 4.0, 14.0, 10.0, -13.0, 11.0, -2.0, -4.0, 10.0, 10.0, 14.0, -1.0, -8.0, 12.0, -12.0, 9.0, 6.0, 3.0, 14.0, 10.0, -12.0, -17.0, 11.0, 12.0, 9.0, 10.0, 13.0, -4.0, -4.0, 9.0, -2.0, 9.0, -1.0, 14.0, 13.0, 8.0, -20.0, 5.0, -4.0, 7.0, 7.0, -4.0, 13.0, -4.0, 10.0, 9.0, -7.0, 6.0, 7.0, 3.0, 14.0, 11.0, -13.0, -4.0, 12.0, -2.0, 9.0, 10.0, 14.0, -5.0, -4.0, 9.0, 4.0, -10.0, 12.0, -19.0, 14.0, 12.0, 8.0, -2.0, 13.0, 4.0, 0.0, -2.0, 9.0, -1.0, 9.0, -6.0, 2.0, 10.0, 9.0, 8.0, 13.0, 11.0, -17.0, 12.0, -8.0, 0.0, 11.0, 9.0, 12.0, 0.0, -6.0, 14.0, -2.0, -9.0, 12.0, 5.0, -11.0, 10.0, 11.0, 9.0, -3.0, 11.0, -2.0, 13.0, 10.0, -3.0, -5.0, 14.0, 1.0, 3.0, -3.0, 6.0, 12.0, 12.0, -15.0, -8.0, 11.0, 1.0, 11.0, -4.0, 13.0, -2.0, 8.0, 4.0, 5.0, -1.0, 7.0, -13.0, 13.0, 4.0, 11.0, 5.0, -3.0, 3.0, 10.0, 12.0, 12.0, 2.0, -11.0, 14.0, 11.0, -1.0, -9.0, -8.0, 13.0, 4.0, 6.0, 13.0, -10.0, 3.0, 9.0, 13.0, 14.0, -9.0, -3.0, 9.0, 5.0, -3.0, 4.0, 9.0, 13.0, -3.0, -4.0, 7.0, -1.0, 0.0, 9.0, 9.0, 10.0, -3.0, -1.0, 11.0, 319.0, 11.0, 13.0, 7.0, 13.0, 7.0, -12.0, -6.0, 5.0, 7.0, 9.0, 13.0, 4.0, 0.0, -2.0, 13.0, 3.0, 7.0, -8.0, -12.0, 7.0, 10.0, 10.0, 9.0, -4.0, 0.0, 10.0, 13.0, 13.0, -19.0, 8.0, 14.0, -3.0, -9.0, 13.0, 12.0, 14.0, 9.0, -20.0, 10.0, 7.0, -12.0, 10.0, 6.0, 13.0, -3.0, -1.0, 4.0, 6.0, 8.0, -3.0, -5.0, 13.0, 7.0, 0.0, 7.0, -4.0, 3.0, 9.0, 9.0, 12.0, -3.0, -3.0, 6.0, 4.0, 6.0, -1.0, -11.0, 13.0, 11.0, 2.0, 14.0, -10.0, 0.0, 11.0, -4.0, 13.0, -4.0, 10.0, 6.0, -2.0, 2.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418205490288228, "mean_inference_ms": 1.0611254486557182, "mean_action_processing_ms": 0.07085831293565396, "mean_env_wait_ms": 0.1743488899783285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 903312, "agent_timesteps_total": 903312, "timers": {"sample_time_ms": 0.086, "sample_throughput": 64096820.419, "learn_time_ms": 13.888, "learn_throughput": 396608.15, "update_time_ms": 6.173}, "info": {"learner": {"learned": {"policy_loss": 1.2888433933258057, "vf_loss": 20.21419334411621, "total_loss": 21.503036499023438, "vf_explained_var": -0.009614229202270508, "model": {}}}, "num_steps_sampled": 903312, "num_agent_steps_sampled": 903312, "num_steps_trained": 903312, "num_agent_steps_trained": 903312}, "done": false, "episodes_total": 17712, "training_iteration": 164, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-30", "timestamp": 1626864510, "time_this_iter_s": 0.36620068550109863, "time_total_s": 59.3136773109436, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182152f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 59.3136773109436, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, 2.0, 13.0, -7.0, 11.0, 1.0, -1.0, 4.0, 12.0, 11.0, 1.0, -9.0, 13.0, 13.0, 1.0, -12.0, 5.0, -8.0, 12.0, 6.0, 5.0, -6.0, 5.0, 11.0, 8.0, -1.0, 7.0, 1.0, 9.0, 14.0, -11.0, 3.0, 8.0, -13.0, 13.0, 7.0, 10.0, 6.0, 10.0, -11.0, 11.0, 13.0, 0.0, -9.0, 12.0, 13.0, -16.0, 6.0, 8.0, -8.0, 11.0, 4.0, 7.0, -2.0, -3.0, 13.0, 11.0, 13.0, -8.0, -1.0, 12.0, 14.0, -18.0, 7.0, 12.0, -14.0, 4.0, 13.0, -10.0, 6.0, 10.0, 9.0, 11.0, -6.0, 7.0, 3.0, 12.0, 14.0, -10.0, -1.0, 11.0, -7.0, 7.0, 4.0, 8.0, -7.0, 10.0, 4.0, 4.0, -6.0, 4.0, 13.0, 5.0, 14.0, 10.0, -14.0, 8.0, -5.0, 4.0, 8.0, -8.0, 6.0, 7.0, 10.0, -4.0, 10.0, 2.0, 7.0, 7.0, 12.0, 6.0, -10.0, -6.0, 10.0, 9.0, 2.0, 6.0, 0.0, 12.0, -3.0, -1.0, 11.0, 2.0, 3.0, 10.0, 7.0, 9.0, -11.0, 13.0, -12.0, 2.0, 12.0, -6.0, 4.0, 4.0, 13.0, 11.0, 4.0, 7.0, -7.0, 9.0, 13.0, 1.0, -8.0, -4.0, 10.0, 4.0, 5.0, 11.0, -8.0, 11.0, 1.0, -3.0, 7.0, 0.0, 11.0, 13.0, 13.0, -9.0, -2.0, 10.0, 7.0, -13.0, 11.0, 10.0, 6.0, 4.0, -5.0, 13.0, -7.0, -2.0, 11.0, 10.0, 12.0, 1.0, -8.0, -10.0, 12.0, 6.0, 7.0, 6.0, 12.0, 10.0, -13.0, 5.0, 6.0, 7.0, -3.0, 6.0, 11.0, -7.0, 5.0, 10.0, -5.0, 2.0, 8.0, -15.0, 7.0, 13.0, 10.0, -3.0, 7.0, 7.0, 4.0, 7.0, 14.0, 9.0, -15.0, 5.0, 11.0, 13.0, -14.0, 6.0, -4.0, 0.0, 13.0, 12.0, -3.0, 1.0, 5.0, 6.0, 14.0, -5.0, 0.0, 2.0, -2.0, 7.0, 8.0, 0.0, -2.0, 13.0, 4.0, 8.0, 12.0, -1.0, -4.0, 12.0, 12.0, -2.0, -7.0, -11.0, 7.0, 12.0, 7.0, 11.0, -11.0, 13.0, 2.0, 6.0, -6.0, 12.0, 3.0, 13.0, 9.0, -13.0, 6.0, -4.0, 1.0, 5.0, 13.0, 5.0, -9.0, 6.0, 13.0, 7.0, -3.0, 0.0, 11.0, 12.0, 14.0, -10.0, -1.0, 10.0, 5.0, 13.0, -13.0, 6.0, 9.0, -8.0, 8.0, 13.0, 10.0, 2.0, -10.0, 4.0, 13.0, 12.0, -14.0, 11.0, 6.0, -9.0, 7.0, 12.0, 8.0, -6.0, 1.0, 11.0, -5.0, 2.0, 7.0, 11.0, 12.0, 11.0, -19.0, -3.0, 2.0, 12.0, 4.0, 8.0, -8.0, 5.0, 10.0, 3.0, 13.0, 0.0, -1.0, 11.0, 14.0, -11.0, 1.0, -6.0, 3.0, 10.0, 8.0, -8.0, 1.0, 12.0, 10.0, -12.0, 13.0, 4.0, 10.0, 11.0, 11.0, 11.0, -18.0, 8.0, -8.0, 11.0, 4.0, -7.0, 7.0, 13.0, 2.0, 11.0, -3.0, 7.0, 0.0, 10.0, 14.0, -9.0, 0.0, -5.0, 1.0, 11.0, 8.0, 9.0, -3.0, -2.0, 11.0, -10.0, 12.0, 2.0, 11.0, 9.0, 14.0, -10.0, 2.0, 11.0, -9.0, 5.0, 8.0, 13.0, -18.0, 12.0, 8.0, 6.0, 9.0, 2.0, -2.0, 13.0, 13.0, -14.0, 3.0, -1.0, 1.0, 12.0, 3.0, 8.0, -16.0, 10.0, 13.0, 8.0, -5.0, 7.0, 5.0, 13.0, 5.0, -1.0, -2.0, 10.0, -14.0, 10.0, 9.0, -7.0, 12.0, 12.0, -2.0, 6.0, -3.0, 7.0, 5.0, 12.0, 11.0, 3.0, -11.0, -2.0, 0.0, 13.0, 4.0, 3.0, -9.0, 9.0, 12.0, 8.0, -5.0, 1.0, 11.0, 11.0, 10.0, -12.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418452145869427, "mean_inference_ms": 1.0611756704779443, "mean_action_processing_ms": 0.07085730432873151, "mean_env_wait_ms": 0.17435297432899965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 908820, "agent_timesteps_total": 908820, "timers": {"sample_time_ms": 0.087, "sample_throughput": 62980961.773, "learn_time_ms": 13.939, "learn_throughput": 395160.46, "update_time_ms": 6.421}, "info": {"learner": {"learned": {"policy_loss": 242380210176.0, "vf_loss": 246.4065704345703, "total_loss": 242380210176.0, "vf_explained_var": -0.0005549192428588867, "model": {}}}, "num_steps_sampled": 908820, "num_agent_steps_sampled": 908820, "num_steps_trained": 908820, "num_agent_steps_trained": 908820}, "done": false, "episodes_total": 17820, "training_iteration": 165, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-30", "timestamp": 1626864510, "time_this_iter_s": 0.3590066432952881, "time_total_s": 59.67268395423889, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829a2f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 59.67268395423889, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 72.7, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 27.546296296296298, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 317.0}, "policy_reward_mean": {"learned": 6.886574074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [6.0, 9.0, 5.0, -5.0, 13.0, 0.0, 9.0, -7.0, 2.0, -2.0, 8.0, 8.0, -5.0, 0.0, 7.0, 13.0, 4.0, 8.0, 9.0, -6.0, 13.0, -7.0, -3.0, 12.0, 2.0, -2.0, 4.0, 12.0, 7.0, -17.0, 13.0, 12.0, 10.0, 9.0, 2.0, -6.0, 13.0, 10.0, -4.0, -4.0, -10.0, 11.0, 7.0, 7.0, -8.0, -1.0, 12.0, 12.0, 4.0, 13.0, -7.0, 5.0, 13.0, 0.0, 9.0, -7.0, 7.0, -5.0, 2.0, 11.0, -9.0, 1.0, 11.0, 12.0, 7.0, 3.0, 11.0, -6.0, 14.0, 0.0, 10.0, -9.0, 7.0, 13.0, 7.0, -12.0, -3.0, -4.0, 12.0, 10.0, 4.0, 13.0, -11.0, 9.0, 13.0, 3.0, -5.0, 4.0, 9.0, 6.0, -7.0, 7.0, -2.0, 6.0, -1.0, 12.0, 3.0, 6.0, -4.0, 10.0, 14.0, 14.0, 9.0, 317.0, -14.0, 14.0, 5.0, 10.0, -10.0, 1.0, 12.0, 12.0, 4.0, 6.0, -4.0, 9.0, 14.0, -4.0, 10.0, -5.0, 9.0, -1.0, 4.0, 3.0, -12.0, 4.0, 11.0, 12.0, 8.0, 0.0, 12.0, -5.0, 11.0, 14.0, 10.0, -20.0, 1.0, 13.0, -6.0, 7.0, -7.0, 2.0, 10.0, 10.0, 2.0, 12.0, -9.0, 10.0, 14.0, -9.0, -2.0, 12.0, 0.0, 0.0, 3.0, 12.0, 7.0, 3.0, -1.0, 6.0, 2.0, -6.0, 8.0, 11.0, 14.0, -5.0, 5.0, 1.0, 5.0, 13.0, -14.0, 11.0, 11.0, 2.0, -11.0, 13.0, 7.0, 3.0, -3.0, 8.0, 6.0, 6.0, -9.0, 12.0, -4.0, 13.0, 1.0, 5.0, -7.0, 13.0, 2.0, 7.0, 9.0, 6.0, -3.0, 3.0, 13.0, -4.0, 10.0, -4.0, 13.0, 14.0, 9.0, 316.0, 9.0, 0.0, 9.0, -3.0, 3.0, 5.0, 11.0, -4.0, 13.0, 13.0, 9.0, -20.0, 6.0, 12.0, 1.0, -4.0, 7.0, 7.0, -2.0, 3.0, 2.0, 8.0, -3.0, 8.0, 14.0, 14.0, -3.0, -10.0, -4.0, 7.0, 6.0, 6.0, 9.0, -4.0, -3.0, 13.0, 9.0, 4.0, -10.0, 12.0, 14.0, 14.0, 10.0, 317.0, -3.0, 0.0, 10.0, 8.0, 9.0, -3.0, -2.0, 11.0, 9.0, 5.0, -8.0, 9.0, 13.0, 5.0, -11.0, 8.0, 6.0, -9.0, 7.0, 11.0, 12.0, -8.0, 12.0, -1.0, 2.0, 7.0, 11.0, -5.0, 10.0, -1.0, 10.0, -4.0, -1.0, -2.0, 12.0, 6.0, 3.0, 7.0, -3.0, 8.0, 9.0, 2.0, -3.0, 7.0, 12.0, -1.0, 9.0, -5.0, 5.0, 13.0, -11.0, 8.0, 4.0, 6.0, 7.0, -2.0, 3.0, 6.0, 10.0, -4.0, 12.0, -3.0, -5.0, 11.0, 1.0, -1.0, 3.0, 12.0, 6.0, 11.0, -15.0, 13.0, 6.0, 6.0, -4.0, 7.0, 7.0, 9.0, 9.0, -10.0, -9.0, 13.0, 2.0, 9.0, -9.0, 11.0, 1.0, 12.0, 3.0, 8.0, -6.0, 10.0, 14.0, 0.0, 10.0, -9.0, 5.0, -2.0, 9.0, 3.0, 7.0, 0.0, 9.0, -1.0, 0.0, 10.0, -6.0, 11.0, 14.0, 13.0, 8.0, -20.0, 11.0, -7.0, 2.0, 9.0, -12.0, 4.0, 10.0, 13.0, 6.0, 2.0, 8.0, -1.0, 13.0, 14.0, 10.0, 315.0, 6.0, 11.0, 2.0, -4.0, 7.0, 3.0, -5.0, 10.0, 9.0, 4.0, 10.0, -8.0, 13.0, 0.0, 10.0, -8.0, 1.0, 13.0, 7.0, -6.0, 3.0, 7.0, -3.0, 8.0, 6.0, 6.0, 9.0, -6.0, 8.0, 12.0, 10.0, -15.0, 5.0, -4.0, 6.0, 8.0, 7.0, -1.0, 10.0, -1.0, 6.0, 7.0, 12.0, -10.0, 9.0, 10.0, -7.0, 3.0, -3.0, 10.0, 3.0, 5.0, -2.0, -3.0, 9.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841875749729205, "mean_inference_ms": 1.0611836537152863, "mean_action_processing_ms": 0.07085399423361409, "mean_env_wait_ms": 0.17434773822513672, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 914328, "agent_timesteps_total": 914328, "timers": {"sample_time_ms": 0.084, "sample_throughput": 65549500.852, "learn_time_ms": 13.952, "learn_throughput": 394789.729, "update_time_ms": 6.408}, "info": {"learner": {"learned": {"policy_loss": 92103884800.0, "vf_loss": 128.74256896972656, "total_loss": 92103884800.0, "vf_explained_var": -0.0010018348693847656, "model": {}}}, "num_steps_sampled": 914328, "num_agent_steps_sampled": 914328, "num_steps_trained": 914328, "num_agent_steps_trained": 914328}, "done": false, "episodes_total": 17928, "training_iteration": 166, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-31", "timestamp": 1626864511, "time_this_iter_s": 0.3469698429107666, "time_total_s": 60.01965379714966, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1829a840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 60.01965379714966, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 356.0, "episode_reward_min": 15.0, "episode_reward_mean": 30.72222222222222, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 321.0}, "policy_reward_mean": {"learned": 7.680555555555555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 356.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 2.0, 5.0, 13.0, 9.0, 4.0, 10.0, -8.0, 10.0, -10.0, 2.0, 13.0, 8.0, -1.0, 1.0, 7.0, 2.0, 11.0, -10.0, 12.0, 12.0, -13.0, 7.0, 9.0, 13.0, 12.0, 12.0, -22.0, -6.0, 8.0, 2.0, 11.0, 3.0, 10.0, -10.0, 12.0, 8.0, 3.0, 7.0, -3.0, 13.0, -7.0, 2.0, 7.0, 10.0, -9.0, 6.0, 8.0, -11.0, 10.0, 7.0, 9.0, 12.0, -14.0, 11.0, 6.0, 14.0, -9.0, 8.0, 2.0, 8.0, -5.0, 0.0, 12.0, 7.0, 10.0, -9.0, 7.0, 11.0, -18.0, 11.0, 11.0, 14.0, 10.0, 8.0, -17.0, 9.0, -2.0, 5.0, 3.0, 4.0, -6.0, 5.0, 12.0, 7.0, 3.0, -8.0, 13.0, 14.0, -2.0, -10.0, 13.0, 11.0, -8.0, 0.0, 12.0, -3.0, 4.0, 3.0, 11.0, 7.0, 6.0, -9.0, 11.0, 14.0, -3.0, -7.0, 11.0, 1.0, -4.0, 5.0, 13.0, 7.0, 2.0, -4.0, 10.0, 10.0, -4.0, 11.0, -2.0, 13.0, 318.0, 12.0, 11.0, 12.0, -6.0, 7.0, 2.0, -7.0, 6.0, 3.0, 13.0, 13.0, -3.0, -4.0, 9.0, 14.0, 2.0, 7.0, -8.0, 9.0, -7.0, 3.0, 10.0, 8.0, -11.0, 7.0, 11.0, 7.0, 4.0, -9.0, 13.0, 13.0, -12.0, 10.0, 4.0, 7.0, -11.0, 11.0, 8.0, 8.0, -9.0, 4.0, 12.0, 5.0, 3.0, -6.0, 13.0, 14.0, 11.0, 315.0, 13.0, -6.0, 6.0, 2.0, 13.0, 7.0, 4.0, -8.0, 12.0, 1.0, 7.0, -5.0, 12.0, 13.0, 11.0, -16.0, 7.0, 13.0, -12.0, 6.0, 8.0, 1.0, -3.0, 4.0, 13.0, 12.0, 5.0, -6.0, 4.0, 13.0, -14.0, 4.0, 12.0, 6.0, -9.0, 7.0, 11.0, 6.0, -5.0, 10.0, 4.0, 10.0, -11.0, 10.0, 6.0, 13.0, 11.0, 4.0, -13.0, -5.0, -1.0, 9.0, 12.0, 7.0, 5.0, -8.0, 11.0, 9.0, 1.0, -6.0, 11.0, 12.0, 10.0, -13.0, 6.0, 6.0, -4.0, 6.0, 7.0, 13.0, -6.0, 0.0, 8.0, 7.0, 9.0, 5.0, -6.0, 14.0, 11.0, -21.0, 11.0, -3.0, 5.0, 3.0, 10.0, 2.0, 5.0, -4.0, 12.0, 12.0, -7.0, 12.0, -2.0, 13.0, -2.0, 1.0, 3.0, -6.0, 8.0, 0.0, 13.0, 7.0, -7.0, 7.0, 8.0, 7.0, -2.0, -2.0, 12.0, 14.0, -16.0, 9.0, 8.0, 13.0, -10.0, 4.0, 8.0, 2.0, -4.0, 5.0, 12.0, 13.0, 5.0, 0.0, -3.0, 14.0, 10.0, 12.0, -21.0, -9.0, -1.0, 12.0, 13.0, 4.0, 6.0, -8.0, 13.0, 6.0, 9.0, 7.0, -7.0, -5.0, 11.0, 2.0, 7.0, -5.0, 3.0, 10.0, 7.0, 5.0, 11.0, -6.0, 5.0, 8.0, 5.0, 9.0, -7.0, 13.0, 10.0, -16.0, 8.0, -7.0, 9.0, 6.0, 7.0, 7.0, -9.0, 5.0, 12.0, 13.0, 321.0, 11.0, 11.0, 13.0, 319.0, 11.0, 12.0, 12.0, -8.0, 5.0, 6.0, -4.0, -2.0, 9.0, 12.0, 7.0, 9.0, -13.0, 12.0, 12.0, 9.0, -18.0, 12.0, -7.0, 6.0, 4.0, 12.0, -14.0, 8.0, 13.0, 8.0, 9.0, 4.0, -9.0, 11.0, 13.0, 10.0, 12.0, -20.0, 8.0, -8.0, 2.0, 13.0, 8.0, -9.0, 10.0, 6.0, 11.0, -6.0, -2.0, 12.0, 13.0, 12.0, -19.0, 9.0, -1.0, 13.0, 6.0, -3.0, 7.0, 6.0, 10.0, -8.0, -3.0, -4.0, 11.0, 11.0, 13.0, 319.0, 12.0, 11.0, 12.0, -9.0, 10.0, 2.0, 8.0, -3.0, 2.0, 8.0, -6.0, 7.0, 2.0, 12.0, 14.0, 10.0, -20.0, 11.0, 5.0, -8.0, 10.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416695826798235, "mean_inference_ms": 1.0609858404839017, "mean_action_processing_ms": 0.07084293332862143, "mean_env_wait_ms": 0.17433490863671375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 919836, "agent_timesteps_total": 919836, "timers": {"sample_time_ms": 0.089, "sample_throughput": 61727150.025, "learn_time_ms": 14.317, "learn_throughput": 384720.354, "update_time_ms": 6.406}, "info": {"learner": {"learned": {"policy_loss": 419821780992.0, "vf_loss": 532.9866943359375, "total_loss": 419821780992.0, "vf_explained_var": -0.00022292137145996094, "model": {}}}, "num_steps_sampled": 919836, "num_agent_steps_sampled": 919836, "num_steps_trained": 919836, "num_agent_steps_trained": 919836}, "done": false, "episodes_total": 18036, "training_iteration": 167, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-31", "timestamp": 1626864511, "time_this_iter_s": 0.3609468936920166, "time_total_s": 60.380600690841675, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346488>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 60.380600690841675, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 75.6, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 18.305555555555557, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 331.0}, "policy_reward_mean": {"learned": 4.576388888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-5.0, 10.0, 7.0, 3.0, 11.0, 5.0, -5.0, 4.0, -1.0, 13.0, -4.0, 7.0, 9.0, 7.0, 0.0, -1.0, -6.0, 9.0, 10.0, 3.0, 11.0, -5.0, 12.0, -3.0, -9.0, 14.0, 12.0, -2.0, -5.0, 7.0, 12.0, 1.0, -8.0, 8.0, 4.0, 11.0, 13.0, 11.0, 12.0, 331.0, 5.0, 0.0, 0.0, 10.0, 8.0, -4.0, 0.0, 11.0, 10.0, 11.0, -14.0, 8.0, -1.0, -2.0, 7.0, 11.0, -9.0, 12.0, 11.0, 1.0, 7.0, 13.0, -11.0, 6.0, 3.0, 10.0, -11.0, 13.0, 3.0, -8.0, 8.0, 12.0, -9.0, 13.0, 4.0, 7.0, 8.0, 8.0, -11.0, 10.0, 6.0, 8.0, 10.0, -9.0, -6.0, 6.0, 2.0, 13.0, -3.0, 10.0, 2.0, 6.0, 12.0, 13.0, 6.0, -16.0, -12.0, 14.0, 3.0, 10.0, 11.0, 12.0, 10.0, -18.0, -6.0, 10.0, 12.0, -1.0, -5.0, 10.0, 6.0, 4.0, -13.0, 13.0, 7.0, 8.0, 13.0, 8.0, 12.0, -18.0, -1.0, 12.0, -6.0, 10.0, 9.0, -2.0, -2.0, 10.0, -6.0, 8.0, 6.0, 8.0, 13.0, 4.0, -14.0, 12.0, -3.0, 12.0, 9.0, -3.0, 7.0, 10.0, -9.0, 7.0, -2.0, 6.0, 5.0, 6.0, -6.0, -2.0, 11.0, 12.0, -1.0, 12.0, -6.0, 10.0, 6.0, 11.0, -9.0, 7.0, -7.0, 7.0, 7.0, 8.0, -4.0, 6.0, 6.0, 7.0, -6.0, 10.0, 8.0, 3.0, 13.0, -7.0, 6.0, 3.0, -9.0, 9.0, 5.0, 10.0, 13.0, -12.0, 1.0, 13.0, 12.0, 2.0, -10.0, 11.0, 9.0, 12.0, -12.0, 6.0, -7.0, 9.0, 9.0, 4.0, 0.0, 5.0, -3.0, 13.0, 5.0, 10.0, -11.0, 11.0, 7.0, 13.0, -7.0, 2.0, 9.0, 8.0, 9.0, -11.0, 6.0, -12.0, 8.0, 13.0, 7.0, -2.0, 3.0, 7.0, 12.0, 8.0, 1.0, -6.0, 3.0, 9.0, 10.0, -6.0, 12.0, -2.0, -8.0, 13.0, -4.0, 7.0, 7.0, 5.0, 13.0, -13.0, 6.0, 9.0, -6.0, 8.0, 4.0, 9.0, 13.0, 6.0, 11.0, -15.0, 4.0, 12.0, -12.0, 11.0, 7.0, 12.0, 2.0, -6.0, -10.0, 13.0, 3.0, 9.0, 12.0, 6.0, -11.0, 8.0, 8.0, 12.0, 12.0, -17.0, -4.0, 6.0, 1.0, 12.0, -9.0, 9.0, 7.0, 8.0, 5.0, 6.0, -7.0, 11.0, -6.0, 11.0, 0.0, 10.0, -3.0, 14.0, 3.0, 1.0, -3.0, 11.0, 8.0, -1.0, 7.0, 5.0, -3.0, 6.0, 6.0, 13.0, -3.0, -1.0, -4.0, 7.0, 9.0, 3.0, -5.0, 12.0, 6.0, 3.0, 8.0, 13.0, -11.0, 5.0, 10.0, 0.0, -7.0, 12.0, 6.0, 12.0, -11.0, 8.0, 6.0, 8.0, 10.0, -9.0, -2.0, 3.0, 2.0, 12.0, -6.0, 2.0, 8.0, 11.0, 9.0, 10.0, -15.0, 11.0, 3.0, 8.0, -6.0, 10.0, 13.0, 10.0, -20.0, 12.0, 10.0, -1.0, -1.0, 7.0, 9.0, 10.0, 12.0, -16.0, -10.0, 8.0, 10.0, 7.0, 8.0, -9.0, 4.0, 12.0, -5.0, 11.0, 0.0, 9.0, 13.0, 1.0, 10.0, -9.0, -10.0, 14.0, 9.0, 2.0, 12.0, -9.0, -1.0, 13.0, 6.0, 13.0, 12.0, -16.0, 14.0, -19.0, 12.0, 8.0, 8.0, 8.0, -7.0, 6.0, 5.0, 3.0, -6.0, 13.0, -12.0, 12.0, 3.0, 12.0, -5.0, 12.0, 0.0, 8.0, -7.0, 6.0, 10.0, 7.0, 12.0, -4.0, -6.0, 13.0, 8.0, -2.0, 1.0, 8.0, 9.0, 13.0, 9.0, -16.0, 6.0, 14.0, 7.0, -12.0, 3.0, 6.0, -7.0, 13.0, -4.0, 13.0, 1.0, 5.0, 0.0, 11.0, -4.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18417960129725972, "mean_inference_ms": 1.0610339865906413, "mean_action_processing_ms": 0.0708453517306725, "mean_env_wait_ms": 0.17434729846053243, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 925344, "agent_timesteps_total": 925344, "timers": {"sample_time_ms": 0.09, "sample_throughput": 61167377.558, "learn_time_ms": 14.047, "learn_throughput": 392100.138, "update_time_ms": 6.097}, "info": {"learner": {"learned": {"policy_loss": 185385402368.0, "vf_loss": 237.9375, "total_loss": 185385402368.0, "vf_explained_var": -0.0009192228317260742, "model": {}}}, "num_steps_sampled": 925344, "num_agent_steps_sampled": 925344, "num_steps_trained": 925344, "num_agent_steps_trained": 925344}, "done": false, "episodes_total": 18144, "training_iteration": 168, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-31", "timestamp": 1626864511, "time_this_iter_s": 0.350430965423584, "time_total_s": 60.73103165626526, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 60.73103165626526, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 81.7, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-2.0, 14.0, 0.0, 3.0, 14.0, 3.0, 9.0, -11.0, 14.0, 13.0, -12.0, 0.0, -6.0, 11.0, 0.0, 10.0, -9.0, 13.0, 5.0, 6.0, -5.0, 1.0, 7.0, 12.0, 14.0, 13.0, -11.0, -1.0, 9.0, -10.0, 9.0, 7.0, -2.0, 14.0, 1.0, 2.0, 6.0, -4.0, 12.0, 1.0, 3.0, -4.0, 4.0, 12.0, 9.0, 11.0, -3.0, -2.0, 6.0, 13.0, -2.0, -2.0, -2.0, -2.0, 13.0, 6.0, 9.0, 11.0, 12.0, -17.0, 7.0, 0.0, -4.0, 12.0, 7.0, 14.0, 1.0, -7.0, 7.0, -4.0, 12.0, 0.0, 14.0, 11.0, -11.0, 1.0, 5.0, 6.0, -2.0, 6.0, 6.0, 0.0, 2.0, 7.0, 9.0, 1.0, 12.0, -7.0, -10.0, 12.0, 11.0, 2.0, 7.0, 1.0, -5.0, 12.0, 3.0, 13.0, 2.0, -3.0, 1.0, -4.0, 12.0, 6.0, 14.0, 14.0, -11.0, -2.0, 10.0, 7.0, -8.0, 6.0, 2.0, 13.0, -4.0, 4.0, 7.0, 8.0, 12.0, -12.0, 7.0, 12.0, 10.0, -14.0, 13.0, 6.0, 8.0, -12.0, -7.0, 14.0, 11.0, -3.0, 3.0, 7.0, 12.0, -7.0, 10.0, 10.0, -17.0, 12.0, 13.0, 4.0, 8.0, -10.0, 8.0, 13.0, 0.0, -6.0, -13.0, 5.0, 11.0, 12.0, 13.0, 12.0, -14.0, 4.0, -1.0, 3.0, 10.0, 3.0, 12.0, -5.0, 8.0, 0.0, 14.0, -6.0, 9.0, -2.0, 14.0, 11.0, -1.0, -9.0, 13.0, 7.0, -18.0, 13.0, 2.0, 13.0, -2.0, 2.0, 1.0, -5.0, 12.0, 7.0, 7.0, -2.0, -2.0, 12.0, 13.0, 9.0, -20.0, 13.0, 9.0, 12.0, 0.0, -6.0, 5.0, 4.0, 13.0, -7.0, -3.0, 14.0, 6.0, -2.0, 14.0, 8.0, 1.0, -8.0, 4.0, 14.0, -4.0, 1.0, 14.0, -3.0, 7.0, -3.0, 14.0, 4.0, -12.0, 9.0, 14.0, 9.0, -19.0, 11.0, 3.0, 12.0, 5.0, -5.0, 9.0, -3.0, -3.0, 12.0, 14.0, 14.0, -6.0, -7.0, 13.0, 11.0, -4.0, -5.0, 4.0, 12.0, 7.0, -8.0, 6.0, 9.0, 13.0, -13.0, 8.0, 13.0, -4.0, -2.0, 6.0, -10.0, 11.0, 8.0, 8.0, -6.0, 5.0, 8.0, -9.0, 4.0, 13.0, 7.0, -2.0, 13.0, -6.0, 10.0, 8.0, 3.0, -7.0, 11.0, 2.0, 0.0, 7.0, 6.0, -6.0, 2.0, 12.0, 7.0, 13.0, 12.0, -12.0, 2.0, 13.0, 11.0, -15.0, 6.0, 4.0, 0.0, 3.0, 8.0, -2.0, 2.0, 12.0, 3.0, 9.0, -3.0, 11.0, -2.0, 9.0, -5.0, 6.0, 5.0, -15.0, 13.0, 12.0, 5.0, -10.0, 7.0, 12.0, 6.0, 13.0, 14.0, -18.0, 6.0, 10.0, 9.0, -10.0, 6.0, 8.0, 9.0, -3.0, 1.0, -2.0, 0.0, 12.0, 5.0, 14.0, 11.0, 10.0, -20.0, 11.0, 4.0, 6.0, -6.0, 5.0, -1.0, 5.0, 6.0, -2.0, -1.0, 12.0, 6.0, -4.0, 11.0, -2.0, 10.0, 9.0, 4.0, -11.0, 13.0, 2.0, 14.0, -8.0, 7.0, -5.0, 7.0, 1.0, 12.0, 14.0, 12.0, -1.0, -10.0, -9.0, 10.0, 8.0, 6.0, 7.0, 14.0, 4.0, -10.0, 8.0, -7.0, 12.0, 2.0, 13.0, 13.0, -12.0, 1.0, -11.0, 10.0, 11.0, 5.0, 9.0, 13.0, 0.0, -7.0, -10.0, 2.0, 12.0, 11.0, 6.0, 14.0, -11.0, 6.0, 6.0, 11.0, 3.0, -5.0, 5.0, -2.0, 1.0, 11.0, -7.0, 9.0, 7.0, 6.0, 13.0, 13.0, -13.0, 2.0, 10.0, 8.0, -6.0, 3.0, 2.0, 12.0, 7.0, -6.0, 13.0, -3.0, 12.0, -7.0, 9.0, 12.0, 7.0, -13.0, 2.0, -5.0, 11.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416523186686987, "mean_inference_ms": 1.0609368663087166, "mean_action_processing_ms": 0.07084231172728747, "mean_env_wait_ms": 0.17433570208504534, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 930852, "agent_timesteps_total": 930852, "timers": {"sample_time_ms": 0.089, "sample_throughput": 62191259.749, "learn_time_ms": 13.839, "learn_throughput": 398012.308, "update_time_ms": 5.866}, "info": {"learner": {"learned": {"policy_loss": 1.187937617301941, "vf_loss": 14.068327903747559, "total_loss": 15.256265640258789, "vf_explained_var": -0.007015347480773926, "model": {}}}, "num_steps_sampled": 930852, "num_agent_steps_sampled": 930852, "num_steps_trained": 930852, "num_agent_steps_trained": 930852}, "done": false, "episodes_total": 18252, "training_iteration": 169, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-32", "timestamp": 1626864512, "time_this_iter_s": 0.3424255847930908, "time_total_s": 61.07345724105835, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 61.07345724105835, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, 7.0, -16.0, 13.0, 8.0, -1.0, 11.0, -3.0, 9.0, -4.0, -2.0, 12.0, 9.0, -9.0, 2.0, 13.0, 9.0, 8.0, 9.0, -11.0, 5.0, 2.0, -4.0, 12.0, -13.0, 3.0, 12.0, 13.0, 1.0, -3.0, 11.0, 6.0, 9.0, -1.0, -2.0, 9.0, 12.0, -10.0, 4.0, 9.0, 10.0, -4.0, 12.0, -3.0, 12.0, -11.0, 2.0, 12.0, 5.0, 5.0, -6.0, 11.0, 8.0, 8.0, 4.0, -5.0, 8.0, -10.0, 11.0, 6.0, 13.0, 3.0, -12.0, 11.0, 4.0, 7.0, -9.0, 13.0, 7.0, 14.0, -4.0, -2.0, 0.0, 3.0, -1.0, 13.0, 12.0, 4.0, -8.0, 7.0, 6.0, 9.0, 4.0, -4.0, 10.0, 8.0, 2.0, -5.0, -17.0, 7.0, 13.0, 12.0, 12.0, -9.0, 7.0, 5.0, 0.0, 12.0, 6.0, -3.0, 4.0, 3.0, -3.0, 11.0, -15.0, 8.0, 12.0, 10.0, 5.0, 11.0, -12.0, 11.0, 7.0, 7.0, 2.0, -1.0, 3.0, 14.0, 10.0, -12.0, 8.0, 2.0, -8.0, 13.0, 13.0, -10.0, 8.0, 4.0, 7.0, 5.0, -8.0, 11.0, 11.0, 7.0, 11.0, -14.0, -2.0, 6.0, -1.0, 12.0, 12.0, -11.0, 8.0, 6.0, 5.0, 2.0, -2.0, 10.0, 9.0, 6.0, -11.0, 11.0, -1.0, 8.0, -2.0, 10.0, 13.0, -10.0, 2.0, 10.0, 6.0, 7.0, -8.0, 10.0, 14.0, 11.0, 8.0, -18.0, 5.0, 9.0, 5.0, -4.0, 9.0, -7.0, 7.0, 6.0, 12.0, 11.0, -1.0, -7.0, 9.0, 7.0, 8.0, -9.0, 0.0, -5.0, 11.0, 9.0, 9.0, -6.0, 7.0, 5.0, 6.0, 10.0, 7.0, -8.0, 3.0, 6.0, -3.0, 9.0, 10.0, -11.0, 12.0, 4.0, 5.0, -8.0, 7.0, 11.0, 12.0, 7.0, -3.0, -1.0, 13.0, 3.0, -10.0, 9.0, 5.0, 5.0, -2.0, 7.0, 14.0, -9.0, 0.0, 10.0, 9.0, -3.0, -3.0, 12.0, 11.0, -9.0, 7.0, 6.0, -4.0, 3.0, 13.0, 3.0, 13.0, -12.0, 7.0, 7.0, 12.0, 11.0, -7.0, -1.0, 4.0, 13.0, 11.0, -13.0, 6.0, 5.0, -4.0, 8.0, 13.0, -11.0, 8.0, 5.0, 5.0, 1.0, 12.0, -3.0, -5.0, 8.0, 3.0, 9.0, -3.0, 1.0, 12.0, 5.0, 11.0, 5.0, -13.0, 12.0, 10.0, 2.0, 5.0, -2.0, 10.0, 8.0, -14.0, 11.0, 9.0, -12.0, 12.0, 6.0, 13.0, -13.0, 7.0, 8.0, 7.0, 7.0, 5.0, -4.0, 8.0, 5.0, 12.0, -10.0, -5.0, 3.0, 6.0, 11.0, 14.0, 6.0, -12.0, 7.0, 12.0, 3.0, 6.0, -6.0, 7.0, 6.0, -5.0, 7.0, -10.0, 1.0, 12.0, 12.0, 7.0, -11.0, 7.0, 12.0, 11.0, 5.0, -8.0, 7.0, 3.0, 7.0, -5.0, 10.0, 7.0, -17.0, 12.0, 13.0, 12.0, -7.0, 5.0, 5.0, 10.0, 7.0, 4.0, -6.0, 12.0, 5.0, -11.0, 9.0, 5.0, -14.0, 12.0, 12.0, 12.0, -12.0, 6.0, 9.0, 12.0, 6.0, 1.0, -4.0, 6.0, 14.0, 5.0, -10.0, -4.0, 6.0, 3.0, 10.0, 9.0, 3.0, -7.0, 10.0, 7.0, 6.0, 11.0, -9.0, 13.0, 8.0, -17.0, 11.0, 0.0, 6.0, 11.0, -2.0, 12.0, -6.0, 7.0, 2.0, 6.0, 8.0, 8.0, -7.0, 11.0, 8.0, -1.0, -3.0, 11.0, 4.0, -6.0, 6.0, 12.0, -9.0, 6.0, 6.0, 13.0, 3.0, -8.0, 7.0, 5.0, 8.0, 4.0, -2.0, 4.0, 3.0, -3.0, 11.0, 12.0, -10.0, 7.0, 6.0, 13.0, 2.0, -3.0, 3.0, 10.0, 2.0, -4.0, 7.0, -15.0, 8.0, 11.0, 11.0, 13.0, -13.0, 11.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416683622734406, "mean_inference_ms": 1.0609504394205178, "mean_action_processing_ms": 0.07084720616750124, "mean_env_wait_ms": 0.174341205122781, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 936360, "agent_timesteps_total": 936360, "timers": {"sample_time_ms": 0.089, "sample_throughput": 61785659.609, "learn_time_ms": 14.392, "learn_throughput": 382699.451, "update_time_ms": 6.389}, "info": {"learner": {"learned": {"policy_loss": 1.2187273502349854, "vf_loss": 18.27665138244629, "total_loss": 19.495378494262695, "vf_explained_var": -0.010710477828979492, "model": {}}}, "num_steps_sampled": 936360, "num_agent_steps_sampled": 936360, "num_steps_trained": 936360, "num_agent_steps_trained": 936360}, "done": false, "episodes_total": 18360, "training_iteration": 170, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-32", "timestamp": 1626864512, "time_this_iter_s": 0.37584352493286133, "time_total_s": 61.44930076599121, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7bf8>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 61.44930076599121, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 79.0, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, -1.0, -3.0, 6.0, 8.0, -11.0, 10.0, 8.0, 8.0, 4.0, -7.0, 10.0, 7.0, 8.0, -12.0, 12.0, 12.0, 13.0, -9.0, -1.0, -2.0, 9.0, 10.0, -2.0, 3.0, 13.0, -8.0, 7.0, 13.0, 8.0, -10.0, 4.0, 1.0, 12.0, -10.0, 12.0, -9.0, 12.0, 8.0, 4.0, 6.0, 7.0, -5.0, 7.0, 4.0, -3.0, 8.0, 6.0, 8.0, 12.0, 8.0, -13.0, -5.0, 7.0, 9.0, 4.0, 10.0, -6.0, 4.0, 7.0, 0.0, -2.0, 6.0, 11.0, -2.0, 9.0, 1.0, 7.0, -2.0, -1.0, 9.0, 9.0, 7.0, 6.0, -10.0, 12.0, -6.0, 1.0, 12.0, 8.0, 7.0, 13.0, 6.0, -11.0, 0.0, 2.0, 4.0, 9.0, 8.0, 2.0, 10.0, -5.0, 12.0, 4.0, 3.0, -4.0, 8.0, 13.0, -1.0, -5.0, -10.0, 7.0, 8.0, 10.0, 3.0, -9.0, 10.0, 11.0, 4.0, 12.0, 2.0, -3.0, 6.0, 13.0, -4.0, 0.0, 8.0, -5.0, 0.0, 12.0, 3.0, 8.0, 11.0, -7.0, 12.0, 8.0, -16.0, 11.0, 5.0, -1.0, 7.0, 4.0, 6.0, -5.0, 11.0, 3.0, 8.0, 5.0, -8.0, 10.0, -10.0, 9.0, 5.0, 11.0, 5.0, 13.0, 2.0, -5.0, 12.0, -2.0, 2.0, 3.0, 4.0, 3.0, -4.0, 12.0, 2.0, 7.0, 9.0, -3.0, 13.0, -2.0, 6.0, -2.0, -3.0, 8.0, -1.0, 11.0, 7.0, 3.0, -6.0, 11.0, -14.0, 10.0, 8.0, 11.0, 12.0, -2.0, 0.0, 5.0, 4.0, -5.0, 10.0, 6.0, 2.0, 7.0, -6.0, 12.0, -5.0, 12.0, -2.0, 10.0, 8.0, 13.0, 0.0, -6.0, -11.0, 11.0, 10.0, 5.0, 3.0, 7.0, -6.0, 11.0, 8.0, 3.0, -6.0, 10.0, 12.0, 8.0, 9.0, -14.0, 13.0, -2.0, 7.0, -3.0, 9.0, 3.0, 11.0, -8.0, 3.0, 10.0, -7.0, 9.0, 3.0, -6.0, 6.0, 12.0, 2.0, -3.0, 8.0, 8.0, 4.0, 7.0, -7.0, 11.0, 7.0, 12.0, -1.0, -3.0, 4.0, 13.0, 7.0, -9.0, 14.0, -8.0, -1.0, 10.0, 4.0, 2.0, 11.0, -2.0, 12.0, 4.0, -10.0, 9.0, 7.0, -4.0, 7.0, 5.0, 4.0, -1.0, 6.0, 6.0, 7.0, 6.0, -9.0, 11.0, -2.0, 12.0, -7.0, 12.0, 11.0, 13.0, 0.0, -9.0, -17.0, 11.0, 10.0, 11.0, 10.0, -1.0, 12.0, -6.0, -1.0, 6.0, 12.0, -2.0, 9.0, -1.0, 6.0, 1.0, -4.0, 12.0, 7.0, 0.0, 5.0, 6.0, -6.0, 10.0, -9.0, 9.0, 10.0, 5.0, 14.0, 12.0, -3.0, -8.0, 0.0, -1.0, 5.0, 11.0, 9.0, 5.0, -9.0, 10.0, 3.0, 1.0, -2.0, 13.0, 8.0, 11.0, 10.0, -14.0, 7.0, -3.0, 13.0, -2.0, 4.0, -11.0, 12.0, 10.0, -5.0, 9.0, 13.0, -2.0, 13.0, 12.0, -2.0, -8.0, 14.0, -10.0, -1.0, 12.0, 4.0, -6.0, 11.0, 6.0, 12.0, 8.0, -5.0, 0.0, 8.0, 12.0, -16.0, 11.0, -1.0, -2.0, 10.0, 8.0, 9.0, 3.0, 9.0, -6.0, 2.0, 13.0, 12.0, -12.0, 10.0, 11.0, -4.0, -2.0, -10.0, 12.0, 6.0, 7.0, 4.0, -9.0, 9.0, 11.0, -13.0, 10.0, 8.0, 10.0, 8.0, 12.0, -11.0, 6.0, 2.0, -3.0, 7.0, 9.0, 3.0, 5.0, 11.0, -4.0, 13.0, -1.0, -8.0, 11.0, 7.0, 12.0, 9.0, -13.0, 1.0, -2.0, 6.0, 10.0, 2.0, 7.0, 12.0, -6.0, -1.0, 10.0, -6.0, 12.0, 8.0, 12.0, -7.0, 2.0, 8.0, -4.0, 6.0, 5.0, 2.0, 6.0, -5.0, 12.0, -18.0, 12.0, 12.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18417841905478818, "mean_inference_ms": 1.0609490557590562, "mean_action_processing_ms": 0.07084437616293682, "mean_env_wait_ms": 0.17434271628866563, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 941868, "agent_timesteps_total": 941868, "timers": {"sample_time_ms": 0.096, "sample_throughput": 57586330.009, "learn_time_ms": 14.987, "learn_throughput": 367508.191, "update_time_ms": 6.982}, "info": {"learner": {"learned": {"policy_loss": 1.325812816619873, "vf_loss": 18.659412384033203, "total_loss": 19.985225677490234, "vf_explained_var": -0.010084152221679688, "model": {}}}, "num_steps_sampled": 941868, "num_agent_steps_sampled": 941868, "num_steps_trained": 941868, "num_agent_steps_trained": 941868}, "done": false, "episodes_total": 18468, "training_iteration": 171, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-33", "timestamp": 1626864513, "time_this_iter_s": 0.3784809112548828, "time_total_s": 61.827781677246094, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7510>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 61.827781677246094, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -19.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [13.0, 9.0, -18.0, 11.0, 2.0, 14.0, -9.0, 8.0, 11.0, 1.0, 10.0, -7.0, 13.0, 6.0, -12.0, 8.0, 0.0, 5.0, 11.0, -1.0, -7.0, 14.0, 1.0, 7.0, 10.0, 4.0, 7.0, -6.0, 14.0, -6.0, 9.0, -2.0, -4.0, 14.0, -3.0, 8.0, -11.0, 13.0, 8.0, 5.0, 6.0, 5.0, 11.0, -7.0, 7.0, 6.0, -5.0, 7.0, -11.0, 14.0, 11.0, 1.0, 4.0, -5.0, 9.0, 7.0, 8.0, 11.0, 6.0, -10.0, 13.0, 1.0, -11.0, 12.0, -11.0, 14.0, 9.0, 3.0, -13.0, 8.0, 8.0, 12.0, -9.0, 12.0, 9.0, 3.0, 9.0, 5.0, -10.0, 11.0, 12.0, 14.0, -19.0, 8.0, 2.0, -1.0, 8.0, 6.0, 9.0, 9.0, 11.0, -14.0, 13.0, -2.0, -5.0, 9.0, -6.0, 14.0, 0.0, 7.0, 9.0, 3.0, 11.0, -8.0, 7.0, -3.0, 11.0, 0.0, 13.0, 2.0, -7.0, 7.0, 7.0, 13.0, 3.0, -8.0, 5.0, 12.0, 4.0, -6.0, 6.0, 13.0, -3.0, -1.0, 13.0, 0.0, 7.0, -5.0, 14.0, 9.0, -7.0, -1.0, 1.0, -4.0, 8.0, 10.0, 12.0, 9.0, 8.0, -14.0, -3.0, 2.0, 5.0, 11.0, 8.0, 11.0, -10.0, 6.0, 3.0, 13.0, 7.0, -8.0, -7.0, 12.0, 11.0, -1.0, 13.0, 2.0, -11.0, 11.0, 13.0, 9.0, -13.0, 6.0, -5.0, 13.0, 10.0, -3.0, 9.0, 5.0, 6.0, -5.0, -10.0, 12.0, 6.0, 7.0, 11.0, 9.0, -17.0, 12.0, 2.0, 12.0, -7.0, 8.0, 1.0, 10.0, 9.0, -5.0, 13.0, 4.0, -5.0, 3.0, 13.0, 7.0, 5.0, -10.0, 5.0, 12.0, 0.0, -2.0, 4.0, 2.0, 11.0, -2.0, 6.0, 6.0, -9.0, 12.0, 12.0, 14.0, -4.0, -7.0, -14.0, 14.0, 9.0, 6.0, 11.0, 3.0, 4.0, -3.0, 8.0, 5.0, -6.0, 8.0, -13.0, 8.0, 9.0, 11.0, 9.0, 11.0, -4.0, -1.0, 9.0, 14.0, -17.0, 9.0, 14.0, 7.0, 1.0, -7.0, 13.0, 6.0, -11.0, 7.0, 7.0, 12.0, 4.0, -8.0, 7.0, 9.0, 9.0, -10.0, -9.0, 6.0, 11.0, 7.0, -3.0, 14.0, 1.0, 3.0, 4.0, 8.0, -9.0, 12.0, 5.0, 9.0, 13.0, -12.0, 8.0, 2.0, -8.0, 13.0, 13.0, 10.0, 6.0, -14.0, -8.0, 12.0, 11.0, 0.0, 4.0, 9.0, -5.0, 7.0, 14.0, 0.0, 7.0, -6.0, 12.0, 9.0, -6.0, 0.0, -4.0, 12.0, -2.0, 9.0, 2.0, 5.0, 13.0, -5.0, 3.0, 5.0, -6.0, 13.0, 14.0, 12.0, 2.0, -13.0, -1.0, 9.0, -3.0, 10.0, 5.0, 6.0, 12.0, -8.0, 11.0, 1.0, -10.0, 13.0, 11.0, 9.0, -11.0, 6.0, -10.0, 8.0, 7.0, 10.0, 10.0, -6.0, 9.0, 2.0, 11.0, 0.0, -9.0, 13.0, 11.0, 4.0, -5.0, 5.0, 6.0, 13.0, 10.0, -14.0, 1.0, 14.0, 8.0, -8.0, 13.0, -1.0, -5.0, 8.0, -2.0, 14.0, 8.0, -5.0, -5.0, 12.0, -1.0, 9.0, 3.0, 14.0, 1.0, -3.0, 12.0, 6.0, 12.0, -15.0, 11.0, 5.0, 11.0, -12.0, 2.0, -2.0, 6.0, 9.0, 3.0, 11.0, 3.0, -2.0, -5.0, 6.0, 8.0, 6.0, -1.0, 14.0, -5.0, 7.0, 10.0, 3.0, 9.0, -7.0, 5.0, 13.0, -14.0, 11.0, 12.0, 2.0, -6.0, 7.0, 5.0, 13.0, -9.0, 6.0, 4.0, 13.0, 7.0, -9.0, 1.0, -3.0, 8.0, 9.0, 13.0, 5.0, 10.0, -13.0, 12.0, 5.0, -9.0, 7.0, -10.0, 13.0, 7.0, 5.0, 9.0, 11.0, 10.0, -15.0, 6.0, 7.0, -11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18416386320097122, "mean_inference_ms": 1.060752284219139, "mean_action_processing_ms": 0.07083955223613887, "mean_env_wait_ms": 0.17433886095908616, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 947376, "agent_timesteps_total": 947376, "timers": {"sample_time_ms": 0.091, "sample_throughput": 60709133.122, "learn_time_ms": 14.624, "learn_throughput": 376650.973, "update_time_ms": 6.777}, "info": {"learner": {"learned": {"policy_loss": 184237506560.0, "vf_loss": 237.9121551513672, "total_loss": 184237506560.0, "vf_explained_var": -0.0009219646453857422, "model": {}}}, "num_steps_sampled": 947376, "num_agent_steps_sampled": 947376, "num_steps_trained": 947376, "num_agent_steps_trained": 947376}, "done": false, "episodes_total": 18576, "training_iteration": 172, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-33", "timestamp": 1626864513, "time_this_iter_s": 0.34398984909057617, "time_total_s": 62.17177152633667, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7c80>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 62.17177152633667, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 69.7, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 367.0, "episode_reward_min": 15.0, "episode_reward_mean": 31.074074074074073, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 332.0}, "policy_reward_mean": {"learned": 7.768518518518518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 366.0, 15.0, 15.0, 15.0, 354.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 367.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [8.0, 12.0, -14.0, 9.0, 13.0, 4.0, 6.0, -8.0, 11.0, 10.0, -18.0, 12.0, -14.0, 9.0, 10.0, 10.0, 11.0, 12.0, -14.0, 6.0, 13.0, 5.0, 6.0, -9.0, 12.0, 11.0, 318.0, 13.0, -4.0, 9.0, -3.0, 13.0, -2.0, 10.0, 10.0, -3.0, 11.0, 6.0, 5.0, -7.0, 11.0, 12.0, 330.0, 13.0, -3.0, 9.0, 6.0, 3.0, -7.0, 12.0, 3.0, 7.0, 12.0, 2.0, 11.0, -10.0, 10.0, 6.0, 12.0, -13.0, -10.0, 8.0, 12.0, 5.0, 6.0, 11.0, 4.0, -6.0, 12.0, 8.0, -8.0, 3.0, 10.0, 9.0, -3.0, -1.0, 8.0, 13.0, -18.0, 12.0, -8.0, 13.0, 9.0, 1.0, 5.0, 10.0, -12.0, 12.0, 12.0, 11.0, 11.0, -19.0, -5.0, 11.0, 8.0, 1.0, 7.0, -3.0, 6.0, 5.0, 13.0, 11.0, 2.0, -11.0, 11.0, 13.0, 330.0, 12.0, 4.0, 12.0, -4.0, 3.0, 11.0, -3.0, 4.0, 3.0, 11.0, 14.0, 1.0, -11.0, 11.0, 13.0, 318.0, 12.0, 9.0, 9.0, -14.0, 11.0, 10.0, 12.0, -10.0, 4.0, 11.0, 2.0, -1.0, 3.0, 12.0, 8.0, -3.0, -2.0, 6.0, 14.0, 11.0, -16.0, 13.0, 13.0, 8.0, -19.0, 13.0, 7.0, 7.0, -12.0, 11.0, 11.0, -20.0, 13.0, -13.0, 14.0, 3.0, 11.0, -6.0, 11.0, 5.0, 5.0, 10.0, 7.0, 6.0, -8.0, 10.0, 12.0, 12.0, -19.0, 12.0, 7.0, -16.0, 12.0, 10.0, 11.0, 5.0, -10.0, 12.0, 9.0, 1.0, -7.0, 10.0, 12.0, -20.0, 13.0, 8.0, 12.0, 12.0, -17.0, -9.0, 11.0, 2.0, 11.0, 12.0, 11.0, -11.0, 3.0, 11.0, 9.0, -17.0, 12.0, -4.0, 7.0, 3.0, 9.0, -9.0, 13.0, 5.0, 6.0, 13.0, 0.0, 11.0, -9.0, 9.0, 13.0, -6.0, -1.0, -4.0, 7.0, 12.0, 0.0, 7.0, 14.0, -4.0, -2.0, 11.0, 8.0, -7.0, 3.0, 11.0, 12.0, -21.0, 13.0, 14.0, 7.0, -8.0, 2.0, 6.0, -8.0, 8.0, 9.0, 10.0, 12.0, 2.0, -9.0, 12.0, 10.0, -19.0, 12.0, -9.0, 1.0, 13.0, 10.0, -1.0, 5.0, 3.0, 9.0, 10.0, 12.0, -1.0, -6.0, 10.0, 6.0, -13.0, 12.0, 5.0, -4.0, 12.0, 2.0, -12.0, 14.0, 4.0, 9.0, 13.0, 0.0, 10.0, -8.0, 9.0, 11.0, 11.0, -16.0, 9.0, 14.0, -21.0, 13.0, 0.0, 11.0, 6.0, -2.0, 12.0, 8.0, -4.0, -1.0, 11.0, 11.0, -6.0, -1.0, -13.0, 13.0, 4.0, 11.0, -3.0, 11.0, 4.0, 3.0, 12.0, 4.0, 10.0, -11.0, 11.0, 8.0, -15.0, 11.0, 1.0, 14.0, -9.0, 9.0, -5.0, 12.0, -1.0, 9.0, 13.0, 7.0, -3.0, -2.0, 12.0, 11.0, 332.0, 12.0, -11.0, 12.0, 6.0, 8.0, 13.0, 13.0, 6.0, -17.0, 11.0, 8.0, 10.0, -14.0, 11.0, 11.0, -6.0, -1.0, 12.0, -3.0, 3.0, 3.0, 8.0, 11.0, 9.0, -13.0, 11.0, 7.0, 6.0, -9.0, 7.0, 12.0, -16.0, 12.0, -7.0, 14.0, 5.0, 3.0, 3.0, 11.0, -8.0, 9.0, 8.0, 13.0, -11.0, 5.0, 9.0, 13.0, -19.0, 12.0, 9.0, 4.0, 4.0, -2.0, -6.0, 14.0, -2.0, 9.0, 8.0, 14.0, -17.0, 10.0, 8.0, 2.0, -7.0, 12.0, -8.0, 5.0, 7.0, 11.0, -11.0, 14.0, 2.0, 10.0, 11.0, 8.0, -2.0, -2.0, 12.0, 13.0, -20.0, 10.0, 12.0, 12.0, 5.0, -14.0, -15.0, 14.0, 6.0, 11.0, 11.0, 8.0, 4.0, -8.0, 9.0, 9.0, -15.0, 12.0, 2.0, 7.0, -2.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418204118347714, "mean_inference_ms": 1.0607988326116793, "mean_action_processing_ms": 0.07084226681484965, "mean_env_wait_ms": 0.174346721790415, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 952884, "agent_timesteps_total": 952884, "timers": {"sample_time_ms": 0.094, "sample_throughput": 58840496.315, "learn_time_ms": 15.065, "learn_throughput": 365604.034, "update_time_ms": 7.038}, "info": {"learner": {"learned": {"policy_loss": 1.2030119895935059, "vf_loss": 16.33357810974121, "total_loss": 17.536590576171875, "vf_explained_var": -0.008942723274230957, "model": {}}}, "num_steps_sampled": 952884, "num_agent_steps_sampled": 952884, "num_steps_trained": 952884, "num_agent_steps_trained": 952884}, "done": false, "episodes_total": 18684, "training_iteration": 173, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-33", "timestamp": 1626864513, "time_this_iter_s": 0.3757812976837158, "time_total_s": 62.547552824020386, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7b70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 62.547552824020386, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, -4.0, 11.0, 12.0, 12.0, -2.0, 11.0, -6.0, 6.0, 9.0, 5.0, -5.0, 8.0, -1.0, 1.0, 7.0, 8.0, 8.0, 12.0, -13.0, 10.0, -14.0, 11.0, 8.0, 10.0, -13.0, 8.0, 10.0, 10.0, -1.0, 5.0, 1.0, 5.0, 2.0, 12.0, -4.0, 0.0, -1.0, 7.0, 9.0, 11.0, 14.0, -10.0, 0.0, 5.0, -7.0, 7.0, 10.0, 6.0, 1.0, 11.0, -3.0, -6.0, 6.0, 10.0, 5.0, 7.0, 8.0, 7.0, -7.0, 7.0, -2.0, 5.0, 5.0, 3.0, 6.0, -5.0, 11.0, 6.0, 8.0, 8.0, -7.0, 0.0, 7.0, -3.0, 11.0, 1.0, -1.0, 10.0, 5.0, -12.0, 3.0, 12.0, 12.0, -11.0, 2.0, 11.0, 13.0, 5.0, 7.0, 11.0, -8.0, 11.0, -3.0, 5.0, 2.0, 7.0, 2.0, 10.0, -4.0, -2.0, 4.0, 4.0, 9.0, 12.0, 3.0, 5.0, -5.0, 1.0, -1.0, 4.0, 11.0, -3.0, -4.0, 11.0, 11.0, -13.0, 5.0, 10.0, 13.0, -9.0, 3.0, 11.0, 10.0, 4.0, -1.0, 3.0, 9.0, 11.0, -2.0, 10.0, -4.0, -2.0, 6.0, 8.0, 3.0, 6.0, 8.0, 11.0, -10.0, 14.0, -6.0, -2.0, 9.0, -12.0, 11.0, 7.0, 9.0, 11.0, 1.0, 10.0, -7.0, 8.0, 14.0, 3.0, -10.0, 7.0, -2.0, 9.0, 1.0, -5.0, 2.0, 11.0, 7.0, -10.0, 5.0, 10.0, 10.0, 10.0, -12.0, 5.0, 12.0, 4.0, -5.0, 5.0, 11.0, -6.0, 3.0, 6.0, 12.0, -7.0, -1.0, 11.0, 12.0, 10.0, 4.0, 5.0, -4.0, 7.0, -1.0, 10.0, -1.0, -7.0, 0.0, 11.0, 11.0, 11.0, -9.0, 11.0, 2.0, 5.0, -1.0, -1.0, 12.0, 10.0, 12.0, -15.0, 8.0, -9.0, 0.0, 12.0, 12.0, -7.0, 0.0, 10.0, 12.0, -7.0, 13.0, -4.0, 13.0, 8.0, 5.0, 12.0, -10.0, 9.0, 1.0, 6.0, -1.0, -7.0, 1.0, 12.0, 9.0, 8.0, 4.0, 6.0, -3.0, 13.0, -6.0, 0.0, 8.0, 9.0, 1.0, 7.0, -2.0, 12.0, -17.0, 12.0, 8.0, -1.0, 13.0, -1.0, 4.0, 9.0, -1.0, -6.0, 13.0, 11.0, 1.0, 11.0, -8.0, 4.0, 3.0, 9.0, -1.0, -9.0, 11.0, 5.0, 8.0, 6.0, -7.0, 6.0, 10.0, 6.0, 5.0, -2.0, 6.0, 7.0, -14.0, 9.0, 13.0, 8.0, 0.0, -4.0, 11.0, 10.0, 11.0, -5.0, -1.0, 9.0, 5.0, -8.0, 9.0, -8.0, 3.0, 7.0, 13.0, 10.0, 13.0, 2.0, -10.0, -7.0, 11.0, 10.0, 1.0, 11.0, 0.0, 9.0, -5.0, 13.0, -11.0, 11.0, 2.0, 13.0, 9.0, -13.0, 6.0, 8.0, -16.0, 11.0, 12.0, -12.0, 5.0, 11.0, 11.0, 8.0, -3.0, 11.0, -1.0, 9.0, -5.0, 5.0, 6.0, 6.0, -12.0, 12.0, 9.0, 8.0, -2.0, 12.0, -3.0, 6.0, -16.0, 12.0, 13.0, 3.0, 7.0, -5.0, 10.0, 14.0, 0.0, -2.0, 3.0, -10.0, 6.0, 7.0, 12.0, 12.0, -16.0, 11.0, 8.0, 6.0, -1.0, -1.0, 11.0, 1.0, 13.0, 5.0, -4.0, 6.0, 0.0, 11.0, -2.0, 5.0, 5.0, 10.0, -5.0, -10.0, 11.0, 4.0, 10.0, 12.0, -2.0, 8.0, -3.0, -7.0, 7.0, 12.0, 3.0, 11.0, 0.0, 10.0, -6.0, 8.0, 6.0, -7.0, 8.0, 5.0, 5.0, -3.0, 8.0, 5.0, -1.0, -2.0, 13.0, -9.0, 7.0, 7.0, 10.0, -9.0, 3.0, 10.0, 11.0, 11.0, -16.0, 7.0, 13.0, 2.0, 3.0, 11.0, -1.0, -9.0, 3.0, 11.0, 10.0, 5.0, 1.0, 11.0, -2.0, -6.0, 11.0, 8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18419576534850962, "mean_inference_ms": 1.060919464739929, "mean_action_processing_ms": 0.07084666690148052, "mean_env_wait_ms": 0.1743466428221749, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 958392, "agent_timesteps_total": 958392, "timers": {"sample_time_ms": 0.094, "sample_throughput": 58715674.785, "learn_time_ms": 14.871, "learn_throughput": 370375.782, "update_time_ms": 7.108}, "info": {"learner": {"learned": {"policy_loss": 126254505984.0, "vf_loss": 130.0759735107422, "total_loss": 126254505984.0, "vf_explained_var": -0.0013979673385620117, "model": {}}}, "num_steps_sampled": 958392, "num_agent_steps_sampled": 958392, "num_steps_trained": 958392, "num_agent_steps_trained": 958392}, "done": false, "episodes_total": 18792, "training_iteration": 174, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-34", "timestamp": 1626864514, "time_this_iter_s": 0.3851330280303955, "time_total_s": 62.93268585205078, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d268>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 62.93268585205078, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 77.9, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [10.0, -10.0, 12.0, 3.0, -4.0, 11.0, 0.0, 8.0, 0.0, 3.0, 4.0, 8.0, 4.0, 7.0, -8.0, 12.0, -1.0, 7.0, -2.0, 11.0, -4.0, 5.0, 6.0, 8.0, 4.0, 11.0, -9.0, 9.0, -7.0, 13.0, 12.0, -3.0, 11.0, 7.0, 10.0, -13.0, 10.0, 11.0, 1.0, -7.0, 5.0, 6.0, -4.0, 8.0, -15.0, 8.0, 12.0, 10.0, -5.0, 7.0, 12.0, 1.0, -2.0, 5.0, 6.0, 6.0, -12.0, 8.0, 7.0, 12.0, -11.0, 7.0, 7.0, 12.0, 11.0, 6.0, 7.0, -9.0, -3.0, 7.0, 0.0, 11.0, 9.0, 8.0, 6.0, -8.0, -13.0, 9.0, 11.0, 8.0, 12.0, 12.0, -13.0, 4.0, 8.0, -5.0, 0.0, 12.0, 10.0, 6.0, -7.0, 6.0, -3.0, 9.0, 12.0, -3.0, 6.0, 7.0, -9.0, 11.0, 8.0, -4.0, 8.0, 3.0, 11.0, 2.0, -11.0, 13.0, -11.0, 9.0, 12.0, 5.0, 7.0, 11.0, 13.0, -16.0, -4.0, 1.0, 12.0, 6.0, 12.0, 0.0, -10.0, 13.0, 4.0, 11.0, 10.0, -10.0, 11.0, -10.0, 12.0, 2.0, 12.0, -10.0, 2.0, 11.0, 9.0, 7.0, 6.0, -7.0, -7.0, 1.0, 10.0, 11.0, -10.0, 13.0, 7.0, 5.0, 7.0, -7.0, 6.0, 9.0, 7.0, 2.0, 9.0, -3.0, 2.0, 13.0, 10.0, -10.0, -7.0, 7.0, 7.0, 8.0, -13.0, 9.0, 6.0, 13.0, 7.0, 0.0, 10.0, -2.0, -10.0, 2.0, 12.0, 11.0, 6.0, 12.0, 13.0, -16.0, 11.0, 11.0, -18.0, 11.0, 3.0, 6.0, 7.0, -1.0, -3.0, 7.0, 1.0, 10.0, -3.0, 7.0, -2.0, 13.0, -8.0, 2.0, 8.0, 13.0, -8.0, 13.0, -1.0, 11.0, 8.0, 8.0, 8.0, -9.0, 12.0, -10.0, 0.0, 13.0, -10.0, -1.0, 13.0, 13.0, 9.0, 5.0, 7.0, -6.0, -2.0, -4.0, 12.0, 9.0, 11.0, 5.0, 13.0, -14.0, -9.0, 5.0, 8.0, 11.0, 9.0, 3.0, -8.0, 11.0, 11.0, 14.0, 6.0, -16.0, -2.0, 11.0, 12.0, -6.0, -3.0, 8.0, 3.0, 7.0, 7.0, 2.0, -7.0, 13.0, -2.0, -2.0, 9.0, 10.0, 12.0, 9.0, 2.0, -8.0, -4.0, 3.0, 6.0, 10.0, -1.0, 9.0, -5.0, 12.0, -1.0, 4.0, 5.0, 7.0, -1.0, 12.0, 13.0, -9.0, 11.0, -7.0, 2.0, 9.0, -7.0, 7.0, 4.0, 11.0, 5.0, 13.0, 10.0, -13.0, 11.0, 7.0, 10.0, -13.0, 10.0, -9.0, 2.0, 12.0, 10.0, 2.0, 6.0, -3.0, -9.0, 7.0, 7.0, 10.0, -4.0, 5.0, 11.0, 3.0, -4.0, 6.0, 6.0, 7.0, 13.0, 0.0, 5.0, -3.0, -9.0, 13.0, 8.0, 3.0, 8.0, 8.0, 9.0, -10.0, 7.0, -2.0, 2.0, 8.0, 9.0, 5.0, 2.0, -1.0, -12.0, 8.0, 10.0, 9.0, 13.0, 6.0, -9.0, 5.0, 8.0, -3.0, 0.0, 10.0, 7.0, 11.0, 5.0, -8.0, 7.0, 9.0, 10.0, -11.0, 11.0, 4.0, 10.0, -10.0, -10.0, 11.0, 2.0, 12.0, 11.0, 1.0, -9.0, 12.0, -12.0, 7.0, 10.0, 10.0, 3.0, 13.0, 6.0, -7.0, 6.0, -9.0, 7.0, 11.0, 8.0, 2.0, 7.0, -2.0, -13.0, 14.0, 9.0, 5.0, -9.0, 7.0, 5.0, 12.0, -4.0, 11.0, 0.0, 8.0, 2.0, 11.0, -11.0, 13.0, -5.0, 4.0, 6.0, 10.0, 10.0, 2.0, -6.0, 9.0, 9.0, -9.0, 6.0, 9.0, -12.0, 10.0, 10.0, 7.0, -14.0, 8.0, 10.0, 11.0, -9.0, 10.0, 12.0, 2.0, -2.0, 7.0, 0.0, 10.0, 8.0, 3.0, -9.0, 13.0, -5.0, 13.0, 11.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18418625798971824, "mean_inference_ms": 1.0609090512671036, "mean_action_processing_ms": 0.07084411861224175, "mean_env_wait_ms": 0.17435003618604286, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 963900, "agent_timesteps_total": 963900, "timers": {"sample_time_ms": 0.099, "sample_throughput": 55647661.985, "learn_time_ms": 15.684, "learn_throughput": 351181.993, "update_time_ms": 7.22}, "info": {"learner": {"learned": {"policy_loss": 127550070784.0, "vf_loss": 126.94434356689453, "total_loss": 127550070784.0, "vf_explained_var": -0.0011889934539794922, "model": {}}}, "num_steps_sampled": 963900, "num_agent_steps_sampled": 963900, "num_steps_trained": 963900, "num_agent_steps_trained": 963900}, "done": false, "episodes_total": 18900, "training_iteration": 175, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-34", "timestamp": 1626864514, "time_this_iter_s": 0.37967419624328613, "time_total_s": 63.31236004829407, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826db70>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 63.31236004829407, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 81.1, "ram_util_percent": 14.3}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -18.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 3.0, 7.0, 8.0, 14.0, -5.0, 12.0, -6.0, 12.0, 13.0, -13.0, 3.0, -11.0, 13.0, 11.0, 2.0, -5.0, 11.0, 1.0, 8.0, 10.0, -12.0, 13.0, 4.0, -11.0, 12.0, 13.0, 1.0, 2.0, 8.0, -2.0, 7.0, -5.0, 7.0, 12.0, 1.0, 13.0, -7.0, 13.0, -4.0, 6.0, 13.0, -5.0, 1.0, 5.0, 14.0, 12.0, -16.0, -3.0, 5.0, 7.0, 6.0, 13.0, -6.0, 12.0, -4.0, 5.0, -2.0, 3.0, 9.0, 7.0, 5.0, 12.0, -9.0, -6.0, 9.0, 12.0, 0.0, 3.0, -11.0, 10.0, 13.0, -9.0, 12.0, 7.0, 5.0, 7.0, 10.0, -5.0, 3.0, 7.0, -4.0, 6.0, 6.0, 6.0, 11.0, -14.0, 12.0, 0.0, 0.0, 13.0, 2.0, 11.0, 5.0, 12.0, -13.0, -14.0, 12.0, 7.0, 10.0, 4.0, -8.0, 11.0, 8.0, 6.0, 14.0, 5.0, -10.0, -7.0, 9.0, 11.0, 2.0, -3.0, 6.0, 12.0, 0.0, 10.0, -6.0, 13.0, -2.0, 6.0, 14.0, 6.0, -11.0, -4.0, 14.0, -5.0, 10.0, 13.0, -7.0, -3.0, 12.0, 14.0, -17.0, 10.0, 8.0, 7.0, 13.0, 7.0, -12.0, 12.0, 9.0, -3.0, -3.0, -5.0, 5.0, 8.0, 7.0, -4.0, 12.0, 13.0, -6.0, 8.0, 9.0, -7.0, 5.0, -1.0, 11.0, 11.0, -6.0, -8.0, 10.0, 7.0, 6.0, 4.0, 12.0, 12.0, -13.0, 7.0, 13.0, 5.0, -10.0, 2.0, 7.0, 9.0, -3.0, -8.0, 10.0, 1.0, 12.0, 10.0, -16.0, 8.0, 13.0, 8.0, -11.0, 7.0, 11.0, -4.0, 8.0, 2.0, 9.0, 6.0, -5.0, 2.0, 12.0, 11.0, -10.0, 10.0, 4.0, 0.0, -1.0, 7.0, 9.0, 7.0, 8.0, -12.0, 12.0, -7.0, 11.0, 2.0, 9.0, 9.0, -17.0, 10.0, 13.0, 11.0, 10.0, -13.0, 7.0, 3.0, 9.0, 13.0, -10.0, -2.0, 4.0, 2.0, 11.0, 3.0, -8.0, 12.0, 8.0, 5.0, -10.0, 13.0, 7.0, 6.0, -6.0, 12.0, 3.0, -4.0, 4.0, 12.0, 3.0, 4.0, -5.0, 12.0, 4.0, 5.0, 14.0, 3.0, -7.0, 6.0, 4.0, -3.0, 8.0, -5.0, 2.0, 13.0, 5.0, 4.0, -4.0, 9.0, 6.0, -11.0, 13.0, 9.0, 4.0, 12.0, -1.0, -7.0, 11.0, 7.0, -1.0, 12.0, -3.0, 11.0, -5.0, 9.0, 0.0, 2.0, -4.0, 12.0, 5.0, -1.0, 7.0, -2.0, 11.0, 7.0, 12.0, -1.0, -3.0, 6.0, -9.0, 13.0, 5.0, -8.0, 13.0, 5.0, 5.0, 0.0, 11.0, -8.0, 12.0, -2.0, -1.0, 7.0, 11.0, 7.0, -2.0, 13.0, -3.0, 7.0, 14.0, -9.0, 3.0, -1.0, 14.0, -5.0, 7.0, 6.0, -1.0, 7.0, 3.0, -6.0, 9.0, -1.0, 13.0, 4.0, 14.0, 5.0, -8.0, 11.0, 9.0, -3.0, -2.0, -8.0, 11.0, 12.0, 0.0, -12.0, 10.0, 13.0, 4.0, 6.0, -7.0, 9.0, 7.0, -18.0, 11.0, 12.0, 10.0, 11.0, -10.0, 5.0, 9.0, 10.0, 8.0, -16.0, 13.0, -6.0, 14.0, 13.0, -6.0, 4.0, 8.0, -2.0, 5.0, -12.0, 14.0, 6.0, 7.0, 12.0, -2.0, 12.0, -7.0, 3.0, 13.0, 9.0, -10.0, 0.0, 8.0, 11.0, -4.0, 0.0, 7.0, 12.0, -4.0, 10.0, -8.0, 10.0, 3.0, 5.0, -10.0, 13.0, 7.0, 7.0, 8.0, 2.0, -2.0, -3.0, 9.0, 7.0, 2.0, 13.0, -16.0, 10.0, 8.0, 7.0, -4.0, 8.0, 4.0, -1.0, 0.0, 5.0, 11.0, -4.0, 6.0, 2.0, 11.0, 7.0, -5.0, 13.0, 0.0, 2.0, -3.0, 5.0, 11.0, 6.0, 2.0, -2.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841853422146334, "mean_inference_ms": 1.060883537876863, "mean_action_processing_ms": 0.07084143622472548, "mean_env_wait_ms": 0.17435508671599872, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 969408, "agent_timesteps_total": 969408, "timers": {"sample_time_ms": 0.099, "sample_throughput": 55768913.523, "learn_time_ms": 15.804, "learn_throughput": 348515.579, "update_time_ms": 7.382}, "info": {"learner": {"learned": {"policy_loss": 191637274624.0, "vf_loss": 240.5935516357422, "total_loss": 191637274624.0, "vf_explained_var": -0.000780940055847168, "model": {}}}, "num_steps_sampled": 969408, "num_agent_steps_sampled": 969408, "num_steps_trained": 969408, "num_agent_steps_trained": 969408}, "done": false, "episodes_total": 19008, "training_iteration": 176, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-35", "timestamp": 1626864515, "time_this_iter_s": 0.34958815574645996, "time_total_s": 63.66194820404053, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826dea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 63.66194820404053, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.40740740740741, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -22.0}, "policy_reward_max": {"learned": 316.0}, "policy_reward_mean": {"learned": 6.101851851851852}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 353.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [14.0, -9.0, 9.0, 1.0, 8.0, 5.0, -9.0, 11.0, 4.0, 7.0, 9.0, -5.0, 3.0, 8.0, -7.0, 11.0, -2.0, 0.0, 13.0, 4.0, -9.0, 10.0, 2.0, 12.0, 4.0, -2.0, 12.0, 1.0, 6.0, 8.0, 9.0, -8.0, -6.0, 1.0, 8.0, 12.0, -2.0, 12.0, -5.0, 10.0, 10.0, 12.0, 13.0, -20.0, 7.0, 7.0, 12.0, -11.0, 10.0, 6.0, -14.0, 13.0, 10.0, 4.0, 7.0, -6.0, 7.0, -12.0, 12.0, 8.0, -11.0, 8.0, 10.0, 8.0, 12.0, -16.0, 6.0, 13.0, 5.0, -8.0, 11.0, 7.0, 6.0, 9.0, 9.0, -9.0, -2.0, 6.0, 7.0, 4.0, -3.0, 2.0, 3.0, 13.0, -7.0, 12.0, -2.0, 12.0, 3.0, -7.0, 9.0, 10.0, -9.0, 13.0, 1.0, 10.0, 14.0, 2.0, -14.0, 13.0, 9.0, 10.0, -16.0, 12.0, -16.0, 11.0, 7.0, 13.0, -2.0, 4.0, 1.0, 12.0, 10.0, 3.0, -10.0, 12.0, -7.0, 8.0, 5.0, 9.0, 3.0, 4.0, 9.0, -1.0, -5.0, 8.0, 2.0, 10.0, -3.0, -3.0, 13.0, 8.0, -5.0, 7.0, 0.0, 13.0, 5.0, -6.0, 4.0, 12.0, 6.0, 13.0, 9.0, -13.0, 12.0, 316.0, 13.0, 13.0, 9.0, 12.0, -16.0, 10.0, 10.0, 1.0, 9.0, -5.0, 11.0, 7.0, 10.0, -13.0, -3.0, 2.0, 3.0, 13.0, -4.0, 7.0, 2.0, 10.0, 11.0, -11.0, 2.0, 13.0, -2.0, 11.0, -5.0, 11.0, 8.0, -5.0, 13.0, -1.0, -1.0, 6.0, 0.0, 10.0, 8.0, -6.0, 5.0, 8.0, 0.0, 5.0, 2.0, 8.0, 13.0, 0.0, -11.0, 13.0, -7.0, 6.0, 3.0, 13.0, 8.0, 7.0, 8.0, -8.0, -5.0, 6.0, 11.0, 3.0, 11.0, -22.0, 13.0, 13.0, 9.0, 11.0, 11.0, -16.0, 12.0, 4.0, 8.0, -9.0, 8.0, 13.0, -11.0, 5.0, -4.0, -1.0, 12.0, 8.0, 4.0, 12.0, -12.0, 11.0, 13.0, -16.0, 6.0, 12.0, 11.0, 13.0, 5.0, -14.0, 11.0, 3.0, -12.0, 13.0, -6.0, 7.0, 2.0, 12.0, 8.0, 7.0, -3.0, 3.0, 5.0, 7.0, -9.0, 12.0, -3.0, 5.0, 6.0, 7.0, 9.0, 6.0, -10.0, 10.0, 11.0, 6.0, 12.0, -14.0, 13.0, 6.0, 10.0, -14.0, -4.0, 4.0, 9.0, 6.0, -5.0, 6.0, 4.0, 10.0, 7.0, -7.0, 4.0, 11.0, 4.0, 13.0, -7.0, 5.0, -2.0, -4.0, 13.0, 8.0, -6.0, 10.0, -2.0, 13.0, 10.0, 12.0, 10.0, -17.0, 8.0, 7.0, -8.0, 8.0, 13.0, -16.0, 10.0, 8.0, -1.0, 7.0, -1.0, 10.0, 6.0, 12.0, 11.0, -14.0, -16.0, 12.0, 10.0, 9.0, 12.0, 5.0, -15.0, 13.0, 11.0, 7.0, -1.0, -2.0, 1.0, 10.0, 6.0, -2.0, -13.0, 13.0, 4.0, 11.0, 14.0, 313.0, 13.0, 13.0, 12.0, 6.0, -12.0, 9.0, 12.0, 5.0, 7.0, -9.0, 5.0, 7.0, 11.0, -8.0, -8.0, 3.0, 7.0, 13.0, 7.0, 6.0, 4.0, -2.0, 5.0, 7.0, -8.0, 11.0, -2.0, 11.0, -5.0, 11.0, 11.0, -1.0, -7.0, 12.0, 10.0, 7.0, -11.0, 9.0, 9.0, 2.0, -9.0, 13.0, 10.0, 6.0, 11.0, -12.0, 8.0, -1.0, -5.0, 13.0, -9.0, 1.0, 12.0, 11.0, 10.0, 3.0, -9.0, 11.0, -14.0, 8.0, 12.0, 9.0, 13.0, 316.0, 13.0, 12.0, -7.0, 4.0, 6.0, 12.0, 11.0, -10.0, 6.0, 8.0, 9.0, 8.0, -6.0, 4.0, -1.0, -6.0, 9.0, 13.0, -9.0, 12.0, 1.0, 11.0, -8.0, 12.0, 5.0, 6.0, 3.0, 8.0, 12.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18417444340766195, "mean_inference_ms": 1.060779162462235, "mean_action_processing_ms": 0.07083784875672323, "mean_env_wait_ms": 0.17434264966185942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 974916, "agent_timesteps_total": 974916, "timers": {"sample_time_ms": 0.095, "sample_throughput": 57817727.239, "learn_time_ms": 15.406, "learn_throughput": 357511.687, "update_time_ms": 7.498}, "info": {"learner": {"learned": {"policy_loss": 182241230848.0, "vf_loss": 237.87564086914062, "total_loss": 182241230848.0, "vf_explained_var": -0.0009074211120605469, "model": {}}}, "num_steps_sampled": 974916, "num_agent_steps_sampled": 974916, "num_steps_trained": 974916, "num_agent_steps_trained": 974916}, "done": false, "episodes_total": 19116, "training_iteration": 177, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-35", "timestamp": 1626864515, "time_this_iter_s": 0.35845017433166504, "time_total_s": 64.02039837837219, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182192f0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 64.02039837837219, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 74.0, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 33.824074074074076, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 322.0}, "policy_reward_mean": {"learned": 8.456018518518519}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 352.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-4.0, -4.0, 11.0, 12.0, 8.0, 7.0, -12.0, 12.0, 13.0, 13.0, -19.0, 8.0, 6.0, 13.0, -4.0, 0.0, 4.0, -11.0, 11.0, 11.0, 6.0, 13.0, 8.0, -12.0, 13.0, 13.0, -21.0, 10.0, 11.0, -1.0, -4.0, 9.0, 12.0, 320.0, 12.0, 10.0, 2.0, 13.0, 5.0, -5.0, 1.0, 13.0, -8.0, 9.0, 11.0, 11.0, -2.0, -5.0, 4.0, -9.0, 11.0, 9.0, 12.0, 6.0, -11.0, 8.0, 14.0, 12.0, -20.0, 9.0, 8.0, 8.0, 3.0, -4.0, 9.0, -13.0, 12.0, 7.0, 3.0, 9.0, 7.0, -4.0, 9.0, 13.0, -19.0, 12.0, 9.0, 11.0, 3.0, -8.0, 13.0, -3.0, 9.0, -4.0, 9.0, 12.0, 4.0, -10.0, 13.0, 13.0, -15.0, 4.0, 9.0, 9.0, 2.0, -5.0, 12.0, -18.0, 9.0, 12.0, -1.0, 13.0, 7.0, -4.0, 14.0, 10.0, -14.0, 5.0, 6.0, 7.0, 10.0, -8.0, 12.0, 318.0, 11.0, 11.0, 2.0, 14.0, 6.0, -7.0, 13.0, 11.0, 7.0, -16.0, -4.0, 11.0, 7.0, 2.0, 6.0, -13.0, 9.0, 13.0, 6.0, 10.0, 4.0, -5.0, 8.0, 11.0, 10.0, -14.0, 0.0, 6.0, 13.0, -4.0, 2.0, -9.0, 11.0, 11.0, 12.0, -2.0, 11.0, -6.0, 9.0, 10.0, 9.0, -13.0, 7.0, 13.0, 1.0, -6.0, 8.0, -2.0, 12.0, -3.0, 6.0, 13.0, 2.0, -6.0, 9.0, 13.0, -9.0, 2.0, 5.0, -2.0, 2.0, 10.0, 5.0, -11.0, 11.0, 10.0, 3.0, 14.0, 7.0, -9.0, 10.0, 12.0, -19.0, 12.0, 9.0, 12.0, -11.0, 5.0, 9.0, -17.0, 11.0, 12.0, 5.0, 13.0, 4.0, -7.0, 13.0, 12.0, -20.0, 10.0, 13.0, 11.0, -2.0, -7.0, -8.0, 3.0, 9.0, 11.0, 12.0, 6.0, 4.0, -7.0, 13.0, 11.0, 11.0, -20.0, 4.0, 13.0, -13.0, 11.0, -3.0, 2.0, 9.0, 7.0, 11.0, 9.0, 2.0, -7.0, 13.0, 10.0, 5.0, -13.0, 10.0, 12.0, 1.0, -8.0, 13.0, 320.0, 10.0, 11.0, 3.0, 8.0, 10.0, -6.0, 8.0, 13.0, 10.0, -16.0, 2.0, 12.0, -11.0, 12.0, 9.0, -17.0, 11.0, 12.0, 4.0, 9.0, 11.0, -9.0, -3.0, 11.0, -5.0, 12.0, 0.0, -4.0, 8.0, 11.0, 3.0, -10.0, 12.0, 10.0, 7.0, 14.0, 6.0, -12.0, 12.0, 12.0, 6.0, -15.0, 10.0, 10.0, 6.0, -11.0, 9.0, -15.0, 10.0, 11.0, 10.0, 9.0, -11.0, 7.0, 12.0, 12.0, 1.0, -10.0, 5.0, 11.0, 5.0, -6.0, 10.0, -18.0, 10.0, 13.0, 7.0, 8.0, 5.0, -5.0, 9.0, 13.0, 7.0, -14.0, 5.0, -4.0, 4.0, 10.0, 6.0, -14.0, 11.0, 12.0, 1.0, 7.0, 12.0, -5.0, 13.0, 14.0, 5.0, -17.0, 4.0, 9.0, -9.0, 12.0, 8.0, -15.0, 12.0, 10.0, 9.0, 4.0, 10.0, -8.0, 7.0, 11.0, 6.0, -9.0, 12.0, 11.0, 5.0, -13.0, 9.0, -18.0, 12.0, 12.0, 9.0, 8.0, 3.0, -5.0, 12.0, 13.0, 12.0, 315.0, 13.0, 10.0, -1.0, -7.0, 11.0, 322.0, 11.0, 11.0, 12.0, 2.0, 11.0, -10.0, 8.0, 13.0, 6.0, -12.0, 5.0, 13.0, 7.0, -10.0, 8.0, 3.0, 11.0, -7.0, 12.0, 5.0, 6.0, -8.0, 12.0, 12.0, 11.0, 319.0, 12.0, 8.0, 7.0, -12.0, 7.0, -9.0, 6.0, 11.0, 12.0, 5.0, 10.0, -12.0, 12.0, 12.0, -18.0, 9.0, 5.0, 11.0, 9.0, -10.0, 4.0, -12.0, 11.0, 12.0, 2.0, 8.0, 10.0, -5.0, 13.0, 11.0, -18.0, 9.0, 3.0, 10.0, 6.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18417415483634295, "mean_inference_ms": 1.060843506012048, "mean_action_processing_ms": 0.07083320829333, "mean_env_wait_ms": 0.17434233977048888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 980424, "agent_timesteps_total": 980424, "timers": {"sample_time_ms": 0.095, "sample_throughput": 58106904.893, "learn_time_ms": 15.6, "learn_throughput": 353076.073, "update_time_ms": 7.832}, "info": {"learner": {"learned": {"policy_loss": 1.2430579662322998, "vf_loss": 18.92268943786621, "total_loss": 20.165746688842773, "vf_explained_var": -0.01043689250946045, "model": {}}}, "num_steps_sampled": 980424, "num_agent_steps_sampled": 980424, "num_steps_trained": 980424, "num_agent_steps_trained": 980424}, "done": false, "episodes_total": 19224, "training_iteration": 178, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-36", "timestamp": 1626864516, "time_this_iter_s": 0.36414432525634766, "time_total_s": 64.38454270362854, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d620>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 64.38454270362854, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.287037037037038, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -17.0}, "policy_reward_max": {"learned": 319.0}, "policy_reward_mean": {"learned": 5.3217592592592595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-3.0, 8.0, 0.0, 10.0, 8.0, -6.0, 12.0, 1.0, 12.0, -9.0, 7.0, 5.0, 10.0, 12.0, 8.0, -15.0, 7.0, 0.0, -2.0, 10.0, 6.0, 8.0, 11.0, -10.0, 7.0, 2.0, 11.0, -5.0, 9.0, 2.0, 11.0, -7.0, -1.0, 5.0, -1.0, 12.0, 11.0, -3.0, 12.0, -5.0, -15.0, 12.0, 11.0, 7.0, 7.0, -9.0, 11.0, 6.0, -3.0, 14.0, -8.0, 12.0, 13.0, 8.0, 7.0, -13.0, -2.0, 1.0, 10.0, 6.0, 13.0, -12.0, 12.0, 2.0, -2.0, 14.0, -9.0, 12.0, 8.0, 11.0, 5.0, -9.0, 8.0, 6.0, -6.0, 7.0, 14.0, -1.0, 12.0, -10.0, 10.0, 8.0, -11.0, 8.0, 13.0, -8.0, 11.0, -1.0, 6.0, 6.0, -8.0, 11.0, -3.0, 8.0, 11.0, -1.0, -7.0, 14.0, -5.0, 13.0, 7.0, 8.0, 10.0, -10.0, 3.0, 6.0, -7.0, 13.0, 13.0, 8.0, -5.0, -1.0, -7.0, 14.0, 13.0, -5.0, 13.0, -3.0, 8.0, -3.0, 7.0, 10.0, -14.0, 12.0, 9.0, 11.0, 12.0, -17.0, -2.0, 14.0, -9.0, 12.0, 6.0, 3.0, 12.0, -6.0, -1.0, 10.0, 4.0, 2.0, 9.0, -12.0, 11.0, 7.0, -9.0, 10.0, 2.0, 12.0, 11.0, 6.0, 11.0, -13.0, -10.0, 12.0, 1.0, 12.0, 13.0, -14.0, 4.0, 12.0, 0.0, 14.0, -4.0, 5.0, 13.0, -9.0, 0.0, 11.0, 5.0, 11.0, -11.0, 10.0, 8.0, 10.0, 11.0, -14.0, -1.0, 13.0, -10.0, 13.0, 6.0, -3.0, 10.0, 2.0, 12.0, 0.0, -9.0, 12.0, 7.0, 5.0, 6.0, -3.0, -2.0, 9.0, -3.0, 11.0, 7.0, 12.0, 10.0, -14.0, -11.0, 12.0, 3.0, 11.0, 8.0, -12.0, 7.0, 12.0, 12.0, 14.0, 315.0, 13.0, 7.0, 8.0, -12.0, 12.0, 7.0, 11.0, 9.0, -12.0, 14.0, 7.0, -9.0, 3.0, -3.0, 12.0, 12.0, -6.0, 12.0, -8.0, 12.0, -1.0, 11.0, 11.0, -15.0, 8.0, 2.0, -5.0, 12.0, 6.0, -2.0, 10.0, 12.0, -5.0, 8.0, 3.0, 11.0, -7.0, 0.0, 12.0, 12.0, -9.0, 14.0, 5.0, -17.0, 13.0, -3.0, 9.0, 12.0, -3.0, 3.0, -7.0, 11.0, 8.0, 0.0, 13.0, -9.0, 11.0, 13.0, 0.0, 11.0, -9.0, -2.0, 10.0, -6.0, 13.0, 13.0, 4.0, 9.0, -11.0, 6.0, 6.0, 9.0, -6.0, 14.0, 9.0, -8.0, 0.0, -5.0, 12.0, -5.0, 13.0, 7.0, 7.0, -3.0, 4.0, 5.0, 12.0, -10.0, 8.0, 14.0, -12.0, 2.0, 11.0, 12.0, 14.0, 10.0, 319.0, 7.0, -8.0, 11.0, 5.0, 11.0, 6.0, -9.0, 7.0, 13.0, 11.0, -2.0, -7.0, -12.0, 14.0, 13.0, 0.0, 7.0, 12.0, 11.0, -15.0, 1.0, 5.0, -3.0, 12.0, 14.0, -16.0, 11.0, 6.0, -1.0, 11.0, 2.0, 3.0, 9.0, -2.0, 4.0, 4.0, -2.0, 3.0, 9.0, 5.0, -7.0, 7.0, 10.0, 5.0, -1.0, 11.0, -8.0, 13.0, 8.0, -7.0, 4.0, 10.0, 11.0, 6.0, -6.0, 4.0, 7.0, -2.0, -2.0, 12.0, -9.0, 10.0, 13.0, 1.0, 13.0, 6.0, 10.0, -14.0, 7.0, 12.0, -16.0, 12.0, 8.0, 11.0, 11.0, -15.0, -3.0, 14.0, 10.0, -6.0, 12.0, 5.0, 13.0, -15.0, 4.0, 9.0, -5.0, 7.0, 10.0, 7.0, -13.0, 11.0, -8.0, 7.0, 3.0, 13.0, 7.0, 9.0, 6.0, -7.0, 3.0, 7.0, 10.0, -5.0, 13.0, -16.0, 10.0, 8.0, -1.0, 0.0, 9.0, 7.0, 13.0, 11.0, 7.0, -16.0, -7.0, 3.0, 10.0, 9.0, 9.0, 4.0, 7.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841491773894748, "mean_inference_ms": 1.0607183044813036, "mean_action_processing_ms": 0.07082982100866497, "mean_env_wait_ms": 0.1743220817612338, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 985932, "agent_timesteps_total": 985932, "timers": {"sample_time_ms": 0.097, "sample_throughput": 57006063.902, "learn_time_ms": 15.844, "learn_throughput": 347647.607, "update_time_ms": 8.016}, "info": {"learner": {"learned": {"policy_loss": 1.200113296508789, "vf_loss": 19.215450286865234, "total_loss": 20.415563583374023, "vf_explained_var": -0.010916709899902344, "model": {}}}, "num_steps_sampled": 985932, "num_agent_steps_sampled": 985932, "num_steps_trained": 985932, "num_agent_steps_trained": 985932}, "done": false, "episodes_total": 19332, "training_iteration": 179, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-36", "timestamp": 1626864516, "time_this_iter_s": 0.3545083999633789, "time_total_s": 64.73905110359192, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a1826d598>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 64.73905110359192, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 72.0, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 355.0, "episode_reward_min": 15.0, "episode_reward_mean": 24.435185185185187, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 6.108796296296297}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 355.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [11.0, -10.0, 10.0, 4.0, 6.0, 12.0, -11.0, 8.0, 8.0, 12.0, 10.0, -15.0, 14.0, 11.0, -17.0, 7.0, 10.0, 7.0, 6.0, -8.0, 7.0, 8.0, -13.0, 13.0, 14.0, 13.0, 12.0, 315.0, 13.0, 9.0, -8.0, 1.0, 13.0, 12.0, -1.0, -9.0, 6.0, -3.0, -1.0, 13.0, -1.0, -3.0, 13.0, 6.0, 0.0, 10.0, -4.0, 9.0, -13.0, 11.0, 6.0, 11.0, -1.0, -7.0, 10.0, 13.0, 5.0, 8.0, -8.0, 10.0, 13.0, 12.0, -16.0, 6.0, -3.0, 6.0, 10.0, 2.0, -5.0, 10.0, 2.0, 8.0, -13.0, 5.0, 11.0, 12.0, 5.0, 12.0, 10.0, -12.0, -7.0, 7.0, 12.0, 3.0, 13.0, 8.0, -11.0, 5.0, 14.0, 13.0, 9.0, -21.0, 13.0, 8.0, -17.0, 11.0, -5.0, 9.0, 2.0, 9.0, 12.0, 9.0, -14.0, 8.0, 13.0, 12.0, 9.0, -19.0, -3.0, 9.0, 3.0, 6.0, 3.0, 12.0, 10.0, -10.0, 13.0, -7.0, 1.0, 8.0, 4.0, -10.0, 9.0, 12.0, 13.0, 12.0, -14.0, 4.0, -7.0, 12.0, 4.0, 6.0, 4.0, -3.0, 1.0, 13.0, 12.0, -10.0, 6.0, 7.0, 14.0, 8.0, -13.0, 6.0, 11.0, 11.0, -20.0, 13.0, -18.0, 11.0, 9.0, 13.0, 13.0, 0.0, -9.0, 11.0, 13.0, 9.0, -15.0, 8.0, -7.0, 6.0, 12.0, 4.0, 1.0, 11.0, -9.0, 12.0, 7.0, 10.0, 13.0, -15.0, 13.0, 11.0, -14.0, 5.0, 7.0, 7.0, -11.0, 12.0, 7.0, -6.0, 5.0, 9.0, 13.0, -8.0, 12.0, -2.0, 14.0, 7.0, -17.0, 11.0, -1.0, -3.0, 13.0, 6.0, 10.0, 8.0, -13.0, 10.0, 5.0, -10.0, 9.0, 11.0, -5.0, 6.0, 11.0, 3.0, -11.0, 12.0, 2.0, 12.0, 3.0, -13.0, 12.0, 13.0, 13.0, 12.0, 13.0, 317.0, 5.0, 7.0, -4.0, 7.0, 10.0, 3.0, 10.0, -8.0, 1.0, 10.0, -9.0, 13.0, -2.0, 9.0, 12.0, -4.0, 14.0, 7.0, -5.0, -1.0, -8.0, 6.0, 10.0, 7.0, -8.0, 12.0, -2.0, 13.0, 8.0, 8.0, -11.0, 10.0, 13.0, 10.0, -14.0, 6.0, -11.0, 13.0, 7.0, 6.0, 1.0, 11.0, -10.0, 13.0, 10.0, 11.0, -18.0, 12.0, 12.0, -1.0, -8.0, 12.0, 8.0, 10.0, 3.0, -6.0, 7.0, 11.0, -16.0, 13.0, -1.0, 10.0, 12.0, -6.0, 13.0, -2.0, 7.0, -3.0, -12.0, 12.0, 4.0, 11.0, -1.0, 11.0, -8.0, 13.0, 9.0, 8.0, 2.0, -4.0, 8.0, -7.0, 10.0, 4.0, -3.0, 8.0, 9.0, 1.0, 6.0, -3.0, 2.0, 10.0, 13.0, -2.0, 11.0, -7.0, 13.0, 3.0, -9.0, 8.0, -9.0, 8.0, 9.0, 7.0, 8.0, 4.0, -10.0, 13.0, 2.0, -7.0, 12.0, 8.0, 13.0, 4.0, -14.0, 12.0, -9.0, 13.0, 4.0, 7.0, 7.0, -6.0, 1.0, 13.0, 11.0, -8.0, 7.0, 5.0, 14.0, 11.0, -16.0, 6.0, -5.0, 11.0, 9.0, 0.0, 1.0, 11.0, -10.0, 13.0, 12.0, 10.0, 12.0, -19.0, 13.0, 8.0, -11.0, 5.0, 12.0, 11.0, 6.0, -14.0, 5.0, 12.0, -10.0, 8.0, 12.0, 7.0, 12.0, -16.0, 13.0, -1.0, 6.0, -3.0, 9.0, 9.0, -10.0, 7.0, 7.0, -7.0, 6.0, 9.0, 9.0, 4.0, 11.0, -9.0, 13.0, 9.0, -10.0, 3.0, 10.0, -11.0, 13.0, 3.0, 5.0, -7.0, 5.0, 12.0, 7.0, 4.0, -4.0, 8.0, 14.0, 3.0, -9.0, 7.0, -2.0, 7.0, 3.0, 7.0, -4.0, 8.0, -2.0, 13.0, 13.0, 13.0, 11.0, 318.0, 10.0, 9.0, 0.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841507392470699, "mean_inference_ms": 1.060713566863329, "mean_action_processing_ms": 0.07083009356682367, "mean_env_wait_ms": 0.1743300182007944, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 991440, "agent_timesteps_total": 991440, "timers": {"sample_time_ms": 0.094, "sample_throughput": 58485244.829, "learn_time_ms": 15.081, "learn_throughput": 365220.256, "update_time_ms": 7.534}, "info": {"learner": {"learned": {"policy_loss": 1.2434779405593872, "vf_loss": 24.874433517456055, "total_loss": 26.11791229248047, "vf_explained_var": -0.009696006774902344, "model": {}}}, "num_steps_sampled": 991440, "num_agent_steps_sampled": 991440, "num_steps_trained": 991440, "num_agent_steps_trained": 991440}, "done": false, "episodes_total": 19440, "training_iteration": 180, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-36", "timestamp": 1626864516, "time_this_iter_s": 0.35039353370666504, "time_total_s": 65.08944463729858, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7a60>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 65.08944463729858, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 83.4, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
{"episode_reward_max": 354.0, "episode_reward_min": 15.0, "episode_reward_mean": 21.27777777777778, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -21.0}, "policy_reward_max": {"learned": 318.0}, "policy_reward_mean": {"learned": 5.319444444444445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 354.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [7.0, -11.0, 12.0, 7.0, -2.0, 1.0, 10.0, 6.0, -10.0, 11.0, 5.0, 9.0, -10.0, 14.0, -2.0, 13.0, 13.0, -18.0, 13.0, 7.0, -3.0, 13.0, -5.0, 10.0, 8.0, 10.0, 4.0, -7.0, -1.0, 11.0, -5.0, 10.0, 14.0, 2.0, 4.0, -5.0, 6.0, -2.0, -1.0, 12.0, -8.0, 5.0, 10.0, 8.0, 6.0, 3.0, -7.0, 13.0, 12.0, -5.0, 8.0, 0.0, -6.0, 11.0, -1.0, 11.0, -9.0, 11.0, 5.0, 8.0, 6.0, -1.0, -3.0, 13.0, -1.0, -5.0, 11.0, 10.0, 0.0, 7.0, 5.0, 3.0, -10.0, 8.0, 4.0, 13.0, -3.0, 0.0, 5.0, 13.0, 13.0, 317.0, 13.0, 11.0, 8.0, -8.0, 3.0, 12.0, 2.0, -6.0, 7.0, 12.0, 1.0, 4.0, -2.0, 12.0, 8.0, -14.0, 12.0, 9.0, 13.0, 11.0, -6.0, -3.0, -1.0, 8.0, -4.0, 12.0, 3.0, -2.0, 1.0, 13.0, 13.0, -14.0, 5.0, 11.0, 9.0, -12.0, 8.0, 10.0, -6.0, 6.0, 8.0, 7.0, 1.0, -1.0, 6.0, 9.0, 13.0, 318.0, 13.0, 10.0, 10.0, 6.0, -3.0, 2.0, -10.0, 10.0, 8.0, 7.0, 6.0, -10.0, 6.0, 13.0, -11.0, 4.0, 10.0, 12.0, 13.0, -6.0, -3.0, 11.0, -6.0, 10.0, 6.0, 5.0, -5.0, 12.0, -2.0, 10.0, -13.0, 4.0, 12.0, 12.0, -5.0, 7.0, 1.0, 12.0, -6.0, 6.0, 4.0, 11.0, -6.0, -3.0, 11.0, 13.0, -4.0, -1.0, 11.0, 9.0, 7.0, -9.0, 5.0, 12.0, 6.0, 10.0, -6.0, 5.0, 7.0, -12.0, 8.0, 12.0, -13.0, 7.0, 10.0, 11.0, -8.0, 11.0, -1.0, 13.0, -8.0, 14.0, 0.0, 9.0, 8.0, -17.0, 11.0, 13.0, -14.0, 8.0, 11.0, 10.0, 9.0, -15.0, 8.0, 13.0, -13.0, 8.0, 11.0, 9.0, -3.0, -2.0, 7.0, 13.0, 8.0, -12.0, 8.0, 11.0, 7.0, 4.0, -8.0, 12.0, 8.0, -5.0, 4.0, 8.0, -7.0, -3.0, 12.0, 13.0, 12.0, -3.0, -1.0, 7.0, 3.0, -5.0, 5.0, 12.0, -9.0, 10.0, 8.0, 6.0, 2.0, 3.0, -3.0, 13.0, 10.0, 0.0, 12.0, -7.0, 7.0, 7.0, -8.0, 9.0, -9.0, 11.0, 8.0, 5.0, -6.0, 14.0, -5.0, 12.0, 7.0, -11.0, 13.0, 6.0, 10.0, -11.0, 12.0, 4.0, -16.0, 11.0, 10.0, 10.0, -4.0, -2.0, 9.0, 12.0, -9.0, 3.0, 13.0, 8.0, 11.0, 7.0, -8.0, 5.0, -6.0, 10.0, 8.0, 3.0, -8.0, 13.0, -2.0, 12.0, 13.0, 2.0, -10.0, 10.0, -5.0, 6.0, 4.0, 10.0, 1.0, -4.0, 11.0, 7.0, -3.0, 8.0, -2.0, 12.0, -16.0, 13.0, 10.0, 8.0, 6.0, 8.0, -12.0, 13.0, 5.0, 8.0, 12.0, -10.0, -3.0, -2.0, 7.0, 13.0, 0.0, 0.0, 5.0, 10.0, 13.0, -7.0, 11.0, -2.0, 13.0, -11.0, 11.0, 2.0, 12.0, -18.0, 8.0, 13.0, 14.0, -19.0, 10.0, 10.0, 12.0, 6.0, -7.0, 4.0, 4.0, 8.0, 5.0, -2.0, -19.0, 13.0, 9.0, 12.0, 10.0, -17.0, 10.0, 12.0, -6.0, 5.0, 5.0, 11.0, -14.0, 10.0, 12.0, 7.0, 5.0, -14.0, 11.0, 13.0, -14.0, 8.0, 8.0, 13.0, 5.0, 5.0, -8.0, 13.0, -18.0, 12.0, 13.0, 8.0, -5.0, -1.0, 8.0, 13.0, 13.0, -19.0, 12.0, 9.0, 12.0, -7.0, 10.0, 0.0, -19.0, 13.0, 12.0, 9.0, 2.0, 12.0, -9.0, 10.0, 5.0, -9.0, 12.0, 7.0, 13.0, -1.0, 8.0, -5.0, -21.0, 13.0, 10.0, 13.0, -6.0, 12.0, -4.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18414865199773256, "mean_inference_ms": 1.0607236411973924, "mean_action_processing_ms": 0.07082221076315058, "mean_env_wait_ms": 0.17432542678127833, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 996948, "agent_timesteps_total": 996948, "timers": {"sample_time_ms": 0.088, "sample_throughput": 62725412.203, "learn_time_ms": 14.488, "learn_throughput": 380180.929, "update_time_ms": 6.991}, "info": {"learner": {"learned": {"policy_loss": 542036262912.0, "vf_loss": 564.2955932617188, "total_loss": 542036262912.0, "vf_explained_var": -0.0004373788833618164, "model": {}}}, "num_steps_sampled": 996948, "num_agent_steps_sampled": 996948, "num_steps_trained": 996948, "num_agent_steps_trained": 996948}, "done": false, "episodes_total": 19548, "training_iteration": 181, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-37", "timestamp": 1626864517, "time_this_iter_s": 0.3512752056121826, "time_total_s": 65.44071984291077, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a182a7ea0>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 65.44071984291077, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {}, "trial_id": "01041_00000"}
{"episode_reward_max": 15.0, "episode_reward_min": 15.0, "episode_reward_mean": 15.0, "episode_len_mean": 51.0, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"learned": -20.0}, "policy_reward_max": {"learned": 14.0}, "policy_reward_mean": {"learned": 3.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0], "episode_lengths": [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51], "policy_learned_reward": [-13.0, 9.0, 12.0, 7.0, -2.0, 9.0, 1.0, 7.0, -17.0, 13.0, 7.0, 12.0, 7.0, 5.0, -5.0, 8.0, 10.0, 8.0, -13.0, 10.0, -3.0, 10.0, 3.0, 5.0, -11.0, 5.0, 10.0, 11.0, 3.0, 4.0, 9.0, -1.0, -13.0, 4.0, 12.0, 12.0, 13.0, -8.0, 5.0, 5.0, 3.0, 2.0, -2.0, 12.0, 13.0, 4.0, -12.0, 10.0, -11.0, 6.0, 10.0, 10.0, -1.0, -4.0, 13.0, 7.0, 4.0, 3.0, -5.0, 13.0, 14.0, 6.0, -11.0, 6.0, -12.0, 8.0, 7.0, 12.0, 12.0, -7.0, 9.0, 1.0, -7.0, -3.0, 12.0, 13.0, 14.0, 4.0, 9.0, -12.0, -10.0, 7.0, 9.0, 9.0, -11.0, 9.0, 10.0, 7.0, 3.0, -8.0, 13.0, 7.0, 13.0, 5.0, -10.0, 7.0, -14.0, 12.0, 10.0, 7.0, -6.0, 8.0, 7.0, 6.0, 9.0, 0.0, -1.0, 7.0, 13.0, 10.0, -15.0, 7.0, 3.0, 10.0, -10.0, 12.0, 12.0, 0.0, 13.0, -10.0, -15.0, 12.0, 8.0, 10.0, 13.0, 6.0, -13.0, 9.0, -1.0, 7.0, -2.0, 11.0, 6.0, -4.0, 7.0, 6.0, -15.0, 12.0, 13.0, 5.0, 12.0, 0.0, 6.0, -3.0, 12.0, 4.0, 2.0, -3.0, -2.0, 5.0, 8.0, 4.0, 4.0, -8.0, 7.0, 12.0, 13.0, 8.0, 7.0, -13.0, 4.0, 12.0, -9.0, 8.0, 5.0, -6.0, 10.0, 6.0, -4.0, -5.0, 12.0, 12.0, 9.0, 5.0, 9.0, -8.0, 4.0, 8.0, -4.0, 7.0, 13.0, 3.0, 13.0, -14.0, 4.0, 2.0, -3.0, 12.0, 13.0, 6.0, 7.0, -11.0, -15.0, 11.0, 7.0, 12.0, 12.0, -4.0, 3.0, 4.0, 11.0, -1.0, -6.0, 11.0, 13.0, 3.0, -4.0, 3.0, -3.0, 2.0, 5.0, 11.0, -3.0, 10.0, 6.0, 2.0, 9.0, -13.0, 13.0, 6.0, 7.0, -1.0, 11.0, -2.0, -14.0, 13.0, 4.0, 12.0, 10.0, -5.0, 4.0, 6.0, 4.0, 13.0, -10.0, 8.0, 12.0, 7.0, -11.0, 7.0, -17.0, 8.0, 11.0, 13.0, 6.0, -3.0, 6.0, 6.0, -14.0, 13.0, 5.0, 11.0, 14.0, 0.0, -5.0, 6.0, -14.0, 7.0, 12.0, 10.0, 9.0, 5.0, 4.0, -3.0, -15.0, 8.0, 13.0, 9.0, 13.0, 11.0, -20.0, 11.0, 4.0, 7.0, -5.0, 9.0, -9.0, 8.0, 13.0, 3.0, -17.0, 8.0, 13.0, 11.0, 9.0, 1.0, -4.0, 9.0, 4.0, 8.0, 12.0, -9.0, -4.0, 2.0, 13.0, 4.0, 2.0, 7.0, 13.0, -7.0, 13.0, 7.0, -13.0, 8.0, -11.0, 12.0, 7.0, 7.0, 5.0, -7.0, 13.0, 4.0, 11.0, -17.0, 12.0, 9.0, 14.0, 12.0, -19.0, 8.0, 13.0, -6.0, 3.0, 5.0, 12.0, 11.0, 10.0, -18.0, -3.0, 13.0, 3.0, 2.0, 8.0, 1.0, 12.0, -6.0, 3.0, 12.0, 6.0, -6.0, -9.0, 8.0, 5.0, 11.0, 8.0, 11.0, -17.0, 13.0, 3.0, 5.0, 9.0, -2.0, -13.0, 7.0, 9.0, 12.0, -8.0, 9.0, 10.0, 4.0, 11.0, 3.0, -10.0, 11.0, 13.0, 11.0, -4.0, -5.0, 9.0, 8.0, 7.0, -9.0, -8.0, 12.0, 5.0, 6.0, 4.0, 8.0, -7.0, 10.0, 9.0, 7.0, 1.0, -2.0, -1.0, 12.0, -8.0, 12.0, 9.0, -9.0, 10.0, 5.0, -7.0, -1.0, 11.0, 12.0, 13.0, 1.0, 5.0, -4.0, -1.0, 5.0, 5.0, 6.0, -5.0, 7.0, 4.0, 9.0, 6.0, 2.0, -5.0, 12.0, 7.0, 7.0, 11.0, -10.0, -1.0, 7.0, -3.0, 12.0, -5.0, 6.0, 8.0, 6.0, 7.0, 10.0, -14.0, 12.0, 8.0, 0.0, 9.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1841384865476465, "mean_inference_ms": 1.0606867760083645, "mean_action_processing_ms": 0.07081846788485165, "mean_env_wait_ms": 0.17431898556942682, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 27, "timesteps_total": 1002456, "agent_timesteps_total": 1002456, "timers": {"sample_time_ms": 0.09, "sample_throughput": 61049343.56, "learn_time_ms": 14.344, "learn_throughput": 383984.988, "update_time_ms": 6.929}, "info": {"learner": {"learned": {"policy_loss": 1.28114914894104, "vf_loss": 20.23548698425293, "total_loss": 21.51663589477539, "vf_explained_var": -0.010135293006896973, "model": {}}}, "num_steps_sampled": 1002456, "num_agent_steps_sampled": 1002456, "num_steps_trained": 1002456, "num_agent_steps_trained": 1002456}, "done": true, "episodes_total": 19656, "training_iteration": 182, "experiment_id": "e5e7395892e84e7d817f1dc741d6df07", "date": "2021-07-21_12-48-37", "timestamp": 1626864517, "time_this_iter_s": 0.3536860942840576, "time_total_s": 65.79440593719482, "pid": 29711, "hostname": "sc-030121l", "node_ip": "10.247.64.5", "config": {"num_workers": 27, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "train_batch_size": 2000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 13, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": 0, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "masked_actions", "custom_model_config": {"model_cls": null, "framework": "tf"}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "Hearts-v0", "env_config": {"num_players": 4, "deck_size": 52, "seed": 0, "mask_actions": true}, "render_env": false, "record_env": false, "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": true, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"learned": ["<class 'ray.rllib.policy.tf_policy_template.MARWILTFPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {}], "random": ["<class 'hearts_gym.policies.random_policy.RandomPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"seed": null, "mask_actions": true}], "rulebased": ["<class 'hearts_gym.policies.rule_based_policy.RuleBasedPolicy'>", "Dict(action_mask:Box(0, 1, (13,), int8), obs:Dict(cards:Box(0, 9, (52,), int8), leading_hearts_allowed:Discrete(2)))", "Discrete(13)", {"mask_actions": true}]}, "policy_mapping_fn": "<function create_policy_mapping.<locals>.policy_mapping_all_learned at 0x7f0a18346840>", "policies_to_train": ["learned"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": true, "monitor": -1, "beta": 1.0, "vf_coeff": 1.0, "grad_clip": null, "replay_buffer_size": 1000, "learning_starts": 0}, "time_since_restore": 65.79440593719482, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 75.9, "ram_util_percent": 14.2}, "trial_id": "01041_00000"}
